{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset,TensorDataset\n",
    "from autoencoder import Autoencoder\n",
    "import torchvision\n",
    "from model2 import classification_model\n",
    "import copy\n",
    "import partition\n",
    "from pca import PCADigitReducer\n",
    "from autoencoder import reduce_dimensions\n",
    "from training import train,test, train_fashion,test_fashion\n",
    "from federated_learning import distribute_global_model, federated_averaging\n",
    "from model4 import MultilayerPerceptron\n",
    "import cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2aa02583e10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predefined stuff\n",
    "\n",
    "n_epochs = 5\n",
    "batch_size_train = 100\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.2860,), (0.3204,))  \n",
    "])\n",
    "\n",
    "fashion_mnist_train_loader = DataLoader(\n",
    "    datasets.FashionMNIST('/files/', train=True, download=True, transform=fashion_mnist_transform),\n",
    "    batch_size=batch_size_train, shuffle=True\n",
    ")\n",
    "\n",
    "fashion_mnist_test_loader = DataLoader(\n",
    "    datasets.FashionMNIST('/files/', train=False, download=True, transform=fashion_mnist_transform),\n",
    "    batch_size=batch_size_test, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_pca = copy.copy(fashion_mnist_train_loader)\n",
    "test_loader_pca = copy.copy(fashion_mnist_test_loader)\n",
    "\n",
    "train_loader_auto = copy.copy(fashion_mnist_train_loader)\n",
    "test_loader_auto = copy.copy(fashion_mnist_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTensorDataset(TensorDataset):\n",
    "    def __init__(self, *tensors):\n",
    "        super().__init__(*tensors)\n",
    "        self.data = tensors[0]\n",
    "        self.targets = tensors[1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "train_labels = []\n",
    "for data, labels in train_loader_pca:\n",
    "    train_data.append(data.view(data.size(0), -1))  \n",
    "    train_labels.append(labels)\n",
    "train_data = torch.cat(train_data, dim=0)  \n",
    "train_labels = torch.cat(train_labels, dim=0)\n",
    "\n",
    "train_data_np = train_data.numpy()\n",
    "\n",
    "pca = PCADigitReducer(100)\n",
    "train_data_reduced = pca.fit_transform(train_data_np)  \n",
    "\n",
    "train_data_reconstructed_np = pca.inverse_transform(train_data_reduced) \n",
    "train_data_reconstructed = torch.tensor(train_data_reconstructed_np, dtype=torch.float32)\n",
    "\n",
    "train_data_reconstructed = train_data_reconstructed.view(-1, 1, 28, 28)\n",
    "\n",
    "train_data_reconstructed = (train_data_reconstructed - 0.2860) / 0.3204\n",
    "\n",
    "batch_size_train = train_loader_pca.batch_size\n",
    "train_dataset_pca = CustomTensorDataset(train_data_reconstructed, train_labels)\n",
    "train_loader_reduced_pca = DataLoader(train_dataset_pca, batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.6598843336105347\n",
      "Epoch [2/5], Loss: 0.6293150186538696\n",
      "Epoch [3/5], Loss: 0.6253346800804138\n",
      "Epoch [4/5], Loss: 0.5940108895301819\n",
      "Epoch [5/5], Loss: 0.6230719089508057\n"
     ]
    }
   ],
   "source": [
    "# Autoencoder\n",
    "latent_dim = 100  \n",
    "autoencoder = Autoencoder(latent_dim=latent_dim)\n",
    "auto_criterion = nn.MSELoss()\n",
    "auto_optimizer = optim.Adam(autoencoder.parameters(), lr=1e-3)\n",
    "auto_num_epochs = 5\n",
    "for epoch in range(auto_num_epochs): \n",
    "    for images, _ in train_loader_auto:\n",
    "        auto_optimizer.zero_grad()\n",
    "        reconstructed = autoencoder(images)\n",
    "        loss = auto_criterion(reconstructed, images)  \n",
    "        loss.backward()\n",
    "        auto_optimizer.step()\n",
    "        \n",
    "    print(f\"Epoch [{epoch+1}/5], Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.eval()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "latent_features, labels = reduce_dimensions(train_loader_auto, autoencoder.encoder, device)\n",
    "latent_features = latent_features.detach()\n",
    "\n",
    "reconstructed_images = autoencoder.decoder(latent_features.to(device))  \n",
    "reconstructed_images = reconstructed_images.view(-1, 1, 28, 28)  # Reshape to [batch_size, channels, height, width]\n",
    "\n",
    "reconstructed_dataset = CustomTensorDataset(reconstructed_images.cpu(), labels)  \n",
    "reduced_train_loader_auto = DataLoader(reconstructed_dataset, batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.5\n",
    "num_clients = 10\n",
    "num_clusters = [2, 4, 6, 8, 10]\n",
    "results = {\"classic\": {}, \"pca\": {}, \"autoencoder\": {}}\n",
    "clusteredResults = {\"classic\": {}, \"pca\": {}, \"autoencoder\": {}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingset = fashion_mnist_train_loader.dataset\n",
    "trial_model_strong = MultilayerPerceptron()\n",
    "global_model_classic_strong = MultilayerPerceptron()\n",
    "rounds_classic = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.324810\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 2.199836\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.106051\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 1.900947\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 1.799925\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 1.511707\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 1.348910\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 1.207755\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 1.161974\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 1.016412\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.945645\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 0.906458\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.855002\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 0.901501\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 0.704619\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.864728\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.889839\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 0.847664\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 0.694646\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 0.868231\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.671750\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 0.718153\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.801688\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 0.750281\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.826234\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.652694\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.732019\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 0.561594\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.644146\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 0.717330\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.601688\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 0.570822\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.747713\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 0.715763\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.502512\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.482374\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.625540\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 0.787463\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.607936\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 0.512569\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.577560\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 0.650192\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.670712\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 0.612866\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.619173\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.451524\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.383784\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 0.637926\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.609271\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 0.377471\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.391996\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 0.463133\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.561105\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 0.615370\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.533281\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.442207\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.600018\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 0.539301\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.638416\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 0.475389\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.580414\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 0.604152\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.453871\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 0.430688\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.619274\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.322217\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.380576\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 0.553794\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.507959\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 0.359990\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.365472\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 0.397876\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.524049\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 0.434529\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.468780\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.409490\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.454093\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 0.364686\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.542348\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 0.418050\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.367089\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 0.350438\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.553736\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 0.471592\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.290673\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.434766\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.466006\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 0.535097\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.460422\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 0.535004\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.543002\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 0.580002\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.463393\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 0.433591\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.364949\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.406440\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.541399\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 0.446972\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.520156\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 0.477473\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.581453\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 0.351168\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.313059\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 0.495975\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.419968\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.475725\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.413279\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 0.341098\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.416840\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 0.412314\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.435924\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 0.377714\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.455753\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 0.423401\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.501808\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.440359\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.476109\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 0.396799\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.611509\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 0.403931\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.497481\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 0.467227\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.347432\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 0.389729\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.507918\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.332721\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.642288\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 0.430780\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.392851\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 0.595691\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.466406\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 0.565025\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.376547\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 0.458290\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.417238\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.553131\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.407008\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 0.447778\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.320819\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 0.528244\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.311235\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 0.490607\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.327020\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 0.571725\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.486682\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.555624\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.469706\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 0.389288\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.311727\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 0.519457\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.543178\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 0.453094\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.583476\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 0.340993\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.374385\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.556313\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.222718\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 0.550254\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.301898\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 0.408734\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.507644\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 0.317091\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.371015\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 0.406141\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.472255\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.521793\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.457967\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 0.391156\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.458224\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 0.307618\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.433541\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 0.376290\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.491311\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 0.445242\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.516759\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.425632\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.390125\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 0.366381\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.506984\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 0.358978\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.414562\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 0.402983\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.422749\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 0.415457\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.258842\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.434286\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.423274\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 0.263214\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.301198\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 0.292538\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.335005\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 0.394807\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.477822\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 0.466052\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.435278\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.446100\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.363528\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 0.472154\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.477539\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 0.600672\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.279875\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 0.360634\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.496553\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 0.367147\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.366720\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.421086\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.491356\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 0.381853\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.352628\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 0.331867\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.373716\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 0.387276\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.347098\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 0.489538\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.439314\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.532139\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.481524\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 0.442446\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.444384\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 0.269552\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.354932\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 0.298892\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.260256\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 0.276362\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.398393\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.352039\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.259183\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 0.525426\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.401250\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 0.477645\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.468421\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 0.284135\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.310752\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 0.307670\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.270601\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.250103\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.347866\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 0.330395\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.302646\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 0.402659\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.370342\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 0.377114\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.303851\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 0.409528\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.247290\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.205749\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.300834\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 0.312544\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.544163\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 0.526945\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.240526\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 0.334159\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.485901\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 0.369074\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.402577\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.456165\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.425216\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 0.200654\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.412832\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 0.354654\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.402368\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 0.316527\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.416587\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 0.327612\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.394811\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.390623\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.396238\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 0.310059\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.415494\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 0.451906\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.404993\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 0.402288\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.390684\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 0.239089\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.532247\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.175896\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.394671\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 0.409376\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.504530\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 0.563459\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.316211\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 0.305766\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.406966\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 0.467438\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.475642\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.439397\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.439275\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 0.402634\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.316285\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 0.364219\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.320714\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 0.395756\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.278752\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 0.255576\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.413563\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.375243\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.400292\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 0.302280\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.458834\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 0.349156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.3693, Accuracy: 52129/60000 (87%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 2.299964\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 1.965513\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 1.761632\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 1.626960\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 1.439416\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 1.407890\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 1.182385\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 1.140931\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 1.201632\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 1.152443\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.998125\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.936935\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.898230\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.826114\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.799782\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 2.275290\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 1.398348\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.761844\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.674585\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.676503\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.461950\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.459736\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.462349\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.696034\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.596003\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.614313\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.409051\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.249700\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.292174\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.499196\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.360735\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.240726\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.521503\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.366211\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.383516\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.257836\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.285219\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.548449\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.282312\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.301259\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.339903\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.414902\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.289536\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.246642\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.265612\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.212258\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.225920\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.244165\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.306135\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.394684\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.368617\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.240623\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.217321\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.232956\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.316486\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 2.369808\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 2.030345\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 1.466695\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 1.398935\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 1.226941\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 1.107553\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.843775\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.765072\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.766130\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.558541\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.641982\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.597409\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.552327\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.574308\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.430154\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.580851\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.525088\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.442786\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.481498\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.403975\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.433460\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.403058\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.419480\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.335523\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.527671\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.351655\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.474864\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.440226\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.323967\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.480425\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.315250\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.535501\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.395841\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.389531\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.329687\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 2.276024\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 2.007636\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 1.557413\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.971036\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 1.014056\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.675844\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.818170\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.880008\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.843863\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.680270\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.784956\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.657017\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.689601\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.640535\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.716415\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.628267\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.736552\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.437988\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.449102\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.409525\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.740670\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.499797\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.466396\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.449932\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.351576\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.573050\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.482728\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.341812\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.386266\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.384329\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 2.303612\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 2.138145\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 1.892252\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 1.339401\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 1.121604\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.904829\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 1.027071\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.992140\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.822136\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.703001\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.656795\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.814918\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.735432\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.642084\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.523944\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.735959\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.541610\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.513826\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.511451\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.653534\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.573252\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.524286\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.548409\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.532048\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.464250\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.447805\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.507006\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.572138\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.393110\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.566283\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 2.395713\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 1.959599\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 1.344444\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 1.118764\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 1.195379\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.915081\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.900490\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 1.029496\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.983801\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.957140\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.796926\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.750971\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 1.014294\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.901529\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.740989\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.756563\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.726452\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.720567\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.648924\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.763315\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 2.329176\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 2.150025\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 1.872548\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 1.640645\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 1.413126\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 1.229187\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 1.155691\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 1.107895\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 1.128352\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.948795\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 1.032607\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.888716\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.761925\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.777249\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.870742\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.748382\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.699959\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.658110\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.755686\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.683609\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.681466\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.568520\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.682082\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.630153\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.685772\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.673126\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.519873\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.568349\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.544758\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.620142\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.561380\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.664152\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.468220\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.591212\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.536272\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.451003\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.545882\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.533235\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.563594\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.458270\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.566010\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.383022\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.455359\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.475255\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.549738\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.524580\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.424856\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.434934\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.401202\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.533903\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 2.289876\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 2.023820\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 1.735570\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 1.420755\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 1.128127\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.879375\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.967232\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.999307\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.937547\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.807997\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.587178\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.710263\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.671189\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.546164\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.447672\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.472617\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.473536\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.523949\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.476013\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.465181\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.362573\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.427180\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.386232\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.464888\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.362921\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.435745\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.475567\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.263629\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.387682\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.401845\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.365621\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.484039\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.319030\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.255537\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.331602\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 2.337782\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 2.194682\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 1.945706\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 1.667629\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 1.355484\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 1.213002\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 1.116568\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 1.062785\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 1.075311\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.838476\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.792915\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.816033\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.718152\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.547072\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.580434\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.736556\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.631549\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.438205\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.473807\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.441364\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.476207\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.604761\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.503927\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.620964\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.460635\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.575163\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.447550\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.661955\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.479392\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.415346\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.408098\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.368562\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.541437\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.514763\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.295013\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 2.296719\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 2.023898\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 1.715352\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 1.334254\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 1.255499\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.988259\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.764013\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.778780\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.699509\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.797383\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.525739\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.525706\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.787791\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.631168\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.580409\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.465787\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.699338\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.702837\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.797704\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.496464\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.511234\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.431470\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.382776\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.488818\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.366275\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.366921\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.364733\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.432115\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.327656\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.360283\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.331429\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.481587\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.326956\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.376317\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.380027\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.0434, Accuracy: 6569/10000 (66%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.933691\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.882700\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.727691\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.797599\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.573314\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.690912\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.625529\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.592948\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.503134\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.618765\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.568126\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.591227\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.540161\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.722387\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.520534\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 1.629729\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.312847\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.290433\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.361181\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.362999\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.212138\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.279373\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.226294\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.270614\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.385515\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.253243\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.388092\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.205497\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.237150\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.278736\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.153195\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.137488\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.119904\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.296528\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.141101\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.128603\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.250511\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.241917\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.222947\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.248614\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.183388\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.235937\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.148488\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.307711\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.168718\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.389597\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.166559\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.188859\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.112048\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.132214\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.185702\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.247981\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.180142\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.129314\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.138988\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.867586\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.578440\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.539387\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.462104\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.535083\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.409261\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.307140\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.404637\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.352840\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.398509\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.394129\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.345650\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.253151\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.297410\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.439207\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.286605\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.421838\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.289256\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.437054\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.323087\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.330422\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.331758\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.361614\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.297885\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.244713\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.272149\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.289401\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.317514\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.274732\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.132657\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.271602\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.304524\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.462328\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.321765\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.397731\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 1.290683\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.546146\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.462158\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.456790\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.468479\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.433367\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.380172\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.407288\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.362972\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.336521\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.414320\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.370599\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.439219\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.370320\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.320023\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.297327\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.418896\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.362418\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.268780\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.355576\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.295777\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.240465\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.481155\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.413262\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.437294\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.373761\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.325608\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.370073\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.227929\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.439585\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.931264\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.639178\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.598188\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.548920\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.489949\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.513635\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.475651\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.469027\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.494772\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.515957\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.505950\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.359381\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.461543\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.419049\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.406417\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.325892\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.309091\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.428327\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.456401\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.338761\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.359839\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.403079\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.365312\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.386652\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.324158\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.472696\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.347097\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.420061\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.310302\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.378255\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.970611\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.722912\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.770930\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.509817\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.617617\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.565340\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.582182\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.427240\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.736547\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.461842\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.568882\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.565133\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.447178\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.480061\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.558910\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.465902\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.403057\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.406608\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.585218\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.575502\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.970752\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.781135\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.686905\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.692044\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.704263\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.686366\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.739292\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.537683\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.636385\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.562211\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.500151\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.590835\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.711502\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.563235\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.436810\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.501096\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.488912\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.473636\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.429352\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.631536\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.464396\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.604074\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.520747\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.553747\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.676256\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.573757\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.421921\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.340503\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.302483\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.472299\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.450242\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.474845\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.522376\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.485518\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.420014\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.450138\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.428597\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.491458\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.414262\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.581457\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.374581\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.423449\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.320733\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.499977\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.445920\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.384569\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.425926\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.452445\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.514862\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.389117\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 1.284225\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.621039\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.472252\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.391955\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.572954\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.448233\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.393600\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.354595\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.344776\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.436388\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.227323\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.462247\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.356861\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.343234\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.297000\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.409081\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.331099\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.290443\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.224799\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.466674\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.324929\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.357577\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.268407\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.322034\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.258374\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.268653\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.246582\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.382808\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.370506\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.288243\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.283892\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.296155\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.375037\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.232423\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.241667\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.852979\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.696243\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.477646\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.585738\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.439472\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.416632\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.502103\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.528748\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.489076\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.460678\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.521672\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.403885\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.601633\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.456959\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.456938\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.586407\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.443190\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.373870\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.528682\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.533695\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.555703\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.399998\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.471643\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.387259\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.416983\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.402074\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.427250\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.425999\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.415459\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.376827\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.367656\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.378512\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.434998\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.379325\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.451733\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.974196\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.582569\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.508431\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.416958\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.524133\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.396934\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.309579\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.356004\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.338615\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.512009\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.520118\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.416396\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.339519\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.340996\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.474624\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.570453\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.408768\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.274947\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.443187\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.341795\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.411635\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.380885\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.411623\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.293017\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.297296\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.321750\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.538117\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.281545\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.309227\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.345422\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.285868\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.332382\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.326340\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.357803\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.267237\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.6397, Accuracy: 7511/10000 (75%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.829609\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.613968\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.552580\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.727515\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.580750\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.526795\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.544750\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.603869\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.508280\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.560355\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.601511\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.532390\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.495481\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.400640\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.565257\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.877077\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.214776\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.249320\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.161670\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.244082\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.230686\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.220375\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.134014\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.244042\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.116422\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.257095\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.146904\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.170696\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.133452\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.110984\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.095922\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.215595\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.102864\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.225057\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.108306\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.204862\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.262563\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.249866\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.218187\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.185446\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.177591\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.159130\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.193844\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.165635\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.150159\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.163519\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.090482\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.171505\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.202813\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.216027\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.150345\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.156838\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.161630\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.262352\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.090844\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.626443\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.255386\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.269003\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.356497\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.301284\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.308728\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.394301\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.262547\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.265262\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.275660\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.208009\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.411005\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.227523\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.388420\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.172507\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.155739\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.162037\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.357526\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.267642\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.332120\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.322717\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.270218\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.365772\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.352899\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.240396\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.378808\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.326855\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.251823\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.241942\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.296450\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.265549\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.244671\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.255670\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.350513\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.399943\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.584328\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.391799\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.396074\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.409784\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.481382\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.330437\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.337638\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.276040\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.306771\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.373559\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.336022\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.292294\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.311470\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.325396\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.398893\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.314290\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.439601\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.298553\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.271169\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.283484\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.251196\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.319900\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.219316\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.281160\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.229746\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.315973\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.315849\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.223914\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.344538\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.241986\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.567133\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.476156\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.444681\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.439883\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.488063\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.434945\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.349063\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.409952\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.389885\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.395348\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.413987\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.339655\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.483641\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.478729\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.305763\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.375208\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.392951\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.464677\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.374088\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.435225\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.369034\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.246011\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.458630\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.414356\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.251180\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.352627\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.296314\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.348449\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.423229\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.430778\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.556711\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.583184\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.531835\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.324664\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.404784\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.512870\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.377747\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.425766\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.366912\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.600615\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.383577\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.499361\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.502318\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.356248\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.464781\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.317933\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.461433\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.461345\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.370664\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.412125\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.589870\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.409752\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.513029\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.450753\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.737173\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.450712\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.474798\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.484651\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.452937\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.400475\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.463361\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.480642\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.574179\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.408058\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.628485\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.449434\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.574659\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.516099\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.395904\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.495863\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.445714\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.417390\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.510054\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.250879\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.502413\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.384211\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.459616\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.477342\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.335775\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.550165\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.403831\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.241462\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.478760\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.392985\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.468234\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.401147\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.516769\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.354321\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.458165\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.418455\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.271296\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.400413\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.392500\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.567196\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.453660\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.515247\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.358074\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.541700\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.399910\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.355103\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.688103\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.541286\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.378522\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.406319\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.372611\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.283088\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.223785\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.347898\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.317773\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.262134\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.244952\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.348479\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.293540\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.264579\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.254110\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.173942\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.308347\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.264199\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.234720\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.360954\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.284504\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.358127\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.399566\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.238028\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.234169\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.298193\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.270271\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.260144\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.283453\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.214141\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.304434\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.215075\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.267050\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.338083\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.140055\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.495937\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.396911\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.329679\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.484183\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.362943\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.493518\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.427476\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.297694\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.424501\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.381919\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.485670\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.349320\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.347413\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.434590\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.423533\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.453735\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.405623\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.328078\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.397647\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.283650\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.523325\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.470136\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.347221\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.214483\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.415149\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.311147\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.320804\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.288699\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.313590\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.466224\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.386571\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.380029\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.293695\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.256314\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.432154\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.425339\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.393647\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.342104\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.378024\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.365540\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.385626\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.308501\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.371239\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.386812\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.376313\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.354846\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.258778\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.232607\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.317677\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.199072\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.343455\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.294344\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.308824\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.295458\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.354592\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.280035\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.226592\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.376642\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.249716\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.241751\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.271853\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.350754\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.239858\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.236486\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.292401\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.438087\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.367186\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.194386\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.271506\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.264078\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.5520, Accuracy: 7906/10000 (79%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.770396\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.538846\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.532021\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.564960\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.369125\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.436189\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.525912\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.537494\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.550465\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.440023\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.358794\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.435929\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.421863\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.364420\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.500354\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.621259\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.144696\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.069856\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.205355\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.211341\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.258478\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.200665\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.142611\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.141098\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.128966\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.203571\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.225051\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.161235\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.194214\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.244108\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.127259\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.099746\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.155396\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.203954\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.092372\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.236365\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.098566\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.196130\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.140338\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.166317\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.070818\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.125585\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.143239\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.223478\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.228922\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.153674\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.118823\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.140231\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.116465\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.180524\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.184995\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.142440\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.119867\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.227206\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.153220\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.504440\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.374707\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.289421\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.256542\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.276816\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.187253\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.476535\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.338069\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.357218\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.342588\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.208650\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.375680\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.228174\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.184689\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.241685\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.236347\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.217747\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.351187\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.353029\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.201951\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.305562\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.243436\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.273937\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.214740\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.288398\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.231105\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.216146\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.246378\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.147455\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.322789\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.220623\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.246231\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.281875\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.246899\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.215019\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.532003\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.272638\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.281965\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.202732\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.270750\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.335333\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.290629\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.343783\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.279393\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.294497\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.271061\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.294323\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.306857\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.397630\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.166855\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.246670\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.273896\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.310968\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.115747\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.260237\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.324042\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.384523\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.332646\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.259792\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.342618\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.223703\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.228986\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.204262\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.213770\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.300903\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.387598\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.335311\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.283430\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.413013\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.225909\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.325118\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.355219\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.228493\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.362469\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.319706\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.426061\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.368942\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.275341\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.289349\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.291651\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.446658\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.339595\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.261437\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.293057\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.300376\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.217471\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.477142\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.334940\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.398857\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.338800\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.376489\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.247291\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.251571\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.357781\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.255618\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.650136\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.408746\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.445549\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.337283\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.285529\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.343473\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.340878\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.473487\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.335400\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.327347\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.426137\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.373546\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.498118\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.471817\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.328892\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.386195\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.430176\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.413839\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.322015\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.288639\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.445430\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.374386\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.552860\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.474996\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.369760\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.405080\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.437726\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.644584\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.513751\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.454675\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.433989\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.385801\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.512210\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.439168\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.387061\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.376216\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.364621\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.361015\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.365671\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.367789\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.426541\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.383608\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.549109\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.453614\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.394381\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.402552\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.448657\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.315020\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.368498\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.390910\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.442266\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.407031\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.484824\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.389598\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.314091\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.293538\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.434711\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.340253\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.338943\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.368165\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.461801\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.322172\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.487899\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.316265\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.451127\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.306112\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.435636\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.351558\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.302441\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.537402\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.595359\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.280691\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.301385\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.277002\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.138473\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.198677\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.381113\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.295602\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.406393\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.284450\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.249798\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.191890\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.227011\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.470164\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.258778\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.282071\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.197645\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.236169\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.202636\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.230025\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.264579\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.175022\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.231923\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.332256\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.126839\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.206787\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.175289\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.230224\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.296441\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.317260\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.172756\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.236035\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.251289\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.278564\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.273690\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.577941\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.351202\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.348640\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.305277\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.504677\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.556831\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.398457\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.270774\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.452123\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.266492\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.522382\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.515631\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.450276\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.369677\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.400339\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.298650\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.335170\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.321542\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.499647\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.298342\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.276892\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.338761\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.396665\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.291346\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.287766\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.322718\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.332420\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.310766\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.300321\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.230521\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.284047\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.381648\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.349682\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.298877\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.351613\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.508368\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.468720\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.257835\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.305144\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.326432\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.385192\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.231744\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.410202\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.163896\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.250876\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.264737\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.292994\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.228957\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.243778\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.286072\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.423565\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.291741\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.281753\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.277681\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.364022\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.267102\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.294857\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.276090\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.243466\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.250193\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.362154\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.233024\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.291380\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.259015\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.170938\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.179386\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.276682\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.204383\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.266314\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.289464\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.5189, Accuracy: 8019/10000 (80%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.500887\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.382019\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.506963\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.472528\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.444264\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.445974\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.281680\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.421118\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.731651\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.354857\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.526634\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.512289\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.446087\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.390719\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.397027\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.782461\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.124934\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.167510\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.086480\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.192565\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.204770\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.111615\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.291464\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.164645\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.165804\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.059237\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.166400\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.163343\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.168143\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.160641\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.169788\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.189885\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.126466\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.139904\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.145195\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.147171\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.063278\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.178506\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.216484\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.101447\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.295990\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.259834\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.188694\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.168266\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.075622\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.134908\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.283231\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.205466\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.218352\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.147736\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.149029\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.229377\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.153815\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.139313\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.158364\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.6112, Accuracy: 7731/10000 (77%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.614357\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.496701\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.425491\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.535602\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.421861\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.389646\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.408838\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.436568\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.522003\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.421794\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.404721\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.554487\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.483631\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.352350\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.528012\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.386595\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.131797\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.111246\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.214410\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.113373\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.200262\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.231649\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.080478\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.098424\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.175707\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.195056\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.119185\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.124090\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.120294\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.144899\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.136534\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.202028\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.173049\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.159886\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.100758\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.113611\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.131041\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.102879\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.078196\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.147023\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.181194\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.167130\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.224527\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.161991\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.203059\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.116782\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.151991\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.105620\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.149290\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.134030\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.272426\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.214077\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.162074\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.077788\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.096773\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.5730, Accuracy: 7864/10000 (79%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.624253\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.499638\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.550590\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.334442\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.545166\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.372112\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.451788\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.369594\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.477423\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.428514\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.357936\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.491442\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.346525\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.362484\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.437946\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.244472\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.078187\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.088968\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.233771\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.101091\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.145367\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.218302\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.072442\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.179085\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.141771\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.080048\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.196750\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.121847\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.222549\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.133291\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.308731\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.138916\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.194760\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.223569\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.094829\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.225608\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.237032\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.174875\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.228048\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.057670\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.091323\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.171288\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.144200\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.119116\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.163606\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.173614\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.110061\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.178387\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.103757\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.100403\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.085828\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.119362\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.104060\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.079446\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.111291\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.5779, Accuracy: 7881/10000 (79%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.683212\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.671036\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.410831\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.348703\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.447387\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.661891\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.434685\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.466190\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.429904\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.406374\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.379756\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.414889\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.364976\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.320585\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.434677\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.181635\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.136121\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.149845\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.159853\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.069619\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.141105\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.154282\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.128462\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.076737\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.139925\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.141992\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.117225\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.132530\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.098115\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.107580\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.242976\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.263903\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.139039\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.152340\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.171634\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.119664\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.081855\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.064000\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.176326\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.162891\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.185323\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.137117\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.216079\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.102458\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.168467\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.102472\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.134020\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.141526\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.162492\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.168190\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.158016\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.152064\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.130374\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.107543\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.213654\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.5886, Accuracy: 7837/10000 (78%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.635427\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.297943\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.363168\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.424107\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.508273\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.412679\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.303762\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.372378\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.315812\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.307681\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.261730\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.344901\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.505364\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.285066\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.319029\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.185448\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.112201\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.139400\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.110546\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.149438\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.118067\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.193295\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.203956\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.083576\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.114850\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.139585\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.077901\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.162906\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.117265\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.118425\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.128436\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.132563\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.114408\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.134647\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.138620\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.100742\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.261215\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.114436\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.135033\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.098407\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.066182\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.206225\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.087803\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.150016\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.097564\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.156903\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.172362\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.063822\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.199944\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.101916\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.072405\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.134267\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.090493\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.150498\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.109640\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.601104\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.347108\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.242246\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.198308\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.293034\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.311556\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.224989\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.181611\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.173691\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.148853\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.190890\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.100036\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.280913\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.169637\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.202268\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.215391\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.234928\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.132492\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.297615\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.289332\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.112116\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.223493\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.309186\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.145888\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.183321\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.196719\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.261234\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.285536\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.142629\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.145738\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.103762\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.224763\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.252186\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.301533\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.202909\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.503623\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.300807\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.281297\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.214223\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.192967\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.407741\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.230467\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.367456\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.239478\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.307805\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.205958\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.165321\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.311219\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.325032\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.172502\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.235648\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.176205\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.182343\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.279089\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.197372\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.192454\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.265871\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.263939\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.262198\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.209570\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.307050\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.253070\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.158076\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.165762\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.269207\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.5569, Accuracy: 7938/10000 (79%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.535249\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.363459\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.280533\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.412716\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.385137\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.454393\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.469453\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.464122\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.320780\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.350330\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.376677\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.466685\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.247958\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.465331\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.244056\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.438387\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.076885\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.113917\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.067979\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.177258\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.092665\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.059617\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.065587\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.090944\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.181671\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.158177\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.133373\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.122648\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.255046\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.060923\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.062866\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.156158\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.084214\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.114308\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.079204\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.107296\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.111024\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.128690\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.090721\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.079450\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.103122\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.115767\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.191515\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.071742\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.191846\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.149667\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.121023\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.081109\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.098521\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.121166\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.116658\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.040319\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.080182\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.141609\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.100303\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.503312\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.182795\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.188394\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.238868\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.148185\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.183523\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.174069\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.186698\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.254026\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.203837\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.192910\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.159450\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.236698\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.243066\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.192494\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.255779\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.205642\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.112615\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.294606\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.171679\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.072909\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.299889\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.208791\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.264165\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.293437\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.319115\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.335967\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.194799\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.120401\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.107691\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.175999\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.184016\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.114783\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.177519\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.140684\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.460975\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.347011\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.289450\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.267044\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.225596\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.176782\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.293542\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.178565\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.272758\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.274970\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.298777\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.196192\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.275188\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.280949\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.304023\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.219854\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.374187\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.230531\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.196500\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.155056\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.248525\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.303627\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.240118\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.242875\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.220731\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.162999\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.286947\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.281156\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.243171\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.145168\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.5165, Accuracy: 8076/10000 (81%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.500653\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.417742\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.332087\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.374935\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.473843\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.362813\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.434873\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.321883\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.328021\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.218007\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.281050\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.340429\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.413754\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.357719\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.267018\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.318202\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.134593\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.141500\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.142878\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.189235\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.194052\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.097093\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.108893\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.086972\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.091154\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.177358\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.217228\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.127598\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.069668\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.105421\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.131714\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.109699\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.096035\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.112159\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.070953\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.273622\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.115681\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.212647\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.125566\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.107189\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.141750\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.137069\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.169362\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.060627\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.074571\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.106716\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.111731\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.188653\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.047254\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.107568\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.102347\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.099026\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.096406\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.124560\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.049381\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.389136\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.187134\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.154161\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.267033\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.220269\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.317749\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.223560\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.264924\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.285972\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.166042\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.229503\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.155776\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.118279\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.178390\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.217917\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.204170\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.223960\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.247390\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.205531\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.177305\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.131635\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.198247\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.181512\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.115364\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.257028\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.237110\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.272352\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.093589\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.157085\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.112376\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.229001\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.148486\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.124481\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.171456\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.159221\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.330629\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.221338\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.230849\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.237320\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.213541\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.210318\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.309655\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.218798\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.147425\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.183883\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.269716\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.341232\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.239656\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.280907\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.136354\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.257181\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.110523\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.188775\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.149611\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.188641\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.242823\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.231033\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.202188\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.134539\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.221307\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.291647\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.250815\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.180084\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.168635\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.155179\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.5320, Accuracy: 8022/10000 (80%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.316697\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.310045\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.419449\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.451377\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.300747\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.350556\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.470199\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.491921\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.363394\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.179636\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.322899\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.289020\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.515457\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.348669\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.323217\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.364842\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.118267\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.093210\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.087781\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.094262\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.178166\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.198301\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.198629\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.092509\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.170471\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.104077\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.102522\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.078423\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.219212\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.193351\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.120347\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.147621\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.146258\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.139654\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.107337\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.074259\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.248437\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.118902\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.170692\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.202215\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.098695\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.173548\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.184857\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.069430\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.135562\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.141307\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.112681\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.068501\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.132119\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.077374\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.115595\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.078189\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.140495\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.084583\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.205088\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.355026\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.191428\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.143065\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.227046\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.184002\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.134973\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.074343\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.237506\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.130421\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.207484\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.336352\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.244260\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.202283\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.176850\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.160535\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.131894\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.085575\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.280859\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.130303\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.183016\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.199729\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.174654\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.118757\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.298307\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.248032\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.127934\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.137724\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.112693\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.189222\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.125995\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.224242\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.142676\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.114054\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.174132\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.152726\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.478359\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.252192\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.236251\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.242801\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.267997\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.210377\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.241073\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.331425\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.124023\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.183002\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.245603\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.135982\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.199300\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.249021\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.181597\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.164644\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.181092\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.271757\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.128855\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.169968\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.240545\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.147068\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.249958\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.216718\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.215323\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.120912\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.186755\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.252357\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.162803\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.210484\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.5280, Accuracy: 8034/10000 (80%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.480296\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.370291\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.341335\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.202191\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.388373\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.448406\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.233708\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.302684\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.474986\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.247980\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.259690\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.411826\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.416101\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.212972\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.384769\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.341472\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.139380\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.170782\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.168333\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.145355\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.149341\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.089870\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.103078\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.091406\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.127923\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.085936\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.141809\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.118475\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.099757\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.231298\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.125682\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.102293\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.132697\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.092372\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.097975\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.159654\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.062537\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.057210\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.154912\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.115247\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.190843\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.096387\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.100933\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.069469\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.047023\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.046399\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.168081\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.046805\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.121991\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.096560\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.144742\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.129576\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.128837\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.065453\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.279841\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.380377\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.149143\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.220355\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.176919\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.188311\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.321970\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.253738\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.215750\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.403892\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.117919\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.179154\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.197505\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.070891\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.168596\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.185582\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.197964\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.133721\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.183956\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.317524\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.162326\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.207018\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.166006\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.161973\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.079752\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.126727\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.221085\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.136873\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.187966\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.112948\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.229183\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.307179\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.264429\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.171017\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.164476\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.099604\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.397008\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.206716\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.242763\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.190290\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.297277\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.226381\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.266816\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.222213\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.245478\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.210272\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.179516\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.109804\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.282205\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.261310\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.168201\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.295089\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.256532\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.210933\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.176585\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.160852\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.183685\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.315859\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.188690\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.190408\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.225827\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.220166\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.279833\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.182970\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.272901\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.251163\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.676845\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.274072\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.396108\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.285357\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.390682\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.182967\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.345863\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.305360\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.358987\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.366989\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.251339\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.176183\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.269082\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.293832\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.492651\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.305795\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.324966\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.289890\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.334142\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.200644\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.294549\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.234962\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.249181\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.301361\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.277292\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.353486\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.241124\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.308706\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.248544\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.235997\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.668325\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.381778\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.422946\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.330520\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.317740\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.362590\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.293546\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.384323\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.325765\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.304014\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.256209\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.336075\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.309697\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.340362\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.411967\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.211396\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.352014\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.237506\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.296017\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.278630\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4633, Accuracy: 8279/10000 (83%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.313426\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.377956\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.433854\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.439377\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.288384\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.260827\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.326926\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.367038\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.436077\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.355846\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.288097\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.400062\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.297141\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.444593\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.417293\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.462580\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.252053\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.084165\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.181746\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.166242\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.124471\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.193024\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.076051\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.172570\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.165023\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.058501\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.122276\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.116911\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.115223\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.066678\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.151694\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.130563\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.138109\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.144277\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.150945\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.052383\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.212493\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.105638\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.210374\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.034665\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.162486\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.177305\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.096032\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.067311\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.122407\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.134052\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.145249\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.137833\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.053686\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.102218\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.068178\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.055474\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.164800\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.036612\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.086414\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.248445\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.183571\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.236735\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.176470\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.156673\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.170420\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.217810\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.208690\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.171675\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.256969\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.173581\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.159612\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.182227\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.203606\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.247513\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.192815\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.182920\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.207010\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.147963\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.167696\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.344988\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.147964\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.161751\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.258140\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.182209\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.158808\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.156319\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.174077\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.164362\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.129444\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.102248\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.114742\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.206824\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.210942\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.275856\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.402337\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.372490\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.229639\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.150695\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.177259\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.226852\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.183766\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.269160\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.223977\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.142295\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.286215\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.125249\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.197790\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.267808\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.184793\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.205147\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.308998\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.208099\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.168256\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.337830\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.401770\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.166256\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.319550\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.149931\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.193189\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.193545\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.078623\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.171661\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.117353\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.190290\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.356937\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.353040\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.213214\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.434648\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.419162\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.221595\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.206352\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.251128\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.393094\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.313731\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.285284\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.305148\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.287636\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.224038\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.225711\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.334950\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.274415\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.311905\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.330519\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.363862\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.192529\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.308922\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.217059\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.390683\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.368219\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.218192\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.317768\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.265980\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.231223\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.300557\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.453811\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.320144\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.336049\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.429674\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.186715\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.279220\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.320423\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.330088\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.323980\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.208957\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.299283\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.336754\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.259389\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.240175\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.339536\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.313369\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.193696\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.149861\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.391522\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.223915\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4645, Accuracy: 8260/10000 (83%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.465519\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.284680\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.387725\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.377923\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.339463\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.328807\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.232083\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.252383\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.297347\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.257904\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.442151\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.266212\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.464739\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.340273\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.292117\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.610128\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.092431\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.087446\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.160718\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.161555\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.135659\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.070340\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.183124\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.201034\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.118628\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.090943\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.109537\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.069644\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.135046\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.252120\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.093088\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.130366\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.182314\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.244705\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.108918\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.067560\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.087555\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.132075\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.079243\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.126544\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.115586\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.125635\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.051412\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.164609\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.085356\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.106465\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.063624\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.026062\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.175544\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.096097\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.092657\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.107864\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.031515\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.068693\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.191126\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.390227\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.098234\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.206133\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.240454\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.236581\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.071747\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.217939\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.170164\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.167633\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.239075\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.129090\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.174715\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.091528\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.138441\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.240676\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.237286\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.265940\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.182578\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.144414\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.139528\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.110570\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.147876\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.129965\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.136248\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.154091\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.147267\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.097203\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.173845\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.073858\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.164832\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.179480\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.193333\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.199472\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.115780\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.189245\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.245195\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.292318\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.195475\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.187069\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.168525\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.163106\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.193552\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.166830\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.300238\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.154611\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.131156\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.203013\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.171245\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.178078\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.181838\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.215385\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.076900\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.266324\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.218077\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.222200\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.256103\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.111430\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.342359\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.241406\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.183560\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.244693\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.161837\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.161398\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.206354\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.181883\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.329196\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.289000\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.269634\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.282959\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.203360\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.343534\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.141024\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.478367\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.227100\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.216175\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.230901\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.265021\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.255071\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.188158\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.296216\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.341270\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.326699\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.196826\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.289286\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.257543\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.236822\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.168207\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.325645\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.265769\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.302720\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.306634\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.247049\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.218291\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.245684\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.161884\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.341858\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.320187\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.370208\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.313560\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.274234\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.253134\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.228716\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.366644\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.327696\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.322291\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.295561\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.342444\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.252451\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.212343\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.395217\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.395105\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.394796\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.297576\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.152874\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.283852\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4653, Accuracy: 8267/10000 (83%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.301158\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.346530\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.359624\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.334856\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.361796\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.353143\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.330088\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.419450\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.240356\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.463127\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.275776\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.392002\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.330308\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.323163\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.280493\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.435316\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.136965\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.173631\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.057712\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.090933\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.160195\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.167796\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.112604\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.142054\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.267021\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.087914\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.062786\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.092354\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.047291\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.119297\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.216399\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.066853\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.111694\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.254017\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.048328\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.130438\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.076901\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.056887\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.100846\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.086789\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.033695\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.063067\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.069524\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.116832\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.154853\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.146866\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.111468\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.075651\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.094869\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.158888\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.037162\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.136099\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.139861\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.121079\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.053735\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.305856\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.194776\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.179371\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.113019\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.180371\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.162150\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.167281\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.171290\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.235158\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.143703\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.252334\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.151072\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.163403\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.268016\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.204613\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.138932\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.170845\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.194104\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.119494\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.165003\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.138114\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.178856\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.127451\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.095485\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.150605\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.113556\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.205251\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.219078\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.127373\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.124030\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.170989\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.095615\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.194816\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.104300\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.124260\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.529208\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.161000\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.218588\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.128547\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.159386\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.212184\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.216593\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.190245\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.247505\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.121890\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.163965\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.137269\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.104155\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.114812\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.234975\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.251284\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.152165\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.216952\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.169476\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.230376\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.196052\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.164652\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.251467\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.151082\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.196571\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.154006\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.147927\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.249077\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.158714\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.252031\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.447678\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.389153\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.478643\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.318129\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.306162\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.360198\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.334020\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.197084\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.384445\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.287907\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.227417\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.215822\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.376383\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.290380\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.198151\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.260488\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.173615\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.162003\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.264838\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.283554\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.284736\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.211419\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.262749\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.286691\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.355068\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.321031\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.252845\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.190155\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.337745\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.213747\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.443454\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.330688\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.237016\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.290297\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.367371\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.222188\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.354357\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.491090\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.305587\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.396866\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.206703\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.397701\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.311782\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.265509\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.230379\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.335479\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.278613\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.269577\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.274405\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.227032\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4457, Accuracy: 8338/10000 (83%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.439488\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.394133\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.323807\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.274360\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.298755\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.338351\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.445281\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.238894\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.369115\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.247024\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.381667\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.262393\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.327939\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.332423\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.275603\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.380541\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.074177\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.113199\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.200506\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.086675\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.098490\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.122597\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.115974\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.111583\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.071316\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.179275\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.052632\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.055235\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.135853\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.113396\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.112774\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.067710\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.147082\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.050861\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.082823\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.161960\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.164155\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.089519\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.072622\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.152212\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.090953\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.085445\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.101530\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.058766\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.088110\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.102670\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.154813\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.085795\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.117424\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.097731\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.107778\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.074069\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.048166\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.133591\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.087837\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.402609\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.238885\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.168251\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.125900\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.131197\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.113855\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.257813\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.171846\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.093651\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.158814\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.200104\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.143793\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.184360\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.164171\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.245224\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.138776\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.061300\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.129076\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.148634\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.252025\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.167038\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.189095\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.176721\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.126105\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.065685\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.200650\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.153481\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.103291\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.072402\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.141795\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.169986\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.124068\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.109491\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.218039\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.101144\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.282995\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.100764\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.214394\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.175689\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.245028\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.169841\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.145503\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.172581\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.258976\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.196607\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.206970\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.133947\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.177770\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.177523\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.189255\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.268234\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.238402\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.122428\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.220003\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.164792\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.146701\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.227280\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.216047\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.105462\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.210506\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.185086\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.166979\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.215341\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.141179\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.145747\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.448295\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.249598\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.476208\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.248312\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.228297\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.255802\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.272716\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.237595\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.284694\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.189721\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.353618\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.320830\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.194358\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.209226\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.370060\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.338807\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.217559\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.189926\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.209729\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.245129\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.171261\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.275899\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.244991\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.197318\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.251304\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.329848\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.120887\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.258641\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.180878\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.313248\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.428076\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.235301\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.270045\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.314400\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.238950\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.366104\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.268074\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.263234\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.212474\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.292374\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.331140\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.275094\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.222919\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.160134\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.398868\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.257040\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.263258\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.233526\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.337690\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.210231\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.546273\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.270326\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.316426\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.283797\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.361059\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.407858\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.284666\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.216411\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.276529\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.550731\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.294631\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.485200\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.344340\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.233092\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.257008\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.403940\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.301431\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.348728\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.399516\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.337731\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.251262\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.385928\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.319407\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.423660\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.357746\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.322975\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.269967\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.298674\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.271091\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.292546\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.333531\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.260746\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.363934\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.159949\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.423121\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.230378\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.305471\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.339463\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.312779\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.229776\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.435758\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.295043\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.212635\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.254968\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.378882\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.246290\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.352076\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.443674\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.262046\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.285436\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.516221\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.277762\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.433942\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.257728\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.242455\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.112095\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.265293\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.233416\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.197868\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.227322\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.209450\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.201811\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.112594\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.168474\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.284295\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.207601\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.281308\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.181599\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.209165\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.248345\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.182300\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.124836\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.182023\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.184563\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.393641\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.217027\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.166699\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.152040\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.228816\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.270225\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.149510\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.145622\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.171464\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.276845\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.352466\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4280, Accuracy: 8437/10000 (84%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.449816\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.535491\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.364424\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.446337\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.363936\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.293811\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.355939\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.235938\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.402319\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.379435\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.474570\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.267377\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.454380\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.229320\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.302477\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.225566\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.300426\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.152115\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.088727\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.085718\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.047184\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.174625\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.202991\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.088217\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.047169\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.031645\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.134508\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.109646\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.073338\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.120395\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.052781\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.133223\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.138022\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.131175\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.070953\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.101667\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.115194\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.105701\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.207721\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.066434\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.055128\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.088664\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.129434\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.094469\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.127973\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.055044\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.061049\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.116923\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.131657\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.084350\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.095432\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.165688\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.137591\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.040036\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.156660\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.222894\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.062312\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.121521\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.211360\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.161291\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.233297\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.067284\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.229023\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.204286\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.167643\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.184016\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.150835\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.165815\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.197172\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.177177\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.124537\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.267792\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.175591\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.160627\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.136878\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.216341\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.106674\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.154854\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.130612\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.206086\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.136780\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.084988\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.254116\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.122084\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.093688\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.159194\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.118489\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.154745\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.150955\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.179223\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.353624\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.309577\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.158668\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.170484\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.141171\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.223124\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.152062\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.206137\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.181623\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.167988\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.150454\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.109205\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.253933\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.184717\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.219792\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.224449\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.276889\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.107432\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.127753\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.192482\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.111100\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.242365\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.193971\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.158249\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.246650\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.141939\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.188796\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.223793\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.132329\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.197588\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.341802\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.259813\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.354301\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.215790\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.313867\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.204550\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.122877\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.239477\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.219275\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.200539\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.210392\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.286286\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.160120\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.333899\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.267033\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.217868\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.230626\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.255229\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.118423\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.250435\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.290985\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.235493\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.167033\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.400648\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.196857\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.253929\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.381078\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.158984\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.332348\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.212057\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.335237\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.439253\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.221639\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.302298\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.217410\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.324866\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.291378\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.349574\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.253632\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.239253\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.331290\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.264455\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.209553\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.261513\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.371308\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.164985\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.388101\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.258368\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.288216\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.162839\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.325081\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.205396\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.348545\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.341452\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.388571\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.388096\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.402811\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.425253\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.395993\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.332349\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.361285\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.239412\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.339696\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.312579\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.175593\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.194173\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.320047\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.371881\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.473968\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.499561\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.357144\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.368912\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.290088\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.208057\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.428087\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.475484\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.338398\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.362988\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.336388\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.324702\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.270949\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.411575\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.273769\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.378643\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.312456\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.242507\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.444081\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.286691\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.264265\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.219111\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.284898\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.270561\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.424625\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.296074\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.267684\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.251573\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.334347\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.237630\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.239400\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.225432\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.501166\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.211736\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.239532\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.304718\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.333653\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.254898\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.082909\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.222165\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.128273\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.179133\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.167742\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.185251\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.147888\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.238577\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.148814\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.103868\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.206114\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.135680\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.176457\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.234174\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.160890\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.141412\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.267346\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.221011\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.328245\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.105949\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.256102\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.105942\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.198236\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.229997\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.124852\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.138927\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.101058\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.200607\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.183959\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4304, Accuracy: 8418/10000 (84%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.509774\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.408769\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.326538\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.384699\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.289908\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.307496\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.343029\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.317717\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.271968\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.396832\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.283031\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.270048\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.320551\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.355712\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.209182\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.421618\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.132065\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.174381\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.101809\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.209508\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.108124\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.095608\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.163012\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.105774\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.220821\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.120439\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.155948\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.221808\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.146292\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.088858\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.094981\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.083229\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.089294\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.119524\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.144571\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.170598\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.084721\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.039555\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.060015\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.093680\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.149583\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.132029\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.190369\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.070972\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.159601\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.133805\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.082344\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.074670\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.083580\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.143734\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.073498\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.169554\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.126269\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.214271\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.083494\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.226422\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.301716\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.165398\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.142951\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.136736\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.119124\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.162435\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.164628\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.169553\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.152155\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.204782\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.145661\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.144790\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.116377\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.186240\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.150487\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.191218\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.248126\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.227726\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.127422\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.126142\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.169937\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.183578\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.116841\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.149583\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.182512\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.111065\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.075451\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.134593\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.107665\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.108904\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.099824\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.064942\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.112873\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.148458\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.437701\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.210965\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.106981\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.228263\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.143041\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.154804\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.258173\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.137008\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.244326\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.171075\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.287871\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.144231\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.190742\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.149424\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.167557\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.153575\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.116506\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.268956\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.133483\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.195066\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.237998\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.243144\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.132926\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.187208\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.240441\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.085774\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.158928\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.194073\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.260497\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.185079\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.274237\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.176862\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.280558\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.212067\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.169040\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.291654\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.280885\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.322976\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.383591\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.287307\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.142998\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.276045\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.248933\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.308125\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.185763\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.162072\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.302305\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.238472\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.188637\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.202250\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.247202\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.368198\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.271018\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.286635\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.269515\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.110271\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.321524\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.162679\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.326067\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.172672\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.383849\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.252042\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.287120\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.353105\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.301740\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.187237\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.322618\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.136667\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.290091\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.303671\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.311815\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.272723\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.226853\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.370702\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.215177\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.198354\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.232574\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.230685\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.257182\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.218447\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.493722\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.379336\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.373594\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.347313\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.397937\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.466038\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.348244\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.299375\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.413687\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.345539\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.238872\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.244306\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.315119\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.320967\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.232003\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.353386\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.338239\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.265790\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.369880\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.493199\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.344028\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.293072\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.379888\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.300580\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.334170\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.472048\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.317791\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.276863\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.190891\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.300636\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.306495\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.331406\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.343955\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.332971\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.241247\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.421024\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.377012\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.454268\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.402852\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.389093\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.190745\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.221748\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.448711\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.256056\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.215448\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.344926\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.240904\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.265505\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.323541\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.326500\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.466124\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.244786\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.247594\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.231194\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.105352\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.242283\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.363579\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.241128\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.350783\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.178828\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.215182\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.140921\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.194150\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.193848\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.096748\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.193075\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.214946\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.173796\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.169206\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.157530\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.184911\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.265809\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.245684\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.292753\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.122950\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.282575\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.311996\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.257342\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.243895\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.141361\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.225947\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.218705\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.135591\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.241753\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.205544\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4187, Accuracy: 8451/10000 (85%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.394975\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.351484\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.350288\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.314036\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.356287\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.355446\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.245600\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.278646\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.263010\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.289008\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.303709\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.334778\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.311602\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.241008\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.366137\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.384072\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.120468\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.096351\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.102422\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.152843\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.122949\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.063217\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.098376\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.166263\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.125466\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.098151\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.210909\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.113942\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.098304\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.072665\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.105500\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.101612\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.110016\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.133412\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.047716\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.061761\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.331761\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.141252\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.078711\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.200506\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.109661\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.065364\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.040520\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.175826\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.084921\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.064465\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.071186\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.081237\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.062698\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.087457\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.071689\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.120506\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.131936\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.059456\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.078833\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.255350\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.153657\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.161781\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.162278\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.103265\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.130723\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.198827\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.144993\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.195002\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.069039\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.102819\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.103998\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.159999\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.116462\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.104198\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.241030\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.281363\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.143213\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.179670\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.141633\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.261535\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.163676\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.124491\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.157793\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.107250\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.147466\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.177518\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.167975\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.179179\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.188274\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.081704\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.123455\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.051407\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.188354\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.220947\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.373945\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.197416\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.117467\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.204086\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.134934\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.128630\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.180709\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.178828\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.204866\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.204865\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.192458\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.336077\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.170568\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.161393\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.158624\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.157860\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.194436\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.082019\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.224602\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.153757\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.102462\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.197819\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.106625\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.144720\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.137402\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.270498\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.201050\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.087591\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.171424\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.175467\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.380377\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.193854\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.329817\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.318155\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.131330\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.376493\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.256065\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.209562\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.239619\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.303535\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.248002\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.200953\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.283431\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.274092\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.192800\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.248339\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.160173\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.272151\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.437426\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.272129\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.212732\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.181824\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.200003\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.256799\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.185793\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.229562\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.273273\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.174681\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.209659\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.230660\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.323343\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.303708\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.170368\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.233367\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.267712\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.288378\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.196266\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.355669\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.222490\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.389749\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.249880\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.311246\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.235971\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.310277\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.360868\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.275044\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.177525\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.292679\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.215483\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.310086\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.280205\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.269674\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.399991\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.332907\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.471556\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.327160\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.280262\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.257396\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.217466\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.293266\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.308103\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.222476\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.307647\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.367186\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.407704\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.273917\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.365750\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.225719\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.265280\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.414609\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.283398\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.276026\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.344714\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.317861\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.345878\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.224384\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.362606\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.412104\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.369222\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.390708\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.275350\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.305981\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.233026\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.268541\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.302939\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.227515\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.308596\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.198859\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.335352\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.221295\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.417778\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.292751\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.267842\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.420103\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.272425\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.297842\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.260935\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.268357\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.385502\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.228800\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.416335\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.161483\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.215190\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.157403\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.296668\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.243784\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.138880\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.121290\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.158049\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.138184\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.141919\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.170149\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.147185\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.119407\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.300448\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.078963\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.285208\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.093543\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.196145\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.191382\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.123965\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.309944\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.098082\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.217126\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.192745\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.142953\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.254623\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.291857\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.276522\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.169363\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.385575\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.126809\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.131555\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.160967\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.266976\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4129, Accuracy: 8512/10000 (85%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.375273\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.216217\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.300408\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.401906\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.344527\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.355000\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.252813\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.270180\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.283094\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.281114\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.366120\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.406946\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.289071\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.237947\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.394845\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.403660\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.039613\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.057862\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.140688\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.227221\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.061751\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.108519\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.076531\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.064883\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.142907\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.115207\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.070758\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.081155\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.097807\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.142061\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.134734\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.077593\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.107302\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.061172\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.105573\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.072295\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.123584\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.100626\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.123746\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.122585\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.127838\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.095940\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.103130\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.145732\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.073234\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.088869\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.063908\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.061237\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.095478\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.059261\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.081771\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.028503\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.079255\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.149288\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.033608\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.260394\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.176086\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.121409\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.096314\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.148213\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.166171\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.163831\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.108048\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.197647\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.125061\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.128394\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.205528\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.195371\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.180286\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.167488\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.207576\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.101126\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.173475\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.163799\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.131793\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.294282\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.144550\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.115480\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.094361\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.158791\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.208049\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.234121\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.133201\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.143032\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.120491\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.096883\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.150784\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.243862\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.156822\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.149671\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.274209\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.145350\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.279261\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.127693\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.267881\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.233331\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.189304\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.198858\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.222644\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.207339\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.115172\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.175022\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.157949\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.197068\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.166565\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.250327\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.177169\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.275834\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.280904\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.139330\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.168491\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.166243\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.142595\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.138923\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.110964\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.262107\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.222513\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.076484\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.165108\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.119224\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.339904\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.253423\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.343849\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.087500\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.241586\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.266636\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.344393\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.283680\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.172822\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.243913\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.225844\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.316237\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.220761\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.344830\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.261464\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.204745\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.243806\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.307930\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.198056\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.228065\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.232130\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.188932\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.220412\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.261135\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.156838\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.324377\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.245389\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.234372\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.181873\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.267095\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.325007\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.348668\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.227319\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.285515\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.234964\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.328486\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.228910\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.496319\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.225344\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.182211\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.235950\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.336697\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.265277\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.320366\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.349402\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.243839\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.253861\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.183536\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.252712\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.189497\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.417535\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.222301\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.248412\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.306822\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.237921\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.257765\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.548745\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.379957\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.318726\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.264625\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.468987\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.309684\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.269191\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.309622\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.326329\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.336465\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.225924\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.390424\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.353079\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.275835\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.272440\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.303875\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.301186\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.362685\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.274206\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.292015\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.280785\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.312649\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.329613\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.352130\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.312929\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.234960\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.380977\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.240192\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.247428\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.394477\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.256888\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.460528\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.272937\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.230389\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.310049\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.207001\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.283837\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.315699\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.271453\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.268417\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.277556\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.266034\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.167090\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.286502\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.475802\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.055464\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.228400\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.246145\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.093613\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.208596\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.215891\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.307884\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.211871\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.160201\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.197733\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.222398\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.173476\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.340038\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.188358\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.127712\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.258006\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.147573\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.175625\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.120521\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.172740\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.272080\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.103985\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.261088\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.166147\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.169471\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.125096\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.198269\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.232527\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.081231\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.160310\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.268830\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.187467\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.103714\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.167061\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.395338\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.418160\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.257732\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.182552\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.552691\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.263562\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.243744\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.232041\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.245275\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.209341\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.259619\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.398465\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.229167\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.167612\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.263795\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.192087\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.292960\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.314796\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.212532\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.259431\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.328355\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.209991\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.209216\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.262997\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.301999\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.316995\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.214546\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.251117\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.242222\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.308223\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.209031\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.419693\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.315505\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.324907\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.271946\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.360968\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.303659\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.191570\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.220086\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.180798\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.264925\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.343936\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.186845\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.171431\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.420788\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.134599\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.221988\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.104247\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.182949\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.201176\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.133795\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.205780\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.217759\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.159883\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.280947\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.208376\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.183285\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.151700\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.185774\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.195532\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.247300\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.158134\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.244990\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.128497\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.126114\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.338492\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.184999\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.310859\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.251372\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.210229\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4158, Accuracy: 8490/10000 (85%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.418002\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.337875\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.337506\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.239235\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.362800\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.400231\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.208260\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.296860\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.349176\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.372782\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.283956\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.223619\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.521721\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.210856\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.246639\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.411436\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.129119\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.070177\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.146128\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.133508\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.218738\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.072416\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.097503\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.109287\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.110487\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.065214\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.144508\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.105685\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.078742\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.088861\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.080560\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.098110\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.133664\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.119969\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.070524\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.138133\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.129531\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.095134\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.177369\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.096989\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.167357\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.053063\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.147432\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.036745\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.098194\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.096253\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.090853\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.014745\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.033778\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.083421\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.113663\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.129417\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.080997\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.172212\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.078923\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.312296\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.173799\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.235757\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.152544\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.187366\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.204778\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.217539\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.261244\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.108392\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.246933\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.177643\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.104938\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.077216\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.071061\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.095222\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.111602\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.145799\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.062793\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.154044\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.102565\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.219996\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.102029\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.109916\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.129836\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.180686\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.161512\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.062027\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.123578\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.160000\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.073232\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.131268\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.097637\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.157858\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.116402\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.181711\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.323583\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.176661\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.210773\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.240804\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.202911\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.177528\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.222382\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.173965\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.197694\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.149157\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.209521\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.163975\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.297490\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.223810\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.173459\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.117052\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.128514\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.270574\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.175038\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.291236\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.157509\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.157733\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.117414\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.175725\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.101515\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.142132\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.149651\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.171895\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.063464\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.136210\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.149881\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.190351\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.209792\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.226776\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.252802\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.194885\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.266812\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.311218\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.167397\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.318180\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.198925\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.247152\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.239685\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.177707\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.250063\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.146388\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.326795\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.201897\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.227288\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.206479\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.232272\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.207160\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.171246\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.218210\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.229294\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.194843\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.290320\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.189856\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.191589\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.161382\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.248508\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.365011\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.320883\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.351769\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.198170\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.231161\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.268949\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.232685\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.225015\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.272278\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.289015\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.162868\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.304669\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.258030\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.283584\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.307563\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.254028\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.146807\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.219379\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.278374\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.361245\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.234166\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.152131\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.323506\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.386943\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.330875\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.240369\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.290184\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.214840\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.329439\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.264360\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.241169\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.205177\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.354986\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.275992\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.266571\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.369615\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.343918\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.405149\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.455640\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.327112\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.291802\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.209076\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.209473\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.196146\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.233799\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.298534\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.242408\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.412265\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.206427\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.297772\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.375039\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.390482\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.198260\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.337919\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.235769\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.127476\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.268183\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.338129\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.390484\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.210065\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.320735\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.231841\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.280095\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.270634\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.290917\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.205912\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.253096\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.233343\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.149124\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.534285\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.130803\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.119820\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.159551\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.224213\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.284135\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.229739\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.252105\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.123784\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.270317\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.104891\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.216691\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.192474\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.101213\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.226488\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.311200\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.145224\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.103642\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.198924\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.161069\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.157881\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.190127\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.185907\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.155443\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.258323\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.252685\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.248074\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.136072\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.123629\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.305530\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.148071\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.160896\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.148990\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.140709\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.151347\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.320188\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.115115\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.352276\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.219593\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.287524\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.370244\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.297750\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.266093\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.207849\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.295321\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.239751\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.240337\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.321508\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.318711\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.354608\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.308077\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.310473\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.221806\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.138192\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.219055\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.206299\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.296909\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.159779\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.152798\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.213801\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.220990\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.105032\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.180043\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.154037\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.248653\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.220003\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.267072\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.235068\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.279580\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.278989\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.319333\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.214042\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.213881\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.215115\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.158751\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.287678\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.174772\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.327299\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.237436\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.246984\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.237732\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.193119\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.186815\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.127730\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.194230\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.215414\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.166274\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.124898\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.139076\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.220398\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.254056\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.162657\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.269530\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.220683\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.216727\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.116166\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.215095\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.108948\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.161547\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.131353\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.158294\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.213149\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.193738\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.137835\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.208965\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4128, Accuracy: 8482/10000 (85%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.282811\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.403103\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.321206\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.394571\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.266444\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.403252\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.235670\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.285423\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.290858\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.217089\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.369661\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.279292\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.355397\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.222198\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.270075\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.343793\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.189663\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.150233\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.130408\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.102034\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.098362\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.105492\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.059753\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.098385\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.124275\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.079080\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.118519\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.084672\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.100550\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.188014\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.215057\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.132314\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.066236\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.130201\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.091815\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.075090\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.124918\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.197370\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.091346\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.063078\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.134817\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.059947\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.095836\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.060998\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.168050\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.018331\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.103536\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.105222\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.084290\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.065353\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.070366\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.074767\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.158515\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.129063\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.040355\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.408164\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.111114\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.160132\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.146833\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.162477\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.139978\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.169158\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.254060\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.144205\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.097441\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.113652\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.143300\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.154909\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.132743\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.172524\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.119789\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.097079\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.145302\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.199568\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.159065\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.150109\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.102920\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.184894\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.173159\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.149474\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.156736\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.179896\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.120552\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.209463\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.263287\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.095746\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.214545\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.151540\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.173182\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.105402\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.340379\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.261780\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.221503\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.254238\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.161396\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.281675\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.221176\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.203036\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.158690\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.196810\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.212784\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.239588\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.234510\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.178770\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.167985\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.111035\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.145902\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.241591\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.194636\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.220765\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.149725\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.117585\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.160280\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.177904\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.089720\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.187041\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.089357\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.118688\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.146928\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.137936\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.321280\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.257029\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.217186\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.231428\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.324425\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.302832\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.119946\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.162308\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.359800\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.283238\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.196535\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.285613\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.211817\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.348135\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.238524\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.190998\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.208012\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.092215\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.154601\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.161179\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.144153\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.156948\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.222354\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.257301\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.224360\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.240218\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.179187\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.246772\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.125622\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.253934\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.474112\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.282808\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.212018\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.314097\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.282395\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.301535\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.254042\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.149195\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.261354\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.225913\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.259374\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.308680\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.355739\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.251538\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.144032\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.241929\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.273079\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.237004\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.188824\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.284157\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.393611\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.305861\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.336727\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.313143\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.229171\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.296688\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.307239\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.244859\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.279457\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.413043\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.321200\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.317750\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.294158\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.397996\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.197782\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.311617\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.356344\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.373738\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.212755\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.287881\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.406326\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.288302\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.221213\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.375213\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.246585\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.352074\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.245548\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.303227\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.231676\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.430391\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.357200\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.271210\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.230310\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.246633\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.287619\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.182854\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.264068\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.265818\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.375870\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.268077\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.332413\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.311569\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.324521\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.353240\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.243556\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.314399\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.290154\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.480684\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.240034\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.323106\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.409355\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.185642\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.183204\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.134696\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.217422\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.195086\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.274616\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.154136\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.182387\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.220367\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.233260\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.239293\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.226338\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.129257\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.232421\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.410176\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.137326\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.248803\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.128504\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.174845\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.171680\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.074600\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.125367\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.272051\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.392870\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.132291\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.237245\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.248235\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.173013\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.198421\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.243954\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.278441\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.159620\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.144301\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.151102\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.226005\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.250920\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.146074\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.175664\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.327060\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.307115\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.291411\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.196595\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.239786\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.225464\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.384599\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.171341\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.252063\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.221110\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.322292\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.322798\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.254337\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.236928\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.359477\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.303144\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.149103\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.223861\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.258712\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.277171\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.148339\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.209406\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.212005\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.282701\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.233596\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.230604\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.217180\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.264945\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.324098\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.203426\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.229524\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.298492\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.188276\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.276826\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.239937\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.122218\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.166809\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.131913\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.184219\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.363128\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.123665\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.223998\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.175648\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.131184\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.190200\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.153483\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.084558\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.281174\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.131732\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.148409\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.243755\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.255855\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.159981\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.214582\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.175344\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.104407\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.193671\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.194009\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.204424\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.237793\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.204555\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.271747\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.117185\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.146137\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.194532\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.193036\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4013, Accuracy: 8530/10000 (85%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.454498\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.225588\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.288940\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.351143\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.233926\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.326130\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.262692\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.246087\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.334186\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.301434\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.243666\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.291594\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.250101\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.254062\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.173934\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.398482\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.160887\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.066681\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.100729\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.156359\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.065247\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.134495\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.184004\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.214539\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.310248\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.151742\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.085135\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.116380\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.178120\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.145262\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.055929\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.116756\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.106736\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.093246\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.082226\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.220865\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.173126\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.119129\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.196633\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.051195\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.149981\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.145741\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.145429\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.086266\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.046011\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.101237\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.046917\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.035813\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.116167\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.086283\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.084416\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.042602\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.089752\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.086439\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.054556\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.286463\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.194787\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.179265\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.197877\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.135720\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.110180\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.170845\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.117930\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.083670\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.108338\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.174083\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.149387\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.083733\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.113254\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.145980\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.082516\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.194709\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.113879\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.111601\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.093719\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.143230\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.148569\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.098987\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.148346\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.079712\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.224457\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.100672\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.099235\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.091064\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.149489\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.172815\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.130115\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.182762\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.088317\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.120621\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.319827\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.131107\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.168384\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.272215\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.136222\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.103476\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.163906\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.198586\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.153156\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.205048\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.169147\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.234110\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.186898\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.205730\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.173147\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.175437\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.118919\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.173740\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.173672\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.142781\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.129913\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.186554\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.198078\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.141085\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.224053\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.106698\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.106010\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.183145\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.125232\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.123095\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.295832\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.179381\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.215182\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.312478\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.273885\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.288971\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.255186\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.311077\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.231891\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.271934\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.188375\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.333172\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.110453\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.223401\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.225668\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.148040\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.217116\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.224252\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.277635\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.223718\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.089813\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.265226\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.353937\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.286428\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.421492\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.243914\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.256848\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.177149\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.264070\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.135405\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.343938\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.203852\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.179720\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.297122\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.224606\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.279544\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.187774\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.293329\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.333276\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.261968\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.236883\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.298431\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.271177\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.264177\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.282235\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.193592\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.126720\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.207445\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.173612\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.201943\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.327820\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.239147\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.337392\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.336939\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.239271\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.458260\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.307811\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.391511\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.326036\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.390427\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.248065\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.259030\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.313429\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.298497\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.306256\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.242081\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.287215\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.331549\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.291349\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.317035\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.221704\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.310295\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.336571\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.286466\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.389270\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.375718\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.371574\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.316590\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.201757\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.337174\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.243496\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.314627\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.217839\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.445937\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.223831\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.285977\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.181215\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.181755\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.256792\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.264333\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.316089\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.276293\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.301665\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.308858\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.280283\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.354151\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.179262\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.301789\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.252298\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.261441\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.520222\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.176359\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.183384\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.269423\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.203893\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.196737\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.209202\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.212241\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.196384\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.135710\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.173673\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.196931\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.235570\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.115173\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.137668\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.246868\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.176971\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.200443\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.111956\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.243132\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.209527\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.150690\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.147734\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.198746\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.210552\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.176502\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.129591\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.264045\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.128860\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.139455\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.169296\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.099895\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.225237\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.144744\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.233582\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.282186\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.266545\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.250626\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.228749\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.208460\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.390347\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.280593\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.354472\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.189308\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.302019\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.252376\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.251082\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.223583\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.250469\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.211544\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.295627\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.133130\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.370543\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.235715\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.174099\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.238309\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.242755\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.237544\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.216655\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.305382\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.300908\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.184011\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.187377\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.185803\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.160516\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.164260\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.175691\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.224971\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.136697\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.125729\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.286979\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.202497\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.145297\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.128994\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.222944\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.222859\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.227031\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.224310\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.126954\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.121137\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.147998\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.147456\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.134943\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.133094\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.234742\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.175593\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.175318\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.088905\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.092582\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.233617\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.136943\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.216787\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.266014\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.128957\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.109843\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.196959\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.210590\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.149957\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.204734\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.159361\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.156573\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.186506\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.153009\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.089702\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.163358\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.3945, Accuracy: 8584/10000 (86%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "partitioned_data_classic = partition.balanced_dirichlet_partition(\n",
    "    trainingset, partitions_number=num_clients, alpha=alpha)\n",
    "\n",
    "classic_client_loaders = [\n",
    "    DataLoader(Subset(trainingset, indices), batch_size=batch_size_train, shuffle=True)\n",
    "    for indices in partitioned_data_classic.values()\n",
    "]\n",
    "\n",
    "local_models_classic_strong = [copy.deepcopy(global_model_classic_strong) for _ in range(num_clients)]\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(trial_model_strong.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):  \n",
    "    train_fashion(epoch, trial_model_strong, fashion_mnist_train_loader, optimizer, log_interval, train_losses, train_counter)\n",
    "\n",
    "\n",
    "\n",
    "test_losses_classic_strong = []\n",
    "test_fashion(trial_model_strong,fashion_mnist_train_loader,test_losses_classic_strong)\n",
    "\n",
    "\n",
    "for round_idx in range(rounds_classic):\n",
    "    \n",
    "    print(f\"Round {round_idx + 1}/{rounds_classic}\")\n",
    "\n",
    "    local_weights_classic = []\n",
    "    for client_idx, client_model in enumerate(local_models_classic_strong):\n",
    "        print(f\"Training client {client_idx + 1}\")\n",
    "        \n",
    "        optimizer = optim.SGD(client_model.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "\n",
    "        train_losses = []\n",
    "        train_counter = []\n",
    "\n",
    "        for epoch in range(1, n_epochs + 1):  \n",
    "            train_fashion(epoch, client_model, classic_client_loaders[client_idx], optimizer, log_interval, train_losses, train_counter)\n",
    "        \n",
    "        client_weights = [param.data.numpy() for param in client_model.parameters()]\n",
    "        local_weights_classic.append(client_weights)\n",
    "        \n",
    "\n",
    "    global_weights_classic = federated_averaging(local_weights_classic)\n",
    "\n",
    "\n",
    "    distribute_global_model(global_weights_classic,local_models_classic_strong,single=False)\n",
    "\n",
    "    distribute_global_model(global_weights_classic,global_model_classic_strong,single=True)\n",
    "    test_losses = []\n",
    "    test_fashion(global_model_classic_strong,fashion_mnist_test_loader,test_losses)\n",
    "\n",
    "    test_accuracies_classic = []\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in fashion_mnist_test_loader:\n",
    "            data = data.view(data.shape[0], -1)\n",
    "            output = global_model_classic_strong(data)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "    accuracy = 100. * correct / len(fashion_mnist_test_loader.dataset)\n",
    "    test_accuracies_classic.append(accuracy)\n",
    "\n",
    "    results[\"classic\"][\"NoCluster\"] = {\"losses\": [], \"accuracy\": []}\n",
    "\n",
    "    results[\"classic\"][\"NoCluster\"][\"losses\"].extend(test_losses)\n",
    "    results[\"classic\"][\"NoCluster\"][\"accuracy\"].extend(test_accuracies_classic)\n",
    "\n",
    "    ######################\n",
    "for num_cluster in num_clusters:\n",
    "    import cluster\n",
    "    cluster = cluster.Cluster(num_clusters=num_cluster)\n",
    "    \n",
    "    targets = trainingset.targets\n",
    "    num_classes = len(set(targets)) \n",
    "    clustered_data = cluster.apply_clustering(partitioned_data_classic, targets, num_classes)\n",
    "    \n",
    "    partitioned_data_classic_clustered = clustered_data\n",
    "\n",
    "    classic_client_loaders_clustered = [\n",
    "        DataLoader(Subset(trainingset, indices), batch_size=batch_size_train, shuffle=True)\n",
    "        for indices in partitioned_data_classic_clustered.values()\n",
    "    ]\n",
    "\n",
    "    for round_idx in range(rounds_classic):\n",
    "        print(f\"Round {round_idx + 1}/{rounds_classic}\")\n",
    "\n",
    "        local_weights_classic = []\n",
    "        for client_idx, client_model in enumerate(local_models_classic_strong[0:num_cluster]):\n",
    "            print(f\"Training client {client_idx + 1}\")\n",
    "            \n",
    "            optimizer = optim.SGD(client_model.parameters(), lr=learning_rate,\n",
    "                          momentum=momentum)\n",
    "    \n",
    "            train_losses = []\n",
    "            train_counter = []\n",
    "    \n",
    "            for epoch in range(1, n_epochs + 1):  \n",
    "                train_fashion(epoch, client_model, classic_client_loaders[client_idx], optimizer, log_interval, train_losses, train_counter)\n",
    "            \n",
    "            client_weights = [param.data.numpy() for param in client_model.parameters()]\n",
    "            local_weights_classic.append(client_weights)\n",
    "            \n",
    "    \n",
    "        global_weights_classic = federated_averaging(local_weights_classic)\n",
    "    \n",
    "    \n",
    "        distribute_global_model(global_weights_classic,local_models_classic_strong,single=False)\n",
    "    \n",
    "        distribute_global_model(global_weights_classic,global_model_classic_strong,single=True)\n",
    "        test_losses = []\n",
    "        test_fashion(global_model_classic_strong,fashion_mnist_test_loader,test_losses)\n",
    "\n",
    "        test_accuracies_classic = []\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in fashion_mnist_test_loader:\n",
    "                data = data.view(data.shape[0], -1)\n",
    "                output = global_model_classic_strong(data)\n",
    "                pred = output.data.max(1, keepdim=True)[1]\n",
    "                correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "        accuracy = 100. * correct / len(fashion_mnist_test_loader.dataset)\n",
    "        test_accuracies_classic.append(accuracy)\n",
    "\n",
    "        if num_cluster not in clusteredResults[\"classic\"]:\n",
    "            clusteredResults[\"classic\"][num_cluster] = {\"losses\": [], \"accuracy\": []}\n",
    "\n",
    "        clusteredResults[\"classic\"][num_cluster][\"losses\"].extend(test_losses)\n",
    "        clusteredResults[\"classic\"][num_cluster][\"accuracy\"].extend(test_accuracies_classic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results (Non-Clustered): {'classic': {'NoCluster': {'losses': [0.5188619812011719], 'accuracy': [80.19]}}, 'pca': {}, 'autoencoder': {}}\n",
      "Final Results (Clustered): {'classic': {2: {'losses': [0.6111913330078125, 0.5729868041992188, 0.5778576416015625, 0.5886122863769532], 'accuracy': [77.31, 78.64, 78.81, 78.37]}, 4: {'losses': [0.5569269927978515, 0.5164715148925781, 0.5319765411376953, 0.5280328765869141], 'accuracy': [79.38, 80.76, 80.22, 80.34]}, 6: {'losses': [0.4632906616210937, 0.4644641296386719, 0.4652772644042969, 0.44572009887695313], 'accuracy': [82.79, 82.6, 82.67, 83.38]}, 8: {'losses': [0.4280053955078125, 0.4304277587890625, 0.41870563354492185, 0.41287210998535157], 'accuracy': [84.37, 84.18, 84.51, 85.12]}, 10: {'losses': [0.4158003601074219, 0.4127583312988281, 0.4012933013916016, 0.39449208984375], 'accuracy': [84.9, 84.82, 85.3, 85.84]}}, 'pca': {}, 'autoencoder': {}}\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Results (Non-Clustered):\", results)\n",
    "print(\"Final Results (Clustered):\", clusteredResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingset_pca = train_loader_reduced_pca.dataset\n",
    "trial_model_pca_strong = MultilayerPerceptron()\n",
    "global_model_pca_strong = MultilayerPerceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.345260\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 1.492300\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 1.183899\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 0.799436\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 0.870424\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 0.633455\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 0.764364\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 0.744924\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.734871\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 0.583149\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.732077\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 0.685209\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.541247\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 0.564458\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 0.517843\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.475491\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.651481\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 0.735209\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 0.700579\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 0.563179\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.426509\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 0.685724\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.572019\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 0.442028\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.414691\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.567187\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.449336\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 0.334818\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.477574\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 0.592800\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.356256\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 0.466473\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.563415\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 0.646774\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.458134\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.433851\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.357626\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 0.355121\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.439423\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 0.540402\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.497836\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 0.476231\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.470322\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 0.466671\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.631173\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.551286\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.617952\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 0.393938\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.509259\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 0.482791\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.538123\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 0.413729\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.444359\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 0.477973\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.455261\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.398374\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.398827\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 0.459602\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.534565\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 0.552401\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.405647\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 0.454856\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.410562\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 0.489739\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.478574\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.447374\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.487679\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 0.604171\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.455915\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 0.340008\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.516496\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 0.389541\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.356564\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 0.428096\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.334384\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.360296\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.455143\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 0.327014\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.394087\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 0.491324\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.400995\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 0.471545\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.539457\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 0.323396\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.570237\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.468877\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.399755\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 0.525830\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.382103\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 0.341732\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.376856\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 0.362911\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.390125\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 0.318731\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.480194\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.387205\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.440378\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 0.481379\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.337893\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 0.441073\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.329174\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 0.414929\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.396995\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 0.395506\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.386086\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.461136\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.442546\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 0.353356\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.246103\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 0.467370\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.312661\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 0.282105\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.351542\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 0.463186\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.337902\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.407191\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.363441\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 0.505853\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.424637\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 0.504398\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.363278\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 0.270606\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.378310\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 0.408202\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.290715\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.411771\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.336716\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 0.514062\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.301274\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 0.384375\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.331303\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 0.453721\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.362547\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 0.313316\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.339376\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.457356\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.407816\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 0.310009\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.343241\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 0.435565\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.236145\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 0.402036\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.439096\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 0.365808\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.328781\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.300614\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.368722\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 0.444508\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.472214\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 0.296671\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.354091\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 0.285285\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.289915\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 0.417886\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.277945\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.344704\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.319512\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 0.441069\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.391468\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 0.387133\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.423923\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 0.328120\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.319725\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 0.399289\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.342629\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.265514\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.291314\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 0.443285\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.399138\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 0.358759\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.215775\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 0.396334\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.439143\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 0.415147\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.418028\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.280589\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.268710\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 0.442465\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.335199\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 0.356413\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.365333\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 0.287556\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.461648\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 0.332171\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.402027\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.413109\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.351447\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 0.304660\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.363089\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 0.333977\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.380713\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 0.333198\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.315424\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 0.357708\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.306175\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.303638\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.428654\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 0.354584\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.409114\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 0.287250\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.347960\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 0.333354\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.308073\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 0.353099\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.262226\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.311761\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.431223\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 0.275731\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.342878\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 0.455164\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.408499\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 0.200006\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.371174\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 0.307116\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.192137\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.422910\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.379023\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 0.317622\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.382678\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 0.437176\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.268679\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 0.365161\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.253988\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 0.395919\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.282328\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.268285\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.285174\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 0.301440\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.200645\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 0.209860\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.229432\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 0.217959\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.355323\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 0.288146\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.283207\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.355136\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.286331\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 0.411398\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.399440\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 0.393630\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.339775\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 0.296367\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.277579\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 0.299687\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.442936\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.351535\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.442412\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 0.294409\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.390010\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 0.564440\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.467341\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 0.354057\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.520654\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 0.323884\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.445546\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.284383\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.374603\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 0.437953\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.322800\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 0.464587\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.397090\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 0.346420\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.244136\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 0.367765\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.319311\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.381398\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.308517\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 0.492971\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.389991\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 0.294648\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.376067\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 0.238529\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.380472\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 0.400102\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.319658\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.276514\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.508755\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 0.444202\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.568668\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 0.442462\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.325281\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 0.350668\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.318989\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 0.356676\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.330820\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.366649\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.295632\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 0.393540\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.207799\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 0.274864\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.262904\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 0.445394\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.233765\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 0.284963\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.234002\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.364571\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.282179\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 0.355705\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.342333\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 0.336105\n",
      "\n",
      "Test set: Avg. loss: 0.3300, Accuracy: 52756/60000 (88%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 2.382020\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 1.080026\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.874078\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.929264\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.778665\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.911295\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.691501\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.631487\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.515842\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.588194\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.550485\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.643707\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.474627\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.612352\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.549419\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 2.487516\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.558867\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.533382\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.353713\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.278891\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.308682\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.347009\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.351548\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.250568\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.189326\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.320164\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.224873\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.180171\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.139959\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.294557\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.301480\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.147382\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.261598\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.229470\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.247891\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.283802\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.287544\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.179211\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.220141\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.213292\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.159359\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.207824\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.237767\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.214159\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.216400\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.263504\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.163511\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.136607\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.257195\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.162627\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.304830\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.240341\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.162206\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.181564\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.146878\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 2.226085\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 1.149138\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.648898\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.539831\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.506288\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.475669\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.316238\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.397928\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.335986\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.327719\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.376028\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.399296\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.335337\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.292824\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.153605\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.396953\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.401338\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.261422\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.277246\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.301147\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.290276\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.324832\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.477664\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.286468\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.301512\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.348452\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.305298\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.258961\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.187640\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.290902\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.204106\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.250499\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.202336\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.180541\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.236414\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 2.305656\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.908873\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.636135\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.665844\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.640326\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.572696\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.545699\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.560070\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.461218\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.498952\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.494329\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.300523\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.326089\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.479892\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.428433\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.280769\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.370187\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.484330\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.426519\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.321572\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.268410\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.356174\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.216180\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.456648\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.246497\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.321034\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.463583\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.364178\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.299331\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.330077\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 2.266643\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 1.044534\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.869875\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.689725\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.729466\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.711906\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.644750\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.433380\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.497001\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.495794\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.424819\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.463566\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.438499\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.533055\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.385891\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.471126\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.537692\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.480689\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.528412\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.352831\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.579248\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.361689\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.333394\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.449672\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.539474\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.328686\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.393281\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.303722\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.285198\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.393591\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 2.315585\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 1.251075\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.642824\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.733496\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.784803\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.635250\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.589601\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.568321\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.497956\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.618805\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.526580\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.497552\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.599217\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.473798\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.353149\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.566705\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.513176\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.459628\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.483582\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.364520\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 2.347540\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 1.449514\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 1.132328\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.817731\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.828070\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.479671\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.636380\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.567999\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.612085\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.634450\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.673255\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.549865\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.610958\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.495688\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.627952\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.445067\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.448879\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.518404\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.507888\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.506440\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.719256\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.578358\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.426243\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.656366\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.486681\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.311664\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.549403\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.501884\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.594275\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.395555\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.568720\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.393421\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.249495\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.473680\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.321886\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.527881\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.299396\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.349413\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.536215\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.348441\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.594481\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.460196\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.367042\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.414400\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.507459\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.416471\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.518328\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.374547\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.409973\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.323326\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 2.446527\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.963274\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.860516\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.618870\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.503765\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.488746\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.488247\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.396268\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.282147\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.330111\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.370885\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.324094\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.476927\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.375328\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.331524\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.288998\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.353352\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.305449\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.311566\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.345293\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.351368\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.349819\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.459729\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.320471\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.225941\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.295254\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.233636\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.418805\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.217037\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.178988\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.197093\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.252480\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.408127\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.303121\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.221408\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 2.207232\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 1.339986\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.951927\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.677636\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.775100\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.650716\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.583975\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.524469\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.454933\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.716811\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.444791\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.430955\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.458093\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.415220\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.390238\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.392135\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.545146\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.427221\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.383696\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.383577\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.338849\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.284557\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.510855\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.245976\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.256129\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.559713\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.447492\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.276594\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.301442\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.432533\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.283279\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.452813\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.326717\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.324346\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.496955\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 2.484153\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 1.179041\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.832004\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.775754\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.637719\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.673760\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.363923\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.372352\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.606268\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.520998\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.293987\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.344365\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.393778\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.367116\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.459773\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.318342\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.377630\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.301054\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.367561\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.389246\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.473745\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.182244\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.299711\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.236069\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.302099\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.311165\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.257094\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.271642\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.229252\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.305358\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.354359\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.439118\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.265576\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.434356\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.267637\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.3712, Accuracy: 7557/10000 (76%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.836753\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.499955\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.662127\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.467615\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.571771\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.526815\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.502304\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.622544\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.420646\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.451945\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.456003\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.466755\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.426051\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.599392\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.404482\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.648810\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.159920\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.169985\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.139888\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.283792\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.190718\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.206344\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.202480\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.165096\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.212407\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.130763\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.131085\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.116844\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.204116\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.125069\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.220524\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.217792\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.075865\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.194170\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.245944\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.118960\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.141961\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.166291\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.154788\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.121720\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.106689\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.071792\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.188214\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.153367\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.175915\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.179029\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.192698\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.133479\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.170917\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.133448\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.189962\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.095322\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.128638\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.238241\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.106860\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.489201\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.291557\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.307398\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.573835\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.229612\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.329563\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.348187\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.258765\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.265950\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.183868\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.243196\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.145520\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.297880\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.187842\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.309315\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.267612\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.319370\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.153349\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.380255\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.179085\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.190734\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.262966\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.237741\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.204161\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.321550\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.271002\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.145737\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.287538\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.180850\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.216621\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.214415\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.120164\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.276199\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.314931\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.224475\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.691276\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.413010\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.522136\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.413743\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.460073\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.401883\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.440457\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.345643\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.338511\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.407028\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.174254\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.332640\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.400963\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.234899\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.401259\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.285654\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.244496\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.272556\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.282975\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.336902\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.433548\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.374983\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.218652\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.361531\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.210623\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.199090\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.400950\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.377669\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.300416\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.236752\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.571698\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.428027\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.327345\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.294073\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.471782\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.354520\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.657290\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.311685\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.352081\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.350969\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.243960\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.390488\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.351537\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.304929\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.219354\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.413859\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.224395\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.288385\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.769398\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.290492\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.403279\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.240347\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.297193\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.266505\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.299392\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.388400\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.334817\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.192547\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.286789\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.359753\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.584217\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.328342\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.482374\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.422997\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.564760\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.405490\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.412326\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.415293\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.321440\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.284049\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.370423\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.381656\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.360466\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.283253\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.367036\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.357904\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.309525\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.314741\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.295706\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.372655\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.628672\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.519551\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.478495\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.435793\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.508695\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.498082\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.446415\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.423835\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.394980\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.568540\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.474541\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.376722\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.353446\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.378269\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.293788\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.360776\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.403599\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.382924\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.356725\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.383938\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.520820\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.412758\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.474843\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.387111\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.427218\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.399270\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.433337\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.342131\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.408903\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.270317\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.442593\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.408141\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.468763\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.359053\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.398206\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.413894\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.455005\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.336226\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.452178\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.485272\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.466066\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.342500\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.271302\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.388599\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.308223\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.301280\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.404263\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.443342\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.333973\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.462208\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.573121\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.316017\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.231227\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.307252\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.391794\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.419438\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.213563\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.313019\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.316895\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.275059\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.230451\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.361224\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.313653\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.295098\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.217012\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.194861\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.135335\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.358015\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.179329\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.347496\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.323712\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.225745\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.352058\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.174184\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.259360\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.148659\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.214711\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.310036\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.257953\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.308599\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.204237\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.200287\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.302231\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.165385\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.353428\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.574437\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.602938\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.492992\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.335705\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.287922\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.522542\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.396988\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.342818\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.349553\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.378010\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.487840\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.316543\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.301178\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.235064\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.365260\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.575948\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.508212\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.518500\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.387002\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.357640\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.353011\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.240076\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.341233\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.310224\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.312140\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.327278\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.398305\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.250521\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.354616\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.323440\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.512076\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.296423\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.356055\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.282515\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.294315\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.466930\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.421509\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.337008\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.357988\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.287804\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.302390\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.356011\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.370529\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.189991\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.328509\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.530132\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.246034\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.247915\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.243403\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.281015\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.306168\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.153186\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.286070\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.243171\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.228507\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.341829\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.331873\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.252604\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.303954\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.247708\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.340281\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.246577\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.249711\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.316327\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.251396\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.324707\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.272169\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.190358\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.227474\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.180904\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.0805, Accuracy: 8008/10000 (80%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.577485\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.543423\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.448025\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.511685\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.444509\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.438420\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.300226\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.314258\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.495002\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.405279\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.511514\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.318990\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.439991\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.422690\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.475356\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.745142\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.077452\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.186941\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.153756\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.063403\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.117895\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.118136\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.327175\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.073543\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.147243\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.174079\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.134664\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.102481\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.141980\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.274713\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.124923\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.080956\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.170056\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.160279\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.225919\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.127854\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.133196\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.205397\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.050157\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.139391\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.089674\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.160018\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.090863\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.127362\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.127114\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.287409\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.125323\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.103819\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.119981\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.058820\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.132783\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.077578\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.166513\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.163053\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.197029\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.383198\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.220046\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.246485\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.375216\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.186662\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.231461\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.263327\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.278001\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.187959\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.229112\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.204315\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.275116\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.141796\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.196405\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.220277\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.191493\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.183319\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.173502\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.157031\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.217361\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.176389\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.344880\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.204775\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.122752\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.301661\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.186393\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.153256\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.313342\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.260081\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.149221\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.363639\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.210453\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.176594\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.254294\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.189678\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.574040\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.328727\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.322404\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.450854\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.285227\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.310464\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.447029\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.347250\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.409534\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.252953\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.425772\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.227822\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.333842\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.192266\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.298274\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.281860\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.228243\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.254240\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.360375\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.222621\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.162454\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.322066\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.376010\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.144281\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.237701\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.266941\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.251144\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.282585\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.380181\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.262433\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.396542\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.256763\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.431290\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.302194\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.323509\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.400693\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.298661\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.305006\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.354049\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.256241\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.338910\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.340944\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.354161\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.334926\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.324019\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.211990\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.442505\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.224760\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.290559\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.341744\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.270677\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.251605\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.318131\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.389861\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.320406\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.407484\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.293984\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.262077\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.293481\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.362817\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.466157\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.463247\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.308482\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.330291\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.471691\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.346382\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.423048\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.379832\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.237568\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.352067\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.365553\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.375201\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.352230\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.261723\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.273227\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.338778\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.298501\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.420869\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.450757\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.343983\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.427533\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.420684\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.369184\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.444934\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.468471\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.408674\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.503147\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.498544\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.448572\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.444245\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.340897\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.471454\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.402537\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.378200\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.570070\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.422912\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.371176\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.506857\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.313241\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.353509\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.461927\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.378673\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.447615\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.426939\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.347077\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.319687\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.333902\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.454193\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.288757\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.305221\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.464346\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.496771\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.371873\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.305405\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.272438\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.248199\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.349939\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.334005\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.332935\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.424301\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.374244\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.272157\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.385159\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.301494\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.330747\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.425349\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.390770\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.382171\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.406694\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.411178\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.604227\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.147351\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.329686\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.194931\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.251978\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.202045\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.231311\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.347956\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.227916\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.248220\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.278110\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.211806\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.188022\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.186183\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.171659\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.274374\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.245448\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.199186\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.136331\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.273456\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.185774\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.168998\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.190354\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.339663\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.282577\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.150526\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.260543\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.173113\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.214390\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.214689\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.322262\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.097972\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.207390\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.117187\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.124183\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.478520\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.231470\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.347805\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.435605\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.300072\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.311100\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.351183\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.338932\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.320412\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.360011\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.176900\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.320835\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.261056\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.343855\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.396556\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.428238\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.323532\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.311429\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.206391\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.333194\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.306646\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.311119\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.297582\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.354539\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.348600\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.321134\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.435532\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.238899\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.365190\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.387386\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.198740\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.319131\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.278783\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.323824\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.281375\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.373175\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.194697\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.286116\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.319852\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.253955\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.252666\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.251600\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.257246\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.417530\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.342002\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.179798\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.201258\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.458191\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.221488\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.169737\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.244724\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.202206\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.191165\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.208249\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.252804\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.268958\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.195530\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.290314\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.433191\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.186865\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.218972\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.173391\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.192512\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.156910\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.222081\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.190083\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.219769\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.258610\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.236963\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.081780\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.0041, Accuracy: 8156/10000 (82%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.559749\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.409108\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.444701\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.515461\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.428229\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.405022\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.464929\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.442921\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.447567\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.355116\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.394303\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.346163\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.485008\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.324390\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.384394\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.571829\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.175582\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.110541\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.167358\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.204129\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.094596\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.119920\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.091552\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.177658\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.118353\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.167623\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.048347\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.067717\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.143151\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.184899\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.195719\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.165423\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.176390\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.227806\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.148195\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.134068\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.237637\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.080367\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.142896\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.173895\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.119168\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.063279\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.061968\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.103490\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.055811\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.083652\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.187072\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.072004\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.091097\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.119884\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.076586\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.121999\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.104207\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.190450\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.030934\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.283586\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.230479\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.180740\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.281769\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.281984\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.161838\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.221678\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.223222\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.276086\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.352109\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.318146\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.218877\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.314575\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.269440\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.245721\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.224702\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.154036\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.226830\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.212472\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.242749\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.243885\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.115672\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.107569\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.353259\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.173109\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.229863\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.116873\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.264192\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.240880\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.216129\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.178706\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.356230\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.177884\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.167784\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.261542\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.530180\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.505212\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.242241\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.292437\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.252103\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.371079\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.202985\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.226081\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.203755\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.464359\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.358730\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.230674\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.162267\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.218732\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.201055\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.283550\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.214326\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.313017\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.254078\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.178136\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.190619\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.293163\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.310275\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.248564\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.193357\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.297360\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.281353\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.193877\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.222102\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.313974\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.423551\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.260790\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.274954\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.284018\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.194496\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.466008\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.244589\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.282108\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.340932\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.283038\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.253366\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.170685\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.499636\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.276637\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.229002\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.355888\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.185446\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.265957\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.483510\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.230071\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.287062\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.319605\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.285660\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.276424\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.362852\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.203368\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.303619\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.322409\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.302992\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.213100\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.531856\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.513100\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.432758\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.310269\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.317239\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.236647\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.376333\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.282145\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.205398\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.237413\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.265306\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.404201\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.263187\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.312413\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.332850\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.327502\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.245653\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.240582\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.349485\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.231775\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.406211\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.236383\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.374797\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.275865\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.330367\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.454933\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.359318\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.388832\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.457005\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.323047\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.358835\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.280821\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.424807\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.313951\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.376662\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.536144\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.294793\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.405354\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.467887\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.272490\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.244073\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.311346\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.380436\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.433743\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.281615\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.389965\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.341161\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.335004\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.318719\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.327249\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.299134\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.335945\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.442850\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.379442\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.390282\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.429067\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.572543\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.308392\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.367107\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.453307\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.344460\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.307921\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.404150\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.361905\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.256114\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.514543\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.435352\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.393302\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.494875\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.324225\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.620605\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.212934\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.324781\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.213894\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.454019\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.145195\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.127452\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.241739\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.174928\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.193341\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.286060\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.268553\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.235133\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.136094\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.191599\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.242412\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.249102\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.119134\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.215929\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.258900\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.352857\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.193410\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.224464\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.285782\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.293610\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.189262\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.309556\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.244823\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.247800\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.171818\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.225838\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.267833\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.254855\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.289101\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.204646\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.426604\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.263591\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.328411\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.481953\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.284346\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.381605\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.258022\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.336347\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.237675\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.238308\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.298415\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.278073\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.314236\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.395139\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.328265\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.254297\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.414430\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.318279\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.288849\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.264486\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.307433\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.277380\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.280749\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.402867\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.310088\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.369111\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.289275\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.305987\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.244943\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.280610\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.284995\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.268552\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.255943\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.298543\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.337543\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.417089\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.161363\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.236540\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.324167\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.220050\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.320025\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.225028\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.489241\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.217586\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.191424\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.137946\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.159971\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.241600\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.262776\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.280000\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.180027\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.196949\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.222941\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.227927\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.261396\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.234109\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.230608\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.147818\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.285815\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.139191\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.223876\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.274173\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.281633\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.296100\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.261651\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.314428\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.226946\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.210690\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.290739\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.186294\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9590, Accuracy: 8292/10000 (83%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.509058\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.403487\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.594962\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.235996\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.457092\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.419309\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.369857\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.364586\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.448041\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.379643\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.373915\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.495969\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.450786\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.443836\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.272508\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.564940\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.139494\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.085109\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.056126\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.217664\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.140832\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.110965\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.290978\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.153604\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.107233\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.124232\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.118795\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.129636\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.140785\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.089813\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.135686\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.078419\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.180233\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.163318\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.164012\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.159816\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.065319\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.241712\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.078497\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.103200\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.145143\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.075208\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.125955\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.180484\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.093711\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.132424\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.192939\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.143154\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.103745\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.063840\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.058759\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.115001\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.105110\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.040905\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.075754\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9849, Accuracy: 7840/10000 (78%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.403425\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.466091\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.379978\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.399717\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.514001\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.405232\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.509005\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.589020\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.337284\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.370132\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.417353\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.373034\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.346568\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.310328\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.495319\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.194777\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.093586\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.149333\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.193455\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.104495\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.205141\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.063490\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.047627\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.136955\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.085871\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.089375\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.180862\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.075273\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.175134\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.141107\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.192818\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.123054\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.094943\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.053421\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.119644\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.095679\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.112668\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.241581\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.096598\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.154591\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.108982\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.103250\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.144199\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.056211\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.152353\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.120936\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.118461\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.139344\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.121403\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.071074\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.131752\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.178410\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.164963\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.088976\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.112921\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9581, Accuracy: 7938/10000 (79%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.493532\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.360600\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.339543\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.330745\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.377740\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.394945\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.304635\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.331382\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.283947\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.339781\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.457305\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.298681\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.375878\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.312119\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.363233\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.368677\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.109874\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.092613\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.087699\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.051480\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.054749\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.207776\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.074413\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.114200\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.136192\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.270036\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.052594\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.103538\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.171365\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.178477\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.199927\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.072816\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.034100\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.100705\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.097973\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.107648\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.108007\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.125095\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.086213\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.059077\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.068850\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.133182\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.063759\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.142734\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.146186\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.180741\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.131063\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.192818\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.145240\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.086759\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.143230\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.086093\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.158121\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.142073\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.115208\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9552, Accuracy: 7906/10000 (79%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.592890\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.278070\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.339634\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.345880\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.384580\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.317788\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.246774\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.244373\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.344760\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.335584\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.339682\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.356923\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.439278\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.420075\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.371997\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.347999\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.175932\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.033062\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.119398\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.078445\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.033834\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.151403\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.096057\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.137288\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.063938\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.116045\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.089633\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.133151\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.111863\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.085315\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.067550\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.094702\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.163533\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.191157\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.136150\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.256934\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.071048\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.066909\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.055202\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.135999\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.074345\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.070356\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.117794\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.068749\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.109629\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.164218\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.073962\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.110255\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.105415\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.105383\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.107677\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.037048\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.052589\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.054943\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.177782\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9255, Accuracy: 7992/10000 (80%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.507107\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.271088\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.431807\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.299309\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.266459\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.332117\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.391043\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.294880\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.337596\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.197352\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.246903\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.268719\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.435130\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.312896\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.281498\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.273190\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.040563\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.103537\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.101947\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.085209\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.071534\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.097063\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.077992\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.094394\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.069770\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.041613\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.095633\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.135938\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.061361\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.051726\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.162717\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.031378\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.235696\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.066835\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.111391\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.093135\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.062430\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.144415\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.057428\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.092399\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.095489\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.116079\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.150114\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.100475\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.143815\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.155954\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.051052\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.154103\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.063809\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.065219\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.081735\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.187211\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.051075\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.111196\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.172936\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.418580\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.182884\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.151107\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.144784\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.239652\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.360480\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.192407\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.289973\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.283379\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.091540\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.132895\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.059900\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.354002\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.148161\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.172663\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.241710\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.161064\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.212353\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.243911\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.154727\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.192866\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.151768\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.161197\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.147930\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.137481\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.205091\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.138495\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.207325\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.250560\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.142474\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.100612\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.049120\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.096629\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.141340\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.254657\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.447502\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.276175\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.350974\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.246622\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.264424\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.160203\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.253721\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.168745\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.290721\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.239294\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.310010\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.231271\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.163097\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.192183\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.136492\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.410954\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.147394\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.238846\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.146672\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.199388\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.367566\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.241474\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.251639\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.302507\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.312854\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.116598\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.233874\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.178970\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.239998\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.331099\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9081, Accuracy: 8118/10000 (81%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.478656\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.422879\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.339254\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.311312\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.408256\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.319862\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.374632\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.307850\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.275211\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.391322\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.355437\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.340875\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.217778\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.382010\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.228668\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.232685\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.098856\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.087721\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.070149\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.127664\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.136951\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.097264\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.143025\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.136858\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.070116\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.146654\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.139943\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.118572\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.143777\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.100270\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.084538\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.153022\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.124295\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.165273\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.124747\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.098714\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.123279\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.124870\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.045279\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.097094\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.098307\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.097753\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.042297\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.066266\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.114104\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.094923\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.090119\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.128416\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.087240\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.028451\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.075243\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.171159\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.111806\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.162634\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.071777\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.376890\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.175645\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.235929\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.122672\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.240949\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.171522\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.197216\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.112844\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.119757\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.156766\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.139122\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.284518\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.246985\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.177279\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.194509\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.061564\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.122257\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.124266\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.176395\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.163344\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.230714\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.103470\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.260885\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.156867\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.110307\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.110080\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.205920\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.238352\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.218125\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.230609\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.177258\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.096519\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.092824\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.083175\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.232952\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.384856\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.135127\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.221358\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.303558\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.218459\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.237960\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.295467\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.240853\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.322592\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.174963\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.198005\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.229316\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.180567\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.282197\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.252291\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.207811\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.213028\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.297343\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.192859\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.171871\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.334960\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.129472\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.161766\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.154462\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.245700\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.238129\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.113481\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.225440\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.127607\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.223946\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8836, Accuracy: 8188/10000 (82%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.341238\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.352857\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.344424\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.325812\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.345346\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.279998\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.395396\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.293771\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.438600\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.264049\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.323289\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.414076\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.199426\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.295784\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.228299\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.308558\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.167129\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.131683\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.044710\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.138040\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.093675\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.127048\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.129091\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.256020\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.069631\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.079469\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.092250\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.075394\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.117664\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.133157\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.043101\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.059831\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.090659\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.090417\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.134356\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.061569\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.083833\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.166457\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.052907\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.073835\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.041071\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.113861\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.119875\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.142905\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.019396\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.118061\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.107153\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.146725\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.121254\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.072513\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.072722\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.160027\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.046797\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.065851\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.125178\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.229048\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.130246\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.235545\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.162583\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.189977\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.221507\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.114693\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.188915\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.122310\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.178747\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.173628\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.160625\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.220979\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.229454\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.221330\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.200035\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.127158\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.203179\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.204173\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.178086\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.068950\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.115622\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.111866\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.117517\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.073498\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.131802\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.113271\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.231234\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.148783\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.221663\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.125648\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.105760\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.185857\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.146732\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.115628\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.312407\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.198197\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.164487\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.204208\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.281848\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.297549\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.162501\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.213722\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.274324\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.250662\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.259535\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.252523\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.136616\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.205914\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.161128\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.097407\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.231197\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.247000\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.217472\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.169069\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.131122\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.242446\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.161638\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.192174\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.240000\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.201288\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.219916\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.152468\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.186508\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.182022\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8705, Accuracy: 8068/10000 (81%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.364575\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.321589\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.270996\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.301638\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.394660\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.172950\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.232844\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.309594\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.323011\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.276011\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.234939\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.219817\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.339667\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.260383\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.385292\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.347448\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.076574\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.056227\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.192961\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.105871\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.042268\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.099825\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.041581\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.081180\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.127223\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.061792\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.081562\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.046718\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.071335\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.116370\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.165581\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.090315\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.167943\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.065072\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.087269\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.022635\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.096363\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.082420\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.094452\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.125701\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.114589\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.055567\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.095666\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.129572\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.146952\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.135859\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.083322\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.081588\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.054468\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.105272\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.045030\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.128052\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.049516\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.060014\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.072140\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.434785\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.155881\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.131348\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.131899\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.229720\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.103609\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.303607\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.206313\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.211815\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.138147\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.127506\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.189230\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.182637\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.166949\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.078413\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.191899\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.152447\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.150814\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.204909\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.142064\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.290477\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.108836\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.082732\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.120513\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.180905\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.137371\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.210242\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.148789\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.100358\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.116929\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.256271\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.150681\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.201119\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.143426\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.242220\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.368467\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.126467\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.337081\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.323751\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.232407\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.336245\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.182734\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.259494\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.304389\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.193081\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.186562\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.279589\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.220800\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.228449\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.369055\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.233353\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.195770\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.193556\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.147073\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.148124\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.227572\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.109629\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.193496\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.226713\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.213560\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.214603\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.219766\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.147138\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.174642\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.140860\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8572, Accuracy: 8184/10000 (82%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.504023\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.378768\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.361248\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.337849\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.274870\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.346227\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.241820\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.278974\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.398213\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.231083\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.289556\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.388544\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.339637\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.303885\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.344652\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.213189\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.063096\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.048375\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.156688\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.182923\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.088318\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.104785\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.113445\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.049378\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.067776\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.130501\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.165257\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.133947\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.144788\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.093842\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.077614\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.054553\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.094406\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.079638\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.109928\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.064840\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.105864\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.034695\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.058046\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.021105\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.088179\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.184894\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.084973\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.054957\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.036507\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.063137\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.054113\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.083045\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.108310\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.209399\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.044159\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.051115\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.089723\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.096443\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.115452\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.242613\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.335486\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.181868\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.169668\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.162624\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.170448\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.115022\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.237212\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.136191\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.092187\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.171548\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.160543\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.137803\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.093444\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.182027\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.079628\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.104258\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.104755\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.103653\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.148717\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.210773\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.090400\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.233868\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.075170\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.109013\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.140883\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.177384\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.090393\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.163335\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.130662\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.107901\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.211316\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.078371\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.192253\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.191245\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.268379\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.222704\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.182790\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.172016\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.210359\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.152304\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.165772\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.361604\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.244907\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.153813\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.186423\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.209989\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.086013\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.229144\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.168512\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.213190\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.163826\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.167341\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.211067\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.128780\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.153280\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.173152\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.176199\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.146482\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.184091\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.133080\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.234865\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.105147\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.120528\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.147413\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.442184\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.210384\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.481963\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.230744\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.192231\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.360996\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.185425\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.298236\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.198109\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.238985\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.297630\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.303180\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.369417\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.247312\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.235363\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.210637\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.192603\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.398711\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.203616\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.239124\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.197830\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.211933\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.339582\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.205730\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.408366\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.248488\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.261130\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.275020\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.140579\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.226706\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.358422\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.328611\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.407427\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.357433\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.412349\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.306379\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.264451\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.314492\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.194885\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.333634\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.262033\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.309016\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.246892\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.421125\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.338013\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.311416\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.175760\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.178382\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.381587\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.330857\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8481, Accuracy: 8388/10000 (84%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.393584\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.235892\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.240078\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.305293\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.296466\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.231869\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.274330\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.257773\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.248597\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.237257\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.234735\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.254997\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.286643\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.268724\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.251394\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.252141\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.109320\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.045106\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.179218\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.115628\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.120158\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.039928\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.176204\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.086021\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.128049\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.065737\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.077947\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.165293\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.087002\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.054834\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.076611\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.132811\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.084317\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.211337\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.072365\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.141432\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.075693\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.127303\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.077624\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.147469\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.100170\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.054535\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.076675\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.095280\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.069714\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.070252\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.085082\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.072159\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.104130\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.150303\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.157968\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.072522\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.145477\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.081567\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.109714\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.345114\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.120257\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.178840\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.176425\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.075458\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.076513\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.122149\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.121772\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.084036\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.192155\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.049194\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.204570\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.194950\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.231229\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.177930\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.156312\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.088200\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.114028\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.173114\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.191316\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.204201\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.078609\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.134578\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.106149\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.097665\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.141789\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.101697\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.225408\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.143475\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.090495\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.143036\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.108327\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.135560\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.360748\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.081254\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.285632\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.146999\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.155265\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.207928\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.218225\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.248743\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.251195\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.182151\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.138142\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.201530\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.255619\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.248768\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.348415\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.142364\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.217920\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.096183\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.339455\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.173618\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.163896\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.172465\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.131903\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.162998\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.129916\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.157093\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.145058\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.258653\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.109388\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.173287\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.165469\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.235944\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.477466\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.393679\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.276420\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.326387\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.195984\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.185329\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.289177\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.340448\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.160561\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.245421\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.154638\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.206475\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.292937\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.232390\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.316352\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.214492\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.235027\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.318851\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.222003\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.196645\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.216183\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.185507\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.225033\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.100337\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.259607\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.229425\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.207918\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.198497\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.170173\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.178418\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.523925\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.305702\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.299235\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.276336\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.310212\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.337013\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.370606\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.314961\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.188687\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.172773\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.191954\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.318627\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.318744\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.262538\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.225808\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.358170\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.194377\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.321424\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.254029\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.262419\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8258, Accuracy: 8420/10000 (84%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.223623\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.317535\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.309437\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.224405\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.309193\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.247669\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.303983\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.281057\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.358369\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.271248\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.244220\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.244719\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.225095\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.187715\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.369578\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.462999\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.146915\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.111534\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.115741\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.104031\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.071983\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.097556\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.094901\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.098426\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.039388\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.065120\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.145470\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.089733\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.046948\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.189488\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.115963\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.055548\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.058393\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.065952\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.045758\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.113692\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.082841\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.193879\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.087662\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.073925\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.117797\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.095809\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.046681\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.087438\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.056546\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.049002\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.082333\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.074152\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.209321\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.124218\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.077326\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.034505\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.049575\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.107459\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.032010\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.284664\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.184820\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.162351\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.097206\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.100001\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.140139\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.089626\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.170037\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.191198\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.119168\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.147986\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.083401\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.086272\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.148107\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.156422\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.085180\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.121046\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.161227\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.250675\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.093405\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.177465\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.130231\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.132230\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.201676\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.158394\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.118029\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.136343\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.087553\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.097127\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.172827\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.115735\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.150283\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.157659\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.214408\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.116402\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.267535\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.155433\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.263880\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.131707\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.236039\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.144582\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.168199\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.173141\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.183829\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.163809\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.172036\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.210979\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.160161\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.214578\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.100993\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.203328\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.211298\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.192444\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.147191\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.142881\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.207152\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.190692\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.154129\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.130451\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.210308\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.216463\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.184117\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.143280\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.192029\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.153351\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.254553\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.213259\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.272780\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.282628\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.240166\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.167818\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.242268\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.237356\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.123126\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.321762\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.276520\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.272951\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.244979\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.311878\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.256630\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.118330\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.230258\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.160924\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.234932\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.184261\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.327778\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.146349\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.221547\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.155121\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.303682\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.269468\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.235347\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.189493\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.207591\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.285997\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.460371\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.194553\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.272657\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.351028\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.243497\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.205623\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.234290\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.407094\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.270877\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.261439\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.163933\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.214153\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.294233\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.223216\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.155265\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.250834\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.177875\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.355001\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.252248\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.300358\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8089, Accuracy: 8472/10000 (85%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.492290\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.252511\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.363199\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.151446\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.203236\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.214662\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.295544\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.177643\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.339160\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.218583\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.320751\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.219237\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.287506\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.246736\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.211449\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.357915\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.093808\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.170297\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.071613\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.083620\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.069295\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.102540\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.038445\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.038848\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.129863\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.141539\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.065716\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.082778\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.144239\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.066538\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.146642\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.077050\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.153191\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.068780\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.029381\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.052333\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.072260\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.051195\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.108546\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.154576\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.075140\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.093667\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.068384\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.062833\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.116662\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.162466\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.034642\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.085680\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.125368\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.123261\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.136519\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.023660\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.072410\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.106198\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.059063\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.279136\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.090778\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.166136\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.162608\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.114983\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.109734\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.120213\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.146205\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.195343\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.182802\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.098241\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.131432\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.154369\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.227294\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.063621\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.166155\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.124155\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.094048\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.168813\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.203392\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.084130\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.126850\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.126501\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.092164\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.176603\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.123090\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.139335\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.075500\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.350272\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.053425\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.129457\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.058784\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.218812\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.082822\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.041184\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.397083\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.156881\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.294972\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.157163\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.114803\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.351067\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.146880\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.168595\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.168068\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.169339\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.218785\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.248662\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.117871\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.153439\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.141269\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.197651\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.201430\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.246975\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.109304\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.138193\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.192677\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.166723\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.120711\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.100669\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.140575\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.177349\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.167337\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.172253\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.235041\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.116451\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.336662\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.120066\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.177535\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.244381\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.174892\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.263445\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.228863\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.229864\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.189220\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.183076\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.311624\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.270850\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.570705\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.249108\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.180508\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.237550\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.177917\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.278886\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.370773\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.270823\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.263832\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.190304\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.229510\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.248611\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.294859\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.164384\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.204908\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.283784\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.203601\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.158121\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.434882\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.354447\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.324375\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.376518\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.338699\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.177659\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.230689\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.209278\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.256963\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.224637\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.197922\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.359005\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.237194\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.159072\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.247477\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.227795\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.209181\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.326981\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.266174\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.190401\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.7914, Accuracy: 8474/10000 (85%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.436610\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.364064\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.282039\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.178040\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.357798\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.191772\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.498751\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.329449\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.253097\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.366274\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.368708\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.300994\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.227439\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.227552\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.258575\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.545561\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.076883\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.126315\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.166842\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.159332\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.092689\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.081470\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.075625\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.037469\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.071517\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.074274\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.094946\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.067132\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.051241\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.121986\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.202663\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.162191\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.122439\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.044321\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.053174\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.128834\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.083356\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.141453\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.044209\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.041340\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.058866\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.069288\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.053652\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.142233\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.129113\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.054795\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.074959\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.118808\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.090255\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.036096\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.038008\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.049416\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.068256\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.049131\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.078713\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.267333\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.139688\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.063754\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.093499\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.098251\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.198134\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.197487\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.146424\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.059763\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.147906\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.257062\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.148762\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.171082\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.198403\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.141625\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.199643\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.085532\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.083916\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.213295\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.140990\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.126845\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.127436\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.172018\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.102554\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.181209\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.207262\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.082736\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.223706\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.119982\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.225777\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.128744\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.169086\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.105233\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.136519\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.160196\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.202411\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.113230\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.209128\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.191607\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.261566\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.229150\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.108905\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.184756\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.136596\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.188558\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.166227\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.132352\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.118180\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.228171\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.126563\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.204480\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.146033\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.107796\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.271607\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.208671\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.106151\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.138720\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.118576\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.186960\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.219702\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.135432\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.150069\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.245592\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.169991\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.191608\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.323787\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.186114\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.201397\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.217505\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.430801\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.332208\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.245004\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.189257\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.163713\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.204151\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.265064\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.228549\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.355525\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.251950\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.221352\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.187453\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.212592\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.188213\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.201461\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.167190\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.086609\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.152288\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.130242\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.138661\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.223600\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.157927\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.195721\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.096924\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.238418\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.218216\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.410147\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.312780\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.359496\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.339318\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.335406\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.311639\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.246866\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.211155\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.315798\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.229379\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.245395\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.318411\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.227721\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.334089\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.194151\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.258944\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.215050\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.217932\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.214833\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.225098\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.316681\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.509143\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.412306\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.238666\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.389779\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.328505\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.311076\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.356174\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.319710\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.268829\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.414772\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.290072\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.235971\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.400204\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.321911\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.355967\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.288702\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.367900\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.363114\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.203607\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.406545\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.363965\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.322102\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.213995\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.227981\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.254883\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.283119\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.272914\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.238017\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.318451\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.225965\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.371397\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.338986\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.345791\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.273665\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.295527\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.374588\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.458988\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.203817\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.208458\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.306795\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.177364\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.213488\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.289690\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.246714\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.222109\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.274095\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.350182\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.331380\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.248868\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.492089\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.228963\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.327788\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.184377\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.219377\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.167657\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.445205\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.124804\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.258448\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.129918\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.250989\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.183205\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.060219\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.245080\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.105929\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.326533\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.157583\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.268978\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.257187\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.195642\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.092924\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.166744\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.111083\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.162326\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.210825\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.169770\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.134111\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.206711\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.155990\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.102807\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.113661\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.133534\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.167793\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.226447\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.173164\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.7948, Accuracy: 8561/10000 (86%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.548628\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.225276\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.353091\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.225404\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.352271\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.287730\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.217662\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.191098\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.288565\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.207317\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.376606\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.396229\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.274050\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.252222\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.260957\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.325408\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.110008\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.102814\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.185387\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.071280\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.029476\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.182007\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.155376\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.053768\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.053861\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.067891\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.246172\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.100432\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.066862\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.049889\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.070860\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.112811\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.060375\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.175508\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.088975\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.140852\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.098367\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.061229\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.059679\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.060318\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.123360\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.140766\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.095797\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.163616\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.057362\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.105888\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.029605\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.101995\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.066636\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.147980\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.080026\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.051809\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.060415\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.064714\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.067272\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.331267\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.157310\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.218808\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.099080\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.210368\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.086275\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.165884\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.104503\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.073979\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.154735\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.104535\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.106249\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.042700\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.150869\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.083780\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.154038\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.165954\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.076020\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.115558\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.103941\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.108022\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.132560\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.080020\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.044511\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.092791\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.080126\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.099223\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.098525\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.133002\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.059270\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.090145\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.072914\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.106680\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.088402\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.163579\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.250398\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.249452\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.148813\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.164853\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.212840\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.103182\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.122523\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.206579\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.190632\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.259652\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.341501\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.190423\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.083632\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.155117\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.109488\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.106062\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.147632\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.128643\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.079904\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.170855\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.305246\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.277016\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.168782\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.258369\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.150793\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.129492\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.192437\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.152785\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.194007\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.137901\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.217549\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.287633\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.306244\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.288706\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.206739\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.219115\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.275369\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.190783\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.264082\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.243524\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.207811\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.129115\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.295727\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.175539\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.136645\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.256935\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.188355\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.318561\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.216459\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.171657\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.161345\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.192773\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.215162\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.232123\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.218205\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.277161\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.162554\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.226458\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.290200\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.152540\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.314296\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.354196\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.199699\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.259386\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.270980\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.233689\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.211251\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.188682\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.178048\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.159866\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.369629\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.205117\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.245244\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.360872\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.402523\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.236284\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.276244\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.271924\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.319559\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.221356\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.301656\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.310812\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.188843\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.454252\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.334217\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.310560\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.262472\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.353658\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.255764\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.210983\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.237526\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.254803\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.277112\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.333054\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.346541\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.377457\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.451147\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.441914\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.420798\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.181958\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.344958\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.251997\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.347887\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.442282\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.316753\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.367805\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.282146\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.158625\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.322004\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.281463\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.418856\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.246723\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.445477\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.263940\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.356115\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.351768\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.322310\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.257912\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.319896\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.278463\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.224216\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.332149\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.257268\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.349650\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.339642\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.319038\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.378805\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.279397\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.242370\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.325985\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.407771\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.259639\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.236086\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.125095\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.224208\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.186966\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.214393\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.185301\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.209298\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.203410\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.215966\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.110490\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.150719\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.312347\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.242221\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.145680\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.147430\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.199837\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.152151\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.266098\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.178046\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.261555\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.162152\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.238273\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.193859\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.085379\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.233478\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.214717\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.078889\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.100339\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.115892\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.151808\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.310805\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.079976\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.121242\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.7851, Accuracy: 8516/10000 (85%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.383389\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.255025\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.279831\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.271809\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.339079\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.234486\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.249582\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.385851\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.320407\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.271729\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.308630\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.390856\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.275980\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.240767\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.140785\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.289617\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.082794\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.110687\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.090741\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.126848\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.070121\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.069445\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.092712\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.057027\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.079329\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.022741\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.123430\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.095984\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.125254\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.067169\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.161017\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.051016\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.062123\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.133738\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.073814\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.075729\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.074606\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.122273\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.071073\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.087469\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.087506\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.061654\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.071606\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.109128\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.163038\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.068924\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.128946\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.168121\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.073765\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.112730\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.159260\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.048732\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.025033\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.059681\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.126829\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.278563\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.224967\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.236221\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.187016\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.124625\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.212674\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.157885\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.051760\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.146252\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.122423\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.199908\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.128643\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.141273\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.124777\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.134432\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.073994\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.081728\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.146324\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.094087\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.153454\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.097864\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.118199\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.169372\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.114456\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.150049\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.135577\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.149958\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.159832\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.126420\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.072663\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.147382\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.242080\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.118550\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.154753\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.075262\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.323421\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.164398\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.184085\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.203285\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.124580\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.222476\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.119414\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.174659\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.113657\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.247076\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.162934\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.224047\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.140590\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.130630\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.180383\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.115357\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.177629\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.160309\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.089276\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.129879\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.197058\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.171953\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.207921\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.112763\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.175396\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.167671\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.156281\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.131140\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.113802\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.134655\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.282757\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.258033\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.245879\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.240342\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.094376\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.178530\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.154688\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.133879\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.246981\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.138997\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.202649\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.229253\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.592941\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.189369\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.145481\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.163742\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.200132\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.217711\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.118552\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.233678\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.205844\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.223037\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.281250\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.169007\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.174624\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.430563\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.149868\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.158572\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.200977\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.204116\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.302239\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.153739\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.204893\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.294454\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.272827\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.273748\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.308139\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.197940\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.229248\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.247351\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.269937\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.253469\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.215434\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.161450\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.278910\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.244569\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.236083\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.144456\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.246105\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.320209\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.312277\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.426252\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.296153\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.377437\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.313590\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.216116\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.211864\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.214961\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.402904\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.352670\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.269173\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.344452\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.365598\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.374908\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.290055\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.245480\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.286918\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.265745\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.364294\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.311334\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.244904\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.383041\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.345943\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.217388\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.244056\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.314897\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.272563\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.317336\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.212069\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.285784\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.520662\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.341276\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.396031\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.173911\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.291551\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.265340\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.237717\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.273676\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.268259\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.431244\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.201968\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.299301\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.293781\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.190457\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.241722\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.201267\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.259717\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.284818\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.389627\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.215320\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.637449\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.133728\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.175392\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.157153\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.181314\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.302631\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.109856\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.104354\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.194525\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.112247\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.135068\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.118766\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.140210\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.155681\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.217393\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.143660\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.196479\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.232239\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.142222\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.159477\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.188670\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.182392\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.077772\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.220595\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.214604\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.181226\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.085574\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.162916\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.132037\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.097797\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.229959\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.208072\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.205671\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.257794\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.061784\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.7719, Accuracy: 8589/10000 (86%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.404520\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.260058\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.347597\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.252499\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.227318\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.308239\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.361816\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.187987\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.217825\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.272722\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.182539\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.183402\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.339036\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.322113\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.269677\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.301424\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.131454\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.095622\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.121223\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.055010\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.112303\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.082163\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.184785\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.040814\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.099053\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.099315\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.033826\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.043497\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.077247\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.036192\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.131302\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.065643\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.072987\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.046129\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.044797\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.103564\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.063936\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.031791\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.223691\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.083988\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.047708\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.098783\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.095686\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.125073\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.034297\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.120075\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.039223\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.060386\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.100110\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.060381\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.062773\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.088700\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.076613\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.036394\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.046504\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.368190\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.176513\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.096378\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.200557\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.042954\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.147567\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.132727\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.186267\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.150862\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.137610\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.158960\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.190232\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.126580\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.134398\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.122816\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.122595\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.069902\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.110866\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.141482\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.086813\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.118430\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.048410\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.115999\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.102363\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.133308\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.081555\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.089987\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.128723\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.126870\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.050229\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.059532\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.064950\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.144703\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.108428\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.111663\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.325220\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.099603\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.134598\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.233751\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.157860\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.213185\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.213951\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.253530\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.167580\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.249629\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.195763\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.147994\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.090405\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.103818\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.094355\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.283260\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.183321\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.213099\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.182991\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.180384\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.159945\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.149032\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.123264\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.133796\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.202230\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.114551\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.152172\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.133221\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.155273\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.215368\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.348573\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.281348\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.178641\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.350343\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.184343\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.221933\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.971519\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.279506\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.208165\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.197582\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.155802\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.211432\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.187454\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.214555\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.239135\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.298809\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.245139\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.145810\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.168114\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.115342\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.245525\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.295228\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.199997\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.196154\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.342512\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.175104\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.129226\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.120373\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.274529\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.212820\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.317211\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.211216\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.203112\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.230683\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.217207\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.306849\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.204693\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.246095\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.355521\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.343459\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.185792\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.266894\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.154221\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.298091\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.204075\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.216463\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.216554\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.230095\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.219172\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.181189\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.450406\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.303654\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.244394\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.426150\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.313319\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.381085\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.310878\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.262805\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.213647\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.205895\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.284111\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.422164\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.191115\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.236671\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.219529\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.348852\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.271216\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.216429\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.299332\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.292423\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.288708\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.292033\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.287661\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.238315\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.210357\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.297081\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.205540\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.200171\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.254036\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.264982\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.266553\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.258172\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.265312\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.224557\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.281236\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.387109\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.242160\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.290383\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.273639\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.288002\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.200744\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.184032\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.143912\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.320075\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.172387\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.248222\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.261294\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.298067\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.330607\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.252855\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.422191\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.179880\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.209728\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.280692\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.238219\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.231430\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.222759\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.202750\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.099675\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.334338\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.186469\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.103991\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.237556\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.222978\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.294542\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.135171\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.088478\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.238222\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.212916\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.154329\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.255738\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.133007\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.094397\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.056823\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.255889\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.208524\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.189893\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.100793\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.115239\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.144718\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.191514\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.245351\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.155445\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.225558\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.135991\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.7641, Accuracy: 8557/10000 (86%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.303104\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.322982\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.359338\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.295940\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.264745\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.263228\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.315406\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.196607\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.267547\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.208431\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.284475\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.188989\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.175165\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.294403\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.196219\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.452190\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.056902\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.049855\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.084756\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.111711\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.106706\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.040095\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.103029\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.077647\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.071887\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.059404\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.042830\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.053443\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.141519\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.064716\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.104795\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.086765\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.067657\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.076318\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.091782\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.068283\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.045432\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.214474\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.087909\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.096550\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.028338\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.051429\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.032060\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.095554\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.026272\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.050778\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.093508\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.041052\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.055906\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.051711\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.123442\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.084056\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.077839\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.031036\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.062800\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.188645\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.081662\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.104816\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.156061\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.130677\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.122276\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.129961\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.128936\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.090438\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.152927\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.117485\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.167412\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.168814\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.086711\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.049352\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.106719\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.074605\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.204476\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.151502\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.121017\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.194726\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.098427\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.112361\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.092550\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.190157\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.067780\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.087879\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.139602\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.204633\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.099970\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.161569\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.078173\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.167552\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.137531\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.040214\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.249330\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.113695\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.211011\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.123466\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.138269\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.172531\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.167489\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.237657\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.211566\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.137563\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.125249\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.168792\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.116473\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.193989\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.125529\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.155836\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.132444\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.188374\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.220608\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.216460\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.188128\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.099816\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.091277\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.101353\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.175106\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.078988\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.180605\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.191722\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.184954\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.207166\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.260924\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.264960\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.190121\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.290518\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.221230\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.301876\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.221102\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.115320\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.170447\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.185252\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.161204\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.273400\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.195515\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.168414\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.219022\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.188166\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.161043\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.218320\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.244995\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.173332\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.185586\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.261318\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.131719\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.223101\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.103132\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.159099\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.281877\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.180645\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.134121\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.126186\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.183151\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.297663\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.336841\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.392747\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.204798\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.263973\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.227554\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.189581\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.186328\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.277106\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.256951\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.291385\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.275780\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.327438\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.187692\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.204755\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.140228\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.233145\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.147268\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.276489\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.286227\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.322423\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.384265\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.271765\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.407799\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.230490\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.313350\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.220721\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.403249\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.288738\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.293369\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.285044\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.236574\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.287215\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.303518\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.177563\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.369513\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.183969\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.233482\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.385683\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.275121\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.197441\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.270632\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.390254\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.324045\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.240648\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.286357\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.237290\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.305540\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.288501\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.266811\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.224953\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.269861\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.333847\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.365826\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.234721\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.246354\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.325472\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.270013\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.228055\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.245922\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.295280\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.274491\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.274405\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.251156\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.190076\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.129503\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.281530\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.243835\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.210317\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.530798\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.310694\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.224692\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.131950\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.122922\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.185457\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.305404\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.160633\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.180643\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.110630\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.101457\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.223114\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.135975\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.100336\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.120627\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.080201\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.215277\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.172458\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.177111\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.170674\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.177234\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.131079\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.206410\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.183284\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.090493\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.106447\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.142869\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.063107\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.166750\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.095022\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.193742\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.140329\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.069862\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.295592\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.260727\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.343585\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.239810\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.317252\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.344310\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.167715\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.384455\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.200090\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.310629\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.224769\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.244179\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.156417\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.204743\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.194841\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.233726\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.181910\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.216129\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.267021\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.160116\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.252204\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.231709\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.233553\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.183730\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.223581\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.195853\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.132697\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.304214\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.255991\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.166021\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.205692\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.202162\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.148647\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.187932\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.179178\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.141902\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.131709\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.277284\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.130490\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.229006\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.171726\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.167616\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.297643\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.328339\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.220388\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.212530\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.159904\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.304625\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.132912\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.281047\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.094098\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.253942\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.167966\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.211179\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.138977\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.277093\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.170485\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.218067\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.145904\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.143682\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.163597\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.186713\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.245486\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.150490\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.158726\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.207553\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.160259\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.088398\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.185200\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.155807\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.177336\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.109175\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.7550, Accuracy: 8603/10000 (86%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.324297\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.250001\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.317970\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.294602\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.245010\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.241314\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.193895\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.286641\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.294945\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.234536\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.230299\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.181895\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.184858\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.228004\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.300328\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.299045\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.053036\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.071906\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.138725\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.052550\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.300347\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.102197\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.104187\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.139372\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.096717\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.110835\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.117190\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.173257\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.091039\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.083607\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.136658\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.139615\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.038326\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.025400\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.093905\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.050269\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.018551\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.113432\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.057497\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.041229\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.035854\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.056294\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.053526\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.044234\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.093288\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.101682\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.069101\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.117428\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.112550\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.029708\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.071379\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.030010\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.063474\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.050091\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.031710\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.224072\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.145108\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.123012\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.131869\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.088661\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.189147\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.133685\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.115539\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.204371\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.164738\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.148747\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.099303\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.118599\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.085518\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.071360\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.140125\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.148430\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.058031\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.111990\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.105627\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.147930\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.076259\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.214835\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.117118\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.065196\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.136803\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.251935\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.082083\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.064470\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.182110\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.072114\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.054257\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.092648\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.100774\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.094918\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.198927\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.163044\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.163713\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.097704\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.214497\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.116328\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.120907\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.112533\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.178129\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.156487\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.140585\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.145547\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.146368\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.165043\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.100737\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.193019\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.114679\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.185971\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.129164\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.171857\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.098250\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.122585\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.183459\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.199872\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.202815\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.077166\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.157034\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.186752\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.125856\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.124478\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.251166\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.202473\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.128680\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.180302\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.164647\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.264756\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.214079\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.250660\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.205128\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.199246\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.208178\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.195316\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.224071\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.150481\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.187962\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.228134\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.263751\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.140350\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.202621\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.128230\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.129708\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.126936\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.207481\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.160827\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.311183\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.105038\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.190410\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.243473\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.208226\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.197335\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.342421\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.188811\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.124763\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.297990\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.171947\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.225208\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.140566\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.301361\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.191887\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.230358\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.138524\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.192519\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.231528\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.284165\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.246112\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.266476\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.155773\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.209282\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.196364\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.144894\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.292747\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.219997\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.324575\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.342338\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.341247\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.272399\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.391344\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.179004\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.244856\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.271520\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.371327\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.281527\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.346344\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.333050\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.260745\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.248207\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.407756\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.262261\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.201447\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.146976\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.329362\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.233937\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.237405\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.221533\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.230646\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.170717\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.240106\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.244506\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.283559\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.310766\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.381435\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.316357\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.159787\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.297430\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.333463\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.193217\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.315176\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.327858\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.299583\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.322874\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.150992\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.279390\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.099206\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.251910\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.201767\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.232946\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.266156\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.272517\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.321192\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.396141\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.422668\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.269997\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.134436\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.129705\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.104910\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.260258\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.237866\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.161088\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.129191\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.148981\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.119395\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.125898\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.139855\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.164694\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.126146\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.185693\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.243489\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.109298\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.132758\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.118571\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.101566\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.114022\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.280114\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.047096\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.202341\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.099171\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.141217\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.064650\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.113427\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.183672\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.159498\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.111510\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.143544\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.126989\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.143493\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.205616\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.185076\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.225460\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.195577\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.351884\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.267618\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.261181\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.201666\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.276716\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.169351\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.324442\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.233614\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.229340\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.259704\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.332155\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.216538\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.227925\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.199401\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.222011\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.348420\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.118837\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.180764\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.321532\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.172296\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.270490\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.241599\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.155497\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.238816\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.205878\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.218270\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.101764\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.238754\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.158638\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.235115\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.202468\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.174016\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.202907\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.254093\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.203658\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.144734\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.110625\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.116102\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.299895\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.132058\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.183858\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.149181\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.141507\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.237770\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.248494\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.192517\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.212473\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.200652\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.123876\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.102093\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.156435\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.193551\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.187341\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.111071\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.155342\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.167514\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.201462\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.193764\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.214837\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.284866\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.161027\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.141870\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.157028\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.125944\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.160227\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.255389\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.7420, Accuracy: 8615/10000 (86%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.458218\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.361762\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.290633\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.238566\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.322783\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.199539\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.216311\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.128775\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.314498\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.238579\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.136681\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.206017\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.275355\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.202053\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.236028\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.367897\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.073358\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.153005\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.095161\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.090312\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.087315\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.065621\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.030991\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.050410\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.042460\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.067255\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.077252\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.109191\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.072618\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.081631\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.045894\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.116475\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.075227\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.081227\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.072122\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.048908\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.072405\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.086416\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.085210\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.058329\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.033635\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.062129\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.027660\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.086990\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.032474\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.050281\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.059511\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.043615\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.022826\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.118120\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.075568\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.076096\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.044820\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.109228\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.145502\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.310972\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.131908\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.166620\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.185626\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.155671\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.321964\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.130889\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.233943\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.112433\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.095440\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.088907\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.112584\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.127175\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.217591\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.098847\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.090814\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.115074\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.073831\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.124666\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.079753\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.037171\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.186638\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.093949\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.113711\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.100151\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.074494\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.150708\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.098004\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.091396\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.051760\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.123350\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.046964\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.076672\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.153520\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.195845\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.373500\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.174261\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.199926\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.259004\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.159691\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.191915\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.150739\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.151547\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.126122\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.181483\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.198429\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.160566\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.150622\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.103010\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.191549\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.091418\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.163139\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.137082\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.138683\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.192385\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.135390\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.090720\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.153081\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.081094\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.188280\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.145602\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.102732\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.133842\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.121244\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.112244\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.378592\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.303523\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.265403\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.249307\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.165008\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.251579\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.226120\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.209503\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.245206\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.200640\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.278598\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.259858\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.176390\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.173303\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.169198\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.179849\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.146149\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.145831\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.484450\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.161180\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.229220\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.158251\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.123488\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.195818\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.318243\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.146496\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.168037\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.267075\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.140463\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.140762\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.406800\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.222943\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.257044\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.308237\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.196299\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.142753\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.180914\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.188983\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.139205\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.283963\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.249672\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.203692\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.169270\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.231536\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.189714\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.298972\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.229946\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.180825\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.255853\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.131691\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.252746\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.336653\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.158596\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.301396\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.258431\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.189449\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.351079\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.305211\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.328094\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.301687\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.241710\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.284149\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.246715\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.279405\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.484840\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.248654\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.340230\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.149987\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.296787\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.253277\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.299200\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.173439\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.198656\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.228480\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.285730\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.371508\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.327408\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.313699\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.229198\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.287227\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.298205\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.216733\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.189237\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.248877\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.315242\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.285177\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.319326\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.243676\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.330019\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.218913\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.236640\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.254422\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.177969\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.350035\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.359955\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.204334\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.294431\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.292277\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.227639\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.200312\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.404069\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.135922\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.291355\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.190274\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.110345\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.181524\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.203083\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.163047\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.056097\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.164227\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.128240\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.208026\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.228326\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.131671\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.209953\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.102118\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.132395\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.176976\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.154018\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.186261\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.120539\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.109090\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.094733\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.167422\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.094884\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.166467\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.150832\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.103808\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.133931\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.191830\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.080753\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.147554\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.121595\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.111397\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.147845\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.382894\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.171346\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.237929\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.269224\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.259095\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.177237\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.302516\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.208759\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.203637\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.288296\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.232257\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.206032\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.234216\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.262329\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.171758\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.263936\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.338834\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.160259\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.226138\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.251213\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.208058\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.222274\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.162431\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.135115\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.198604\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.265671\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.236053\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.223066\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.151773\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.187398\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.219358\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.184995\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.167227\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.242104\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.208456\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.165779\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.120646\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.329036\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.155936\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.259515\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.100185\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.104603\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.202591\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.141782\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.169218\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.259195\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.081558\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.206850\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.118267\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.209746\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.144713\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.151531\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.165157\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.127177\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.096493\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.143787\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.152587\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.208901\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.065977\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.074844\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.120651\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.253503\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.259463\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.153998\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.131100\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.185268\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.163038\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.086556\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.107599\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.168335\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.7227, Accuracy: 8646/10000 (86%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.393447\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.269477\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.294105\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.200558\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.328511\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.359881\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.315378\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.300111\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.280135\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.292065\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.441062\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.275501\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.219198\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.218868\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.205788\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.231520\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.178502\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.055258\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.045593\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.105224\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.107898\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.055125\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.071903\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.082614\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.161897\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.096077\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.122604\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.185855\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.153024\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.092604\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.096140\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.036295\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.134861\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.114326\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.047806\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.052070\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.092517\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.041682\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.037306\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.061144\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.045853\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.128142\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.060554\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.045151\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.109971\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.076130\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.138165\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.072308\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.067206\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.059009\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.020254\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.044568\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.059003\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.109056\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.042366\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.188103\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.099583\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.076270\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.106964\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.178009\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.060260\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.192377\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.090218\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.058069\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.050256\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.215462\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.141555\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.116454\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.079619\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.143902\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.050447\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.071860\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.087363\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.111504\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.130012\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.286392\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.136475\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.172273\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.079137\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.136051\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.102080\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.100552\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.063360\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.140695\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.038012\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.082203\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.183929\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.045296\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.134043\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.109900\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.261791\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.227134\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.105342\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.256208\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.182540\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.136011\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.179202\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.177053\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.166736\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.156219\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.139426\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.192686\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.107630\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.119016\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.221575\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.225911\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.142289\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.110081\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.061531\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.159500\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.308632\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.145100\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.182198\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.188716\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.169627\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.169239\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.193074\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.085204\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.240261\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.157955\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.309535\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.378640\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.171105\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.229728\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.212406\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.183522\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.182534\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.218002\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.219870\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.303862\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.250540\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.228314\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.140550\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.134935\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.187844\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.197240\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.236448\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.227228\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.108284\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.137346\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.274066\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.120076\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.186469\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.186862\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.259347\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.213480\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.201930\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.140464\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.116000\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.128080\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.215485\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.287326\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.347300\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.267068\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.166873\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.194782\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.183988\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.210251\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.169243\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.197188\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.217829\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.192130\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.163754\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.236643\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.287270\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.246938\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.189299\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.304135\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.286824\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.189093\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.230660\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.303066\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.207537\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.415102\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.316837\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.288298\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.342494\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.264650\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.164052\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.316152\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.451915\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.281675\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.273425\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.173387\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.169953\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.198476\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.276622\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.295616\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.239562\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.271938\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.266448\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.346090\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.226041\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.250859\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.344842\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.200433\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.293730\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.319392\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.232032\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.406563\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.226771\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.146107\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.201198\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.335057\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.311874\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.224011\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.330098\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.328779\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.245171\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.238527\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.302530\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.277918\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.419889\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.246932\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.217193\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.359163\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.319844\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.260474\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.146980\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.360561\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.369952\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.126508\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.309707\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.149659\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.180534\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.192435\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.135445\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.146257\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.089337\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.120104\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.123321\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.146881\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.184117\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.194259\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.122072\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.177615\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.222203\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.109234\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.252753\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.207738\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.091679\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.214324\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.164339\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.261927\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.132084\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.263752\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.211861\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.128896\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.128440\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.231839\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.095588\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.124815\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.115281\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.221561\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.301196\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.209120\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.157777\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.254647\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.136042\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.339800\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.230005\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.159116\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.167240\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.128989\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.217920\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.222663\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.268170\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.172657\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.167733\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.275103\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.225653\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.170411\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.215783\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.210506\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.170092\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.203986\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.207664\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.177078\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.313341\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.215319\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.261891\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.155396\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.208245\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.212409\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.136254\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.234820\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.175271\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.272149\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.278133\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.177288\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.145836\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.283128\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.219535\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.176103\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.128648\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.203207\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.218668\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.123353\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.154039\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.122689\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.090718\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.203827\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.244479\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.159005\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.101857\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.161459\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.192034\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.163374\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.161807\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.147287\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.136300\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.085401\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.205803\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.221058\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.128200\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.179419\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.025240\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.118497\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.273849\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.189102\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.156689\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.095700\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.116149\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.223743\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.074146\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.7172, Accuracy: 8650/10000 (86%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "partitioned_data_pca = partition.balanced_dirichlet_partition(trainingset_pca, partitions_number=num_clients, alpha=alpha)\n",
    "pca_client_loaders = [\n",
    "    DataLoader(Subset(trainingset_pca, indices), batch_size=batch_size_train, shuffle=True)\n",
    "    for indices in partitioned_data_pca.values()\n",
    "]\n",
    "\n",
    "local_models_pca_strong = [copy.deepcopy(global_model_pca_strong) for _ in range(num_clients)]\n",
    "\n",
    "# Pca strong\n",
    "optimizer = optim.SGD(trial_model_pca_strong.parameters(), lr=learning_rate,\n",
    "                  momentum=momentum)\n",
    "\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):  \n",
    "    train_fashion(epoch, trial_model_pca_strong, train_loader_reduced_pca, optimizer, log_interval, train_losses, train_counter)\n",
    "\n",
    "\n",
    "\n",
    "test_losses_pca_strong = []\n",
    "test_fashion(trial_model_pca_strong,train_loader_reduced_pca,test_losses_pca_strong)\n",
    "\n",
    "rounds_pca = 4\n",
    "for round_idx in range(rounds_pca):\n",
    "    \n",
    "    print(f\"Round {round_idx + 1}/{rounds_pca}\")\n",
    "\n",
    "    local_weights_pca = []\n",
    "    for client_idx, client_model in enumerate(local_models_pca_strong):\n",
    "        print(f\"Training client {client_idx + 1}\")\n",
    "        \n",
    "        optimizer = optim.SGD(client_model.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "\n",
    "        train_losses = []\n",
    "        train_counter = []\n",
    "\n",
    "\n",
    "        for epoch in range(1, n_epochs + 1):  \n",
    "            train_fashion(epoch, client_model, pca_client_loaders[client_idx], optimizer, log_interval, train_losses, train_counter)\n",
    "        \n",
    "        client_weights = [param.data.numpy() for param in client_model.parameters()]\n",
    "        local_weights_pca.append(client_weights)\n",
    "        \n",
    "\n",
    "    global_weights_pca = federated_averaging(local_weights_pca)\n",
    "\n",
    "    distribute_global_model(global_weights_pca,local_models_pca_strong,single=False)\n",
    "\n",
    "    distribute_global_model(global_weights_pca,global_model_pca_strong,single=True)\n",
    "    test_losses = []\n",
    "    test_fashion(global_model_pca_strong,test_loader_pca,test_losses)\n",
    "\n",
    "    test_accuracies_classic = []\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader_pca:\n",
    "            data = data.view(data.shape[0], -1)\n",
    "            output = global_model_pca_strong(data)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "    accuracy = 100. * correct / len(test_loader_pca.dataset)\n",
    "    test_accuracies_classic.append(accuracy)\n",
    "\n",
    "    # Save results for non-clustered classic\n",
    "    results[\"pca\"][\"NoCluster\"] = {\"losses\": [], \"accuracy\": []}\n",
    "\n",
    "    results[\"pca\"][\"NoCluster\"][\"losses\"].extend(test_losses)\n",
    "    results[\"pca\"][\"NoCluster\"][\"accuracy\"].extend(test_accuracies_classic)\n",
    "\n",
    "    ######################\n",
    "for num_cluster in num_clusters:\n",
    "    import cluster\n",
    "    cluster = cluster.Cluster(num_clusters=num_cluster)\n",
    "    \n",
    "    targets = trainingset_pca.targets\n",
    "    num_classes = len(set(targets)) \n",
    "    clustered_data = cluster.apply_clustering(partitioned_data_pca, targets, num_classes)\n",
    "    \n",
    "    partitioned_data_pca_clustered = clustered_data\n",
    "\n",
    "    pca_client_loaders_clustered = [\n",
    "        DataLoader(Subset(trainingset_pca, indices), batch_size=batch_size_train, shuffle=True)\n",
    "        for indices in partitioned_data_pca_clustered.values()\n",
    "    ]\n",
    "\n",
    "    for round_idx in range(rounds_classic):\n",
    "        print(f\"Round {round_idx + 1}/{rounds_classic}\")\n",
    "\n",
    "        local_weights_pca = []\n",
    "        for client_idx, client_model in enumerate(local_models_pca_strong[0:num_cluster]):\n",
    "            print(f\"Training client {client_idx + 1}\")\n",
    "            \n",
    "            optimizer = optim.SGD(client_model.parameters(), lr=learning_rate,\n",
    "                          momentum=momentum)\n",
    "    \n",
    "            train_losses = []\n",
    "            train_counter = []\n",
    "    \n",
    "    \n",
    "            for epoch in range(1, n_epochs + 1):  \n",
    "                train_fashion(epoch, client_model, pca_client_loaders[client_idx], optimizer, log_interval, train_losses, train_counter)\n",
    "            \n",
    "            client_weights = [param.data.numpy() for param in client_model.parameters()]\n",
    "            local_weights_pca.append(client_weights)\n",
    "            \n",
    "    \n",
    "        global_weights_pca = federated_averaging(local_weights_pca)\n",
    "    \n",
    "        distribute_global_model(global_weights_pca,local_models_pca_strong,single=False)\n",
    "    \n",
    "        distribute_global_model(global_weights_pca,global_model_pca_strong,single=True)\n",
    "        test_losses = []\n",
    "        test_fashion(global_model_pca_strong,test_loader_pca,test_losses)\n",
    "    \n",
    "        test_accuracies_pca = []\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader_pca:\n",
    "                data = data.view(data.shape[0], -1)\n",
    "                output = global_model_pca_strong(data)\n",
    "                pred = output.data.max(1, keepdim=True)[1]\n",
    "                correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "        accuracy = 100. * correct / len(test_loader_pca.dataset)\n",
    "        test_accuracies_classic.append(accuracy)\n",
    "\n",
    "        # Save results for clustered classic\n",
    "        if num_cluster not in clusteredResults[\"pca\"]:\n",
    "            clusteredResults[\"pca\"][num_cluster] = {\"losses\": [], \"accuracy\": []}\n",
    "\n",
    "        clusteredResults[\"pca\"][num_cluster][\"losses\"].extend(test_losses)\n",
    "        clusteredResults[\"pca\"][num_cluster][\"accuracy\"].extend(test_accuracies_classic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results (Non-Clustered): {'classic': {'NoCluster': {'losses': [0.5188619812011719], 'accuracy': [80.19]}}, 'pca': {'NoCluster': {'losses': [0.9590497436523437], 'accuracy': [82.92]}}, 'autoencoder': {}}\n",
      "Final Results (Clustered): {'classic': {2: {'losses': [0.6111913330078125, 0.5729868041992188, 0.5778576416015625, 0.5886122863769532], 'accuracy': [77.31, 78.64, 78.81, 78.37]}, 4: {'losses': [0.5569269927978515, 0.5164715148925781, 0.5319765411376953, 0.5280328765869141], 'accuracy': [79.38, 80.76, 80.22, 80.34]}, 6: {'losses': [0.4632906616210937, 0.4644641296386719, 0.4652772644042969, 0.44572009887695313], 'accuracy': [82.79, 82.6, 82.67, 83.38]}, 8: {'losses': [0.4280053955078125, 0.4304277587890625, 0.41870563354492185, 0.41287210998535157], 'accuracy': [84.37, 84.18, 84.51, 85.12]}, 10: {'losses': [0.4158003601074219, 0.4127583312988281, 0.4012933013916016, 0.39449208984375], 'accuracy': [84.9, 84.82, 85.3, 85.84]}}, 'pca': {2: {'losses': [0.9848575317382813, 0.958135205078125, 0.9552243103027344, 0.9255470031738281], 'accuracy': [82.92, 78.4, 82.92, 78.4, 79.38, 82.92, 78.4, 79.38, 79.06, 82.92, 78.4, 79.38, 79.06, 79.92]}, 4: {'losses': [0.9080875244140625, 0.8836036071777343, 0.8704821105957031, 0.8572081481933593], 'accuracy': [82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 81.88, 82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 81.88, 80.68, 82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 81.88, 80.68, 81.84]}, 6: {'losses': [0.8480521362304687, 0.82582578125, 0.8089499572753907, 0.7913673217773437], 'accuracy': [82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 81.88, 80.68, 81.84, 83.88, 82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 81.88, 80.68, 81.84, 83.88, 84.2, 82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 81.88, 80.68, 81.84, 83.88, 84.2, 84.72, 82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 81.88, 80.68, 81.84, 83.88, 84.2, 84.72, 84.74]}, 8: {'losses': [0.7948213684082032, 0.7850610473632812, 0.7718647644042969, 0.7641170227050781], 'accuracy': [82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 81.88, 80.68, 81.84, 83.88, 84.2, 84.72, 84.74, 85.61, 82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 81.88, 80.68, 81.84, 83.88, 84.2, 84.72, 84.74, 85.61, 85.16, 82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 81.88, 80.68, 81.84, 83.88, 84.2, 84.72, 84.74, 85.61, 85.16, 85.89, 82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 81.88, 80.68, 81.84, 83.88, 84.2, 84.72, 84.74, 85.61, 85.16, 85.89, 85.57]}, 10: {'losses': [0.7549970031738281, 0.741978515625, 0.7226565307617188, 0.7171844665527344], 'accuracy': [82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 81.88, 80.68, 81.84, 83.88, 84.2, 84.72, 84.74, 85.61, 85.16, 85.89, 85.57, 86.03, 82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 81.88, 80.68, 81.84, 83.88, 84.2, 84.72, 84.74, 85.61, 85.16, 85.89, 85.57, 86.03, 86.15, 82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 81.88, 80.68, 81.84, 83.88, 84.2, 84.72, 84.74, 85.61, 85.16, 85.89, 85.57, 86.03, 86.15, 86.46, 82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 81.88, 80.68, 81.84, 83.88, 84.2, 84.72, 84.74, 85.61, 85.16, 85.89, 85.57, 86.03, 86.15, 86.46, 86.5]}}, 'autoencoder': {}}\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Results (Non-Clustered):\", results)\n",
    "print(\"Final Results (Clustered):\", clusteredResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder\n",
    "trainingset_auto = reduced_train_loader_auto.dataset\n",
    "trial_model_auto_strong = MultilayerPerceptron()\n",
    "global_model_auto_strong = MultilayerPerceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.311788\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 2.297354\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.281559\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 2.260314\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 2.218559\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 2.193289\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 2.171206\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 2.116008\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 2.084164\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 1.963554\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 1.980799\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 1.847897\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 1.837845\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 1.744823\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 1.735857\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 1.559035\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.543303\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 1.371148\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 1.232727\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 1.291346\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 1.324041\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 1.204301\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 1.190851\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 1.108628\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 1.187462\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.995786\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 1.120788\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 1.086503\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 1.023790\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 1.054452\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 1.059861\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 0.937672\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.002105\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 1.005561\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 1.014439\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 1.081030\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.860093\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 0.987080\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.787137\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 0.879051\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.965638\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 0.723544\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.864103\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 0.885257\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.885036\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 1.096074\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.869215\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 0.790466\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.586371\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 0.746935\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.728116\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 0.836634\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.780758\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 0.743279\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.728800\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.777796\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.759281\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 0.906071\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.900026\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 0.675147\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.803872\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 0.613192\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.674789\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 0.776516\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.914664\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.916591\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.862634\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 0.682478\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.715825\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 0.641428\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.840833\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 0.781655\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.732989\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 0.868692\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.650531\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.765894\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.679212\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 0.668856\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.798064\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 0.589771\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.733820\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 0.739429\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.607145\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 0.666686\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.602573\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.627300\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.641081\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 0.640306\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.813178\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 0.680481\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.526349\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 0.620189\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.731549\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 0.582765\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.650148\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.664173\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.634064\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 0.648967\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.739686\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 0.690954\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.553446\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 0.691501\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.760149\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 0.768468\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.797390\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.746775\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.599889\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 0.543633\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.617434\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 0.658816\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.621754\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 0.720619\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.823954\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 0.547180\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.540212\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.645893\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.641059\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 0.827641\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.803982\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 0.683072\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.707755\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 0.682606\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.515520\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 0.665280\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.699647\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.672949\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.731590\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 0.669489\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.672007\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 0.718324\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.805215\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 0.726031\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.692530\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 0.548358\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.497794\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.662400\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.612373\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 0.712769\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.662566\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 0.585116\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.662574\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 0.600140\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.507747\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 0.577812\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.464322\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.571176\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.600918\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 0.541950\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.719993\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 0.605883\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.555523\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 0.479437\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.639113\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 0.564705\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.616196\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.582068\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.729552\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 0.532840\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.479183\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 0.959672\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.658479\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 0.416722\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.703385\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 0.596104\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.598718\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.486415\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.475612\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 0.652871\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.564051\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 0.599822\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.710229\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 0.735889\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.703917\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 0.646219\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.698099\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.650963\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.721523\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 0.433142\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.560740\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 0.483366\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.580711\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 0.626084\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.580280\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 0.743878\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.487551\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.554071\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.566571\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 0.629746\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.759818\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 0.726774\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.501625\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 0.625221\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.486118\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 0.716244\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.633157\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.732035\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.474090\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 0.519338\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.367484\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 0.590158\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.599446\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 0.824153\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.689511\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 0.630669\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.523967\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.473595\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.667083\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 0.556161\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.517904\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 0.390027\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.597362\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 0.537766\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.645637\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 0.602707\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.469816\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.638454\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.516121\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 0.528292\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.505648\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 0.632319\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.748167\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 0.660272\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.541588\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 0.638003\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.720852\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.491934\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.497310\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 0.517936\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.649731\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 0.609063\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.714414\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 0.716055\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.591783\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 0.438930\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.548146\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.531497\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.713545\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 0.629277\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.594407\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 0.589588\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.668961\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 0.551221\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.710594\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 0.494810\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.498360\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.622920\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.598156\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 0.605419\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.497342\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 0.920292\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.607317\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 0.572758\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.421399\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 0.463318\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.399940\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.718756\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.697370\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 0.725984\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.760267\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 0.525110\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.492387\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 0.586879\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.614055\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 0.685226\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.568697\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.577842\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.455714\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 0.734283\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.488256\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 0.592110\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.559636\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 0.584479\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.670111\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 0.619237\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.602443\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.486175\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.494002\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 0.519554\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.511671\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 0.547022\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.537220\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 0.801897\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.472750\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 0.652698\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.610560\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.563980\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.507270\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 0.702315\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.610037\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 0.546160\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.589336\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 0.605334\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.539792\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 0.529339\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.629974\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.483913\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.537612\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 0.654153\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.663836\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 0.428750\n",
      "\n",
      "Test set: Avg. loss: 0.5554, Accuracy: 48246/60000 (80%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 2.279322\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 2.156003\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 2.109490\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 2.006161\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 1.800844\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 1.753901\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 1.738304\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 1.599473\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 1.630333\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 1.622503\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 1.497242\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 1.497798\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 1.446073\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 1.416022\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 1.259459\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 2.325688\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 2.067135\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 1.648685\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 1.060290\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.869213\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.959871\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.773338\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.526930\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.608200\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.615884\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.607344\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.638131\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.334685\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.690279\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.606546\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.535409\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.423350\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.527764\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.522197\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.507103\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.618083\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.299267\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.505903\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.531853\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.457812\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.461258\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.315224\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.515839\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.471306\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.448994\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.383376\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.360962\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.469297\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.312408\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.398457\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.430623\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.428941\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.275795\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.408264\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.230126\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 2.313073\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 2.183893\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 1.980855\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 1.774460\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 1.532289\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 1.580812\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 1.570667\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 1.361124\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 1.339759\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 1.069330\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 1.136018\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 1.126023\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 1.061750\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.949885\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.995380\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 1.033376\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.956463\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.918322\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 1.064127\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.769858\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.930693\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.814920\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.935244\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.750872\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.664503\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.839794\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.963913\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.827215\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.625509\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.518299\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.627035\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.722645\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.716640\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.651961\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.608997\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 2.281156\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 2.183605\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 2.077933\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 1.960615\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 1.580244\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 1.414396\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 1.317839\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 1.140226\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 1.153681\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.985725\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 1.143223\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.992867\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.875596\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.816583\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.909529\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.897070\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.909028\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.665092\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.969143\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.711580\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.713210\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.790784\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.710892\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.917381\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.643138\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.720277\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.696715\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.729161\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.666607\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.638324\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 2.282169\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 2.220270\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 2.169312\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 2.127840\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 2.005120\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 1.871469\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 1.829298\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 1.851876\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 1.658916\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 1.535202\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 1.444733\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 1.518804\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 1.269354\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 1.292430\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 1.240017\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.989532\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 1.080267\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 1.117519\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 1.176453\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 1.073224\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 1.071499\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.830094\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.803561\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 1.020225\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.856867\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 1.018956\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.870796\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.755448\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.716388\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.885011\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 2.371800\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 2.222866\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 2.075718\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 1.755535\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 1.636695\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 1.490567\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 1.305718\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 1.143956\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 1.318218\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 1.316740\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 1.198254\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 1.196298\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 1.029136\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 1.286969\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 1.126489\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 1.173519\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 1.125160\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 1.195727\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 1.098273\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.996716\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 2.318560\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 2.250316\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 2.172736\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 2.090582\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 2.008910\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 1.946322\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 1.772945\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 1.640180\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 1.568670\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 1.460589\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 1.579621\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 1.262388\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 1.453764\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 1.328887\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 1.310401\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 1.325356\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 1.161714\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 1.372773\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 1.216470\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 1.221642\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 1.123841\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 1.035095\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 1.228736\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 1.027061\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.941686\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 1.049824\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.913721\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 1.062023\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 1.006046\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.993889\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.889144\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 1.087904\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 1.081816\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.917989\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.922573\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.944362\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.942584\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.995822\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.994468\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.785674\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.800816\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.718861\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.851226\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.725759\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.651055\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.772391\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.856825\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.835055\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.888610\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.789917\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 2.286565\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 2.199796\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 2.053256\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 1.896929\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 1.840985\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 1.667555\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 1.784522\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 1.594676\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 1.487015\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 1.644578\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 1.472539\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 1.257939\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 1.221751\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 1.276953\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 1.167293\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 1.105687\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 1.227645\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.890465\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.912824\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.883410\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.848359\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.886916\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.918501\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.748919\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.805916\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.743374\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.673492\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.666378\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.645205\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.651505\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.742143\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.557244\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.666143\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.660669\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.750588\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 2.274944\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 2.211716\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 2.119386\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 2.000696\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 1.898564\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 1.906322\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 1.759642\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 1.897782\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 1.719160\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 1.667066\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 1.489890\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 1.557024\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 1.442198\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 1.301614\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 1.290220\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 1.206517\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 1.155326\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 1.164051\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 1.066433\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 1.044921\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 1.151536\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 1.152176\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 1.067886\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.926681\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.884402\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.867187\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.992204\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.942710\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.923127\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.939794\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.873544\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.925272\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.646409\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.764151\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.744657\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 2.276176\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 2.211550\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 2.059017\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 2.046206\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 1.750689\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 1.607407\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 1.525047\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 1.515868\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 1.298883\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 1.405027\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 1.416122\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 1.204566\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 1.354464\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 1.260897\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.863297\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 1.256100\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.941463\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 1.179681\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.956804\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.920670\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.866709\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.971004\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.770214\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.891195\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.948789\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 1.039981\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.695407\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.758105\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.709109\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.819491\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 1.040465\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.669726\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.827984\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.609512\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.912791\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.5333, Accuracy: 5193/10000 (52%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 1.503967\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 1.223030\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 1.306165\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 1.132094\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 1.202418\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 1.015559\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 1.049915\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 1.145972\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.923602\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 1.032592\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.966834\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.934823\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.984547\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.945118\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.914910\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 1.771944\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.571407\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.529150\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.436596\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.639910\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.348167\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.390650\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.383663\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.643122\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.476032\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.511056\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.397706\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.425162\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.306277\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.288430\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.410750\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.222562\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.392643\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.308850\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.382617\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.373791\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.284913\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.238736\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.335194\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.293834\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.344902\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.277421\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.249326\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.424571\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.257321\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.275180\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.418268\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.186955\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.327882\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.290799\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.312465\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.204556\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.394406\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.247733\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.361801\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 1.351692\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 1.104084\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 1.046698\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.762198\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.805609\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.736177\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.824725\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.748226\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.789285\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.741555\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.591688\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.725302\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.697836\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.637223\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.504312\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.536154\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.599243\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.639859\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.715703\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.534525\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.590625\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.657452\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.530338\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.420930\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.465707\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.546441\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.440075\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.558015\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.492877\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.695553\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.399799\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.595020\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.639733\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.489040\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.435656\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 1.738097\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.901675\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.737657\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.854827\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.827137\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.669370\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.638639\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.550076\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.734681\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.685888\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.519622\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.716179\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.799614\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.627915\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.613206\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.701039\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.787160\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.532646\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.671689\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.791327\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.390687\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.608136\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.440327\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.570787\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.605306\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.473807\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.596604\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.559138\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.464103\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.468528\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 1.583507\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 1.190757\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.919946\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.992981\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.756169\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.755618\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 1.071552\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.815373\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.687622\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.824869\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.923665\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.679895\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.902306\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.753639\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.669226\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.836252\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.771986\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.591566\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.663415\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.789199\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.646715\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.722167\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.577998\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.682673\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 1.007232\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.626331\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.547846\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.638762\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.721275\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.664178\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 1.398697\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.993635\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 1.001876\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.896887\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.908714\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.792512\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.694125\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.889993\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.900752\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.914665\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.758252\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.755582\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.961304\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.710112\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.603549\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.780636\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.814101\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.682609\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.640018\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.685399\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 1.381459\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 1.294465\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 1.036603\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 1.077782\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.886926\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.959233\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 1.011784\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 1.019612\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.806507\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.840078\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 1.094290\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.993301\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.821320\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.880983\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.718388\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.850249\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.827990\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.883643\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.706373\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.893677\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.796402\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 1.041608\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.812175\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.660381\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.787286\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.735653\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.759146\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.789489\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.790428\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.661897\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.715121\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.683342\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.762592\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.663671\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.694374\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.586617\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.705769\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.582911\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.731897\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.822239\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.941350\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.838741\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.831027\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.756259\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.640763\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.805411\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.624842\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.543063\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.539312\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.724603\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 1.960074\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 1.151514\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.909426\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.876596\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.672442\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.749628\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.737427\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.660100\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.865942\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.700400\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.644214\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.607642\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.655891\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.808472\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.578540\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.710247\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.744547\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.594667\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.670693\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.560983\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.595276\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.770029\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.537308\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.627194\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.690423\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.571473\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.528608\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.567988\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.555900\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.615300\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.464598\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.565798\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.544082\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.443930\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.450885\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 1.539462\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 1.144542\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 1.221900\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 1.114298\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.920234\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 1.044070\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.910018\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.965034\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.859525\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.819323\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.850225\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.781613\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.819199\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.857960\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.645689\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.841485\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.764444\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.910076\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.622705\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.710337\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.666325\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.605281\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.882790\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.629460\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.579115\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.699729\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.778200\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.710073\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.585919\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.684323\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.734435\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.562376\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.611165\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.634958\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.629383\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 1.576117\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 1.111001\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.999439\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.992044\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.839029\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.828309\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.883859\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.721102\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.804234\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.781631\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.774501\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.753817\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.647798\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.643334\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.854321\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.644791\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.739286\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.707659\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.756447\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.646994\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.661244\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.707893\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.496948\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.826717\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.609507\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.522529\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.620317\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.573201\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.625718\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.556535\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.630408\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.599523\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.696576\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.673494\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.632061\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.1577, Accuracy: 6091/10000 (61%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 1.089477\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.846156\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.973110\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.836366\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.993309\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.775396\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.861025\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.740627\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.718272\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.645753\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.983453\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.838668\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.762200\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.750174\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.796122\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 1.343166\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.414610\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.277892\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.359280\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.471280\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.267130\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.393640\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.276339\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.265272\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.272467\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.438421\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.353927\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.390377\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.149852\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.391800\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.267499\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.228757\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.285543\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.423826\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.301513\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.189317\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.305300\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.302942\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.318034\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.308155\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.239464\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.298046\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.181885\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.262957\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.326545\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.254720\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.295752\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.291146\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.245288\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.280940\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.208876\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.223049\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.252777\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.232981\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.219737\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.803232\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.493433\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.550396\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.496993\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.574563\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.474490\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.492190\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.540632\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.613396\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.550368\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.486138\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.491123\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.441389\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.545656\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.399360\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.424374\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.651097\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.467384\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.544186\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.441656\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.522920\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.438855\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.484004\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.688921\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.534206\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.354609\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.385300\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.386170\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.341536\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.574796\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.461386\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.225001\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.592493\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.463025\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.458977\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 1.061812\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.469960\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.403816\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.551334\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.517164\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.454368\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.464117\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.655694\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.562802\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.489462\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.620673\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.433580\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.451992\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.408531\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.464759\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.450152\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.437978\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.317911\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.362931\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.413439\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.543824\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.544062\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.527818\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.394093\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.375042\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.512741\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.382392\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.418862\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.632311\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.440299\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.872500\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.736356\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.670131\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.612371\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.559241\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.618343\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.632588\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.719693\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.666699\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.731265\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.567479\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.694355\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.657335\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.677262\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.488769\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.620361\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.549773\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.470804\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.486147\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.623776\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.509776\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.614326\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.502719\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.577128\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.580973\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.385544\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.586894\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.561450\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.653608\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.620716\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.806588\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.753509\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.646111\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.719581\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.618080\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.642923\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.671704\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.749253\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.590671\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.566353\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.697487\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.443334\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.547551\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.569147\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.626235\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.634053\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.526003\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.551853\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.444868\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.464851\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.962668\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.771569\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.949709\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.780543\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.743205\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.790685\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.541203\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.743557\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.805292\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.659475\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.641190\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.865735\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.782537\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.793222\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.820062\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.631031\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.695801\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.695246\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.664342\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.735437\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.769887\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.659050\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.811332\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.606233\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.505865\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.674279\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.671346\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.648103\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.610505\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.651005\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.657902\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.586966\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.694759\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.637480\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.621009\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.857831\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.498178\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.517744\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.783251\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.516476\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.703519\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.573674\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.715088\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.556744\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.548946\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.583872\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.602112\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.723611\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.554381\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.727754\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 1.278503\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.575296\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.618231\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.540081\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.545731\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.683811\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.457698\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.688553\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.616858\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.675557\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.557153\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.538208\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.651010\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.563778\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.509715\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.529764\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.674433\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.479221\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.601083\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.459480\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.477896\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.565804\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.592011\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.359149\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.442216\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.338629\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.572597\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.493909\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.415989\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.422266\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.393893\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.463422\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.529185\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.368426\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.456392\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.910788\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.711230\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.693061\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.686518\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.644764\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.693759\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.712950\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.534283\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.553701\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.646976\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.567643\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.633629\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.628115\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.703465\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.544160\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.634415\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.702365\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.689985\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.685250\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.583414\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.527061\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.537148\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.716823\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.676386\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.554284\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.404815\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.684817\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.565785\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.630213\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.575668\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.556502\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.491638\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.640711\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.584344\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.632572\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.903262\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.678893\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.737972\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.591772\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.531561\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.568556\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.628949\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.614249\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.512292\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.505543\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.615986\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.561252\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.487347\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.643674\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.595008\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.447427\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.630165\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.598680\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.611242\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.532424\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.467752\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.476697\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.525038\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.537436\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.480146\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.533615\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.604494\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.440475\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.450009\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.471400\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.523039\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.521742\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.452817\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.411615\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.622375\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.0149, Accuracy: 6603/10000 (66%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.961681\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.816284\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.681605\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.799108\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.627156\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.661960\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.689056\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.691077\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.689795\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.709927\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.809812\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.631189\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.719991\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.700453\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.732428\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.931554\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.195059\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.328104\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.244255\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.259391\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.310184\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.199761\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.237400\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.259373\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.240865\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.266089\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.369934\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.261969\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.161739\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.301675\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.334089\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.316118\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.338162\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.374351\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.244994\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.208865\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.217630\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.177813\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.324260\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.232097\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.145151\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.293891\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.214918\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.190675\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.241808\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.239202\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.250327\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.194158\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.226034\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.218715\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.335105\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.274186\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.186553\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.292224\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.196541\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.737527\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.610663\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.392531\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.497518\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.631166\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.455043\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.566270\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.497797\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.485398\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.358061\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.483732\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.362593\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.421823\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.607426\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.438703\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.307682\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.385881\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.541368\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.367651\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.475672\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.559174\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.352064\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.466851\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.507291\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.445067\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.382315\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.389089\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.348312\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.490041\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.527399\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.375951\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.364656\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.545549\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.328574\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.495776\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.814745\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.458151\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.462437\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.517651\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.409718\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.569514\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.501298\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.483425\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.438776\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.528786\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.405216\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.376506\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.462793\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.588008\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.486715\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.541906\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.424355\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.539186\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.338558\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.354785\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.427032\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.422853\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.344674\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.415220\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.489520\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.382188\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.793199\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.431302\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.347399\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.506222\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.648602\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.433711\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.626497\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.591966\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.584596\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.524720\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.665589\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.702582\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.395818\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.520900\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.474243\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.508688\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.573170\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.446967\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.433470\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.372537\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.546853\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.574598\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.421304\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.521526\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.542489\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.469749\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.460525\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.658534\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.571439\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.690416\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.580696\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.426327\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.540364\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.633866\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.647430\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.575196\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.648984\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.599585\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.775856\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.575311\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.593257\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.519874\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.572804\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.725066\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.496395\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.555317\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.591059\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.566376\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.509207\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.758574\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.512343\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.643179\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.535100\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.525761\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.733545\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.609723\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.818974\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.587390\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.762332\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.717900\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.718415\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.781152\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.618501\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.697199\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.609930\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.589566\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.735018\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.452501\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.821979\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.674073\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.548395\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.746681\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.639377\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.643904\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.585283\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.787297\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.623053\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.564939\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.435494\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.685943\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.586721\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.574663\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.538837\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.598519\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.654442\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.470297\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.678097\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.569384\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.550962\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.679138\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.505095\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.533526\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.629643\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.611832\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.758436\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.737317\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.668434\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.611370\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.498545\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.667923\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.669599\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.647775\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.559878\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.658154\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 1.060098\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.528292\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.627541\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.578691\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.493822\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.480862\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.511276\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.485649\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.479018\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.500602\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.605963\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.517165\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.459079\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.520970\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.335866\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.455670\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.358230\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.442155\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.516941\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.382190\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.470575\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.356454\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.519097\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.403082\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.485539\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.328524\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.444260\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.394761\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.486252\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.370140\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.333860\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.350846\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.459742\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.357567\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.478733\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.846814\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.614275\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.652614\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.830564\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.701990\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.722225\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.605303\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.616874\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.490359\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.496334\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.541525\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.512540\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.456639\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.511545\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.535070\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.706462\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.683361\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.612752\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.534137\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.580911\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.567994\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.550933\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.516998\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.589574\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.543734\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.538841\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.586209\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.500554\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.382101\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.635663\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.623706\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.526794\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.574907\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.587596\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.481622\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.708253\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.633081\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.583774\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.592649\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.623927\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.645518\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.531597\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.649689\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.333170\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.507306\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.487898\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.536014\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.470617\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.486276\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.578117\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.573137\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.459850\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.560495\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.437483\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.516404\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.515045\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.543722\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.541185\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.435647\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.561741\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.518564\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.463230\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.493660\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.414651\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.348060\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.672427\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.372146\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.417987\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.448534\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.510222\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9626, Accuracy: 6905/10000 (69%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/30711 (0%)]\tLoss: 0.584574\n",
      "Train Epoch: 1 [1000/30711 (3%)]\tLoss: 0.617837\n",
      "Train Epoch: 1 [2000/30711 (6%)]\tLoss: 0.621112\n",
      "Train Epoch: 1 [3000/30711 (10%)]\tLoss: 0.674595\n",
      "Train Epoch: 1 [4000/30711 (13%)]\tLoss: 0.748459\n",
      "Train Epoch: 1 [5000/30711 (16%)]\tLoss: 0.658854\n",
      "Train Epoch: 1 [6000/30711 (19%)]\tLoss: 0.642868\n",
      "Train Epoch: 1 [7000/30711 (23%)]\tLoss: 0.698655\n",
      "Train Epoch: 1 [8000/30711 (26%)]\tLoss: 0.663222\n",
      "Train Epoch: 1 [9000/30711 (29%)]\tLoss: 0.464920\n",
      "Train Epoch: 1 [10000/30711 (32%)]\tLoss: 0.606770\n",
      "Train Epoch: 1 [11000/30711 (36%)]\tLoss: 0.588382\n",
      "Train Epoch: 1 [12000/30711 (39%)]\tLoss: 0.807401\n",
      "Train Epoch: 1 [13000/30711 (42%)]\tLoss: 0.548278\n",
      "Train Epoch: 1 [14000/30711 (45%)]\tLoss: 0.615746\n",
      "Train Epoch: 1 [15000/30711 (49%)]\tLoss: 0.661810\n",
      "Train Epoch: 1 [16000/30711 (52%)]\tLoss: 0.549107\n",
      "Train Epoch: 1 [17000/30711 (55%)]\tLoss: 0.482119\n",
      "Train Epoch: 1 [18000/30711 (58%)]\tLoss: 0.449567\n",
      "Train Epoch: 1 [19000/30711 (62%)]\tLoss: 0.637229\n",
      "Train Epoch: 1 [20000/30711 (65%)]\tLoss: 0.677208\n",
      "Train Epoch: 1 [21000/30711 (68%)]\tLoss: 0.527719\n",
      "Train Epoch: 1 [22000/30711 (71%)]\tLoss: 0.454029\n",
      "Train Epoch: 1 [23000/30711 (75%)]\tLoss: 0.527707\n",
      "Train Epoch: 1 [24000/30711 (78%)]\tLoss: 0.506932\n",
      "Train Epoch: 1 [25000/30711 (81%)]\tLoss: 0.395379\n",
      "Train Epoch: 1 [26000/30711 (84%)]\tLoss: 0.670138\n",
      "Train Epoch: 1 [27000/30711 (88%)]\tLoss: 0.636006\n",
      "Train Epoch: 1 [28000/30711 (91%)]\tLoss: 0.636911\n",
      "Train Epoch: 1 [29000/30711 (94%)]\tLoss: 0.647102\n",
      "Train Epoch: 1 [30000/30711 (97%)]\tLoss: 0.785448\n",
      "Train Epoch: 2 [0/30711 (0%)]\tLoss: 0.727167\n",
      "Train Epoch: 2 [1000/30711 (3%)]\tLoss: 0.580458\n",
      "Train Epoch: 2 [2000/30711 (6%)]\tLoss: 0.579008\n",
      "Train Epoch: 2 [3000/30711 (10%)]\tLoss: 0.540277\n",
      "Train Epoch: 2 [4000/30711 (13%)]\tLoss: 0.668949\n",
      "Train Epoch: 2 [5000/30711 (16%)]\tLoss: 0.451077\n",
      "Train Epoch: 2 [6000/30711 (19%)]\tLoss: 0.539143\n",
      "Train Epoch: 2 [7000/30711 (23%)]\tLoss: 0.684405\n",
      "Train Epoch: 2 [8000/30711 (26%)]\tLoss: 0.690772\n",
      "Train Epoch: 2 [9000/30711 (29%)]\tLoss: 0.554028\n",
      "Train Epoch: 2 [10000/30711 (32%)]\tLoss: 0.724692\n",
      "Train Epoch: 2 [11000/30711 (36%)]\tLoss: 0.524516\n",
      "Train Epoch: 2 [12000/30711 (39%)]\tLoss: 0.628658\n",
      "Train Epoch: 2 [13000/30711 (42%)]\tLoss: 0.552501\n",
      "Train Epoch: 2 [14000/30711 (45%)]\tLoss: 0.516352\n",
      "Train Epoch: 2 [15000/30711 (49%)]\tLoss: 0.607653\n",
      "Train Epoch: 2 [16000/30711 (52%)]\tLoss: 0.585119\n",
      "Train Epoch: 2 [17000/30711 (55%)]\tLoss: 0.803598\n",
      "Train Epoch: 2 [18000/30711 (58%)]\tLoss: 0.664635\n",
      "Train Epoch: 2 [19000/30711 (62%)]\tLoss: 0.545723\n",
      "Train Epoch: 2 [20000/30711 (65%)]\tLoss: 0.690188\n",
      "Train Epoch: 2 [21000/30711 (68%)]\tLoss: 0.586168\n",
      "Train Epoch: 2 [22000/30711 (71%)]\tLoss: 0.554397\n",
      "Train Epoch: 2 [23000/30711 (75%)]\tLoss: 0.478373\n",
      "Train Epoch: 2 [24000/30711 (78%)]\tLoss: 0.535513\n",
      "Train Epoch: 2 [25000/30711 (81%)]\tLoss: 0.425005\n",
      "Train Epoch: 2 [26000/30711 (84%)]\tLoss: 0.541088\n",
      "Train Epoch: 2 [27000/30711 (88%)]\tLoss: 0.528294\n",
      "Train Epoch: 2 [28000/30711 (91%)]\tLoss: 0.579225\n",
      "Train Epoch: 2 [29000/30711 (94%)]\tLoss: 0.481306\n",
      "Train Epoch: 2 [30000/30711 (97%)]\tLoss: 0.494343\n",
      "Train Epoch: 3 [0/30711 (0%)]\tLoss: 0.617934\n",
      "Train Epoch: 3 [1000/30711 (3%)]\tLoss: 0.597933\n",
      "Train Epoch: 3 [2000/30711 (6%)]\tLoss: 0.555103\n",
      "Train Epoch: 3 [3000/30711 (10%)]\tLoss: 0.508192\n",
      "Train Epoch: 3 [4000/30711 (13%)]\tLoss: 0.500411\n",
      "Train Epoch: 3 [5000/30711 (16%)]\tLoss: 0.673838\n",
      "Train Epoch: 3 [6000/30711 (19%)]\tLoss: 0.801517\n",
      "Train Epoch: 3 [7000/30711 (23%)]\tLoss: 0.666190\n",
      "Train Epoch: 3 [8000/30711 (26%)]\tLoss: 0.603012\n",
      "Train Epoch: 3 [9000/30711 (29%)]\tLoss: 0.538182\n",
      "Train Epoch: 3 [10000/30711 (32%)]\tLoss: 0.558231\n",
      "Train Epoch: 3 [11000/30711 (36%)]\tLoss: 0.634283\n",
      "Train Epoch: 3 [12000/30711 (39%)]\tLoss: 0.603076\n",
      "Train Epoch: 3 [13000/30711 (42%)]\tLoss: 0.599240\n",
      "Train Epoch: 3 [14000/30711 (45%)]\tLoss: 0.401126\n",
      "Train Epoch: 3 [15000/30711 (49%)]\tLoss: 0.746169\n",
      "Train Epoch: 3 [16000/30711 (52%)]\tLoss: 0.501203\n",
      "Train Epoch: 3 [17000/30711 (55%)]\tLoss: 0.646016\n",
      "Train Epoch: 3 [18000/30711 (58%)]\tLoss: 0.636666\n",
      "Train Epoch: 3 [19000/30711 (62%)]\tLoss: 0.770260\n",
      "Train Epoch: 3 [20000/30711 (65%)]\tLoss: 0.690836\n",
      "Train Epoch: 3 [21000/30711 (68%)]\tLoss: 0.608610\n",
      "Train Epoch: 3 [22000/30711 (71%)]\tLoss: 0.481063\n",
      "Train Epoch: 3 [23000/30711 (75%)]\tLoss: 0.598322\n",
      "Train Epoch: 3 [24000/30711 (78%)]\tLoss: 0.546808\n",
      "Train Epoch: 3 [25000/30711 (81%)]\tLoss: 0.568254\n",
      "Train Epoch: 3 [26000/30711 (84%)]\tLoss: 0.525216\n",
      "Train Epoch: 3 [27000/30711 (88%)]\tLoss: 0.510666\n",
      "Train Epoch: 3 [28000/30711 (91%)]\tLoss: 0.492288\n",
      "Train Epoch: 3 [29000/30711 (94%)]\tLoss: 0.521038\n",
      "Train Epoch: 3 [30000/30711 (97%)]\tLoss: 0.539491\n",
      "Train Epoch: 4 [0/30711 (0%)]\tLoss: 0.725763\n",
      "Train Epoch: 4 [1000/30711 (3%)]\tLoss: 0.570941\n",
      "Train Epoch: 4 [2000/30711 (6%)]\tLoss: 0.640896\n",
      "Train Epoch: 4 [3000/30711 (10%)]\tLoss: 0.499458\n",
      "Train Epoch: 4 [4000/30711 (13%)]\tLoss: 0.521903\n",
      "Train Epoch: 4 [5000/30711 (16%)]\tLoss: 0.486928\n",
      "Train Epoch: 4 [6000/30711 (19%)]\tLoss: 0.696954\n",
      "Train Epoch: 4 [7000/30711 (23%)]\tLoss: 0.583187\n",
      "Train Epoch: 4 [8000/30711 (26%)]\tLoss: 0.471793\n",
      "Train Epoch: 4 [9000/30711 (29%)]\tLoss: 0.626148\n",
      "Train Epoch: 4 [10000/30711 (32%)]\tLoss: 0.557686\n",
      "Train Epoch: 4 [11000/30711 (36%)]\tLoss: 0.515467\n",
      "Train Epoch: 4 [12000/30711 (39%)]\tLoss: 0.567159\n",
      "Train Epoch: 4 [13000/30711 (42%)]\tLoss: 0.732429\n",
      "Train Epoch: 4 [14000/30711 (45%)]\tLoss: 0.508324\n",
      "Train Epoch: 4 [15000/30711 (49%)]\tLoss: 0.426150\n",
      "Train Epoch: 4 [16000/30711 (52%)]\tLoss: 0.565440\n",
      "Train Epoch: 4 [17000/30711 (55%)]\tLoss: 0.549854\n",
      "Train Epoch: 4 [18000/30711 (58%)]\tLoss: 0.696396\n",
      "Train Epoch: 4 [19000/30711 (62%)]\tLoss: 0.413187\n",
      "Train Epoch: 4 [20000/30711 (65%)]\tLoss: 0.668712\n",
      "Train Epoch: 4 [21000/30711 (68%)]\tLoss: 0.527221\n",
      "Train Epoch: 4 [22000/30711 (71%)]\tLoss: 0.662080\n",
      "Train Epoch: 4 [23000/30711 (75%)]\tLoss: 0.548498\n",
      "Train Epoch: 4 [24000/30711 (78%)]\tLoss: 0.611680\n",
      "Train Epoch: 4 [25000/30711 (81%)]\tLoss: 0.506269\n",
      "Train Epoch: 4 [26000/30711 (84%)]\tLoss: 0.676533\n",
      "Train Epoch: 4 [27000/30711 (88%)]\tLoss: 0.516629\n",
      "Train Epoch: 4 [28000/30711 (91%)]\tLoss: 0.600884\n",
      "Train Epoch: 4 [29000/30711 (94%)]\tLoss: 0.570223\n",
      "Train Epoch: 4 [30000/30711 (97%)]\tLoss: 0.582137\n",
      "Train Epoch: 5 [0/30711 (0%)]\tLoss: 0.697114\n",
      "Train Epoch: 5 [1000/30711 (3%)]\tLoss: 0.513621\n",
      "Train Epoch: 5 [2000/30711 (6%)]\tLoss: 0.424613\n",
      "Train Epoch: 5 [3000/30711 (10%)]\tLoss: 0.502361\n",
      "Train Epoch: 5 [4000/30711 (13%)]\tLoss: 0.762834\n",
      "Train Epoch: 5 [5000/30711 (16%)]\tLoss: 0.446201\n",
      "Train Epoch: 5 [6000/30711 (19%)]\tLoss: 0.648753\n",
      "Train Epoch: 5 [7000/30711 (23%)]\tLoss: 0.537008\n",
      "Train Epoch: 5 [8000/30711 (26%)]\tLoss: 0.600437\n",
      "Train Epoch: 5 [9000/30711 (29%)]\tLoss: 0.665679\n",
      "Train Epoch: 5 [10000/30711 (32%)]\tLoss: 0.497206\n",
      "Train Epoch: 5 [11000/30711 (36%)]\tLoss: 0.500301\n",
      "Train Epoch: 5 [12000/30711 (39%)]\tLoss: 0.571249\n",
      "Train Epoch: 5 [13000/30711 (42%)]\tLoss: 0.473808\n",
      "Train Epoch: 5 [14000/30711 (45%)]\tLoss: 0.603035\n",
      "Train Epoch: 5 [15000/30711 (49%)]\tLoss: 0.478246\n",
      "Train Epoch: 5 [16000/30711 (52%)]\tLoss: 0.525237\n",
      "Train Epoch: 5 [17000/30711 (55%)]\tLoss: 0.569819\n",
      "Train Epoch: 5 [18000/30711 (58%)]\tLoss: 0.554943\n",
      "Train Epoch: 5 [19000/30711 (62%)]\tLoss: 0.538336\n",
      "Train Epoch: 5 [20000/30711 (65%)]\tLoss: 0.469697\n",
      "Train Epoch: 5 [21000/30711 (68%)]\tLoss: 0.493692\n",
      "Train Epoch: 5 [22000/30711 (71%)]\tLoss: 0.542266\n",
      "Train Epoch: 5 [23000/30711 (75%)]\tLoss: 0.612225\n",
      "Train Epoch: 5 [24000/30711 (78%)]\tLoss: 0.681471\n",
      "Train Epoch: 5 [25000/30711 (81%)]\tLoss: 0.406343\n",
      "Train Epoch: 5 [26000/30711 (84%)]\tLoss: 0.502804\n",
      "Train Epoch: 5 [27000/30711 (88%)]\tLoss: 0.515492\n",
      "Train Epoch: 5 [28000/30711 (91%)]\tLoss: 0.375574\n",
      "Train Epoch: 5 [29000/30711 (94%)]\tLoss: 0.566174\n",
      "Train Epoch: 5 [30000/30711 (97%)]\tLoss: 0.499837\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/29289 (0%)]\tLoss: 0.613401\n",
      "Train Epoch: 1 [1000/29289 (3%)]\tLoss: 0.575167\n",
      "Train Epoch: 1 [2000/29289 (7%)]\tLoss: 0.678570\n",
      "Train Epoch: 1 [3000/29289 (10%)]\tLoss: 0.575002\n",
      "Train Epoch: 1 [4000/29289 (14%)]\tLoss: 0.683244\n",
      "Train Epoch: 1 [5000/29289 (17%)]\tLoss: 0.629229\n",
      "Train Epoch: 1 [6000/29289 (20%)]\tLoss: 0.609823\n",
      "Train Epoch: 1 [7000/29289 (24%)]\tLoss: 0.696587\n",
      "Train Epoch: 1 [8000/29289 (27%)]\tLoss: 0.759756\n",
      "Train Epoch: 1 [9000/29289 (31%)]\tLoss: 0.637694\n",
      "Train Epoch: 1 [10000/29289 (34%)]\tLoss: 0.460334\n",
      "Train Epoch: 1 [11000/29289 (38%)]\tLoss: 0.657979\n",
      "Train Epoch: 1 [12000/29289 (41%)]\tLoss: 0.558285\n",
      "Train Epoch: 1 [13000/29289 (44%)]\tLoss: 0.657887\n",
      "Train Epoch: 1 [14000/29289 (48%)]\tLoss: 0.590400\n",
      "Train Epoch: 1 [15000/29289 (51%)]\tLoss: 0.475710\n",
      "Train Epoch: 1 [16000/29289 (55%)]\tLoss: 0.680992\n",
      "Train Epoch: 1 [17000/29289 (58%)]\tLoss: 0.539595\n",
      "Train Epoch: 1 [18000/29289 (61%)]\tLoss: 0.866741\n",
      "Train Epoch: 1 [19000/29289 (65%)]\tLoss: 0.446280\n",
      "Train Epoch: 1 [20000/29289 (68%)]\tLoss: 0.656590\n",
      "Train Epoch: 1 [21000/29289 (72%)]\tLoss: 0.634863\n",
      "Train Epoch: 1 [22000/29289 (75%)]\tLoss: 0.661955\n",
      "Train Epoch: 1 [23000/29289 (78%)]\tLoss: 0.590329\n",
      "Train Epoch: 1 [24000/29289 (82%)]\tLoss: 0.728437\n",
      "Train Epoch: 1 [25000/29289 (85%)]\tLoss: 0.638499\n",
      "Train Epoch: 1 [26000/29289 (89%)]\tLoss: 0.465199\n",
      "Train Epoch: 1 [27000/29289 (92%)]\tLoss: 0.537608\n",
      "Train Epoch: 1 [28000/29289 (96%)]\tLoss: 0.786875\n",
      "Train Epoch: 1 [29000/29289 (99%)]\tLoss: 0.447482\n",
      "Train Epoch: 2 [0/29289 (0%)]\tLoss: 0.638879\n",
      "Train Epoch: 2 [1000/29289 (3%)]\tLoss: 0.433567\n",
      "Train Epoch: 2 [2000/29289 (7%)]\tLoss: 0.544685\n",
      "Train Epoch: 2 [3000/29289 (10%)]\tLoss: 0.667518\n",
      "Train Epoch: 2 [4000/29289 (14%)]\tLoss: 0.605738\n",
      "Train Epoch: 2 [5000/29289 (17%)]\tLoss: 0.708557\n",
      "Train Epoch: 2 [6000/29289 (20%)]\tLoss: 0.590896\n",
      "Train Epoch: 2 [7000/29289 (24%)]\tLoss: 0.662610\n",
      "Train Epoch: 2 [8000/29289 (27%)]\tLoss: 0.572580\n",
      "Train Epoch: 2 [9000/29289 (31%)]\tLoss: 0.601860\n",
      "Train Epoch: 2 [10000/29289 (34%)]\tLoss: 0.574729\n",
      "Train Epoch: 2 [11000/29289 (38%)]\tLoss: 0.508707\n",
      "Train Epoch: 2 [12000/29289 (41%)]\tLoss: 0.724818\n",
      "Train Epoch: 2 [13000/29289 (44%)]\tLoss: 0.531168\n",
      "Train Epoch: 2 [14000/29289 (48%)]\tLoss: 0.769754\n",
      "Train Epoch: 2 [15000/29289 (51%)]\tLoss: 0.557762\n",
      "Train Epoch: 2 [16000/29289 (55%)]\tLoss: 0.672157\n",
      "Train Epoch: 2 [17000/29289 (58%)]\tLoss: 0.497558\n",
      "Train Epoch: 2 [18000/29289 (61%)]\tLoss: 0.548659\n",
      "Train Epoch: 2 [19000/29289 (65%)]\tLoss: 0.703411\n",
      "Train Epoch: 2 [20000/29289 (68%)]\tLoss: 0.519297\n",
      "Train Epoch: 2 [21000/29289 (72%)]\tLoss: 0.527574\n",
      "Train Epoch: 2 [22000/29289 (75%)]\tLoss: 0.483210\n",
      "Train Epoch: 2 [23000/29289 (78%)]\tLoss: 0.601970\n",
      "Train Epoch: 2 [24000/29289 (82%)]\tLoss: 0.455741\n",
      "Train Epoch: 2 [25000/29289 (85%)]\tLoss: 0.546057\n",
      "Train Epoch: 2 [26000/29289 (89%)]\tLoss: 0.521957\n",
      "Train Epoch: 2 [27000/29289 (92%)]\tLoss: 0.607655\n",
      "Train Epoch: 2 [28000/29289 (96%)]\tLoss: 0.618123\n",
      "Train Epoch: 2 [29000/29289 (99%)]\tLoss: 0.536634\n",
      "Train Epoch: 3 [0/29289 (0%)]\tLoss: 0.527859\n",
      "Train Epoch: 3 [1000/29289 (3%)]\tLoss: 0.590847\n",
      "Train Epoch: 3 [2000/29289 (7%)]\tLoss: 0.762718\n",
      "Train Epoch: 3 [3000/29289 (10%)]\tLoss: 0.565190\n",
      "Train Epoch: 3 [4000/29289 (14%)]\tLoss: 0.712304\n",
      "Train Epoch: 3 [5000/29289 (17%)]\tLoss: 0.505755\n",
      "Train Epoch: 3 [6000/29289 (20%)]\tLoss: 0.636984\n",
      "Train Epoch: 3 [7000/29289 (24%)]\tLoss: 0.579929\n",
      "Train Epoch: 3 [8000/29289 (27%)]\tLoss: 0.679168\n",
      "Train Epoch: 3 [9000/29289 (31%)]\tLoss: 0.464705\n",
      "Train Epoch: 3 [10000/29289 (34%)]\tLoss: 0.582746\n",
      "Train Epoch: 3 [11000/29289 (38%)]\tLoss: 0.617178\n",
      "Train Epoch: 3 [12000/29289 (41%)]\tLoss: 0.510884\n",
      "Train Epoch: 3 [13000/29289 (44%)]\tLoss: 0.610719\n",
      "Train Epoch: 3 [14000/29289 (48%)]\tLoss: 0.556250\n",
      "Train Epoch: 3 [15000/29289 (51%)]\tLoss: 0.669727\n",
      "Train Epoch: 3 [16000/29289 (55%)]\tLoss: 0.639559\n",
      "Train Epoch: 3 [17000/29289 (58%)]\tLoss: 0.444214\n",
      "Train Epoch: 3 [18000/29289 (61%)]\tLoss: 0.558342\n",
      "Train Epoch: 3 [19000/29289 (65%)]\tLoss: 0.407758\n",
      "Train Epoch: 3 [20000/29289 (68%)]\tLoss: 0.476195\n",
      "Train Epoch: 3 [21000/29289 (72%)]\tLoss: 0.428052\n",
      "Train Epoch: 3 [22000/29289 (75%)]\tLoss: 0.537429\n",
      "Train Epoch: 3 [23000/29289 (78%)]\tLoss: 0.439664\n",
      "Train Epoch: 3 [24000/29289 (82%)]\tLoss: 0.503211\n",
      "Train Epoch: 3 [25000/29289 (85%)]\tLoss: 0.463328\n",
      "Train Epoch: 3 [26000/29289 (89%)]\tLoss: 0.594889\n",
      "Train Epoch: 3 [27000/29289 (92%)]\tLoss: 0.445165\n",
      "Train Epoch: 3 [28000/29289 (96%)]\tLoss: 0.515027\n",
      "Train Epoch: 3 [29000/29289 (99%)]\tLoss: 0.671320\n",
      "Train Epoch: 4 [0/29289 (0%)]\tLoss: 0.427863\n",
      "Train Epoch: 4 [1000/29289 (3%)]\tLoss: 0.436944\n",
      "Train Epoch: 4 [2000/29289 (7%)]\tLoss: 0.540188\n",
      "Train Epoch: 4 [3000/29289 (10%)]\tLoss: 0.513055\n",
      "Train Epoch: 4 [4000/29289 (14%)]\tLoss: 0.561148\n",
      "Train Epoch: 4 [5000/29289 (17%)]\tLoss: 0.619891\n",
      "Train Epoch: 4 [6000/29289 (20%)]\tLoss: 0.629299\n",
      "Train Epoch: 4 [7000/29289 (24%)]\tLoss: 0.460243\n",
      "Train Epoch: 4 [8000/29289 (27%)]\tLoss: 0.509444\n",
      "Train Epoch: 4 [9000/29289 (31%)]\tLoss: 0.745379\n",
      "Train Epoch: 4 [10000/29289 (34%)]\tLoss: 0.537172\n",
      "Train Epoch: 4 [11000/29289 (38%)]\tLoss: 0.562415\n",
      "Train Epoch: 4 [12000/29289 (41%)]\tLoss: 0.539649\n",
      "Train Epoch: 4 [13000/29289 (44%)]\tLoss: 0.464138\n",
      "Train Epoch: 4 [14000/29289 (48%)]\tLoss: 0.801649\n",
      "Train Epoch: 4 [15000/29289 (51%)]\tLoss: 0.642021\n",
      "Train Epoch: 4 [16000/29289 (55%)]\tLoss: 0.565518\n",
      "Train Epoch: 4 [17000/29289 (58%)]\tLoss: 0.528808\n",
      "Train Epoch: 4 [18000/29289 (61%)]\tLoss: 0.722108\n",
      "Train Epoch: 4 [19000/29289 (65%)]\tLoss: 0.396931\n",
      "Train Epoch: 4 [20000/29289 (68%)]\tLoss: 0.517648\n",
      "Train Epoch: 4 [21000/29289 (72%)]\tLoss: 0.684035\n",
      "Train Epoch: 4 [22000/29289 (75%)]\tLoss: 0.562098\n",
      "Train Epoch: 4 [23000/29289 (78%)]\tLoss: 0.539881\n",
      "Train Epoch: 4 [24000/29289 (82%)]\tLoss: 0.651470\n",
      "Train Epoch: 4 [25000/29289 (85%)]\tLoss: 0.453414\n",
      "Train Epoch: 4 [26000/29289 (89%)]\tLoss: 0.545010\n",
      "Train Epoch: 4 [27000/29289 (92%)]\tLoss: 0.518266\n",
      "Train Epoch: 4 [28000/29289 (96%)]\tLoss: 0.423906\n",
      "Train Epoch: 4 [29000/29289 (99%)]\tLoss: 0.571155\n",
      "Train Epoch: 5 [0/29289 (0%)]\tLoss: 0.513147\n",
      "Train Epoch: 5 [1000/29289 (3%)]\tLoss: 0.581917\n",
      "Train Epoch: 5 [2000/29289 (7%)]\tLoss: 0.743718\n",
      "Train Epoch: 5 [3000/29289 (10%)]\tLoss: 0.490425\n",
      "Train Epoch: 5 [4000/29289 (14%)]\tLoss: 0.583330\n",
      "Train Epoch: 5 [5000/29289 (17%)]\tLoss: 0.542124\n",
      "Train Epoch: 5 [6000/29289 (20%)]\tLoss: 0.434936\n",
      "Train Epoch: 5 [7000/29289 (24%)]\tLoss: 0.410798\n",
      "Train Epoch: 5 [8000/29289 (27%)]\tLoss: 0.482289\n",
      "Train Epoch: 5 [9000/29289 (31%)]\tLoss: 0.548501\n",
      "Train Epoch: 5 [10000/29289 (34%)]\tLoss: 0.484191\n",
      "Train Epoch: 5 [11000/29289 (38%)]\tLoss: 0.555114\n",
      "Train Epoch: 5 [12000/29289 (41%)]\tLoss: 0.433851\n",
      "Train Epoch: 5 [13000/29289 (44%)]\tLoss: 0.495739\n",
      "Train Epoch: 5 [14000/29289 (48%)]\tLoss: 0.519933\n",
      "Train Epoch: 5 [15000/29289 (51%)]\tLoss: 0.596065\n",
      "Train Epoch: 5 [16000/29289 (55%)]\tLoss: 0.608740\n",
      "Train Epoch: 5 [17000/29289 (58%)]\tLoss: 0.537522\n",
      "Train Epoch: 5 [18000/29289 (61%)]\tLoss: 0.472079\n",
      "Train Epoch: 5 [19000/29289 (65%)]\tLoss: 0.789107\n",
      "Train Epoch: 5 [20000/29289 (68%)]\tLoss: 0.491406\n",
      "Train Epoch: 5 [21000/29289 (72%)]\tLoss: 0.595138\n",
      "Train Epoch: 5 [22000/29289 (75%)]\tLoss: 0.358391\n",
      "Train Epoch: 5 [23000/29289 (78%)]\tLoss: 0.545690\n",
      "Train Epoch: 5 [24000/29289 (82%)]\tLoss: 0.426058\n",
      "Train Epoch: 5 [25000/29289 (85%)]\tLoss: 0.510083\n",
      "Train Epoch: 5 [26000/29289 (89%)]\tLoss: 0.536572\n",
      "Train Epoch: 5 [27000/29289 (92%)]\tLoss: 0.447032\n",
      "Train Epoch: 5 [28000/29289 (96%)]\tLoss: 0.496541\n",
      "Train Epoch: 5 [29000/29289 (99%)]\tLoss: 0.476904\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8712, Accuracy: 7429/10000 (74%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/30711 (0%)]\tLoss: 0.616004\n",
      "Train Epoch: 1 [1000/30711 (3%)]\tLoss: 0.612274\n",
      "Train Epoch: 1 [2000/30711 (6%)]\tLoss: 0.496523\n",
      "Train Epoch: 1 [3000/30711 (10%)]\tLoss: 0.600734\n",
      "Train Epoch: 1 [4000/30711 (13%)]\tLoss: 0.506269\n",
      "Train Epoch: 1 [5000/30711 (16%)]\tLoss: 0.537448\n",
      "Train Epoch: 1 [6000/30711 (19%)]\tLoss: 0.524561\n",
      "Train Epoch: 1 [7000/30711 (23%)]\tLoss: 0.661703\n",
      "Train Epoch: 1 [8000/30711 (26%)]\tLoss: 0.581412\n",
      "Train Epoch: 1 [9000/30711 (29%)]\tLoss: 0.444479\n",
      "Train Epoch: 1 [10000/30711 (32%)]\tLoss: 0.543178\n",
      "Train Epoch: 1 [11000/30711 (36%)]\tLoss: 0.620494\n",
      "Train Epoch: 1 [12000/30711 (39%)]\tLoss: 0.598833\n",
      "Train Epoch: 1 [13000/30711 (42%)]\tLoss: 0.516357\n",
      "Train Epoch: 1 [14000/30711 (45%)]\tLoss: 0.601879\n",
      "Train Epoch: 1 [15000/30711 (49%)]\tLoss: 0.411032\n",
      "Train Epoch: 1 [16000/30711 (52%)]\tLoss: 0.605384\n",
      "Train Epoch: 1 [17000/30711 (55%)]\tLoss: 0.543655\n",
      "Train Epoch: 1 [18000/30711 (58%)]\tLoss: 0.514856\n",
      "Train Epoch: 1 [19000/30711 (62%)]\tLoss: 0.573342\n",
      "Train Epoch: 1 [20000/30711 (65%)]\tLoss: 0.548841\n",
      "Train Epoch: 1 [21000/30711 (68%)]\tLoss: 0.414261\n",
      "Train Epoch: 1 [22000/30711 (71%)]\tLoss: 0.448209\n",
      "Train Epoch: 1 [23000/30711 (75%)]\tLoss: 0.756178\n",
      "Train Epoch: 1 [24000/30711 (78%)]\tLoss: 0.483866\n",
      "Train Epoch: 1 [25000/30711 (81%)]\tLoss: 0.480665\n",
      "Train Epoch: 1 [26000/30711 (84%)]\tLoss: 0.487362\n",
      "Train Epoch: 1 [27000/30711 (88%)]\tLoss: 0.425654\n",
      "Train Epoch: 1 [28000/30711 (91%)]\tLoss: 0.525171\n",
      "Train Epoch: 1 [29000/30711 (94%)]\tLoss: 0.528627\n",
      "Train Epoch: 1 [30000/30711 (97%)]\tLoss: 0.357790\n",
      "Train Epoch: 2 [0/30711 (0%)]\tLoss: 0.614781\n",
      "Train Epoch: 2 [1000/30711 (3%)]\tLoss: 0.548874\n",
      "Train Epoch: 2 [2000/30711 (6%)]\tLoss: 0.519889\n",
      "Train Epoch: 2 [3000/30711 (10%)]\tLoss: 0.643053\n",
      "Train Epoch: 2 [4000/30711 (13%)]\tLoss: 0.534851\n",
      "Train Epoch: 2 [5000/30711 (16%)]\tLoss: 0.618181\n",
      "Train Epoch: 2 [6000/30711 (19%)]\tLoss: 0.416839\n",
      "Train Epoch: 2 [7000/30711 (23%)]\tLoss: 0.549446\n",
      "Train Epoch: 2 [8000/30711 (26%)]\tLoss: 0.549166\n",
      "Train Epoch: 2 [9000/30711 (29%)]\tLoss: 0.601583\n",
      "Train Epoch: 2 [10000/30711 (32%)]\tLoss: 0.572759\n",
      "Train Epoch: 2 [11000/30711 (36%)]\tLoss: 0.531616\n",
      "Train Epoch: 2 [12000/30711 (39%)]\tLoss: 0.629302\n",
      "Train Epoch: 2 [13000/30711 (42%)]\tLoss: 0.522301\n",
      "Train Epoch: 2 [14000/30711 (45%)]\tLoss: 0.532059\n",
      "Train Epoch: 2 [15000/30711 (49%)]\tLoss: 0.424055\n",
      "Train Epoch: 2 [16000/30711 (52%)]\tLoss: 0.529909\n",
      "Train Epoch: 2 [17000/30711 (55%)]\tLoss: 0.523990\n",
      "Train Epoch: 2 [18000/30711 (58%)]\tLoss: 0.519246\n",
      "Train Epoch: 2 [19000/30711 (62%)]\tLoss: 0.591140\n",
      "Train Epoch: 2 [20000/30711 (65%)]\tLoss: 0.595921\n",
      "Train Epoch: 2 [21000/30711 (68%)]\tLoss: 0.463226\n",
      "Train Epoch: 2 [22000/30711 (71%)]\tLoss: 0.416468\n",
      "Train Epoch: 2 [23000/30711 (75%)]\tLoss: 0.529711\n",
      "Train Epoch: 2 [24000/30711 (78%)]\tLoss: 0.472585\n",
      "Train Epoch: 2 [25000/30711 (81%)]\tLoss: 0.466552\n",
      "Train Epoch: 2 [26000/30711 (84%)]\tLoss: 0.417262\n",
      "Train Epoch: 2 [27000/30711 (88%)]\tLoss: 0.422658\n",
      "Train Epoch: 2 [28000/30711 (91%)]\tLoss: 0.606880\n",
      "Train Epoch: 2 [29000/30711 (94%)]\tLoss: 0.509307\n",
      "Train Epoch: 2 [30000/30711 (97%)]\tLoss: 0.534331\n",
      "Train Epoch: 3 [0/30711 (0%)]\tLoss: 0.532242\n",
      "Train Epoch: 3 [1000/30711 (3%)]\tLoss: 0.442123\n",
      "Train Epoch: 3 [2000/30711 (6%)]\tLoss: 0.553578\n",
      "Train Epoch: 3 [3000/30711 (10%)]\tLoss: 0.671992\n",
      "Train Epoch: 3 [4000/30711 (13%)]\tLoss: 0.470780\n",
      "Train Epoch: 3 [5000/30711 (16%)]\tLoss: 0.525364\n",
      "Train Epoch: 3 [6000/30711 (19%)]\tLoss: 0.547590\n",
      "Train Epoch: 3 [7000/30711 (23%)]\tLoss: 0.404452\n",
      "Train Epoch: 3 [8000/30711 (26%)]\tLoss: 0.387284\n",
      "Train Epoch: 3 [9000/30711 (29%)]\tLoss: 0.407847\n",
      "Train Epoch: 3 [10000/30711 (32%)]\tLoss: 0.478647\n",
      "Train Epoch: 3 [11000/30711 (36%)]\tLoss: 0.450314\n",
      "Train Epoch: 3 [12000/30711 (39%)]\tLoss: 0.520586\n",
      "Train Epoch: 3 [13000/30711 (42%)]\tLoss: 0.429283\n",
      "Train Epoch: 3 [14000/30711 (45%)]\tLoss: 0.394361\n",
      "Train Epoch: 3 [15000/30711 (49%)]\tLoss: 0.328132\n",
      "Train Epoch: 3 [16000/30711 (52%)]\tLoss: 0.397397\n",
      "Train Epoch: 3 [17000/30711 (55%)]\tLoss: 0.440185\n",
      "Train Epoch: 3 [18000/30711 (58%)]\tLoss: 0.444111\n",
      "Train Epoch: 3 [19000/30711 (62%)]\tLoss: 0.441999\n",
      "Train Epoch: 3 [20000/30711 (65%)]\tLoss: 0.483587\n",
      "Train Epoch: 3 [21000/30711 (68%)]\tLoss: 0.469660\n",
      "Train Epoch: 3 [22000/30711 (71%)]\tLoss: 0.537818\n",
      "Train Epoch: 3 [23000/30711 (75%)]\tLoss: 0.640778\n",
      "Train Epoch: 3 [24000/30711 (78%)]\tLoss: 0.456424\n",
      "Train Epoch: 3 [25000/30711 (81%)]\tLoss: 0.468182\n",
      "Train Epoch: 3 [26000/30711 (84%)]\tLoss: 0.450548\n",
      "Train Epoch: 3 [27000/30711 (88%)]\tLoss: 0.655183\n",
      "Train Epoch: 3 [28000/30711 (91%)]\tLoss: 0.697003\n",
      "Train Epoch: 3 [29000/30711 (94%)]\tLoss: 0.742462\n",
      "Train Epoch: 3 [30000/30711 (97%)]\tLoss: 0.345032\n",
      "Train Epoch: 4 [0/30711 (0%)]\tLoss: 0.525352\n",
      "Train Epoch: 4 [1000/30711 (3%)]\tLoss: 0.559840\n",
      "Train Epoch: 4 [2000/30711 (6%)]\tLoss: 0.698821\n",
      "Train Epoch: 4 [3000/30711 (10%)]\tLoss: 0.328488\n",
      "Train Epoch: 4 [4000/30711 (13%)]\tLoss: 0.375589\n",
      "Train Epoch: 4 [5000/30711 (16%)]\tLoss: 0.623594\n",
      "Train Epoch: 4 [6000/30711 (19%)]\tLoss: 0.495700\n",
      "Train Epoch: 4 [7000/30711 (23%)]\tLoss: 0.401191\n",
      "Train Epoch: 4 [8000/30711 (26%)]\tLoss: 0.378972\n",
      "Train Epoch: 4 [9000/30711 (29%)]\tLoss: 0.513327\n",
      "Train Epoch: 4 [10000/30711 (32%)]\tLoss: 0.651960\n",
      "Train Epoch: 4 [11000/30711 (36%)]\tLoss: 0.532137\n",
      "Train Epoch: 4 [12000/30711 (39%)]\tLoss: 0.550512\n",
      "Train Epoch: 4 [13000/30711 (42%)]\tLoss: 0.528836\n",
      "Train Epoch: 4 [14000/30711 (45%)]\tLoss: 0.738630\n",
      "Train Epoch: 4 [15000/30711 (49%)]\tLoss: 0.483147\n",
      "Train Epoch: 4 [16000/30711 (52%)]\tLoss: 0.550379\n",
      "Train Epoch: 4 [17000/30711 (55%)]\tLoss: 0.482637\n",
      "Train Epoch: 4 [18000/30711 (58%)]\tLoss: 0.631136\n",
      "Train Epoch: 4 [19000/30711 (62%)]\tLoss: 0.414884\n",
      "Train Epoch: 4 [20000/30711 (65%)]\tLoss: 0.632309\n",
      "Train Epoch: 4 [21000/30711 (68%)]\tLoss: 0.446342\n",
      "Train Epoch: 4 [22000/30711 (71%)]\tLoss: 0.602344\n",
      "Train Epoch: 4 [23000/30711 (75%)]\tLoss: 0.414056\n",
      "Train Epoch: 4 [24000/30711 (78%)]\tLoss: 0.582850\n",
      "Train Epoch: 4 [25000/30711 (81%)]\tLoss: 0.444967\n",
      "Train Epoch: 4 [26000/30711 (84%)]\tLoss: 0.497736\n",
      "Train Epoch: 4 [27000/30711 (88%)]\tLoss: 0.485827\n",
      "Train Epoch: 4 [28000/30711 (91%)]\tLoss: 0.557863\n",
      "Train Epoch: 4 [29000/30711 (94%)]\tLoss: 0.598901\n",
      "Train Epoch: 4 [30000/30711 (97%)]\tLoss: 0.395563\n",
      "Train Epoch: 5 [0/30711 (0%)]\tLoss: 0.506560\n",
      "Train Epoch: 5 [1000/30711 (3%)]\tLoss: 0.267777\n",
      "Train Epoch: 5 [2000/30711 (6%)]\tLoss: 0.471374\n",
      "Train Epoch: 5 [3000/30711 (10%)]\tLoss: 0.461841\n",
      "Train Epoch: 5 [4000/30711 (13%)]\tLoss: 0.475681\n",
      "Train Epoch: 5 [5000/30711 (16%)]\tLoss: 0.510035\n",
      "Train Epoch: 5 [6000/30711 (19%)]\tLoss: 0.501704\n",
      "Train Epoch: 5 [7000/30711 (23%)]\tLoss: 0.344332\n",
      "Train Epoch: 5 [8000/30711 (26%)]\tLoss: 0.446451\n",
      "Train Epoch: 5 [9000/30711 (29%)]\tLoss: 0.426257\n",
      "Train Epoch: 5 [10000/30711 (32%)]\tLoss: 0.379819\n",
      "Train Epoch: 5 [11000/30711 (36%)]\tLoss: 0.411799\n",
      "Train Epoch: 5 [12000/30711 (39%)]\tLoss: 0.524145\n",
      "Train Epoch: 5 [13000/30711 (42%)]\tLoss: 0.553468\n",
      "Train Epoch: 5 [14000/30711 (45%)]\tLoss: 0.526952\n",
      "Train Epoch: 5 [15000/30711 (49%)]\tLoss: 0.650926\n",
      "Train Epoch: 5 [16000/30711 (52%)]\tLoss: 0.588739\n",
      "Train Epoch: 5 [17000/30711 (55%)]\tLoss: 0.537283\n",
      "Train Epoch: 5 [18000/30711 (58%)]\tLoss: 0.431854\n",
      "Train Epoch: 5 [19000/30711 (62%)]\tLoss: 0.549119\n",
      "Train Epoch: 5 [20000/30711 (65%)]\tLoss: 0.535871\n",
      "Train Epoch: 5 [21000/30711 (68%)]\tLoss: 0.479543\n",
      "Train Epoch: 5 [22000/30711 (71%)]\tLoss: 0.472738\n",
      "Train Epoch: 5 [23000/30711 (75%)]\tLoss: 0.437286\n",
      "Train Epoch: 5 [24000/30711 (78%)]\tLoss: 0.415813\n",
      "Train Epoch: 5 [25000/30711 (81%)]\tLoss: 0.542865\n",
      "Train Epoch: 5 [26000/30711 (84%)]\tLoss: 0.467971\n",
      "Train Epoch: 5 [27000/30711 (88%)]\tLoss: 0.417468\n",
      "Train Epoch: 5 [28000/30711 (91%)]\tLoss: 0.309594\n",
      "Train Epoch: 5 [29000/30711 (94%)]\tLoss: 0.574342\n",
      "Train Epoch: 5 [30000/30711 (97%)]\tLoss: 0.441368\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/29289 (0%)]\tLoss: 0.528504\n",
      "Train Epoch: 1 [1000/29289 (3%)]\tLoss: 0.687496\n",
      "Train Epoch: 1 [2000/29289 (7%)]\tLoss: 0.447570\n",
      "Train Epoch: 1 [3000/29289 (10%)]\tLoss: 0.497791\n",
      "Train Epoch: 1 [4000/29289 (14%)]\tLoss: 0.512417\n",
      "Train Epoch: 1 [5000/29289 (17%)]\tLoss: 0.547215\n",
      "Train Epoch: 1 [6000/29289 (20%)]\tLoss: 0.496143\n",
      "Train Epoch: 1 [7000/29289 (24%)]\tLoss: 0.474299\n",
      "Train Epoch: 1 [8000/29289 (27%)]\tLoss: 0.545153\n",
      "Train Epoch: 1 [9000/29289 (31%)]\tLoss: 0.532829\n",
      "Train Epoch: 1 [10000/29289 (34%)]\tLoss: 0.616955\n",
      "Train Epoch: 1 [11000/29289 (38%)]\tLoss: 0.517865\n",
      "Train Epoch: 1 [12000/29289 (41%)]\tLoss: 0.495630\n",
      "Train Epoch: 1 [13000/29289 (44%)]\tLoss: 0.475993\n",
      "Train Epoch: 1 [14000/29289 (48%)]\tLoss: 0.627276\n",
      "Train Epoch: 1 [15000/29289 (51%)]\tLoss: 0.417037\n",
      "Train Epoch: 1 [16000/29289 (55%)]\tLoss: 0.470261\n",
      "Train Epoch: 1 [17000/29289 (58%)]\tLoss: 0.466605\n",
      "Train Epoch: 1 [18000/29289 (61%)]\tLoss: 0.493717\n",
      "Train Epoch: 1 [19000/29289 (65%)]\tLoss: 0.594226\n",
      "Train Epoch: 1 [20000/29289 (68%)]\tLoss: 0.511846\n",
      "Train Epoch: 1 [21000/29289 (72%)]\tLoss: 0.509478\n",
      "Train Epoch: 1 [22000/29289 (75%)]\tLoss: 0.460697\n",
      "Train Epoch: 1 [23000/29289 (78%)]\tLoss: 0.506281\n",
      "Train Epoch: 1 [24000/29289 (82%)]\tLoss: 0.455598\n",
      "Train Epoch: 1 [25000/29289 (85%)]\tLoss: 0.513475\n",
      "Train Epoch: 1 [26000/29289 (89%)]\tLoss: 0.535022\n",
      "Train Epoch: 1 [27000/29289 (92%)]\tLoss: 0.481352\n",
      "Train Epoch: 1 [28000/29289 (96%)]\tLoss: 0.535673\n",
      "Train Epoch: 1 [29000/29289 (99%)]\tLoss: 0.543934\n",
      "Train Epoch: 2 [0/29289 (0%)]\tLoss: 0.527584\n",
      "Train Epoch: 2 [1000/29289 (3%)]\tLoss: 0.391246\n",
      "Train Epoch: 2 [2000/29289 (7%)]\tLoss: 0.420332\n",
      "Train Epoch: 2 [3000/29289 (10%)]\tLoss: 0.482030\n",
      "Train Epoch: 2 [4000/29289 (14%)]\tLoss: 0.591035\n",
      "Train Epoch: 2 [5000/29289 (17%)]\tLoss: 0.482811\n",
      "Train Epoch: 2 [6000/29289 (20%)]\tLoss: 0.580618\n",
      "Train Epoch: 2 [7000/29289 (24%)]\tLoss: 0.648384\n",
      "Train Epoch: 2 [8000/29289 (27%)]\tLoss: 0.468126\n",
      "Train Epoch: 2 [9000/29289 (31%)]\tLoss: 0.453458\n",
      "Train Epoch: 2 [10000/29289 (34%)]\tLoss: 0.502832\n",
      "Train Epoch: 2 [11000/29289 (38%)]\tLoss: 0.484692\n",
      "Train Epoch: 2 [12000/29289 (41%)]\tLoss: 0.521600\n",
      "Train Epoch: 2 [13000/29289 (44%)]\tLoss: 0.457186\n",
      "Train Epoch: 2 [14000/29289 (48%)]\tLoss: 0.353305\n",
      "Train Epoch: 2 [15000/29289 (51%)]\tLoss: 0.554492\n",
      "Train Epoch: 2 [16000/29289 (55%)]\tLoss: 0.414305\n",
      "Train Epoch: 2 [17000/29289 (58%)]\tLoss: 0.502754\n",
      "Train Epoch: 2 [18000/29289 (61%)]\tLoss: 0.559684\n",
      "Train Epoch: 2 [19000/29289 (65%)]\tLoss: 0.542652\n",
      "Train Epoch: 2 [20000/29289 (68%)]\tLoss: 0.316858\n",
      "Train Epoch: 2 [21000/29289 (72%)]\tLoss: 0.562038\n",
      "Train Epoch: 2 [22000/29289 (75%)]\tLoss: 0.476776\n",
      "Train Epoch: 2 [23000/29289 (78%)]\tLoss: 0.511871\n",
      "Train Epoch: 2 [24000/29289 (82%)]\tLoss: 0.236191\n",
      "Train Epoch: 2 [25000/29289 (85%)]\tLoss: 0.603327\n",
      "Train Epoch: 2 [26000/29289 (89%)]\tLoss: 0.561340\n",
      "Train Epoch: 2 [27000/29289 (92%)]\tLoss: 0.607133\n",
      "Train Epoch: 2 [28000/29289 (96%)]\tLoss: 0.576661\n",
      "Train Epoch: 2 [29000/29289 (99%)]\tLoss: 0.493039\n",
      "Train Epoch: 3 [0/29289 (0%)]\tLoss: 0.590379\n",
      "Train Epoch: 3 [1000/29289 (3%)]\tLoss: 0.492522\n",
      "Train Epoch: 3 [2000/29289 (7%)]\tLoss: 0.498870\n",
      "Train Epoch: 3 [3000/29289 (10%)]\tLoss: 0.490733\n",
      "Train Epoch: 3 [4000/29289 (14%)]\tLoss: 0.522113\n",
      "Train Epoch: 3 [5000/29289 (17%)]\tLoss: 0.405180\n",
      "Train Epoch: 3 [6000/29289 (20%)]\tLoss: 0.378836\n",
      "Train Epoch: 3 [7000/29289 (24%)]\tLoss: 0.392435\n",
      "Train Epoch: 3 [8000/29289 (27%)]\tLoss: 0.514697\n",
      "Train Epoch: 3 [9000/29289 (31%)]\tLoss: 0.528817\n",
      "Train Epoch: 3 [10000/29289 (34%)]\tLoss: 0.377763\n",
      "Train Epoch: 3 [11000/29289 (38%)]\tLoss: 0.551248\n",
      "Train Epoch: 3 [12000/29289 (41%)]\tLoss: 0.491015\n",
      "Train Epoch: 3 [13000/29289 (44%)]\tLoss: 0.502404\n",
      "Train Epoch: 3 [14000/29289 (48%)]\tLoss: 0.678936\n",
      "Train Epoch: 3 [15000/29289 (51%)]\tLoss: 0.623831\n",
      "Train Epoch: 3 [16000/29289 (55%)]\tLoss: 0.562284\n",
      "Train Epoch: 3 [17000/29289 (58%)]\tLoss: 0.357845\n",
      "Train Epoch: 3 [18000/29289 (61%)]\tLoss: 0.408015\n",
      "Train Epoch: 3 [19000/29289 (65%)]\tLoss: 0.469043\n",
      "Train Epoch: 3 [20000/29289 (68%)]\tLoss: 0.424018\n",
      "Train Epoch: 3 [21000/29289 (72%)]\tLoss: 0.533891\n",
      "Train Epoch: 3 [22000/29289 (75%)]\tLoss: 0.347341\n",
      "Train Epoch: 3 [23000/29289 (78%)]\tLoss: 0.365462\n",
      "Train Epoch: 3 [24000/29289 (82%)]\tLoss: 0.403592\n",
      "Train Epoch: 3 [25000/29289 (85%)]\tLoss: 0.578781\n",
      "Train Epoch: 3 [26000/29289 (89%)]\tLoss: 0.446053\n",
      "Train Epoch: 3 [27000/29289 (92%)]\tLoss: 0.339793\n",
      "Train Epoch: 3 [28000/29289 (96%)]\tLoss: 0.447254\n",
      "Train Epoch: 3 [29000/29289 (99%)]\tLoss: 0.418326\n",
      "Train Epoch: 4 [0/29289 (0%)]\tLoss: 0.366515\n",
      "Train Epoch: 4 [1000/29289 (3%)]\tLoss: 0.542478\n",
      "Train Epoch: 4 [2000/29289 (7%)]\tLoss: 0.368942\n",
      "Train Epoch: 4 [3000/29289 (10%)]\tLoss: 0.443955\n",
      "Train Epoch: 4 [4000/29289 (14%)]\tLoss: 0.528484\n",
      "Train Epoch: 4 [5000/29289 (17%)]\tLoss: 0.473562\n",
      "Train Epoch: 4 [6000/29289 (20%)]\tLoss: 0.582621\n",
      "Train Epoch: 4 [7000/29289 (24%)]\tLoss: 0.414918\n",
      "Train Epoch: 4 [8000/29289 (27%)]\tLoss: 0.618722\n",
      "Train Epoch: 4 [9000/29289 (31%)]\tLoss: 0.451703\n",
      "Train Epoch: 4 [10000/29289 (34%)]\tLoss: 0.391321\n",
      "Train Epoch: 4 [11000/29289 (38%)]\tLoss: 0.360182\n",
      "Train Epoch: 4 [12000/29289 (41%)]\tLoss: 0.547401\n",
      "Train Epoch: 4 [13000/29289 (44%)]\tLoss: 0.328097\n",
      "Train Epoch: 4 [14000/29289 (48%)]\tLoss: 0.576679\n",
      "Train Epoch: 4 [15000/29289 (51%)]\tLoss: 0.532163\n",
      "Train Epoch: 4 [16000/29289 (55%)]\tLoss: 0.517956\n",
      "Train Epoch: 4 [17000/29289 (58%)]\tLoss: 0.500694\n",
      "Train Epoch: 4 [18000/29289 (61%)]\tLoss: 0.342536\n",
      "Train Epoch: 4 [19000/29289 (65%)]\tLoss: 0.328953\n",
      "Train Epoch: 4 [20000/29289 (68%)]\tLoss: 0.483330\n",
      "Train Epoch: 4 [21000/29289 (72%)]\tLoss: 0.458942\n",
      "Train Epoch: 4 [22000/29289 (75%)]\tLoss: 0.421811\n",
      "Train Epoch: 4 [23000/29289 (78%)]\tLoss: 0.494847\n",
      "Train Epoch: 4 [24000/29289 (82%)]\tLoss: 0.592403\n",
      "Train Epoch: 4 [25000/29289 (85%)]\tLoss: 0.608418\n",
      "Train Epoch: 4 [26000/29289 (89%)]\tLoss: 0.469828\n",
      "Train Epoch: 4 [27000/29289 (92%)]\tLoss: 0.598291\n",
      "Train Epoch: 4 [28000/29289 (96%)]\tLoss: 0.363888\n",
      "Train Epoch: 4 [29000/29289 (99%)]\tLoss: 0.525717\n",
      "Train Epoch: 5 [0/29289 (0%)]\tLoss: 0.674176\n",
      "Train Epoch: 5 [1000/29289 (3%)]\tLoss: 0.498446\n",
      "Train Epoch: 5 [2000/29289 (7%)]\tLoss: 0.542840\n",
      "Train Epoch: 5 [3000/29289 (10%)]\tLoss: 0.284795\n",
      "Train Epoch: 5 [4000/29289 (14%)]\tLoss: 0.497915\n",
      "Train Epoch: 5 [5000/29289 (17%)]\tLoss: 0.528704\n",
      "Train Epoch: 5 [6000/29289 (20%)]\tLoss: 0.482844\n",
      "Train Epoch: 5 [7000/29289 (24%)]\tLoss: 0.623605\n",
      "Train Epoch: 5 [8000/29289 (27%)]\tLoss: 0.337185\n",
      "Train Epoch: 5 [9000/29289 (31%)]\tLoss: 0.531003\n",
      "Train Epoch: 5 [10000/29289 (34%)]\tLoss: 0.425050\n",
      "Train Epoch: 5 [11000/29289 (38%)]\tLoss: 0.587969\n",
      "Train Epoch: 5 [12000/29289 (41%)]\tLoss: 0.339206\n",
      "Train Epoch: 5 [13000/29289 (44%)]\tLoss: 0.364671\n",
      "Train Epoch: 5 [14000/29289 (48%)]\tLoss: 0.537952\n",
      "Train Epoch: 5 [15000/29289 (51%)]\tLoss: 0.377545\n",
      "Train Epoch: 5 [16000/29289 (55%)]\tLoss: 0.438320\n",
      "Train Epoch: 5 [17000/29289 (58%)]\tLoss: 0.536240\n",
      "Train Epoch: 5 [18000/29289 (61%)]\tLoss: 0.517056\n",
      "Train Epoch: 5 [19000/29289 (65%)]\tLoss: 0.475873\n",
      "Train Epoch: 5 [20000/29289 (68%)]\tLoss: 0.475449\n",
      "Train Epoch: 5 [21000/29289 (72%)]\tLoss: 0.507472\n",
      "Train Epoch: 5 [22000/29289 (75%)]\tLoss: 0.481970\n",
      "Train Epoch: 5 [23000/29289 (78%)]\tLoss: 0.457037\n",
      "Train Epoch: 5 [24000/29289 (82%)]\tLoss: 0.489542\n",
      "Train Epoch: 5 [25000/29289 (85%)]\tLoss: 0.529770\n",
      "Train Epoch: 5 [26000/29289 (89%)]\tLoss: 0.390103\n",
      "Train Epoch: 5 [27000/29289 (92%)]\tLoss: 0.450475\n",
      "Train Epoch: 5 [28000/29289 (96%)]\tLoss: 0.444713\n",
      "Train Epoch: 5 [29000/29289 (99%)]\tLoss: 0.312243\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8803, Accuracy: 7495/10000 (75%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/30711 (0%)]\tLoss: 0.654307\n",
      "Train Epoch: 1 [1000/30711 (3%)]\tLoss: 0.485181\n",
      "Train Epoch: 1 [2000/30711 (6%)]\tLoss: 0.587664\n",
      "Train Epoch: 1 [3000/30711 (10%)]\tLoss: 0.422079\n",
      "Train Epoch: 1 [4000/30711 (13%)]\tLoss: 0.362497\n",
      "Train Epoch: 1 [5000/30711 (16%)]\tLoss: 0.527563\n",
      "Train Epoch: 1 [6000/30711 (19%)]\tLoss: 0.571904\n",
      "Train Epoch: 1 [7000/30711 (23%)]\tLoss: 0.597856\n",
      "Train Epoch: 1 [8000/30711 (26%)]\tLoss: 0.501920\n",
      "Train Epoch: 1 [9000/30711 (29%)]\tLoss: 0.599994\n",
      "Train Epoch: 1 [10000/30711 (32%)]\tLoss: 0.387835\n",
      "Train Epoch: 1 [11000/30711 (36%)]\tLoss: 0.509891\n",
      "Train Epoch: 1 [12000/30711 (39%)]\tLoss: 0.494541\n",
      "Train Epoch: 1 [13000/30711 (42%)]\tLoss: 0.399152\n",
      "Train Epoch: 1 [14000/30711 (45%)]\tLoss: 0.442381\n",
      "Train Epoch: 1 [15000/30711 (49%)]\tLoss: 0.506708\n",
      "Train Epoch: 1 [16000/30711 (52%)]\tLoss: 0.430165\n",
      "Train Epoch: 1 [17000/30711 (55%)]\tLoss: 0.428453\n",
      "Train Epoch: 1 [18000/30711 (58%)]\tLoss: 0.502812\n",
      "Train Epoch: 1 [19000/30711 (62%)]\tLoss: 0.433152\n",
      "Train Epoch: 1 [20000/30711 (65%)]\tLoss: 0.520240\n",
      "Train Epoch: 1 [21000/30711 (68%)]\tLoss: 0.483962\n",
      "Train Epoch: 1 [22000/30711 (71%)]\tLoss: 0.568732\n",
      "Train Epoch: 1 [23000/30711 (75%)]\tLoss: 0.500639\n",
      "Train Epoch: 1 [24000/30711 (78%)]\tLoss: 0.495265\n",
      "Train Epoch: 1 [25000/30711 (81%)]\tLoss: 0.508488\n",
      "Train Epoch: 1 [26000/30711 (84%)]\tLoss: 0.569553\n",
      "Train Epoch: 1 [27000/30711 (88%)]\tLoss: 0.460127\n",
      "Train Epoch: 1 [28000/30711 (91%)]\tLoss: 0.642951\n",
      "Train Epoch: 1 [29000/30711 (94%)]\tLoss: 0.633729\n",
      "Train Epoch: 1 [30000/30711 (97%)]\tLoss: 0.458426\n",
      "Train Epoch: 2 [0/30711 (0%)]\tLoss: 0.433158\n",
      "Train Epoch: 2 [1000/30711 (3%)]\tLoss: 0.456441\n",
      "Train Epoch: 2 [2000/30711 (6%)]\tLoss: 0.526048\n",
      "Train Epoch: 2 [3000/30711 (10%)]\tLoss: 0.494254\n",
      "Train Epoch: 2 [4000/30711 (13%)]\tLoss: 0.400829\n",
      "Train Epoch: 2 [5000/30711 (16%)]\tLoss: 0.332292\n",
      "Train Epoch: 2 [6000/30711 (19%)]\tLoss: 0.407474\n",
      "Train Epoch: 2 [7000/30711 (23%)]\tLoss: 0.345786\n",
      "Train Epoch: 2 [8000/30711 (26%)]\tLoss: 0.412794\n",
      "Train Epoch: 2 [9000/30711 (29%)]\tLoss: 0.573050\n",
      "Train Epoch: 2 [10000/30711 (32%)]\tLoss: 0.323191\n",
      "Train Epoch: 2 [11000/30711 (36%)]\tLoss: 0.535063\n",
      "Train Epoch: 2 [12000/30711 (39%)]\tLoss: 0.656503\n",
      "Train Epoch: 2 [13000/30711 (42%)]\tLoss: 0.601625\n",
      "Train Epoch: 2 [14000/30711 (45%)]\tLoss: 0.567031\n",
      "Train Epoch: 2 [15000/30711 (49%)]\tLoss: 0.557515\n",
      "Train Epoch: 2 [16000/30711 (52%)]\tLoss: 0.401389\n",
      "Train Epoch: 2 [17000/30711 (55%)]\tLoss: 0.492322\n",
      "Train Epoch: 2 [18000/30711 (58%)]\tLoss: 0.542190\n",
      "Train Epoch: 2 [19000/30711 (62%)]\tLoss: 0.562265\n",
      "Train Epoch: 2 [20000/30711 (65%)]\tLoss: 0.392717\n",
      "Train Epoch: 2 [21000/30711 (68%)]\tLoss: 0.523915\n",
      "Train Epoch: 2 [22000/30711 (71%)]\tLoss: 0.378025\n",
      "Train Epoch: 2 [23000/30711 (75%)]\tLoss: 0.467755\n",
      "Train Epoch: 2 [24000/30711 (78%)]\tLoss: 0.505221\n",
      "Train Epoch: 2 [25000/30711 (81%)]\tLoss: 0.645777\n",
      "Train Epoch: 2 [26000/30711 (84%)]\tLoss: 0.515714\n",
      "Train Epoch: 2 [27000/30711 (88%)]\tLoss: 0.616748\n",
      "Train Epoch: 2 [28000/30711 (91%)]\tLoss: 0.469674\n",
      "Train Epoch: 2 [29000/30711 (94%)]\tLoss: 0.404113\n",
      "Train Epoch: 2 [30000/30711 (97%)]\tLoss: 0.524157\n",
      "Train Epoch: 3 [0/30711 (0%)]\tLoss: 0.376734\n",
      "Train Epoch: 3 [1000/30711 (3%)]\tLoss: 0.558671\n",
      "Train Epoch: 3 [2000/30711 (6%)]\tLoss: 0.407988\n",
      "Train Epoch: 3 [3000/30711 (10%)]\tLoss: 0.413418\n",
      "Train Epoch: 3 [4000/30711 (13%)]\tLoss: 0.506144\n",
      "Train Epoch: 3 [5000/30711 (16%)]\tLoss: 0.514737\n",
      "Train Epoch: 3 [6000/30711 (19%)]\tLoss: 0.452095\n",
      "Train Epoch: 3 [7000/30711 (23%)]\tLoss: 0.367620\n",
      "Train Epoch: 3 [8000/30711 (26%)]\tLoss: 0.670071\n",
      "Train Epoch: 3 [9000/30711 (29%)]\tLoss: 0.494440\n",
      "Train Epoch: 3 [10000/30711 (32%)]\tLoss: 0.388263\n",
      "Train Epoch: 3 [11000/30711 (36%)]\tLoss: 0.469953\n",
      "Train Epoch: 3 [12000/30711 (39%)]\tLoss: 0.502502\n",
      "Train Epoch: 3 [13000/30711 (42%)]\tLoss: 0.403874\n",
      "Train Epoch: 3 [14000/30711 (45%)]\tLoss: 0.545425\n",
      "Train Epoch: 3 [15000/30711 (49%)]\tLoss: 0.434873\n",
      "Train Epoch: 3 [16000/30711 (52%)]\tLoss: 0.306037\n",
      "Train Epoch: 3 [17000/30711 (55%)]\tLoss: 0.550099\n",
      "Train Epoch: 3 [18000/30711 (58%)]\tLoss: 0.443272\n",
      "Train Epoch: 3 [19000/30711 (62%)]\tLoss: 0.504022\n",
      "Train Epoch: 3 [20000/30711 (65%)]\tLoss: 0.484617\n",
      "Train Epoch: 3 [21000/30711 (68%)]\tLoss: 0.516458\n",
      "Train Epoch: 3 [22000/30711 (71%)]\tLoss: 0.582447\n",
      "Train Epoch: 3 [23000/30711 (75%)]\tLoss: 0.653224\n",
      "Train Epoch: 3 [24000/30711 (78%)]\tLoss: 0.474858\n",
      "Train Epoch: 3 [25000/30711 (81%)]\tLoss: 0.550230\n",
      "Train Epoch: 3 [26000/30711 (84%)]\tLoss: 0.629316\n",
      "Train Epoch: 3 [27000/30711 (88%)]\tLoss: 0.365238\n",
      "Train Epoch: 3 [28000/30711 (91%)]\tLoss: 0.456399\n",
      "Train Epoch: 3 [29000/30711 (94%)]\tLoss: 0.549371\n",
      "Train Epoch: 3 [30000/30711 (97%)]\tLoss: 0.516548\n",
      "Train Epoch: 4 [0/30711 (0%)]\tLoss: 0.519261\n",
      "Train Epoch: 4 [1000/30711 (3%)]\tLoss: 0.658085\n",
      "Train Epoch: 4 [2000/30711 (6%)]\tLoss: 0.566164\n",
      "Train Epoch: 4 [3000/30711 (10%)]\tLoss: 0.289141\n",
      "Train Epoch: 4 [4000/30711 (13%)]\tLoss: 0.350232\n",
      "Train Epoch: 4 [5000/30711 (16%)]\tLoss: 0.534800\n",
      "Train Epoch: 4 [6000/30711 (19%)]\tLoss: 0.515863\n",
      "Train Epoch: 4 [7000/30711 (23%)]\tLoss: 0.366847\n",
      "Train Epoch: 4 [8000/30711 (26%)]\tLoss: 0.567901\n",
      "Train Epoch: 4 [9000/30711 (29%)]\tLoss: 0.455331\n",
      "Train Epoch: 4 [10000/30711 (32%)]\tLoss: 0.562412\n",
      "Train Epoch: 4 [11000/30711 (36%)]\tLoss: 0.431004\n",
      "Train Epoch: 4 [12000/30711 (39%)]\tLoss: 0.463086\n",
      "Train Epoch: 4 [13000/30711 (42%)]\tLoss: 0.350140\n",
      "Train Epoch: 4 [14000/30711 (45%)]\tLoss: 0.432568\n",
      "Train Epoch: 4 [15000/30711 (49%)]\tLoss: 0.391737\n",
      "Train Epoch: 4 [16000/30711 (52%)]\tLoss: 0.553557\n",
      "Train Epoch: 4 [17000/30711 (55%)]\tLoss: 0.551744\n",
      "Train Epoch: 4 [18000/30711 (58%)]\tLoss: 0.402792\n",
      "Train Epoch: 4 [19000/30711 (62%)]\tLoss: 0.465216\n",
      "Train Epoch: 4 [20000/30711 (65%)]\tLoss: 0.426477\n",
      "Train Epoch: 4 [21000/30711 (68%)]\tLoss: 0.377619\n",
      "Train Epoch: 4 [22000/30711 (71%)]\tLoss: 0.418214\n",
      "Train Epoch: 4 [23000/30711 (75%)]\tLoss: 0.464318\n",
      "Train Epoch: 4 [24000/30711 (78%)]\tLoss: 0.625049\n",
      "Train Epoch: 4 [25000/30711 (81%)]\tLoss: 0.500507\n",
      "Train Epoch: 4 [26000/30711 (84%)]\tLoss: 0.397266\n",
      "Train Epoch: 4 [27000/30711 (88%)]\tLoss: 0.371152\n",
      "Train Epoch: 4 [28000/30711 (91%)]\tLoss: 0.347490\n",
      "Train Epoch: 4 [29000/30711 (94%)]\tLoss: 0.437694\n",
      "Train Epoch: 4 [30000/30711 (97%)]\tLoss: 0.397059\n",
      "Train Epoch: 5 [0/30711 (0%)]\tLoss: 0.469080\n",
      "Train Epoch: 5 [1000/30711 (3%)]\tLoss: 0.580705\n",
      "Train Epoch: 5 [2000/30711 (6%)]\tLoss: 0.438045\n",
      "Train Epoch: 5 [3000/30711 (10%)]\tLoss: 0.517012\n",
      "Train Epoch: 5 [4000/30711 (13%)]\tLoss: 0.442328\n",
      "Train Epoch: 5 [5000/30711 (16%)]\tLoss: 0.560201\n",
      "Train Epoch: 5 [6000/30711 (19%)]\tLoss: 0.477507\n",
      "Train Epoch: 5 [7000/30711 (23%)]\tLoss: 0.252605\n",
      "Train Epoch: 5 [8000/30711 (26%)]\tLoss: 0.500868\n",
      "Train Epoch: 5 [9000/30711 (29%)]\tLoss: 0.601553\n",
      "Train Epoch: 5 [10000/30711 (32%)]\tLoss: 0.656779\n",
      "Train Epoch: 5 [11000/30711 (36%)]\tLoss: 0.434289\n",
      "Train Epoch: 5 [12000/30711 (39%)]\tLoss: 0.386808\n",
      "Train Epoch: 5 [13000/30711 (42%)]\tLoss: 0.576783\n",
      "Train Epoch: 5 [14000/30711 (45%)]\tLoss: 0.560095\n",
      "Train Epoch: 5 [15000/30711 (49%)]\tLoss: 0.444150\n",
      "Train Epoch: 5 [16000/30711 (52%)]\tLoss: 0.393765\n",
      "Train Epoch: 5 [17000/30711 (55%)]\tLoss: 0.477093\n",
      "Train Epoch: 5 [18000/30711 (58%)]\tLoss: 0.430672\n",
      "Train Epoch: 5 [19000/30711 (62%)]\tLoss: 0.449644\n",
      "Train Epoch: 5 [20000/30711 (65%)]\tLoss: 0.517743\n",
      "Train Epoch: 5 [21000/30711 (68%)]\tLoss: 0.590552\n",
      "Train Epoch: 5 [22000/30711 (71%)]\tLoss: 0.544644\n",
      "Train Epoch: 5 [23000/30711 (75%)]\tLoss: 0.422543\n",
      "Train Epoch: 5 [24000/30711 (78%)]\tLoss: 0.505656\n",
      "Train Epoch: 5 [25000/30711 (81%)]\tLoss: 0.436139\n",
      "Train Epoch: 5 [26000/30711 (84%)]\tLoss: 0.353540\n",
      "Train Epoch: 5 [27000/30711 (88%)]\tLoss: 0.508117\n",
      "Train Epoch: 5 [28000/30711 (91%)]\tLoss: 0.358190\n",
      "Train Epoch: 5 [29000/30711 (94%)]\tLoss: 0.477060\n",
      "Train Epoch: 5 [30000/30711 (97%)]\tLoss: 0.356183\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/29289 (0%)]\tLoss: 0.440848\n",
      "Train Epoch: 1 [1000/29289 (3%)]\tLoss: 0.474508\n",
      "Train Epoch: 1 [2000/29289 (7%)]\tLoss: 0.467805\n",
      "Train Epoch: 1 [3000/29289 (10%)]\tLoss: 0.441927\n",
      "Train Epoch: 1 [4000/29289 (14%)]\tLoss: 0.555143\n",
      "Train Epoch: 1 [5000/29289 (17%)]\tLoss: 0.454249\n",
      "Train Epoch: 1 [6000/29289 (20%)]\tLoss: 0.506409\n",
      "Train Epoch: 1 [7000/29289 (24%)]\tLoss: 0.557435\n",
      "Train Epoch: 1 [8000/29289 (27%)]\tLoss: 0.428605\n",
      "Train Epoch: 1 [9000/29289 (31%)]\tLoss: 0.641120\n",
      "Train Epoch: 1 [10000/29289 (34%)]\tLoss: 0.477538\n",
      "Train Epoch: 1 [11000/29289 (38%)]\tLoss: 0.399305\n",
      "Train Epoch: 1 [12000/29289 (41%)]\tLoss: 0.499155\n",
      "Train Epoch: 1 [13000/29289 (44%)]\tLoss: 0.504321\n",
      "Train Epoch: 1 [14000/29289 (48%)]\tLoss: 0.561154\n",
      "Train Epoch: 1 [15000/29289 (51%)]\tLoss: 0.503799\n",
      "Train Epoch: 1 [16000/29289 (55%)]\tLoss: 0.463337\n",
      "Train Epoch: 1 [17000/29289 (58%)]\tLoss: 0.386040\n",
      "Train Epoch: 1 [18000/29289 (61%)]\tLoss: 0.582125\n",
      "Train Epoch: 1 [19000/29289 (65%)]\tLoss: 0.427772\n",
      "Train Epoch: 1 [20000/29289 (68%)]\tLoss: 0.442539\n",
      "Train Epoch: 1 [21000/29289 (72%)]\tLoss: 0.423000\n",
      "Train Epoch: 1 [22000/29289 (75%)]\tLoss: 0.476400\n",
      "Train Epoch: 1 [23000/29289 (78%)]\tLoss: 0.574401\n",
      "Train Epoch: 1 [24000/29289 (82%)]\tLoss: 0.405517\n",
      "Train Epoch: 1 [25000/29289 (85%)]\tLoss: 0.406652\n",
      "Train Epoch: 1 [26000/29289 (89%)]\tLoss: 0.499191\n",
      "Train Epoch: 1 [27000/29289 (92%)]\tLoss: 0.364101\n",
      "Train Epoch: 1 [28000/29289 (96%)]\tLoss: 0.426306\n",
      "Train Epoch: 1 [29000/29289 (99%)]\tLoss: 0.315300\n",
      "Train Epoch: 2 [0/29289 (0%)]\tLoss: 0.727352\n",
      "Train Epoch: 2 [1000/29289 (3%)]\tLoss: 0.584179\n",
      "Train Epoch: 2 [2000/29289 (7%)]\tLoss: 0.413091\n",
      "Train Epoch: 2 [3000/29289 (10%)]\tLoss: 0.510372\n",
      "Train Epoch: 2 [4000/29289 (14%)]\tLoss: 0.292256\n",
      "Train Epoch: 2 [5000/29289 (17%)]\tLoss: 0.504034\n",
      "Train Epoch: 2 [6000/29289 (20%)]\tLoss: 0.392745\n",
      "Train Epoch: 2 [7000/29289 (24%)]\tLoss: 0.421120\n",
      "Train Epoch: 2 [8000/29289 (27%)]\tLoss: 0.362717\n",
      "Train Epoch: 2 [9000/29289 (31%)]\tLoss: 0.448527\n",
      "Train Epoch: 2 [10000/29289 (34%)]\tLoss: 0.435820\n",
      "Train Epoch: 2 [11000/29289 (38%)]\tLoss: 0.496085\n",
      "Train Epoch: 2 [12000/29289 (41%)]\tLoss: 0.415425\n",
      "Train Epoch: 2 [13000/29289 (44%)]\tLoss: 0.527371\n",
      "Train Epoch: 2 [14000/29289 (48%)]\tLoss: 0.442343\n",
      "Train Epoch: 2 [15000/29289 (51%)]\tLoss: 0.642731\n",
      "Train Epoch: 2 [16000/29289 (55%)]\tLoss: 0.410427\n",
      "Train Epoch: 2 [17000/29289 (58%)]\tLoss: 0.362869\n",
      "Train Epoch: 2 [18000/29289 (61%)]\tLoss: 0.350176\n",
      "Train Epoch: 2 [19000/29289 (65%)]\tLoss: 0.498973\n",
      "Train Epoch: 2 [20000/29289 (68%)]\tLoss: 0.470515\n",
      "Train Epoch: 2 [21000/29289 (72%)]\tLoss: 0.349070\n",
      "Train Epoch: 2 [22000/29289 (75%)]\tLoss: 0.485288\n",
      "Train Epoch: 2 [23000/29289 (78%)]\tLoss: 0.357994\n",
      "Train Epoch: 2 [24000/29289 (82%)]\tLoss: 0.381542\n",
      "Train Epoch: 2 [25000/29289 (85%)]\tLoss: 0.514081\n",
      "Train Epoch: 2 [26000/29289 (89%)]\tLoss: 0.511033\n",
      "Train Epoch: 2 [27000/29289 (92%)]\tLoss: 0.388042\n",
      "Train Epoch: 2 [28000/29289 (96%)]\tLoss: 0.445059\n",
      "Train Epoch: 2 [29000/29289 (99%)]\tLoss: 0.441548\n",
      "Train Epoch: 3 [0/29289 (0%)]\tLoss: 0.406524\n",
      "Train Epoch: 3 [1000/29289 (3%)]\tLoss: 0.474788\n",
      "Train Epoch: 3 [2000/29289 (7%)]\tLoss: 0.412427\n",
      "Train Epoch: 3 [3000/29289 (10%)]\tLoss: 0.399730\n",
      "Train Epoch: 3 [4000/29289 (14%)]\tLoss: 0.567017\n",
      "Train Epoch: 3 [5000/29289 (17%)]\tLoss: 0.289253\n",
      "Train Epoch: 3 [6000/29289 (20%)]\tLoss: 0.280041\n",
      "Train Epoch: 3 [7000/29289 (24%)]\tLoss: 0.365511\n",
      "Train Epoch: 3 [8000/29289 (27%)]\tLoss: 0.475954\n",
      "Train Epoch: 3 [9000/29289 (31%)]\tLoss: 0.686605\n",
      "Train Epoch: 3 [10000/29289 (34%)]\tLoss: 0.422584\n",
      "Train Epoch: 3 [11000/29289 (38%)]\tLoss: 0.428643\n",
      "Train Epoch: 3 [12000/29289 (41%)]\tLoss: 0.503160\n",
      "Train Epoch: 3 [13000/29289 (44%)]\tLoss: 0.290529\n",
      "Train Epoch: 3 [14000/29289 (48%)]\tLoss: 0.476121\n",
      "Train Epoch: 3 [15000/29289 (51%)]\tLoss: 0.355207\n",
      "Train Epoch: 3 [16000/29289 (55%)]\tLoss: 0.504672\n",
      "Train Epoch: 3 [17000/29289 (58%)]\tLoss: 0.443358\n",
      "Train Epoch: 3 [18000/29289 (61%)]\tLoss: 0.603651\n",
      "Train Epoch: 3 [19000/29289 (65%)]\tLoss: 0.337642\n",
      "Train Epoch: 3 [20000/29289 (68%)]\tLoss: 0.433118\n",
      "Train Epoch: 3 [21000/29289 (72%)]\tLoss: 0.494623\n",
      "Train Epoch: 3 [22000/29289 (75%)]\tLoss: 0.365563\n",
      "Train Epoch: 3 [23000/29289 (78%)]\tLoss: 0.495917\n",
      "Train Epoch: 3 [24000/29289 (82%)]\tLoss: 0.436378\n",
      "Train Epoch: 3 [25000/29289 (85%)]\tLoss: 0.417065\n",
      "Train Epoch: 3 [26000/29289 (89%)]\tLoss: 0.416430\n",
      "Train Epoch: 3 [27000/29289 (92%)]\tLoss: 0.406752\n",
      "Train Epoch: 3 [28000/29289 (96%)]\tLoss: 0.445825\n",
      "Train Epoch: 3 [29000/29289 (99%)]\tLoss: 0.501769\n",
      "Train Epoch: 4 [0/29289 (0%)]\tLoss: 0.460332\n",
      "Train Epoch: 4 [1000/29289 (3%)]\tLoss: 0.447930\n",
      "Train Epoch: 4 [2000/29289 (7%)]\tLoss: 0.539788\n",
      "Train Epoch: 4 [3000/29289 (10%)]\tLoss: 0.479877\n",
      "Train Epoch: 4 [4000/29289 (14%)]\tLoss: 0.470383\n",
      "Train Epoch: 4 [5000/29289 (17%)]\tLoss: 0.445549\n",
      "Train Epoch: 4 [6000/29289 (20%)]\tLoss: 0.377634\n",
      "Train Epoch: 4 [7000/29289 (24%)]\tLoss: 0.331414\n",
      "Train Epoch: 4 [8000/29289 (27%)]\tLoss: 0.530170\n",
      "Train Epoch: 4 [9000/29289 (31%)]\tLoss: 0.318314\n",
      "Train Epoch: 4 [10000/29289 (34%)]\tLoss: 0.487955\n",
      "Train Epoch: 4 [11000/29289 (38%)]\tLoss: 0.486696\n",
      "Train Epoch: 4 [12000/29289 (41%)]\tLoss: 0.573977\n",
      "Train Epoch: 4 [13000/29289 (44%)]\tLoss: 0.429584\n",
      "Train Epoch: 4 [14000/29289 (48%)]\tLoss: 0.403453\n",
      "Train Epoch: 4 [15000/29289 (51%)]\tLoss: 0.493212\n",
      "Train Epoch: 4 [16000/29289 (55%)]\tLoss: 0.589952\n",
      "Train Epoch: 4 [17000/29289 (58%)]\tLoss: 0.448052\n",
      "Train Epoch: 4 [18000/29289 (61%)]\tLoss: 0.389626\n",
      "Train Epoch: 4 [19000/29289 (65%)]\tLoss: 0.568278\n",
      "Train Epoch: 4 [20000/29289 (68%)]\tLoss: 0.465931\n",
      "Train Epoch: 4 [21000/29289 (72%)]\tLoss: 0.422010\n",
      "Train Epoch: 4 [22000/29289 (75%)]\tLoss: 0.524829\n",
      "Train Epoch: 4 [23000/29289 (78%)]\tLoss: 0.467265\n",
      "Train Epoch: 4 [24000/29289 (82%)]\tLoss: 0.588895\n",
      "Train Epoch: 4 [25000/29289 (85%)]\tLoss: 0.330547\n",
      "Train Epoch: 4 [26000/29289 (89%)]\tLoss: 0.495661\n",
      "Train Epoch: 4 [27000/29289 (92%)]\tLoss: 0.481694\n",
      "Train Epoch: 4 [28000/29289 (96%)]\tLoss: 0.351169\n",
      "Train Epoch: 4 [29000/29289 (99%)]\tLoss: 0.337767\n",
      "Train Epoch: 5 [0/29289 (0%)]\tLoss: 0.381981\n",
      "Train Epoch: 5 [1000/29289 (3%)]\tLoss: 0.506221\n",
      "Train Epoch: 5 [2000/29289 (7%)]\tLoss: 0.608143\n",
      "Train Epoch: 5 [3000/29289 (10%)]\tLoss: 0.357475\n",
      "Train Epoch: 5 [4000/29289 (14%)]\tLoss: 0.504626\n",
      "Train Epoch: 5 [5000/29289 (17%)]\tLoss: 0.275901\n",
      "Train Epoch: 5 [6000/29289 (20%)]\tLoss: 0.649685\n",
      "Train Epoch: 5 [7000/29289 (24%)]\tLoss: 0.317696\n",
      "Train Epoch: 5 [8000/29289 (27%)]\tLoss: 0.400316\n",
      "Train Epoch: 5 [9000/29289 (31%)]\tLoss: 0.443639\n",
      "Train Epoch: 5 [10000/29289 (34%)]\tLoss: 0.493441\n",
      "Train Epoch: 5 [11000/29289 (38%)]\tLoss: 0.309918\n",
      "Train Epoch: 5 [12000/29289 (41%)]\tLoss: 0.564813\n",
      "Train Epoch: 5 [13000/29289 (44%)]\tLoss: 0.395705\n",
      "Train Epoch: 5 [14000/29289 (48%)]\tLoss: 0.329032\n",
      "Train Epoch: 5 [15000/29289 (51%)]\tLoss: 0.424025\n",
      "Train Epoch: 5 [16000/29289 (55%)]\tLoss: 0.344670\n",
      "Train Epoch: 5 [17000/29289 (58%)]\tLoss: 0.441164\n",
      "Train Epoch: 5 [18000/29289 (61%)]\tLoss: 0.493513\n",
      "Train Epoch: 5 [19000/29289 (65%)]\tLoss: 0.462850\n",
      "Train Epoch: 5 [20000/29289 (68%)]\tLoss: 0.461510\n",
      "Train Epoch: 5 [21000/29289 (72%)]\tLoss: 0.346328\n",
      "Train Epoch: 5 [22000/29289 (75%)]\tLoss: 0.601932\n",
      "Train Epoch: 5 [23000/29289 (78%)]\tLoss: 0.640739\n",
      "Train Epoch: 5 [24000/29289 (82%)]\tLoss: 0.374963\n",
      "Train Epoch: 5 [25000/29289 (85%)]\tLoss: 0.398408\n",
      "Train Epoch: 5 [26000/29289 (89%)]\tLoss: 0.378142\n",
      "Train Epoch: 5 [27000/29289 (92%)]\tLoss: 0.384992\n",
      "Train Epoch: 5 [28000/29289 (96%)]\tLoss: 0.417987\n",
      "Train Epoch: 5 [29000/29289 (99%)]\tLoss: 0.557198\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8388, Accuracy: 7657/10000 (77%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/30711 (0%)]\tLoss: 0.564921\n",
      "Train Epoch: 1 [1000/30711 (3%)]\tLoss: 0.452890\n",
      "Train Epoch: 1 [2000/30711 (6%)]\tLoss: 0.476806\n",
      "Train Epoch: 1 [3000/30711 (10%)]\tLoss: 0.625382\n",
      "Train Epoch: 1 [4000/30711 (13%)]\tLoss: 0.641554\n",
      "Train Epoch: 1 [5000/30711 (16%)]\tLoss: 0.302057\n",
      "Train Epoch: 1 [6000/30711 (19%)]\tLoss: 0.555042\n",
      "Train Epoch: 1 [7000/30711 (23%)]\tLoss: 0.529210\n",
      "Train Epoch: 1 [8000/30711 (26%)]\tLoss: 0.400923\n",
      "Train Epoch: 1 [9000/30711 (29%)]\tLoss: 0.357537\n",
      "Train Epoch: 1 [10000/30711 (32%)]\tLoss: 0.512508\n",
      "Train Epoch: 1 [11000/30711 (36%)]\tLoss: 0.356883\n",
      "Train Epoch: 1 [12000/30711 (39%)]\tLoss: 0.562808\n",
      "Train Epoch: 1 [13000/30711 (42%)]\tLoss: 0.581171\n",
      "Train Epoch: 1 [14000/30711 (45%)]\tLoss: 0.439667\n",
      "Train Epoch: 1 [15000/30711 (49%)]\tLoss: 0.365841\n",
      "Train Epoch: 1 [16000/30711 (52%)]\tLoss: 0.642739\n",
      "Train Epoch: 1 [17000/30711 (55%)]\tLoss: 0.489735\n",
      "Train Epoch: 1 [18000/30711 (58%)]\tLoss: 0.470023\n",
      "Train Epoch: 1 [19000/30711 (62%)]\tLoss: 0.494908\n",
      "Train Epoch: 1 [20000/30711 (65%)]\tLoss: 0.466288\n",
      "Train Epoch: 1 [21000/30711 (68%)]\tLoss: 0.594477\n",
      "Train Epoch: 1 [22000/30711 (71%)]\tLoss: 0.536766\n",
      "Train Epoch: 1 [23000/30711 (75%)]\tLoss: 0.447686\n",
      "Train Epoch: 1 [24000/30711 (78%)]\tLoss: 0.416108\n",
      "Train Epoch: 1 [25000/30711 (81%)]\tLoss: 0.419035\n",
      "Train Epoch: 1 [26000/30711 (84%)]\tLoss: 0.466751\n",
      "Train Epoch: 1 [27000/30711 (88%)]\tLoss: 0.372969\n",
      "Train Epoch: 1 [28000/30711 (91%)]\tLoss: 0.390506\n",
      "Train Epoch: 1 [29000/30711 (94%)]\tLoss: 0.422029\n",
      "Train Epoch: 1 [30000/30711 (97%)]\tLoss: 0.453210\n",
      "Train Epoch: 2 [0/30711 (0%)]\tLoss: 0.473909\n",
      "Train Epoch: 2 [1000/30711 (3%)]\tLoss: 0.363623\n",
      "Train Epoch: 2 [2000/30711 (6%)]\tLoss: 0.537537\n",
      "Train Epoch: 2 [3000/30711 (10%)]\tLoss: 0.632017\n",
      "Train Epoch: 2 [4000/30711 (13%)]\tLoss: 0.481544\n",
      "Train Epoch: 2 [5000/30711 (16%)]\tLoss: 0.514200\n",
      "Train Epoch: 2 [6000/30711 (19%)]\tLoss: 0.464125\n",
      "Train Epoch: 2 [7000/30711 (23%)]\tLoss: 0.476997\n",
      "Train Epoch: 2 [8000/30711 (26%)]\tLoss: 0.597405\n",
      "Train Epoch: 2 [9000/30711 (29%)]\tLoss: 0.389806\n",
      "Train Epoch: 2 [10000/30711 (32%)]\tLoss: 0.353134\n",
      "Train Epoch: 2 [11000/30711 (36%)]\tLoss: 0.445089\n",
      "Train Epoch: 2 [12000/30711 (39%)]\tLoss: 0.456956\n",
      "Train Epoch: 2 [13000/30711 (42%)]\tLoss: 0.382924\n",
      "Train Epoch: 2 [14000/30711 (45%)]\tLoss: 0.473361\n",
      "Train Epoch: 2 [15000/30711 (49%)]\tLoss: 0.385176\n",
      "Train Epoch: 2 [16000/30711 (52%)]\tLoss: 0.491952\n",
      "Train Epoch: 2 [17000/30711 (55%)]\tLoss: 0.639064\n",
      "Train Epoch: 2 [18000/30711 (58%)]\tLoss: 0.587325\n",
      "Train Epoch: 2 [19000/30711 (62%)]\tLoss: 0.502525\n",
      "Train Epoch: 2 [20000/30711 (65%)]\tLoss: 0.548562\n",
      "Train Epoch: 2 [21000/30711 (68%)]\tLoss: 0.380211\n",
      "Train Epoch: 2 [22000/30711 (71%)]\tLoss: 0.367765\n",
      "Train Epoch: 2 [23000/30711 (75%)]\tLoss: 0.386561\n",
      "Train Epoch: 2 [24000/30711 (78%)]\tLoss: 0.403707\n",
      "Train Epoch: 2 [25000/30711 (81%)]\tLoss: 0.550802\n",
      "Train Epoch: 2 [26000/30711 (84%)]\tLoss: 0.518768\n",
      "Train Epoch: 2 [27000/30711 (88%)]\tLoss: 0.318105\n",
      "Train Epoch: 2 [28000/30711 (91%)]\tLoss: 0.475245\n",
      "Train Epoch: 2 [29000/30711 (94%)]\tLoss: 0.416446\n",
      "Train Epoch: 2 [30000/30711 (97%)]\tLoss: 0.671268\n",
      "Train Epoch: 3 [0/30711 (0%)]\tLoss: 0.457757\n",
      "Train Epoch: 3 [1000/30711 (3%)]\tLoss: 0.499897\n",
      "Train Epoch: 3 [2000/30711 (6%)]\tLoss: 0.519198\n",
      "Train Epoch: 3 [3000/30711 (10%)]\tLoss: 0.418943\n",
      "Train Epoch: 3 [4000/30711 (13%)]\tLoss: 0.284977\n",
      "Train Epoch: 3 [5000/30711 (16%)]\tLoss: 0.416794\n",
      "Train Epoch: 3 [6000/30711 (19%)]\tLoss: 0.402482\n",
      "Train Epoch: 3 [7000/30711 (23%)]\tLoss: 0.568681\n",
      "Train Epoch: 3 [8000/30711 (26%)]\tLoss: 0.450070\n",
      "Train Epoch: 3 [9000/30711 (29%)]\tLoss: 0.440112\n",
      "Train Epoch: 3 [10000/30711 (32%)]\tLoss: 0.592664\n",
      "Train Epoch: 3 [11000/30711 (36%)]\tLoss: 0.358433\n",
      "Train Epoch: 3 [12000/30711 (39%)]\tLoss: 0.336151\n",
      "Train Epoch: 3 [13000/30711 (42%)]\tLoss: 0.322545\n",
      "Train Epoch: 3 [14000/30711 (45%)]\tLoss: 0.506863\n",
      "Train Epoch: 3 [15000/30711 (49%)]\tLoss: 0.368306\n",
      "Train Epoch: 3 [16000/30711 (52%)]\tLoss: 0.409182\n",
      "Train Epoch: 3 [17000/30711 (55%)]\tLoss: 0.411105\n",
      "Train Epoch: 3 [18000/30711 (58%)]\tLoss: 0.345910\n",
      "Train Epoch: 3 [19000/30711 (62%)]\tLoss: 0.492042\n",
      "Train Epoch: 3 [20000/30711 (65%)]\tLoss: 0.423959\n",
      "Train Epoch: 3 [21000/30711 (68%)]\tLoss: 0.386545\n",
      "Train Epoch: 3 [22000/30711 (71%)]\tLoss: 0.361567\n",
      "Train Epoch: 3 [23000/30711 (75%)]\tLoss: 0.479334\n",
      "Train Epoch: 3 [24000/30711 (78%)]\tLoss: 0.427266\n",
      "Train Epoch: 3 [25000/30711 (81%)]\tLoss: 0.347278\n",
      "Train Epoch: 3 [26000/30711 (84%)]\tLoss: 0.319994\n",
      "Train Epoch: 3 [27000/30711 (88%)]\tLoss: 0.432693\n",
      "Train Epoch: 3 [28000/30711 (91%)]\tLoss: 0.394898\n",
      "Train Epoch: 3 [29000/30711 (94%)]\tLoss: 0.384206\n",
      "Train Epoch: 3 [30000/30711 (97%)]\tLoss: 0.318921\n",
      "Train Epoch: 4 [0/30711 (0%)]\tLoss: 0.484651\n",
      "Train Epoch: 4 [1000/30711 (3%)]\tLoss: 0.403061\n",
      "Train Epoch: 4 [2000/30711 (6%)]\tLoss: 0.422106\n",
      "Train Epoch: 4 [3000/30711 (10%)]\tLoss: 0.376666\n",
      "Train Epoch: 4 [4000/30711 (13%)]\tLoss: 0.272946\n",
      "Train Epoch: 4 [5000/30711 (16%)]\tLoss: 0.547007\n",
      "Train Epoch: 4 [6000/30711 (19%)]\tLoss: 0.397269\n",
      "Train Epoch: 4 [7000/30711 (23%)]\tLoss: 0.459431\n",
      "Train Epoch: 4 [8000/30711 (26%)]\tLoss: 0.689467\n",
      "Train Epoch: 4 [9000/30711 (29%)]\tLoss: 0.567607\n",
      "Train Epoch: 4 [10000/30711 (32%)]\tLoss: 0.437994\n",
      "Train Epoch: 4 [11000/30711 (36%)]\tLoss: 0.517786\n",
      "Train Epoch: 4 [12000/30711 (39%)]\tLoss: 0.422767\n",
      "Train Epoch: 4 [13000/30711 (42%)]\tLoss: 0.376028\n",
      "Train Epoch: 4 [14000/30711 (45%)]\tLoss: 0.488975\n",
      "Train Epoch: 4 [15000/30711 (49%)]\tLoss: 0.477433\n",
      "Train Epoch: 4 [16000/30711 (52%)]\tLoss: 0.471592\n",
      "Train Epoch: 4 [17000/30711 (55%)]\tLoss: 0.476102\n",
      "Train Epoch: 4 [18000/30711 (58%)]\tLoss: 0.495269\n",
      "Train Epoch: 4 [19000/30711 (62%)]\tLoss: 0.552262\n",
      "Train Epoch: 4 [20000/30711 (65%)]\tLoss: 0.406028\n",
      "Train Epoch: 4 [21000/30711 (68%)]\tLoss: 0.477588\n",
      "Train Epoch: 4 [22000/30711 (71%)]\tLoss: 0.389320\n",
      "Train Epoch: 4 [23000/30711 (75%)]\tLoss: 0.623458\n",
      "Train Epoch: 4 [24000/30711 (78%)]\tLoss: 0.446341\n",
      "Train Epoch: 4 [25000/30711 (81%)]\tLoss: 0.439507\n",
      "Train Epoch: 4 [26000/30711 (84%)]\tLoss: 0.409845\n",
      "Train Epoch: 4 [27000/30711 (88%)]\tLoss: 0.482003\n",
      "Train Epoch: 4 [28000/30711 (91%)]\tLoss: 0.414399\n",
      "Train Epoch: 4 [29000/30711 (94%)]\tLoss: 0.503979\n",
      "Train Epoch: 4 [30000/30711 (97%)]\tLoss: 0.376956\n",
      "Train Epoch: 5 [0/30711 (0%)]\tLoss: 0.501759\n",
      "Train Epoch: 5 [1000/30711 (3%)]\tLoss: 0.463667\n",
      "Train Epoch: 5 [2000/30711 (6%)]\tLoss: 0.315714\n",
      "Train Epoch: 5 [3000/30711 (10%)]\tLoss: 0.467870\n",
      "Train Epoch: 5 [4000/30711 (13%)]\tLoss: 0.414140\n",
      "Train Epoch: 5 [5000/30711 (16%)]\tLoss: 0.310902\n",
      "Train Epoch: 5 [6000/30711 (19%)]\tLoss: 0.434973\n",
      "Train Epoch: 5 [7000/30711 (23%)]\tLoss: 0.503344\n",
      "Train Epoch: 5 [8000/30711 (26%)]\tLoss: 0.443239\n",
      "Train Epoch: 5 [9000/30711 (29%)]\tLoss: 0.606247\n",
      "Train Epoch: 5 [10000/30711 (32%)]\tLoss: 0.436753\n",
      "Train Epoch: 5 [11000/30711 (36%)]\tLoss: 0.460855\n",
      "Train Epoch: 5 [12000/30711 (39%)]\tLoss: 0.313715\n",
      "Train Epoch: 5 [13000/30711 (42%)]\tLoss: 0.517663\n",
      "Train Epoch: 5 [14000/30711 (45%)]\tLoss: 0.577304\n",
      "Train Epoch: 5 [15000/30711 (49%)]\tLoss: 0.472780\n",
      "Train Epoch: 5 [16000/30711 (52%)]\tLoss: 0.399631\n",
      "Train Epoch: 5 [17000/30711 (55%)]\tLoss: 0.499956\n",
      "Train Epoch: 5 [18000/30711 (58%)]\tLoss: 0.624524\n",
      "Train Epoch: 5 [19000/30711 (62%)]\tLoss: 0.549194\n",
      "Train Epoch: 5 [20000/30711 (65%)]\tLoss: 0.492331\n",
      "Train Epoch: 5 [21000/30711 (68%)]\tLoss: 0.420168\n",
      "Train Epoch: 5 [22000/30711 (71%)]\tLoss: 0.456399\n",
      "Train Epoch: 5 [23000/30711 (75%)]\tLoss: 0.567551\n",
      "Train Epoch: 5 [24000/30711 (78%)]\tLoss: 0.389448\n",
      "Train Epoch: 5 [25000/30711 (81%)]\tLoss: 0.446133\n",
      "Train Epoch: 5 [26000/30711 (84%)]\tLoss: 0.499411\n",
      "Train Epoch: 5 [27000/30711 (88%)]\tLoss: 0.453663\n",
      "Train Epoch: 5 [28000/30711 (91%)]\tLoss: 0.364132\n",
      "Train Epoch: 5 [29000/30711 (94%)]\tLoss: 0.368600\n",
      "Train Epoch: 5 [30000/30711 (97%)]\tLoss: 0.455374\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/29289 (0%)]\tLoss: 0.466698\n",
      "Train Epoch: 1 [1000/29289 (3%)]\tLoss: 0.407303\n",
      "Train Epoch: 1 [2000/29289 (7%)]\tLoss: 0.389007\n",
      "Train Epoch: 1 [3000/29289 (10%)]\tLoss: 0.507680\n",
      "Train Epoch: 1 [4000/29289 (14%)]\tLoss: 0.471458\n",
      "Train Epoch: 1 [5000/29289 (17%)]\tLoss: 0.448207\n",
      "Train Epoch: 1 [6000/29289 (20%)]\tLoss: 0.438592\n",
      "Train Epoch: 1 [7000/29289 (24%)]\tLoss: 0.308308\n",
      "Train Epoch: 1 [8000/29289 (27%)]\tLoss: 0.363584\n",
      "Train Epoch: 1 [9000/29289 (31%)]\tLoss: 0.551659\n",
      "Train Epoch: 1 [10000/29289 (34%)]\tLoss: 0.380345\n",
      "Train Epoch: 1 [11000/29289 (38%)]\tLoss: 0.322725\n",
      "Train Epoch: 1 [12000/29289 (41%)]\tLoss: 0.420616\n",
      "Train Epoch: 1 [13000/29289 (44%)]\tLoss: 0.342331\n",
      "Train Epoch: 1 [14000/29289 (48%)]\tLoss: 0.409898\n",
      "Train Epoch: 1 [15000/29289 (51%)]\tLoss: 0.392575\n",
      "Train Epoch: 1 [16000/29289 (55%)]\tLoss: 0.527295\n",
      "Train Epoch: 1 [17000/29289 (58%)]\tLoss: 0.344189\n",
      "Train Epoch: 1 [18000/29289 (61%)]\tLoss: 0.332079\n",
      "Train Epoch: 1 [19000/29289 (65%)]\tLoss: 0.479774\n",
      "Train Epoch: 1 [20000/29289 (68%)]\tLoss: 0.489334\n",
      "Train Epoch: 1 [21000/29289 (72%)]\tLoss: 0.544674\n",
      "Train Epoch: 1 [22000/29289 (75%)]\tLoss: 0.511031\n",
      "Train Epoch: 1 [23000/29289 (78%)]\tLoss: 0.427004\n",
      "Train Epoch: 1 [24000/29289 (82%)]\tLoss: 0.459897\n",
      "Train Epoch: 1 [25000/29289 (85%)]\tLoss: 0.438129\n",
      "Train Epoch: 1 [26000/29289 (89%)]\tLoss: 0.432472\n",
      "Train Epoch: 1 [27000/29289 (92%)]\tLoss: 0.501550\n",
      "Train Epoch: 1 [28000/29289 (96%)]\tLoss: 0.502859\n",
      "Train Epoch: 1 [29000/29289 (99%)]\tLoss: 0.404653\n",
      "Train Epoch: 2 [0/29289 (0%)]\tLoss: 0.389988\n",
      "Train Epoch: 2 [1000/29289 (3%)]\tLoss: 0.451408\n",
      "Train Epoch: 2 [2000/29289 (7%)]\tLoss: 0.453355\n",
      "Train Epoch: 2 [3000/29289 (10%)]\tLoss: 0.375740\n",
      "Train Epoch: 2 [4000/29289 (14%)]\tLoss: 0.421888\n",
      "Train Epoch: 2 [5000/29289 (17%)]\tLoss: 0.336612\n",
      "Train Epoch: 2 [6000/29289 (20%)]\tLoss: 0.400541\n",
      "Train Epoch: 2 [7000/29289 (24%)]\tLoss: 0.389413\n",
      "Train Epoch: 2 [8000/29289 (27%)]\tLoss: 0.510726\n",
      "Train Epoch: 2 [9000/29289 (31%)]\tLoss: 0.442668\n",
      "Train Epoch: 2 [10000/29289 (34%)]\tLoss: 0.402658\n",
      "Train Epoch: 2 [11000/29289 (38%)]\tLoss: 0.393082\n",
      "Train Epoch: 2 [12000/29289 (41%)]\tLoss: 0.360664\n",
      "Train Epoch: 2 [13000/29289 (44%)]\tLoss: 0.406892\n",
      "Train Epoch: 2 [14000/29289 (48%)]\tLoss: 0.485667\n",
      "Train Epoch: 2 [15000/29289 (51%)]\tLoss: 0.409948\n",
      "Train Epoch: 2 [16000/29289 (55%)]\tLoss: 0.467761\n",
      "Train Epoch: 2 [17000/29289 (58%)]\tLoss: 0.455584\n",
      "Train Epoch: 2 [18000/29289 (61%)]\tLoss: 0.418652\n",
      "Train Epoch: 2 [19000/29289 (65%)]\tLoss: 0.411365\n",
      "Train Epoch: 2 [20000/29289 (68%)]\tLoss: 0.398776\n",
      "Train Epoch: 2 [21000/29289 (72%)]\tLoss: 0.454262\n",
      "Train Epoch: 2 [22000/29289 (75%)]\tLoss: 0.513140\n",
      "Train Epoch: 2 [23000/29289 (78%)]\tLoss: 0.329600\n",
      "Train Epoch: 2 [24000/29289 (82%)]\tLoss: 0.400109\n",
      "Train Epoch: 2 [25000/29289 (85%)]\tLoss: 0.405899\n",
      "Train Epoch: 2 [26000/29289 (89%)]\tLoss: 0.406778\n",
      "Train Epoch: 2 [27000/29289 (92%)]\tLoss: 0.357231\n",
      "Train Epoch: 2 [28000/29289 (96%)]\tLoss: 0.561289\n",
      "Train Epoch: 2 [29000/29289 (99%)]\tLoss: 0.430064\n",
      "Train Epoch: 3 [0/29289 (0%)]\tLoss: 0.608308\n",
      "Train Epoch: 3 [1000/29289 (3%)]\tLoss: 0.546397\n",
      "Train Epoch: 3 [2000/29289 (7%)]\tLoss: 0.539043\n",
      "Train Epoch: 3 [3000/29289 (10%)]\tLoss: 0.453886\n",
      "Train Epoch: 3 [4000/29289 (14%)]\tLoss: 0.429960\n",
      "Train Epoch: 3 [5000/29289 (17%)]\tLoss: 0.442672\n",
      "Train Epoch: 3 [6000/29289 (20%)]\tLoss: 0.410383\n",
      "Train Epoch: 3 [7000/29289 (24%)]\tLoss: 0.375274\n",
      "Train Epoch: 3 [8000/29289 (27%)]\tLoss: 0.629730\n",
      "Train Epoch: 3 [9000/29289 (31%)]\tLoss: 0.348471\n",
      "Train Epoch: 3 [10000/29289 (34%)]\tLoss: 0.381009\n",
      "Train Epoch: 3 [11000/29289 (38%)]\tLoss: 0.378456\n",
      "Train Epoch: 3 [12000/29289 (41%)]\tLoss: 0.432820\n",
      "Train Epoch: 3 [13000/29289 (44%)]\tLoss: 0.399653\n",
      "Train Epoch: 3 [14000/29289 (48%)]\tLoss: 0.558973\n",
      "Train Epoch: 3 [15000/29289 (51%)]\tLoss: 0.508002\n",
      "Train Epoch: 3 [16000/29289 (55%)]\tLoss: 0.331050\n",
      "Train Epoch: 3 [17000/29289 (58%)]\tLoss: 0.411056\n",
      "Train Epoch: 3 [18000/29289 (61%)]\tLoss: 0.365517\n",
      "Train Epoch: 3 [19000/29289 (65%)]\tLoss: 0.387787\n",
      "Train Epoch: 3 [20000/29289 (68%)]\tLoss: 0.370534\n",
      "Train Epoch: 3 [21000/29289 (72%)]\tLoss: 0.479299\n",
      "Train Epoch: 3 [22000/29289 (75%)]\tLoss: 0.322139\n",
      "Train Epoch: 3 [23000/29289 (78%)]\tLoss: 0.605605\n",
      "Train Epoch: 3 [24000/29289 (82%)]\tLoss: 0.360512\n",
      "Train Epoch: 3 [25000/29289 (85%)]\tLoss: 0.361171\n",
      "Train Epoch: 3 [26000/29289 (89%)]\tLoss: 0.495342\n",
      "Train Epoch: 3 [27000/29289 (92%)]\tLoss: 0.511720\n",
      "Train Epoch: 3 [28000/29289 (96%)]\tLoss: 0.428710\n",
      "Train Epoch: 3 [29000/29289 (99%)]\tLoss: 0.617380\n",
      "Train Epoch: 4 [0/29289 (0%)]\tLoss: 0.448132\n",
      "Train Epoch: 4 [1000/29289 (3%)]\tLoss: 0.464820\n",
      "Train Epoch: 4 [2000/29289 (7%)]\tLoss: 0.510307\n",
      "Train Epoch: 4 [3000/29289 (10%)]\tLoss: 0.358516\n",
      "Train Epoch: 4 [4000/29289 (14%)]\tLoss: 0.403898\n",
      "Train Epoch: 4 [5000/29289 (17%)]\tLoss: 0.553569\n",
      "Train Epoch: 4 [6000/29289 (20%)]\tLoss: 0.314300\n",
      "Train Epoch: 4 [7000/29289 (24%)]\tLoss: 0.346023\n",
      "Train Epoch: 4 [8000/29289 (27%)]\tLoss: 0.564348\n",
      "Train Epoch: 4 [9000/29289 (31%)]\tLoss: 0.299832\n",
      "Train Epoch: 4 [10000/29289 (34%)]\tLoss: 0.370872\n",
      "Train Epoch: 4 [11000/29289 (38%)]\tLoss: 0.406937\n",
      "Train Epoch: 4 [12000/29289 (41%)]\tLoss: 0.334770\n",
      "Train Epoch: 4 [13000/29289 (44%)]\tLoss: 0.601944\n",
      "Train Epoch: 4 [14000/29289 (48%)]\tLoss: 0.494841\n",
      "Train Epoch: 4 [15000/29289 (51%)]\tLoss: 0.418155\n",
      "Train Epoch: 4 [16000/29289 (55%)]\tLoss: 0.432219\n",
      "Train Epoch: 4 [17000/29289 (58%)]\tLoss: 0.566821\n",
      "Train Epoch: 4 [18000/29289 (61%)]\tLoss: 0.425897\n",
      "Train Epoch: 4 [19000/29289 (65%)]\tLoss: 0.344953\n",
      "Train Epoch: 4 [20000/29289 (68%)]\tLoss: 0.371043\n",
      "Train Epoch: 4 [21000/29289 (72%)]\tLoss: 0.511896\n",
      "Train Epoch: 4 [22000/29289 (75%)]\tLoss: 0.350322\n",
      "Train Epoch: 4 [23000/29289 (78%)]\tLoss: 0.365768\n",
      "Train Epoch: 4 [24000/29289 (82%)]\tLoss: 0.358380\n",
      "Train Epoch: 4 [25000/29289 (85%)]\tLoss: 0.423329\n",
      "Train Epoch: 4 [26000/29289 (89%)]\tLoss: 0.464231\n",
      "Train Epoch: 4 [27000/29289 (92%)]\tLoss: 0.500156\n",
      "Train Epoch: 4 [28000/29289 (96%)]\tLoss: 0.434027\n",
      "Train Epoch: 4 [29000/29289 (99%)]\tLoss: 0.343732\n",
      "Train Epoch: 5 [0/29289 (0%)]\tLoss: 0.355520\n",
      "Train Epoch: 5 [1000/29289 (3%)]\tLoss: 0.418103\n",
      "Train Epoch: 5 [2000/29289 (7%)]\tLoss: 0.387508\n",
      "Train Epoch: 5 [3000/29289 (10%)]\tLoss: 0.485778\n",
      "Train Epoch: 5 [4000/29289 (14%)]\tLoss: 0.556362\n",
      "Train Epoch: 5 [5000/29289 (17%)]\tLoss: 0.456162\n",
      "Train Epoch: 5 [6000/29289 (20%)]\tLoss: 0.378461\n",
      "Train Epoch: 5 [7000/29289 (24%)]\tLoss: 0.395693\n",
      "Train Epoch: 5 [8000/29289 (27%)]\tLoss: 0.401279\n",
      "Train Epoch: 5 [9000/29289 (31%)]\tLoss: 0.585139\n",
      "Train Epoch: 5 [10000/29289 (34%)]\tLoss: 0.439908\n",
      "Train Epoch: 5 [11000/29289 (38%)]\tLoss: 0.463249\n",
      "Train Epoch: 5 [12000/29289 (41%)]\tLoss: 0.415746\n",
      "Train Epoch: 5 [13000/29289 (44%)]\tLoss: 0.442527\n",
      "Train Epoch: 5 [14000/29289 (48%)]\tLoss: 0.385382\n",
      "Train Epoch: 5 [15000/29289 (51%)]\tLoss: 0.593603\n",
      "Train Epoch: 5 [16000/29289 (55%)]\tLoss: 0.440213\n",
      "Train Epoch: 5 [17000/29289 (58%)]\tLoss: 0.511145\n",
      "Train Epoch: 5 [18000/29289 (61%)]\tLoss: 0.362752\n",
      "Train Epoch: 5 [19000/29289 (65%)]\tLoss: 0.409379\n",
      "Train Epoch: 5 [20000/29289 (68%)]\tLoss: 0.389194\n",
      "Train Epoch: 5 [21000/29289 (72%)]\tLoss: 0.539418\n",
      "Train Epoch: 5 [22000/29289 (75%)]\tLoss: 0.271624\n",
      "Train Epoch: 5 [23000/29289 (78%)]\tLoss: 0.383447\n",
      "Train Epoch: 5 [24000/29289 (82%)]\tLoss: 0.489059\n",
      "Train Epoch: 5 [25000/29289 (85%)]\tLoss: 0.475699\n",
      "Train Epoch: 5 [26000/29289 (89%)]\tLoss: 0.402284\n",
      "Train Epoch: 5 [27000/29289 (92%)]\tLoss: 0.323335\n",
      "Train Epoch: 5 [28000/29289 (96%)]\tLoss: 0.350945\n",
      "Train Epoch: 5 [29000/29289 (99%)]\tLoss: 0.477053\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8339, Accuracy: 7690/10000 (77%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/14254 (0%)]\tLoss: 0.399289\n",
      "Train Epoch: 1 [1000/14254 (7%)]\tLoss: 0.301612\n",
      "Train Epoch: 1 [2000/14254 (14%)]\tLoss: 0.472552\n",
      "Train Epoch: 1 [3000/14254 (21%)]\tLoss: 0.374448\n",
      "Train Epoch: 1 [4000/14254 (28%)]\tLoss: 0.310990\n",
      "Train Epoch: 1 [5000/14254 (35%)]\tLoss: 0.446679\n",
      "Train Epoch: 1 [6000/14254 (42%)]\tLoss: 0.294161\n",
      "Train Epoch: 1 [7000/14254 (49%)]\tLoss: 0.428099\n",
      "Train Epoch: 1 [8000/14254 (56%)]\tLoss: 0.447439\n",
      "Train Epoch: 1 [9000/14254 (63%)]\tLoss: 0.321263\n",
      "Train Epoch: 1 [10000/14254 (70%)]\tLoss: 0.558900\n",
      "Train Epoch: 1 [11000/14254 (77%)]\tLoss: 0.543940\n",
      "Train Epoch: 1 [12000/14254 (84%)]\tLoss: 0.339502\n",
      "Train Epoch: 1 [13000/14254 (91%)]\tLoss: 0.503344\n",
      "Train Epoch: 1 [14000/14254 (98%)]\tLoss: 0.466037\n",
      "Train Epoch: 2 [0/14254 (0%)]\tLoss: 0.451210\n",
      "Train Epoch: 2 [1000/14254 (7%)]\tLoss: 0.390404\n",
      "Train Epoch: 2 [2000/14254 (14%)]\tLoss: 0.394446\n",
      "Train Epoch: 2 [3000/14254 (21%)]\tLoss: 0.280271\n",
      "Train Epoch: 2 [4000/14254 (28%)]\tLoss: 0.395602\n",
      "Train Epoch: 2 [5000/14254 (35%)]\tLoss: 0.509543\n",
      "Train Epoch: 2 [6000/14254 (42%)]\tLoss: 0.431934\n",
      "Train Epoch: 2 [7000/14254 (49%)]\tLoss: 0.457215\n",
      "Train Epoch: 2 [8000/14254 (56%)]\tLoss: 0.471879\n",
      "Train Epoch: 2 [9000/14254 (63%)]\tLoss: 0.456652\n",
      "Train Epoch: 2 [10000/14254 (70%)]\tLoss: 0.338499\n",
      "Train Epoch: 2 [11000/14254 (77%)]\tLoss: 0.422269\n",
      "Train Epoch: 2 [12000/14254 (84%)]\tLoss: 0.510172\n",
      "Train Epoch: 2 [13000/14254 (91%)]\tLoss: 0.482315\n",
      "Train Epoch: 2 [14000/14254 (98%)]\tLoss: 0.250629\n",
      "Train Epoch: 3 [0/14254 (0%)]\tLoss: 0.406406\n",
      "Train Epoch: 3 [1000/14254 (7%)]\tLoss: 0.372811\n",
      "Train Epoch: 3 [2000/14254 (14%)]\tLoss: 0.460892\n",
      "Train Epoch: 3 [3000/14254 (21%)]\tLoss: 0.314132\n",
      "Train Epoch: 3 [4000/14254 (28%)]\tLoss: 0.365313\n",
      "Train Epoch: 3 [5000/14254 (35%)]\tLoss: 0.290493\n",
      "Train Epoch: 3 [6000/14254 (42%)]\tLoss: 0.254133\n",
      "Train Epoch: 3 [7000/14254 (49%)]\tLoss: 0.404709\n",
      "Train Epoch: 3 [8000/14254 (56%)]\tLoss: 0.590978\n",
      "Train Epoch: 3 [9000/14254 (63%)]\tLoss: 0.401272\n",
      "Train Epoch: 3 [10000/14254 (70%)]\tLoss: 0.436442\n",
      "Train Epoch: 3 [11000/14254 (77%)]\tLoss: 0.412741\n",
      "Train Epoch: 3 [12000/14254 (84%)]\tLoss: 0.493892\n",
      "Train Epoch: 3 [13000/14254 (91%)]\tLoss: 0.449140\n",
      "Train Epoch: 3 [14000/14254 (98%)]\tLoss: 0.327247\n",
      "Train Epoch: 4 [0/14254 (0%)]\tLoss: 0.295138\n",
      "Train Epoch: 4 [1000/14254 (7%)]\tLoss: 0.483133\n",
      "Train Epoch: 4 [2000/14254 (14%)]\tLoss: 0.548220\n",
      "Train Epoch: 4 [3000/14254 (21%)]\tLoss: 0.339101\n",
      "Train Epoch: 4 [4000/14254 (28%)]\tLoss: 0.319878\n",
      "Train Epoch: 4 [5000/14254 (35%)]\tLoss: 0.385467\n",
      "Train Epoch: 4 [6000/14254 (42%)]\tLoss: 0.376444\n",
      "Train Epoch: 4 [7000/14254 (49%)]\tLoss: 0.464354\n",
      "Train Epoch: 4 [8000/14254 (56%)]\tLoss: 0.472226\n",
      "Train Epoch: 4 [9000/14254 (63%)]\tLoss: 0.250209\n",
      "Train Epoch: 4 [10000/14254 (70%)]\tLoss: 0.320102\n",
      "Train Epoch: 4 [11000/14254 (77%)]\tLoss: 0.320589\n",
      "Train Epoch: 4 [12000/14254 (84%)]\tLoss: 0.346848\n",
      "Train Epoch: 4 [13000/14254 (91%)]\tLoss: 0.362807\n",
      "Train Epoch: 4 [14000/14254 (98%)]\tLoss: 0.435155\n",
      "Train Epoch: 5 [0/14254 (0%)]\tLoss: 0.536981\n",
      "Train Epoch: 5 [1000/14254 (7%)]\tLoss: 0.425811\n",
      "Train Epoch: 5 [2000/14254 (14%)]\tLoss: 0.403392\n",
      "Train Epoch: 5 [3000/14254 (21%)]\tLoss: 0.510983\n",
      "Train Epoch: 5 [4000/14254 (28%)]\tLoss: 0.310557\n",
      "Train Epoch: 5 [5000/14254 (35%)]\tLoss: 0.356574\n",
      "Train Epoch: 5 [6000/14254 (42%)]\tLoss: 0.340817\n",
      "Train Epoch: 5 [7000/14254 (49%)]\tLoss: 0.481932\n",
      "Train Epoch: 5 [8000/14254 (56%)]\tLoss: 0.609191\n",
      "Train Epoch: 5 [9000/14254 (63%)]\tLoss: 0.344445\n",
      "Train Epoch: 5 [10000/14254 (70%)]\tLoss: 0.348025\n",
      "Train Epoch: 5 [11000/14254 (77%)]\tLoss: 0.423579\n",
      "Train Epoch: 5 [12000/14254 (84%)]\tLoss: 0.437818\n",
      "Train Epoch: 5 [13000/14254 (91%)]\tLoss: 0.396368\n",
      "Train Epoch: 5 [14000/14254 (98%)]\tLoss: 0.512076\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/13824 (0%)]\tLoss: 0.431705\n",
      "Train Epoch: 1 [1000/13824 (7%)]\tLoss: 0.333605\n",
      "Train Epoch: 1 [2000/13824 (14%)]\tLoss: 0.340944\n",
      "Train Epoch: 1 [3000/13824 (22%)]\tLoss: 0.231292\n",
      "Train Epoch: 1 [4000/13824 (29%)]\tLoss: 0.395307\n",
      "Train Epoch: 1 [5000/13824 (36%)]\tLoss: 0.528006\n",
      "Train Epoch: 1 [6000/13824 (43%)]\tLoss: 0.204190\n",
      "Train Epoch: 1 [7000/13824 (50%)]\tLoss: 0.305354\n",
      "Train Epoch: 1 [8000/13824 (58%)]\tLoss: 0.305395\n",
      "Train Epoch: 1 [9000/13824 (65%)]\tLoss: 0.289656\n",
      "Train Epoch: 1 [10000/13824 (72%)]\tLoss: 0.230940\n",
      "Train Epoch: 1 [11000/13824 (79%)]\tLoss: 0.289127\n",
      "Train Epoch: 1 [12000/13824 (86%)]\tLoss: 0.350134\n",
      "Train Epoch: 1 [13000/13824 (94%)]\tLoss: 0.257420\n",
      "Train Epoch: 2 [0/13824 (0%)]\tLoss: 0.340029\n",
      "Train Epoch: 2 [1000/13824 (7%)]\tLoss: 0.259544\n",
      "Train Epoch: 2 [2000/13824 (14%)]\tLoss: 0.411635\n",
      "Train Epoch: 2 [3000/13824 (22%)]\tLoss: 0.212357\n",
      "Train Epoch: 2 [4000/13824 (29%)]\tLoss: 0.162306\n",
      "Train Epoch: 2 [5000/13824 (36%)]\tLoss: 0.269417\n",
      "Train Epoch: 2 [6000/13824 (43%)]\tLoss: 0.260850\n",
      "Train Epoch: 2 [7000/13824 (50%)]\tLoss: 0.197145\n",
      "Train Epoch: 2 [8000/13824 (58%)]\tLoss: 0.425066\n",
      "Train Epoch: 2 [9000/13824 (65%)]\tLoss: 0.438519\n",
      "Train Epoch: 2 [10000/13824 (72%)]\tLoss: 0.195639\n",
      "Train Epoch: 2 [11000/13824 (79%)]\tLoss: 0.276704\n",
      "Train Epoch: 2 [12000/13824 (86%)]\tLoss: 0.214323\n",
      "Train Epoch: 2 [13000/13824 (94%)]\tLoss: 0.322399\n",
      "Train Epoch: 3 [0/13824 (0%)]\tLoss: 0.242786\n",
      "Train Epoch: 3 [1000/13824 (7%)]\tLoss: 0.406238\n",
      "Train Epoch: 3 [2000/13824 (14%)]\tLoss: 0.302491\n",
      "Train Epoch: 3 [3000/13824 (22%)]\tLoss: 0.147231\n",
      "Train Epoch: 3 [4000/13824 (29%)]\tLoss: 0.280057\n",
      "Train Epoch: 3 [5000/13824 (36%)]\tLoss: 0.348140\n",
      "Train Epoch: 3 [6000/13824 (43%)]\tLoss: 0.310146\n",
      "Train Epoch: 3 [7000/13824 (50%)]\tLoss: 0.223696\n",
      "Train Epoch: 3 [8000/13824 (58%)]\tLoss: 0.281410\n",
      "Train Epoch: 3 [9000/13824 (65%)]\tLoss: 0.258639\n",
      "Train Epoch: 3 [10000/13824 (72%)]\tLoss: 0.318323\n",
      "Train Epoch: 3 [11000/13824 (79%)]\tLoss: 0.173722\n",
      "Train Epoch: 3 [12000/13824 (86%)]\tLoss: 0.294209\n",
      "Train Epoch: 3 [13000/13824 (94%)]\tLoss: 0.170796\n",
      "Train Epoch: 4 [0/13824 (0%)]\tLoss: 0.220921\n",
      "Train Epoch: 4 [1000/13824 (7%)]\tLoss: 0.358413\n",
      "Train Epoch: 4 [2000/13824 (14%)]\tLoss: 0.255219\n",
      "Train Epoch: 4 [3000/13824 (22%)]\tLoss: 0.278180\n",
      "Train Epoch: 4 [4000/13824 (29%)]\tLoss: 0.174438\n",
      "Train Epoch: 4 [5000/13824 (36%)]\tLoss: 0.282284\n",
      "Train Epoch: 4 [6000/13824 (43%)]\tLoss: 0.298825\n",
      "Train Epoch: 4 [7000/13824 (50%)]\tLoss: 0.301331\n",
      "Train Epoch: 4 [8000/13824 (58%)]\tLoss: 0.252945\n",
      "Train Epoch: 4 [9000/13824 (65%)]\tLoss: 0.460671\n",
      "Train Epoch: 4 [10000/13824 (72%)]\tLoss: 0.233072\n",
      "Train Epoch: 4 [11000/13824 (79%)]\tLoss: 0.166842\n",
      "Train Epoch: 4 [12000/13824 (86%)]\tLoss: 0.265358\n",
      "Train Epoch: 4 [13000/13824 (94%)]\tLoss: 0.276025\n",
      "Train Epoch: 5 [0/13824 (0%)]\tLoss: 0.275676\n",
      "Train Epoch: 5 [1000/13824 (7%)]\tLoss: 0.313520\n",
      "Train Epoch: 5 [2000/13824 (14%)]\tLoss: 0.167649\n",
      "Train Epoch: 5 [3000/13824 (22%)]\tLoss: 0.185445\n",
      "Train Epoch: 5 [4000/13824 (29%)]\tLoss: 0.292510\n",
      "Train Epoch: 5 [5000/13824 (36%)]\tLoss: 0.253219\n",
      "Train Epoch: 5 [6000/13824 (43%)]\tLoss: 0.233172\n",
      "Train Epoch: 5 [7000/13824 (50%)]\tLoss: 0.303046\n",
      "Train Epoch: 5 [8000/13824 (58%)]\tLoss: 0.244903\n",
      "Train Epoch: 5 [9000/13824 (65%)]\tLoss: 0.280753\n",
      "Train Epoch: 5 [10000/13824 (72%)]\tLoss: 0.281896\n",
      "Train Epoch: 5 [11000/13824 (79%)]\tLoss: 0.317449\n",
      "Train Epoch: 5 [12000/13824 (86%)]\tLoss: 0.211595\n",
      "Train Epoch: 5 [13000/13824 (94%)]\tLoss: 0.220031\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/16239 (0%)]\tLoss: 0.461284\n",
      "Train Epoch: 1 [1000/16239 (6%)]\tLoss: 0.346961\n",
      "Train Epoch: 1 [2000/16239 (12%)]\tLoss: 0.364082\n",
      "Train Epoch: 1 [3000/16239 (18%)]\tLoss: 0.329442\n",
      "Train Epoch: 1 [4000/16239 (25%)]\tLoss: 0.301045\n",
      "Train Epoch: 1 [5000/16239 (31%)]\tLoss: 0.429457\n",
      "Train Epoch: 1 [6000/16239 (37%)]\tLoss: 0.546310\n",
      "Train Epoch: 1 [7000/16239 (43%)]\tLoss: 0.321324\n",
      "Train Epoch: 1 [8000/16239 (49%)]\tLoss: 0.389709\n",
      "Train Epoch: 1 [9000/16239 (55%)]\tLoss: 0.519575\n",
      "Train Epoch: 1 [10000/16239 (61%)]\tLoss: 0.291628\n",
      "Train Epoch: 1 [11000/16239 (67%)]\tLoss: 0.347320\n",
      "Train Epoch: 1 [12000/16239 (74%)]\tLoss: 0.340749\n",
      "Train Epoch: 1 [13000/16239 (80%)]\tLoss: 0.372405\n",
      "Train Epoch: 1 [14000/16239 (86%)]\tLoss: 0.309259\n",
      "Train Epoch: 1 [15000/16239 (92%)]\tLoss: 0.306976\n",
      "Train Epoch: 1 [16000/16239 (98%)]\tLoss: 0.408653\n",
      "Train Epoch: 2 [0/16239 (0%)]\tLoss: 0.462868\n",
      "Train Epoch: 2 [1000/16239 (6%)]\tLoss: 0.234474\n",
      "Train Epoch: 2 [2000/16239 (12%)]\tLoss: 0.363476\n",
      "Train Epoch: 2 [3000/16239 (18%)]\tLoss: 0.362056\n",
      "Train Epoch: 2 [4000/16239 (25%)]\tLoss: 0.512604\n",
      "Train Epoch: 2 [5000/16239 (31%)]\tLoss: 0.408012\n",
      "Train Epoch: 2 [6000/16239 (37%)]\tLoss: 0.430247\n",
      "Train Epoch: 2 [7000/16239 (43%)]\tLoss: 0.477762\n",
      "Train Epoch: 2 [8000/16239 (49%)]\tLoss: 0.367586\n",
      "Train Epoch: 2 [9000/16239 (55%)]\tLoss: 0.296313\n",
      "Train Epoch: 2 [10000/16239 (61%)]\tLoss: 0.352636\n",
      "Train Epoch: 2 [11000/16239 (67%)]\tLoss: 0.442837\n",
      "Train Epoch: 2 [12000/16239 (74%)]\tLoss: 0.348142\n",
      "Train Epoch: 2 [13000/16239 (80%)]\tLoss: 0.435786\n",
      "Train Epoch: 2 [14000/16239 (86%)]\tLoss: 0.516132\n",
      "Train Epoch: 2 [15000/16239 (92%)]\tLoss: 0.283869\n",
      "Train Epoch: 2 [16000/16239 (98%)]\tLoss: 0.406622\n",
      "Train Epoch: 3 [0/16239 (0%)]\tLoss: 0.332956\n",
      "Train Epoch: 3 [1000/16239 (6%)]\tLoss: 0.417376\n",
      "Train Epoch: 3 [2000/16239 (12%)]\tLoss: 0.317384\n",
      "Train Epoch: 3 [3000/16239 (18%)]\tLoss: 0.424506\n",
      "Train Epoch: 3 [4000/16239 (25%)]\tLoss: 0.426273\n",
      "Train Epoch: 3 [5000/16239 (31%)]\tLoss: 0.334233\n",
      "Train Epoch: 3 [6000/16239 (37%)]\tLoss: 0.363487\n",
      "Train Epoch: 3 [7000/16239 (43%)]\tLoss: 0.495725\n",
      "Train Epoch: 3 [8000/16239 (49%)]\tLoss: 0.413771\n",
      "Train Epoch: 3 [9000/16239 (55%)]\tLoss: 0.417742\n",
      "Train Epoch: 3 [10000/16239 (61%)]\tLoss: 0.321559\n",
      "Train Epoch: 3 [11000/16239 (67%)]\tLoss: 0.436656\n",
      "Train Epoch: 3 [12000/16239 (74%)]\tLoss: 0.439806\n",
      "Train Epoch: 3 [13000/16239 (80%)]\tLoss: 0.405377\n",
      "Train Epoch: 3 [14000/16239 (86%)]\tLoss: 0.454859\n",
      "Train Epoch: 3 [15000/16239 (92%)]\tLoss: 0.385165\n",
      "Train Epoch: 3 [16000/16239 (98%)]\tLoss: 0.488538\n",
      "Train Epoch: 4 [0/16239 (0%)]\tLoss: 0.394764\n",
      "Train Epoch: 4 [1000/16239 (6%)]\tLoss: 0.306293\n",
      "Train Epoch: 4 [2000/16239 (12%)]\tLoss: 0.381263\n",
      "Train Epoch: 4 [3000/16239 (18%)]\tLoss: 0.368502\n",
      "Train Epoch: 4 [4000/16239 (25%)]\tLoss: 0.370121\n",
      "Train Epoch: 4 [5000/16239 (31%)]\tLoss: 0.357880\n",
      "Train Epoch: 4 [6000/16239 (37%)]\tLoss: 0.381046\n",
      "Train Epoch: 4 [7000/16239 (43%)]\tLoss: 0.386617\n",
      "Train Epoch: 4 [8000/16239 (49%)]\tLoss: 0.448546\n",
      "Train Epoch: 4 [9000/16239 (55%)]\tLoss: 0.402184\n",
      "Train Epoch: 4 [10000/16239 (61%)]\tLoss: 0.367180\n",
      "Train Epoch: 4 [11000/16239 (67%)]\tLoss: 0.536754\n",
      "Train Epoch: 4 [12000/16239 (74%)]\tLoss: 0.418220\n",
      "Train Epoch: 4 [13000/16239 (80%)]\tLoss: 0.293743\n",
      "Train Epoch: 4 [14000/16239 (86%)]\tLoss: 0.428381\n",
      "Train Epoch: 4 [15000/16239 (92%)]\tLoss: 0.405510\n",
      "Train Epoch: 4 [16000/16239 (98%)]\tLoss: 0.371981\n",
      "Train Epoch: 5 [0/16239 (0%)]\tLoss: 0.605891\n",
      "Train Epoch: 5 [1000/16239 (6%)]\tLoss: 0.360608\n",
      "Train Epoch: 5 [2000/16239 (12%)]\tLoss: 0.315153\n",
      "Train Epoch: 5 [3000/16239 (18%)]\tLoss: 0.268010\n",
      "Train Epoch: 5 [4000/16239 (25%)]\tLoss: 0.466221\n",
      "Train Epoch: 5 [5000/16239 (31%)]\tLoss: 0.478212\n",
      "Train Epoch: 5 [6000/16239 (37%)]\tLoss: 0.399177\n",
      "Train Epoch: 5 [7000/16239 (43%)]\tLoss: 0.406548\n",
      "Train Epoch: 5 [8000/16239 (49%)]\tLoss: 0.309395\n",
      "Train Epoch: 5 [9000/16239 (55%)]\tLoss: 0.423843\n",
      "Train Epoch: 5 [10000/16239 (61%)]\tLoss: 0.235460\n",
      "Train Epoch: 5 [11000/16239 (67%)]\tLoss: 0.347253\n",
      "Train Epoch: 5 [12000/16239 (74%)]\tLoss: 0.433221\n",
      "Train Epoch: 5 [13000/16239 (80%)]\tLoss: 0.353978\n",
      "Train Epoch: 5 [14000/16239 (86%)]\tLoss: 0.299444\n",
      "Train Epoch: 5 [15000/16239 (92%)]\tLoss: 0.240525\n",
      "Train Epoch: 5 [16000/16239 (98%)]\tLoss: 0.372415\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/15683 (0%)]\tLoss: 0.320748\n",
      "Train Epoch: 1 [1000/15683 (6%)]\tLoss: 0.471757\n",
      "Train Epoch: 1 [2000/15683 (13%)]\tLoss: 0.363607\n",
      "Train Epoch: 1 [3000/15683 (19%)]\tLoss: 0.448738\n",
      "Train Epoch: 1 [4000/15683 (25%)]\tLoss: 0.458873\n",
      "Train Epoch: 1 [5000/15683 (32%)]\tLoss: 0.417472\n",
      "Train Epoch: 1 [6000/15683 (38%)]\tLoss: 0.505916\n",
      "Train Epoch: 1 [7000/15683 (45%)]\tLoss: 0.442560\n",
      "Train Epoch: 1 [8000/15683 (51%)]\tLoss: 0.430853\n",
      "Train Epoch: 1 [9000/15683 (57%)]\tLoss: 0.383108\n",
      "Train Epoch: 1 [10000/15683 (64%)]\tLoss: 0.415913\n",
      "Train Epoch: 1 [11000/15683 (70%)]\tLoss: 0.392365\n",
      "Train Epoch: 1 [12000/15683 (76%)]\tLoss: 0.489083\n",
      "Train Epoch: 1 [13000/15683 (83%)]\tLoss: 0.382831\n",
      "Train Epoch: 1 [14000/15683 (89%)]\tLoss: 0.395027\n",
      "Train Epoch: 1 [15000/15683 (96%)]\tLoss: 0.310909\n",
      "Train Epoch: 2 [0/15683 (0%)]\tLoss: 0.329122\n",
      "Train Epoch: 2 [1000/15683 (6%)]\tLoss: 0.527064\n",
      "Train Epoch: 2 [2000/15683 (13%)]\tLoss: 0.527976\n",
      "Train Epoch: 2 [3000/15683 (19%)]\tLoss: 0.216048\n",
      "Train Epoch: 2 [4000/15683 (25%)]\tLoss: 0.317344\n",
      "Train Epoch: 2 [5000/15683 (32%)]\tLoss: 0.416892\n",
      "Train Epoch: 2 [6000/15683 (38%)]\tLoss: 0.335989\n",
      "Train Epoch: 2 [7000/15683 (45%)]\tLoss: 0.452765\n",
      "Train Epoch: 2 [8000/15683 (51%)]\tLoss: 0.520157\n",
      "Train Epoch: 2 [9000/15683 (57%)]\tLoss: 0.375850\n",
      "Train Epoch: 2 [10000/15683 (64%)]\tLoss: 0.396540\n",
      "Train Epoch: 2 [11000/15683 (70%)]\tLoss: 0.445566\n",
      "Train Epoch: 2 [12000/15683 (76%)]\tLoss: 0.392374\n",
      "Train Epoch: 2 [13000/15683 (83%)]\tLoss: 0.649447\n",
      "Train Epoch: 2 [14000/15683 (89%)]\tLoss: 0.405585\n",
      "Train Epoch: 2 [15000/15683 (96%)]\tLoss: 0.317258\n",
      "Train Epoch: 3 [0/15683 (0%)]\tLoss: 0.359338\n",
      "Train Epoch: 3 [1000/15683 (6%)]\tLoss: 0.478125\n",
      "Train Epoch: 3 [2000/15683 (13%)]\tLoss: 0.380412\n",
      "Train Epoch: 3 [3000/15683 (19%)]\tLoss: 0.347581\n",
      "Train Epoch: 3 [4000/15683 (25%)]\tLoss: 0.475390\n",
      "Train Epoch: 3 [5000/15683 (32%)]\tLoss: 0.463046\n",
      "Train Epoch: 3 [6000/15683 (38%)]\tLoss: 0.378135\n",
      "Train Epoch: 3 [7000/15683 (45%)]\tLoss: 0.480945\n",
      "Train Epoch: 3 [8000/15683 (51%)]\tLoss: 0.466598\n",
      "Train Epoch: 3 [9000/15683 (57%)]\tLoss: 0.380072\n",
      "Train Epoch: 3 [10000/15683 (64%)]\tLoss: 0.477816\n",
      "Train Epoch: 3 [11000/15683 (70%)]\tLoss: 0.481729\n",
      "Train Epoch: 3 [12000/15683 (76%)]\tLoss: 0.479771\n",
      "Train Epoch: 3 [13000/15683 (83%)]\tLoss: 0.443762\n",
      "Train Epoch: 3 [14000/15683 (89%)]\tLoss: 0.278290\n",
      "Train Epoch: 3 [15000/15683 (96%)]\tLoss: 0.496687\n",
      "Train Epoch: 4 [0/15683 (0%)]\tLoss: 0.339813\n",
      "Train Epoch: 4 [1000/15683 (6%)]\tLoss: 0.475343\n",
      "Train Epoch: 4 [2000/15683 (13%)]\tLoss: 0.407820\n",
      "Train Epoch: 4 [3000/15683 (19%)]\tLoss: 0.213175\n",
      "Train Epoch: 4 [4000/15683 (25%)]\tLoss: 0.328556\n",
      "Train Epoch: 4 [5000/15683 (32%)]\tLoss: 0.492313\n",
      "Train Epoch: 4 [6000/15683 (38%)]\tLoss: 0.284995\n",
      "Train Epoch: 4 [7000/15683 (45%)]\tLoss: 0.315854\n",
      "Train Epoch: 4 [8000/15683 (51%)]\tLoss: 0.373764\n",
      "Train Epoch: 4 [9000/15683 (57%)]\tLoss: 0.398758\n",
      "Train Epoch: 4 [10000/15683 (64%)]\tLoss: 0.294453\n",
      "Train Epoch: 4 [11000/15683 (70%)]\tLoss: 0.455919\n",
      "Train Epoch: 4 [12000/15683 (76%)]\tLoss: 0.555649\n",
      "Train Epoch: 4 [13000/15683 (83%)]\tLoss: 0.560935\n",
      "Train Epoch: 4 [14000/15683 (89%)]\tLoss: 0.414891\n",
      "Train Epoch: 4 [15000/15683 (96%)]\tLoss: 0.510471\n",
      "Train Epoch: 5 [0/15683 (0%)]\tLoss: 0.398461\n",
      "Train Epoch: 5 [1000/15683 (6%)]\tLoss: 0.426602\n",
      "Train Epoch: 5 [2000/15683 (13%)]\tLoss: 0.416884\n",
      "Train Epoch: 5 [3000/15683 (19%)]\tLoss: 0.345661\n",
      "Train Epoch: 5 [4000/15683 (25%)]\tLoss: 0.367535\n",
      "Train Epoch: 5 [5000/15683 (32%)]\tLoss: 0.440587\n",
      "Train Epoch: 5 [6000/15683 (38%)]\tLoss: 0.402575\n",
      "Train Epoch: 5 [7000/15683 (45%)]\tLoss: 0.471416\n",
      "Train Epoch: 5 [8000/15683 (51%)]\tLoss: 0.341342\n",
      "Train Epoch: 5 [9000/15683 (57%)]\tLoss: 0.452943\n",
      "Train Epoch: 5 [10000/15683 (64%)]\tLoss: 0.355955\n",
      "Train Epoch: 5 [11000/15683 (70%)]\tLoss: 0.407269\n",
      "Train Epoch: 5 [12000/15683 (76%)]\tLoss: 0.415594\n",
      "Train Epoch: 5 [13000/15683 (83%)]\tLoss: 0.451256\n",
      "Train Epoch: 5 [14000/15683 (89%)]\tLoss: 0.367521\n",
      "Train Epoch: 5 [15000/15683 (96%)]\tLoss: 0.351110\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8652, Accuracy: 7643/10000 (76%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/14254 (0%)]\tLoss: 0.401757\n",
      "Train Epoch: 1 [1000/14254 (7%)]\tLoss: 0.354324\n",
      "Train Epoch: 1 [2000/14254 (14%)]\tLoss: 0.465665\n",
      "Train Epoch: 1 [3000/14254 (21%)]\tLoss: 0.311325\n",
      "Train Epoch: 1 [4000/14254 (28%)]\tLoss: 0.433707\n",
      "Train Epoch: 1 [5000/14254 (35%)]\tLoss: 0.392568\n",
      "Train Epoch: 1 [6000/14254 (42%)]\tLoss: 0.517576\n",
      "Train Epoch: 1 [7000/14254 (49%)]\tLoss: 0.349449\n",
      "Train Epoch: 1 [8000/14254 (56%)]\tLoss: 0.270469\n",
      "Train Epoch: 1 [9000/14254 (63%)]\tLoss: 0.439412\n",
      "Train Epoch: 1 [10000/14254 (70%)]\tLoss: 0.519365\n",
      "Train Epoch: 1 [11000/14254 (77%)]\tLoss: 0.537577\n",
      "Train Epoch: 1 [12000/14254 (84%)]\tLoss: 0.306432\n",
      "Train Epoch: 1 [13000/14254 (91%)]\tLoss: 0.488606\n",
      "Train Epoch: 1 [14000/14254 (98%)]\tLoss: 0.423045\n",
      "Train Epoch: 2 [0/14254 (0%)]\tLoss: 0.401407\n",
      "Train Epoch: 2 [1000/14254 (7%)]\tLoss: 0.439286\n",
      "Train Epoch: 2 [2000/14254 (14%)]\tLoss: 0.393730\n",
      "Train Epoch: 2 [3000/14254 (21%)]\tLoss: 0.390470\n",
      "Train Epoch: 2 [4000/14254 (28%)]\tLoss: 0.478809\n",
      "Train Epoch: 2 [5000/14254 (35%)]\tLoss: 0.432244\n",
      "Train Epoch: 2 [6000/14254 (42%)]\tLoss: 0.428381\n",
      "Train Epoch: 2 [7000/14254 (49%)]\tLoss: 0.453485\n",
      "Train Epoch: 2 [8000/14254 (56%)]\tLoss: 0.361946\n",
      "Train Epoch: 2 [9000/14254 (63%)]\tLoss: 0.545431\n",
      "Train Epoch: 2 [10000/14254 (70%)]\tLoss: 0.411752\n",
      "Train Epoch: 2 [11000/14254 (77%)]\tLoss: 0.468679\n",
      "Train Epoch: 2 [12000/14254 (84%)]\tLoss: 0.329467\n",
      "Train Epoch: 2 [13000/14254 (91%)]\tLoss: 0.362765\n",
      "Train Epoch: 2 [14000/14254 (98%)]\tLoss: 0.469334\n",
      "Train Epoch: 3 [0/14254 (0%)]\tLoss: 0.407360\n",
      "Train Epoch: 3 [1000/14254 (7%)]\tLoss: 0.452195\n",
      "Train Epoch: 3 [2000/14254 (14%)]\tLoss: 0.362586\n",
      "Train Epoch: 3 [3000/14254 (21%)]\tLoss: 0.302365\n",
      "Train Epoch: 3 [4000/14254 (28%)]\tLoss: 0.398008\n",
      "Train Epoch: 3 [5000/14254 (35%)]\tLoss: 0.402390\n",
      "Train Epoch: 3 [6000/14254 (42%)]\tLoss: 0.386355\n",
      "Train Epoch: 3 [7000/14254 (49%)]\tLoss: 0.394193\n",
      "Train Epoch: 3 [8000/14254 (56%)]\tLoss: 0.321326\n",
      "Train Epoch: 3 [9000/14254 (63%)]\tLoss: 0.355689\n",
      "Train Epoch: 3 [10000/14254 (70%)]\tLoss: 0.356672\n",
      "Train Epoch: 3 [11000/14254 (77%)]\tLoss: 0.362221\n",
      "Train Epoch: 3 [12000/14254 (84%)]\tLoss: 0.317253\n",
      "Train Epoch: 3 [13000/14254 (91%)]\tLoss: 0.469880\n",
      "Train Epoch: 3 [14000/14254 (98%)]\tLoss: 0.441637\n",
      "Train Epoch: 4 [0/14254 (0%)]\tLoss: 0.428172\n",
      "Train Epoch: 4 [1000/14254 (7%)]\tLoss: 0.351689\n",
      "Train Epoch: 4 [2000/14254 (14%)]\tLoss: 0.317221\n",
      "Train Epoch: 4 [3000/14254 (21%)]\tLoss: 0.459205\n",
      "Train Epoch: 4 [4000/14254 (28%)]\tLoss: 0.462399\n",
      "Train Epoch: 4 [5000/14254 (35%)]\tLoss: 0.527915\n",
      "Train Epoch: 4 [6000/14254 (42%)]\tLoss: 0.365186\n",
      "Train Epoch: 4 [7000/14254 (49%)]\tLoss: 0.504674\n",
      "Train Epoch: 4 [8000/14254 (56%)]\tLoss: 0.402662\n",
      "Train Epoch: 4 [9000/14254 (63%)]\tLoss: 0.451876\n",
      "Train Epoch: 4 [10000/14254 (70%)]\tLoss: 0.368628\n",
      "Train Epoch: 4 [11000/14254 (77%)]\tLoss: 0.352892\n",
      "Train Epoch: 4 [12000/14254 (84%)]\tLoss: 0.462570\n",
      "Train Epoch: 4 [13000/14254 (91%)]\tLoss: 0.366029\n",
      "Train Epoch: 4 [14000/14254 (98%)]\tLoss: 0.372750\n",
      "Train Epoch: 5 [0/14254 (0%)]\tLoss: 0.454053\n",
      "Train Epoch: 5 [1000/14254 (7%)]\tLoss: 0.424766\n",
      "Train Epoch: 5 [2000/14254 (14%)]\tLoss: 0.489795\n",
      "Train Epoch: 5 [3000/14254 (21%)]\tLoss: 0.410603\n",
      "Train Epoch: 5 [4000/14254 (28%)]\tLoss: 0.266742\n",
      "Train Epoch: 5 [5000/14254 (35%)]\tLoss: 0.341624\n",
      "Train Epoch: 5 [6000/14254 (42%)]\tLoss: 0.430432\n",
      "Train Epoch: 5 [7000/14254 (49%)]\tLoss: 0.427515\n",
      "Train Epoch: 5 [8000/14254 (56%)]\tLoss: 0.448430\n",
      "Train Epoch: 5 [9000/14254 (63%)]\tLoss: 0.464466\n",
      "Train Epoch: 5 [10000/14254 (70%)]\tLoss: 0.304318\n",
      "Train Epoch: 5 [11000/14254 (77%)]\tLoss: 0.439245\n",
      "Train Epoch: 5 [12000/14254 (84%)]\tLoss: 0.423132\n",
      "Train Epoch: 5 [13000/14254 (91%)]\tLoss: 0.261410\n",
      "Train Epoch: 5 [14000/14254 (98%)]\tLoss: 0.469881\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/13824 (0%)]\tLoss: 0.444534\n",
      "Train Epoch: 1 [1000/13824 (7%)]\tLoss: 0.327080\n",
      "Train Epoch: 1 [2000/13824 (14%)]\tLoss: 0.227384\n",
      "Train Epoch: 1 [3000/13824 (22%)]\tLoss: 0.180664\n",
      "Train Epoch: 1 [4000/13824 (29%)]\tLoss: 0.199953\n",
      "Train Epoch: 1 [5000/13824 (36%)]\tLoss: 0.373711\n",
      "Train Epoch: 1 [6000/13824 (43%)]\tLoss: 0.301440\n",
      "Train Epoch: 1 [7000/13824 (50%)]\tLoss: 0.323114\n",
      "Train Epoch: 1 [8000/13824 (58%)]\tLoss: 0.313847\n",
      "Train Epoch: 1 [9000/13824 (65%)]\tLoss: 0.176345\n",
      "Train Epoch: 1 [10000/13824 (72%)]\tLoss: 0.229474\n",
      "Train Epoch: 1 [11000/13824 (79%)]\tLoss: 0.238766\n",
      "Train Epoch: 1 [12000/13824 (86%)]\tLoss: 0.203075\n",
      "Train Epoch: 1 [13000/13824 (94%)]\tLoss: 0.266700\n",
      "Train Epoch: 2 [0/13824 (0%)]\tLoss: 0.477180\n",
      "Train Epoch: 2 [1000/13824 (7%)]\tLoss: 0.274005\n",
      "Train Epoch: 2 [2000/13824 (14%)]\tLoss: 0.213564\n",
      "Train Epoch: 2 [3000/13824 (22%)]\tLoss: 0.281178\n",
      "Train Epoch: 2 [4000/13824 (29%)]\tLoss: 0.367543\n",
      "Train Epoch: 2 [5000/13824 (36%)]\tLoss: 0.318809\n",
      "Train Epoch: 2 [6000/13824 (43%)]\tLoss: 0.231274\n",
      "Train Epoch: 2 [7000/13824 (50%)]\tLoss: 0.328336\n",
      "Train Epoch: 2 [8000/13824 (58%)]\tLoss: 0.184211\n",
      "Train Epoch: 2 [9000/13824 (65%)]\tLoss: 0.220191\n",
      "Train Epoch: 2 [10000/13824 (72%)]\tLoss: 0.239104\n",
      "Train Epoch: 2 [11000/13824 (79%)]\tLoss: 0.165765\n",
      "Train Epoch: 2 [12000/13824 (86%)]\tLoss: 0.249885\n",
      "Train Epoch: 2 [13000/13824 (94%)]\tLoss: 0.218414\n",
      "Train Epoch: 3 [0/13824 (0%)]\tLoss: 0.278851\n",
      "Train Epoch: 3 [1000/13824 (7%)]\tLoss: 0.262808\n",
      "Train Epoch: 3 [2000/13824 (14%)]\tLoss: 0.234565\n",
      "Train Epoch: 3 [3000/13824 (22%)]\tLoss: 0.286523\n",
      "Train Epoch: 3 [4000/13824 (29%)]\tLoss: 0.287746\n",
      "Train Epoch: 3 [5000/13824 (36%)]\tLoss: 0.230045\n",
      "Train Epoch: 3 [6000/13824 (43%)]\tLoss: 0.350739\n",
      "Train Epoch: 3 [7000/13824 (50%)]\tLoss: 0.260684\n",
      "Train Epoch: 3 [8000/13824 (58%)]\tLoss: 0.231719\n",
      "Train Epoch: 3 [9000/13824 (65%)]\tLoss: 0.310791\n",
      "Train Epoch: 3 [10000/13824 (72%)]\tLoss: 0.308389\n",
      "Train Epoch: 3 [11000/13824 (79%)]\tLoss: 0.334388\n",
      "Train Epoch: 3 [12000/13824 (86%)]\tLoss: 0.171905\n",
      "Train Epoch: 3 [13000/13824 (94%)]\tLoss: 0.356176\n",
      "Train Epoch: 4 [0/13824 (0%)]\tLoss: 0.210112\n",
      "Train Epoch: 4 [1000/13824 (7%)]\tLoss: 0.236215\n",
      "Train Epoch: 4 [2000/13824 (14%)]\tLoss: 0.267434\n",
      "Train Epoch: 4 [3000/13824 (22%)]\tLoss: 0.228495\n",
      "Train Epoch: 4 [4000/13824 (29%)]\tLoss: 0.329236\n",
      "Train Epoch: 4 [5000/13824 (36%)]\tLoss: 0.281130\n",
      "Train Epoch: 4 [6000/13824 (43%)]\tLoss: 0.366045\n",
      "Train Epoch: 4 [7000/13824 (50%)]\tLoss: 0.232848\n",
      "Train Epoch: 4 [8000/13824 (58%)]\tLoss: 0.160762\n",
      "Train Epoch: 4 [9000/13824 (65%)]\tLoss: 0.167978\n",
      "Train Epoch: 4 [10000/13824 (72%)]\tLoss: 0.268625\n",
      "Train Epoch: 4 [11000/13824 (79%)]\tLoss: 0.285968\n",
      "Train Epoch: 4 [12000/13824 (86%)]\tLoss: 0.340513\n",
      "Train Epoch: 4 [13000/13824 (94%)]\tLoss: 0.278821\n",
      "Train Epoch: 5 [0/13824 (0%)]\tLoss: 0.173856\n",
      "Train Epoch: 5 [1000/13824 (7%)]\tLoss: 0.202273\n",
      "Train Epoch: 5 [2000/13824 (14%)]\tLoss: 0.172109\n",
      "Train Epoch: 5 [3000/13824 (22%)]\tLoss: 0.299228\n",
      "Train Epoch: 5 [4000/13824 (29%)]\tLoss: 0.123495\n",
      "Train Epoch: 5 [5000/13824 (36%)]\tLoss: 0.296460\n",
      "Train Epoch: 5 [6000/13824 (43%)]\tLoss: 0.238234\n",
      "Train Epoch: 5 [7000/13824 (50%)]\tLoss: 0.114549\n",
      "Train Epoch: 5 [8000/13824 (58%)]\tLoss: 0.262612\n",
      "Train Epoch: 5 [9000/13824 (65%)]\tLoss: 0.225562\n",
      "Train Epoch: 5 [10000/13824 (72%)]\tLoss: 0.235364\n",
      "Train Epoch: 5 [11000/13824 (79%)]\tLoss: 0.213721\n",
      "Train Epoch: 5 [12000/13824 (86%)]\tLoss: 0.174445\n",
      "Train Epoch: 5 [13000/13824 (94%)]\tLoss: 0.279386\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/16239 (0%)]\tLoss: 0.521567\n",
      "Train Epoch: 1 [1000/16239 (6%)]\tLoss: 0.451211\n",
      "Train Epoch: 1 [2000/16239 (12%)]\tLoss: 0.339141\n",
      "Train Epoch: 1 [3000/16239 (18%)]\tLoss: 0.343844\n",
      "Train Epoch: 1 [4000/16239 (25%)]\tLoss: 0.309641\n",
      "Train Epoch: 1 [5000/16239 (31%)]\tLoss: 0.494981\n",
      "Train Epoch: 1 [6000/16239 (37%)]\tLoss: 0.510002\n",
      "Train Epoch: 1 [7000/16239 (43%)]\tLoss: 0.455855\n",
      "Train Epoch: 1 [8000/16239 (49%)]\tLoss: 0.303171\n",
      "Train Epoch: 1 [9000/16239 (55%)]\tLoss: 0.427169\n",
      "Train Epoch: 1 [10000/16239 (61%)]\tLoss: 0.495020\n",
      "Train Epoch: 1 [11000/16239 (67%)]\tLoss: 0.476889\n",
      "Train Epoch: 1 [12000/16239 (74%)]\tLoss: 0.388859\n",
      "Train Epoch: 1 [13000/16239 (80%)]\tLoss: 0.360301\n",
      "Train Epoch: 1 [14000/16239 (86%)]\tLoss: 0.276956\n",
      "Train Epoch: 1 [15000/16239 (92%)]\tLoss: 0.387876\n",
      "Train Epoch: 1 [16000/16239 (98%)]\tLoss: 0.292915\n",
      "Train Epoch: 2 [0/16239 (0%)]\tLoss: 0.462138\n",
      "Train Epoch: 2 [1000/16239 (6%)]\tLoss: 0.361198\n",
      "Train Epoch: 2 [2000/16239 (12%)]\tLoss: 0.335849\n",
      "Train Epoch: 2 [3000/16239 (18%)]\tLoss: 0.544040\n",
      "Train Epoch: 2 [4000/16239 (25%)]\tLoss: 0.500735\n",
      "Train Epoch: 2 [5000/16239 (31%)]\tLoss: 0.407149\n",
      "Train Epoch: 2 [6000/16239 (37%)]\tLoss: 0.347092\n",
      "Train Epoch: 2 [7000/16239 (43%)]\tLoss: 0.416321\n",
      "Train Epoch: 2 [8000/16239 (49%)]\tLoss: 0.336097\n",
      "Train Epoch: 2 [9000/16239 (55%)]\tLoss: 0.478332\n",
      "Train Epoch: 2 [10000/16239 (61%)]\tLoss: 0.453250\n",
      "Train Epoch: 2 [11000/16239 (67%)]\tLoss: 0.505058\n",
      "Train Epoch: 2 [12000/16239 (74%)]\tLoss: 0.502031\n",
      "Train Epoch: 2 [13000/16239 (80%)]\tLoss: 0.422134\n",
      "Train Epoch: 2 [14000/16239 (86%)]\tLoss: 0.458720\n",
      "Train Epoch: 2 [15000/16239 (92%)]\tLoss: 0.427069\n",
      "Train Epoch: 2 [16000/16239 (98%)]\tLoss: 0.348622\n",
      "Train Epoch: 3 [0/16239 (0%)]\tLoss: 0.491421\n",
      "Train Epoch: 3 [1000/16239 (6%)]\tLoss: 0.292307\n",
      "Train Epoch: 3 [2000/16239 (12%)]\tLoss: 0.522922\n",
      "Train Epoch: 3 [3000/16239 (18%)]\tLoss: 0.321836\n",
      "Train Epoch: 3 [4000/16239 (25%)]\tLoss: 0.332420\n",
      "Train Epoch: 3 [5000/16239 (31%)]\tLoss: 0.359224\n",
      "Train Epoch: 3 [6000/16239 (37%)]\tLoss: 0.354932\n",
      "Train Epoch: 3 [7000/16239 (43%)]\tLoss: 0.410382\n",
      "Train Epoch: 3 [8000/16239 (49%)]\tLoss: 0.510247\n",
      "Train Epoch: 3 [9000/16239 (55%)]\tLoss: 0.382080\n",
      "Train Epoch: 3 [10000/16239 (61%)]\tLoss: 0.485351\n",
      "Train Epoch: 3 [11000/16239 (67%)]\tLoss: 0.231151\n",
      "Train Epoch: 3 [12000/16239 (74%)]\tLoss: 0.448542\n",
      "Train Epoch: 3 [13000/16239 (80%)]\tLoss: 0.428409\n",
      "Train Epoch: 3 [14000/16239 (86%)]\tLoss: 0.348960\n",
      "Train Epoch: 3 [15000/16239 (92%)]\tLoss: 0.370648\n",
      "Train Epoch: 3 [16000/16239 (98%)]\tLoss: 0.486107\n",
      "Train Epoch: 4 [0/16239 (0%)]\tLoss: 0.433390\n",
      "Train Epoch: 4 [1000/16239 (6%)]\tLoss: 0.374855\n",
      "Train Epoch: 4 [2000/16239 (12%)]\tLoss: 0.303955\n",
      "Train Epoch: 4 [3000/16239 (18%)]\tLoss: 0.354336\n",
      "Train Epoch: 4 [4000/16239 (25%)]\tLoss: 0.491929\n",
      "Train Epoch: 4 [5000/16239 (31%)]\tLoss: 0.326190\n",
      "Train Epoch: 4 [6000/16239 (37%)]\tLoss: 0.385281\n",
      "Train Epoch: 4 [7000/16239 (43%)]\tLoss: 0.435276\n",
      "Train Epoch: 4 [8000/16239 (49%)]\tLoss: 0.468764\n",
      "Train Epoch: 4 [9000/16239 (55%)]\tLoss: 0.328235\n",
      "Train Epoch: 4 [10000/16239 (61%)]\tLoss: 0.515695\n",
      "Train Epoch: 4 [11000/16239 (67%)]\tLoss: 0.371221\n",
      "Train Epoch: 4 [12000/16239 (74%)]\tLoss: 0.326300\n",
      "Train Epoch: 4 [13000/16239 (80%)]\tLoss: 0.506069\n",
      "Train Epoch: 4 [14000/16239 (86%)]\tLoss: 0.324686\n",
      "Train Epoch: 4 [15000/16239 (92%)]\tLoss: 0.310245\n",
      "Train Epoch: 4 [16000/16239 (98%)]\tLoss: 0.361219\n",
      "Train Epoch: 5 [0/16239 (0%)]\tLoss: 0.287073\n",
      "Train Epoch: 5 [1000/16239 (6%)]\tLoss: 0.300204\n",
      "Train Epoch: 5 [2000/16239 (12%)]\tLoss: 0.376510\n",
      "Train Epoch: 5 [3000/16239 (18%)]\tLoss: 0.288663\n",
      "Train Epoch: 5 [4000/16239 (25%)]\tLoss: 0.459321\n",
      "Train Epoch: 5 [5000/16239 (31%)]\tLoss: 0.400035\n",
      "Train Epoch: 5 [6000/16239 (37%)]\tLoss: 0.307427\n",
      "Train Epoch: 5 [7000/16239 (43%)]\tLoss: 0.351860\n",
      "Train Epoch: 5 [8000/16239 (49%)]\tLoss: 0.417665\n",
      "Train Epoch: 5 [9000/16239 (55%)]\tLoss: 0.492989\n",
      "Train Epoch: 5 [10000/16239 (61%)]\tLoss: 0.419252\n",
      "Train Epoch: 5 [11000/16239 (67%)]\tLoss: 0.312880\n",
      "Train Epoch: 5 [12000/16239 (74%)]\tLoss: 0.363755\n",
      "Train Epoch: 5 [13000/16239 (80%)]\tLoss: 0.353016\n",
      "Train Epoch: 5 [14000/16239 (86%)]\tLoss: 0.360448\n",
      "Train Epoch: 5 [15000/16239 (92%)]\tLoss: 0.502040\n",
      "Train Epoch: 5 [16000/16239 (98%)]\tLoss: 0.546466\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/15683 (0%)]\tLoss: 0.451607\n",
      "Train Epoch: 1 [1000/15683 (6%)]\tLoss: 0.359421\n",
      "Train Epoch: 1 [2000/15683 (13%)]\tLoss: 0.425314\n",
      "Train Epoch: 1 [3000/15683 (19%)]\tLoss: 0.457368\n",
      "Train Epoch: 1 [4000/15683 (25%)]\tLoss: 0.449995\n",
      "Train Epoch: 1 [5000/15683 (32%)]\tLoss: 0.403970\n",
      "Train Epoch: 1 [6000/15683 (38%)]\tLoss: 0.391371\n",
      "Train Epoch: 1 [7000/15683 (45%)]\tLoss: 0.268091\n",
      "Train Epoch: 1 [8000/15683 (51%)]\tLoss: 0.431121\n",
      "Train Epoch: 1 [9000/15683 (57%)]\tLoss: 0.446327\n",
      "Train Epoch: 1 [10000/15683 (64%)]\tLoss: 0.418084\n",
      "Train Epoch: 1 [11000/15683 (70%)]\tLoss: 0.492564\n",
      "Train Epoch: 1 [12000/15683 (76%)]\tLoss: 0.362244\n",
      "Train Epoch: 1 [13000/15683 (83%)]\tLoss: 0.426548\n",
      "Train Epoch: 1 [14000/15683 (89%)]\tLoss: 0.587898\n",
      "Train Epoch: 1 [15000/15683 (96%)]\tLoss: 0.322103\n",
      "Train Epoch: 2 [0/15683 (0%)]\tLoss: 0.443436\n",
      "Train Epoch: 2 [1000/15683 (6%)]\tLoss: 0.478530\n",
      "Train Epoch: 2 [2000/15683 (13%)]\tLoss: 0.521322\n",
      "Train Epoch: 2 [3000/15683 (19%)]\tLoss: 0.391067\n",
      "Train Epoch: 2 [4000/15683 (25%)]\tLoss: 0.367684\n",
      "Train Epoch: 2 [5000/15683 (32%)]\tLoss: 0.537056\n",
      "Train Epoch: 2 [6000/15683 (38%)]\tLoss: 0.319705\n",
      "Train Epoch: 2 [7000/15683 (45%)]\tLoss: 0.418868\n",
      "Train Epoch: 2 [8000/15683 (51%)]\tLoss: 0.480637\n",
      "Train Epoch: 2 [9000/15683 (57%)]\tLoss: 0.402977\n",
      "Train Epoch: 2 [10000/15683 (64%)]\tLoss: 0.343554\n",
      "Train Epoch: 2 [11000/15683 (70%)]\tLoss: 0.370652\n",
      "Train Epoch: 2 [12000/15683 (76%)]\tLoss: 0.213686\n",
      "Train Epoch: 2 [13000/15683 (83%)]\tLoss: 0.450416\n",
      "Train Epoch: 2 [14000/15683 (89%)]\tLoss: 0.424911\n",
      "Train Epoch: 2 [15000/15683 (96%)]\tLoss: 0.287081\n",
      "Train Epoch: 3 [0/15683 (0%)]\tLoss: 0.324106\n",
      "Train Epoch: 3 [1000/15683 (6%)]\tLoss: 0.446486\n",
      "Train Epoch: 3 [2000/15683 (13%)]\tLoss: 0.327859\n",
      "Train Epoch: 3 [3000/15683 (19%)]\tLoss: 0.518875\n",
      "Train Epoch: 3 [4000/15683 (25%)]\tLoss: 0.464877\n",
      "Train Epoch: 3 [5000/15683 (32%)]\tLoss: 0.432828\n",
      "Train Epoch: 3 [6000/15683 (38%)]\tLoss: 0.491969\n",
      "Train Epoch: 3 [7000/15683 (45%)]\tLoss: 0.478825\n",
      "Train Epoch: 3 [8000/15683 (51%)]\tLoss: 0.367303\n",
      "Train Epoch: 3 [9000/15683 (57%)]\tLoss: 0.281040\n",
      "Train Epoch: 3 [10000/15683 (64%)]\tLoss: 0.457562\n",
      "Train Epoch: 3 [11000/15683 (70%)]\tLoss: 0.378234\n",
      "Train Epoch: 3 [12000/15683 (76%)]\tLoss: 0.336788\n",
      "Train Epoch: 3 [13000/15683 (83%)]\tLoss: 0.357638\n",
      "Train Epoch: 3 [14000/15683 (89%)]\tLoss: 0.313857\n",
      "Train Epoch: 3 [15000/15683 (96%)]\tLoss: 0.465051\n",
      "Train Epoch: 4 [0/15683 (0%)]\tLoss: 0.306188\n",
      "Train Epoch: 4 [1000/15683 (6%)]\tLoss: 0.559679\n",
      "Train Epoch: 4 [2000/15683 (13%)]\tLoss: 0.322597\n",
      "Train Epoch: 4 [3000/15683 (19%)]\tLoss: 0.348351\n",
      "Train Epoch: 4 [4000/15683 (25%)]\tLoss: 0.381242\n",
      "Train Epoch: 4 [5000/15683 (32%)]\tLoss: 0.398592\n",
      "Train Epoch: 4 [6000/15683 (38%)]\tLoss: 0.732755\n",
      "Train Epoch: 4 [7000/15683 (45%)]\tLoss: 0.484905\n",
      "Train Epoch: 4 [8000/15683 (51%)]\tLoss: 0.397879\n",
      "Train Epoch: 4 [9000/15683 (57%)]\tLoss: 0.331980\n",
      "Train Epoch: 4 [10000/15683 (64%)]\tLoss: 0.341568\n",
      "Train Epoch: 4 [11000/15683 (70%)]\tLoss: 0.385963\n",
      "Train Epoch: 4 [12000/15683 (76%)]\tLoss: 0.257606\n",
      "Train Epoch: 4 [13000/15683 (83%)]\tLoss: 0.420553\n",
      "Train Epoch: 4 [14000/15683 (89%)]\tLoss: 0.318423\n",
      "Train Epoch: 4 [15000/15683 (96%)]\tLoss: 0.443354\n",
      "Train Epoch: 5 [0/15683 (0%)]\tLoss: 0.334108\n",
      "Train Epoch: 5 [1000/15683 (6%)]\tLoss: 0.334734\n",
      "Train Epoch: 5 [2000/15683 (13%)]\tLoss: 0.347835\n",
      "Train Epoch: 5 [3000/15683 (19%)]\tLoss: 0.431909\n",
      "Train Epoch: 5 [4000/15683 (25%)]\tLoss: 0.335386\n",
      "Train Epoch: 5 [5000/15683 (32%)]\tLoss: 0.303741\n",
      "Train Epoch: 5 [6000/15683 (38%)]\tLoss: 0.323181\n",
      "Train Epoch: 5 [7000/15683 (45%)]\tLoss: 0.344626\n",
      "Train Epoch: 5 [8000/15683 (51%)]\tLoss: 0.351363\n",
      "Train Epoch: 5 [9000/15683 (57%)]\tLoss: 0.408526\n",
      "Train Epoch: 5 [10000/15683 (64%)]\tLoss: 0.386543\n",
      "Train Epoch: 5 [11000/15683 (70%)]\tLoss: 0.342107\n",
      "Train Epoch: 5 [12000/15683 (76%)]\tLoss: 0.426874\n",
      "Train Epoch: 5 [13000/15683 (83%)]\tLoss: 0.543420\n",
      "Train Epoch: 5 [14000/15683 (89%)]\tLoss: 0.541939\n",
      "Train Epoch: 5 [15000/15683 (96%)]\tLoss: 0.390961\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8992, Accuracy: 7630/10000 (76%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/14254 (0%)]\tLoss: 0.517987\n",
      "Train Epoch: 1 [1000/14254 (7%)]\tLoss: 0.427358\n",
      "Train Epoch: 1 [2000/14254 (14%)]\tLoss: 0.453792\n",
      "Train Epoch: 1 [3000/14254 (21%)]\tLoss: 0.463601\n",
      "Train Epoch: 1 [4000/14254 (28%)]\tLoss: 0.437091\n",
      "Train Epoch: 1 [5000/14254 (35%)]\tLoss: 0.417975\n",
      "Train Epoch: 1 [6000/14254 (42%)]\tLoss: 0.419020\n",
      "Train Epoch: 1 [7000/14254 (49%)]\tLoss: 0.528995\n",
      "Train Epoch: 1 [8000/14254 (56%)]\tLoss: 0.263403\n",
      "Train Epoch: 1 [9000/14254 (63%)]\tLoss: 0.485040\n",
      "Train Epoch: 1 [10000/14254 (70%)]\tLoss: 0.352679\n",
      "Train Epoch: 1 [11000/14254 (77%)]\tLoss: 0.393726\n",
      "Train Epoch: 1 [12000/14254 (84%)]\tLoss: 0.356691\n",
      "Train Epoch: 1 [13000/14254 (91%)]\tLoss: 0.575252\n",
      "Train Epoch: 1 [14000/14254 (98%)]\tLoss: 0.262517\n",
      "Train Epoch: 2 [0/14254 (0%)]\tLoss: 0.277176\n",
      "Train Epoch: 2 [1000/14254 (7%)]\tLoss: 0.313298\n",
      "Train Epoch: 2 [2000/14254 (14%)]\tLoss: 0.427817\n",
      "Train Epoch: 2 [3000/14254 (21%)]\tLoss: 0.563169\n",
      "Train Epoch: 2 [4000/14254 (28%)]\tLoss: 0.512633\n",
      "Train Epoch: 2 [5000/14254 (35%)]\tLoss: 0.434261\n",
      "Train Epoch: 2 [6000/14254 (42%)]\tLoss: 0.326946\n",
      "Train Epoch: 2 [7000/14254 (49%)]\tLoss: 0.320000\n",
      "Train Epoch: 2 [8000/14254 (56%)]\tLoss: 0.459821\n",
      "Train Epoch: 2 [9000/14254 (63%)]\tLoss: 0.355951\n",
      "Train Epoch: 2 [10000/14254 (70%)]\tLoss: 0.496083\n",
      "Train Epoch: 2 [11000/14254 (77%)]\tLoss: 0.393725\n",
      "Train Epoch: 2 [12000/14254 (84%)]\tLoss: 0.588621\n",
      "Train Epoch: 2 [13000/14254 (91%)]\tLoss: 0.460168\n",
      "Train Epoch: 2 [14000/14254 (98%)]\tLoss: 0.366787\n",
      "Train Epoch: 3 [0/14254 (0%)]\tLoss: 0.456881\n",
      "Train Epoch: 3 [1000/14254 (7%)]\tLoss: 0.317015\n",
      "Train Epoch: 3 [2000/14254 (14%)]\tLoss: 0.373050\n",
      "Train Epoch: 3 [3000/14254 (21%)]\tLoss: 0.472856\n",
      "Train Epoch: 3 [4000/14254 (28%)]\tLoss: 0.368569\n",
      "Train Epoch: 3 [5000/14254 (35%)]\tLoss: 0.382451\n",
      "Train Epoch: 3 [6000/14254 (42%)]\tLoss: 0.380985\n",
      "Train Epoch: 3 [7000/14254 (49%)]\tLoss: 0.356525\n",
      "Train Epoch: 3 [8000/14254 (56%)]\tLoss: 0.461705\n",
      "Train Epoch: 3 [9000/14254 (63%)]\tLoss: 0.454758\n",
      "Train Epoch: 3 [10000/14254 (70%)]\tLoss: 0.415609\n",
      "Train Epoch: 3 [11000/14254 (77%)]\tLoss: 0.370892\n",
      "Train Epoch: 3 [12000/14254 (84%)]\tLoss: 0.325892\n",
      "Train Epoch: 3 [13000/14254 (91%)]\tLoss: 0.462772\n",
      "Train Epoch: 3 [14000/14254 (98%)]\tLoss: 0.312615\n",
      "Train Epoch: 4 [0/14254 (0%)]\tLoss: 0.242472\n",
      "Train Epoch: 4 [1000/14254 (7%)]\tLoss: 0.320809\n",
      "Train Epoch: 4 [2000/14254 (14%)]\tLoss: 0.462906\n",
      "Train Epoch: 4 [3000/14254 (21%)]\tLoss: 0.523655\n",
      "Train Epoch: 4 [4000/14254 (28%)]\tLoss: 0.355637\n",
      "Train Epoch: 4 [5000/14254 (35%)]\tLoss: 0.440091\n",
      "Train Epoch: 4 [6000/14254 (42%)]\tLoss: 0.362213\n",
      "Train Epoch: 4 [7000/14254 (49%)]\tLoss: 0.404667\n",
      "Train Epoch: 4 [8000/14254 (56%)]\tLoss: 0.458362\n",
      "Train Epoch: 4 [9000/14254 (63%)]\tLoss: 0.485095\n",
      "Train Epoch: 4 [10000/14254 (70%)]\tLoss: 0.325350\n",
      "Train Epoch: 4 [11000/14254 (77%)]\tLoss: 0.384372\n",
      "Train Epoch: 4 [12000/14254 (84%)]\tLoss: 0.358866\n",
      "Train Epoch: 4 [13000/14254 (91%)]\tLoss: 0.319315\n",
      "Train Epoch: 4 [14000/14254 (98%)]\tLoss: 0.300439\n",
      "Train Epoch: 5 [0/14254 (0%)]\tLoss: 0.413146\n",
      "Train Epoch: 5 [1000/14254 (7%)]\tLoss: 0.579995\n",
      "Train Epoch: 5 [2000/14254 (14%)]\tLoss: 0.378083\n",
      "Train Epoch: 5 [3000/14254 (21%)]\tLoss: 0.349547\n",
      "Train Epoch: 5 [4000/14254 (28%)]\tLoss: 0.282540\n",
      "Train Epoch: 5 [5000/14254 (35%)]\tLoss: 0.331312\n",
      "Train Epoch: 5 [6000/14254 (42%)]\tLoss: 0.341004\n",
      "Train Epoch: 5 [7000/14254 (49%)]\tLoss: 0.336696\n",
      "Train Epoch: 5 [8000/14254 (56%)]\tLoss: 0.377618\n",
      "Train Epoch: 5 [9000/14254 (63%)]\tLoss: 0.319299\n",
      "Train Epoch: 5 [10000/14254 (70%)]\tLoss: 0.388988\n",
      "Train Epoch: 5 [11000/14254 (77%)]\tLoss: 0.450369\n",
      "Train Epoch: 5 [12000/14254 (84%)]\tLoss: 0.330717\n",
      "Train Epoch: 5 [13000/14254 (91%)]\tLoss: 0.346724\n",
      "Train Epoch: 5 [14000/14254 (98%)]\tLoss: 0.420508\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/13824 (0%)]\tLoss: 0.632905\n",
      "Train Epoch: 1 [1000/13824 (7%)]\tLoss: 0.284066\n",
      "Train Epoch: 1 [2000/13824 (14%)]\tLoss: 0.318381\n",
      "Train Epoch: 1 [3000/13824 (22%)]\tLoss: 0.185802\n",
      "Train Epoch: 1 [4000/13824 (29%)]\tLoss: 0.194029\n",
      "Train Epoch: 1 [5000/13824 (36%)]\tLoss: 0.186944\n",
      "Train Epoch: 1 [6000/13824 (43%)]\tLoss: 0.328876\n",
      "Train Epoch: 1 [7000/13824 (50%)]\tLoss: 0.272372\n",
      "Train Epoch: 1 [8000/13824 (58%)]\tLoss: 0.344622\n",
      "Train Epoch: 1 [9000/13824 (65%)]\tLoss: 0.304967\n",
      "Train Epoch: 1 [10000/13824 (72%)]\tLoss: 0.261154\n",
      "Train Epoch: 1 [11000/13824 (79%)]\tLoss: 0.343477\n",
      "Train Epoch: 1 [12000/13824 (86%)]\tLoss: 0.327917\n",
      "Train Epoch: 1 [13000/13824 (94%)]\tLoss: 0.243498\n",
      "Train Epoch: 2 [0/13824 (0%)]\tLoss: 0.294381\n",
      "Train Epoch: 2 [1000/13824 (7%)]\tLoss: 0.274438\n",
      "Train Epoch: 2 [2000/13824 (14%)]\tLoss: 0.180598\n",
      "Train Epoch: 2 [3000/13824 (22%)]\tLoss: 0.271375\n",
      "Train Epoch: 2 [4000/13824 (29%)]\tLoss: 0.324083\n",
      "Train Epoch: 2 [5000/13824 (36%)]\tLoss: 0.301564\n",
      "Train Epoch: 2 [6000/13824 (43%)]\tLoss: 0.178010\n",
      "Train Epoch: 2 [7000/13824 (50%)]\tLoss: 0.271028\n",
      "Train Epoch: 2 [8000/13824 (58%)]\tLoss: 0.212869\n",
      "Train Epoch: 2 [9000/13824 (65%)]\tLoss: 0.221538\n",
      "Train Epoch: 2 [10000/13824 (72%)]\tLoss: 0.409382\n",
      "Train Epoch: 2 [11000/13824 (79%)]\tLoss: 0.202585\n",
      "Train Epoch: 2 [12000/13824 (86%)]\tLoss: 0.309911\n",
      "Train Epoch: 2 [13000/13824 (94%)]\tLoss: 0.353589\n",
      "Train Epoch: 3 [0/13824 (0%)]\tLoss: 0.304767\n",
      "Train Epoch: 3 [1000/13824 (7%)]\tLoss: 0.366387\n",
      "Train Epoch: 3 [2000/13824 (14%)]\tLoss: 0.181235\n",
      "Train Epoch: 3 [3000/13824 (22%)]\tLoss: 0.258700\n",
      "Train Epoch: 3 [4000/13824 (29%)]\tLoss: 0.205821\n",
      "Train Epoch: 3 [5000/13824 (36%)]\tLoss: 0.343987\n",
      "Train Epoch: 3 [6000/13824 (43%)]\tLoss: 0.220518\n",
      "Train Epoch: 3 [7000/13824 (50%)]\tLoss: 0.335540\n",
      "Train Epoch: 3 [8000/13824 (58%)]\tLoss: 0.267177\n",
      "Train Epoch: 3 [9000/13824 (65%)]\tLoss: 0.183103\n",
      "Train Epoch: 3 [10000/13824 (72%)]\tLoss: 0.228207\n",
      "Train Epoch: 3 [11000/13824 (79%)]\tLoss: 0.323193\n",
      "Train Epoch: 3 [12000/13824 (86%)]\tLoss: 0.238213\n",
      "Train Epoch: 3 [13000/13824 (94%)]\tLoss: 0.172080\n",
      "Train Epoch: 4 [0/13824 (0%)]\tLoss: 0.172890\n",
      "Train Epoch: 4 [1000/13824 (7%)]\tLoss: 0.169786\n",
      "Train Epoch: 4 [2000/13824 (14%)]\tLoss: 0.497632\n",
      "Train Epoch: 4 [3000/13824 (22%)]\tLoss: 0.174791\n",
      "Train Epoch: 4 [4000/13824 (29%)]\tLoss: 0.226285\n",
      "Train Epoch: 4 [5000/13824 (36%)]\tLoss: 0.248583\n",
      "Train Epoch: 4 [6000/13824 (43%)]\tLoss: 0.264514\n",
      "Train Epoch: 4 [7000/13824 (50%)]\tLoss: 0.355337\n",
      "Train Epoch: 4 [8000/13824 (58%)]\tLoss: 0.220771\n",
      "Train Epoch: 4 [9000/13824 (65%)]\tLoss: 0.269962\n",
      "Train Epoch: 4 [10000/13824 (72%)]\tLoss: 0.280480\n",
      "Train Epoch: 4 [11000/13824 (79%)]\tLoss: 0.203472\n",
      "Train Epoch: 4 [12000/13824 (86%)]\tLoss: 0.246102\n",
      "Train Epoch: 4 [13000/13824 (94%)]\tLoss: 0.251662\n",
      "Train Epoch: 5 [0/13824 (0%)]\tLoss: 0.375947\n",
      "Train Epoch: 5 [1000/13824 (7%)]\tLoss: 0.163878\n",
      "Train Epoch: 5 [2000/13824 (14%)]\tLoss: 0.210543\n",
      "Train Epoch: 5 [3000/13824 (22%)]\tLoss: 0.285249\n",
      "Train Epoch: 5 [4000/13824 (29%)]\tLoss: 0.168601\n",
      "Train Epoch: 5 [5000/13824 (36%)]\tLoss: 0.235055\n",
      "Train Epoch: 5 [6000/13824 (43%)]\tLoss: 0.378068\n",
      "Train Epoch: 5 [7000/13824 (50%)]\tLoss: 0.226215\n",
      "Train Epoch: 5 [8000/13824 (58%)]\tLoss: 0.372483\n",
      "Train Epoch: 5 [9000/13824 (65%)]\tLoss: 0.314349\n",
      "Train Epoch: 5 [10000/13824 (72%)]\tLoss: 0.254107\n",
      "Train Epoch: 5 [11000/13824 (79%)]\tLoss: 0.442327\n",
      "Train Epoch: 5 [12000/13824 (86%)]\tLoss: 0.199400\n",
      "Train Epoch: 5 [13000/13824 (94%)]\tLoss: 0.427465\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/16239 (0%)]\tLoss: 0.349484\n",
      "Train Epoch: 1 [1000/16239 (6%)]\tLoss: 0.261052\n",
      "Train Epoch: 1 [2000/16239 (12%)]\tLoss: 0.335944\n",
      "Train Epoch: 1 [3000/16239 (18%)]\tLoss: 0.329801\n",
      "Train Epoch: 1 [4000/16239 (25%)]\tLoss: 0.349755\n",
      "Train Epoch: 1 [5000/16239 (31%)]\tLoss: 0.445760\n",
      "Train Epoch: 1 [6000/16239 (37%)]\tLoss: 0.348943\n",
      "Train Epoch: 1 [7000/16239 (43%)]\tLoss: 0.352729\n",
      "Train Epoch: 1 [8000/16239 (49%)]\tLoss: 0.342496\n",
      "Train Epoch: 1 [9000/16239 (55%)]\tLoss: 0.302612\n",
      "Train Epoch: 1 [10000/16239 (61%)]\tLoss: 0.464501\n",
      "Train Epoch: 1 [11000/16239 (67%)]\tLoss: 0.287628\n",
      "Train Epoch: 1 [12000/16239 (74%)]\tLoss: 0.316803\n",
      "Train Epoch: 1 [13000/16239 (80%)]\tLoss: 0.453207\n",
      "Train Epoch: 1 [14000/16239 (86%)]\tLoss: 0.210305\n",
      "Train Epoch: 1 [15000/16239 (92%)]\tLoss: 0.272373\n",
      "Train Epoch: 1 [16000/16239 (98%)]\tLoss: 0.244621\n",
      "Train Epoch: 2 [0/16239 (0%)]\tLoss: 0.278942\n",
      "Train Epoch: 2 [1000/16239 (6%)]\tLoss: 0.530832\n",
      "Train Epoch: 2 [2000/16239 (12%)]\tLoss: 0.492002\n",
      "Train Epoch: 2 [3000/16239 (18%)]\tLoss: 0.326295\n",
      "Train Epoch: 2 [4000/16239 (25%)]\tLoss: 0.352624\n",
      "Train Epoch: 2 [5000/16239 (31%)]\tLoss: 0.379268\n",
      "Train Epoch: 2 [6000/16239 (37%)]\tLoss: 0.443392\n",
      "Train Epoch: 2 [7000/16239 (43%)]\tLoss: 0.238003\n",
      "Train Epoch: 2 [8000/16239 (49%)]\tLoss: 0.454655\n",
      "Train Epoch: 2 [9000/16239 (55%)]\tLoss: 0.262093\n",
      "Train Epoch: 2 [10000/16239 (61%)]\tLoss: 0.351331\n",
      "Train Epoch: 2 [11000/16239 (67%)]\tLoss: 0.484960\n",
      "Train Epoch: 2 [12000/16239 (74%)]\tLoss: 0.353002\n",
      "Train Epoch: 2 [13000/16239 (80%)]\tLoss: 0.357694\n",
      "Train Epoch: 2 [14000/16239 (86%)]\tLoss: 0.479365\n",
      "Train Epoch: 2 [15000/16239 (92%)]\tLoss: 0.501401\n",
      "Train Epoch: 2 [16000/16239 (98%)]\tLoss: 0.407314\n",
      "Train Epoch: 3 [0/16239 (0%)]\tLoss: 0.602311\n",
      "Train Epoch: 3 [1000/16239 (6%)]\tLoss: 0.476508\n",
      "Train Epoch: 3 [2000/16239 (12%)]\tLoss: 0.469800\n",
      "Train Epoch: 3 [3000/16239 (18%)]\tLoss: 0.270079\n",
      "Train Epoch: 3 [4000/16239 (25%)]\tLoss: 0.339421\n",
      "Train Epoch: 3 [5000/16239 (31%)]\tLoss: 0.275349\n",
      "Train Epoch: 3 [6000/16239 (37%)]\tLoss: 0.458030\n",
      "Train Epoch: 3 [7000/16239 (43%)]\tLoss: 0.493963\n",
      "Train Epoch: 3 [8000/16239 (49%)]\tLoss: 0.346311\n",
      "Train Epoch: 3 [9000/16239 (55%)]\tLoss: 0.281608\n",
      "Train Epoch: 3 [10000/16239 (61%)]\tLoss: 0.350335\n",
      "Train Epoch: 3 [11000/16239 (67%)]\tLoss: 0.390185\n",
      "Train Epoch: 3 [12000/16239 (74%)]\tLoss: 0.409083\n",
      "Train Epoch: 3 [13000/16239 (80%)]\tLoss: 0.469150\n",
      "Train Epoch: 3 [14000/16239 (86%)]\tLoss: 0.367363\n",
      "Train Epoch: 3 [15000/16239 (92%)]\tLoss: 0.348787\n",
      "Train Epoch: 3 [16000/16239 (98%)]\tLoss: 0.311794\n",
      "Train Epoch: 4 [0/16239 (0%)]\tLoss: 0.431903\n",
      "Train Epoch: 4 [1000/16239 (6%)]\tLoss: 0.373881\n",
      "Train Epoch: 4 [2000/16239 (12%)]\tLoss: 0.300728\n",
      "Train Epoch: 4 [3000/16239 (18%)]\tLoss: 0.432999\n",
      "Train Epoch: 4 [4000/16239 (25%)]\tLoss: 0.321530\n",
      "Train Epoch: 4 [5000/16239 (31%)]\tLoss: 0.395396\n",
      "Train Epoch: 4 [6000/16239 (37%)]\tLoss: 0.463512\n",
      "Train Epoch: 4 [7000/16239 (43%)]\tLoss: 0.417764\n",
      "Train Epoch: 4 [8000/16239 (49%)]\tLoss: 0.542038\n",
      "Train Epoch: 4 [9000/16239 (55%)]\tLoss: 0.444154\n",
      "Train Epoch: 4 [10000/16239 (61%)]\tLoss: 0.494197\n",
      "Train Epoch: 4 [11000/16239 (67%)]\tLoss: 0.301180\n",
      "Train Epoch: 4 [12000/16239 (74%)]\tLoss: 0.512094\n",
      "Train Epoch: 4 [13000/16239 (80%)]\tLoss: 0.344230\n",
      "Train Epoch: 4 [14000/16239 (86%)]\tLoss: 0.441875\n",
      "Train Epoch: 4 [15000/16239 (92%)]\tLoss: 0.263025\n",
      "Train Epoch: 4 [16000/16239 (98%)]\tLoss: 0.364672\n",
      "Train Epoch: 5 [0/16239 (0%)]\tLoss: 0.345985\n",
      "Train Epoch: 5 [1000/16239 (6%)]\tLoss: 0.493027\n",
      "Train Epoch: 5 [2000/16239 (12%)]\tLoss: 0.407181\n",
      "Train Epoch: 5 [3000/16239 (18%)]\tLoss: 0.335136\n",
      "Train Epoch: 5 [4000/16239 (25%)]\tLoss: 0.362975\n",
      "Train Epoch: 5 [5000/16239 (31%)]\tLoss: 0.474039\n",
      "Train Epoch: 5 [6000/16239 (37%)]\tLoss: 0.342168\n",
      "Train Epoch: 5 [7000/16239 (43%)]\tLoss: 0.386991\n",
      "Train Epoch: 5 [8000/16239 (49%)]\tLoss: 0.238946\n",
      "Train Epoch: 5 [9000/16239 (55%)]\tLoss: 0.332240\n",
      "Train Epoch: 5 [10000/16239 (61%)]\tLoss: 0.440524\n",
      "Train Epoch: 5 [11000/16239 (67%)]\tLoss: 0.396797\n",
      "Train Epoch: 5 [12000/16239 (74%)]\tLoss: 0.330436\n",
      "Train Epoch: 5 [13000/16239 (80%)]\tLoss: 0.464779\n",
      "Train Epoch: 5 [14000/16239 (86%)]\tLoss: 0.337373\n",
      "Train Epoch: 5 [15000/16239 (92%)]\tLoss: 0.390758\n",
      "Train Epoch: 5 [16000/16239 (98%)]\tLoss: 0.363969\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/15683 (0%)]\tLoss: 0.415203\n",
      "Train Epoch: 1 [1000/15683 (6%)]\tLoss: 0.308978\n",
      "Train Epoch: 1 [2000/15683 (13%)]\tLoss: 0.428617\n",
      "Train Epoch: 1 [3000/15683 (19%)]\tLoss: 0.499947\n",
      "Train Epoch: 1 [4000/15683 (25%)]\tLoss: 0.367192\n",
      "Train Epoch: 1 [5000/15683 (32%)]\tLoss: 0.485754\n",
      "Train Epoch: 1 [6000/15683 (38%)]\tLoss: 0.409414\n",
      "Train Epoch: 1 [7000/15683 (45%)]\tLoss: 0.571909\n",
      "Train Epoch: 1 [8000/15683 (51%)]\tLoss: 0.360887\n",
      "Train Epoch: 1 [9000/15683 (57%)]\tLoss: 0.350445\n",
      "Train Epoch: 1 [10000/15683 (64%)]\tLoss: 0.367806\n",
      "Train Epoch: 1 [11000/15683 (70%)]\tLoss: 0.310066\n",
      "Train Epoch: 1 [12000/15683 (76%)]\tLoss: 0.460901\n",
      "Train Epoch: 1 [13000/15683 (83%)]\tLoss: 0.502546\n",
      "Train Epoch: 1 [14000/15683 (89%)]\tLoss: 0.318225\n",
      "Train Epoch: 1 [15000/15683 (96%)]\tLoss: 0.444156\n",
      "Train Epoch: 2 [0/15683 (0%)]\tLoss: 0.413352\n",
      "Train Epoch: 2 [1000/15683 (6%)]\tLoss: 0.309352\n",
      "Train Epoch: 2 [2000/15683 (13%)]\tLoss: 0.447329\n",
      "Train Epoch: 2 [3000/15683 (19%)]\tLoss: 0.385860\n",
      "Train Epoch: 2 [4000/15683 (25%)]\tLoss: 0.355562\n",
      "Train Epoch: 2 [5000/15683 (32%)]\tLoss: 0.213470\n",
      "Train Epoch: 2 [6000/15683 (38%)]\tLoss: 0.330791\n",
      "Train Epoch: 2 [7000/15683 (45%)]\tLoss: 0.504081\n",
      "Train Epoch: 2 [8000/15683 (51%)]\tLoss: 0.272038\n",
      "Train Epoch: 2 [9000/15683 (57%)]\tLoss: 0.327906\n",
      "Train Epoch: 2 [10000/15683 (64%)]\tLoss: 0.443880\n",
      "Train Epoch: 2 [11000/15683 (70%)]\tLoss: 0.409506\n",
      "Train Epoch: 2 [12000/15683 (76%)]\tLoss: 0.366993\n",
      "Train Epoch: 2 [13000/15683 (83%)]\tLoss: 0.380282\n",
      "Train Epoch: 2 [14000/15683 (89%)]\tLoss: 0.400992\n",
      "Train Epoch: 2 [15000/15683 (96%)]\tLoss: 0.274375\n",
      "Train Epoch: 3 [0/15683 (0%)]\tLoss: 0.450016\n",
      "Train Epoch: 3 [1000/15683 (6%)]\tLoss: 0.491023\n",
      "Train Epoch: 3 [2000/15683 (13%)]\tLoss: 0.317278\n",
      "Train Epoch: 3 [3000/15683 (19%)]\tLoss: 0.313057\n",
      "Train Epoch: 3 [4000/15683 (25%)]\tLoss: 0.452527\n",
      "Train Epoch: 3 [5000/15683 (32%)]\tLoss: 0.346363\n",
      "Train Epoch: 3 [6000/15683 (38%)]\tLoss: 0.309261\n",
      "Train Epoch: 3 [7000/15683 (45%)]\tLoss: 0.407017\n",
      "Train Epoch: 3 [8000/15683 (51%)]\tLoss: 0.392037\n",
      "Train Epoch: 3 [9000/15683 (57%)]\tLoss: 0.273321\n",
      "Train Epoch: 3 [10000/15683 (64%)]\tLoss: 0.456685\n",
      "Train Epoch: 3 [11000/15683 (70%)]\tLoss: 0.276265\n",
      "Train Epoch: 3 [12000/15683 (76%)]\tLoss: 0.412256\n",
      "Train Epoch: 3 [13000/15683 (83%)]\tLoss: 0.212065\n",
      "Train Epoch: 3 [14000/15683 (89%)]\tLoss: 0.451499\n",
      "Train Epoch: 3 [15000/15683 (96%)]\tLoss: 0.316952\n",
      "Train Epoch: 4 [0/15683 (0%)]\tLoss: 0.551160\n",
      "Train Epoch: 4 [1000/15683 (6%)]\tLoss: 0.304160\n",
      "Train Epoch: 4 [2000/15683 (13%)]\tLoss: 0.313461\n",
      "Train Epoch: 4 [3000/15683 (19%)]\tLoss: 0.361992\n",
      "Train Epoch: 4 [4000/15683 (25%)]\tLoss: 0.396920\n",
      "Train Epoch: 4 [5000/15683 (32%)]\tLoss: 0.336963\n",
      "Train Epoch: 4 [6000/15683 (38%)]\tLoss: 0.380273\n",
      "Train Epoch: 4 [7000/15683 (45%)]\tLoss: 0.303708\n",
      "Train Epoch: 4 [8000/15683 (51%)]\tLoss: 0.577995\n",
      "Train Epoch: 4 [9000/15683 (57%)]\tLoss: 0.561239\n",
      "Train Epoch: 4 [10000/15683 (64%)]\tLoss: 0.288872\n",
      "Train Epoch: 4 [11000/15683 (70%)]\tLoss: 0.358817\n",
      "Train Epoch: 4 [12000/15683 (76%)]\tLoss: 0.444543\n",
      "Train Epoch: 4 [13000/15683 (83%)]\tLoss: 0.249083\n",
      "Train Epoch: 4 [14000/15683 (89%)]\tLoss: 0.469381\n",
      "Train Epoch: 4 [15000/15683 (96%)]\tLoss: 0.361910\n",
      "Train Epoch: 5 [0/15683 (0%)]\tLoss: 0.353272\n",
      "Train Epoch: 5 [1000/15683 (6%)]\tLoss: 0.416828\n",
      "Train Epoch: 5 [2000/15683 (13%)]\tLoss: 0.302029\n",
      "Train Epoch: 5 [3000/15683 (19%)]\tLoss: 0.418976\n",
      "Train Epoch: 5 [4000/15683 (25%)]\tLoss: 0.363276\n",
      "Train Epoch: 5 [5000/15683 (32%)]\tLoss: 0.357861\n",
      "Train Epoch: 5 [6000/15683 (38%)]\tLoss: 0.545355\n",
      "Train Epoch: 5 [7000/15683 (45%)]\tLoss: 0.315414\n",
      "Train Epoch: 5 [8000/15683 (51%)]\tLoss: 0.428583\n",
      "Train Epoch: 5 [9000/15683 (57%)]\tLoss: 0.336648\n",
      "Train Epoch: 5 [10000/15683 (64%)]\tLoss: 0.292364\n",
      "Train Epoch: 5 [11000/15683 (70%)]\tLoss: 0.523068\n",
      "Train Epoch: 5 [12000/15683 (76%)]\tLoss: 0.460662\n",
      "Train Epoch: 5 [13000/15683 (83%)]\tLoss: 0.399388\n",
      "Train Epoch: 5 [14000/15683 (89%)]\tLoss: 0.518051\n",
      "Train Epoch: 5 [15000/15683 (96%)]\tLoss: 0.462501\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8995, Accuracy: 7647/10000 (76%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/14254 (0%)]\tLoss: 0.570970\n",
      "Train Epoch: 1 [1000/14254 (7%)]\tLoss: 0.446992\n",
      "Train Epoch: 1 [2000/14254 (14%)]\tLoss: 0.474452\n",
      "Train Epoch: 1 [3000/14254 (21%)]\tLoss: 0.473718\n",
      "Train Epoch: 1 [4000/14254 (28%)]\tLoss: 0.464674\n",
      "Train Epoch: 1 [5000/14254 (35%)]\tLoss: 0.494546\n",
      "Train Epoch: 1 [6000/14254 (42%)]\tLoss: 0.354021\n",
      "Train Epoch: 1 [7000/14254 (49%)]\tLoss: 0.482709\n",
      "Train Epoch: 1 [8000/14254 (56%)]\tLoss: 0.531339\n",
      "Train Epoch: 1 [9000/14254 (63%)]\tLoss: 0.371546\n",
      "Train Epoch: 1 [10000/14254 (70%)]\tLoss: 0.449590\n",
      "Train Epoch: 1 [11000/14254 (77%)]\tLoss: 0.333346\n",
      "Train Epoch: 1 [12000/14254 (84%)]\tLoss: 0.302760\n",
      "Train Epoch: 1 [13000/14254 (91%)]\tLoss: 0.496056\n",
      "Train Epoch: 1 [14000/14254 (98%)]\tLoss: 0.367106\n",
      "Train Epoch: 2 [0/14254 (0%)]\tLoss: 0.417357\n",
      "Train Epoch: 2 [1000/14254 (7%)]\tLoss: 0.301983\n",
      "Train Epoch: 2 [2000/14254 (14%)]\tLoss: 0.391096\n",
      "Train Epoch: 2 [3000/14254 (21%)]\tLoss: 0.251235\n",
      "Train Epoch: 2 [4000/14254 (28%)]\tLoss: 0.404506\n",
      "Train Epoch: 2 [5000/14254 (35%)]\tLoss: 0.304794\n",
      "Train Epoch: 2 [6000/14254 (42%)]\tLoss: 0.357487\n",
      "Train Epoch: 2 [7000/14254 (49%)]\tLoss: 0.560876\n",
      "Train Epoch: 2 [8000/14254 (56%)]\tLoss: 0.451891\n",
      "Train Epoch: 2 [9000/14254 (63%)]\tLoss: 0.419033\n",
      "Train Epoch: 2 [10000/14254 (70%)]\tLoss: 0.349140\n",
      "Train Epoch: 2 [11000/14254 (77%)]\tLoss: 0.431205\n",
      "Train Epoch: 2 [12000/14254 (84%)]\tLoss: 0.392077\n",
      "Train Epoch: 2 [13000/14254 (91%)]\tLoss: 0.394379\n",
      "Train Epoch: 2 [14000/14254 (98%)]\tLoss: 0.314497\n",
      "Train Epoch: 3 [0/14254 (0%)]\tLoss: 0.556251\n",
      "Train Epoch: 3 [1000/14254 (7%)]\tLoss: 0.465534\n",
      "Train Epoch: 3 [2000/14254 (14%)]\tLoss: 0.383266\n",
      "Train Epoch: 3 [3000/14254 (21%)]\tLoss: 0.353567\n",
      "Train Epoch: 3 [4000/14254 (28%)]\tLoss: 0.242651\n",
      "Train Epoch: 3 [5000/14254 (35%)]\tLoss: 0.441715\n",
      "Train Epoch: 3 [6000/14254 (42%)]\tLoss: 0.325496\n",
      "Train Epoch: 3 [7000/14254 (49%)]\tLoss: 0.356526\n",
      "Train Epoch: 3 [8000/14254 (56%)]\tLoss: 0.455410\n",
      "Train Epoch: 3 [9000/14254 (63%)]\tLoss: 0.364814\n",
      "Train Epoch: 3 [10000/14254 (70%)]\tLoss: 0.369087\n",
      "Train Epoch: 3 [11000/14254 (77%)]\tLoss: 0.342997\n",
      "Train Epoch: 3 [12000/14254 (84%)]\tLoss: 0.614482\n",
      "Train Epoch: 3 [13000/14254 (91%)]\tLoss: 0.472328\n",
      "Train Epoch: 3 [14000/14254 (98%)]\tLoss: 0.339155\n",
      "Train Epoch: 4 [0/14254 (0%)]\tLoss: 0.305710\n",
      "Train Epoch: 4 [1000/14254 (7%)]\tLoss: 0.430603\n",
      "Train Epoch: 4 [2000/14254 (14%)]\tLoss: 0.342138\n",
      "Train Epoch: 4 [3000/14254 (21%)]\tLoss: 0.378218\n",
      "Train Epoch: 4 [4000/14254 (28%)]\tLoss: 0.433829\n",
      "Train Epoch: 4 [5000/14254 (35%)]\tLoss: 0.374617\n",
      "Train Epoch: 4 [6000/14254 (42%)]\tLoss: 0.325316\n",
      "Train Epoch: 4 [7000/14254 (49%)]\tLoss: 0.382348\n",
      "Train Epoch: 4 [8000/14254 (56%)]\tLoss: 0.305087\n",
      "Train Epoch: 4 [9000/14254 (63%)]\tLoss: 0.391986\n",
      "Train Epoch: 4 [10000/14254 (70%)]\tLoss: 0.325493\n",
      "Train Epoch: 4 [11000/14254 (77%)]\tLoss: 0.404209\n",
      "Train Epoch: 4 [12000/14254 (84%)]\tLoss: 0.312365\n",
      "Train Epoch: 4 [13000/14254 (91%)]\tLoss: 0.415978\n",
      "Train Epoch: 4 [14000/14254 (98%)]\tLoss: 0.314599\n",
      "Train Epoch: 5 [0/14254 (0%)]\tLoss: 0.391668\n",
      "Train Epoch: 5 [1000/14254 (7%)]\tLoss: 0.287205\n",
      "Train Epoch: 5 [2000/14254 (14%)]\tLoss: 0.345500\n",
      "Train Epoch: 5 [3000/14254 (21%)]\tLoss: 0.274142\n",
      "Train Epoch: 5 [4000/14254 (28%)]\tLoss: 0.364931\n",
      "Train Epoch: 5 [5000/14254 (35%)]\tLoss: 0.471478\n",
      "Train Epoch: 5 [6000/14254 (42%)]\tLoss: 0.261167\n",
      "Train Epoch: 5 [7000/14254 (49%)]\tLoss: 0.470513\n",
      "Train Epoch: 5 [8000/14254 (56%)]\tLoss: 0.392141\n",
      "Train Epoch: 5 [9000/14254 (63%)]\tLoss: 0.397208\n",
      "Train Epoch: 5 [10000/14254 (70%)]\tLoss: 0.255568\n",
      "Train Epoch: 5 [11000/14254 (77%)]\tLoss: 0.424457\n",
      "Train Epoch: 5 [12000/14254 (84%)]\tLoss: 0.333975\n",
      "Train Epoch: 5 [13000/14254 (91%)]\tLoss: 0.483326\n",
      "Train Epoch: 5 [14000/14254 (98%)]\tLoss: 0.303547\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/13824 (0%)]\tLoss: 0.487225\n",
      "Train Epoch: 1 [1000/13824 (7%)]\tLoss: 0.166436\n",
      "Train Epoch: 1 [2000/13824 (14%)]\tLoss: 0.166617\n",
      "Train Epoch: 1 [3000/13824 (22%)]\tLoss: 0.284050\n",
      "Train Epoch: 1 [4000/13824 (29%)]\tLoss: 0.220443\n",
      "Train Epoch: 1 [5000/13824 (36%)]\tLoss: 0.480312\n",
      "Train Epoch: 1 [6000/13824 (43%)]\tLoss: 0.184764\n",
      "Train Epoch: 1 [7000/13824 (50%)]\tLoss: 0.336176\n",
      "Train Epoch: 1 [8000/13824 (58%)]\tLoss: 0.282830\n",
      "Train Epoch: 1 [9000/13824 (65%)]\tLoss: 0.220823\n",
      "Train Epoch: 1 [10000/13824 (72%)]\tLoss: 0.248418\n",
      "Train Epoch: 1 [11000/13824 (79%)]\tLoss: 0.195550\n",
      "Train Epoch: 1 [12000/13824 (86%)]\tLoss: 0.278087\n",
      "Train Epoch: 1 [13000/13824 (94%)]\tLoss: 0.148529\n",
      "Train Epoch: 2 [0/13824 (0%)]\tLoss: 0.283283\n",
      "Train Epoch: 2 [1000/13824 (7%)]\tLoss: 0.290456\n",
      "Train Epoch: 2 [2000/13824 (14%)]\tLoss: 0.307800\n",
      "Train Epoch: 2 [3000/13824 (22%)]\tLoss: 0.364836\n",
      "Train Epoch: 2 [4000/13824 (29%)]\tLoss: 0.340185\n",
      "Train Epoch: 2 [5000/13824 (36%)]\tLoss: 0.309713\n",
      "Train Epoch: 2 [6000/13824 (43%)]\tLoss: 0.211028\n",
      "Train Epoch: 2 [7000/13824 (50%)]\tLoss: 0.255827\n",
      "Train Epoch: 2 [8000/13824 (58%)]\tLoss: 0.177564\n",
      "Train Epoch: 2 [9000/13824 (65%)]\tLoss: 0.275212\n",
      "Train Epoch: 2 [10000/13824 (72%)]\tLoss: 0.109391\n",
      "Train Epoch: 2 [11000/13824 (79%)]\tLoss: 0.265225\n",
      "Train Epoch: 2 [12000/13824 (86%)]\tLoss: 0.074499\n",
      "Train Epoch: 2 [13000/13824 (94%)]\tLoss: 0.251507\n",
      "Train Epoch: 3 [0/13824 (0%)]\tLoss: 0.315049\n",
      "Train Epoch: 3 [1000/13824 (7%)]\tLoss: 0.272347\n",
      "Train Epoch: 3 [2000/13824 (14%)]\tLoss: 0.230155\n",
      "Train Epoch: 3 [3000/13824 (22%)]\tLoss: 0.220376\n",
      "Train Epoch: 3 [4000/13824 (29%)]\tLoss: 0.203096\n",
      "Train Epoch: 3 [5000/13824 (36%)]\tLoss: 0.338071\n",
      "Train Epoch: 3 [6000/13824 (43%)]\tLoss: 0.295189\n",
      "Train Epoch: 3 [7000/13824 (50%)]\tLoss: 0.413459\n",
      "Train Epoch: 3 [8000/13824 (58%)]\tLoss: 0.256212\n",
      "Train Epoch: 3 [9000/13824 (65%)]\tLoss: 0.343596\n",
      "Train Epoch: 3 [10000/13824 (72%)]\tLoss: 0.293877\n",
      "Train Epoch: 3 [11000/13824 (79%)]\tLoss: 0.216023\n",
      "Train Epoch: 3 [12000/13824 (86%)]\tLoss: 0.303543\n",
      "Train Epoch: 3 [13000/13824 (94%)]\tLoss: 0.175567\n",
      "Train Epoch: 4 [0/13824 (0%)]\tLoss: 0.332357\n",
      "Train Epoch: 4 [1000/13824 (7%)]\tLoss: 0.259078\n",
      "Train Epoch: 4 [2000/13824 (14%)]\tLoss: 0.248872\n",
      "Train Epoch: 4 [3000/13824 (22%)]\tLoss: 0.214572\n",
      "Train Epoch: 4 [4000/13824 (29%)]\tLoss: 0.208699\n",
      "Train Epoch: 4 [5000/13824 (36%)]\tLoss: 0.218073\n",
      "Train Epoch: 4 [6000/13824 (43%)]\tLoss: 0.266940\n",
      "Train Epoch: 4 [7000/13824 (50%)]\tLoss: 0.268808\n",
      "Train Epoch: 4 [8000/13824 (58%)]\tLoss: 0.228556\n",
      "Train Epoch: 4 [9000/13824 (65%)]\tLoss: 0.258325\n",
      "Train Epoch: 4 [10000/13824 (72%)]\tLoss: 0.280093\n",
      "Train Epoch: 4 [11000/13824 (79%)]\tLoss: 0.321820\n",
      "Train Epoch: 4 [12000/13824 (86%)]\tLoss: 0.347891\n",
      "Train Epoch: 4 [13000/13824 (94%)]\tLoss: 0.153315\n",
      "Train Epoch: 5 [0/13824 (0%)]\tLoss: 0.156578\n",
      "Train Epoch: 5 [1000/13824 (7%)]\tLoss: 0.325193\n",
      "Train Epoch: 5 [2000/13824 (14%)]\tLoss: 0.152502\n",
      "Train Epoch: 5 [3000/13824 (22%)]\tLoss: 0.226399\n",
      "Train Epoch: 5 [4000/13824 (29%)]\tLoss: 0.253156\n",
      "Train Epoch: 5 [5000/13824 (36%)]\tLoss: 0.199305\n",
      "Train Epoch: 5 [6000/13824 (43%)]\tLoss: 0.273640\n",
      "Train Epoch: 5 [7000/13824 (50%)]\tLoss: 0.301462\n",
      "Train Epoch: 5 [8000/13824 (58%)]\tLoss: 0.411109\n",
      "Train Epoch: 5 [9000/13824 (65%)]\tLoss: 0.364985\n",
      "Train Epoch: 5 [10000/13824 (72%)]\tLoss: 0.429126\n",
      "Train Epoch: 5 [11000/13824 (79%)]\tLoss: 0.248946\n",
      "Train Epoch: 5 [12000/13824 (86%)]\tLoss: 0.215925\n",
      "Train Epoch: 5 [13000/13824 (94%)]\tLoss: 0.210013\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/16239 (0%)]\tLoss: 0.483460\n",
      "Train Epoch: 1 [1000/16239 (6%)]\tLoss: 0.338994\n",
      "Train Epoch: 1 [2000/16239 (12%)]\tLoss: 0.382175\n",
      "Train Epoch: 1 [3000/16239 (18%)]\tLoss: 0.399458\n",
      "Train Epoch: 1 [4000/16239 (25%)]\tLoss: 0.224457\n",
      "Train Epoch: 1 [5000/16239 (31%)]\tLoss: 0.392494\n",
      "Train Epoch: 1 [6000/16239 (37%)]\tLoss: 0.507071\n",
      "Train Epoch: 1 [7000/16239 (43%)]\tLoss: 0.309534\n",
      "Train Epoch: 1 [8000/16239 (49%)]\tLoss: 0.473326\n",
      "Train Epoch: 1 [9000/16239 (55%)]\tLoss: 0.445108\n",
      "Train Epoch: 1 [10000/16239 (61%)]\tLoss: 0.354115\n",
      "Train Epoch: 1 [11000/16239 (67%)]\tLoss: 0.473491\n",
      "Train Epoch: 1 [12000/16239 (74%)]\tLoss: 0.306668\n",
      "Train Epoch: 1 [13000/16239 (80%)]\tLoss: 0.355133\n",
      "Train Epoch: 1 [14000/16239 (86%)]\tLoss: 0.560305\n",
      "Train Epoch: 1 [15000/16239 (92%)]\tLoss: 0.488833\n",
      "Train Epoch: 1 [16000/16239 (98%)]\tLoss: 0.296044\n",
      "Train Epoch: 2 [0/16239 (0%)]\tLoss: 0.344131\n",
      "Train Epoch: 2 [1000/16239 (6%)]\tLoss: 0.312394\n",
      "Train Epoch: 2 [2000/16239 (12%)]\tLoss: 0.569104\n",
      "Train Epoch: 2 [3000/16239 (18%)]\tLoss: 0.346378\n",
      "Train Epoch: 2 [4000/16239 (25%)]\tLoss: 0.394703\n",
      "Train Epoch: 2 [5000/16239 (31%)]\tLoss: 0.381380\n",
      "Train Epoch: 2 [6000/16239 (37%)]\tLoss: 0.401046\n",
      "Train Epoch: 2 [7000/16239 (43%)]\tLoss: 0.355013\n",
      "Train Epoch: 2 [8000/16239 (49%)]\tLoss: 0.329017\n",
      "Train Epoch: 2 [9000/16239 (55%)]\tLoss: 0.277207\n",
      "Train Epoch: 2 [10000/16239 (61%)]\tLoss: 0.304379\n",
      "Train Epoch: 2 [11000/16239 (67%)]\tLoss: 0.462553\n",
      "Train Epoch: 2 [12000/16239 (74%)]\tLoss: 0.371460\n",
      "Train Epoch: 2 [13000/16239 (80%)]\tLoss: 0.444298\n",
      "Train Epoch: 2 [14000/16239 (86%)]\tLoss: 0.320000\n",
      "Train Epoch: 2 [15000/16239 (92%)]\tLoss: 0.316616\n",
      "Train Epoch: 2 [16000/16239 (98%)]\tLoss: 0.295096\n",
      "Train Epoch: 3 [0/16239 (0%)]\tLoss: 0.300682\n",
      "Train Epoch: 3 [1000/16239 (6%)]\tLoss: 0.473613\n",
      "Train Epoch: 3 [2000/16239 (12%)]\tLoss: 0.359209\n",
      "Train Epoch: 3 [3000/16239 (18%)]\tLoss: 0.356533\n",
      "Train Epoch: 3 [4000/16239 (25%)]\tLoss: 0.397467\n",
      "Train Epoch: 3 [5000/16239 (31%)]\tLoss: 0.428805\n",
      "Train Epoch: 3 [6000/16239 (37%)]\tLoss: 0.291297\n",
      "Train Epoch: 3 [7000/16239 (43%)]\tLoss: 0.288852\n",
      "Train Epoch: 3 [8000/16239 (49%)]\tLoss: 0.283514\n",
      "Train Epoch: 3 [9000/16239 (55%)]\tLoss: 0.372490\n",
      "Train Epoch: 3 [10000/16239 (61%)]\tLoss: 0.389539\n",
      "Train Epoch: 3 [11000/16239 (67%)]\tLoss: 0.238885\n",
      "Train Epoch: 3 [12000/16239 (74%)]\tLoss: 0.388605\n",
      "Train Epoch: 3 [13000/16239 (80%)]\tLoss: 0.360465\n",
      "Train Epoch: 3 [14000/16239 (86%)]\tLoss: 0.290327\n",
      "Train Epoch: 3 [15000/16239 (92%)]\tLoss: 0.440699\n",
      "Train Epoch: 3 [16000/16239 (98%)]\tLoss: 0.360348\n",
      "Train Epoch: 4 [0/16239 (0%)]\tLoss: 0.640538\n",
      "Train Epoch: 4 [1000/16239 (6%)]\tLoss: 0.395195\n",
      "Train Epoch: 4 [2000/16239 (12%)]\tLoss: 0.245754\n",
      "Train Epoch: 4 [3000/16239 (18%)]\tLoss: 0.434814\n",
      "Train Epoch: 4 [4000/16239 (25%)]\tLoss: 0.489199\n",
      "Train Epoch: 4 [5000/16239 (31%)]\tLoss: 0.366152\n",
      "Train Epoch: 4 [6000/16239 (37%)]\tLoss: 0.372799\n",
      "Train Epoch: 4 [7000/16239 (43%)]\tLoss: 0.438085\n",
      "Train Epoch: 4 [8000/16239 (49%)]\tLoss: 0.347883\n",
      "Train Epoch: 4 [9000/16239 (55%)]\tLoss: 0.502520\n",
      "Train Epoch: 4 [10000/16239 (61%)]\tLoss: 0.379232\n",
      "Train Epoch: 4 [11000/16239 (67%)]\tLoss: 0.368788\n",
      "Train Epoch: 4 [12000/16239 (74%)]\tLoss: 0.280334\n",
      "Train Epoch: 4 [13000/16239 (80%)]\tLoss: 0.389990\n",
      "Train Epoch: 4 [14000/16239 (86%)]\tLoss: 0.363137\n",
      "Train Epoch: 4 [15000/16239 (92%)]\tLoss: 0.374826\n",
      "Train Epoch: 4 [16000/16239 (98%)]\tLoss: 0.273682\n",
      "Train Epoch: 5 [0/16239 (0%)]\tLoss: 0.380622\n",
      "Train Epoch: 5 [1000/16239 (6%)]\tLoss: 0.367354\n",
      "Train Epoch: 5 [2000/16239 (12%)]\tLoss: 0.476568\n",
      "Train Epoch: 5 [3000/16239 (18%)]\tLoss: 0.350463\n",
      "Train Epoch: 5 [4000/16239 (25%)]\tLoss: 0.359069\n",
      "Train Epoch: 5 [5000/16239 (31%)]\tLoss: 0.273150\n",
      "Train Epoch: 5 [6000/16239 (37%)]\tLoss: 0.420859\n",
      "Train Epoch: 5 [7000/16239 (43%)]\tLoss: 0.384637\n",
      "Train Epoch: 5 [8000/16239 (49%)]\tLoss: 0.453690\n",
      "Train Epoch: 5 [9000/16239 (55%)]\tLoss: 0.361858\n",
      "Train Epoch: 5 [10000/16239 (61%)]\tLoss: 0.420128\n",
      "Train Epoch: 5 [11000/16239 (67%)]\tLoss: 0.473934\n",
      "Train Epoch: 5 [12000/16239 (74%)]\tLoss: 0.319242\n",
      "Train Epoch: 5 [13000/16239 (80%)]\tLoss: 0.289766\n",
      "Train Epoch: 5 [14000/16239 (86%)]\tLoss: 0.557364\n",
      "Train Epoch: 5 [15000/16239 (92%)]\tLoss: 0.293386\n",
      "Train Epoch: 5 [16000/16239 (98%)]\tLoss: 0.504581\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/15683 (0%)]\tLoss: 0.334069\n",
      "Train Epoch: 1 [1000/15683 (6%)]\tLoss: 0.496014\n",
      "Train Epoch: 1 [2000/15683 (13%)]\tLoss: 0.333260\n",
      "Train Epoch: 1 [3000/15683 (19%)]\tLoss: 0.452055\n",
      "Train Epoch: 1 [4000/15683 (25%)]\tLoss: 0.347273\n",
      "Train Epoch: 1 [5000/15683 (32%)]\tLoss: 0.382226\n",
      "Train Epoch: 1 [6000/15683 (38%)]\tLoss: 0.379174\n",
      "Train Epoch: 1 [7000/15683 (45%)]\tLoss: 0.325694\n",
      "Train Epoch: 1 [8000/15683 (51%)]\tLoss: 0.458054\n",
      "Train Epoch: 1 [9000/15683 (57%)]\tLoss: 0.288008\n",
      "Train Epoch: 1 [10000/15683 (64%)]\tLoss: 0.252262\n",
      "Train Epoch: 1 [11000/15683 (70%)]\tLoss: 0.225341\n",
      "Train Epoch: 1 [12000/15683 (76%)]\tLoss: 0.499996\n",
      "Train Epoch: 1 [13000/15683 (83%)]\tLoss: 0.450623\n",
      "Train Epoch: 1 [14000/15683 (89%)]\tLoss: 0.398467\n",
      "Train Epoch: 1 [15000/15683 (96%)]\tLoss: 0.361846\n",
      "Train Epoch: 2 [0/15683 (0%)]\tLoss: 0.452923\n",
      "Train Epoch: 2 [1000/15683 (6%)]\tLoss: 0.391080\n",
      "Train Epoch: 2 [2000/15683 (13%)]\tLoss: 0.370958\n",
      "Train Epoch: 2 [3000/15683 (19%)]\tLoss: 0.440565\n",
      "Train Epoch: 2 [4000/15683 (25%)]\tLoss: 0.517935\n",
      "Train Epoch: 2 [5000/15683 (32%)]\tLoss: 0.307659\n",
      "Train Epoch: 2 [6000/15683 (38%)]\tLoss: 0.397269\n",
      "Train Epoch: 2 [7000/15683 (45%)]\tLoss: 0.513932\n",
      "Train Epoch: 2 [8000/15683 (51%)]\tLoss: 0.389474\n",
      "Train Epoch: 2 [9000/15683 (57%)]\tLoss: 0.350118\n",
      "Train Epoch: 2 [10000/15683 (64%)]\tLoss: 0.262875\n",
      "Train Epoch: 2 [11000/15683 (70%)]\tLoss: 0.366222\n",
      "Train Epoch: 2 [12000/15683 (76%)]\tLoss: 0.305145\n",
      "Train Epoch: 2 [13000/15683 (83%)]\tLoss: 0.509882\n",
      "Train Epoch: 2 [14000/15683 (89%)]\tLoss: 0.305198\n",
      "Train Epoch: 2 [15000/15683 (96%)]\tLoss: 0.282222\n",
      "Train Epoch: 3 [0/15683 (0%)]\tLoss: 0.441483\n",
      "Train Epoch: 3 [1000/15683 (6%)]\tLoss: 0.271212\n",
      "Train Epoch: 3 [2000/15683 (13%)]\tLoss: 0.595356\n",
      "Train Epoch: 3 [3000/15683 (19%)]\tLoss: 0.461568\n",
      "Train Epoch: 3 [4000/15683 (25%)]\tLoss: 0.337985\n",
      "Train Epoch: 3 [5000/15683 (32%)]\tLoss: 0.422035\n",
      "Train Epoch: 3 [6000/15683 (38%)]\tLoss: 0.306858\n",
      "Train Epoch: 3 [7000/15683 (45%)]\tLoss: 0.353374\n",
      "Train Epoch: 3 [8000/15683 (51%)]\tLoss: 0.438603\n",
      "Train Epoch: 3 [9000/15683 (57%)]\tLoss: 0.323970\n",
      "Train Epoch: 3 [10000/15683 (64%)]\tLoss: 0.369798\n",
      "Train Epoch: 3 [11000/15683 (70%)]\tLoss: 0.405061\n",
      "Train Epoch: 3 [12000/15683 (76%)]\tLoss: 0.384463\n",
      "Train Epoch: 3 [13000/15683 (83%)]\tLoss: 0.355597\n",
      "Train Epoch: 3 [14000/15683 (89%)]\tLoss: 0.337589\n",
      "Train Epoch: 3 [15000/15683 (96%)]\tLoss: 0.404126\n",
      "Train Epoch: 4 [0/15683 (0%)]\tLoss: 0.268773\n",
      "Train Epoch: 4 [1000/15683 (6%)]\tLoss: 0.285437\n",
      "Train Epoch: 4 [2000/15683 (13%)]\tLoss: 0.375872\n",
      "Train Epoch: 4 [3000/15683 (19%)]\tLoss: 0.337633\n",
      "Train Epoch: 4 [4000/15683 (25%)]\tLoss: 0.444737\n",
      "Train Epoch: 4 [5000/15683 (32%)]\tLoss: 0.272926\n",
      "Train Epoch: 4 [6000/15683 (38%)]\tLoss: 0.558358\n",
      "Train Epoch: 4 [7000/15683 (45%)]\tLoss: 0.384660\n",
      "Train Epoch: 4 [8000/15683 (51%)]\tLoss: 0.277388\n",
      "Train Epoch: 4 [9000/15683 (57%)]\tLoss: 0.510586\n",
      "Train Epoch: 4 [10000/15683 (64%)]\tLoss: 0.561820\n",
      "Train Epoch: 4 [11000/15683 (70%)]\tLoss: 0.343697\n",
      "Train Epoch: 4 [12000/15683 (76%)]\tLoss: 0.343251\n",
      "Train Epoch: 4 [13000/15683 (83%)]\tLoss: 0.301846\n",
      "Train Epoch: 4 [14000/15683 (89%)]\tLoss: 0.416419\n",
      "Train Epoch: 4 [15000/15683 (96%)]\tLoss: 0.327243\n",
      "Train Epoch: 5 [0/15683 (0%)]\tLoss: 0.291777\n",
      "Train Epoch: 5 [1000/15683 (6%)]\tLoss: 0.377424\n",
      "Train Epoch: 5 [2000/15683 (13%)]\tLoss: 0.375026\n",
      "Train Epoch: 5 [3000/15683 (19%)]\tLoss: 0.267915\n",
      "Train Epoch: 5 [4000/15683 (25%)]\tLoss: 0.447482\n",
      "Train Epoch: 5 [5000/15683 (32%)]\tLoss: 0.305454\n",
      "Train Epoch: 5 [6000/15683 (38%)]\tLoss: 0.239799\n",
      "Train Epoch: 5 [7000/15683 (45%)]\tLoss: 0.304934\n",
      "Train Epoch: 5 [8000/15683 (51%)]\tLoss: 0.279727\n",
      "Train Epoch: 5 [9000/15683 (57%)]\tLoss: 0.481119\n",
      "Train Epoch: 5 [10000/15683 (64%)]\tLoss: 0.288362\n",
      "Train Epoch: 5 [11000/15683 (70%)]\tLoss: 0.319429\n",
      "Train Epoch: 5 [12000/15683 (76%)]\tLoss: 0.269219\n",
      "Train Epoch: 5 [13000/15683 (83%)]\tLoss: 0.382847\n",
      "Train Epoch: 5 [14000/15683 (89%)]\tLoss: 0.325953\n",
      "Train Epoch: 5 [15000/15683 (96%)]\tLoss: 0.434839\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9637, Accuracy: 7530/10000 (75%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/12367 (0%)]\tLoss: 0.441922\n",
      "Train Epoch: 1 [1000/12367 (8%)]\tLoss: 0.435613\n",
      "Train Epoch: 1 [2000/12367 (16%)]\tLoss: 0.340818\n",
      "Train Epoch: 1 [3000/12367 (24%)]\tLoss: 0.424996\n",
      "Train Epoch: 1 [4000/12367 (32%)]\tLoss: 0.520435\n",
      "Train Epoch: 1 [5000/12367 (40%)]\tLoss: 0.489197\n",
      "Train Epoch: 1 [6000/12367 (48%)]\tLoss: 0.556220\n",
      "Train Epoch: 1 [7000/12367 (56%)]\tLoss: 0.415763\n",
      "Train Epoch: 1 [8000/12367 (65%)]\tLoss: 0.418016\n",
      "Train Epoch: 1 [9000/12367 (73%)]\tLoss: 0.541807\n",
      "Train Epoch: 1 [10000/12367 (81%)]\tLoss: 0.279123\n",
      "Train Epoch: 1 [11000/12367 (89%)]\tLoss: 0.388670\n",
      "Train Epoch: 1 [12000/12367 (97%)]\tLoss: 0.437669\n",
      "Train Epoch: 2 [0/12367 (0%)]\tLoss: 0.387333\n",
      "Train Epoch: 2 [1000/12367 (8%)]\tLoss: 0.343888\n",
      "Train Epoch: 2 [2000/12367 (16%)]\tLoss: 0.575024\n",
      "Train Epoch: 2 [3000/12367 (24%)]\tLoss: 0.373011\n",
      "Train Epoch: 2 [4000/12367 (32%)]\tLoss: 0.500693\n",
      "Train Epoch: 2 [5000/12367 (40%)]\tLoss: 0.368681\n",
      "Train Epoch: 2 [6000/12367 (48%)]\tLoss: 0.463415\n",
      "Train Epoch: 2 [7000/12367 (56%)]\tLoss: 0.467279\n",
      "Train Epoch: 2 [8000/12367 (65%)]\tLoss: 0.450366\n",
      "Train Epoch: 2 [9000/12367 (73%)]\tLoss: 0.429269\n",
      "Train Epoch: 2 [10000/12367 (81%)]\tLoss: 0.441090\n",
      "Train Epoch: 2 [11000/12367 (89%)]\tLoss: 0.449583\n",
      "Train Epoch: 2 [12000/12367 (97%)]\tLoss: 0.481709\n",
      "Train Epoch: 3 [0/12367 (0%)]\tLoss: 0.502056\n",
      "Train Epoch: 3 [1000/12367 (8%)]\tLoss: 0.391383\n",
      "Train Epoch: 3 [2000/12367 (16%)]\tLoss: 0.378580\n",
      "Train Epoch: 3 [3000/12367 (24%)]\tLoss: 0.294797\n",
      "Train Epoch: 3 [4000/12367 (32%)]\tLoss: 0.332988\n",
      "Train Epoch: 3 [5000/12367 (40%)]\tLoss: 0.398498\n",
      "Train Epoch: 3 [6000/12367 (48%)]\tLoss: 0.449262\n",
      "Train Epoch: 3 [7000/12367 (56%)]\tLoss: 0.567269\n",
      "Train Epoch: 3 [8000/12367 (65%)]\tLoss: 0.320872\n",
      "Train Epoch: 3 [9000/12367 (73%)]\tLoss: 0.358956\n",
      "Train Epoch: 3 [10000/12367 (81%)]\tLoss: 0.457324\n",
      "Train Epoch: 3 [11000/12367 (89%)]\tLoss: 0.458647\n",
      "Train Epoch: 3 [12000/12367 (97%)]\tLoss: 0.432452\n",
      "Train Epoch: 4 [0/12367 (0%)]\tLoss: 0.345046\n",
      "Train Epoch: 4 [1000/12367 (8%)]\tLoss: 0.478638\n",
      "Train Epoch: 4 [2000/12367 (16%)]\tLoss: 0.429474\n",
      "Train Epoch: 4 [3000/12367 (24%)]\tLoss: 0.285904\n",
      "Train Epoch: 4 [4000/12367 (32%)]\tLoss: 0.454565\n",
      "Train Epoch: 4 [5000/12367 (40%)]\tLoss: 0.333513\n",
      "Train Epoch: 4 [6000/12367 (48%)]\tLoss: 0.502421\n",
      "Train Epoch: 4 [7000/12367 (56%)]\tLoss: 0.467465\n",
      "Train Epoch: 4 [8000/12367 (65%)]\tLoss: 0.520440\n",
      "Train Epoch: 4 [9000/12367 (73%)]\tLoss: 0.399879\n",
      "Train Epoch: 4 [10000/12367 (81%)]\tLoss: 0.351694\n",
      "Train Epoch: 4 [11000/12367 (89%)]\tLoss: 0.642713\n",
      "Train Epoch: 4 [12000/12367 (97%)]\tLoss: 0.272878\n",
      "Train Epoch: 5 [0/12367 (0%)]\tLoss: 0.314861\n",
      "Train Epoch: 5 [1000/12367 (8%)]\tLoss: 0.502513\n",
      "Train Epoch: 5 [2000/12367 (16%)]\tLoss: 0.378192\n",
      "Train Epoch: 5 [3000/12367 (24%)]\tLoss: 0.381863\n",
      "Train Epoch: 5 [4000/12367 (32%)]\tLoss: 0.335587\n",
      "Train Epoch: 5 [5000/12367 (40%)]\tLoss: 0.389286\n",
      "Train Epoch: 5 [6000/12367 (48%)]\tLoss: 0.394943\n",
      "Train Epoch: 5 [7000/12367 (56%)]\tLoss: 0.260494\n",
      "Train Epoch: 5 [8000/12367 (65%)]\tLoss: 0.559693\n",
      "Train Epoch: 5 [9000/12367 (73%)]\tLoss: 0.306864\n",
      "Train Epoch: 5 [10000/12367 (81%)]\tLoss: 0.343539\n",
      "Train Epoch: 5 [11000/12367 (89%)]\tLoss: 0.404982\n",
      "Train Epoch: 5 [12000/12367 (97%)]\tLoss: 0.454064\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.630400\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.322126\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.326991\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.125673\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.201186\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.141754\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.170688\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.105576\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.181938\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.268595\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.168120\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.151533\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.273770\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.135542\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.147163\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.217965\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.226626\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.195825\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.093674\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.050734\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.150762\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.188317\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.166620\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.258911\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.110630\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.183271\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.192315\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.285928\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.189096\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.234340\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.093601\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.047254\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.127313\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.210851\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.215826\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.065199\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.084003\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.190913\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.265270\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.131453\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.252454\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.372118\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.329565\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.414319\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.224916\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.276232\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.234324\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.351700\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.234287\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.145034\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.437321\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.311965\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.188372\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.284059\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.263573\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.192175\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.216887\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.255529\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.204179\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.290982\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.181895\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.460559\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.202838\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.270591\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.182769\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.161745\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.285285\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.192367\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.130425\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.235465\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.131272\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.214190\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.273234\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.322401\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.311380\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/12288 (0%)]\tLoss: 0.299105\n",
      "Train Epoch: 1 [1000/12288 (8%)]\tLoss: 0.513914\n",
      "Train Epoch: 1 [2000/12288 (16%)]\tLoss: 0.354272\n",
      "Train Epoch: 1 [3000/12288 (24%)]\tLoss: 0.154394\n",
      "Train Epoch: 1 [4000/12288 (33%)]\tLoss: 0.267091\n",
      "Train Epoch: 1 [5000/12288 (41%)]\tLoss: 0.458812\n",
      "Train Epoch: 1 [6000/12288 (49%)]\tLoss: 0.332433\n",
      "Train Epoch: 1 [7000/12288 (57%)]\tLoss: 0.347545\n",
      "Train Epoch: 1 [8000/12288 (65%)]\tLoss: 0.334144\n",
      "Train Epoch: 1 [9000/12288 (73%)]\tLoss: 0.293301\n",
      "Train Epoch: 1 [10000/12288 (81%)]\tLoss: 0.345665\n",
      "Train Epoch: 1 [11000/12288 (89%)]\tLoss: 0.203004\n",
      "Train Epoch: 1 [12000/12288 (98%)]\tLoss: 0.350239\n",
      "Train Epoch: 2 [0/12288 (0%)]\tLoss: 0.324183\n",
      "Train Epoch: 2 [1000/12288 (8%)]\tLoss: 0.402089\n",
      "Train Epoch: 2 [2000/12288 (16%)]\tLoss: 0.326096\n",
      "Train Epoch: 2 [3000/12288 (24%)]\tLoss: 0.263973\n",
      "Train Epoch: 2 [4000/12288 (33%)]\tLoss: 0.460159\n",
      "Train Epoch: 2 [5000/12288 (41%)]\tLoss: 0.342553\n",
      "Train Epoch: 2 [6000/12288 (49%)]\tLoss: 0.186926\n",
      "Train Epoch: 2 [7000/12288 (57%)]\tLoss: 0.260150\n",
      "Train Epoch: 2 [8000/12288 (65%)]\tLoss: 0.222361\n",
      "Train Epoch: 2 [9000/12288 (73%)]\tLoss: 0.283862\n",
      "Train Epoch: 2 [10000/12288 (81%)]\tLoss: 0.236568\n",
      "Train Epoch: 2 [11000/12288 (89%)]\tLoss: 0.304420\n",
      "Train Epoch: 2 [12000/12288 (98%)]\tLoss: 0.278596\n",
      "Train Epoch: 3 [0/12288 (0%)]\tLoss: 0.211001\n",
      "Train Epoch: 3 [1000/12288 (8%)]\tLoss: 0.293202\n",
      "Train Epoch: 3 [2000/12288 (16%)]\tLoss: 0.293178\n",
      "Train Epoch: 3 [3000/12288 (24%)]\tLoss: 0.343901\n",
      "Train Epoch: 3 [4000/12288 (33%)]\tLoss: 0.357596\n",
      "Train Epoch: 3 [5000/12288 (41%)]\tLoss: 0.185184\n",
      "Train Epoch: 3 [6000/12288 (49%)]\tLoss: 0.268030\n",
      "Train Epoch: 3 [7000/12288 (57%)]\tLoss: 0.258875\n",
      "Train Epoch: 3 [8000/12288 (65%)]\tLoss: 0.357817\n",
      "Train Epoch: 3 [9000/12288 (73%)]\tLoss: 0.309789\n",
      "Train Epoch: 3 [10000/12288 (81%)]\tLoss: 0.347973\n",
      "Train Epoch: 3 [11000/12288 (89%)]\tLoss: 0.269426\n",
      "Train Epoch: 3 [12000/12288 (98%)]\tLoss: 0.372337\n",
      "Train Epoch: 4 [0/12288 (0%)]\tLoss: 0.338933\n",
      "Train Epoch: 4 [1000/12288 (8%)]\tLoss: 0.309628\n",
      "Train Epoch: 4 [2000/12288 (16%)]\tLoss: 0.320384\n",
      "Train Epoch: 4 [3000/12288 (24%)]\tLoss: 0.225160\n",
      "Train Epoch: 4 [4000/12288 (33%)]\tLoss: 0.390916\n",
      "Train Epoch: 4 [5000/12288 (41%)]\tLoss: 0.307029\n",
      "Train Epoch: 4 [6000/12288 (49%)]\tLoss: 0.298102\n",
      "Train Epoch: 4 [7000/12288 (57%)]\tLoss: 0.167832\n",
      "Train Epoch: 4 [8000/12288 (65%)]\tLoss: 0.254214\n",
      "Train Epoch: 4 [9000/12288 (73%)]\tLoss: 0.264102\n",
      "Train Epoch: 4 [10000/12288 (81%)]\tLoss: 0.273889\n",
      "Train Epoch: 4 [11000/12288 (89%)]\tLoss: 0.316308\n",
      "Train Epoch: 4 [12000/12288 (98%)]\tLoss: 0.323419\n",
      "Train Epoch: 5 [0/12288 (0%)]\tLoss: 0.356488\n",
      "Train Epoch: 5 [1000/12288 (8%)]\tLoss: 0.331591\n",
      "Train Epoch: 5 [2000/12288 (16%)]\tLoss: 0.384738\n",
      "Train Epoch: 5 [3000/12288 (24%)]\tLoss: 0.366020\n",
      "Train Epoch: 5 [4000/12288 (33%)]\tLoss: 0.270546\n",
      "Train Epoch: 5 [5000/12288 (41%)]\tLoss: 0.271561\n",
      "Train Epoch: 5 [6000/12288 (49%)]\tLoss: 0.151166\n",
      "Train Epoch: 5 [7000/12288 (57%)]\tLoss: 0.302638\n",
      "Train Epoch: 5 [8000/12288 (65%)]\tLoss: 0.243106\n",
      "Train Epoch: 5 [9000/12288 (73%)]\tLoss: 0.208299\n",
      "Train Epoch: 5 [10000/12288 (81%)]\tLoss: 0.275494\n",
      "Train Epoch: 5 [11000/12288 (89%)]\tLoss: 0.449306\n",
      "Train Epoch: 5 [12000/12288 (98%)]\tLoss: 0.435891\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/11714 (0%)]\tLoss: 0.403542\n",
      "Train Epoch: 1 [1000/11714 (8%)]\tLoss: 0.373360\n",
      "Train Epoch: 1 [2000/11714 (17%)]\tLoss: 0.437267\n",
      "Train Epoch: 1 [3000/11714 (25%)]\tLoss: 0.489327\n",
      "Train Epoch: 1 [4000/11714 (34%)]\tLoss: 0.265482\n",
      "Train Epoch: 1 [5000/11714 (42%)]\tLoss: 0.289761\n",
      "Train Epoch: 1 [6000/11714 (51%)]\tLoss: 0.219525\n",
      "Train Epoch: 1 [7000/11714 (59%)]\tLoss: 0.275308\n",
      "Train Epoch: 1 [8000/11714 (68%)]\tLoss: 0.444539\n",
      "Train Epoch: 1 [9000/11714 (76%)]\tLoss: 0.310392\n",
      "Train Epoch: 1 [10000/11714 (85%)]\tLoss: 0.247001\n",
      "Train Epoch: 1 [11000/11714 (93%)]\tLoss: 0.291352\n",
      "Train Epoch: 2 [0/11714 (0%)]\tLoss: 0.357557\n",
      "Train Epoch: 2 [1000/11714 (8%)]\tLoss: 0.322971\n",
      "Train Epoch: 2 [2000/11714 (17%)]\tLoss: 0.342869\n",
      "Train Epoch: 2 [3000/11714 (25%)]\tLoss: 0.349398\n",
      "Train Epoch: 2 [4000/11714 (34%)]\tLoss: 0.430607\n",
      "Train Epoch: 2 [5000/11714 (42%)]\tLoss: 0.310934\n",
      "Train Epoch: 2 [6000/11714 (51%)]\tLoss: 0.350759\n",
      "Train Epoch: 2 [7000/11714 (59%)]\tLoss: 0.349860\n",
      "Train Epoch: 2 [8000/11714 (68%)]\tLoss: 0.324522\n",
      "Train Epoch: 2 [9000/11714 (76%)]\tLoss: 0.395814\n",
      "Train Epoch: 2 [10000/11714 (85%)]\tLoss: 0.288344\n",
      "Train Epoch: 2 [11000/11714 (93%)]\tLoss: 0.302426\n",
      "Train Epoch: 3 [0/11714 (0%)]\tLoss: 0.417995\n",
      "Train Epoch: 3 [1000/11714 (8%)]\tLoss: 0.384183\n",
      "Train Epoch: 3 [2000/11714 (17%)]\tLoss: 0.517047\n",
      "Train Epoch: 3 [3000/11714 (25%)]\tLoss: 0.337548\n",
      "Train Epoch: 3 [4000/11714 (34%)]\tLoss: 0.417891\n",
      "Train Epoch: 3 [5000/11714 (42%)]\tLoss: 0.278202\n",
      "Train Epoch: 3 [6000/11714 (51%)]\tLoss: 0.373723\n",
      "Train Epoch: 3 [7000/11714 (59%)]\tLoss: 0.305324\n",
      "Train Epoch: 3 [8000/11714 (68%)]\tLoss: 0.359093\n",
      "Train Epoch: 3 [9000/11714 (76%)]\tLoss: 0.473714\n",
      "Train Epoch: 3 [10000/11714 (85%)]\tLoss: 0.265191\n",
      "Train Epoch: 3 [11000/11714 (93%)]\tLoss: 0.469775\n",
      "Train Epoch: 4 [0/11714 (0%)]\tLoss: 0.335503\n",
      "Train Epoch: 4 [1000/11714 (8%)]\tLoss: 0.487874\n",
      "Train Epoch: 4 [2000/11714 (17%)]\tLoss: 0.311747\n",
      "Train Epoch: 4 [3000/11714 (25%)]\tLoss: 0.384632\n",
      "Train Epoch: 4 [4000/11714 (34%)]\tLoss: 0.390280\n",
      "Train Epoch: 4 [5000/11714 (42%)]\tLoss: 0.452417\n",
      "Train Epoch: 4 [6000/11714 (51%)]\tLoss: 0.360115\n",
      "Train Epoch: 4 [7000/11714 (59%)]\tLoss: 0.419000\n",
      "Train Epoch: 4 [8000/11714 (68%)]\tLoss: 0.301202\n",
      "Train Epoch: 4 [9000/11714 (76%)]\tLoss: 0.445590\n",
      "Train Epoch: 4 [10000/11714 (85%)]\tLoss: 0.415776\n",
      "Train Epoch: 4 [11000/11714 (93%)]\tLoss: 0.329469\n",
      "Train Epoch: 5 [0/11714 (0%)]\tLoss: 0.351297\n",
      "Train Epoch: 5 [1000/11714 (8%)]\tLoss: 0.297714\n",
      "Train Epoch: 5 [2000/11714 (17%)]\tLoss: 0.318809\n",
      "Train Epoch: 5 [3000/11714 (25%)]\tLoss: 0.246141\n",
      "Train Epoch: 5 [4000/11714 (34%)]\tLoss: 0.310556\n",
      "Train Epoch: 5 [5000/11714 (42%)]\tLoss: 0.454840\n",
      "Train Epoch: 5 [6000/11714 (51%)]\tLoss: 0.369796\n",
      "Train Epoch: 5 [7000/11714 (59%)]\tLoss: 0.297617\n",
      "Train Epoch: 5 [8000/11714 (68%)]\tLoss: 0.188784\n",
      "Train Epoch: 5 [9000/11714 (76%)]\tLoss: 0.372372\n",
      "Train Epoch: 5 [10000/11714 (85%)]\tLoss: 0.347984\n",
      "Train Epoch: 5 [11000/11714 (93%)]\tLoss: 0.255361\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/9877 (0%)]\tLoss: 0.397391\n",
      "Train Epoch: 1 [1000/9877 (10%)]\tLoss: 0.345459\n",
      "Train Epoch: 1 [2000/9877 (20%)]\tLoss: 0.345633\n",
      "Train Epoch: 1 [3000/9877 (30%)]\tLoss: 0.239582\n",
      "Train Epoch: 1 [4000/9877 (40%)]\tLoss: 0.267704\n",
      "Train Epoch: 1 [5000/9877 (51%)]\tLoss: 0.257352\n",
      "Train Epoch: 1 [6000/9877 (61%)]\tLoss: 0.360839\n",
      "Train Epoch: 1 [7000/9877 (71%)]\tLoss: 0.336629\n",
      "Train Epoch: 1 [8000/9877 (81%)]\tLoss: 0.265686\n",
      "Train Epoch: 1 [9000/9877 (91%)]\tLoss: 0.354574\n",
      "Train Epoch: 2 [0/9877 (0%)]\tLoss: 0.472855\n",
      "Train Epoch: 2 [1000/9877 (10%)]\tLoss: 0.389636\n",
      "Train Epoch: 2 [2000/9877 (20%)]\tLoss: 0.392127\n",
      "Train Epoch: 2 [3000/9877 (30%)]\tLoss: 0.315029\n",
      "Train Epoch: 2 [4000/9877 (40%)]\tLoss: 0.290875\n",
      "Train Epoch: 2 [5000/9877 (51%)]\tLoss: 0.479880\n",
      "Train Epoch: 2 [6000/9877 (61%)]\tLoss: 0.354963\n",
      "Train Epoch: 2 [7000/9877 (71%)]\tLoss: 0.375395\n",
      "Train Epoch: 2 [8000/9877 (81%)]\tLoss: 0.293682\n",
      "Train Epoch: 2 [9000/9877 (91%)]\tLoss: 0.482120\n",
      "Train Epoch: 3 [0/9877 (0%)]\tLoss: 0.298567\n",
      "Train Epoch: 3 [1000/9877 (10%)]\tLoss: 0.362787\n",
      "Train Epoch: 3 [2000/9877 (20%)]\tLoss: 0.401792\n",
      "Train Epoch: 3 [3000/9877 (30%)]\tLoss: 0.422326\n",
      "Train Epoch: 3 [4000/9877 (40%)]\tLoss: 0.293423\n",
      "Train Epoch: 3 [5000/9877 (51%)]\tLoss: 0.470852\n",
      "Train Epoch: 3 [6000/9877 (61%)]\tLoss: 0.333433\n",
      "Train Epoch: 3 [7000/9877 (71%)]\tLoss: 0.466070\n",
      "Train Epoch: 3 [8000/9877 (81%)]\tLoss: 0.311320\n",
      "Train Epoch: 3 [9000/9877 (91%)]\tLoss: 0.175717\n",
      "Train Epoch: 4 [0/9877 (0%)]\tLoss: 0.373890\n",
      "Train Epoch: 4 [1000/9877 (10%)]\tLoss: 0.329157\n",
      "Train Epoch: 4 [2000/9877 (20%)]\tLoss: 0.377489\n",
      "Train Epoch: 4 [3000/9877 (30%)]\tLoss: 0.348310\n",
      "Train Epoch: 4 [4000/9877 (40%)]\tLoss: 0.238528\n",
      "Train Epoch: 4 [5000/9877 (51%)]\tLoss: 0.375690\n",
      "Train Epoch: 4 [6000/9877 (61%)]\tLoss: 0.370578\n",
      "Train Epoch: 4 [7000/9877 (71%)]\tLoss: 0.396134\n",
      "Train Epoch: 4 [8000/9877 (81%)]\tLoss: 0.437721\n",
      "Train Epoch: 4 [9000/9877 (91%)]\tLoss: 0.301870\n",
      "Train Epoch: 5 [0/9877 (0%)]\tLoss: 0.305022\n",
      "Train Epoch: 5 [1000/9877 (10%)]\tLoss: 0.392549\n",
      "Train Epoch: 5 [2000/9877 (20%)]\tLoss: 0.266421\n",
      "Train Epoch: 5 [3000/9877 (30%)]\tLoss: 0.350849\n",
      "Train Epoch: 5 [4000/9877 (40%)]\tLoss: 0.239148\n",
      "Train Epoch: 5 [5000/9877 (51%)]\tLoss: 0.506136\n",
      "Train Epoch: 5 [6000/9877 (61%)]\tLoss: 0.245349\n",
      "Train Epoch: 5 [7000/9877 (71%)]\tLoss: 0.427258\n",
      "Train Epoch: 5 [8000/9877 (81%)]\tLoss: 0.351368\n",
      "Train Epoch: 5 [9000/9877 (91%)]\tLoss: 0.338402\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8648, Accuracy: 7700/10000 (77%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/12367 (0%)]\tLoss: 0.437312\n",
      "Train Epoch: 1 [1000/12367 (8%)]\tLoss: 0.483541\n",
      "Train Epoch: 1 [2000/12367 (16%)]\tLoss: 0.444756\n",
      "Train Epoch: 1 [3000/12367 (24%)]\tLoss: 0.366920\n",
      "Train Epoch: 1 [4000/12367 (32%)]\tLoss: 0.524994\n",
      "Train Epoch: 1 [5000/12367 (40%)]\tLoss: 0.433763\n",
      "Train Epoch: 1 [6000/12367 (48%)]\tLoss: 0.307896\n",
      "Train Epoch: 1 [7000/12367 (56%)]\tLoss: 0.363519\n",
      "Train Epoch: 1 [8000/12367 (65%)]\tLoss: 0.341662\n",
      "Train Epoch: 1 [9000/12367 (73%)]\tLoss: 0.426908\n",
      "Train Epoch: 1 [10000/12367 (81%)]\tLoss: 0.433670\n",
      "Train Epoch: 1 [11000/12367 (89%)]\tLoss: 0.544098\n",
      "Train Epoch: 1 [12000/12367 (97%)]\tLoss: 0.577470\n",
      "Train Epoch: 2 [0/12367 (0%)]\tLoss: 0.426972\n",
      "Train Epoch: 2 [1000/12367 (8%)]\tLoss: 0.360179\n",
      "Train Epoch: 2 [2000/12367 (16%)]\tLoss: 0.398068\n",
      "Train Epoch: 2 [3000/12367 (24%)]\tLoss: 0.297101\n",
      "Train Epoch: 2 [4000/12367 (32%)]\tLoss: 0.509037\n",
      "Train Epoch: 2 [5000/12367 (40%)]\tLoss: 0.439676\n",
      "Train Epoch: 2 [6000/12367 (48%)]\tLoss: 0.419643\n",
      "Train Epoch: 2 [7000/12367 (56%)]\tLoss: 0.385348\n",
      "Train Epoch: 2 [8000/12367 (65%)]\tLoss: 0.327583\n",
      "Train Epoch: 2 [9000/12367 (73%)]\tLoss: 0.461726\n",
      "Train Epoch: 2 [10000/12367 (81%)]\tLoss: 0.472812\n",
      "Train Epoch: 2 [11000/12367 (89%)]\tLoss: 0.541593\n",
      "Train Epoch: 2 [12000/12367 (97%)]\tLoss: 0.408066\n",
      "Train Epoch: 3 [0/12367 (0%)]\tLoss: 0.431334\n",
      "Train Epoch: 3 [1000/12367 (8%)]\tLoss: 0.440693\n",
      "Train Epoch: 3 [2000/12367 (16%)]\tLoss: 0.570275\n",
      "Train Epoch: 3 [3000/12367 (24%)]\tLoss: 0.394974\n",
      "Train Epoch: 3 [4000/12367 (32%)]\tLoss: 0.293614\n",
      "Train Epoch: 3 [5000/12367 (40%)]\tLoss: 0.348857\n",
      "Train Epoch: 3 [6000/12367 (48%)]\tLoss: 0.325928\n",
      "Train Epoch: 3 [7000/12367 (56%)]\tLoss: 0.375924\n",
      "Train Epoch: 3 [8000/12367 (65%)]\tLoss: 0.397890\n",
      "Train Epoch: 3 [9000/12367 (73%)]\tLoss: 0.415296\n",
      "Train Epoch: 3 [10000/12367 (81%)]\tLoss: 0.428838\n",
      "Train Epoch: 3 [11000/12367 (89%)]\tLoss: 0.427203\n",
      "Train Epoch: 3 [12000/12367 (97%)]\tLoss: 0.483487\n",
      "Train Epoch: 4 [0/12367 (0%)]\tLoss: 0.359163\n",
      "Train Epoch: 4 [1000/12367 (8%)]\tLoss: 0.525468\n",
      "Train Epoch: 4 [2000/12367 (16%)]\tLoss: 0.449354\n",
      "Train Epoch: 4 [3000/12367 (24%)]\tLoss: 0.435597\n",
      "Train Epoch: 4 [4000/12367 (32%)]\tLoss: 0.479685\n",
      "Train Epoch: 4 [5000/12367 (40%)]\tLoss: 0.442567\n",
      "Train Epoch: 4 [6000/12367 (48%)]\tLoss: 0.493462\n",
      "Train Epoch: 4 [7000/12367 (56%)]\tLoss: 0.475087\n",
      "Train Epoch: 4 [8000/12367 (65%)]\tLoss: 0.368552\n",
      "Train Epoch: 4 [9000/12367 (73%)]\tLoss: 0.413242\n",
      "Train Epoch: 4 [10000/12367 (81%)]\tLoss: 0.408666\n",
      "Train Epoch: 4 [11000/12367 (89%)]\tLoss: 0.322538\n",
      "Train Epoch: 4 [12000/12367 (97%)]\tLoss: 0.487179\n",
      "Train Epoch: 5 [0/12367 (0%)]\tLoss: 0.369134\n",
      "Train Epoch: 5 [1000/12367 (8%)]\tLoss: 0.560940\n",
      "Train Epoch: 5 [2000/12367 (16%)]\tLoss: 0.509201\n",
      "Train Epoch: 5 [3000/12367 (24%)]\tLoss: 0.322744\n",
      "Train Epoch: 5 [4000/12367 (32%)]\tLoss: 0.425964\n",
      "Train Epoch: 5 [5000/12367 (40%)]\tLoss: 0.370308\n",
      "Train Epoch: 5 [6000/12367 (48%)]\tLoss: 0.453108\n",
      "Train Epoch: 5 [7000/12367 (56%)]\tLoss: 0.340121\n",
      "Train Epoch: 5 [8000/12367 (65%)]\tLoss: 0.341669\n",
      "Train Epoch: 5 [9000/12367 (73%)]\tLoss: 0.624049\n",
      "Train Epoch: 5 [10000/12367 (81%)]\tLoss: 0.297589\n",
      "Train Epoch: 5 [11000/12367 (89%)]\tLoss: 0.434366\n",
      "Train Epoch: 5 [12000/12367 (97%)]\tLoss: 0.291794\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.499790\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.194287\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.086965\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.162791\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.156384\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.306014\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.156850\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.191571\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.228607\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.148905\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.189283\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.242620\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.066490\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.108582\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.142437\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.112540\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.161490\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.162616\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.113953\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.090320\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.184586\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.243598\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.158324\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.259531\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.134618\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.126839\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.091324\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.102435\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.108543\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.106289\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.270512\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.129867\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.085539\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.104657\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.204014\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.120192\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.140211\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.088867\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.163580\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.098648\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.301734\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.279203\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.272331\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.128741\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.342388\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.216850\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.326979\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.256106\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.244502\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.289098\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.267268\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.190216\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.256100\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.251169\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.296450\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.203951\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.146864\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.244299\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.251356\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.211487\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.208381\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.252251\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.220294\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.220395\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.286227\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.399868\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.245764\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.246559\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.232799\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.228457\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.382268\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.223101\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.329475\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.290572\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.189287\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/12288 (0%)]\tLoss: 0.449467\n",
      "Train Epoch: 1 [1000/12288 (8%)]\tLoss: 0.356312\n",
      "Train Epoch: 1 [2000/12288 (16%)]\tLoss: 0.340881\n",
      "Train Epoch: 1 [3000/12288 (24%)]\tLoss: 0.177575\n",
      "Train Epoch: 1 [4000/12288 (33%)]\tLoss: 0.485811\n",
      "Train Epoch: 1 [5000/12288 (41%)]\tLoss: 0.340029\n",
      "Train Epoch: 1 [6000/12288 (49%)]\tLoss: 0.434315\n",
      "Train Epoch: 1 [7000/12288 (57%)]\tLoss: 0.393881\n",
      "Train Epoch: 1 [8000/12288 (65%)]\tLoss: 0.280731\n",
      "Train Epoch: 1 [9000/12288 (73%)]\tLoss: 0.288289\n",
      "Train Epoch: 1 [10000/12288 (81%)]\tLoss: 0.346075\n",
      "Train Epoch: 1 [11000/12288 (89%)]\tLoss: 0.371724\n",
      "Train Epoch: 1 [12000/12288 (98%)]\tLoss: 0.350030\n",
      "Train Epoch: 2 [0/12288 (0%)]\tLoss: 0.394168\n",
      "Train Epoch: 2 [1000/12288 (8%)]\tLoss: 0.327389\n",
      "Train Epoch: 2 [2000/12288 (16%)]\tLoss: 0.360803\n",
      "Train Epoch: 2 [3000/12288 (24%)]\tLoss: 0.400298\n",
      "Train Epoch: 2 [4000/12288 (33%)]\tLoss: 0.386313\n",
      "Train Epoch: 2 [5000/12288 (41%)]\tLoss: 0.238911\n",
      "Train Epoch: 2 [6000/12288 (49%)]\tLoss: 0.232431\n",
      "Train Epoch: 2 [7000/12288 (57%)]\tLoss: 0.449095\n",
      "Train Epoch: 2 [8000/12288 (65%)]\tLoss: 0.288504\n",
      "Train Epoch: 2 [9000/12288 (73%)]\tLoss: 0.243055\n",
      "Train Epoch: 2 [10000/12288 (81%)]\tLoss: 0.266172\n",
      "Train Epoch: 2 [11000/12288 (89%)]\tLoss: 0.344100\n",
      "Train Epoch: 2 [12000/12288 (98%)]\tLoss: 0.293918\n",
      "Train Epoch: 3 [0/12288 (0%)]\tLoss: 0.494624\n",
      "Train Epoch: 3 [1000/12288 (8%)]\tLoss: 0.350269\n",
      "Train Epoch: 3 [2000/12288 (16%)]\tLoss: 0.226604\n",
      "Train Epoch: 3 [3000/12288 (24%)]\tLoss: 0.196867\n",
      "Train Epoch: 3 [4000/12288 (33%)]\tLoss: 0.397049\n",
      "Train Epoch: 3 [5000/12288 (41%)]\tLoss: 0.348976\n",
      "Train Epoch: 3 [6000/12288 (49%)]\tLoss: 0.412257\n",
      "Train Epoch: 3 [7000/12288 (57%)]\tLoss: 0.304389\n",
      "Train Epoch: 3 [8000/12288 (65%)]\tLoss: 0.203642\n",
      "Train Epoch: 3 [9000/12288 (73%)]\tLoss: 0.201749\n",
      "Train Epoch: 3 [10000/12288 (81%)]\tLoss: 0.161031\n",
      "Train Epoch: 3 [11000/12288 (89%)]\tLoss: 0.249588\n",
      "Train Epoch: 3 [12000/12288 (98%)]\tLoss: 0.311317\n",
      "Train Epoch: 4 [0/12288 (0%)]\tLoss: 0.194232\n",
      "Train Epoch: 4 [1000/12288 (8%)]\tLoss: 0.273762\n",
      "Train Epoch: 4 [2000/12288 (16%)]\tLoss: 0.246641\n",
      "Train Epoch: 4 [3000/12288 (24%)]\tLoss: 0.258496\n",
      "Train Epoch: 4 [4000/12288 (33%)]\tLoss: 0.337844\n",
      "Train Epoch: 4 [5000/12288 (41%)]\tLoss: 0.236899\n",
      "Train Epoch: 4 [6000/12288 (49%)]\tLoss: 0.368593\n",
      "Train Epoch: 4 [7000/12288 (57%)]\tLoss: 0.322601\n",
      "Train Epoch: 4 [8000/12288 (65%)]\tLoss: 0.264876\n",
      "Train Epoch: 4 [9000/12288 (73%)]\tLoss: 0.367156\n",
      "Train Epoch: 4 [10000/12288 (81%)]\tLoss: 0.272646\n",
      "Train Epoch: 4 [11000/12288 (89%)]\tLoss: 0.259334\n",
      "Train Epoch: 4 [12000/12288 (98%)]\tLoss: 0.325841\n",
      "Train Epoch: 5 [0/12288 (0%)]\tLoss: 0.409494\n",
      "Train Epoch: 5 [1000/12288 (8%)]\tLoss: 0.280499\n",
      "Train Epoch: 5 [2000/12288 (16%)]\tLoss: 0.305844\n",
      "Train Epoch: 5 [3000/12288 (24%)]\tLoss: 0.165101\n",
      "Train Epoch: 5 [4000/12288 (33%)]\tLoss: 0.346611\n",
      "Train Epoch: 5 [5000/12288 (41%)]\tLoss: 0.213097\n",
      "Train Epoch: 5 [6000/12288 (49%)]\tLoss: 0.308415\n",
      "Train Epoch: 5 [7000/12288 (57%)]\tLoss: 0.386469\n",
      "Train Epoch: 5 [8000/12288 (65%)]\tLoss: 0.305051\n",
      "Train Epoch: 5 [9000/12288 (73%)]\tLoss: 0.257361\n",
      "Train Epoch: 5 [10000/12288 (81%)]\tLoss: 0.204703\n",
      "Train Epoch: 5 [11000/12288 (89%)]\tLoss: 0.195168\n",
      "Train Epoch: 5 [12000/12288 (98%)]\tLoss: 0.254363\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/11714 (0%)]\tLoss: 0.580049\n",
      "Train Epoch: 1 [1000/11714 (8%)]\tLoss: 0.245956\n",
      "Train Epoch: 1 [2000/11714 (17%)]\tLoss: 0.388175\n",
      "Train Epoch: 1 [3000/11714 (25%)]\tLoss: 0.288266\n",
      "Train Epoch: 1 [4000/11714 (34%)]\tLoss: 0.445976\n",
      "Train Epoch: 1 [5000/11714 (42%)]\tLoss: 0.368912\n",
      "Train Epoch: 1 [6000/11714 (51%)]\tLoss: 0.279693\n",
      "Train Epoch: 1 [7000/11714 (59%)]\tLoss: 0.386150\n",
      "Train Epoch: 1 [8000/11714 (68%)]\tLoss: 0.387684\n",
      "Train Epoch: 1 [9000/11714 (76%)]\tLoss: 0.368530\n",
      "Train Epoch: 1 [10000/11714 (85%)]\tLoss: 0.352260\n",
      "Train Epoch: 1 [11000/11714 (93%)]\tLoss: 0.425705\n",
      "Train Epoch: 2 [0/11714 (0%)]\tLoss: 0.287914\n",
      "Train Epoch: 2 [1000/11714 (8%)]\tLoss: 0.303902\n",
      "Train Epoch: 2 [2000/11714 (17%)]\tLoss: 0.290047\n",
      "Train Epoch: 2 [3000/11714 (25%)]\tLoss: 0.275388\n",
      "Train Epoch: 2 [4000/11714 (34%)]\tLoss: 0.247727\n",
      "Train Epoch: 2 [5000/11714 (42%)]\tLoss: 0.388794\n",
      "Train Epoch: 2 [6000/11714 (51%)]\tLoss: 0.291927\n",
      "Train Epoch: 2 [7000/11714 (59%)]\tLoss: 0.348898\n",
      "Train Epoch: 2 [8000/11714 (68%)]\tLoss: 0.367730\n",
      "Train Epoch: 2 [9000/11714 (76%)]\tLoss: 0.306236\n",
      "Train Epoch: 2 [10000/11714 (85%)]\tLoss: 0.234791\n",
      "Train Epoch: 2 [11000/11714 (93%)]\tLoss: 0.333648\n",
      "Train Epoch: 3 [0/11714 (0%)]\tLoss: 0.466440\n",
      "Train Epoch: 3 [1000/11714 (8%)]\tLoss: 0.352888\n",
      "Train Epoch: 3 [2000/11714 (17%)]\tLoss: 0.232485\n",
      "Train Epoch: 3 [3000/11714 (25%)]\tLoss: 0.275254\n",
      "Train Epoch: 3 [4000/11714 (34%)]\tLoss: 0.446796\n",
      "Train Epoch: 3 [5000/11714 (42%)]\tLoss: 0.552243\n",
      "Train Epoch: 3 [6000/11714 (51%)]\tLoss: 0.408390\n",
      "Train Epoch: 3 [7000/11714 (59%)]\tLoss: 0.321318\n",
      "Train Epoch: 3 [8000/11714 (68%)]\tLoss: 0.452749\n",
      "Train Epoch: 3 [9000/11714 (76%)]\tLoss: 0.299196\n",
      "Train Epoch: 3 [10000/11714 (85%)]\tLoss: 0.242804\n",
      "Train Epoch: 3 [11000/11714 (93%)]\tLoss: 0.339589\n",
      "Train Epoch: 4 [0/11714 (0%)]\tLoss: 0.271111\n",
      "Train Epoch: 4 [1000/11714 (8%)]\tLoss: 0.561040\n",
      "Train Epoch: 4 [2000/11714 (17%)]\tLoss: 0.320835\n",
      "Train Epoch: 4 [3000/11714 (25%)]\tLoss: 0.297632\n",
      "Train Epoch: 4 [4000/11714 (34%)]\tLoss: 0.393110\n",
      "Train Epoch: 4 [5000/11714 (42%)]\tLoss: 0.306655\n",
      "Train Epoch: 4 [6000/11714 (51%)]\tLoss: 0.369820\n",
      "Train Epoch: 4 [7000/11714 (59%)]\tLoss: 0.312148\n",
      "Train Epoch: 4 [8000/11714 (68%)]\tLoss: 0.328585\n",
      "Train Epoch: 4 [9000/11714 (76%)]\tLoss: 0.325868\n",
      "Train Epoch: 4 [10000/11714 (85%)]\tLoss: 0.426240\n",
      "Train Epoch: 4 [11000/11714 (93%)]\tLoss: 0.267977\n",
      "Train Epoch: 5 [0/11714 (0%)]\tLoss: 0.357468\n",
      "Train Epoch: 5 [1000/11714 (8%)]\tLoss: 0.404036\n",
      "Train Epoch: 5 [2000/11714 (17%)]\tLoss: 0.465774\n",
      "Train Epoch: 5 [3000/11714 (25%)]\tLoss: 0.362563\n",
      "Train Epoch: 5 [4000/11714 (34%)]\tLoss: 0.289979\n",
      "Train Epoch: 5 [5000/11714 (42%)]\tLoss: 0.292070\n",
      "Train Epoch: 5 [6000/11714 (51%)]\tLoss: 0.266955\n",
      "Train Epoch: 5 [7000/11714 (59%)]\tLoss: 0.297058\n",
      "Train Epoch: 5 [8000/11714 (68%)]\tLoss: 0.247019\n",
      "Train Epoch: 5 [9000/11714 (76%)]\tLoss: 0.289357\n",
      "Train Epoch: 5 [10000/11714 (85%)]\tLoss: 0.380590\n",
      "Train Epoch: 5 [11000/11714 (93%)]\tLoss: 0.382017\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/9877 (0%)]\tLoss: 0.562531\n",
      "Train Epoch: 1 [1000/9877 (10%)]\tLoss: 0.417234\n",
      "Train Epoch: 1 [2000/9877 (20%)]\tLoss: 0.244850\n",
      "Train Epoch: 1 [3000/9877 (30%)]\tLoss: 0.358083\n",
      "Train Epoch: 1 [4000/9877 (40%)]\tLoss: 0.382046\n",
      "Train Epoch: 1 [5000/9877 (51%)]\tLoss: 0.497398\n",
      "Train Epoch: 1 [6000/9877 (61%)]\tLoss: 0.363007\n",
      "Train Epoch: 1 [7000/9877 (71%)]\tLoss: 0.428947\n",
      "Train Epoch: 1 [8000/9877 (81%)]\tLoss: 0.376945\n",
      "Train Epoch: 1 [9000/9877 (91%)]\tLoss: 0.406275\n",
      "Train Epoch: 2 [0/9877 (0%)]\tLoss: 0.401701\n",
      "Train Epoch: 2 [1000/9877 (10%)]\tLoss: 0.409137\n",
      "Train Epoch: 2 [2000/9877 (20%)]\tLoss: 0.396510\n",
      "Train Epoch: 2 [3000/9877 (30%)]\tLoss: 0.264515\n",
      "Train Epoch: 2 [4000/9877 (40%)]\tLoss: 0.331564\n",
      "Train Epoch: 2 [5000/9877 (51%)]\tLoss: 0.564845\n",
      "Train Epoch: 2 [6000/9877 (61%)]\tLoss: 0.315274\n",
      "Train Epoch: 2 [7000/9877 (71%)]\tLoss: 0.398192\n",
      "Train Epoch: 2 [8000/9877 (81%)]\tLoss: 0.395419\n",
      "Train Epoch: 2 [9000/9877 (91%)]\tLoss: 0.291875\n",
      "Train Epoch: 3 [0/9877 (0%)]\tLoss: 0.230696\n",
      "Train Epoch: 3 [1000/9877 (10%)]\tLoss: 0.357825\n",
      "Train Epoch: 3 [2000/9877 (20%)]\tLoss: 0.438250\n",
      "Train Epoch: 3 [3000/9877 (30%)]\tLoss: 0.372074\n",
      "Train Epoch: 3 [4000/9877 (40%)]\tLoss: 0.242186\n",
      "Train Epoch: 3 [5000/9877 (51%)]\tLoss: 0.332716\n",
      "Train Epoch: 3 [6000/9877 (61%)]\tLoss: 0.370524\n",
      "Train Epoch: 3 [7000/9877 (71%)]\tLoss: 0.501107\n",
      "Train Epoch: 3 [8000/9877 (81%)]\tLoss: 0.372578\n",
      "Train Epoch: 3 [9000/9877 (91%)]\tLoss: 0.573729\n",
      "Train Epoch: 4 [0/9877 (0%)]\tLoss: 0.395629\n",
      "Train Epoch: 4 [1000/9877 (10%)]\tLoss: 0.261967\n",
      "Train Epoch: 4 [2000/9877 (20%)]\tLoss: 0.606663\n",
      "Train Epoch: 4 [3000/9877 (30%)]\tLoss: 0.292846\n",
      "Train Epoch: 4 [4000/9877 (40%)]\tLoss: 0.314943\n",
      "Train Epoch: 4 [5000/9877 (51%)]\tLoss: 0.278453\n",
      "Train Epoch: 4 [6000/9877 (61%)]\tLoss: 0.362028\n",
      "Train Epoch: 4 [7000/9877 (71%)]\tLoss: 0.234618\n",
      "Train Epoch: 4 [8000/9877 (81%)]\tLoss: 0.410210\n",
      "Train Epoch: 4 [9000/9877 (91%)]\tLoss: 0.338513\n",
      "Train Epoch: 5 [0/9877 (0%)]\tLoss: 0.257585\n",
      "Train Epoch: 5 [1000/9877 (10%)]\tLoss: 0.486133\n",
      "Train Epoch: 5 [2000/9877 (20%)]\tLoss: 0.300698\n",
      "Train Epoch: 5 [3000/9877 (30%)]\tLoss: 0.305884\n",
      "Train Epoch: 5 [4000/9877 (40%)]\tLoss: 0.379985\n",
      "Train Epoch: 5 [5000/9877 (51%)]\tLoss: 0.280492\n",
      "Train Epoch: 5 [6000/9877 (61%)]\tLoss: 0.317052\n",
      "Train Epoch: 5 [7000/9877 (71%)]\tLoss: 0.264417\n",
      "Train Epoch: 5 [8000/9877 (81%)]\tLoss: 0.419813\n",
      "Train Epoch: 5 [9000/9877 (91%)]\tLoss: 0.331133\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8960, Accuracy: 7663/10000 (77%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/12367 (0%)]\tLoss: 0.509477\n",
      "Train Epoch: 1 [1000/12367 (8%)]\tLoss: 0.455962\n",
      "Train Epoch: 1 [2000/12367 (16%)]\tLoss: 0.328679\n",
      "Train Epoch: 1 [3000/12367 (24%)]\tLoss: 0.486558\n",
      "Train Epoch: 1 [4000/12367 (32%)]\tLoss: 0.418967\n",
      "Train Epoch: 1 [5000/12367 (40%)]\tLoss: 0.533112\n",
      "Train Epoch: 1 [6000/12367 (48%)]\tLoss: 0.406658\n",
      "Train Epoch: 1 [7000/12367 (56%)]\tLoss: 0.363962\n",
      "Train Epoch: 1 [8000/12367 (65%)]\tLoss: 0.329560\n",
      "Train Epoch: 1 [9000/12367 (73%)]\tLoss: 0.397020\n",
      "Train Epoch: 1 [10000/12367 (81%)]\tLoss: 0.301981\n",
      "Train Epoch: 1 [11000/12367 (89%)]\tLoss: 0.426125\n",
      "Train Epoch: 1 [12000/12367 (97%)]\tLoss: 0.340253\n",
      "Train Epoch: 2 [0/12367 (0%)]\tLoss: 0.445046\n",
      "Train Epoch: 2 [1000/12367 (8%)]\tLoss: 0.386300\n",
      "Train Epoch: 2 [2000/12367 (16%)]\tLoss: 0.367943\n",
      "Train Epoch: 2 [3000/12367 (24%)]\tLoss: 0.519427\n",
      "Train Epoch: 2 [4000/12367 (32%)]\tLoss: 0.380733\n",
      "Train Epoch: 2 [5000/12367 (40%)]\tLoss: 0.442428\n",
      "Train Epoch: 2 [6000/12367 (48%)]\tLoss: 0.356903\n",
      "Train Epoch: 2 [7000/12367 (56%)]\tLoss: 0.476765\n",
      "Train Epoch: 2 [8000/12367 (65%)]\tLoss: 0.424650\n",
      "Train Epoch: 2 [9000/12367 (73%)]\tLoss: 0.431752\n",
      "Train Epoch: 2 [10000/12367 (81%)]\tLoss: 0.496154\n",
      "Train Epoch: 2 [11000/12367 (89%)]\tLoss: 0.415750\n",
      "Train Epoch: 2 [12000/12367 (97%)]\tLoss: 0.500138\n",
      "Train Epoch: 3 [0/12367 (0%)]\tLoss: 0.485568\n",
      "Train Epoch: 3 [1000/12367 (8%)]\tLoss: 0.382256\n",
      "Train Epoch: 3 [2000/12367 (16%)]\tLoss: 0.301371\n",
      "Train Epoch: 3 [3000/12367 (24%)]\tLoss: 0.341375\n",
      "Train Epoch: 3 [4000/12367 (32%)]\tLoss: 0.431214\n",
      "Train Epoch: 3 [5000/12367 (40%)]\tLoss: 0.284148\n",
      "Train Epoch: 3 [6000/12367 (48%)]\tLoss: 0.433406\n",
      "Train Epoch: 3 [7000/12367 (56%)]\tLoss: 0.533069\n",
      "Train Epoch: 3 [8000/12367 (65%)]\tLoss: 0.446567\n",
      "Train Epoch: 3 [9000/12367 (73%)]\tLoss: 0.480376\n",
      "Train Epoch: 3 [10000/12367 (81%)]\tLoss: 0.305025\n",
      "Train Epoch: 3 [11000/12367 (89%)]\tLoss: 0.600157\n",
      "Train Epoch: 3 [12000/12367 (97%)]\tLoss: 0.509134\n",
      "Train Epoch: 4 [0/12367 (0%)]\tLoss: 0.463468\n",
      "Train Epoch: 4 [1000/12367 (8%)]\tLoss: 0.623726\n",
      "Train Epoch: 4 [2000/12367 (16%)]\tLoss: 0.397272\n",
      "Train Epoch: 4 [3000/12367 (24%)]\tLoss: 0.251256\n",
      "Train Epoch: 4 [4000/12367 (32%)]\tLoss: 0.419731\n",
      "Train Epoch: 4 [5000/12367 (40%)]\tLoss: 0.512666\n",
      "Train Epoch: 4 [6000/12367 (48%)]\tLoss: 0.366568\n",
      "Train Epoch: 4 [7000/12367 (56%)]\tLoss: 0.377832\n",
      "Train Epoch: 4 [8000/12367 (65%)]\tLoss: 0.402912\n",
      "Train Epoch: 4 [9000/12367 (73%)]\tLoss: 0.412649\n",
      "Train Epoch: 4 [10000/12367 (81%)]\tLoss: 0.477310\n",
      "Train Epoch: 4 [11000/12367 (89%)]\tLoss: 0.466277\n",
      "Train Epoch: 4 [12000/12367 (97%)]\tLoss: 0.369779\n",
      "Train Epoch: 5 [0/12367 (0%)]\tLoss: 0.454765\n",
      "Train Epoch: 5 [1000/12367 (8%)]\tLoss: 0.411185\n",
      "Train Epoch: 5 [2000/12367 (16%)]\tLoss: 0.394251\n",
      "Train Epoch: 5 [3000/12367 (24%)]\tLoss: 0.482437\n",
      "Train Epoch: 5 [4000/12367 (32%)]\tLoss: 0.381398\n",
      "Train Epoch: 5 [5000/12367 (40%)]\tLoss: 0.463032\n",
      "Train Epoch: 5 [6000/12367 (48%)]\tLoss: 0.369686\n",
      "Train Epoch: 5 [7000/12367 (56%)]\tLoss: 0.343447\n",
      "Train Epoch: 5 [8000/12367 (65%)]\tLoss: 0.465703\n",
      "Train Epoch: 5 [9000/12367 (73%)]\tLoss: 0.442302\n",
      "Train Epoch: 5 [10000/12367 (81%)]\tLoss: 0.350100\n",
      "Train Epoch: 5 [11000/12367 (89%)]\tLoss: 0.428136\n",
      "Train Epoch: 5 [12000/12367 (97%)]\tLoss: 0.563248\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.559650\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.198663\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.168490\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.215359\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.149207\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.259308\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.101137\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.177209\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.139662\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.138965\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.022432\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.061681\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.114188\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.129795\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.172634\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.153235\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.251984\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.304596\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.114712\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.106789\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.105941\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.072521\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.129671\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.097743\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.139998\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.071312\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.180777\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.162822\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.154655\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.305266\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.188374\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.145297\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.131935\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.131468\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.193404\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.072604\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.161624\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.116695\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.108511\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.142696\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.340235\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.139040\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.310680\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.195108\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.198273\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.133678\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.239276\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.203976\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.201855\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.179904\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.268208\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.205734\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.189015\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.166220\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.285289\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.169831\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.212960\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.167470\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.214561\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.259445\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.177903\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.305101\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.283876\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.301924\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.178320\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.194075\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.165745\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.173815\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.379346\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.264106\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.266825\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.237383\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.204413\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.152640\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.229321\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/12288 (0%)]\tLoss: 0.566624\n",
      "Train Epoch: 1 [1000/12288 (8%)]\tLoss: 0.165763\n",
      "Train Epoch: 1 [2000/12288 (16%)]\tLoss: 0.422050\n",
      "Train Epoch: 1 [3000/12288 (24%)]\tLoss: 0.418023\n",
      "Train Epoch: 1 [4000/12288 (33%)]\tLoss: 0.407594\n",
      "Train Epoch: 1 [5000/12288 (41%)]\tLoss: 0.302480\n",
      "Train Epoch: 1 [6000/12288 (49%)]\tLoss: 0.421929\n",
      "Train Epoch: 1 [7000/12288 (57%)]\tLoss: 0.407928\n",
      "Train Epoch: 1 [8000/12288 (65%)]\tLoss: 0.222882\n",
      "Train Epoch: 1 [9000/12288 (73%)]\tLoss: 0.357332\n",
      "Train Epoch: 1 [10000/12288 (81%)]\tLoss: 0.248714\n",
      "Train Epoch: 1 [11000/12288 (89%)]\tLoss: 0.354704\n",
      "Train Epoch: 1 [12000/12288 (98%)]\tLoss: 0.313015\n",
      "Train Epoch: 2 [0/12288 (0%)]\tLoss: 0.256801\n",
      "Train Epoch: 2 [1000/12288 (8%)]\tLoss: 0.224173\n",
      "Train Epoch: 2 [2000/12288 (16%)]\tLoss: 0.289563\n",
      "Train Epoch: 2 [3000/12288 (24%)]\tLoss: 0.209311\n",
      "Train Epoch: 2 [4000/12288 (33%)]\tLoss: 0.439792\n",
      "Train Epoch: 2 [5000/12288 (41%)]\tLoss: 0.377351\n",
      "Train Epoch: 2 [6000/12288 (49%)]\tLoss: 0.324048\n",
      "Train Epoch: 2 [7000/12288 (57%)]\tLoss: 0.312625\n",
      "Train Epoch: 2 [8000/12288 (65%)]\tLoss: 0.256012\n",
      "Train Epoch: 2 [9000/12288 (73%)]\tLoss: 0.286749\n",
      "Train Epoch: 2 [10000/12288 (81%)]\tLoss: 0.313799\n",
      "Train Epoch: 2 [11000/12288 (89%)]\tLoss: 0.236072\n",
      "Train Epoch: 2 [12000/12288 (98%)]\tLoss: 0.389272\n",
      "Train Epoch: 3 [0/12288 (0%)]\tLoss: 0.312420\n",
      "Train Epoch: 3 [1000/12288 (8%)]\tLoss: 0.268775\n",
      "Train Epoch: 3 [2000/12288 (16%)]\tLoss: 0.326471\n",
      "Train Epoch: 3 [3000/12288 (24%)]\tLoss: 0.384810\n",
      "Train Epoch: 3 [4000/12288 (33%)]\tLoss: 0.290783\n",
      "Train Epoch: 3 [5000/12288 (41%)]\tLoss: 0.272159\n",
      "Train Epoch: 3 [6000/12288 (49%)]\tLoss: 0.385230\n",
      "Train Epoch: 3 [7000/12288 (57%)]\tLoss: 0.333477\n",
      "Train Epoch: 3 [8000/12288 (65%)]\tLoss: 0.383492\n",
      "Train Epoch: 3 [9000/12288 (73%)]\tLoss: 0.244155\n",
      "Train Epoch: 3 [10000/12288 (81%)]\tLoss: 0.313092\n",
      "Train Epoch: 3 [11000/12288 (89%)]\tLoss: 0.222355\n",
      "Train Epoch: 3 [12000/12288 (98%)]\tLoss: 0.412521\n",
      "Train Epoch: 4 [0/12288 (0%)]\tLoss: 0.314482\n",
      "Train Epoch: 4 [1000/12288 (8%)]\tLoss: 0.399546\n",
      "Train Epoch: 4 [2000/12288 (16%)]\tLoss: 0.348485\n",
      "Train Epoch: 4 [3000/12288 (24%)]\tLoss: 0.203860\n",
      "Train Epoch: 4 [4000/12288 (33%)]\tLoss: 0.346124\n",
      "Train Epoch: 4 [5000/12288 (41%)]\tLoss: 0.254018\n",
      "Train Epoch: 4 [6000/12288 (49%)]\tLoss: 0.326731\n",
      "Train Epoch: 4 [7000/12288 (57%)]\tLoss: 0.302659\n",
      "Train Epoch: 4 [8000/12288 (65%)]\tLoss: 0.269523\n",
      "Train Epoch: 4 [9000/12288 (73%)]\tLoss: 0.445385\n",
      "Train Epoch: 4 [10000/12288 (81%)]\tLoss: 0.241352\n",
      "Train Epoch: 4 [11000/12288 (89%)]\tLoss: 0.295902\n",
      "Train Epoch: 4 [12000/12288 (98%)]\tLoss: 0.363185\n",
      "Train Epoch: 5 [0/12288 (0%)]\tLoss: 0.469668\n",
      "Train Epoch: 5 [1000/12288 (8%)]\tLoss: 0.182819\n",
      "Train Epoch: 5 [2000/12288 (16%)]\tLoss: 0.367843\n",
      "Train Epoch: 5 [3000/12288 (24%)]\tLoss: 0.395224\n",
      "Train Epoch: 5 [4000/12288 (33%)]\tLoss: 0.218838\n",
      "Train Epoch: 5 [5000/12288 (41%)]\tLoss: 0.386242\n",
      "Train Epoch: 5 [6000/12288 (49%)]\tLoss: 0.238039\n",
      "Train Epoch: 5 [7000/12288 (57%)]\tLoss: 0.264462\n",
      "Train Epoch: 5 [8000/12288 (65%)]\tLoss: 0.256762\n",
      "Train Epoch: 5 [9000/12288 (73%)]\tLoss: 0.239847\n",
      "Train Epoch: 5 [10000/12288 (81%)]\tLoss: 0.245014\n",
      "Train Epoch: 5 [11000/12288 (89%)]\tLoss: 0.207086\n",
      "Train Epoch: 5 [12000/12288 (98%)]\tLoss: 0.137294\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/11714 (0%)]\tLoss: 0.442204\n",
      "Train Epoch: 1 [1000/11714 (8%)]\tLoss: 0.235064\n",
      "Train Epoch: 1 [2000/11714 (17%)]\tLoss: 0.281277\n",
      "Train Epoch: 1 [3000/11714 (25%)]\tLoss: 0.362310\n",
      "Train Epoch: 1 [4000/11714 (34%)]\tLoss: 0.292352\n",
      "Train Epoch: 1 [5000/11714 (42%)]\tLoss: 0.378010\n",
      "Train Epoch: 1 [6000/11714 (51%)]\tLoss: 0.379954\n",
      "Train Epoch: 1 [7000/11714 (59%)]\tLoss: 0.533216\n",
      "Train Epoch: 1 [8000/11714 (68%)]\tLoss: 0.383255\n",
      "Train Epoch: 1 [9000/11714 (76%)]\tLoss: 0.559954\n",
      "Train Epoch: 1 [10000/11714 (85%)]\tLoss: 0.242599\n",
      "Train Epoch: 1 [11000/11714 (93%)]\tLoss: 0.376764\n",
      "Train Epoch: 2 [0/11714 (0%)]\tLoss: 0.435762\n",
      "Train Epoch: 2 [1000/11714 (8%)]\tLoss: 0.388459\n",
      "Train Epoch: 2 [2000/11714 (17%)]\tLoss: 0.249412\n",
      "Train Epoch: 2 [3000/11714 (25%)]\tLoss: 0.531374\n",
      "Train Epoch: 2 [4000/11714 (34%)]\tLoss: 0.389030\n",
      "Train Epoch: 2 [5000/11714 (42%)]\tLoss: 0.437777\n",
      "Train Epoch: 2 [6000/11714 (51%)]\tLoss: 0.359953\n",
      "Train Epoch: 2 [7000/11714 (59%)]\tLoss: 0.311520\n",
      "Train Epoch: 2 [8000/11714 (68%)]\tLoss: 0.339611\n",
      "Train Epoch: 2 [9000/11714 (76%)]\tLoss: 0.252681\n",
      "Train Epoch: 2 [10000/11714 (85%)]\tLoss: 0.389834\n",
      "Train Epoch: 2 [11000/11714 (93%)]\tLoss: 0.285466\n",
      "Train Epoch: 3 [0/11714 (0%)]\tLoss: 0.328075\n",
      "Train Epoch: 3 [1000/11714 (8%)]\tLoss: 0.262694\n",
      "Train Epoch: 3 [2000/11714 (17%)]\tLoss: 0.305319\n",
      "Train Epoch: 3 [3000/11714 (25%)]\tLoss: 0.404477\n",
      "Train Epoch: 3 [4000/11714 (34%)]\tLoss: 0.345831\n",
      "Train Epoch: 3 [5000/11714 (42%)]\tLoss: 0.407014\n",
      "Train Epoch: 3 [6000/11714 (51%)]\tLoss: 0.394350\n",
      "Train Epoch: 3 [7000/11714 (59%)]\tLoss: 0.397035\n",
      "Train Epoch: 3 [8000/11714 (68%)]\tLoss: 0.289279\n",
      "Train Epoch: 3 [9000/11714 (76%)]\tLoss: 0.322006\n",
      "Train Epoch: 3 [10000/11714 (85%)]\tLoss: 0.373225\n",
      "Train Epoch: 3 [11000/11714 (93%)]\tLoss: 0.347603\n",
      "Train Epoch: 4 [0/11714 (0%)]\tLoss: 0.286759\n",
      "Train Epoch: 4 [1000/11714 (8%)]\tLoss: 0.375355\n",
      "Train Epoch: 4 [2000/11714 (17%)]\tLoss: 0.411877\n",
      "Train Epoch: 4 [3000/11714 (25%)]\tLoss: 0.439645\n",
      "Train Epoch: 4 [4000/11714 (34%)]\tLoss: 0.329179\n",
      "Train Epoch: 4 [5000/11714 (42%)]\tLoss: 0.371850\n",
      "Train Epoch: 4 [6000/11714 (51%)]\tLoss: 0.258437\n",
      "Train Epoch: 4 [7000/11714 (59%)]\tLoss: 0.278644\n",
      "Train Epoch: 4 [8000/11714 (68%)]\tLoss: 0.374533\n",
      "Train Epoch: 4 [9000/11714 (76%)]\tLoss: 0.293572\n",
      "Train Epoch: 4 [10000/11714 (85%)]\tLoss: 0.399825\n",
      "Train Epoch: 4 [11000/11714 (93%)]\tLoss: 0.504578\n",
      "Train Epoch: 5 [0/11714 (0%)]\tLoss: 0.392021\n",
      "Train Epoch: 5 [1000/11714 (8%)]\tLoss: 0.407418\n",
      "Train Epoch: 5 [2000/11714 (17%)]\tLoss: 0.315219\n",
      "Train Epoch: 5 [3000/11714 (25%)]\tLoss: 0.357533\n",
      "Train Epoch: 5 [4000/11714 (34%)]\tLoss: 0.345128\n",
      "Train Epoch: 5 [5000/11714 (42%)]\tLoss: 0.360965\n",
      "Train Epoch: 5 [6000/11714 (51%)]\tLoss: 0.389094\n",
      "Train Epoch: 5 [7000/11714 (59%)]\tLoss: 0.378481\n",
      "Train Epoch: 5 [8000/11714 (68%)]\tLoss: 0.222538\n",
      "Train Epoch: 5 [9000/11714 (76%)]\tLoss: 0.364723\n",
      "Train Epoch: 5 [10000/11714 (85%)]\tLoss: 0.389204\n",
      "Train Epoch: 5 [11000/11714 (93%)]\tLoss: 0.267392\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/9877 (0%)]\tLoss: 0.400724\n",
      "Train Epoch: 1 [1000/9877 (10%)]\tLoss: 0.335822\n",
      "Train Epoch: 1 [2000/9877 (20%)]\tLoss: 0.359848\n",
      "Train Epoch: 1 [3000/9877 (30%)]\tLoss: 0.305172\n",
      "Train Epoch: 1 [4000/9877 (40%)]\tLoss: 0.394302\n",
      "Train Epoch: 1 [5000/9877 (51%)]\tLoss: 0.376928\n",
      "Train Epoch: 1 [6000/9877 (61%)]\tLoss: 0.372475\n",
      "Train Epoch: 1 [7000/9877 (71%)]\tLoss: 0.281409\n",
      "Train Epoch: 1 [8000/9877 (81%)]\tLoss: 0.333944\n",
      "Train Epoch: 1 [9000/9877 (91%)]\tLoss: 0.256235\n",
      "Train Epoch: 2 [0/9877 (0%)]\tLoss: 0.409590\n",
      "Train Epoch: 2 [1000/9877 (10%)]\tLoss: 0.362253\n",
      "Train Epoch: 2 [2000/9877 (20%)]\tLoss: 0.372446\n",
      "Train Epoch: 2 [3000/9877 (30%)]\tLoss: 0.434564\n",
      "Train Epoch: 2 [4000/9877 (40%)]\tLoss: 0.465384\n",
      "Train Epoch: 2 [5000/9877 (51%)]\tLoss: 0.263916\n",
      "Train Epoch: 2 [6000/9877 (61%)]\tLoss: 0.387253\n",
      "Train Epoch: 2 [7000/9877 (71%)]\tLoss: 0.449581\n",
      "Train Epoch: 2 [8000/9877 (81%)]\tLoss: 0.542268\n",
      "Train Epoch: 2 [9000/9877 (91%)]\tLoss: 0.319920\n",
      "Train Epoch: 3 [0/9877 (0%)]\tLoss: 0.373853\n",
      "Train Epoch: 3 [1000/9877 (10%)]\tLoss: 0.365135\n",
      "Train Epoch: 3 [2000/9877 (20%)]\tLoss: 0.375018\n",
      "Train Epoch: 3 [3000/9877 (30%)]\tLoss: 0.329440\n",
      "Train Epoch: 3 [4000/9877 (40%)]\tLoss: 0.344045\n",
      "Train Epoch: 3 [5000/9877 (51%)]\tLoss: 0.271674\n",
      "Train Epoch: 3 [6000/9877 (61%)]\tLoss: 0.255460\n",
      "Train Epoch: 3 [7000/9877 (71%)]\tLoss: 0.310721\n",
      "Train Epoch: 3 [8000/9877 (81%)]\tLoss: 0.386055\n",
      "Train Epoch: 3 [9000/9877 (91%)]\tLoss: 0.341185\n",
      "Train Epoch: 4 [0/9877 (0%)]\tLoss: 0.313321\n",
      "Train Epoch: 4 [1000/9877 (10%)]\tLoss: 0.333867\n",
      "Train Epoch: 4 [2000/9877 (20%)]\tLoss: 0.251765\n",
      "Train Epoch: 4 [3000/9877 (30%)]\tLoss: 0.363041\n",
      "Train Epoch: 4 [4000/9877 (40%)]\tLoss: 0.224946\n",
      "Train Epoch: 4 [5000/9877 (51%)]\tLoss: 0.404688\n",
      "Train Epoch: 4 [6000/9877 (61%)]\tLoss: 0.359945\n",
      "Train Epoch: 4 [7000/9877 (71%)]\tLoss: 0.342347\n",
      "Train Epoch: 4 [8000/9877 (81%)]\tLoss: 0.283982\n",
      "Train Epoch: 4 [9000/9877 (91%)]\tLoss: 0.392382\n",
      "Train Epoch: 5 [0/9877 (0%)]\tLoss: 0.452180\n",
      "Train Epoch: 5 [1000/9877 (10%)]\tLoss: 0.322276\n",
      "Train Epoch: 5 [2000/9877 (20%)]\tLoss: 0.427762\n",
      "Train Epoch: 5 [3000/9877 (30%)]\tLoss: 0.368595\n",
      "Train Epoch: 5 [4000/9877 (40%)]\tLoss: 0.228687\n",
      "Train Epoch: 5 [5000/9877 (51%)]\tLoss: 0.254814\n",
      "Train Epoch: 5 [6000/9877 (61%)]\tLoss: 0.309261\n",
      "Train Epoch: 5 [7000/9877 (71%)]\tLoss: 0.366727\n",
      "Train Epoch: 5 [8000/9877 (81%)]\tLoss: 0.371195\n",
      "Train Epoch: 5 [9000/9877 (91%)]\tLoss: 0.298475\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9260, Accuracy: 7644/10000 (76%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/12367 (0%)]\tLoss: 0.297946\n",
      "Train Epoch: 1 [1000/12367 (8%)]\tLoss: 0.420093\n",
      "Train Epoch: 1 [2000/12367 (16%)]\tLoss: 0.624520\n",
      "Train Epoch: 1 [3000/12367 (24%)]\tLoss: 0.311132\n",
      "Train Epoch: 1 [4000/12367 (32%)]\tLoss: 0.306670\n",
      "Train Epoch: 1 [5000/12367 (40%)]\tLoss: 0.409601\n",
      "Train Epoch: 1 [6000/12367 (48%)]\tLoss: 0.372720\n",
      "Train Epoch: 1 [7000/12367 (56%)]\tLoss: 0.342400\n",
      "Train Epoch: 1 [8000/12367 (65%)]\tLoss: 0.379842\n",
      "Train Epoch: 1 [9000/12367 (73%)]\tLoss: 0.440651\n",
      "Train Epoch: 1 [10000/12367 (81%)]\tLoss: 0.383716\n",
      "Train Epoch: 1 [11000/12367 (89%)]\tLoss: 0.468932\n",
      "Train Epoch: 1 [12000/12367 (97%)]\tLoss: 0.446707\n",
      "Train Epoch: 2 [0/12367 (0%)]\tLoss: 0.504693\n",
      "Train Epoch: 2 [1000/12367 (8%)]\tLoss: 0.383249\n",
      "Train Epoch: 2 [2000/12367 (16%)]\tLoss: 0.423469\n",
      "Train Epoch: 2 [3000/12367 (24%)]\tLoss: 0.385124\n",
      "Train Epoch: 2 [4000/12367 (32%)]\tLoss: 0.344247\n",
      "Train Epoch: 2 [5000/12367 (40%)]\tLoss: 0.416983\n",
      "Train Epoch: 2 [6000/12367 (48%)]\tLoss: 0.501653\n",
      "Train Epoch: 2 [7000/12367 (56%)]\tLoss: 0.570157\n",
      "Train Epoch: 2 [8000/12367 (65%)]\tLoss: 0.386496\n",
      "Train Epoch: 2 [9000/12367 (73%)]\tLoss: 0.511310\n",
      "Train Epoch: 2 [10000/12367 (81%)]\tLoss: 0.401536\n",
      "Train Epoch: 2 [11000/12367 (89%)]\tLoss: 0.499040\n",
      "Train Epoch: 2 [12000/12367 (97%)]\tLoss: 0.416119\n",
      "Train Epoch: 3 [0/12367 (0%)]\tLoss: 0.491727\n",
      "Train Epoch: 3 [1000/12367 (8%)]\tLoss: 0.350314\n",
      "Train Epoch: 3 [2000/12367 (16%)]\tLoss: 0.376696\n",
      "Train Epoch: 3 [3000/12367 (24%)]\tLoss: 0.344003\n",
      "Train Epoch: 3 [4000/12367 (32%)]\tLoss: 0.333095\n",
      "Train Epoch: 3 [5000/12367 (40%)]\tLoss: 0.432110\n",
      "Train Epoch: 3 [6000/12367 (48%)]\tLoss: 0.468944\n",
      "Train Epoch: 3 [7000/12367 (56%)]\tLoss: 0.269887\n",
      "Train Epoch: 3 [8000/12367 (65%)]\tLoss: 0.248778\n",
      "Train Epoch: 3 [9000/12367 (73%)]\tLoss: 0.238200\n",
      "Train Epoch: 3 [10000/12367 (81%)]\tLoss: 0.528412\n",
      "Train Epoch: 3 [11000/12367 (89%)]\tLoss: 0.370279\n",
      "Train Epoch: 3 [12000/12367 (97%)]\tLoss: 0.400486\n",
      "Train Epoch: 4 [0/12367 (0%)]\tLoss: 0.432478\n",
      "Train Epoch: 4 [1000/12367 (8%)]\tLoss: 0.419469\n",
      "Train Epoch: 4 [2000/12367 (16%)]\tLoss: 0.542866\n",
      "Train Epoch: 4 [3000/12367 (24%)]\tLoss: 0.525533\n",
      "Train Epoch: 4 [4000/12367 (32%)]\tLoss: 0.488958\n",
      "Train Epoch: 4 [5000/12367 (40%)]\tLoss: 0.434854\n",
      "Train Epoch: 4 [6000/12367 (48%)]\tLoss: 0.483599\n",
      "Train Epoch: 4 [7000/12367 (56%)]\tLoss: 0.461389\n",
      "Train Epoch: 4 [8000/12367 (65%)]\tLoss: 0.442433\n",
      "Train Epoch: 4 [9000/12367 (73%)]\tLoss: 0.347566\n",
      "Train Epoch: 4 [10000/12367 (81%)]\tLoss: 0.383401\n",
      "Train Epoch: 4 [11000/12367 (89%)]\tLoss: 0.241967\n",
      "Train Epoch: 4 [12000/12367 (97%)]\tLoss: 0.302094\n",
      "Train Epoch: 5 [0/12367 (0%)]\tLoss: 0.332171\n",
      "Train Epoch: 5 [1000/12367 (8%)]\tLoss: 0.289863\n",
      "Train Epoch: 5 [2000/12367 (16%)]\tLoss: 0.300104\n",
      "Train Epoch: 5 [3000/12367 (24%)]\tLoss: 0.407463\n",
      "Train Epoch: 5 [4000/12367 (32%)]\tLoss: 0.346600\n",
      "Train Epoch: 5 [5000/12367 (40%)]\tLoss: 0.382473\n",
      "Train Epoch: 5 [6000/12367 (48%)]\tLoss: 0.387064\n",
      "Train Epoch: 5 [7000/12367 (56%)]\tLoss: 0.472783\n",
      "Train Epoch: 5 [8000/12367 (65%)]\tLoss: 0.560890\n",
      "Train Epoch: 5 [9000/12367 (73%)]\tLoss: 0.244845\n",
      "Train Epoch: 5 [10000/12367 (81%)]\tLoss: 0.455987\n",
      "Train Epoch: 5 [11000/12367 (89%)]\tLoss: 0.352729\n",
      "Train Epoch: 5 [12000/12367 (97%)]\tLoss: 0.296120\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.492648\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.177129\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.155839\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.114541\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.080202\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.146442\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.127337\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.179582\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.149292\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.232362\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.166350\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.206042\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.138001\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.229358\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.169646\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.100078\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.274460\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.139351\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.100089\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.105256\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.127107\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.256614\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.260468\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.190424\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.173832\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.130772\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.195207\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.167134\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.169983\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.137144\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.137707\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.328200\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.202548\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.169256\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.127976\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.289513\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.155081\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.240622\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.178221\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.047512\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.252491\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.309899\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.185819\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.371546\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.208258\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.240473\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.171701\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.232688\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.263491\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.306754\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.231672\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.232853\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.227185\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.253125\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.249800\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.291923\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.184746\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.222925\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.221808\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.165912\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.237955\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.266263\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.257557\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.219026\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.265673\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.194603\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.128393\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.285413\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.251163\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.227890\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.272907\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.327658\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.233930\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.351793\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.380441\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/12288 (0%)]\tLoss: 0.315491\n",
      "Train Epoch: 1 [1000/12288 (8%)]\tLoss: 0.293646\n",
      "Train Epoch: 1 [2000/12288 (16%)]\tLoss: 0.296543\n",
      "Train Epoch: 1 [3000/12288 (24%)]\tLoss: 0.298875\n",
      "Train Epoch: 1 [4000/12288 (33%)]\tLoss: 0.442366\n",
      "Train Epoch: 1 [5000/12288 (41%)]\tLoss: 0.448006\n",
      "Train Epoch: 1 [6000/12288 (49%)]\tLoss: 0.314043\n",
      "Train Epoch: 1 [7000/12288 (57%)]\tLoss: 0.329250\n",
      "Train Epoch: 1 [8000/12288 (65%)]\tLoss: 0.448274\n",
      "Train Epoch: 1 [9000/12288 (73%)]\tLoss: 0.339386\n",
      "Train Epoch: 1 [10000/12288 (81%)]\tLoss: 0.291985\n",
      "Train Epoch: 1 [11000/12288 (89%)]\tLoss: 0.448681\n",
      "Train Epoch: 1 [12000/12288 (98%)]\tLoss: 0.391824\n",
      "Train Epoch: 2 [0/12288 (0%)]\tLoss: 0.263430\n",
      "Train Epoch: 2 [1000/12288 (8%)]\tLoss: 0.422481\n",
      "Train Epoch: 2 [2000/12288 (16%)]\tLoss: 0.261363\n",
      "Train Epoch: 2 [3000/12288 (24%)]\tLoss: 0.352081\n",
      "Train Epoch: 2 [4000/12288 (33%)]\tLoss: 0.438724\n",
      "Train Epoch: 2 [5000/12288 (41%)]\tLoss: 0.306261\n",
      "Train Epoch: 2 [6000/12288 (49%)]\tLoss: 0.273210\n",
      "Train Epoch: 2 [7000/12288 (57%)]\tLoss: 0.275000\n",
      "Train Epoch: 2 [8000/12288 (65%)]\tLoss: 0.343754\n",
      "Train Epoch: 2 [9000/12288 (73%)]\tLoss: 0.335448\n",
      "Train Epoch: 2 [10000/12288 (81%)]\tLoss: 0.397026\n",
      "Train Epoch: 2 [11000/12288 (89%)]\tLoss: 0.288945\n",
      "Train Epoch: 2 [12000/12288 (98%)]\tLoss: 0.263613\n",
      "Train Epoch: 3 [0/12288 (0%)]\tLoss: 0.229523\n",
      "Train Epoch: 3 [1000/12288 (8%)]\tLoss: 0.333797\n",
      "Train Epoch: 3 [2000/12288 (16%)]\tLoss: 0.245470\n",
      "Train Epoch: 3 [3000/12288 (24%)]\tLoss: 0.207669\n",
      "Train Epoch: 3 [4000/12288 (33%)]\tLoss: 0.334314\n",
      "Train Epoch: 3 [5000/12288 (41%)]\tLoss: 0.248625\n",
      "Train Epoch: 3 [6000/12288 (49%)]\tLoss: 0.341466\n",
      "Train Epoch: 3 [7000/12288 (57%)]\tLoss: 0.238541\n",
      "Train Epoch: 3 [8000/12288 (65%)]\tLoss: 0.339295\n",
      "Train Epoch: 3 [9000/12288 (73%)]\tLoss: 0.423386\n",
      "Train Epoch: 3 [10000/12288 (81%)]\tLoss: 0.364840\n",
      "Train Epoch: 3 [11000/12288 (89%)]\tLoss: 0.284317\n",
      "Train Epoch: 3 [12000/12288 (98%)]\tLoss: 0.225366\n",
      "Train Epoch: 4 [0/12288 (0%)]\tLoss: 0.238025\n",
      "Train Epoch: 4 [1000/12288 (8%)]\tLoss: 0.282990\n",
      "Train Epoch: 4 [2000/12288 (16%)]\tLoss: 0.282501\n",
      "Train Epoch: 4 [3000/12288 (24%)]\tLoss: 0.173427\n",
      "Train Epoch: 4 [4000/12288 (33%)]\tLoss: 0.290800\n",
      "Train Epoch: 4 [5000/12288 (41%)]\tLoss: 0.146069\n",
      "Train Epoch: 4 [6000/12288 (49%)]\tLoss: 0.252442\n",
      "Train Epoch: 4 [7000/12288 (57%)]\tLoss: 0.414058\n",
      "Train Epoch: 4 [8000/12288 (65%)]\tLoss: 0.323188\n",
      "Train Epoch: 4 [9000/12288 (73%)]\tLoss: 0.290176\n",
      "Train Epoch: 4 [10000/12288 (81%)]\tLoss: 0.383524\n",
      "Train Epoch: 4 [11000/12288 (89%)]\tLoss: 0.219542\n",
      "Train Epoch: 4 [12000/12288 (98%)]\tLoss: 0.387179\n",
      "Train Epoch: 5 [0/12288 (0%)]\tLoss: 0.323131\n",
      "Train Epoch: 5 [1000/12288 (8%)]\tLoss: 0.277077\n",
      "Train Epoch: 5 [2000/12288 (16%)]\tLoss: 0.418828\n",
      "Train Epoch: 5 [3000/12288 (24%)]\tLoss: 0.469564\n",
      "Train Epoch: 5 [4000/12288 (33%)]\tLoss: 0.367231\n",
      "Train Epoch: 5 [5000/12288 (41%)]\tLoss: 0.346632\n",
      "Train Epoch: 5 [6000/12288 (49%)]\tLoss: 0.340136\n",
      "Train Epoch: 5 [7000/12288 (57%)]\tLoss: 0.329820\n",
      "Train Epoch: 5 [8000/12288 (65%)]\tLoss: 0.326992\n",
      "Train Epoch: 5 [9000/12288 (73%)]\tLoss: 0.340042\n",
      "Train Epoch: 5 [10000/12288 (81%)]\tLoss: 0.279789\n",
      "Train Epoch: 5 [11000/12288 (89%)]\tLoss: 0.358466\n",
      "Train Epoch: 5 [12000/12288 (98%)]\tLoss: 0.238040\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/11714 (0%)]\tLoss: 0.357933\n",
      "Train Epoch: 1 [1000/11714 (8%)]\tLoss: 0.416088\n",
      "Train Epoch: 1 [2000/11714 (17%)]\tLoss: 0.365538\n",
      "Train Epoch: 1 [3000/11714 (25%)]\tLoss: 0.403311\n",
      "Train Epoch: 1 [4000/11714 (34%)]\tLoss: 0.362494\n",
      "Train Epoch: 1 [5000/11714 (42%)]\tLoss: 0.372306\n",
      "Train Epoch: 1 [6000/11714 (51%)]\tLoss: 0.422601\n",
      "Train Epoch: 1 [7000/11714 (59%)]\tLoss: 0.469173\n",
      "Train Epoch: 1 [8000/11714 (68%)]\tLoss: 0.251413\n",
      "Train Epoch: 1 [9000/11714 (76%)]\tLoss: 0.387454\n",
      "Train Epoch: 1 [10000/11714 (85%)]\tLoss: 0.360366\n",
      "Train Epoch: 1 [11000/11714 (93%)]\tLoss: 0.440364\n",
      "Train Epoch: 2 [0/11714 (0%)]\tLoss: 0.390636\n",
      "Train Epoch: 2 [1000/11714 (8%)]\tLoss: 0.337453\n",
      "Train Epoch: 2 [2000/11714 (17%)]\tLoss: 0.322791\n",
      "Train Epoch: 2 [3000/11714 (25%)]\tLoss: 0.266933\n",
      "Train Epoch: 2 [4000/11714 (34%)]\tLoss: 0.309613\n",
      "Train Epoch: 2 [5000/11714 (42%)]\tLoss: 0.294701\n",
      "Train Epoch: 2 [6000/11714 (51%)]\tLoss: 0.376410\n",
      "Train Epoch: 2 [7000/11714 (59%)]\tLoss: 0.348022\n",
      "Train Epoch: 2 [8000/11714 (68%)]\tLoss: 0.358311\n",
      "Train Epoch: 2 [9000/11714 (76%)]\tLoss: 0.361621\n",
      "Train Epoch: 2 [10000/11714 (85%)]\tLoss: 0.438498\n",
      "Train Epoch: 2 [11000/11714 (93%)]\tLoss: 0.339990\n",
      "Train Epoch: 3 [0/11714 (0%)]\tLoss: 0.463979\n",
      "Train Epoch: 3 [1000/11714 (8%)]\tLoss: 0.431674\n",
      "Train Epoch: 3 [2000/11714 (17%)]\tLoss: 0.234689\n",
      "Train Epoch: 3 [3000/11714 (25%)]\tLoss: 0.274175\n",
      "Train Epoch: 3 [4000/11714 (34%)]\tLoss: 0.380807\n",
      "Train Epoch: 3 [5000/11714 (42%)]\tLoss: 0.227513\n",
      "Train Epoch: 3 [6000/11714 (51%)]\tLoss: 0.289877\n",
      "Train Epoch: 3 [7000/11714 (59%)]\tLoss: 0.346485\n",
      "Train Epoch: 3 [8000/11714 (68%)]\tLoss: 0.335051\n",
      "Train Epoch: 3 [9000/11714 (76%)]\tLoss: 0.312487\n",
      "Train Epoch: 3 [10000/11714 (85%)]\tLoss: 0.302250\n",
      "Train Epoch: 3 [11000/11714 (93%)]\tLoss: 0.298154\n",
      "Train Epoch: 4 [0/11714 (0%)]\tLoss: 0.371644\n",
      "Train Epoch: 4 [1000/11714 (8%)]\tLoss: 0.275488\n",
      "Train Epoch: 4 [2000/11714 (17%)]\tLoss: 0.402109\n",
      "Train Epoch: 4 [3000/11714 (25%)]\tLoss: 0.276249\n",
      "Train Epoch: 4 [4000/11714 (34%)]\tLoss: 0.481198\n",
      "Train Epoch: 4 [5000/11714 (42%)]\tLoss: 0.325894\n",
      "Train Epoch: 4 [6000/11714 (51%)]\tLoss: 0.311357\n",
      "Train Epoch: 4 [7000/11714 (59%)]\tLoss: 0.281848\n",
      "Train Epoch: 4 [8000/11714 (68%)]\tLoss: 0.221019\n",
      "Train Epoch: 4 [9000/11714 (76%)]\tLoss: 0.369406\n",
      "Train Epoch: 4 [10000/11714 (85%)]\tLoss: 0.329169\n",
      "Train Epoch: 4 [11000/11714 (93%)]\tLoss: 0.293484\n",
      "Train Epoch: 5 [0/11714 (0%)]\tLoss: 0.530497\n",
      "Train Epoch: 5 [1000/11714 (8%)]\tLoss: 0.306449\n",
      "Train Epoch: 5 [2000/11714 (17%)]\tLoss: 0.431359\n",
      "Train Epoch: 5 [3000/11714 (25%)]\tLoss: 0.407573\n",
      "Train Epoch: 5 [4000/11714 (34%)]\tLoss: 0.352324\n",
      "Train Epoch: 5 [5000/11714 (42%)]\tLoss: 0.326088\n",
      "Train Epoch: 5 [6000/11714 (51%)]\tLoss: 0.366815\n",
      "Train Epoch: 5 [7000/11714 (59%)]\tLoss: 0.288549\n",
      "Train Epoch: 5 [8000/11714 (68%)]\tLoss: 0.243749\n",
      "Train Epoch: 5 [9000/11714 (76%)]\tLoss: 0.318909\n",
      "Train Epoch: 5 [10000/11714 (85%)]\tLoss: 0.298178\n",
      "Train Epoch: 5 [11000/11714 (93%)]\tLoss: 0.258608\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/9877 (0%)]\tLoss: 0.550674\n",
      "Train Epoch: 1 [1000/9877 (10%)]\tLoss: 0.327919\n",
      "Train Epoch: 1 [2000/9877 (20%)]\tLoss: 0.372414\n",
      "Train Epoch: 1 [3000/9877 (30%)]\tLoss: 0.306292\n",
      "Train Epoch: 1 [4000/9877 (40%)]\tLoss: 0.306751\n",
      "Train Epoch: 1 [5000/9877 (51%)]\tLoss: 0.303422\n",
      "Train Epoch: 1 [6000/9877 (61%)]\tLoss: 0.432686\n",
      "Train Epoch: 1 [7000/9877 (71%)]\tLoss: 0.354454\n",
      "Train Epoch: 1 [8000/9877 (81%)]\tLoss: 0.404735\n",
      "Train Epoch: 1 [9000/9877 (91%)]\tLoss: 0.396695\n",
      "Train Epoch: 2 [0/9877 (0%)]\tLoss: 0.274422\n",
      "Train Epoch: 2 [1000/9877 (10%)]\tLoss: 0.298388\n",
      "Train Epoch: 2 [2000/9877 (20%)]\tLoss: 0.305335\n",
      "Train Epoch: 2 [3000/9877 (30%)]\tLoss: 0.279245\n",
      "Train Epoch: 2 [4000/9877 (40%)]\tLoss: 0.286634\n",
      "Train Epoch: 2 [5000/9877 (51%)]\tLoss: 0.341853\n",
      "Train Epoch: 2 [6000/9877 (61%)]\tLoss: 0.440691\n",
      "Train Epoch: 2 [7000/9877 (71%)]\tLoss: 0.237581\n",
      "Train Epoch: 2 [8000/9877 (81%)]\tLoss: 0.310823\n",
      "Train Epoch: 2 [9000/9877 (91%)]\tLoss: 0.347244\n",
      "Train Epoch: 3 [0/9877 (0%)]\tLoss: 0.323127\n",
      "Train Epoch: 3 [1000/9877 (10%)]\tLoss: 0.311366\n",
      "Train Epoch: 3 [2000/9877 (20%)]\tLoss: 0.254392\n",
      "Train Epoch: 3 [3000/9877 (30%)]\tLoss: 0.362898\n",
      "Train Epoch: 3 [4000/9877 (40%)]\tLoss: 0.308298\n",
      "Train Epoch: 3 [5000/9877 (51%)]\tLoss: 0.379349\n",
      "Train Epoch: 3 [6000/9877 (61%)]\tLoss: 0.270444\n",
      "Train Epoch: 3 [7000/9877 (71%)]\tLoss: 0.461036\n",
      "Train Epoch: 3 [8000/9877 (81%)]\tLoss: 0.284690\n",
      "Train Epoch: 3 [9000/9877 (91%)]\tLoss: 0.379013\n",
      "Train Epoch: 4 [0/9877 (0%)]\tLoss: 0.361010\n",
      "Train Epoch: 4 [1000/9877 (10%)]\tLoss: 0.427513\n",
      "Train Epoch: 4 [2000/9877 (20%)]\tLoss: 0.445223\n",
      "Train Epoch: 4 [3000/9877 (30%)]\tLoss: 0.271698\n",
      "Train Epoch: 4 [4000/9877 (40%)]\tLoss: 0.442658\n",
      "Train Epoch: 4 [5000/9877 (51%)]\tLoss: 0.362798\n",
      "Train Epoch: 4 [6000/9877 (61%)]\tLoss: 0.411597\n",
      "Train Epoch: 4 [7000/9877 (71%)]\tLoss: 0.389898\n",
      "Train Epoch: 4 [8000/9877 (81%)]\tLoss: 0.397203\n",
      "Train Epoch: 4 [9000/9877 (91%)]\tLoss: 0.273503\n",
      "Train Epoch: 5 [0/9877 (0%)]\tLoss: 0.256515\n",
      "Train Epoch: 5 [1000/9877 (10%)]\tLoss: 0.389179\n",
      "Train Epoch: 5 [2000/9877 (20%)]\tLoss: 0.330367\n",
      "Train Epoch: 5 [3000/9877 (30%)]\tLoss: 0.372959\n",
      "Train Epoch: 5 [4000/9877 (40%)]\tLoss: 0.272885\n",
      "Train Epoch: 5 [5000/9877 (51%)]\tLoss: 0.321210\n",
      "Train Epoch: 5 [6000/9877 (61%)]\tLoss: 0.244543\n",
      "Train Epoch: 5 [7000/9877 (71%)]\tLoss: 0.429994\n",
      "Train Epoch: 5 [8000/9877 (81%)]\tLoss: 0.334487\n",
      "Train Epoch: 5 [9000/9877 (91%)]\tLoss: 0.372818\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9189, Accuracy: 7656/10000 (77%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/9140 (0%)]\tLoss: 0.486466\n",
      "Train Epoch: 1 [1000/9140 (11%)]\tLoss: 0.314479\n",
      "Train Epoch: 1 [2000/9140 (22%)]\tLoss: 0.344788\n",
      "Train Epoch: 1 [3000/9140 (33%)]\tLoss: 0.337608\n",
      "Train Epoch: 1 [4000/9140 (43%)]\tLoss: 0.492688\n",
      "Train Epoch: 1 [5000/9140 (54%)]\tLoss: 0.422244\n",
      "Train Epoch: 1 [6000/9140 (65%)]\tLoss: 0.309510\n",
      "Train Epoch: 1 [7000/9140 (76%)]\tLoss: 0.500784\n",
      "Train Epoch: 1 [8000/9140 (87%)]\tLoss: 0.266979\n",
      "Train Epoch: 1 [9000/9140 (98%)]\tLoss: 0.280501\n",
      "Train Epoch: 2 [0/9140 (0%)]\tLoss: 0.230314\n",
      "Train Epoch: 2 [1000/9140 (11%)]\tLoss: 0.407869\n",
      "Train Epoch: 2 [2000/9140 (22%)]\tLoss: 0.320807\n",
      "Train Epoch: 2 [3000/9140 (33%)]\tLoss: 0.487327\n",
      "Train Epoch: 2 [4000/9140 (43%)]\tLoss: 0.321147\n",
      "Train Epoch: 2 [5000/9140 (54%)]\tLoss: 0.391205\n",
      "Train Epoch: 2 [6000/9140 (65%)]\tLoss: 0.388430\n",
      "Train Epoch: 2 [7000/9140 (76%)]\tLoss: 0.433930\n",
      "Train Epoch: 2 [8000/9140 (87%)]\tLoss: 0.344711\n",
      "Train Epoch: 2 [9000/9140 (98%)]\tLoss: 0.275238\n",
      "Train Epoch: 3 [0/9140 (0%)]\tLoss: 0.458716\n",
      "Train Epoch: 3 [1000/9140 (11%)]\tLoss: 0.275496\n",
      "Train Epoch: 3 [2000/9140 (22%)]\tLoss: 0.284499\n",
      "Train Epoch: 3 [3000/9140 (33%)]\tLoss: 0.328202\n",
      "Train Epoch: 3 [4000/9140 (43%)]\tLoss: 0.343490\n",
      "Train Epoch: 3 [5000/9140 (54%)]\tLoss: 0.345971\n",
      "Train Epoch: 3 [6000/9140 (65%)]\tLoss: 0.393615\n",
      "Train Epoch: 3 [7000/9140 (76%)]\tLoss: 0.436004\n",
      "Train Epoch: 3 [8000/9140 (87%)]\tLoss: 0.378373\n",
      "Train Epoch: 3 [9000/9140 (98%)]\tLoss: 0.262397\n",
      "Train Epoch: 4 [0/9140 (0%)]\tLoss: 0.355396\n",
      "Train Epoch: 4 [1000/9140 (11%)]\tLoss: 0.381222\n",
      "Train Epoch: 4 [2000/9140 (22%)]\tLoss: 0.410393\n",
      "Train Epoch: 4 [3000/9140 (33%)]\tLoss: 0.352058\n",
      "Train Epoch: 4 [4000/9140 (43%)]\tLoss: 0.352855\n",
      "Train Epoch: 4 [5000/9140 (54%)]\tLoss: 0.388827\n",
      "Train Epoch: 4 [6000/9140 (65%)]\tLoss: 0.374756\n",
      "Train Epoch: 4 [7000/9140 (76%)]\tLoss: 0.417171\n",
      "Train Epoch: 4 [8000/9140 (87%)]\tLoss: 0.260863\n",
      "Train Epoch: 4 [9000/9140 (98%)]\tLoss: 0.384985\n",
      "Train Epoch: 5 [0/9140 (0%)]\tLoss: 0.299311\n",
      "Train Epoch: 5 [1000/9140 (11%)]\tLoss: 0.395600\n",
      "Train Epoch: 5 [2000/9140 (22%)]\tLoss: 0.521541\n",
      "Train Epoch: 5 [3000/9140 (33%)]\tLoss: 0.452778\n",
      "Train Epoch: 5 [4000/9140 (43%)]\tLoss: 0.360386\n",
      "Train Epoch: 5 [5000/9140 (54%)]\tLoss: 0.265125\n",
      "Train Epoch: 5 [6000/9140 (65%)]\tLoss: 0.342625\n",
      "Train Epoch: 5 [7000/9140 (76%)]\tLoss: 0.429264\n",
      "Train Epoch: 5 [8000/9140 (87%)]\tLoss: 0.252327\n",
      "Train Epoch: 5 [9000/9140 (98%)]\tLoss: 0.280239\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.524890\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.233764\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.139977\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.295013\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.174817\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.297875\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.239605\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.083101\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.157071\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.154735\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.089686\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.123606\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.240437\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.156078\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.085720\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.132807\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.165269\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.278264\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.172623\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.121165\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.212534\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.143326\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.109475\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.131086\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.110785\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.085321\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.171142\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.174936\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.090448\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.199500\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.195255\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.163774\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.231922\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.081625\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.073775\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.146867\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.142891\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.151496\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.128870\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.151514\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.483074\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.234630\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.313272\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.291296\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.264177\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.254533\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.223093\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.135464\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.192978\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.310138\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.207829\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.270026\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.275004\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.246620\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.425088\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.193096\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.215507\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.233138\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.197202\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.243989\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.114492\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.292480\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.252436\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.411285\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.264151\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.385251\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.270068\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.277937\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.200517\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.217771\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.260907\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.161863\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.239919\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.195866\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.152068\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.477403\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.278267\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.354992\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.237669\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.332107\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.244063\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.272015\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.264253\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.193929\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.299596\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.255907\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.203702\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.286283\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.174454\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.360618\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.191385\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.323865\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.332301\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.155658\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.323358\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.209192\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.162258\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.211173\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.276959\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.306783\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.152613\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.214919\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.240471\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.182547\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.252792\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.374376\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.209394\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.331384\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.286010\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.267596\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.388561\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.372970\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.306129\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.244164\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.406167\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.241932\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.295249\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.202159\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.275674\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.362841\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.300420\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.334703\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.364777\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.338316\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.257862\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.338420\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.348413\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.278577\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.337515\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.254978\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.205471\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.246922\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.330852\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.452893\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.243766\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/10213 (0%)]\tLoss: 0.523811\n",
      "Train Epoch: 1 [1000/10213 (10%)]\tLoss: 0.404300\n",
      "Train Epoch: 1 [2000/10213 (19%)]\tLoss: 0.267138\n",
      "Train Epoch: 1 [3000/10213 (29%)]\tLoss: 0.285357\n",
      "Train Epoch: 1 [4000/10213 (39%)]\tLoss: 0.382374\n",
      "Train Epoch: 1 [5000/10213 (49%)]\tLoss: 0.381801\n",
      "Train Epoch: 1 [6000/10213 (58%)]\tLoss: 0.486181\n",
      "Train Epoch: 1 [7000/10213 (68%)]\tLoss: 0.271522\n",
      "Train Epoch: 1 [8000/10213 (78%)]\tLoss: 0.560911\n",
      "Train Epoch: 1 [9000/10213 (87%)]\tLoss: 0.324997\n",
      "Train Epoch: 1 [10000/10213 (97%)]\tLoss: 0.295442\n",
      "Train Epoch: 2 [0/10213 (0%)]\tLoss: 0.248277\n",
      "Train Epoch: 2 [1000/10213 (10%)]\tLoss: 0.405616\n",
      "Train Epoch: 2 [2000/10213 (19%)]\tLoss: 0.427648\n",
      "Train Epoch: 2 [3000/10213 (29%)]\tLoss: 0.319791\n",
      "Train Epoch: 2 [4000/10213 (39%)]\tLoss: 0.374597\n",
      "Train Epoch: 2 [5000/10213 (49%)]\tLoss: 0.382570\n",
      "Train Epoch: 2 [6000/10213 (58%)]\tLoss: 0.443652\n",
      "Train Epoch: 2 [7000/10213 (68%)]\tLoss: 0.357877\n",
      "Train Epoch: 2 [8000/10213 (78%)]\tLoss: 0.294017\n",
      "Train Epoch: 2 [9000/10213 (87%)]\tLoss: 0.320618\n",
      "Train Epoch: 2 [10000/10213 (97%)]\tLoss: 0.313047\n",
      "Train Epoch: 3 [0/10213 (0%)]\tLoss: 0.358324\n",
      "Train Epoch: 3 [1000/10213 (10%)]\tLoss: 0.263137\n",
      "Train Epoch: 3 [2000/10213 (19%)]\tLoss: 0.376144\n",
      "Train Epoch: 3 [3000/10213 (29%)]\tLoss: 0.340779\n",
      "Train Epoch: 3 [4000/10213 (39%)]\tLoss: 0.381599\n",
      "Train Epoch: 3 [5000/10213 (49%)]\tLoss: 0.396532\n",
      "Train Epoch: 3 [6000/10213 (58%)]\tLoss: 0.349970\n",
      "Train Epoch: 3 [7000/10213 (68%)]\tLoss: 0.491395\n",
      "Train Epoch: 3 [8000/10213 (78%)]\tLoss: 0.352896\n",
      "Train Epoch: 3 [9000/10213 (87%)]\tLoss: 0.381048\n",
      "Train Epoch: 3 [10000/10213 (97%)]\tLoss: 0.411239\n",
      "Train Epoch: 4 [0/10213 (0%)]\tLoss: 0.443288\n",
      "Train Epoch: 4 [1000/10213 (10%)]\tLoss: 0.486247\n",
      "Train Epoch: 4 [2000/10213 (19%)]\tLoss: 0.458252\n",
      "Train Epoch: 4 [3000/10213 (29%)]\tLoss: 0.369317\n",
      "Train Epoch: 4 [4000/10213 (39%)]\tLoss: 0.232903\n",
      "Train Epoch: 4 [5000/10213 (49%)]\tLoss: 0.388880\n",
      "Train Epoch: 4 [6000/10213 (58%)]\tLoss: 0.231650\n",
      "Train Epoch: 4 [7000/10213 (68%)]\tLoss: 0.233118\n",
      "Train Epoch: 4 [8000/10213 (78%)]\tLoss: 0.499735\n",
      "Train Epoch: 4 [9000/10213 (87%)]\tLoss: 0.481585\n",
      "Train Epoch: 4 [10000/10213 (97%)]\tLoss: 0.302682\n",
      "Train Epoch: 5 [0/10213 (0%)]\tLoss: 0.367878\n",
      "Train Epoch: 5 [1000/10213 (10%)]\tLoss: 0.341182\n",
      "Train Epoch: 5 [2000/10213 (19%)]\tLoss: 0.343476\n",
      "Train Epoch: 5 [3000/10213 (29%)]\tLoss: 0.394089\n",
      "Train Epoch: 5 [4000/10213 (39%)]\tLoss: 0.368228\n",
      "Train Epoch: 5 [5000/10213 (49%)]\tLoss: 0.282557\n",
      "Train Epoch: 5 [6000/10213 (58%)]\tLoss: 0.251288\n",
      "Train Epoch: 5 [7000/10213 (68%)]\tLoss: 0.300822\n",
      "Train Epoch: 5 [8000/10213 (78%)]\tLoss: 0.349259\n",
      "Train Epoch: 5 [9000/10213 (87%)]\tLoss: 0.465639\n",
      "Train Epoch: 5 [10000/10213 (97%)]\tLoss: 0.447819\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.490500\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.492546\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.446543\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.403541\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.302248\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.404756\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.335381\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.337953\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.379182\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.389662\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.405864\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.448157\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.417296\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.299931\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.466637\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.344294\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.356980\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.386985\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.346048\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.348087\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.450774\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.302992\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.295839\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.359403\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.447942\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.487023\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.339685\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.410299\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.294976\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.325527\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.363393\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.436843\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.426705\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.357030\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.387890\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.400483\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.335042\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.315884\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.336284\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.438051\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.365962\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.356287\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.548694\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.347469\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.309189\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.334264\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.383321\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.334990\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.358820\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.305601\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.554209\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.142056\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.111023\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.218886\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.254005\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.331803\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.151426\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.209453\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.350994\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.354465\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.297966\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.246561\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.188885\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.153506\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.258959\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.191768\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.227690\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.178647\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.208676\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.197021\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.148953\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.147799\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.187157\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.200808\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.151439\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.311650\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.157367\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.147010\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.309038\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.233025\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.282080\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.143038\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.190335\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.363899\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.241105\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.0044, Accuracy: 7504/10000 (75%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/9140 (0%)]\tLoss: 0.418958\n",
      "Train Epoch: 1 [1000/9140 (11%)]\tLoss: 0.442877\n",
      "Train Epoch: 1 [2000/9140 (22%)]\tLoss: 0.364901\n",
      "Train Epoch: 1 [3000/9140 (33%)]\tLoss: 0.404034\n",
      "Train Epoch: 1 [4000/9140 (43%)]\tLoss: 0.377485\n",
      "Train Epoch: 1 [5000/9140 (54%)]\tLoss: 0.259949\n",
      "Train Epoch: 1 [6000/9140 (65%)]\tLoss: 0.256389\n",
      "Train Epoch: 1 [7000/9140 (76%)]\tLoss: 0.374706\n",
      "Train Epoch: 1 [8000/9140 (87%)]\tLoss: 0.301131\n",
      "Train Epoch: 1 [9000/9140 (98%)]\tLoss: 0.391964\n",
      "Train Epoch: 2 [0/9140 (0%)]\tLoss: 0.358824\n",
      "Train Epoch: 2 [1000/9140 (11%)]\tLoss: 0.267540\n",
      "Train Epoch: 2 [2000/9140 (22%)]\tLoss: 0.312510\n",
      "Train Epoch: 2 [3000/9140 (33%)]\tLoss: 0.358884\n",
      "Train Epoch: 2 [4000/9140 (43%)]\tLoss: 0.260132\n",
      "Train Epoch: 2 [5000/9140 (54%)]\tLoss: 0.290070\n",
      "Train Epoch: 2 [6000/9140 (65%)]\tLoss: 0.342240\n",
      "Train Epoch: 2 [7000/9140 (76%)]\tLoss: 0.359159\n",
      "Train Epoch: 2 [8000/9140 (87%)]\tLoss: 0.473855\n",
      "Train Epoch: 2 [9000/9140 (98%)]\tLoss: 0.340879\n",
      "Train Epoch: 3 [0/9140 (0%)]\tLoss: 0.378277\n",
      "Train Epoch: 3 [1000/9140 (11%)]\tLoss: 0.266106\n",
      "Train Epoch: 3 [2000/9140 (22%)]\tLoss: 0.365285\n",
      "Train Epoch: 3 [3000/9140 (33%)]\tLoss: 0.499462\n",
      "Train Epoch: 3 [4000/9140 (43%)]\tLoss: 0.251622\n",
      "Train Epoch: 3 [5000/9140 (54%)]\tLoss: 0.298599\n",
      "Train Epoch: 3 [6000/9140 (65%)]\tLoss: 0.321032\n",
      "Train Epoch: 3 [7000/9140 (76%)]\tLoss: 0.440883\n",
      "Train Epoch: 3 [8000/9140 (87%)]\tLoss: 0.432663\n",
      "Train Epoch: 3 [9000/9140 (98%)]\tLoss: 0.267453\n",
      "Train Epoch: 4 [0/9140 (0%)]\tLoss: 0.302615\n",
      "Train Epoch: 4 [1000/9140 (11%)]\tLoss: 0.341950\n",
      "Train Epoch: 4 [2000/9140 (22%)]\tLoss: 0.293035\n",
      "Train Epoch: 4 [3000/9140 (33%)]\tLoss: 0.272098\n",
      "Train Epoch: 4 [4000/9140 (43%)]\tLoss: 0.490857\n",
      "Train Epoch: 4 [5000/9140 (54%)]\tLoss: 0.446013\n",
      "Train Epoch: 4 [6000/9140 (65%)]\tLoss: 0.331935\n",
      "Train Epoch: 4 [7000/9140 (76%)]\tLoss: 0.379627\n",
      "Train Epoch: 4 [8000/9140 (87%)]\tLoss: 0.391404\n",
      "Train Epoch: 4 [9000/9140 (98%)]\tLoss: 0.289103\n",
      "Train Epoch: 5 [0/9140 (0%)]\tLoss: 0.412401\n",
      "Train Epoch: 5 [1000/9140 (11%)]\tLoss: 0.356713\n",
      "Train Epoch: 5 [2000/9140 (22%)]\tLoss: 0.277955\n",
      "Train Epoch: 5 [3000/9140 (33%)]\tLoss: 0.358303\n",
      "Train Epoch: 5 [4000/9140 (43%)]\tLoss: 0.447601\n",
      "Train Epoch: 5 [5000/9140 (54%)]\tLoss: 0.337806\n",
      "Train Epoch: 5 [6000/9140 (65%)]\tLoss: 0.340643\n",
      "Train Epoch: 5 [7000/9140 (76%)]\tLoss: 0.361702\n",
      "Train Epoch: 5 [8000/9140 (87%)]\tLoss: 0.365304\n",
      "Train Epoch: 5 [9000/9140 (98%)]\tLoss: 0.447270\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.457162\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.326113\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.129660\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.223482\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.338334\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.058648\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.088132\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.108628\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.200833\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.126885\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.172973\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.156292\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.111217\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.187388\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.299730\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.096258\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.188360\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.191408\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.168120\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.147572\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.122605\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.109228\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.176516\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.193413\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.173847\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.197513\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.134250\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.166926\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.183442\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.213239\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.197416\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.151240\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.070885\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.118665\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.106281\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.124900\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.212975\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.075833\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.113661\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.103666\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.437701\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.206535\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.222800\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.298972\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.230171\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.284673\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.255466\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.152070\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.148759\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.140861\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.241286\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.169612\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.243761\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.198797\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.234091\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.259278\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.302502\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.425066\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.247344\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.179075\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.129602\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.356292\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.144126\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.324255\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.131029\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.224239\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.343144\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.154736\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.208965\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.286646\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.165785\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.211662\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.148176\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.336975\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.149731\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.410880\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.257600\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.276438\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.252820\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.255610\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.358857\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.209645\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.194528\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.227856\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.183287\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.296615\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.212777\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.228507\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.270636\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.322856\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.119320\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.274593\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.266487\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.375144\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.253998\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.324356\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.304310\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.180346\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.348469\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.174026\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.162764\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.264943\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.203470\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.416673\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.107972\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.446499\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.189159\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.243169\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.266156\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.336456\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.265514\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.165795\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.278497\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.196658\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.291924\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.187835\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.260229\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.298666\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.335346\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.302627\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.295732\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.400402\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.265434\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.273912\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.283602\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.182527\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.317721\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.197740\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.191042\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.236015\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.359838\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.322218\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.332764\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.338612\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.197739\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/10213 (0%)]\tLoss: 0.323233\n",
      "Train Epoch: 1 [1000/10213 (10%)]\tLoss: 0.195577\n",
      "Train Epoch: 1 [2000/10213 (19%)]\tLoss: 0.401355\n",
      "Train Epoch: 1 [3000/10213 (29%)]\tLoss: 0.442480\n",
      "Train Epoch: 1 [4000/10213 (39%)]\tLoss: 0.389454\n",
      "Train Epoch: 1 [5000/10213 (49%)]\tLoss: 0.349321\n",
      "Train Epoch: 1 [6000/10213 (58%)]\tLoss: 0.283763\n",
      "Train Epoch: 1 [7000/10213 (68%)]\tLoss: 0.334826\n",
      "Train Epoch: 1 [8000/10213 (78%)]\tLoss: 0.502351\n",
      "Train Epoch: 1 [9000/10213 (87%)]\tLoss: 0.190458\n",
      "Train Epoch: 1 [10000/10213 (97%)]\tLoss: 0.375225\n",
      "Train Epoch: 2 [0/10213 (0%)]\tLoss: 0.332863\n",
      "Train Epoch: 2 [1000/10213 (10%)]\tLoss: 0.302420\n",
      "Train Epoch: 2 [2000/10213 (19%)]\tLoss: 0.260316\n",
      "Train Epoch: 2 [3000/10213 (29%)]\tLoss: 0.378114\n",
      "Train Epoch: 2 [4000/10213 (39%)]\tLoss: 0.362302\n",
      "Train Epoch: 2 [5000/10213 (49%)]\tLoss: 0.328422\n",
      "Train Epoch: 2 [6000/10213 (58%)]\tLoss: 0.363503\n",
      "Train Epoch: 2 [7000/10213 (68%)]\tLoss: 0.210625\n",
      "Train Epoch: 2 [8000/10213 (78%)]\tLoss: 0.239455\n",
      "Train Epoch: 2 [9000/10213 (87%)]\tLoss: 0.442103\n",
      "Train Epoch: 2 [10000/10213 (97%)]\tLoss: 0.383882\n",
      "Train Epoch: 3 [0/10213 (0%)]\tLoss: 0.402267\n",
      "Train Epoch: 3 [1000/10213 (10%)]\tLoss: 0.360796\n",
      "Train Epoch: 3 [2000/10213 (19%)]\tLoss: 0.360942\n",
      "Train Epoch: 3 [3000/10213 (29%)]\tLoss: 0.477343\n",
      "Train Epoch: 3 [4000/10213 (39%)]\tLoss: 0.236731\n",
      "Train Epoch: 3 [5000/10213 (49%)]\tLoss: 0.418874\n",
      "Train Epoch: 3 [6000/10213 (58%)]\tLoss: 0.285628\n",
      "Train Epoch: 3 [7000/10213 (68%)]\tLoss: 0.383450\n",
      "Train Epoch: 3 [8000/10213 (78%)]\tLoss: 0.341767\n",
      "Train Epoch: 3 [9000/10213 (87%)]\tLoss: 0.432978\n",
      "Train Epoch: 3 [10000/10213 (97%)]\tLoss: 0.377630\n",
      "Train Epoch: 4 [0/10213 (0%)]\tLoss: 0.384279\n",
      "Train Epoch: 4 [1000/10213 (10%)]\tLoss: 0.507638\n",
      "Train Epoch: 4 [2000/10213 (19%)]\tLoss: 0.271791\n",
      "Train Epoch: 4 [3000/10213 (29%)]\tLoss: 0.367362\n",
      "Train Epoch: 4 [4000/10213 (39%)]\tLoss: 0.333633\n",
      "Train Epoch: 4 [5000/10213 (49%)]\tLoss: 0.389292\n",
      "Train Epoch: 4 [6000/10213 (58%)]\tLoss: 0.277760\n",
      "Train Epoch: 4 [7000/10213 (68%)]\tLoss: 0.257676\n",
      "Train Epoch: 4 [8000/10213 (78%)]\tLoss: 0.383509\n",
      "Train Epoch: 4 [9000/10213 (87%)]\tLoss: 0.303894\n",
      "Train Epoch: 4 [10000/10213 (97%)]\tLoss: 0.449892\n",
      "Train Epoch: 5 [0/10213 (0%)]\tLoss: 0.400031\n",
      "Train Epoch: 5 [1000/10213 (10%)]\tLoss: 0.378851\n",
      "Train Epoch: 5 [2000/10213 (19%)]\tLoss: 0.329133\n",
      "Train Epoch: 5 [3000/10213 (29%)]\tLoss: 0.240289\n",
      "Train Epoch: 5 [4000/10213 (39%)]\tLoss: 0.257646\n",
      "Train Epoch: 5 [5000/10213 (49%)]\tLoss: 0.263299\n",
      "Train Epoch: 5 [6000/10213 (58%)]\tLoss: 0.292231\n",
      "Train Epoch: 5 [7000/10213 (68%)]\tLoss: 0.378948\n",
      "Train Epoch: 5 [8000/10213 (78%)]\tLoss: 0.385095\n",
      "Train Epoch: 5 [9000/10213 (87%)]\tLoss: 0.221091\n",
      "Train Epoch: 5 [10000/10213 (97%)]\tLoss: 0.403717\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.524356\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.451814\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.379382\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.308774\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.375481\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.334103\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.587718\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.380165\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.314353\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.397514\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.381682\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.416454\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.366221\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.232261\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.512292\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.331788\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.474683\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.313403\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.340016\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.425225\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.432784\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.325748\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.278493\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.258521\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.297174\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.363001\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.391633\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.242804\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.560301\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.299487\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.382867\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.495721\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.412595\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.413251\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.489715\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.339610\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.303079\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.290312\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.293918\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.375303\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.327222\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.277335\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.366557\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.358822\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.340399\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.292771\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.484609\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.206375\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.275929\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.279180\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.597644\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.279265\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.153693\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.180085\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.191217\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.249453\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.162946\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.314955\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.241580\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.180768\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.350353\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.193836\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.253823\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.123753\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.216661\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.122703\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.208158\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.164612\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.259103\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.280583\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.272902\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.158088\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.235437\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.213724\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.241833\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.175943\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.206837\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.183326\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.274674\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.222460\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.160589\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.238488\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.190931\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.115252\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.214761\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9775, Accuracy: 7556/10000 (76%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/9140 (0%)]\tLoss: 0.420281\n",
      "Train Epoch: 1 [1000/9140 (11%)]\tLoss: 0.375989\n",
      "Train Epoch: 1 [2000/9140 (22%)]\tLoss: 0.388408\n",
      "Train Epoch: 1 [3000/9140 (33%)]\tLoss: 0.337710\n",
      "Train Epoch: 1 [4000/9140 (43%)]\tLoss: 0.323790\n",
      "Train Epoch: 1 [5000/9140 (54%)]\tLoss: 0.470462\n",
      "Train Epoch: 1 [6000/9140 (65%)]\tLoss: 0.329724\n",
      "Train Epoch: 1 [7000/9140 (76%)]\tLoss: 0.326633\n",
      "Train Epoch: 1 [8000/9140 (87%)]\tLoss: 0.466665\n",
      "Train Epoch: 1 [9000/9140 (98%)]\tLoss: 0.404840\n",
      "Train Epoch: 2 [0/9140 (0%)]\tLoss: 0.471813\n",
      "Train Epoch: 2 [1000/9140 (11%)]\tLoss: 0.558836\n",
      "Train Epoch: 2 [2000/9140 (22%)]\tLoss: 0.374164\n",
      "Train Epoch: 2 [3000/9140 (33%)]\tLoss: 0.326150\n",
      "Train Epoch: 2 [4000/9140 (43%)]\tLoss: 0.279415\n",
      "Train Epoch: 2 [5000/9140 (54%)]\tLoss: 0.328199\n",
      "Train Epoch: 2 [6000/9140 (65%)]\tLoss: 0.289757\n",
      "Train Epoch: 2 [7000/9140 (76%)]\tLoss: 0.361137\n",
      "Train Epoch: 2 [8000/9140 (87%)]\tLoss: 0.376219\n",
      "Train Epoch: 2 [9000/9140 (98%)]\tLoss: 0.491285\n",
      "Train Epoch: 3 [0/9140 (0%)]\tLoss: 0.401476\n",
      "Train Epoch: 3 [1000/9140 (11%)]\tLoss: 0.328530\n",
      "Train Epoch: 3 [2000/9140 (22%)]\tLoss: 0.204904\n",
      "Train Epoch: 3 [3000/9140 (33%)]\tLoss: 0.224688\n",
      "Train Epoch: 3 [4000/9140 (43%)]\tLoss: 0.373953\n",
      "Train Epoch: 3 [5000/9140 (54%)]\tLoss: 0.394460\n",
      "Train Epoch: 3 [6000/9140 (65%)]\tLoss: 0.289506\n",
      "Train Epoch: 3 [7000/9140 (76%)]\tLoss: 0.342875\n",
      "Train Epoch: 3 [8000/9140 (87%)]\tLoss: 0.359453\n",
      "Train Epoch: 3 [9000/9140 (98%)]\tLoss: 0.359710\n",
      "Train Epoch: 4 [0/9140 (0%)]\tLoss: 0.357263\n",
      "Train Epoch: 4 [1000/9140 (11%)]\tLoss: 0.398926\n",
      "Train Epoch: 4 [2000/9140 (22%)]\tLoss: 0.316284\n",
      "Train Epoch: 4 [3000/9140 (33%)]\tLoss: 0.272956\n",
      "Train Epoch: 4 [4000/9140 (43%)]\tLoss: 0.393905\n",
      "Train Epoch: 4 [5000/9140 (54%)]\tLoss: 0.338758\n",
      "Train Epoch: 4 [6000/9140 (65%)]\tLoss: 0.396626\n",
      "Train Epoch: 4 [7000/9140 (76%)]\tLoss: 0.290036\n",
      "Train Epoch: 4 [8000/9140 (87%)]\tLoss: 0.302501\n",
      "Train Epoch: 4 [9000/9140 (98%)]\tLoss: 0.245900\n",
      "Train Epoch: 5 [0/9140 (0%)]\tLoss: 0.415293\n",
      "Train Epoch: 5 [1000/9140 (11%)]\tLoss: 0.225526\n",
      "Train Epoch: 5 [2000/9140 (22%)]\tLoss: 0.356853\n",
      "Train Epoch: 5 [3000/9140 (33%)]\tLoss: 0.286465\n",
      "Train Epoch: 5 [4000/9140 (43%)]\tLoss: 0.314691\n",
      "Train Epoch: 5 [5000/9140 (54%)]\tLoss: 0.263653\n",
      "Train Epoch: 5 [6000/9140 (65%)]\tLoss: 0.383216\n",
      "Train Epoch: 5 [7000/9140 (76%)]\tLoss: 0.382865\n",
      "Train Epoch: 5 [8000/9140 (87%)]\tLoss: 0.407816\n",
      "Train Epoch: 5 [9000/9140 (98%)]\tLoss: 0.430305\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.350762\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.168514\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.208151\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.135445\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.134273\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.270393\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.249893\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.262785\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.164205\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.110715\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.144422\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.177360\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.079691\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.168340\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.156832\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.298087\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.190987\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.190403\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.192636\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.166687\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.028214\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.181668\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.058840\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.146939\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.187379\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.129420\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.087192\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.095912\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.139813\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.148177\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.101787\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.131041\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.235367\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.144388\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.222486\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.125221\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.086073\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.094324\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.126821\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.196932\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.245073\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.222178\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.287598\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.194549\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.130670\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.129606\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.223620\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.320772\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.125761\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.337086\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.270766\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.193747\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.128639\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.216897\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.227633\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.184058\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.284396\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.185050\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.137508\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.203481\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.125647\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.265491\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.172187\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.267007\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.137890\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.283993\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.232777\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.223040\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.274612\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.197334\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.268257\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.133192\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.210942\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.248378\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.156615\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.372996\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.270533\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.326076\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.421334\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.256200\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.279685\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.249023\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.336497\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.205144\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.220950\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.230463\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.302737\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.308610\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.300484\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.121567\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.230823\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.273787\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.202533\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.224712\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.284694\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.295881\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.266579\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.310431\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.164322\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.232641\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.382347\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.226009\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.207431\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.177851\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.313252\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.312136\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.275500\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.256716\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.221182\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.223704\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.291621\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.329331\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.214227\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.340775\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.227316\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.223781\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.306434\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.309548\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.292650\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.237164\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.378890\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.324794\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.302498\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.295415\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.233200\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.193608\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.298183\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.235450\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.258743\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.315575\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.319854\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.252530\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.246984\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.306373\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.424795\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/10213 (0%)]\tLoss: 0.272331\n",
      "Train Epoch: 1 [1000/10213 (10%)]\tLoss: 0.347550\n",
      "Train Epoch: 1 [2000/10213 (19%)]\tLoss: 0.366778\n",
      "Train Epoch: 1 [3000/10213 (29%)]\tLoss: 0.332204\n",
      "Train Epoch: 1 [4000/10213 (39%)]\tLoss: 0.423966\n",
      "Train Epoch: 1 [5000/10213 (49%)]\tLoss: 0.292635\n",
      "Train Epoch: 1 [6000/10213 (58%)]\tLoss: 0.319609\n",
      "Train Epoch: 1 [7000/10213 (68%)]\tLoss: 0.334527\n",
      "Train Epoch: 1 [8000/10213 (78%)]\tLoss: 0.379212\n",
      "Train Epoch: 1 [9000/10213 (87%)]\tLoss: 0.377795\n",
      "Train Epoch: 1 [10000/10213 (97%)]\tLoss: 0.413521\n",
      "Train Epoch: 2 [0/10213 (0%)]\tLoss: 0.482430\n",
      "Train Epoch: 2 [1000/10213 (10%)]\tLoss: 0.393073\n",
      "Train Epoch: 2 [2000/10213 (19%)]\tLoss: 0.267378\n",
      "Train Epoch: 2 [3000/10213 (29%)]\tLoss: 0.329367\n",
      "Train Epoch: 2 [4000/10213 (39%)]\tLoss: 0.258266\n",
      "Train Epoch: 2 [5000/10213 (49%)]\tLoss: 0.320350\n",
      "Train Epoch: 2 [6000/10213 (58%)]\tLoss: 0.419751\n",
      "Train Epoch: 2 [7000/10213 (68%)]\tLoss: 0.559320\n",
      "Train Epoch: 2 [8000/10213 (78%)]\tLoss: 0.311275\n",
      "Train Epoch: 2 [9000/10213 (87%)]\tLoss: 0.402735\n",
      "Train Epoch: 2 [10000/10213 (97%)]\tLoss: 0.320679\n",
      "Train Epoch: 3 [0/10213 (0%)]\tLoss: 0.351432\n",
      "Train Epoch: 3 [1000/10213 (10%)]\tLoss: 0.302867\n",
      "Train Epoch: 3 [2000/10213 (19%)]\tLoss: 0.353807\n",
      "Train Epoch: 3 [3000/10213 (29%)]\tLoss: 0.288993\n",
      "Train Epoch: 3 [4000/10213 (39%)]\tLoss: 0.300168\n",
      "Train Epoch: 3 [5000/10213 (49%)]\tLoss: 0.395694\n",
      "Train Epoch: 3 [6000/10213 (58%)]\tLoss: 0.309993\n",
      "Train Epoch: 3 [7000/10213 (68%)]\tLoss: 0.380102\n",
      "Train Epoch: 3 [8000/10213 (78%)]\tLoss: 0.457341\n",
      "Train Epoch: 3 [9000/10213 (87%)]\tLoss: 0.410396\n",
      "Train Epoch: 3 [10000/10213 (97%)]\tLoss: 0.312851\n",
      "Train Epoch: 4 [0/10213 (0%)]\tLoss: 0.247594\n",
      "Train Epoch: 4 [1000/10213 (10%)]\tLoss: 0.410543\n",
      "Train Epoch: 4 [2000/10213 (19%)]\tLoss: 0.301671\n",
      "Train Epoch: 4 [3000/10213 (29%)]\tLoss: 0.366382\n",
      "Train Epoch: 4 [4000/10213 (39%)]\tLoss: 0.258664\n",
      "Train Epoch: 4 [5000/10213 (49%)]\tLoss: 0.329379\n",
      "Train Epoch: 4 [6000/10213 (58%)]\tLoss: 0.406304\n",
      "Train Epoch: 4 [7000/10213 (68%)]\tLoss: 0.330794\n",
      "Train Epoch: 4 [8000/10213 (78%)]\tLoss: 0.412064\n",
      "Train Epoch: 4 [9000/10213 (87%)]\tLoss: 0.450625\n",
      "Train Epoch: 4 [10000/10213 (97%)]\tLoss: 0.259736\n",
      "Train Epoch: 5 [0/10213 (0%)]\tLoss: 0.311959\n",
      "Train Epoch: 5 [1000/10213 (10%)]\tLoss: 0.479357\n",
      "Train Epoch: 5 [2000/10213 (19%)]\tLoss: 0.213270\n",
      "Train Epoch: 5 [3000/10213 (29%)]\tLoss: 0.229861\n",
      "Train Epoch: 5 [4000/10213 (39%)]\tLoss: 0.315690\n",
      "Train Epoch: 5 [5000/10213 (49%)]\tLoss: 0.310955\n",
      "Train Epoch: 5 [6000/10213 (58%)]\tLoss: 0.425461\n",
      "Train Epoch: 5 [7000/10213 (68%)]\tLoss: 0.295731\n",
      "Train Epoch: 5 [8000/10213 (78%)]\tLoss: 0.288722\n",
      "Train Epoch: 5 [9000/10213 (87%)]\tLoss: 0.373005\n",
      "Train Epoch: 5 [10000/10213 (97%)]\tLoss: 0.321249\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.514497\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.415797\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.281608\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.237045\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.364421\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.272768\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.450736\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.337475\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.414322\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.447386\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.368680\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.327462\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.375626\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.416620\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.288958\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.325316\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.380590\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.289349\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.516969\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.354814\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.353199\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.345520\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.373412\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.438602\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.304042\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.328774\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.302672\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.297159\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.342575\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.445714\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.352593\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.502482\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.343321\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.325289\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.349551\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.371924\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.285417\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.290745\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.278309\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.376055\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.261949\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.357950\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.436734\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.382960\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.386723\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.577020\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.343593\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.322279\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.339746\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.321807\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.475423\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.222797\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.162091\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.229673\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.217295\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.222449\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.308005\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.163227\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.171162\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.131042\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.229472\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.121547\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.181447\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.189029\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.160145\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.186032\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.291860\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.177764\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.397875\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.236244\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.169347\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.222728\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.217323\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.177575\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.176224\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.264178\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.215207\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.169457\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.252834\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.201274\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.234476\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.242649\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.212129\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.121514\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.228964\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.0077, Accuracy: 7524/10000 (75%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/9140 (0%)]\tLoss: 0.533546\n",
      "Train Epoch: 1 [1000/9140 (11%)]\tLoss: 0.560721\n",
      "Train Epoch: 1 [2000/9140 (22%)]\tLoss: 0.490477\n",
      "Train Epoch: 1 [3000/9140 (33%)]\tLoss: 0.487604\n",
      "Train Epoch: 1 [4000/9140 (43%)]\tLoss: 0.298139\n",
      "Train Epoch: 1 [5000/9140 (54%)]\tLoss: 0.269725\n",
      "Train Epoch: 1 [6000/9140 (65%)]\tLoss: 0.312230\n",
      "Train Epoch: 1 [7000/9140 (76%)]\tLoss: 0.368411\n",
      "Train Epoch: 1 [8000/9140 (87%)]\tLoss: 0.384177\n",
      "Train Epoch: 1 [9000/9140 (98%)]\tLoss: 0.382238\n",
      "Train Epoch: 2 [0/9140 (0%)]\tLoss: 0.382932\n",
      "Train Epoch: 2 [1000/9140 (11%)]\tLoss: 0.261272\n",
      "Train Epoch: 2 [2000/9140 (22%)]\tLoss: 0.287483\n",
      "Train Epoch: 2 [3000/9140 (33%)]\tLoss: 0.228111\n",
      "Train Epoch: 2 [4000/9140 (43%)]\tLoss: 0.348461\n",
      "Train Epoch: 2 [5000/9140 (54%)]\tLoss: 0.294278\n",
      "Train Epoch: 2 [6000/9140 (65%)]\tLoss: 0.353650\n",
      "Train Epoch: 2 [7000/9140 (76%)]\tLoss: 0.389430\n",
      "Train Epoch: 2 [8000/9140 (87%)]\tLoss: 0.356694\n",
      "Train Epoch: 2 [9000/9140 (98%)]\tLoss: 0.367450\n",
      "Train Epoch: 3 [0/9140 (0%)]\tLoss: 0.400157\n",
      "Train Epoch: 3 [1000/9140 (11%)]\tLoss: 0.244727\n",
      "Train Epoch: 3 [2000/9140 (22%)]\tLoss: 0.339728\n",
      "Train Epoch: 3 [3000/9140 (33%)]\tLoss: 0.406057\n",
      "Train Epoch: 3 [4000/9140 (43%)]\tLoss: 0.448709\n",
      "Train Epoch: 3 [5000/9140 (54%)]\tLoss: 0.351557\n",
      "Train Epoch: 3 [6000/9140 (65%)]\tLoss: 0.363148\n",
      "Train Epoch: 3 [7000/9140 (76%)]\tLoss: 0.294256\n",
      "Train Epoch: 3 [8000/9140 (87%)]\tLoss: 0.249965\n",
      "Train Epoch: 3 [9000/9140 (98%)]\tLoss: 0.274222\n",
      "Train Epoch: 4 [0/9140 (0%)]\tLoss: 0.434306\n",
      "Train Epoch: 4 [1000/9140 (11%)]\tLoss: 0.215940\n",
      "Train Epoch: 4 [2000/9140 (22%)]\tLoss: 0.399352\n",
      "Train Epoch: 4 [3000/9140 (33%)]\tLoss: 0.247520\n",
      "Train Epoch: 4 [4000/9140 (43%)]\tLoss: 0.430144\n",
      "Train Epoch: 4 [5000/9140 (54%)]\tLoss: 0.413727\n",
      "Train Epoch: 4 [6000/9140 (65%)]\tLoss: 0.389970\n",
      "Train Epoch: 4 [7000/9140 (76%)]\tLoss: 0.316074\n",
      "Train Epoch: 4 [8000/9140 (87%)]\tLoss: 0.300226\n",
      "Train Epoch: 4 [9000/9140 (98%)]\tLoss: 0.415408\n",
      "Train Epoch: 5 [0/9140 (0%)]\tLoss: 0.340505\n",
      "Train Epoch: 5 [1000/9140 (11%)]\tLoss: 0.351779\n",
      "Train Epoch: 5 [2000/9140 (22%)]\tLoss: 0.351471\n",
      "Train Epoch: 5 [3000/9140 (33%)]\tLoss: 0.298030\n",
      "Train Epoch: 5 [4000/9140 (43%)]\tLoss: 0.425217\n",
      "Train Epoch: 5 [5000/9140 (54%)]\tLoss: 0.275763\n",
      "Train Epoch: 5 [6000/9140 (65%)]\tLoss: 0.368982\n",
      "Train Epoch: 5 [7000/9140 (76%)]\tLoss: 0.298436\n",
      "Train Epoch: 5 [8000/9140 (87%)]\tLoss: 0.424602\n",
      "Train Epoch: 5 [9000/9140 (98%)]\tLoss: 0.314204\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.364502\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.195038\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.241694\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.103834\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.168210\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.080318\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.136346\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.106605\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.096643\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.094457\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.102680\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.155308\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.150723\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.197693\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.161958\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.095381\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.188945\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.082171\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.106892\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.186823\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.218656\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.096510\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.176964\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.308950\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.145083\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.153653\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.226392\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.148379\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.125393\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.256819\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.089517\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.075633\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.117243\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.129538\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.389335\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.114746\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.125084\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.113916\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.062422\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.224463\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.344586\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.254666\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.247248\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.201230\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.155075\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.228498\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.122386\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.151903\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.252194\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.144232\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.217092\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.198450\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.279581\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.267544\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.332918\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.125943\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.186803\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.299923\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.210904\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.201532\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.322889\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.195515\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.408318\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.210945\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.181611\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.310302\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.247833\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.222812\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.122159\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.237179\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.221360\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.211208\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.199142\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.209749\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.267314\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.407285\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.270852\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.205822\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.331406\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.301106\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.488360\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.365242\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.244180\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.187946\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.141858\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.251761\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.201043\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.298025\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.277600\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.244983\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.183693\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.365000\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.226748\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.252974\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.216061\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.349432\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.189133\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.272556\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.331521\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.143035\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.196396\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.263042\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.188004\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.327214\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.214158\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.233767\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.338891\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.219608\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.189131\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.306251\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.225653\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.270386\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.238273\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.189080\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.230925\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.231751\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.372962\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.354193\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.332187\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.194184\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.255900\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.359619\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.254919\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.441314\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.244894\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.269414\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.191516\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.257082\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.368369\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.291789\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.248758\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.314692\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.265165\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.326148\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.307372\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/10213 (0%)]\tLoss: 0.396194\n",
      "Train Epoch: 1 [1000/10213 (10%)]\tLoss: 0.279997\n",
      "Train Epoch: 1 [2000/10213 (19%)]\tLoss: 0.466779\n",
      "Train Epoch: 1 [3000/10213 (29%)]\tLoss: 0.490914\n",
      "Train Epoch: 1 [4000/10213 (39%)]\tLoss: 0.445140\n",
      "Train Epoch: 1 [5000/10213 (49%)]\tLoss: 0.467374\n",
      "Train Epoch: 1 [6000/10213 (58%)]\tLoss: 0.268173\n",
      "Train Epoch: 1 [7000/10213 (68%)]\tLoss: 0.488300\n",
      "Train Epoch: 1 [8000/10213 (78%)]\tLoss: 0.264210\n",
      "Train Epoch: 1 [9000/10213 (87%)]\tLoss: 0.207190\n",
      "Train Epoch: 1 [10000/10213 (97%)]\tLoss: 0.373972\n",
      "Train Epoch: 2 [0/10213 (0%)]\tLoss: 0.263237\n",
      "Train Epoch: 2 [1000/10213 (10%)]\tLoss: 0.432794\n",
      "Train Epoch: 2 [2000/10213 (19%)]\tLoss: 0.247054\n",
      "Train Epoch: 2 [3000/10213 (29%)]\tLoss: 0.281745\n",
      "Train Epoch: 2 [4000/10213 (39%)]\tLoss: 0.320775\n",
      "Train Epoch: 2 [5000/10213 (49%)]\tLoss: 0.372632\n",
      "Train Epoch: 2 [6000/10213 (58%)]\tLoss: 0.384010\n",
      "Train Epoch: 2 [7000/10213 (68%)]\tLoss: 0.313804\n",
      "Train Epoch: 2 [8000/10213 (78%)]\tLoss: 0.391346\n",
      "Train Epoch: 2 [9000/10213 (87%)]\tLoss: 0.456019\n",
      "Train Epoch: 2 [10000/10213 (97%)]\tLoss: 0.407305\n",
      "Train Epoch: 3 [0/10213 (0%)]\tLoss: 0.302226\n",
      "Train Epoch: 3 [1000/10213 (10%)]\tLoss: 0.469346\n",
      "Train Epoch: 3 [2000/10213 (19%)]\tLoss: 0.317746\n",
      "Train Epoch: 3 [3000/10213 (29%)]\tLoss: 0.379309\n",
      "Train Epoch: 3 [4000/10213 (39%)]\tLoss: 0.509246\n",
      "Train Epoch: 3 [5000/10213 (49%)]\tLoss: 0.466814\n",
      "Train Epoch: 3 [6000/10213 (58%)]\tLoss: 0.392594\n",
      "Train Epoch: 3 [7000/10213 (68%)]\tLoss: 0.263145\n",
      "Train Epoch: 3 [8000/10213 (78%)]\tLoss: 0.342170\n",
      "Train Epoch: 3 [9000/10213 (87%)]\tLoss: 0.416274\n",
      "Train Epoch: 3 [10000/10213 (97%)]\tLoss: 0.546737\n",
      "Train Epoch: 4 [0/10213 (0%)]\tLoss: 0.438944\n",
      "Train Epoch: 4 [1000/10213 (10%)]\tLoss: 0.372096\n",
      "Train Epoch: 4 [2000/10213 (19%)]\tLoss: 0.218609\n",
      "Train Epoch: 4 [3000/10213 (29%)]\tLoss: 0.273611\n",
      "Train Epoch: 4 [4000/10213 (39%)]\tLoss: 0.610135\n",
      "Train Epoch: 4 [5000/10213 (49%)]\tLoss: 0.472759\n",
      "Train Epoch: 4 [6000/10213 (58%)]\tLoss: 0.385867\n",
      "Train Epoch: 4 [7000/10213 (68%)]\tLoss: 0.385981\n",
      "Train Epoch: 4 [8000/10213 (78%)]\tLoss: 0.306484\n",
      "Train Epoch: 4 [9000/10213 (87%)]\tLoss: 0.387689\n",
      "Train Epoch: 4 [10000/10213 (97%)]\tLoss: 0.377450\n",
      "Train Epoch: 5 [0/10213 (0%)]\tLoss: 0.401104\n",
      "Train Epoch: 5 [1000/10213 (10%)]\tLoss: 0.309116\n",
      "Train Epoch: 5 [2000/10213 (19%)]\tLoss: 0.394324\n",
      "Train Epoch: 5 [3000/10213 (29%)]\tLoss: 0.390988\n",
      "Train Epoch: 5 [4000/10213 (39%)]\tLoss: 0.284100\n",
      "Train Epoch: 5 [5000/10213 (49%)]\tLoss: 0.383348\n",
      "Train Epoch: 5 [6000/10213 (58%)]\tLoss: 0.238777\n",
      "Train Epoch: 5 [7000/10213 (68%)]\tLoss: 0.287740\n",
      "Train Epoch: 5 [8000/10213 (78%)]\tLoss: 0.383600\n",
      "Train Epoch: 5 [9000/10213 (87%)]\tLoss: 0.181821\n",
      "Train Epoch: 5 [10000/10213 (97%)]\tLoss: 0.381150\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.343841\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.361012\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.441892\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.367084\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.367902\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.497144\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.419955\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.356544\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.500562\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.338690\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.393412\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.484092\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.333852\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.251768\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.250605\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.487856\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.363672\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.436880\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.345095\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.233898\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.583269\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.319416\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.540569\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.302601\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.479851\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.317202\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.372898\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.384489\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.488249\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.262143\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.306824\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.390681\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.327927\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.523270\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.528981\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.319691\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.313898\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.346189\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.462254\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.453602\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.386579\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.320505\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.579348\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.375540\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.251836\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.239863\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.373255\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.300104\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.263766\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.510905\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.513854\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.208677\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.401969\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.202947\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.198854\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.293400\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.262817\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.239270\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.202619\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.180951\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.252130\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.161776\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.156358\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.127524\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.237731\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.195242\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.252608\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.266018\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.209130\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.196765\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.365950\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.273277\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.158579\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.254176\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.156244\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.143587\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.212251\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.157195\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.228937\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.272499\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.268913\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.222580\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.252326\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.145842\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.126957\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.0285, Accuracy: 7500/10000 (75%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.473272\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.380014\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.361556\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.295845\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.553987\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.425564\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.441298\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.382491\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.515119\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.323917\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.361243\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.451532\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.326222\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.401254\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.379412\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.440404\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.204572\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.175550\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.120572\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.118527\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.158530\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.229635\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.162302\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.178258\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.167929\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.118550\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.218127\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.166178\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.162297\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.142438\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.069686\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.162509\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.068734\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.170476\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.180623\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.055664\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.187165\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.170391\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.204170\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.078585\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.087108\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.174050\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.142583\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.174599\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.167411\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.113284\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.160698\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.173662\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.111756\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.162913\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.248262\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.138347\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.106066\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.126188\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.195874\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.422848\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.249760\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.231093\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.432676\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.334881\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.290783\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.240498\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.254141\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.256465\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.255779\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.199151\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.305615\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.229729\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.180873\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.119578\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.164121\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.199129\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.205549\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.101451\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.207953\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.156621\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.168973\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.178534\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.256284\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.247284\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.160006\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.268445\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.229373\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.128882\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.247499\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.175372\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.184121\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.214847\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.185060\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.134914\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.286404\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.326992\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.155135\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.228001\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.321850\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.290630\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.178852\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.261672\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.256223\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.212755\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.245248\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.273319\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.294734\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.329110\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.290232\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.265158\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.247816\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.355055\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.267661\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.280961\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.276031\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.312022\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.201587\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.259209\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.169459\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.284006\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.261657\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.225831\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.273871\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.242231\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.371588\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.284752\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.294396\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.363411\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.315019\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.299587\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.209285\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.301473\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.157364\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.274787\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.256576\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.280392\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.443663\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.257580\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.270855\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.343482\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.274091\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.255600\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.278780\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.234532\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.318782\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.294822\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.258147\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.312965\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.308441\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.300390\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.220197\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.367438\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.181806\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.186224\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.436476\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.195802\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.323418\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.362079\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.365835\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.276486\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.310051\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.280572\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.352739\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.253835\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.223280\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.417777\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.304265\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.277985\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.253400\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.311702\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.248877\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.311210\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.303885\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.322239\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.291405\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.418778\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.348907\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.351962\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.462010\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.463361\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.338506\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.684695\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.408622\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.398140\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.455104\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.542109\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.286051\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.489658\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.421987\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.307564\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.350614\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.363287\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.268901\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.278879\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.342973\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.435097\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.506822\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.335359\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.391767\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.322220\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.524563\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.304861\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.241413\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.315250\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.436314\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.283303\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.379611\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.348965\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.447879\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.294249\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.426010\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.358338\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.513625\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.495958\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.464071\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.257380\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.427740\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.363265\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.288096\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.526346\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.329106\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.480488\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.348654\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.396613\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.582719\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.261662\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.204878\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.294258\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.286082\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.221577\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.277691\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.277561\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.267572\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.183082\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.107439\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.204816\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.130879\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.216981\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.267226\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.132008\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.250985\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.307262\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.282504\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.196638\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.215904\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.304292\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.151923\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.181911\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.281741\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.217920\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.153358\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.266167\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.144537\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.210779\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.140807\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.321328\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.280747\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.166742\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.206177\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.476201\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.326622\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.375284\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.383334\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.321785\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.312266\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.282179\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.301761\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.307273\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.336605\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.272760\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.370472\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.305608\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.294738\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.341363\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.198916\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.350445\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.195206\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.349966\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.279267\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.278784\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.312544\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.282703\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.324741\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.360906\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.222255\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.198265\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.328265\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.220913\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.351596\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.335809\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.279433\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.269875\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.310030\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.284260\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.303121\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.323120\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.262586\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.383501\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.409641\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.287261\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.380550\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.235917\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.237766\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.183642\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.255254\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.185779\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.210173\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.177846\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.259082\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.256033\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.209432\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.215965\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.194194\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.260546\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.391316\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.312493\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.245730\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.151846\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.194687\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.244500\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.319330\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.316079\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.314323\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.314671\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.316225\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.419015\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.208766\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.191403\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.201829\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.0418, Accuracy: 7471/10000 (75%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.512682\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.400433\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.371174\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.279080\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.343433\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.385605\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.321125\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.395045\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.552368\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.303714\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.508683\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.423464\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.410353\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.397678\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.368949\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.456735\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.238571\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.233491\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.207081\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.160695\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.120939\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.059956\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.175166\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.062959\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.136963\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.226429\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.195502\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.139867\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.112199\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.145127\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.096914\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.200846\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.086865\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.091984\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.111014\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.134953\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.092088\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.129400\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.216151\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.075143\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.071659\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.111347\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.088904\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.118440\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.159503\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.134755\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.123319\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.186080\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.155538\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.199906\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.122277\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.180481\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.117693\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.257751\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.092285\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.291661\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.145115\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.173474\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.155300\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.274884\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.273567\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.284597\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.198405\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.252326\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.362259\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.165587\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.323392\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.226389\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.287239\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.183965\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.190868\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.257130\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.188328\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.285407\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.240350\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.189538\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.236989\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.257306\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.185113\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.209859\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.257192\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.200927\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.206478\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.216949\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.200583\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.179205\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.269457\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.123919\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.275378\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.162576\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.313980\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.412617\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.210552\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.284057\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.247339\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.280316\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.296907\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.402671\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.227396\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.350998\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.130590\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.328224\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.212598\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.315721\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.327636\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.302793\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.272619\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.155686\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.245252\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.248775\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.136345\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.270761\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.272044\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.174886\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.200222\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.224970\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.317540\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.293577\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.221345\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.179641\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.314664\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.316394\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.250955\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.152414\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.314361\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.397624\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.243317\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.294196\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.247748\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.322335\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.282167\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.358746\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.335306\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.261013\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.200575\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.284534\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.402296\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.280712\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.179290\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.243703\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.285261\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.275300\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.151395\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.267986\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.335527\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.194255\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.219109\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.301770\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.384416\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.203422\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.389270\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.346731\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.356297\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.252297\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.344902\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.241865\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.287420\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.300701\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.337254\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.312108\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.333710\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.272799\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.386368\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.294511\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.247270\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.450244\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.364114\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.244055\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.273909\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.268363\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.383798\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.300994\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.462424\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.506332\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.314879\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.381748\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.371877\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.388592\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.384528\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.396689\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.399162\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.361597\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.347829\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.309837\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.443901\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.379809\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.475783\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.400114\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.337148\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.358707\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.220339\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.222493\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.315445\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.338702\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.545598\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.322186\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.292348\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.328388\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.337052\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.317722\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.390747\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.352668\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.263275\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.380717\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.361461\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.441211\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.219868\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.305095\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.294893\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.410965\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.381793\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.290368\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.423966\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.409613\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.449561\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.362212\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.339777\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.399162\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.415430\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.313563\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.380756\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.170802\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.299021\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.249295\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.155095\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.328262\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.201868\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.193694\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.168782\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.159497\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.178715\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.315700\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.120613\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.223733\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.203900\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.291323\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.224695\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.204320\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.184259\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.165443\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.163594\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.258992\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.249091\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.266349\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.209931\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.157051\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.124258\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.158581\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.283194\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.257466\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.200979\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.297542\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.226038\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.111702\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.107123\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.365039\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.324600\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.303584\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.446433\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.322333\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.288735\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.267059\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.285404\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.326435\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.312155\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.157098\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.394721\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.281494\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.349262\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.353469\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.422058\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.363835\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.227588\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.312345\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.400164\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.312353\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.164942\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.286789\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.370592\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.278750\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.354957\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.409020\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.303319\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.294083\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.291767\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.315459\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.213302\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.337009\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.405514\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.199631\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.385165\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.182945\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.302561\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.299192\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.231376\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.251743\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.285950\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.127995\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.314592\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.164781\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.195095\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.330197\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.236286\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.332791\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.242448\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.181740\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.319304\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.190848\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.430242\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.162370\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.442171\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.307799\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.153118\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.224202\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.244164\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.236663\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.248816\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.228378\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.223871\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.195771\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.305771\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.284979\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.241026\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.222607\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.185132\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.0550, Accuracy: 7466/10000 (75%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.395070\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.279948\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.355243\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.387618\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.443030\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.393929\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.310406\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.338496\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.352968\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.352667\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.365435\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.323905\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.368945\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.433256\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.441996\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.590235\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.123444\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.101486\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.192596\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.196082\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.170396\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.172993\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.153855\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.147529\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.183076\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.194647\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.080129\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.115629\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.067868\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.157498\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.178093\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.164721\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.218234\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.116058\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.325014\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.187227\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.230052\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.182314\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.122650\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.135048\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.168383\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.188183\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.157264\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.192700\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.064808\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.213462\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.110456\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.050758\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.150953\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.212466\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.142934\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.098879\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.191111\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.133413\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.150386\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.333857\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.202926\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.251719\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.233348\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.186162\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.229260\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.277194\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.185596\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.185483\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.143678\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.260632\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.237173\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.217947\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.177169\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.188955\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.166597\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.185611\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.200132\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.220006\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.227891\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.266064\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.178063\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.173193\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.170963\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.127238\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.184713\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.230578\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.276848\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.194560\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.160807\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.274041\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.230279\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.124339\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.177841\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.298286\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.333604\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.216444\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.314654\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.254255\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.241466\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.230376\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.261246\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.265271\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.263587\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.256097\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.302726\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.211257\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.311656\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.177267\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.254758\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.224982\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.181544\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.255468\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.172170\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.214279\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.353769\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.193164\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.246120\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.102942\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.296912\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.357500\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.167476\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.340568\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.272102\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.195182\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.404575\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.236099\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.291913\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.267601\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.329125\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.222174\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.203471\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.228787\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.326378\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.434788\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.325657\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.259746\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.304198\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.300800\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.210923\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.311741\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.281721\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.297682\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.213596\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.286534\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.313218\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.212785\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.279794\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.247047\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.262079\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.212693\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.173019\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.234992\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.273736\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.321399\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.379540\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.264448\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.311582\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.361728\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.366550\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.340698\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.322404\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.270920\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.400715\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.212713\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.375149\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.277823\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.207010\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.254983\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.298839\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.303997\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.268341\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.393476\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.190028\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.398835\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.431694\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.377842\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.314267\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.237256\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.495748\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.327716\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.285441\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.366292\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.396580\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.495030\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.364775\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.336953\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.290974\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.381797\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.279379\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.435347\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.424328\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.282727\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.375014\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.392029\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.496974\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.275991\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.352343\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.405170\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.407435\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.454175\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.305597\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.178011\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.381996\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.241093\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.363839\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.498735\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.385623\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.338468\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.406749\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.289333\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.414961\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.373450\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.342767\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.315538\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.478264\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.320433\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.274643\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.271352\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.508945\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.428962\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.293917\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.366811\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.315356\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.340834\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.489873\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.213210\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.248262\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.198330\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.258904\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.175583\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.180075\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.188249\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.225329\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.284492\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.103637\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.132670\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.145346\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.224577\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.260811\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.185543\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.145901\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.262221\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.107080\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.186939\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.338954\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.360447\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.178741\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.195466\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.118934\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.314463\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.146929\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.187144\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.378189\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.215313\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.149988\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.194652\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.164555\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.300839\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.181327\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.436220\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.268944\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.412313\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.291305\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.355989\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.298228\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.321180\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.334393\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.238668\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.246879\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.226982\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.199313\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.433843\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.192594\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.223631\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.248438\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.353265\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.300834\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.280446\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.234892\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.189526\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.392194\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.145669\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.227231\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.320293\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.270578\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.231084\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.223936\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.648085\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.266763\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.325566\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.314822\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.305108\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.255813\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.324146\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.383937\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.170032\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.315744\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.340821\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.147166\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.241424\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.254079\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.387548\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.180178\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.359181\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.261510\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.187448\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.245725\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.264808\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.236675\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.157210\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.468452\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.254942\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.360603\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.120274\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.200467\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.255282\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.339900\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.169548\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.210206\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.314130\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.278522\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.247115\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.322093\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.175366\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.423354\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.257928\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.283016\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.272990\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.221747\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.0963, Accuracy: 7412/10000 (74%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.460337\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.735510\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.505353\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.412654\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.372858\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.416686\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.255508\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.380716\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.368283\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.455138\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.361820\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.475924\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.400693\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.330639\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.410669\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.424962\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.169100\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.238848\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.144590\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.172858\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.087567\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.369588\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.277315\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.125622\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.088399\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.139463\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.217348\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.120548\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.116613\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.154712\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.173511\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.150572\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.155811\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.207742\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.125047\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.193395\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.144451\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.129122\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.116008\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.067213\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.150736\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.153342\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.094105\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.106557\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.120111\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.049005\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.143152\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.110610\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.190198\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.097352\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.239182\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.115220\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.170247\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.137595\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.153876\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.365968\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.252554\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.332927\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.208467\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.339435\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.236600\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.240257\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.196669\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.369773\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.203754\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.208947\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.143931\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.220518\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.180490\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.190542\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.247442\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.250410\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.214982\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.134042\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.205675\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.378566\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.245986\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.200529\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.184660\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.155825\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.154310\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.293308\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.157420\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.262529\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.179727\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.247074\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.272841\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.283456\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.184014\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.318477\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.428310\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.187624\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.102327\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.168553\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.285174\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.329185\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.323572\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.191224\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.229518\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.197328\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.371438\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.237600\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.234944\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.201682\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.241584\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.428586\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.212686\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.472537\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.290116\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.231883\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.191406\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.198432\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.181692\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.262582\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.247242\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.311165\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.249472\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.320024\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.162525\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.335016\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.269119\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.323341\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.263538\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.258915\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.386341\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.173675\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.268436\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.202780\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.306759\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.266882\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.350216\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.221222\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.213010\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.325872\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.278128\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.238337\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.159890\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.381429\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.328003\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.162487\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.248135\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.238262\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.301517\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.327220\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.339803\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.237643\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.205752\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.219072\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.194707\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.198475\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.451643\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.301895\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.332440\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.328926\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.279449\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.310024\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.426041\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.317922\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.223520\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.241986\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.305289\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.349691\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.250846\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.332935\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.260082\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.242750\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.342801\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.273760\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.268234\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.324186\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.438746\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.469597\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.319382\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.425442\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.198468\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.367522\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.346351\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.358372\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.386681\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.508690\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.341676\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.366136\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.502440\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.454471\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.393557\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.378823\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.319612\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.406009\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.380890\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.383595\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.485928\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.374439\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.272323\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.432713\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.384095\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.267988\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.472264\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.370601\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.366899\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.443124\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.286362\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.293421\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.345073\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.395375\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.361660\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.432072\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.378388\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.302852\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.383677\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.367053\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.359656\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.482726\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.278054\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.377788\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.352525\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.346076\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.395115\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.395692\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.248839\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.323305\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.433067\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.172989\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.208102\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.200464\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.186609\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.308950\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.110748\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.181745\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.262661\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.269504\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.160236\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.107207\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.195550\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.163373\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.266723\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.174748\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.231308\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.201976\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.186348\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.219678\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.206214\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.183375\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.195610\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.146464\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.208798\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.086489\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.218623\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.188044\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.200698\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.131545\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.270015\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.137402\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.331829\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.181419\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.166592\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.359124\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.262423\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.228262\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.325305\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.206480\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.217746\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.321598\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.427550\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.288294\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.338038\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.274066\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.238219\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.311407\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.345361\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.224786\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.287671\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.329013\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.306244\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.330531\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.315993\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.302945\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.285791\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.235114\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.366230\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.393276\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.216310\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.214341\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.211611\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.448633\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.329179\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.306455\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.256640\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.267385\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.269994\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.179773\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.301848\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.273862\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.442951\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.170118\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.328062\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.245581\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.211802\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.458142\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.186579\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.323123\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.222749\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.309436\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.170617\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.325926\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.233067\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.343384\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.369776\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.215558\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.145660\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.382066\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.248427\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.300944\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.223158\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.240193\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.244310\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.367763\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.264516\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.282705\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.208526\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.321128\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.214588\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.250264\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.305530\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.189401\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.170684\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.1025, Accuracy: 7407/10000 (74%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "partitioned_data_auto = partition.balanced_dirichlet_partition(trainingset_auto, partitions_number=num_clients, alpha=alpha)\n",
    "auto_client_loaders = [\n",
    "    DataLoader(Subset(trainingset_auto, indices), batch_size=batch_size_train, shuffle=True)\n",
    "    for indices in partitioned_data_auto.values()\n",
    "]\n",
    "\n",
    "local_model_autoencoder_strong = [copy.deepcopy(global_model_auto_strong) for _ in range(num_clients)]\n",
    "\n",
    "optimizer = optim.SGD(trial_model_auto_strong.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):  \n",
    "    train_fashion(epoch, trial_model_auto_strong, reduced_train_loader_auto, optimizer, log_interval, train_losses, train_counter)\n",
    "\n",
    "test_losses_auto_strong = []\n",
    "test_fashion(trial_model_auto_strong, reduced_train_loader_auto, test_losses_auto_strong)\n",
    "\n",
    "rounds_auto = 4\n",
    "for round_idx in range(rounds_auto):\n",
    "    print(f\"Round {round_idx + 1}/{rounds_auto}\")\n",
    "    \n",
    "    local_weights_auto = []\n",
    "    for client_idx, client_model in enumerate(local_model_autoencoder_strong):\n",
    "        print(f\"Training client {client_idx + 1}\")\n",
    "        \n",
    "        optimizer = optim.SGD(client_model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        \n",
    "        train_losses = []\n",
    "        train_counter = []\n",
    "    \n",
    "        for epoch in range(1, n_epochs + 1):  \n",
    "            train_fashion(epoch, client_model, auto_client_loaders[client_idx], optimizer, log_interval, train_losses, train_counter)\n",
    "        \n",
    "        client_weights = [param.data.numpy() for param in client_model.parameters()]\n",
    "        local_weights_auto.append(client_weights)\n",
    "    \n",
    "    global_weights_auto = federated_averaging(local_weights_auto)\n",
    "    \n",
    "    distribute_global_model(global_weights_auto, local_model_autoencoder_strong, single=False)\n",
    "    distribute_global_model(global_weights_auto, global_model_auto_strong, single=True)\n",
    "    \n",
    "    test_losses = []\n",
    "    test_fashion(global_model_auto_strong, test_loader_auto, test_losses)\n",
    "    \n",
    "    test_accuracies_classic = []\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader_auto:\n",
    "            data = data.view(data.shape[0], -1)\n",
    "            output = global_model_auto_strong(data)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "    accuracy = 100. * correct / len(test_loader_auto.dataset)\n",
    "    test_accuracies_classic.append(accuracy)\n",
    "    \n",
    "    # Save results for non-clustered classic\n",
    "    results[\"autoencoder\"][\"NoCluster\"] = {\"losses\": [], \"accuracy\": []}\n",
    "    \n",
    "    results[\"autoencoder\"][\"NoCluster\"][\"losses\"].extend(test_losses)\n",
    "    results[\"autoencoder\"][\"NoCluster\"][\"accuracy\"].extend(test_accuracies_classic)\n",
    "\n",
    "    ######################\n",
    "    # Clustering process\n",
    "for num_cluster in num_clusters:\n",
    "    import cluster\n",
    "    cluster = cluster.Cluster(num_clusters=num_cluster)\n",
    "    \n",
    "    targets = trainingset_auto.targets\n",
    "    num_classes = len(set(targets)) \n",
    "    clustered_data = cluster.apply_clustering(partitioned_data_auto, targets, num_classes)\n",
    "    \n",
    "    partitioned_data_auto_clustered = clustered_data\n",
    "    \n",
    "    auto_client_loaders_clustered = [\n",
    "        DataLoader(Subset(trainingset_auto, indices), batch_size=batch_size_train, shuffle=True)\n",
    "        for indices in partitioned_data_auto_clustered.values()\n",
    "    ]\n",
    "    \n",
    "    for round_idx in range(rounds_auto):\n",
    "        print(f\"Round {round_idx + 1}/{rounds_auto}\")\n",
    "        \n",
    "        local_weights_auto = []\n",
    "        for client_idx, client_model in enumerate(local_model_autoencoder_strong[0:num_cluster]):\n",
    "            print(f\"Training client {client_idx + 1}\")\n",
    "            \n",
    "            optimizer = optim.SGD(client_model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "            \n",
    "            train_losses = []\n",
    "            train_counter = []\n",
    "        \n",
    "            for epoch in range(1, n_epochs + 1):  \n",
    "                train_fashion(epoch, client_model, auto_client_loaders_clustered[client_idx], optimizer, log_interval, train_losses, train_counter)\n",
    "            \n",
    "            client_weights = [param.data.numpy() for param in client_model.parameters()]\n",
    "            local_weights_auto.append(client_weights)\n",
    "        \n",
    "        global_weights_auto = federated_averaging(local_weights_auto)\n",
    "        \n",
    "        distribute_global_model(global_weights_auto, local_model_autoencoder_strong, single=False)\n",
    "        distribute_global_model(global_weights_auto, global_model_auto_strong, single=True)\n",
    "        \n",
    "        test_losses = []\n",
    "        test_fashion(global_model_auto_strong, test_loader_auto, test_losses)\n",
    "        \n",
    "        test_accuracies_classic = []\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader_auto:\n",
    "                data = data.view(data.shape[0], -1)\n",
    "                output = global_model_auto_strong(data)\n",
    "                pred = output.data.max(1, keepdim=True)[1]\n",
    "                correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "        accuracy = 100. * correct / len(test_loader_auto.dataset)\n",
    "        test_accuracies_classic.append(accuracy)\n",
    "        \n",
    "        # Save results for clustered classic\n",
    "        if num_cluster not in clusteredResults[\"autoencoder\"]:\n",
    "            clusteredResults[\"autoencoder\"][num_cluster] = {\"losses\": [], \"accuracy\": []}\n",
    "\n",
    "        clusteredResults[\"autoencoder\"][num_cluster][\"losses\"].extend(test_losses)\n",
    "        clusteredResults[\"autoencoder\"][num_cluster][\"accuracy\"].extend(test_accuracies_classic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results (Non-Clustered): {'classic': {'NoCluster': {'losses': [0.5188619812011719], 'accuracy': [80.19]}}, 'pca': {'NoCluster': {'losses': [0.9590497436523437], 'accuracy': [82.92]}}, 'autoencoder': {'NoCluster': {'losses': [0.9626321166992188], 'accuracy': [69.05]}}}\n",
      "Final Results (Clustered): {'classic': {2: {'losses': [0.6111913330078125, 0.5729868041992188, 0.5778576416015625, 0.5886122863769532], 'accuracy': [77.31, 78.64, 78.81, 78.37]}, 4: {'losses': [0.5569269927978515, 0.5164715148925781, 0.5319765411376953, 0.5280328765869141], 'accuracy': [79.38, 80.76, 80.22, 80.34]}, 6: {'losses': [0.4632906616210937, 0.4644641296386719, 0.4652772644042969, 0.44572009887695313], 'accuracy': [82.79, 82.6, 82.67, 83.38]}, 8: {'losses': [0.4280053955078125, 0.4304277587890625, 0.41870563354492185, 0.41287210998535157], 'accuracy': [84.37, 84.18, 84.51, 85.12]}, 10: {'losses': [0.4158003601074219, 0.4127583312988281, 0.4012933013916016, 0.39449208984375], 'accuracy': [84.9, 84.82, 85.3, 85.84]}}, 'pca': {2: {'losses': [0.9848575317382813, 0.958135205078125, 0.9552243103027344, 0.9255470031738281], 'accuracy': [82.92, 78.4, 82.92, 78.4, 79.38, 82.92, 78.4, 79.38, 79.06, 82.92, 78.4, 79.38, 79.06, 79.92]}, 4: {'losses': [0.9080875244140625, 0.8836036071777343, 0.8704821105957031, 0.8572081481933593], 'accuracy': [82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 81.88, 82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 81.88, 80.68, 82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 81.88, 80.68, 81.84]}, 6: {'losses': [0.8480521362304687, 0.82582578125, 0.8089499572753907, 0.7913673217773437], 'accuracy': [82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 81.88, 80.68, 81.84, 83.88, 82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 81.88, 80.68, 81.84, 83.88, 84.2, 82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 81.88, 80.68, 81.84, 83.88, 84.2, 84.72, 82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 81.88, 80.68, 81.84, 83.88, 84.2, 84.72, 84.74]}, 8: {'losses': [0.7948213684082032, 0.7850610473632812, 0.7718647644042969, 0.7641170227050781], 'accuracy': [82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 81.88, 80.68, 81.84, 83.88, 84.2, 84.72, 84.74, 85.61, 82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 81.88, 80.68, 81.84, 83.88, 84.2, 84.72, 84.74, 85.61, 85.16, 82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 81.88, 80.68, 81.84, 83.88, 84.2, 84.72, 84.74, 85.61, 85.16, 85.89, 82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 81.88, 80.68, 81.84, 83.88, 84.2, 84.72, 84.74, 85.61, 85.16, 85.89, 85.57]}, 10: {'losses': [0.7549970031738281, 0.741978515625, 0.7226565307617188, 0.7171844665527344], 'accuracy': [82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 81.88, 80.68, 81.84, 83.88, 84.2, 84.72, 84.74, 85.61, 85.16, 85.89, 85.57, 86.03, 82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 81.88, 80.68, 81.84, 83.88, 84.2, 84.72, 84.74, 85.61, 85.16, 85.89, 85.57, 86.03, 86.15, 82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 81.88, 80.68, 81.84, 83.88, 84.2, 84.72, 84.74, 85.61, 85.16, 85.89, 85.57, 86.03, 86.15, 86.46, 82.92, 78.4, 79.38, 79.06, 79.92, 81.18, 81.88, 80.68, 81.84, 83.88, 84.2, 84.72, 84.74, 85.61, 85.16, 85.89, 85.57, 86.03, 86.15, 86.46, 86.5]}}, 'autoencoder': {2: {'losses': [0.8712482238769531, 0.8802846435546875, 0.8387731689453125, 0.8339138732910156], 'accuracy': [74.29, 74.95, 76.57, 76.9]}, 4: {'losses': [0.8651753723144531, 0.8991546142578125, 0.8995482238769531, 0.9636681030273437], 'accuracy': [76.43, 76.3, 76.47, 75.3]}, 6: {'losses': [0.8647954406738281, 0.8959936401367188, 0.9259752746582032, 0.9188942016601562], 'accuracy': [77.0, 76.63, 76.44, 76.56]}, 8: {'losses': [1.0044416931152345, 0.9775485168457031, 1.007714892578125, 1.0284607421875], 'accuracy': [75.04, 75.56, 75.24, 75.0]}, 10: {'losses': [1.0417603332519532, 1.0550320373535156, 1.096275439453125, 1.102545751953125], 'accuracy': [74.71, 74.66, 74.12, 74.07]}}}\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Results (Non-Clustered):\", results)\n",
    "print(\"Final Results (Clustered):\", clusteredResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Non-Clustered Results:\n",
      "classic:\n",
      "  Average Loss: {'NoCluster': 0.5188619812011719}\n",
      "  Average Accuracy: {'NoCluster': 80.19}\n",
      "pca:\n",
      "  Average Loss: {'NoCluster': 0.9590497436523437}\n",
      "  Average Accuracy: {'NoCluster': 82.92}\n",
      "autoencoder:\n",
      "  Average Loss: {'NoCluster': 0.9626321166992188}\n",
      "  Average Accuracy: {'NoCluster': 69.05}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clustered Results:\n",
      "classic:\n",
      "  Average Loss: {2: 0.5876620162963867, 4: 0.5333519813537598, 6: 0.4596880386352539, 8: 0.42250272445678716, 10: 0.4060860206604004}\n",
      "  Average Accuracy: {2: 78.2825, 4: 80.175, 6: 82.86, 8: 84.545, 10: 85.215}\n",
      "pca:\n",
      "  Average Loss: {2: 0.9559410125732423, 4: 0.8798453475952148, 6: 0.8185487991333007, 8: 0.7789660507202149, 10: 0.7342041290283202}\n",
      "  Average Accuracy: {2: 80.10428571428572, 4: 80.40933333333334, 6: 81.37695652173912, 8: 82.3624193548387, 10: 83.10397435897436}\n",
      "autoencoder:\n",
      "  Average Loss: {2: 0.8560549774169921, 4: 0.9068865783691407, 6: 0.9014146392822266, 8: 1.0045414611816406, 10: 1.0739033905029296}\n",
      "  Average Accuracy: {2: 75.67750000000001, 4: 76.125, 6: 76.6575, 8: 75.21000000000001, 10: 74.39}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+kAAAHUCAYAAABGRmklAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAADVAklEQVR4nOzdeVxU9frA8c/MsMsiKKssoriAO26JmlqaSy7YYukt12zx9iuzTK207GZaltqm5s291VuJZqappaW4IS4p7rK4gIAoi+wz5/fHwcERRFBgWJ73fZ3Xdc45c+aZgfjOc77Lo1EURUEIIYQQQgghhBBmpzV3AEIIIYQQQgghhFBJki6EEEIIIYQQQlQRkqQLIYQQQgghhBBVhCTpQgghhBBCCCFEFSFJuhBCCCGEEEIIUUVIki6EEEIIIYQQQlQRkqQLIYQQQgghhBBVhCTpQgghhBBCCCFEFSFJuhBCCCGEEEIIUUVIki5EKR05coQxY8bg7++PjY0N9vb2BAcH8+GHH5KSkmI8r2fPnvTs2bPC4li4cCErVqyosOvfi+3bt6PRaNi+fXuJ561YsQKNRmPcLCws8PT05Mknn+T06dOVE+wdaDQa3nnnHePjqKgo3nnnHWJiYswWkxBCiIolbf2dSVsvRMWzMHcAQlQH//3vf5kwYQLNmjVj8uTJBAUFkZeXR0REBIsXL2b37t2sXbu2UmJZuHAh9evXZ/To0ZXyehVp+fLlNG/enOzsbHbt2sWsWbP4888/OXHiBM7OzuYOz0RUVBQzZ86kZ8+eNGzY0NzhCCGEKGfS1lcMaeuFKDtJ0oW4g927d/PCCy/Qp08fwsLCsLa2Nh7r06cPr776Kps2bTJjhPdOURSys7OxtbWt1Ndt2bIlHTp0ANReCb1ez9tvv01YWBhjxoyp1FiEEELUXtLWVxxp64UoOxnuLsQdvP/++2g0GpYsWWLSaN9gZWXF4MGDb/v82w0Li4mJQaPRmAxnO3fuHE8++SReXl5YW1vj7u7Ogw8+yKFDhwBo2LAhx44dY8eOHcbhYzff6U1LS+O1117D398fKysrGjRowMSJE7l+/brJa2s0Gl588UUWL15MYGAg1tbWrFy5EoDTp08zYsQI3NzcsLa2JjAwkC+++KLI+zpx4gT9+vXDzs6O+vXr8/zzz5Oenn6HT7NkNxrxy5cvm+yPiIhg8ODBuLi4YGNjQ7t27VizZo3JOZmZmcb3bmNjg4uLCx06dOC7774znnO74YmjR48u8Y75ihUrePzxxwHo1auX8bO/8bM7ePAgAwcONH5mXl5ePPzww1y4cOEuPgUhhBCVTdp6aeulrRdVifSkC1ECvV7PH3/8Qfv27fHx8anw1xswYAB6vZ4PP/wQX19fkpOTCQ8P59q1awCsXbuWxx57DCcnJxYuXAhg/DKRmZlJjx49uHDhAm+88QatW7fm2LFjzJgxg3/++YetW7ei0WiMrxUWFsbff//NjBkz8PDwwM3NjaioKEJCQvD19eXjjz/Gw8ODzZs389JLL5GcnMzbb78NqA1rjx49sLS0ZOHChbi7u/PNN9/w4osv3tP7j46OBqBp06bGfX/++Sf9+vWjc+fOLF68GCcnJ77//nueeOIJMjMzjUMBJ02axOrVq3nvvfdo164d169f5+jRo1y5cuWeYgJ4+OGHef/993njjTf44osvCA4OBqBx48Zcv36dPn364O/vzxdffIG7uzsJCQn8+eef9/xFRgghRMWTtl7aepC2XlQxihDithISEhRAefLJJ0v9nB49eig9evQwPv7zzz8VQPnzzz9NzouOjlYAZfny5YqiKEpycrICKAsWLCjx+i1atDC5/g2zZ89WtFqtsn//fpP9P/74owIoGzduNO4DFCcnJyUlJcXk3L59+yre3t5Kamqqyf4XX3xRsbGxMZ4/ZcoURaPRKIcOHTI5r0+fPsW+11stX75cAZQ9e/YoeXl5Snp6urJp0ybFw8NDuf/++5W8vDzjuc2bN1fatWtnsk9RFGXgwIGKp6enotfrFUVRlJYtWyqhoaElvu6tP5sbRo0apfj5+ZnsA5S3337b+Ph///tfse8tIiJCAZSwsLASX1sIIUTVJG29Stp6aetF1SHD3YWoIlxcXGjcuDFz585l3rx5HDx4EIPBUOrnb9iwgZYtW9K2bVvy8/ONW9++fYsdgvfAAw+YLNiSnZ3Ntm3bGDp0KHZ2dibXGDBgANnZ2ezZswdQ73i3aNGCNm3amFxzxIgRZXrP9913H5aWljg4ONCvXz+cnZ1Zt24dFhbqIJ8zZ85w4sQJ/vWvfwEUiSk+Pp6TJ08C0KlTJ3777TemTp3K9u3bycrKKlMsdysgIABnZ2emTJnC4sWLiYqKqpTXFUIIUf1IWy9tvRClIUm6ECWoX78+dnZ2xqFZFUmj0bBt2zb69u3Lhx9+SHBwMK6urrz00kulGkp1+fJljhw5gqWlpcnm4OCAoigkJyebnO/p6Wny+MqVK+Tn5/PZZ58VucaAAQMAjNe4cuUKHh4eRWIobl9JVq1axf79+/njjz947rnnOH78OMOHDzd5TwCvvfZakZgmTJhgEtOnn37KlClTCAsLo1evXri4uBAaGlrhZV6cnJzYsWMHbdu25Y033qBFixZ4eXnx9ttvk5eXV6GvLYQQ4t5JWy9t/Z1IWy8qm8xJF6IEOp2OBx98kN9++40LFy7g7e1d5mvY2NgAkJOTY7L/1oYUwM/Pj6VLlwJw6tQp1qxZwzvvvENubi6LFy8u8XXq16+Pra0ty5Ytu+3xm908Zw3A2dkZnU7H008/zb///e9ir+Hv7w9AvXr1SEhIKHK8uH0lCQwMNC4g06tXL/R6PV999RU//vgjjz32mDHmadOm8cgjjxR7jWbNmgFQp04dZs6cycyZM7l8+bLxTvugQYM4ceIEoP4sUlNTi1yjuJ9FWbRq1Yrvv/8eRVE4cuQIK1as4N1338XW1papU6fe07WFEEJULGnrTUlbXzxp60Vlkp50Ie5g2rRpKIrC+PHjyc3NLXI8Ly+PX3755bbPv7GS6JEjR0z2r1+/vsTXbdq0KW+99RatWrUiMjLSuN/a2rrY4V0DBw7k7Nmz1KtXjw4dOhTZ7lTv087Ojl69enHw4EFat25d7DXq1asHqI3ssWPHOHz4sMk1vv322xJf404+/PBDnJ2dmTFjBgaDgWbNmtGkSRMOHz5cbDwdOnTAwcGhyHXc3d0ZPXo0w4cP5+TJk2RmZgLqz+LUqVMmX6KuXLlCeHj4HWO7sWhPSUPrNBoNbdq0Yf78+dStW9fk5yaEEKLqkrZe2nqQtl5UHdKTLsQddOnShUWLFjFhwgTat2/PCy+8QIsWLcjLy+PgwYMsWbKEli1bMmjQoGKf7+HhQe/evZk9ezbOzs74+fmxbds2fv75Z5Pzjhw5wosvvsjjjz9OkyZNsLKy4o8//uDIkSMmd2hv3Mn94YcfaNSoETY2NrRq1YqJEyfy008/cf/99/PKK6/QunVrDAYDcXFx/P7777z66qt07ty5xPf6ySef0K1bN7p3784LL7xAw4YNSU9P58yZM/zyyy/88ccfAEycOJFly5bx8MMP89577xlXfL1xF/tuOTs7M23aNF5//XW+/fZbnnrqKb788kv69+9P3759GT16NA0aNCAlJYXjx48TGRnJ//73PwA6d+7MwIEDad26Nc7Ozhw/fpzVq1fTpUsX7OzsAHj66af58ssveeqppxg/fjxXrlzhww8/xNHR8Y6xtWzZEoAlS5bg4OCAjY0N/v7+7N69m4ULFxIaGkqjRo1QFIWff/6Za9eu0adPn3v6PIQQQlQOaeulrQdp60UVYr4164SoXg4dOqSMGjVK8fX1VaysrJQ6deoo7dq1U2bMmKEkJiYazytuVdH4+HjlscceU1xcXBQnJyflqaeeMq4UemPF18uXLyujR49WmjdvrtSpU0ext7dXWrdurcyfP1/Jz883XismJkZ56KGHFAcHBwUwWak0IyNDeeutt5RmzZopVlZWipOTk9KqVSvllVdeURISEoznAcq///3vYt9ndHS0MnbsWKVBgwaKpaWl4urqqoSEhCjvvfeeyXlRUVFKnz59FBsbG8XFxUUZN26csm7dujKt+Hrr6rSKoihZWVmKr6+v0qRJE+P7Pnz4sDJs2DDFzc1NsbS0VDw8PJQHHnhAWbx4sfF5U6dOVTp06KA4Ozsr1tbWSqNGjZRXXnlFSU5ONrn+ypUrlcDAQMXGxkYJCgpSfvjhh1Kt+KooirJgwQLF399f0el0xp/diRMnlOHDhyuNGzdWbG1tFScnJ6VTp07KihUrSvwMhBBCVD3S1ktbL229qAo0iqIo5rg5IIQQQgghhBBCCFMyJ10IIYQQQgghhKgiJEkXQgghhBBCCCGqCEnShRBCCCGEEEKIKkKSdCGEEEIIIYQQooqQJF0IIYQQQgghhKgiJEkXQgghhBBCCCGqCAtzB1DZDAYDly5dwsHBAY1GY+5whBBCCBRFIT09HS8vL7RauX9eHqS9F0IIUZWUpa03a5L+119/MXfuXA4cOEB8fDxr164lNDT0tufHx8fz6quvcuDAAU6fPs1LL73EggULyvSaly5dwsfH594CF0IIISrA+fPn8fb2NncYNYK090IIIaqi0rT1Zk3Sr1+/Tps2bRgzZgyPPvroHc/PycnB1dWVN998k/nz59/Vazo4OADqh+Po6HhX1xBCCCHKU1paGj4+PsY2Stw7ae+FEEJUJWVp682apPfv35/+/fuX+vyGDRvyySefALBs2bK7es0bQ94cHR2l0RZCCFGlyLDs8iPtvRBCiKqoNG19jZ+TnpOTQ05OjvFxWlqaGaMRQgghhBBCCCFur8avTjN79mycnJyMm8xPE0IIIYQQQghRVdX4JH3atGmkpqYat/Pnz5s7JCGEEEIIIYQQolg1fri7tbU11tbWZXqOoijk5+ej1+srKCpRXel0OiwsLGTeqBBC1AB6vZ68vDxzhyGqIEtLS3Q6nbnDEELUUjU+SS+r3Nxc4uPjyczMNHcoooqys7PD09MTKysrc4cihBDiLmVkZHDhwgUURTF3KKIK0mg0eHt7Y29vb+5QhBC1kFmT9IyMDM6cOWN8HB0dzaFDh3BxccHX15dp06Zx8eJFVq1aZTzn0KFDxucmJSVx6NAhrKysCAoKuud4DAYD0dHR6HQ6vLy8sLKykh5TYaQoCrm5uSQlJREdHU2TJk3Qamv8jBEhhKhx9Ho9Fy5cwM7ODldXV2nrhQlFUUhKSuLChQs0adJEetSFEJXOrEl6REQEvXr1Mj6eNGkSAKNGjWLFihXEx8cTFxdn8px27doZ/33gwAG+/fZb/Pz8iImJued4cnNzMRgM+Pj4YGdnd8/XEzWPra0tlpaWxMbGkpubi42NjblDEkIIUUZ5eXkoioKrqyu2trbmDkdUQa6ursTExJCXlydJuhCi0pk1Se/Zs2eJw8xWrFhRZF9lDEuT3lFREvn9EEKImkF60MXtyO+GEMKcJNsQQgghhBBCCCGqCFk4TgghhCgjvUFPZGIkSZlJuNq5EuwWjE4rQ2KFEEKImkJvUNgXnUJiejZuDjZ08ndBp62cUTaSpFcQc/5QbxUTE4O/vz8HDx6kbdu2FfpaK1asYOLEiVy7dq1CX0cIIcxla+xW5uybw+XMy8Z97nbuTO00ld5+vc0Ymahs0tZfq9DXEUIIc9l0NJ6Zv0QRn5pt3OfpZMPbg4Lo19Kzwl9fkvQKYO4fqjk98cQTDBgwwNxhCCFEhdgau5VJ2yehYLo+SmJmIpO2T2Jez3mSqNcS0tZLWy+EqJk2HY3nha8juXUltITUbF74OpJFTwVX+N95mZNezm78UG9utKHwh7rpaLyZIqsctra2uLm5mTsMIYQod3qDnjn75hRJ0AHjvg/2fYDeoK/s0EQlk7Ze2nohRM2kNyjM/CWqmJYe476Zv0ShN1TsYuaSpN+Boihk5uaXakvPzuPt9cdK/KG+sz6K9Oy8Ul2vrCvZGwwGPvjgAwICArC2tsbX15dZs2YVOU+v1zNu3Dj8/f2xtbWlWbNmfPLJJybnbN++nU6dOlGnTh3q1q1L165diY2NBeDw4cP06tULBwcHHB0dad++PREREYA6BK5u3bom11q/fj0dOnTAxsaG+vXr88gjj5TpfQkhRFUQmRhpMsT9VgoKCZkJRCZGVmJUojxIWy9tvRBCAOyLTilyA/ZmChCfms2+6JQKjUOGu99BVp6eoBmby+VaCpCQlk2rd34v1flR7/bFzqr0P6Jp06bx3//+l/nz59OtWzfi4+M5ceJEkfMMBgPe3t6sWbOG+vXrEx4ezrPPPounpyfDhg0jPz+f0NBQxo8fz3fffUdubi779u0zliP517/+Rbt27Vi0aBE6nY5Dhw5haWlZbEy//vorjzzyCG+++SarV68mNzeXX3/9tdTvSQghqgJFUYhIiCjVuUmZSRUcjShv0tZLWy+EqL0uXcviQOxVDsReZduJ29+Mv1li+u0T+fIgSXoNkZ6ezieffMLnn3/OqFGjAGjcuDHdunUjJibG5FxLS0tmzpxpfOzv7094eDhr1qxh2LBhpKWlkZqaysCBA2ncuDEAgYGBxvPj4uKYPHkyzZs3B6BJkya3jWvWrFk8+eSTJq/Xpk2be36/QghRGRIzE1l/dj3rzqwjJi2mVM9xtXOt2KBErSVtvRBC3JvcfAPHLqUSGXeNyILEPCGt7Am3m4NNBURXSJL0O7C11BH1bt9SnbsvOoXRy/ff8bwVYzrSyd+lVK9dWsePHycnJ4cHH3ywVOcvXryYr776itjYWLKyssjNzTWuBuvi4sLo0aPp27cvffr0oXfv3gwbNgxPT3WBhEmTJvHMM8+wevVqevfuzeOPP25s4G916NAhxo8fX+r3IYQQ5parz+WP83+w7sw6wi+FY1AMANjo1AY5W198Y65Bg7udO8FuwZUWqygf0tZLWy+EqJmS0nOIjLtKZOxVIuOucuRCKjn5BpNzdFoNQZ6OtPdzpq1PXWZtPE5yek6x05o0gIeTTan+vt8LSdLvQKPRlHoYWvcmrng62ZCQml3iD7V7E9dyL9Fia2tb6nPXrFnDK6+8wscff0yXLl1wcHBg7ty57N2713jO8uXLeemll9i0aRM//PADb731Flu2bOG+++7jnXfeYcSIEfz666/89ttvvP3223z//fcMHTr0nuISQghzURSFqJQowk6HsTF6I2m5acZjwW7BhAaE8lDDh9h9aTeTtk9Sn3PTX3oN6t/0KZ2mSL30akjaemnrhRDVn96gcDIhnQM3JeWxVzKLnOdsZ0l7P2fa+TrT3s+Z1t5OJm2AjaWWF76ORAMmf+dv/EV/e1BQhZfblCS9HOm0Gt4eFGSWH2qTJk2wtbVl27ZtPPPMMyWe+/fffxMSEsKECROM+86ePVvkvHbt2tGuXTumTZtGly5d+Pbbb7nvvvsAaNq0KU2bNuWVV15h+PDhLF++vNiGu3Xr1mzbto0xY8bc4zsUQojydyXrCr+e+5Wws2GcvnrauN/Nzo0hjYcwJGAIfo5+xv29/Xozr+e8YuukT+k0Rcqv1QLS1ktbL4SoGlKz8jhYkJAfiLvKobhrXM81rbCi0UBTNweC/dSEPNi3Lv716xjX3yhOv5aeLHoquEiZTQ+pk159meuHamNjw5QpU3j99dexsrKia9euJCUlcezYsSLD4gICAli1ahWbN2/G39+f1atXs3//fvz9/QGIjo5myZIlDB48GC8vL06ePMmpU6cYOXIkWVlZTJ48mcceewx/f38uXLjA/v37efTRR4uN6+233+bBBx+kcePGPPnkk+Tn5/Pbb7/x+uuvV8jnIIQQd5JnyOPvC38TdiaMvy/8Tb6SD4CV1ooHfR9kSMAQ7vO877Y94r39etPLpxeRiZEkZSbhaudKsFuw9KDXItLWm5K2XghR0RRF4WzSdePQ9QOxVzmdmFHkPHtrC9r51iW4oJe8rW9dHG2KX/SyJP1aetInyIN90Skkpmfj5qAOca/oHvQbJEmvAOb6oU6fPh0LCwtmzJjBpUuX8PT05Pnnny9y3vPPP8+hQ4d44okn0Gg0DB8+nAkTJvDbb78BYGdnx4kTJ1i5ciVXrlzB09OTF198keeee478/HyuXLnCyJEjuXz5srHMys2LxdysZ8+e/O9//+M///kPc+bMwdHRkfvvv79CPwchhCjO6aunCTsTxoZzG0jJLiyd0rJeS0IDQunn3w8na6dSXUun1dHRo2NFhSqqAWnrC0lbL4Qob9dz8jl84VrBsPVrRMZd5VpmXpHzGtazM/aSt/dzpombQ7n9HdZpNXRpXK9crlVWGqWsBTqrubS0NJycnEhNTcXR0dHkWHZ2NtHR0fj7+2NjU7Er9onqS35PhKg+UnNS+S36N8LOhHHsyjHjfhcbFwY1GsSQgCE0cb79qtWVpaS2Sdwdae/FvZDfESEqj6IoXLiaRWSc2kMeGXeV4/Hp6A2maaq1hZY2PoW95O1861Lf3tpMUZddWdp66UkXQghRo+gNenbH72bdmXX8EfcHuYZcACw0FvTw6UFoQChdG3TFUlv24W9CCCGEuDc5+XqOXkwzDls/EHeVpPScIud5OdkQ7OdsTMoDPR2xstCaIeLKJ0m6EEKIGiEmNYZ1Z9ex/ux6EjMTjfubOjclNCCUhxs9jItNxZZMEUIIIYSpxLRsYw/5gdirHL2YRq7etAyahVZDiwZOtPd1JthP7S33qlt7K0dIki6EEKLaup53nc0xmwk7E8bBxIPG/U7WTgzwH0BoQCiBLoElruIqhBBCiPKRrzdwIiHdJCm/cDWryHn16ljdtOK6WgbNxlIWYL1BknQhhBDVikExEJEQQdiZMLbGbSUrX238tRotXb26EhoQSk+fnljprMwcqRBCCFGzXb2ey8HzBcPWY69y+HwqWXmmZdC0Gmjm4Uiwb13jAm++LnZyA70EkqQLIYSoFi5mXGT9mfWsO7uOixkXjfsbOjYkNCCUQY0H4WbnZsYIhRBCiJrLYFA4k5RhMpf8XNL1Iuc52FgQ7Fs4l7yNjxMOd1EGrTaTJF0IIUSVlZWfxdbYraw7s469CXuN++0t7enn348hjYfQxrWN3I0XQgghyllGTj6HCsqfHYi9ysG4q6Rl5xc5r5FrnYK55GpSHuBqj7aS6onXVJKkCyGEqFIUReFw0mHCzoSxOWYzGXkZxmOdPTsTGhDKg74PYmtRexeUEUIIIcqToijEpWQah61Hxl3jZEIat1RBw9ZSRxsfJ+Ow9XY+zjjXkell5U2SdCGEEFVCYmYi68+uZ92ZdcSkxRj3N7BvwJCAIQxpPAQvey/zBSiEEELUENl5ev65mGpMyg/GXSU5I7fIeQ3q2hoT8vZ+zjT3cMBCVzvKoJmTJOlCCCHMJlefy5/n/yTsTBjhl8IxKGpJFlsLW/r49SE0IJT27u3RauQLgRBCCHG34lOziIy9ZpxLHnUplTy9aTe5lU5LiwaOtC+YSx7s54y7o42ZIq7dJEmvKAY9xIZDxmWwdwe/ENBKWQEhhFAUhaiUKMJOh7ExeiNpuWnGY8FuwYQGhPJQw4eoY1nHjFEKUQrS1gshKpDeoLAvOoXE9GzcHGzo5O+CrhRzvfP0BqIupRnnkkfGXuVSanaR8+rbW9PBT61L3t7PmRZeUgatqpAkvSJErYdNUyDtUuE+Ry/o9wEEDTZfXEIIYUYp2SlsOLuBsLNhnL562rjf3c6dwY0HMyRgCH6OfmaMUIgykLZeCFGBNh2NZ+YvUcTflFx7Otnw9qAg+rX0NDn3SkYOkXHXjLXJj1y4RnaeweQcrQYCPR2Ndcnb+znj7WwrC69WUZKkl7eo9bBmJHDLKgtp8er+Yauk8RZC1Bp5hjx2XthJ2Jkw/rrwF/mKuiqsldaKB30fJDQglM6endFJ76OoTqStF0JUoE1H43nh68hb/8KQkJrNC19H8ubAQGwtdQVzya8RnVy0DJqTraWxLnmwnzNtvOtSx1pSv+pCflJ3oiiQl1m6cw16+O11ijTa6oUAjXrXvVHP0g2Hs7SDUt7d6tmzJy1btgTg66+/RqfT8cILL/Cf//wHjUZDTk4O06dP57vvviMxMRFfX1+mTp3KuHHj0Ov1PPvss/zxxx8kJCTg6+vLhAkTePnll0v3voUQ4hanr54m7EwYG85tICU7xbi/Zb2WhAaE0s+/H07WTmaMUIibSFsvhKgi9AaFmb9E3fYvDMB7G44XORbgZm8yl7xR/TpSBq0akyT9TvIy4f3yWk1YUYfFzfEp3elvXAKr0s/JXLlyJePGjWPv3r1ERETw7LPP4ufnx/jx4xk5ciS7d+/m008/pU2bNkRHR5OcnAyAwWDA29ubNWvWUL9+fcLDw3n22Wfx9PRk2LBhd/NGhRC1UGpOKr9F/0bYmTCOXTlm3F/Pph6DGg9iSOMhBDgHmDFCIW5D2vq7eaNCiAqwLzrFZIj77bT0cqRXczeC/ZwJ9nHGyc6yEqITlUWS9BrEx8eH+fPno9FoaNasGf/88w/z58+nR48erFmzhi1bttC7d28AGjVqZHyepaUlM2fOND729/cnPDycNWvWSMMthCiR3qBnT/wews6E8UfcH+Qa1PItFhoLevj0IDQglK4NumKplS8PQpQHaeuFqNkS0++coAOMv78RQ9o2qOBohLlIkn4nlnbqXe7SiA2Hbx6783n/+lFdAbY0r10G9913n8niD126dOHjjz/m4MGD6HQ6evTocdvnLl68mK+++orY2FiysrLIzc2lbdu2ZXp9IUTtEZMaw7qz61h/dj2JmYnG/U2dmxIaEMrDjR7GxcbFjBEKUQbS1gshqoCzSRms3BVTqnPdHKQ0Wk0mSfqdaDSlH4bW+AF1Zde0eIqfq6ZRjzd+oFJLtNjYlPwf8Zo1a3jllVf4+OOP6dKlCw4ODsydO5e9e/dWUoRCiOrget51NsdsJuxMGAcTDxr3O1k78bD/w4QGhNLcpbmsFCuqH2nrhRBmdC0zl0+2nWb17ljyDcX9XSmkATyc1HJsouaSJL08aXVq6ZU1I1H/E7r5P7KCL6395lRYo71nz54ij5s0aUKbNm0wGAzs2LHDOATuZn///TchISFMmDDBuO/s2bMVEqMQonoxKAYOXD5A2JkwtsRuISs/CwCtRktXr66EBoTS06cnVjorM0cqRCWRtl4IUU7y9Aa+3hPLgq2nSc3KA6B3oBvdmtRn5voooNi/MLw9KKhU9dJF9SVJenkLGqyWXim2duqcCi3Jcv78eSZNmsRzzz1HZGQkn332GR9//DENGzZk1KhRjB071riYTGxsLImJiQwbNoyAgABWrVrF5s2b8ff3Z/Xq1ezfvx9/f/8Ki1UIUbVdzLjI+jPrWXd2HRczLhr3N3RsSGhAKIMaD8LNzs2MEQphRtLWCyHugaIo/HEikVkbj3MuSS2f1tzDgbceDqJbk/oAeDjaFKmT7nGbOumi5pEkvSIEDYbmD6vz1jIug727Oi+tgoe9jRw5kqysLDp16oROp+P//u//ePbZZwFYtGgRb7zxBhMmTODKlSv4+vryxhtvAPD8889z6NAhnnjiCTQaDcOHD2fChAn89ttvFRqvEKJqycrPYmvsVtadWcfehMIhsPaW9vTz70doQCit67eW4exCgLT1Qoi7ciIhjfc2HGfnGbXyQn17Kyb1acYTHX1Mesf7tfSkT5AH+6JTSEzPxs1BHeIuPei1g0ZRlJInPtQwaWlpODk5kZqaiqOjo8mx7OxsoqOj8ff3v+PcrqqmZ8+etG3blgULFpg7lBqvOv+eCHErRVE4nHSYsDNhbI7ZTEZeBgAaNHTy7ERoQCgP+j6IrYWtmSOt2Upqm8TdqYntvbT1lae6/o6Iqis5I4d5W07x/b44DApY6bSM7ebPv3s1xsFGKqDUBmVp66UnXQghaqHEzETWn13PujPriEmLMe73tvdmSMAQBjcejJd9edWNFkIIIWqnnHw9y3fF8MUfZ0jPyQfg4VaeTO3fHB+XslV3ELWHJOlCCFFL5Opz+fP8n4SdCSP8UjgGxQCArYUtffz6EBoQSnv39mg1WjNHKoQQQlRviqLw29EEZv92nPMp6qKrrRo4MX1gkKzMLu5IkvQaYvv27eYOQQhRBSmKwvGU44SdCWNj9EZSc1KNx4LdggkNCOWhhg9Rx7KU5aeEEGYjbb0Q1cM/F1L5z4Yo9sWkAODuaM3rfZsztF0DtDKnXJSCJOlCCFEN6Q16IhMjScpMwtXOlWC3YHQ3LViVkp3ChrMbCDsbxumrp4373e3cGdx4MKEBofg6+pojdCGEEKJGupyWzYebTvLzwQsoCthYann2/sY836MRdlaSdonSk98WIYSoZrbGbmXOvjlczrxs3Odu585rHV/DWmtN2Jkw/rrwF/mKOvfNSmvFg74PEhoQSmfPzibJvBBCCCHuTVauniV/nWPxjrNk5ekBGNquAa/3a4ankyy8KspOknQhhKhGtsZuZdL2SSiYFua4nHmZyTsmm+xrVb8VQxoPoZ9/P5ysnSozTCGEEKLGMxgU1h2+yIebThrrmbf3c2b6wCDa+tQ1b3CiWjPr6kB//fUXgwYNwsvLC41GQ1hY2B2fs2PHDtq3b4+NjQ2NGjVi8eLFFR+oEEJUAXqDnjn75hRJ0G+mRcvIoJGsHbyWbx/+lieaPyEJuhBCCFHODsSmMHRROK/8cJj41Gwa1LXl8xHt+PH5LpKgi3tm1iT9+vXrtGnThs8//7xU50dHRzNgwAC6d+/OwYMHeeONN3jppZf46aefKjhSIYQwv8jESJMh7sUxYKCnT08CnAMqKSohyiY/P5+33noLf39/bG1tadSoEe+++y4Gg6HY85977jk0Go3UBhdCVAkXrmby4reRPLpoN4fPX6OOlY7JfZux7dUeDGytdjwKca/MOty9f//+9O/fv9TnL168GF9fX2NDHRgYSEREBB999BGPPvpoBUUphBBVw6HEQ6U6LykzqWIDEeIefPDBByxevJiVK1fSokULIiIiGDNmDE5OTrz88ssm54aFhbF37168vLzMFK0QQqgycvJZ+OcZvtoZTW6+AY0Gnujgw6SHmuLmYGPu8EQNU63mpO/evZuHHnrIZF/fvn1ZunQpeXl5WFpaFnlOTk4OOTk5xsdpaWkVHifceeVlUTk0Gg1r164lNDTU3KEIcdcSMxP5NPJT1p1dV6rzXe1cKzgiIe7e7t27GTJkCA8//DAADRs25LvvviMiIsLkvIsXL/Liiy+yefNm47lVjbT1VYO09aIi6Q0K/4s4z0e/nyI5Q80pQhrX462HgwjycjRzdKKmqlZJekJCAu7u7ib73N3dyc/PJzk5GU9PzyLPmT17NjNnzqysEIHbr7w8tdNUevv1rtRYymLFihVMnDiRa9eumTsUIQSQmZfJymMrWX5sOVn5WQDY6GzI1mcXe74GDe527gS7BVdmmEKUSbdu3Vi8eDGnTp2iadOmHD58mJ07d5oMZzcYDDz99NNMnjyZFi1alOq6lX1TXtp6IWq+8LPJ/GfDcY7Hq39P/OvX4Y0BgfQOdJNh7aJCmXVO+t249T8IRVGK3X/DtGnTSE1NNW7nz5+v0PhurLx867zRxMxEJm2fxNbYrRX6+qJ85ebmmjsEUQsZFAPrz65nUNggFh5eSFZ+Fm1d2/LNgG+Y3X02moL/3ezG4ymdpkhPnqjSpkyZwvDhw2nevDmWlpa0a9eOiRMnMnz4cOM5H3zwARYWFrz00kulvu7s2bNxcnIybj4+PhURPiBtfU0jbb24VXTydcavimDEf/dyPD4NRxsL3no4kM0T76dPkLsk6KLCVask3cPDg4SEBJN9iYmJWFhYUK9evWKfY21tjaOjo8lWFoqikJmXWaotPSed2ftmF7vyslLwvzn75pCek16q6924AVFamzZtolu3btStW5d69eoxcOBAzp49C8D27dvRaDQmd84PHTqERqMhJiaG7du3M2bMGFJTU9FoNGg0Gt555x0Arl69ysiRI3F2dsbOzo7+/ftz+vRpk9cODw/n/vvvx9bWFh8fH1566SWuX79uPN6wYUPef/99xo4di4ODA76+vixZssTkGhcuXODJJ5/ExcWFOnXq0KFDB/bu3Ws8vmjRIho3boyVlRXNmjVj9erVJs8/ffo0999/PzY2NgQFBbFly5Yin9HFixd54okncHZ2pl69egwZMoSYmBjj8dGjRxMaGsrs2bPx8vKiadOmZfoZCHGv9ifs58kNT/LmzjdJzEykgX0DPurxEav6r6K1a2t6+/VmXs95uNm5mTzP3c6deT3nVekePCEAfvjhB77++mu+/fZbIiMjWblyJR999BErV64E4MCBA3zyySesWLGiTF+E7+WmvLT10tYLAZCamcd/NkTx0PwdbIm6jE6rYVQXP7ZP7sUz3RthZVGtUidRjVWr4e5dunThl19+Mdn3+++/06FDh2Lno5eHrPwsOn/budyudznzMiHfh5Tq3L0j9mJnaVfqa1+/fp1JkybRqlUrrl+/zowZMxg6dCiHDh2643NDQkJYsGABM2bM4OTJkwDY29sDamN2+vRp1q9fj6OjI1OmTGHAgAFERUVhaWnJP//8Q9++ffnPf/7D0qVLSUpK4sUXX+TFF19k+fLlxtf4+OOP+c9//sMbb7zBjz/+yAsvvMD9999P8+bNycjIoEePHjRo0ID169fj4eFBZGSkcbXftWvX8vLLL7NgwQJ69+7Nhg0bGDNmDN7e3vTq1QuDwcAjjzxC/fr12bNnD2lpaUycONHkPWZmZtKrVy+6d+/OX3/9hYWFBe+99x79+vXjyJEjWFlZAbBt2zYcHR3ZsmVLmb88CXG3YtNimX9gPtvitgFgb2nPs62fZUTgCKx11ibn9vbrTS+fXjIXVlRLkydPZurUqTz55JMAtGrVitjYWGbPns2oUaP4+++/SUxMxNfX1/gcvV7Pq6++yoIFC0ySrZtZW1tjbW1d7LE7kbZe2npRu+XrDXy7L475W05xNTMPgF7NXHnz4UAC3BzMHJ2ojcyapGdkZHDmzBnj4+joaA4dOoSLiwu+vr5MmzaNixcvsmrVKgCef/55Pv/8cyZNmsT48ePZvXs3S5cu5bvvvjPXW6hSbl3hfunSpbi5uREVFXXH51pZWeHk5IRGo8HDw8O4/0aDvWvXLkJC1C8c33zzDT4+PoSFhfH4448zd+5cRowYYWwomzRpwqeffkqPHj1YtGgRNjbqipcDBgxgwoQJgDrccf78+Wzfvp3mzZvz7bffkpSUxP79+3FxcQEgIKCwhNRHH33E6NGjjc+fNGkSe/bs4aOPPqJXr15s3bqV48ePExMTg7e3NwDvv/++SfWA77//Hq1Wy1dffWXsnVm+fDl169Zl+/btxkUJ69Spw1dffWVsyIWoSKk5qXx55Eu+O/Ed+YZ8dBodjzV9jAltJ+Bi43Lb5+m0Ojp6dKzESIUoH5mZmWi1pr1ROp3OmKg9/fTT9O5tOiKkb9++PP3004wZM6bS4qyqpK2Xtl6Urz9PJjLr1+OcScwAoImbPW8NDKJHU1mEVZiPWZP0iIgIevXqZXw8adIkAEaNGsWKFSuIj48nLi7OeNzf35+NGzfyyiuv8MUXX+Dl5cWnn35aoeXXbC1s2Tti751PBA5cPsCEbRPueN7CBxfS3r19qV67LM6ePcv06dPZs2cPycnJxi88cXFx2NmV/i79zY4fP46FhQWdOxf2MNSrV49mzZpx/PhxQB2aeObMGb755hvjOYqiYDAYiI6OJjAwEIDWrVsbj9/4gpCYmAiow/HatWtnbLSLi+PZZ5812de1a1c++eQT43FfX19jow3qyIub3YjTwcH0jmh2drZxqCCovTrSaIuKlmfIY83JNSw6vIjUnFQAujfozqsdXqVx3cZmjk6IijNo0CBmzZqFr68vLVq04ODBg8ybN4+xY8cCahtz6xQ2S0tLPDw8aNasWYXEJG29tPWi9jl1OZ33fj3OX6fUsqUudax4pU9Thnf0wUInw9qFeZk1Se/Zs2eJQ4xWrFhRZF+PHj2IjIyswKhMaTSaUg9DC/EKwd3OncTMxGLnqt1YeTnEK6RChqUOGjQIHx8f/vvf/+Ll5YXBYKBly5bk5uYah7Pd/Hnn5eXd8Zq3+/koimK8Q20wGHjuueeKXeDn5uGKt05J0Gg0xi8XtrZ3/pJS3KKBN/YVF+et5xsMBtq3b2/yBeMGV9fCu6V16tS5YyxC3C1FUdh+fjvzDswjJi0GgIC6AUzuMJmQBqUbHitEdfbZZ58xffp0JkyYQGJiIl5eXjz33HPMmDHDbDFJWy9tvag9Uq7nMn/LKb7dF4feoGCp0zCmqz//7hWAk23FTJ8Voqyq1Zz0qk6n1TG101QmbZ+EBo1J413RKy9fuXKF48eP8+WXX9K9e3cAdu7caTx+o2GKj4/H2dkZoMj8NSsrK/R6vcm+oKAg8vPz2bt3r3EI3JUrVzh16pTxrnlwcDDHjh0zGbJWVq1bt+arr74iJSWl2DvsgYGB7Ny5k5EjRxr3hYeHG2MICgoiLi6OS5cu4eXlBai1eG8WHBzMDz/8gJubW5kXEBSiPBy/cpyPIj5iX8I+AFxsXPi/dv9HaEAoFlr5cyxqBwcHBxYsWGBScu1ObjcP3RykrZe2XlRPufkGVobH8Okfp0nPzgegbwt3pvUPpGF9uWkjqhYZy1HOzLXy8o0VTJcsWcKZM2f4448/jNMHQJ3z5ePjwzvvvMOpU6f49ddf+fjjj02u0bBhQzIyMti2bRvJyclkZmbSpEkThgwZwvjx49m5cyeHDx/mqaeeokGDBgwZMgRQ55zt3r2bf//73xw6dMg4t+3//u//Sh3/8OHD8fDwIDQ0lF27dnHu3Dl++uknY+M7efJkVqxYweLFizl9+jTz5s3j559/5rXXXgOgd+/eNGvWjJEjR3L48GH+/vtv3nzzTZPX+Ne//kX9+vUZMmQIf//9N9HR0ezYsYOXX36ZCxcu3NXnLkRpJGYmMn3XdJ7Y8AT7EvZhpbVifKvx/Dr0Vx5r+pgk6EJUM9LWS1svqg9FUdh0NIE+83cwa+Nx0rPzaeHlyHfj7+PLpztIgi6qJqWWSU1NVQAlNTW1yLGsrCwlKipKycrKuufXydfnK/vi9ym/nv1V2Re/T8nX59/zNe9ky5YtSmBgoGJtba20bt1a2b59uwIoa9euVRRFUXbu3Km0atVKsbGxUbp3767873//UwAlOjraeI3nn39eqVevngIob7/9tqIoipKSkqI8/fTTipOTk2Jra6v07dtXOXXqlMlr79u3T+nTp49ib2+v1KlTR2ndurUya9Ys43E/Pz9l/vz5Js9p06aN8TUURVFiYmKURx99VHF0dFTs7OyUDh06KHv37jUeX7hwodKoUSPF0tJSadq0qbJq1SqT6508eVLp1q2bYmVlpTRt2lTZtGmTyftXFEWJj49XRo4cqdSvX1+xtrZWGjVqpIwfP974+zBq1ChlyJAhJX7O5fl7Imq267nXlYWHFiodv+6otFzRUmm5oqXy+o7XlYvpF80dmqhiSmqbxN2pjPZe2npp60XV9s+Fa8oTX4YrflM2KH5TNigd3tui/LA/TsnXG8wdmqiFytLWaxSldtWdSEtLw8nJidTU1CLDoLKzs4mOjsbf39+4SqkQt5LfE3EnBsXAhnMb+CTyExIz1QWT2ri2YXLHybRxbWPm6ERVVFLbJO6OtPfiXsjvSPWWmJbNR7+f5H8HLqAoYG2hZXz3RrzQszF1rGX0mjCPsrT18lsqhBDlaH/Cfubun8vxFHVF5Ab2DZjYfiJ9/foWWeBICCGEEOUnO0/PV3+fY+H2s2TmqmsvDG7jxZT+zWlQt2yVFIQwJ0nShRCiHMSlxTHvwDy2xW0DwN7SnmdbP8uIwBFY66zNHJ0QQghRcymKwvrDl/hw00kuXssCoK1PXWYMCiLY19nM0QlRdpKkCyHEPUjNSeXLI1/y3YnvyDfko9PoeKzpY0xoOwEXm+JrAQshhBCifETGXeU/G6I4GHcNAC8nG6b0b87gNl4ygk1UW5KkCyHEXcgz5LHm5BoWHV5Eak4qAN0bdOfVDq/SuG5jM0cnhBBC1GwXr2Xx4aYTrDt0CQA7Kx0v9GjM+PsbYWNZ/iUQhahMkqQXo5atpSfKSH4/ajdFUdh+fjvzDswjJi0GgIC6AUzuMJmQBiFmjU0IUTby91zcjvxuVF3Xc/JZvOMsS/46R06+AY0GHgv25rW+zXB3lEX+RM0gSfpNLC0tAcjMzMTWVhaXEMXLzMwECn9fRO1x/MpxPor4iH0J+wBwsXHh/9r9H6EBoVLrXIhqRKdTe9lyc3OlvRfFys3NBQp/V4T5GQwKP0Ze4KPNJ0lMzwGgs78L0wcG0bKBk5mjE6J8ybfKm+h0OurWrUtioloyyc7OTuayCCNFUcjMzCQxMZG6detKw12LJGYm8tnBz1h3Zh0KClZaK0a1GMXYlmOxt7I3d3hCiDKysLDAzs6OpKQkLC0t0Wq15g5JVCEGg4GkpCTs7OywsJCvylXB3nNX+M+vURy9mAaAr4sdbwxoTt8WHvJdXdRI8pfnFh4eHgDGRL1EigL6HDAYQKsFnTXIH4oar27dusbfE1GzZeZlsjJqJcuPLicrX10tdoD/AF4Ofhkvey8zRyeEuFsajQZPT0+io6OJjY01dziiCtJqtfj6+koCaGaxV64ze+MJNh1LAMDB2oL/ezCAUSENsbaQzhJRc0mSfosbDbebmxt5eXm3P/HMH/D3R3D9pmS+jht0fw0CHqj4QIVZWFpaSg96LWBQDGw4t4FPIj8hMVP9b7yNaxsmd5xMG9c2Zo5OCFEerKysaNKkiXFYsxA3s7KykhEWZpSWncfnf5xhxa4YcvUGtBoY0dmXV3o3pZ69lDUVNZ8k6beh0+lun4xFrYcfRwK3LCqScQF+HAHDVkHQ4AqPUQhR/vYn7Gfu/rkcTzkOQAP7BkxsP5G+fn2lR0WIGkar1WJjIwtNCVFV5OsNfL//PPO3nOLKdfUGWvcm9Xnr4SCaeTiYOTohKo8k6WVl0MOmKRRJ0KFgnwY2TYXmD4NWelyFqC7i0uKYd2Ae2+K2AWBvac/41uP5V+C/sNbJXXshhBCiIv11Kon3fo3i1OUMABq71uGth4Po2cxVbpKLWkeS9LKKDYe0SyWcoEDaRfU8/+6VFpYQ4u6k5qTy5ZEv+e7Ed+Qb8tFqtDze9HFeaPMC9WzrmTs8IYQQokY7k5jBrF+j+PNkEgB17Sx5pXdTRnT2xVInUw5E7SRJelllXC7f84QQZpFnyGPNyTUsOryI1JxUALo16Mar7V8lwDnAzNEJIYQQNdvV67ks2HqKr/fGoTcoWGg1jAppyEsPNMHJTsrcitpNkvSysncv3XmRq8HJB3w6yYrvQlQhiqKw/fx25h2YR0xaDAABdQN4rcNrdG3Q1ayxCSGEEDVdbr6B1Xti+WTrKdKy8wHoHejOGwOa08hVypqKKsSgV0dHZ1xWc0C/kEqbzixJeln5hYCjF6TFU/y89ALR29XNvRV0HAetHgdr+cMjhDmdSDnB3P1z2ZewDwAXGxdebPciQwOGYqGVP4dCCCFERVEUha3HE3l/43Gik68D0NzDgRkDgwgJqG/m6IS4RdR6dR2ym6c5O3pBvw8qZYFwjaIoJWSaNU9aWhpOTk6kpqbi6Oh4dxeJWg9rRhY8uPnjK+gx7/0OXDkN//wI+dnqPmtHaDsCOowD16Z3Gb0Q4m4kZiby+cHPCTsThoKCldaKkS1GMq7lOOyt5OaZML9yaZuECflMhag6jsen8Z8NUYSfvQJAfXtrXnuoKY938EGnlRGnooox5nq3pskFv6t3WcmrLO2SJOl3q9i7Kw2g35zCH1pmChz6FiKWQsq5wvP874eO46HZANBJ750QFSUrP4uVx1ay7OgysvKzAOjv35+JwRPxsvcyc3RCFJKEsvzJZyqE+SWl5zBvy0l+2H8egwJWFlqe6ebPhF4B2FvLd2BRBRn0sKBlCQuFa9Qe9Yn/lHnoe1naJfmv424FDVbLrJU0T8HOBUJehPsmwLk/YP9SOLUJov9SNwcvaD8a2o8CBw+zvRUhahqDYuDXc7+yIHIBiZmJALRxbcPkjpNp49rGzNEJIYQQNVt2np5lu6JZ+OdZMnLUeecPt/Zkar/m+LjYmTk6IUpQRSp5SZJ+L7S60v1wtFoI6K1u1+LgwAo4sBLSL8H29+GvDyFwEHR8Bvy6ykJzQtyDiIQI5kbMJepKFAAN7Bswsf1E+vr1lTqrQgghRAVSFIVf/4lnzm8nuHBVHcHWxtuJ6QOD6NDQxczRCVECgwESo+DgN6U7v4IreUmSXtnq+sKDM6DHFHXI/P6v4PweOLZW3VwD1YXmWj8BNjI8T4jSikuLY/6B+WyN2wpAHcs6PNv6Wf4V+C+sddZmjk4IIYSo2Q6fv8Z/NkQREXsVAA9HG6b0b8aQNg3QyrxzUdXcSMpjdkLM3xC7C7Kulv75pa34dZckSTcXC2to/bi6JfyjJutH1kDScdj4Gmx9R03UOz4D7kHmjlaIKis1J5UlR5bw7YlvyTfko9Voebzp47zQ5gXq2dYzd3hCCCFEjRafmsXcTSf5+eBFAGwtdTzXoxHP3t8IOytJNUQVYTBA4rGCpHxn8Um5ZR3wvQ8u7IectNtcqGBOul9IhYYr/+VUBR6tYNAn0OddOPy9mrAnn1IXnItYCr4h0OkZaD4ILKzMHa0QVUKeIY81J9ew6PAiUnNSAejWoBuvtn+VAOcAM0cnhBBCVH96g8K+6BQS07Nxc7Chk7+LcTX2zNx8vtxxji//Okt2ngGAR4Ib8Hrf5ng42ZgzbCFKl5Rb2atJecNu0LA7eLYBneWdK3n1m1Ph9dIlSa9KbJyg83PQ6Vl1Ybn9X8GJXyEuXN3quKmLzLUfA04NzB2tEGahKAo7Luzg44iPiUmLASCgbgCvdXiNrg26mjc4IYQQoobYdDSemb9EEZ+abdzn6WTD9IeDyM7X8+GmkySkqcc6NnRm+sAgWnvXNVO0otYzGODy0cKEPGYnZF8zPed2SfmtggarZdaKrZM+R+qkV4RqV5Il7VLBQnMrChco0OigWX91KHyjnrLQnKg1TqSc4KP9H7E3YS8ALjYuvNjuRYYGDMVCK/ccRfVV7dqmakA+UyHu3qaj8bzwdWSRKtG38na25Y0BgfRv6SGLs4rKdXNSfiMxLzYp73JLUl6G74sGfcmVvMpISrDVJI5e0OsNuH8ynNiglnGL+Vv994kNUC9ATdbbDAfbuuaOVogKkZiZyOcHPyfsTBgKClZaK54OeppnWj2DvZW9ucMTQgghagy9QWHmL1ElJuga4LW+zRjXzR8by4od9isEUDlJ+a1KW8mrAkiSXl3oLKHFUHVLPK4m64e/hytnYNNU2DpTXYSu4zPqL6QQNUBWfhYrj61k2dFlZOWrpVz6N+zPy+1fpoG9TPkQQgghytu+6BSTIe7FUYBgX2dJ0EXFMeiLScpTTc+xcgC/G0l5N/C4x6S8CqkZ76K2cQuEhz+C3m+rK8Lv/0otIRC5St28O0LH8RA0BCxl4Q5R/RgUA7+e+5UFkQtIzEwEoLVrayZ3mExbt7bmDU4IIYSowRLTS07Qy3qeEKVSy5PyW9XMd1VbWDuoNdU7jIW43WqyHrVOLRtwYT9sngbBI9WF5pz9zB2tEKUSkRDB3Ii5RF2JAsCrjhevtH+Fvg37ynw3IYQQooK5OZSug6e05wlRLINeLUNtTMrDIae4pDzkpqS8dY1Nym9VO95lTafRqL/AfiGQflntTT+wHNIuws75sHMBNO2rDoVv/CBoteaOWIgi4tLimH9gPlvjtgJQx7IO41uN56mgp7DWWZs5OiGEEKJ2aORaB0uthjxD8bPSNYCHk1qOTYhSK01Sbu1405zy2pWU36p2vuuazMEdekyGbq/AqU1q7/q5P9V/n9oEzg2hwzho9xTYyR9XYX6pOaksObKEb098S74hH61Gy2NNHmNC2wnUs61n7vCEEEKIWiPuSiYjl+0tMUEHeHtQkLFeuhDFMugh4UhBUr7r9km5Xwj4da31Sfmt5FOoqXQWEDhQ3ZJPQ8QyOPgNXI2BLdPhj/eg5aPQ6Rlo0N7c0YpaKM+Qx5qTa1h0eBGpBX+0uzboymvtXyPAOcDM0QkhhBC1y9GLqYxevp/kjBy8nW15prs/X+44Z7KInIeTDW8PCqJfS08zRiqqJJOkfCfE7r59Un5zT/k9lDSryaROem2Sex2O/gT7/qv+R3SDVzt1KHzLR8HS1nzxiVpBURR2XNjBxxEfE5MWA0BA3QBe7fAq3Rp0M29wQphJrW6bKoh8pkKUXviZZJ5dfYCMnHwCPR1ZOaYjbo426A0K+6JTSEzPxs1BHeIuPegCAH1+YVIee6OnPM30HGungqS8qyTllK1dkiS9NlIUuBChDoU/9jPoc9X9NnXVYfAdxkK9xmYNUdRMJ1JO8NH+j9ibsBcAFxsX/t323zzS5BEstDKwR9Re0jaVP/lMhSidDUcuMemHw+TqDdzXyIUlIzvgaGNp7rBEVXNzUh6zU120+rZJ+Y2e8la1Oim/VVnaJflWXBtpNODTUd36zoKDq9Xh8NfiYPfn6tb4QbV3vWnfKvsfl96gJzIxkqTMJFztXAl2C0ZXRWOt7ZIyk/js4GeEnQlDQcFKa8XTQU/zTKtnsLeyN3d4QgghRK20Ylc0MzdEoSgwoJUH84a1ldrnQiVJuVlJkl7b1amvLjIX8hKc2ar2rp/eAme3qZuTD3QYA+1Ggr2ruaM12hq7lTn75nA587Jxn7udO1M7TaW3X28zRiZulpWfxcpjK1l2dBlZ+VkA9G/Yn5fbv0wD+wZmjk4IIYSonRRF4aPfT/LFn2cBGNnFj7cHtZCh7LWZPh8SDpvOKc9NNz3HxqlwkbeG3cC9pSTlFUSGu4uiUs5BxHK1hz3rqrpPZwVBoWrvuk8ntTfeTLbGbmXS9kkomP7qagrWHJ3Xc54k6mZmUAz8eu5XFkQuIDEzEYDWrq2Z3GEybd3amjc4IaogaZvKn3ymQhQvX2/gjbX/sCbiAgCv9mnKiw8EoDHjdzthBpKUVzqZk14CabTLIC8Ljq1Ve9cvHijc794KOo6DVo+DdeUOVdYb9PT9qa9JD/qt6tvWZ3X/1dha2GKts8ZKZ4Wl1lIan3J2u+kGEQkRzI2YS9SVKAC86njxSvtX6Nuwr/wMhLgNaZvKn3ymQhSVlavnxW8j2XYiEa0G3h/aiic7+Zo7LFEZ9PkQfxhi/i4Yvr7nNkl5t5uS8haSlJejapWkL1y4kLlz5xIfH0+LFi1YsGAB3bt3v+35X3zxBZ9//jkxMTH4+vry5ptvMnLkyFK/njTad+liJEQshX9+hPyCUhzWjtB2hFp33bVphYegKArrzqxjevj0u3q+tc4aK60VVjorY/J+49+WWssi+6x0Vlhpi55r8u+C65XqOVqrGjNnvrjpBvVt6uNl78WRZLVyQB3LOoxvNZ6ngp7CWmdtrlCFqBakbSp/8pkKYepaZi5jV+wnMu4a1hZaPh8RTJ8gd3OHJUpi0KurpmdcBnt3df53ab9LFknKd0Nuhuk5NnVv6SmXpLwiVZuF43744QcmTpzIwoUL6dq1K19++SX9+/cnKioKX9+id/UWLVrEtGnT+O9//0vHjh3Zt28f48ePx9nZmUGDBpnhHdQiDYLVrc9/4NC3asKecg72LlY3//uh43hoNkCt0V5OUnNS2R2/m/CL4YRfCi+xB/1mOo0OvaI32ZejzyFHnwN55RZemVloLIzJ+50S+pJuDty4qWCts8ZSd9O/77C/PEYV3G66QXJ2MsnZyWjQ8HjTx5nQdgL1bOvd60cmhBBCiHt06VoWI5ft40xiBo42Fiwb3ZEODV3MHZYoSdR62DQF0i4V7nP0gn4fQNDgoufr8yH+UEFSvuv2SXnDm3rK3VqAVluR70LcJbP2pHfu3Jng4GAWLVpk3BcYGEhoaCizZ88ucn5ISAhdu3Zl7ty5xn0TJ04kIiKCnTt3luo15c56OTEY4NwfsH8pnNoEikHd7+AF7UdD+1Hg4FHmy+Yb8jmafJRdl3YRfjGco1eOYrhxbcBSa0me4c5Z9rK+y+jg3oE8Q54xOc/T3/TvYvbnGnLJ1eeq/9bf9O877DfZd+PfhhzjvpvjryrudlSBpdaSn8/8zPW867e9dn2b+mx9fGuNGTUgRGWQtqn8yWcqhOrU5XRGLt1HQlo2nk42rBzbiabuDuYOS5Qkaj2sGQncmqYVdLIMWwXN+hczfF2S8qqsWvSk5+bmcuDAAaZOnWqy/6GHHiI8PLzY5+Tk5GBjY2Oyz9bWln379pGXl4elZdGajjk5OeTk5Bgfp6WlFTlH3AWtFgJ6q9u1ODiwAg6shPRLsP19+OtDCBykLjTn17XEhebiM+LVpPxSOHsu7SE9z3R+TEDdAEK8Qujq1ZU2rm0Ysm4IiZmJRXpyQV08zt3OnWC3YDQajTHRdMB8jVG+If+2yb0xsTcUcxPgNvtv3GAo6eaA8dybbkDcrCJHFSRnJxOZGElHj47lf3EhhBBClFpETApjV+wnLTufADd7Vo3thFddW3OHJUpi0Ks96MV8zzXu+/kZ0FjArZ0mts6mw9clKa+2zJakJycno9frcXc3nQvj7u5OQkJCsc/p27cvX331FaGhoQQHB3PgwAGWLVtGXl4eycnJeHp6FnnO7NmzmTlzZoW8B1Ggri88OAN6TFHv/O3/Cs7vURedO7YWXJuryXrrJ8DGkaz8LCISIgi/FM6uS7uITo02uZyjlSNdvLrQ1asrXby64FHHtEd+aqepTNo+CQ0ak0T9xuruUzpNqVK9uBZaCyy0FthZ2pktBkVRymVUwYmUE+y4sOOOr5eUmVQJ70oIIYQQt7Ml6jIvfhtJTr6BYN+6LBvdkbp2VuYOS9xJbLjpEPfi5OcAOTcl5d0LkvIgScprCLPXSb91bqyiKLedLzt9+nQSEhK47777UBQFd3d3Ro8ezYcffohOV3xSNm3aNCZNmmR8nJaWho+PT/m9AVHIwhpaP65uCf+oyfqRNShJJzi9ZRrhe+awq743kfp0cm8asq7VaGldvzUhDdTe8hb1WpSYZPf26828nvOKrZM+pdMUKb9WjPIaVbA/YX+pknRXO9e7fg0hhBBC3Jvv98Xxxtp/MCjwYHM3Ph8RjK1V1enAECW4fKx05z34DnR9WZLyGspsSXr9+vXR6XRFes0TExOL9K7fYGtry7Jly/jyyy+5fPkynp6eLFmyBAcHB+rXr1/sc6ytrbG2lpWlK9u1uj7sbtmPXY427L6wg8T8guE4eSkAeCo6Qlzb0DXwSTp7d8XRqmzzBXv79aaXT69iS4CJihPsFoy7nXupphsIIYQQonIpisLnf5zh4y2nABjWwZv3h7bCQieJXJV2NRai1kFUmGnZ45J4d5AEvQYzW5JuZWVF+/bt2bJlC0OHDjXu37JlC0OGDCnxuZaWlnh7ewPw/fffM3DgQLTyS2pWeYY8/kn6x7jg27Erx0ySOBudDR0cG9E1PZWQ2Ej8c3PQxERDVLi6yFz7MeDUoEyvqdPqZN5zJdNpddVuuoEQQghRG+gNCjN/Ocaq3bEA/LtXY157qNk9VXQRFehqjJqYHwuDS5E3HdCAzhL0ubd5okZd5d0vpOJjFGZj1uHukyZN4umnn6ZDhw506dKFJUuWEBcXx/PPPw+oQ9UvXrzIqlWrADh16hT79u2jc+fOXL16lXnz5nH06FFWrlxpzrdRa13MuMiui+qCb3vj95KRZ7qiZBPnJnT16kqIVwjB7sGFtbLTLqmLzB1YARkJ8Ndc+Hueukplx2egUc8SF5oT5iXTDYQQQoiqJTtPz6Q1h9j4TwIaDbw9MIjRXf3NHZa4VUq02lt+LEwtl3aDRqvOLW8RCoGD1ZXa14wsOHjzyMWC78f95kg98xrOrEn6E088wZUrV3j33XeJj4+nZcuWbNy4ET8/PwDi4+OJi4sznq/X6/n44485efIklpaW9OrVi/DwcBo2bGimd1C7ZOZlEnE5wpiYx6TFmByva12XLp5dCGkQQohXCG52bsVfyNELek2D+1+DExvUMm4xf6v/PrEB6gWoyXqb4WBbt8Lflyg7mW4ghBBCVA1p2Xk8uyqCPedSsNJpmfdEGwa29jJ3WOKGlHNqUh4VppZMu0GjVRd7CwpVKyLZ3/S9OWiwWmat2Drpc4qvky5qFLPWSTcHqZtaeoqicPLqScIvhRN+MZzIxEiTGuU6jY42rm3U8mgNuhLoEnj3SVricTVZP/w95BaUYLOwVReh6/gMeLYp+hyDXl0BM+My2Lurw34kSRRCVEPSNpU/+UxFbZCYls2o5fs5Hp+GvbUFS55uT0hA8es0iUp05Wxhj3nCkcL9Gh34d1cT8+YDwf4OC+3Kd90apSztkiTpwkRKdooxKQ+/FM6V7CsmxxvYNzDWLO/k2QkHq3KuP56TDkfWqCvDJ0YV7vfuCB3HQ9AQsLRRS70Ve3fxA7m7KISodqRtKn/ymYqa7lxSBiOX7ePC1Szq21uzYkxHWjZwMndYtVfyGYhaC8fWweV/CvdrdOB/vzqUvflAqCM3UWorSdJLII22qTxDHocSD6k1yy/u4njKcZPjtha2dPToaEzM/Rz9KmcBEkWBuN1qsh61Hm704NvVA98ucOJXKLK6eEFcw1ZJoi6EqFakbSp/8pmKmuzw+WuMWbGflOu5NKxnx6qxnfGtZ2fusGqf5NOFQ9kvHy3cr9FBox6FPeZ16pkpQFGVlKVdMnuddFH5zqedZ9elXey6tIt98fvIzM80Od7MuZmxZnk7t3ZY6awqP0iNRh3S4xcC6ZchchUcWA5pF9V568VSAA1smgrNH5bhQEIIUQXl5+fzzjvv8M0335CQkICnpyejR4/mrbfeQqvVkpeXx1tvvcXGjRs5d+4cTk5O9O7dmzlz5uDlJfNshdhxKokXvj5AZq6eVg2cWD6mI/XtpdxwpUk6VTiUPfGmmuZaC3Xx46BQ9XuonYt54hM1giTptcD1vOvsi9+nlke7FM759PMmx52tneni1YWuDdSV2OvbVrFhOA7u0GMydHsFds6DP2eVcLKiJvKx4eqcHyGEEFXKBx98wOLFi1m5ciUtWrQgIiKCMWPG4OTkxMsvv0xmZiaRkZFMnz6dNm3acPXqVSZOnMjgwYOJiIgwd/hCmFXYwYu89r/D5BsUujepz6Kn2mNvLV/nK1ziicLEPOmmUadaC2jUSx3K3myAJOai3Mh/1TWQQTFwIuWEcQj7oaRD5BvyjcctNBa0cWujlkdrEEKgSyBaTTWoM6+zAJdGpTs35m+1lIW2GrwvIYSoRXbv3s2QIUN4+OGHAWjYsCHfffedMQF3cnJiy5YtJs/57LPP6NSpE3Fxcfj6+lZ6zEJUBf/96xyzNqoJ4uA2Xnz0eBusLOR7ToVJPF44lD3pROF+rSU07lXQYz4AbJ3NFKCoySRJryGSs5LZfWk3uy7tYvel3aRkp5gc93HwMVnwrY5lHTNFeo/s3Ut33o4PIHK1utBci1Dw7iQJuxBCVAHdunVj8eLFnDp1iqZNm3L48GF27tzJggULbvuc1NRUNBoNdevWve05OTk55OTkGB+npaWVY9RCmI/BoDBn0wmW/HUOgLFd/Xnr4UC02kpYI6g2URQ1Mb/RY558svCYzgoaP6Am5s36S4lgUeEkSa+m8vR5HEw8aBzCfiLlhMlxOws7Onl0Ms4t93WsIT0PfiHqKu5p8RRdOK6ApZ26YEf6Jdi7SN0cvAoS9qHqSvGSsAshhFlMmTKF1NRUmjdvjk6nQ6/XM2vWLIYPH17s+dnZ2UydOpURI0aUuNDO7NmzmTlzZkWFLYRZ5OkNvP7jEdYevAjAtP7Nefb+RpWziG9toChqNaEbPebJpwqP6ayg8YMFQ9n7g42snC8qj6zuXo3EpcWx8+JOwi+Fsy9hH1n5WSbHA10CjfPK27q2xVJnaaZIK1jUelgzsuDBzb++N63u3rQvnP1D/aN7ciPk3NSj4uCl/sFtMRQadJCEXQhhdtW5bSqr77//nsmTJzN37lxatGjBoUOHmDhxIvPmzWPUqFEm5+bl5fH4448TFxfH9u3bS/xsiutJ9/HxqRWfqaiZrufk88I3kfx1KgmdVsOHj7bm0fbe5g6r+lMUdSX2Y2EQtQ6unC48prOCgN4FPeb9JDEX5UpKsJWgOn0RysjNYG/CXmPN8gsZF0yO17OpR4hXCCENQuji2YV6trWovEOxddIbQL85Rcuv5WWrCXtUGJzYCLnpps8JClWTdknYhRBmUp3apnvl4+PD1KlT+fe//23c99577/H1119z4kThqLC8vDyGDRvGuXPn+OOPP6hXr2xtXG36TEXNcyUjh7Er9nP4Qiq2ljoWPhVMr2Zu5g6r+lIUSPincCh7ytnCYzprNTFvEQpN+4GN/L0QFUNKsFVTBsXA8SvH1fJoF3dxJOkI+cpNC75pLQh2C1bnljfoSlPnptVjwbeKEDRYLW8RGw4Zl9W56n4hxZdds7RRF/ZoPqAwYT+2Vu1hT7sIe75QN0dv9Q90UCh4d1DLwAkhhChXmZmZaG+5IarT6TAYDMbHNxL006dP8+eff5Y5QReiOjufksnIZfuITr6Os50ly0Z3pJ2vLE5WZooCCUcKh7KnnCs8ZmFTkJgPhSYPSWIuqhxJ0s0sKTNJXYX90i72XNrD1ZyrJsf9HP2MC7519OiInaWdmSKtgrS6spdZK5KwbytI2H+DtAuw+3N1c/IpnMPeoL0k7EIIUU4GDRrErFmz8PX1pUWLFhw8eJB58+YxduxYQK2j/thjjxEZGcmGDRvQ6/UkJCQA4OLigpWVlTnDF6JCRV1KY9TyfSSl59Cgri2rxnWisau9ucOqPhQF4g8VDmW/Gl14zMIGmvRRO2Oa9gVrBzMFKcSdyXD3e6A36IlMjCQpMwlXO1eC3YLRFdeTe5NcfS6RiZGEX1QT81NXT5kcr2NZh84enY1zy70dZO5RpcjLgjMFCfupTZCbUXjMyVftuW/xCDQIloRdCFHuatPQ7PT0dKZPn87atWtJTEzEy8uL4cOHM2PGDKysrIiJicHf37/Y5/7555/07NmzVK9Tmz5TUTPsPnuFZ1dFkJ6TT3MPB1aO7YS7o425w6r6FAUuHVR7y6PWwdWYwmMWtmpi3iIUmvQFa7nhIcxH5qSXoLwa7a2xW5mzbw6XMy8b97nbuTO101R6+/U27lMUhZi0GGPN8ojLESYLvmnQEFQvyDiEvbVrayy1NXTBt+oiLwvObC1YdO43yLteeMzJF1oU9LB7ScIuhCgfklCWP/lMRXXy2z/xvPz9IXL1Bjr5u/DfkR1wspXvg7elKHApsrDH/Fps4TFLO3UIe9AQtcfcqpqWHRY1jiTpJSiPRntr7FYmbZ+EcksJME3B6uKzus3C1sJWLY92MZxL1y+ZnOdq60oXry509epKF68uONvIPKMqKy8LTm9R786e3GSasNf1LVh0bih4tZOEXQhx1yShLH/ymYrqYvWeWGasO4qiQN8W7nzyZDtsLEsemVkrKQpcjISotQWJeVzhMUs7NSEPClV7ziUxF1WQJOkluNdGW2/Q0/enviY96HdiqbUk2D2Yrl7qEPamzk2lvmV1lJtZ0MNeMCQ+L7PwWF2/wkXnJGEXQpSRJJTlTz5TUdUpisL8Laf49I8zAIzo7Mt/hrREp5XvEEaKAhciCoeyp54vPGZZR03MW4RCQB+wknWbRNUmq7tXoMjEyFIl6O527vT2602IVwgd3DvIgm81gZWdOjc9aHBBwr6lIGHfrA6z2vWJutX1U3vXW4SCZ1tJ2IUQQghhIl9vYPq6o3y3T006J/ZuwssPNpFOHACDAS5GFA5lT7upBLFlHbV++Y0ec0tbc0UpRIWSJL2MkjKTSnXepPaTGNBoQAVHI8zGyk6d6xQ0RE3YT/+u3uU1JuwL1M25oZqwB4WCZxtJ2IUQ1daKFSsYNmwYdnZy01mIe5Gdp+f/vjvIlqjLaDXwn9CW/Kuzn7nDMi+DAS7sL+wxT7tYeMzKHpr1V79zBfSWxFzUCpKkl5GrnWu5nidqACs7tde8RSjkXlcT9mNhasJ+NQZ2zlc3Z/+C84aCR2tJ2IUQ1cq0adN46aWXePzxxxk3bhwhISHmDkmIaic1M49nVu1nf8xVrCy0fPpkO/q19DB3WOZhMMD5vQWJ+XpIv2kNJysHNTFvEQqNH1RL6ApRi0iSXkbBbsG427mTmJlYZOE4UBePc7dzJ9gt2AzRCbOzqlMw1H2omrCf2lzQw/67WqvzRsLu0qhw0TmPVpKwCyGqvAsXLvDrr7+yYsUKevXqhb+/P2PGjGHUqFF4eNTSJEOIMohPzWLUsn2cupyBg40FX43sQOdG9cwdVuUyGOD8HrUz4/h6SI8vPGbtWNBjHgqNH5DEXNRqsnDcXbixujtgkqjfWN19Xs95JmXYhCAno6CHfa36//nZhcdcGhUOiZeEXYhaqbotcpaYmMjXX3/NihUrOHHiBP369WPcuHEMGjQIrVZr7vCA6veZiprtTGI6I5fu41JqNu6O1qwc24nmHrXk99Kgh7g9hT3mGQmFx6ydoPkAdSh74wfAwtpsYQpR0WR19xJUZJ10DzsPpnSaIgm6KFlOBpzeXJCwb7klYW9cuOice0tJ2IWoJapjQrl3716WLVvGypUr8fT05Nq1a9StW5fly5fTs2dPc4dXLT9TUTMdiL3KuJX7uZaZRyPXOqwa2wlv5xq+toNBD7HhamJ+/BfIuGnRZWsnaP6w+l2nUU9JzEWtIUl6Ccqz0dYb9EQmRpKUmYSrnSvBbsHotFLXUpRBToZazu3YWrW8280Je72Awh529xaSsAtRg1WXhPLy5cusXr2a5cuXc+7cOUJDQxk3bhy9e/cmKyuLt956ix9//JHY2Fhzh1ptPlNRs207fpl/fxtJdp6Btj51WTa6Iy51rMwdVundSLYzLoO9O/iFwO2+6xr0ELurYCj7L3A9sfCYjRM0H6h+p2nUEyyq0WcgRDmRJL0E0miLKisnXZ3DfqOHXZ9TeKxek8JF59yCJGEXooapDm3ToEGD2Lx5M02bNuWZZ55h5MiRuLi4mJxz6dIlvL29MRgMZoqyUHX4TEXNtibiPNN+/ge9QaFXM1e++FcwdlbVaDmoqPWwaQqk3bSgm6MX9PtALUcLoM9XE/MbPebXb6qCZFMXAgsSc/8ekpiLWk/qpAtRHVk7QKvH1C0nHU5uUhu901vgymn4a6661W9auOicW6Ak7EKISuHm5saOHTvo0qXLbc/x9PQkOjq6EqMSoupRFIWF288yd/NJAB4N9mbOo62w1FWN9RpKJWo9rBkJty6SnBav7u8xRe1dP/4LZCYXHrd1VnvMW4SqibnOsjKjFqLGkJ50Iaq67LTCHvYzW0CfW3isftPC1eTdAs0XoxDinkjbVP7kMxXmYDAovLshihXhMQA836MxU/o1Q1Odbqgb9LCgpWkPeklsXW7qMb9fEnMhbkN60oWoSWwcofXj6padZjqHPfkU7PhA3eo3K1x0ThJ2IUQ5e+mllwgICOCll14y2f/5559z5swZFixYYJ7AhKgicvL1vLrmMBuOqGXFpg8MYlw3fzNHdRdiw0uXoDfpC/c9Dw27S2IuRDmrRuNuhBBqwj4Mhn8Hk8/A0CXQtD/orCD5JOyYAwvvgy86w/Y5kHjC3BELIWqIn376ia5duxbZHxISwo8//miGiISoOtKz8xi7Yj8bjsRjqdPwyZNtq2eCnpetdgaURuthatk0SdCFKHfSky5EdWXjBG2eULfsVDj5m7qi6tltkHQCts9WN9fAwh5212bmjloIUU1duXIFJyenIvsdHR1JTk4u5hlC1A6J6dmMWb6fY5fSqGOlY/HT7enexNXcYZVe7nV1/Zvj69XpdbkZpXuevXvFxiVELSZJuhA1gY0TtHlS3bKuqQl7VBic2QZJx2H7cdj+vroy/I2ybq5NzRy0EKI6CQgIYNOmTbz44osm+3/77TcaNWpkpqiEMK+Y5OuMXLaPuJRM6tWxYsWYTrTyLnozq8rJToPTvxcsULsV8rMKjzl4QU6qmrwXS6Ou8u4XUhmRClErSZIuRE1jWxfaDle3Gwn7sbVw9g9IjFK3P2eBW4vCsm71m5g5aCFEVTdp0iRefPFFkpKSeOCBBwDYtm0bH3/8scxHF7XSPxdSGbNiH8kZufi62LFqbCca1q9j7rBuL+tqwU38dep3gpsXonVuCIGDIWgIeAXDiQ0Fq7uD6QrvBQvg9Ztz+3rpQoh7Jqu7C1Fb3Gicj62Fs3+CIa/wmHvLwrJu9QPMFqIQtVV1aZsWLVrErFmzuHRJXVSqYcOGvPPOO4wcOfIOz6x81eUzFdXT36eTeH71Aa7n6gnydGTF2I64OdiYO6yirierCXfUOoj+Cwz5hcfqNVGT8qDB4NG6aEnXYuukN1AT9Bt10oUQpVaWdkmSdCFqo6yrcGKjmrCf+9O00XZvqfawB90hYTfo1RVgMy6r89L8QuSuuhB3qbq1TUlJSdja2mJvb2/uUG6run2movpYf/gSr645RJ5eIaRxPb58uj0ONlVo8bS0+MLEPHYXKIbCY24tChNz1+ZFE/NbSVsvRLmRJL0E0mgLcYvMFDi5UV10rkjC3qpwSHy9xoX7i7277gX9PpC760LcBWmbyp98pqIiLNsZzbsbogB4uLUn84a1wdqiCiSt1+Lg+C9qYn5+HyZD1D3bFiTmQ0zbciFEpar0JP3atWvUrVv3Xi9TKaTRFqIEmSlw4ld1IZlz200Tdo9WarJu5QC/vY7pHDUwzlMbtkoSdSHKqLq0TT/++CNr1qwhLi6O3Nxck2ORkZFmiqp41eUzFdWDoih8sOkki3ecBWB0SENmDAxCq71DT3RFunJWXZE9aj1cuuW/P+9OalIeOAic/cwTnxDCRFnapTIvHPfBBx/QsGFDnnjiCQCGDRvGTz/9hIeHBxs3bqRNmzZ3F7UQwvzsXCD4aXW7kbAfW6sm7An/qNttKYAGNk2F5g/LcDghaphPP/2UN998k1GjRrFu3TrGjBnD2bNn2b9/P//+97/NHZ4QFSZPb2DqT//wU+QFACb3bcaEno3R3GmoeEVIPFGYmF++qU3WaME3RL1JHjhIHd0mhKi2ytyT3qhRI77++mtCQkLYsmULw4YN44cffjDeWf/9998rKtZyIXfWhbgLmSnq/LaIZXDp4J3PH7UB/LtXfFxC1BDVoW1q3rw5b7/9NsOHD8fBwYHDhw/TqFEjZsyYQUpKCp9//rm5QzRRHT5TUfVl5ubz728i+fNkEjqthtmPtGJYB5/KC0BR4PJRdRh71HpIPll4TKMD//vVxLz5QLB3q7y4hBBlVqE96fHx8fj4qH+cNmzYwLBhw3jooYdo2LAhnTt3vruIhRBVm50LBI8ESzv4adydz//lJWjSF7w7qFtdvzsvTiOEqNLi4uIICVHrItva2pKeng7A008/zX333VflknQh7lXK9VzGrtjPofPXsLHU8sWIYB4MdK/4F1YUuBgJxwsS86vRhcd0VtCol5qYNxugts9CiBqnzEm6s7Mz58+fx8fHh02bNvHee+8B6lwdvV5f7gEKIaoQ+1J+OUk5B3sXwd6Cx3b1CxP2Bh2gQTDYOFVYmEKI8ufh4cGVK1fw8/PDz8+PPXv20KZNG6Kjo6lla9CKWuDC1UxGLtvHuaTrONlasmx0R9r7OVfcCxoMcGGf2mN+/BdIPV94zMIGAnqrc8yb9pX2U4haoMxJ+iOPPMKIESNo0qQJV65coX///gAcOnSIgACpryxEjeYXos5zS4un6MJxABp1uF2fd9VegAv71XnsmclwapO63TivflPw7gje7dXE3S0IdGX+kySEqCQPPPAAv/zyC8HBwYwbN45XXnmFH3/8kYiICB555BFzhydEuTmRkMaoZfu4nJaDl5MNq8Z1IsDNofxfSJ8PceEFifkGyEgoPGZZR03IgwZDQB+wrrrlDoUQ5a/Mc9Lz8vL45JNPOH/+PKNHj6Zdu3YALFiwAHt7e5555pkKCbS8yBw1Ie5R1HpYM7Lgwc1/Pm6zuntetpqoX4xQk/YLEXAttuh1Le3Aqx00aF/Q695RFr4RtUZ1aJsMBgMGgwELC/Vm2po1a9i5cycBAQE8//zzWFlZmTlCU9XhMxVVz95zV3hmVQTp2fk0dbdn5dhOeDrZlt8L6PMgeoeamJ/4FTKvFB6zdoJm/dU2tPEDYFmOryuEMDupk14CabSFKAfF1klvAP3mlK78WkZSQdIeof7/xUjISSt6noNXYU+7d0fwagtWdcrtbQhRVVT1tik/P59Zs2YxduxY47o0VV1V/0xF1bPpaAIvfX+Q3HwDHfycWTqqI052lvd+4bxsOPen2nae/BWyUwuP2bqoFVGChoB/D7CoWje7hBDlp0KT9JUrV1K/fn0efvhhAF5//XWWLFlCUFAQ3333HX5+VbsWozTaQpQTgx5iwyHjsjpX3S/k7suuGQyQfKowcb8QAYnHQDGYnqfRqcPivdurSXuDDuqwea323t+PEGZUHdome3t7jh49SsOGDc0dSqlUh89UVB3f7I1lethRDAr0DnTn8xHtsLG8h1KiudfhzFY1MT+1GXLTC4/VcYPAgWpi7tdNpnoJUUtUaJLerFkzFi1axAMPPMDu3bt58MEHWbBgARs2bMDCwoKff/65TMEuXLiQuXPnEh8fT4sWLViwYAHdu9++dNM333zDhx9+yOnTp3FycqJfv3589NFH1KtXr1SvJ422ENVE7nW4dOimYfIHIP1S0fOsHdVh8t4dCxems3et9HCFuBfVoW0KDQ0lNDSU0aNHmzuUUqkOn6kwP0VR+GTbaRZsPQ3A8E4+/GdISyx0d3HzNzsNTv+uDmU/vQXyswqPOTZQ65cHDQGfznd/U1sIUW1VaAm28+fPGxeICwsL47HHHuPZZ5+la9eu9OzZs0zX+uGHH5g4cSILFy6ka9eufPnll/Tv35+oqCh8fX2LnL9z505GjhzJ/PnzGTRoEBcvXuT555/nmWeeYe3atWV9K0KIqsyqDjTsqm43pF68aZj8AbVme06aOr8vekfheXX9ChN27w7g0RosbSr/PQhRg/Tv359p06Zx9OhR2rdvT506plNPBg8uxVQXIaoQvUFh+rqjfLs3DoCXHgjglT5N0ZSlZGjWVTj5m9pjfnYb6HMLj9X1U6eABQ5R11uRUV9CiFIqc0+6m5sbmzdvpl27drRr145XXnmFkSNHcvbsWdq0aUNGRkapr9W5c2eCg4NZtGiRcV9gYCChoaHMnj27yPkfffQRixYt4uzZs8Z9n332GR9++CHnz58vcn5x5M66EDWIPh8SowoS9wPq/yedpMjK81pL8Ghlmri7NJLa7aLKqA5tk7aEBEOj0VS5MqzV4TMV5pOdp2fi94fYdCwBjQbeHdyCp7s0LN2TryfDiQ1qYh69Awz5hcfqBai95YGDwbONtDNCCKMK7Unv06cPzzzzDO3atePUqVPGuenHjh0r0zy13NxcDhw4wNSpU032P/TQQ4SHhxf7nJCQEN588002btxI//79SUxM5McffzTGUJycnBxycnKMj9PSilmcSghRPekswLO1unUYq+7LTlUXort5fntmMlyKVDeWqOfZuhSsJH+jDFx7sK3AGrhCVHMGg+HOJwlRDaRm5TF+VQT7olOw0mlZ8GRbBrTyLPlJafEFifk6iN1lumaKW1BhYu4WKIm5EOKelTlJ/+KLL3jrrbc4f/48P/30k3Eu+IEDBxg+fHipr5OcnIxer8fd3d1kv7u7OwkJCcU+JyQkhG+++YYnnniC7Oxs8vPzGTx4MJ999tltX2f27NnMnDmz1HEJIao5Gydo3EvdABRFLfl24abV5OMPQ1YKnNmibjfUCyhYkK6gDJx7S9CVw8q+QgghqoTLadmMWraPEwnpOFhbsGRkB7o0vs26RtfOw/H1ao/5+b2YjNLybFOQmA+B+gGVErsQovYwWwm2S5cu0aBBA8LDw+nSpYtx/6xZs1i9ejUnTpwo8pyoqCh69+7NK6+8Qt++fYmPj2fy5Ml07NiRpUuXFvs6xfWk+/j4yPA3IWqz/Fy4/I9p4p5yruh5Fjbg2bZgmHxBr7uTt/SSiHJXHYZmv/vuuyUenzFjRiVFUjrV4TMVletsUgYjl+7j4rUsXB2sWTmmE0Fet/xuXDlbmJhfijQ95t2xIDEfBM4NKy1uIUTNUKHD3QGuXbvG0qVLOX78OBqNhsDAQMaNG4eTk1Opr1G/fn10Ol2RXvPExMQives3zJ49m65duzJ58mQAWrduTZ06dejevTvvvfcenp5FhypZW1tjbW1dhncnhKjxLKzUpLtBe+j8nLrv+hV1Mbqb67dnp8L5Pep2g717wbz2gqTdqx1YO5jnfQhRiW5doDUvL4/o6GgsLCxo3LhxlUvShbjZwbirjF2xn6uZefjXr8OqsZ3wcbFTDyadVIexR61Xb+AaadTyooGD1cTcqYFZYhdC1D5lTtIjIiLo27cvtra2dOrUCUVRmD9/Pu+//z6///47wcHBpbqOlZUV7du3Z8uWLQwdOtS4f8uWLQwZMqTY52RmZmJhYRqyTqeWsDDTgAAhRE1Rpx40fUjdQK3dnnK2oLd9v5q0Xz6m1oU/+au6AWi04NrcdFE61+ZSXkfUOAcPHiyyLy0tjdGjR5u040JUNX+eTGTC15Fk5elp4+3EslEdqHf9NPyxXk3Ok08WnqzRgX93NTFvPhAciu84EkKIilTm4e7du3cnICCA//73v8aEOT8/n2eeeYZz587x119/lfpaP/zwA08//TSLFy+mS5cuLFmyhP/+978cO3YMPz8/pk2bxsWLF1m1ahUAK1asYPz48Xz66afG4e4TJ05Eq9Wyd+/eUr2mDH8TQty1vCx1PvuF/YVl4FKLqSxhZV9Qu/2mxN3Bo/LjFdVGdW6bjh49ysCBA4mJiTF3KCaq82cqys9PBy7w+k9H0BsMjPK7ypv+p7A6+QtcjS48SWuprmMSOBiaPwx2LuYLWAhRY1XocPeIiAiTBB3AwsKC119/nQ4dOpTpWk888QRXrlzh3XffJT4+npYtW7Jx40b8/PwAiI+PJy4uznj+6NGjSU9P5/PPP+fVV1+lbt26PPDAA3zwwQdlfRtCCFF2lrbge5+63ZCeUDg8/kKEurJ8bgbE/K1uNzj5FC5I591RXXTI0rby34MQ5ezatWukpqaaOwwhTCiKwpIdZ/h98y9M0+3jEbtIXC5fhssFJ1jYQEBvNTFv2hds65ozXCGEMFHmnnR3d3dWr17NQw89ZLJ/8+bNjBw5ksuXL9/mmVWD3FkXQlQogx6STtw0TP4AJB6naO12C3BvUdDT3rGgdntjKKEWdZHXiQ1Xh9/bu6vzJmWIfbVVHdqmTz/91OSxoijEx8ezevVq7r//fr777jszRVa86vCZigqgz8cQs4sDm1bim7gNd821wmOWdaBJH3XxtyYPgbW92cIUQtQ+FdqT/sQTTzBu3Dg++ugjQkJC0Gg07Ny5k8mTJ5epBJsQQtRIWp2afLu3gPaj1H056XDpYMEw+YLF6TIuq0Pn4w9DREF1ChunwlXkbwyTL27YZdR62DQF0i4V7nP0gn4fQNDgin+PolaaP3++yWOtVourqyujRo1i2rRpZopK1HiluSGpz4PoHRC1HuXEr2gzk+kIoIFcnT1WLR5We8wDHpQRTEKIaqHMSfpHH32ERqNh5MiR5OfnA2BpackLL7zAnDlzyj1AIYSo9qwdwP9+dQO1dnvqhcKe9gsREH9IXU3+7B/qdoNLo8KEvUEHteb7j2Mp0jOfFg9rRsKwVZKoiwoRHR1955OEKE8l3ZBs8hCc+1M95+RGyL4GgAa4qtiz1dCBBl2fIKT3o2AhVX6EENXLXddJz8zM5OzZsyiKQkBAAJaWlsTHx+Pr61veMZYrGf4mhKiS9Hlw+WjhgnQX9sOVM2W8iEb9AjvxHxn6Xs1Uh7YpNTUVvV6Pi4vp6I6UlBQsLCyqXNzV4TMVJYhar954vPWG5A0WNpCfbXxosKvPZn1Hvk5vyz8WLfn0X53o2cytcmIVQohSqPA66QB2dna0atXK+Pjw4cMEBwej1+vv9pJCCFF76SzVFeG92gHj1X1ZVwsS9oKkPW63uijdbSmQdhFidxX22gtRTp588kkGDRrEhAkTTPavWbOG9evXs3HjRjNFJmqc/DzYOJnbJuigJuj2nhA0mMvefRm+SeFcag4udaxYPbojbXzqVla0QghR7u46SRdCCFHBbJ3V1YcDequPj/wPfn7mzs/74Wl17qVfV3VzbQYaTcXGKmq8vXv3Mm/evCL7e/bsyZtvvmmGiES1oyjqsPT0BEiPV/8/7dJNj+ML/60Y7ny9R5Zw1LoNo5fvJzkjB29nW1aN7UQjV1kQTghRvUmSLoQQ1UVpa61nX4OjP6kbgF09dbElv27q/7u3kOHwosxycnKMa9HcLC8vj6ysLDNEJKqU3EzTJLvYJDwB8svvd+XU2TM8uTOLjJx8Aj0dWTmmI26ONuV2fSGEMBdJ0oUQorrwC1HnnKfFU/wwUA04esKQRXB+jzrs/fx+yLwCx39RN1BXkfftUtjT7tkGdNIciJJ17NiRJUuW8Nlnn5nsX7x4Me3btzdTVKLC6fPUldXT4otJwm96nJ1a+mvaOoOD502bh7o5eqn/f+08/G/UHS/z7o4UMvLdua+RC0tGdsDRxvIe3qgQQlQdpf5WduTIkRKPnzx58p6DEUIIUQKtTl3VeM1I1DWMb07UC4az9/sAGvdUN4D8XLX8W+xOtYxR3B71y/SpTeoGYGUPPp0Kk/YGwbIasihi1qxZ9O7dm8OHD/Pggw8CsG3bNvbv38/vv/9u5uhEmRkMkJlsmmgXl4hfT6bEueE3s6yj3ii8OfF2KEi8jfs8wfIOvd2ebUu8IamgIV5xITy/GQNaeTBvWFtsLGV0kBCi5ij16u5arRaNRkNxp9/Yr9FoqvzCcbLaqxCi2iu2LFED6DfnzuXX9PmQcETtZY8NV7eC0kVGFjZqrXa/rmrvvXdHsLIr97chClWXtunQoUPMnTuXQ4cOYWtrS+vWrZk2bRpNmjQxd2hFVJfPtNwpinoj7nY93mkF/85IAEPR6QvF0loW3+Nt3Ffw2Nqh/Na/iFqPsmYkCgram3YbCr6GvpA3EbdOj/PO4BbotLLmhhCi6itLu1TqJD02NrZUL+7n51eq88yl1jbaQoiaxaBXE+yMy2DvribTdzPP3GCAxKiCpH0XxOxSe9duprVUe9dv9LT7dla/jItyI21T+Su3z7S8/lsrD3lZt+/xvnned15mKS+oAXu34nu8b07EbV1Aq73z5crRpqPxhH27mBmWq/DSpBj3X1LqMTPvaaxbDuGT4e3QyKKYQohqokKS9JpCvggJIUQJFAWSTxcOj4/ZBemXTM/R6MCzdWHS7tdFnWMq7lp1aJs2btyITqejb9++Jvs3b96MwWCgf//+ZoqseOXymRY7asVLnVZyp1ErZaHPg4zEkhdcS79UtnnfNnXVBNtk+Pkt88Dt3avkehR6g0K3D/4gPjUbLQY6aU/gxjUSqcs+Q3MMaPF0smHnlAekF10IUW1USp10IYQQNZBGA65N1a3DWDVpvxpT2Mseuwuuxarz3C8dhN2fAxp1xfgbw+P9uoK9q7nfiShnU6dOZc6cOUX2K4rC1KlTq1ySfs+i1hes/3BLX0ZavLp/2Ko7J+oGg7pw482JdnHlx64nFX2d27G0u/2Cazfvt7S9m3ddJeyLTiE+NRsAA1r2GIKKnBOfms2+6BS6NK5X2eEJIUSFkyRdCCHE7Wk04OKvbu2eUvelXijoZS/obb9yGi4fVbd9X6rn1G9a2NPesKuaRIhq7fTp0wQFFU2WmjdvzpkzZ8wQUQUy6NUe9GITZwXQwG+vQ70AuJ54y/DzG4l4wWbIK91rai1uv+Dazb3h1o7lN++7ikpMzy7X84QQorqRJF0IIUTZOHlD62HqBpB+GeIKhsbHhkPiMUg+pW4HlqvnODcsrNPesCvU9avxiUZN4+TkxLlz52jYsKHJ/jNnzlCnTh3zBFVRYsNNh7gXoahJ+aIupbiYBuq4lrzgmoMn2NWr9HnfVdW1zNxSnefmIDXRhRA1kyTpQggh7o2DO7QYqm4AmSkQt7tweHzCEXXI/NUYOPS1eo6jd2HC7tdV7ZGUpL1KGzx4MBMnTmTt2rU0btwYUBP0V199lcGDSz8/Oz8/n3feeYdvvvmGhIQEPD09GT16NG+99RbagiRVURRmzpzJkiVLuHr1Kp07d+aLL76gRYsWFfLeisi4XLrzLG2hbsPbL7jm4KkuzKaT+t2lkZ6dx4ebTrJ6T8mLFWsADycbOvm7VE5gQghRye4qSc/Pz2f79u2cPXuWESNG4ODgwKVLl3B0dMTe3r68YxRCCFGd2LlA84fVDdTFrs7vKxwefykS0i7AP2vUDaCOW0HSXtDb7hoovYpVzNy5c+nXrx/NmzfH29sbgAsXLtC9e3fmzp1b6ut88MEHLF68mJUrV9KiRQsiIiIYM2YMTk5OvPzyywB8+OGHzJs3jxUrVtC0aVPee+89+vTpw8mTJ3FwqITKAvbupTtvxP/Av3vFxlJL/H4sgRnrjpGQpg5h79KoHnvOXQFMJx3cuJX39qAgWTROCFFjlXl199jYWPr160dcXBw5OTmcOnWKRo0aMXHiRLKzs1m8eHFFxVouqsMKukIIUaPlXocL+wuHx1/YD/oc03NsncH3Rk97CHi0Nl/Zq0pQXdomRVHYsmULhw8fNtZJv//++8t0jYEDB+Lu7s7SpUuN+x599FHs7OxYvXo1iqLg5eXFxIkTmTJlCgA5OTm4u7vzwQcf8Nxzz5Xqde7pMzXoYUFLda55sfPSNWqP+cR/avTvZWVITMvm7fXH+O1oAgB+9ex4f2grugbUZ9PReGb+EmVcRA7A08mGtwcF0a+lp7lCFkKIu1Khq7u//PLLdOjQgcOHD1OvXuGKmkOHDuWZZ54pe7RCCCFqF6s60KinugHkZau96zeGx5/fC1lX4eSv6gbqYlk+nQuHx3u1kyHEZqDRaHjooYd46KGHADAYDPzyyy8sXbqUsLCwUl2jW7duLF68mFOnTtG0aVMOHz7Mzp07WbBgAQDR0dEkJCQYXwPA2tqaHj16EB4eftskPScnh5ycwps9aWlpd/cmQU28+31QsLq7hmL7cvvNkQT9HhgMCt/vP8/s346Tnp2PTqthfPdGTOzdBBtL9XPt19KTPkEe7ItOITE9GzcHdYi79KALIWq6MifpO3fuZNeuXVhZWZns9/Pz4+LFi+UWmBBCiFrC0qagdFsIMFmtGR1/uHB4fNxuyEmDM1vUDdQyVN4dC4fHN+igXkdUitOnT7Ns2TJWrlzJ1atXi9ROL8mUKVNITU2lefPm6HQ69Ho9s2bNYvjw4QAkJKg9qu7upkPO3d3diY29/Vzl2bNnM3PmzLt4N7cRNFgts1ZsnfQ55VsnvZY5m5TBtJ//YV90CgCtvZ2Y/UgrWng5FTlXp9VImTUhRK1T5iTdYDCg1+uL7L9w4ULlzBMTQghRs+kswbuDunWbqA49vny0sKc9NhyyUiB6h7oB6KzURP3G8HifzmqPvSg3WVlZrFmzhqVLl7Jnzx70ej3z589n7NixZVqP5ocffuDrr7/m22+/pUWLFhw6dIiJEyfi5eXFqFGjjOdpbllIUFGUIvtuNm3aNCZNmmR8nJaWho+PTxneYTGCBqtrK8SGq4vJ2burv1/Sg35XcvMNfLnjLJ/9eYbcfAO2ljpefagpY7r6S++4EELcpMxJep8+fViwYAFLliwB1EY0IyODt99+mwEDBpR7gEIIIWo5rQ4826hblwlgMEDyycKe9thdagIVF65uoNac9mxbODze9z6wKdpLJ+5s3759fPXVV/zwww80bdqUp556iv/97394e3vTu3fvMi8YO3nyZKZOncqTTz4JQKtWrYiNjWX27NmMGjUKDw8PAOPK7zckJiYW6V2/mbW1NdbW1nfxDu9Aq5PF4cpBZNxVpv30DycvpwPQo6kr74W2xMfFzsyRCSFE1VPmJH3+/Pn06tWLoKAgsrOzGTFiBKdPn6Z+/fp89913FRGjEEIIUUirBbdAdes0HhQFUs6ZJu2p5+FihLrt+gQ0WnBvWTg83jcE6sgQ2tIICQnh//7v/9i3bx/NmjW75+tlZmYaS63doNPpMBgMAPj7++Ph4cGWLVto164dALm5uezYsYMPPvjgnl9fVK6MnHzmbjrBqj2xKArUq2PFjEFBDG7jVeLICCGEqM3KnKR7eXlx6NAhvvvuOyIjIzEYDIwbN45//etf2NraVkSMQgghxO1pNFCvsbq1LxgufS3upuHxu9QkPuGIuu1ZqJ7jGlg4PN6vm1rvvbQM+lozBPqBBx5g6dKlJCYm8vTTT9O3b997Sq4GDRrErFmz8PX1pUWLFhw8eJB58+YxduxYQB2hN3HiRN5//32aNGlCkyZNeP/997Gzs2PEiBHl9bZEJdgadZnp644aV2d/NNibtx4OxLmO1R2eKYQQtVuZS7BVd9WlzI0QQohylBZfOJ89dhcknSh6Tr2AwoTdLwTq3mY+c9T62ywm9sFdLyZW1dum8+fPs3z5cpYvX05WVhZPPPEECxcu5MiRIwQGBpbpWunp6UyfPp21a9eSmJiIl5cXw4cPZ8aMGcZFaRVFYebMmXz55ZdcvXqVzp0788UXX9CyZctSv05V/0xrssT0bGauj+LXf+IB8HVRy6p1a1LfzJEJIYT5lKVdKnOSvn79+uIvpNFgY2NDQEAA/v7+ZblkpZJGWwghBNeTCxL2cIjdCQlHKVIP28m3cE67Xwi4NILjvxSU5bq16SzoWR626q4S9erUNm3ZsoVly5YRFhaGj48Pjz32GI899hjBwcHmDs1EdfpMawpFUfhh/3ne33ictIKyas9092fig02xtaqZI02EEKK0KjRJ12q1aDQabn3ajX0ajYZu3boRFhaGs7Nz2aOvYNJoCyGEKCLrGsTtURP22HC4dAiUWyqZ2HtAdirkZ93mIhq1R33iP2Ue+l4d26arV6/y9ddfs2zZMo4cOVJs5Rdzqo6faXV2rqCs2t6CsmqtGqhl1Vo2kAUbhRACytYuaUs8WowtW7bQsWNHtmzZQmpqKqmpqWzZsoVOnTqxYcMG/vrrL65cucJrr712129ACCGEqFS2daFZP3joPRj/B0yNhad+hu6vgm8XtcRbRkIJCTqAAmkX1SS/FnB2dub//u//OHjwIPv37zd3OMJMcvMNfP7Hafp98jd7o1OwtdTx1sOBrJ0QIgm6EELcpTIvHPfyyy+zZMkSQkJCjPsefPBBbGxsePbZZzl27BgLFiwwLgAjhBBCVDvWDhDwoLoB5GXBXx/D33Pv/NyMyxUbWxVU1Ya6i8pxMO4qU28qq3Z/U1dmSVk1IYS4Z2VO0s+ePVts97yjoyPnzp0DoEmTJiQnJ997dEIIIURVYGkLjXqULkm3L8Mq8UJUQxk5+Xy0+SQrd8egKOBSx4rpAwMJbdtAyqoJIUQ5KPNw9/bt2zN58mSSkpKM+5KSknj99dfp2LEjAKdPn8bb27v8ohRCCCHMzS9EnXPO7ZIQDTg2UM8ToobadvwyD83bwYpwNUF/pF0Dtk7qwdB23pKgCyFEOSlzT/rSpUsZMmQI3t7e+Pj4oNFoiIuLo1GjRqxbtw6AjIwMpk+fXu7BCiGEEGaj1all1taMRE3Ub15AtSA56TenxtZLF7VbUnoOM385xoYjalk1HxdbZoW24v6mrmaOTAghap4yJ+nNmjXj+PHjbN68mVOnTqEoCs2bN6dPnz5otWrHfGhoaHnHKYQQQphf0GC1zFqxddLn3HWd9OoiPz+f7du3c/bsWUaMGIGDgwOXLl3C0dERe3t7c4cnKoCiKPwv4gKzNh4nNSsPrQae6d6Iib2bYGdV5q+RQgghSqHMJdiqOynJIoQQ4p4Z9Ooq7hmX1TnofiH31INeHdqm2NhY+vXrR1xcHDk5OZw6dYpGjRoxceJEsrOzWbx4sblDNFEdPtOqLjr5Om/8/A+7z10BoIWXIx882lpWbRdCiLtQlnbprm6BXr9+nR07dhAXF0dubq7JsZdeeuluLimEEEJUH1od+Hc3dxSV6uWXX6ZDhw4cPnyYevXqGfcPHTqUZ555xoyRifKWpzew5K9zfLLtNLn5BmwstUzq05SxXf2x0JV5OSMhhBBlVOYk/eDBgwwYMIDMzEyuX7+Oi4sLycnJ2NnZ4ebmJkm6EEIIUQPt3LmTXbt2YWVlZbLfz8+PixcvmikqUd4Onb/G1J+OcCJBLavWvUl9ZoW2wreelFUTQojKUubboa+88gqDBg0iJSUFW1tb9uzZQ2xsLO3bt+ejjz6qiBiFEEIIYWYGgwG9Xl9k/4ULF3BwcDBDRKI8Xc/JZ+Yvxxi6cBcnEtJxtrNk3rA2rBrbSRJ0IYSoZGVO0g8dOsSrr76KTqdDp9ORk5ODj48PH374IW+88UZFxCiEEEIIM+vTpw8LFiwwPtZoNGRkZPD2228zYMAA8wUm7tmfJxJ5aP5fLN+lllUbWlBW7ZFgKasmhBDmUObh7paWlsY/2O7u7sTFxREYGIiTkxNxcXHlHqAQQgghzG/+/Pn06tWLoKAgsrOzGTFiBKdPn6Z+/fp899135g5P3IWk9Bze3RDFL4fVSgXezrbMGtqKHlJWTQghzKrMSXq7du2IiIigadOm9OrVixkzZpCcnMzq1atp1apVRcQohBBCCDPz8vLi0KFDfPfdd0RGRmIwGBg3bhz/+te/sLW1NXd4ogwUReF/By4w69fCsmrjuvnzSp+mUlZNCCGqgDKXYIuIiCA9PZ1evXqRlJTEqFGj2LlzJwEBASxfvpw2bdpUVKzlQkqyCCGEqGqkbSp/8pkWLyb5Om+s/Yfws4Vl1eY80ppW3lJWTQghKlKFlWBTFAVXV1datGgBgKurKxs3brz7SIUQQghRLaxfv77Y/RqNBhsbGwICAvD396/kqERp5ekN/Pfvc3yy9TQ5BWXVXundlHHdpKyaEEJUNWVO0ps0acKxY8do0qRJuQSwcOFC5s6dS3x8PC1atGDBggV071587dnRo0ezcuXKIvuDgoI4duxYucQjhBBCiKJCQ0PRaDTcOgDvxj6NRkO3bt0ICwvD2dnZTFGK4hw+f42pP//D8fg0ALoF1GfW0Jb41atj5siEEEIUp0y3TrVaLU2aNOHKlSvl8uI//PADEydO5M033+TgwYN0796d/v3733YBuk8++YT4+Hjjdv78eVxcXHj88cfLJR4hhBBCFG/Lli107NiRLVu2kJqaSmpqKlu2bKFTp05s2LCBv/76iytXrvDaa6+ZO1RR4HpOPu/+EsXQhbs4Hp9GXTtLPn68DavHdZIEXQghqrAyz0n/9ddfmTNnDosWLaJly5b39OKdO3cmODiYRYsWGfcFBgYSGhrK7Nmz7/j8sLAwHnnkEaKjo/Hz8yvVa8ocNSGEEFVNdWibWrZsyZIlSwgJCTHZv2vXLp599lmOHTvG1q1bGTt2bJWo9lIdPtOK9OfJRN5ae5SL17IACG3rxfSBQdSztzZzZEIIUTtV2Jx0gKeeeorMzEzatGmDlZVVkRVdU1JSSnWd3NxcDhw4wNSpU032P/TQQ4SHh5fqGkuXLqV3794lJug5OTnk5OQYH6elpZXq2kIIIYQodPbs2WK/VDg6OnLu3DkAmjRpQnJycmWHJm6SnJHDu79Esb6grFqDurbMGtqSns3czByZEEKI0ipzkr5gwYJyeeHk5GT0ej3u7u4m+93d3UlISLjj8+Pj4/ntt9/49ttvSzxv9uzZzJw5855iFUIIIWq79u3bM3nyZFatWoWrq1pHOykpiddff52OHTsCcPr0aby9vc0ZZq2lKAo/HrjArI3HuZapllUb29WfSQ9JWTUhhKhuyvxXe9SoUeUagEajMXl8Y/GZO1mxYgV169YlNDS0xPOmTZvGpEmTjI/T0tLw8fG5q1iFEEKI2mrp0qUMGTIEb29vfHx80Gg0xMXF0ahRI9atWwdARkYG06dPN3OktU/sFbWs2q4z6ppBQZ6OzHm0Fa2965o3MCGEEHflrm6tnj17luXLl3P27Fk++eQT3Nzc2LRpEz4+PsbybHdSv359dDpdkV7zxMTEIr3rt1IUhWXLlvH0009jZWVV4rnW1tZYW8v8KyGEEOJeNGvWjOPHj7N582ZOnTqFoig0b96cPn36oNWq69De6ca5KF95egNf/R3Ngq2nyMk3YG2h5ZU+alk1SymrJoQQ1VaZk/QdO3bQv39/unbtyl9//cWsWbNwc3PjyJEjfPXVV/z444+luo6VlRXt27dny5YtDB061Lh/y5YtDBky5I4xnDlzhnHjxpU1fCGEEELcJc3/t3fn4U3V6dvA7yTdt5Qu6UoXSllKKVKg2IKyg6Ao6ijSAUFGUYFRxAXQmUEdBWTeYXB0QIosA8gyv2ERHUWoLAJFylba0kJZSks3utGkC92S8/4RGohdSErak7T357pyaU9OTp4cwSdPv8sjkeCxxx7DY489JnYonV5KjhILdiYj7U5btSHd3bHk6b7ctZ2IqAMwukhfuHAhPvnkE8yfPx/Ozs664yNGjMDnn39u1LXmz5+PadOmYeDAgYiOjkZcXByys7Px2muvAdBOVc/NzcWmTZv0Xrdu3ToMHjz4gXeXJyIiIsNVVlbiyJEjyM7ORm1trd5zb7zxhkhRdS5VtfVYsT8D649nQiMArg7W+GBCb/xugL9BywWJiMj8GV2kp6SkNLlZm6enp9H90ydPnoySkhJ8/PHHyM/PR3h4OH744Qfdbu35+fmN2rgolUrs3LnT6F8IEBERUeudO3cOEyZMQFVVFSorK+Hm5obi4mI4ODhAoVCwSG8HRzKK8MHuFOTc0rZVe7KfL/4yMQwebKtGRNShGF2ku7q6Ij8/H8HBwXrHz507Bz8/P6MDmD17NmbPnt3kcxs3bmx0TC6Xo6qqyuj3ISIiotZ76623MHHiRKxevRqurq749ddfYW1tjalTp+LNN98UO7wOraSiBn/9Pg17ku62Vfvk6XCMYFs1IqIOyehdRWJjY7FgwQIUFBRAIpFAo9Hg+PHjeOedd/Diiy+2RYxEREQksqSkJLz99tuQyWSQyWSoqalB165dsXz5crz//vtih9chCYKAnWdyMHrFEexJytO1Vdv/1qMs0ImIOjCjR9I//fRTzJgxA35+fhAEAWFhYVCr1YiNjcWf/vSntoiRiIiIRGZtba1b8+zl5YXs7Gz07t0bcrm80dI0enDZJVX4YE8Kjl4uBgD08nbGZ89GoF9XV3EDIyKiNmd0kW5tbY1vvvkGH3/8Mc6dOweNRoP+/fsjNDS0LeIjIiIiM9C/f3+cPn0aPXr0wIgRI/CXv/wFxcXF2Lx5M/r27St2eB1GvVqDdccy8Y/4DFTXaduqvTk6FK880o1t1YiIOolWtWAbNmwYQkJCEBIS0hYxERERkZlZsmQJysvLAQB//etfMX36dLz++uvo3r07NmzYIHJ0HUNqrrat2oU8bVu1mBBtW7UgD7ZVIyLqTIwu0seMGQNvb2/ExsZi6tSpbINGRETUwQmCAE9PT/Tp0weAtqPLDz/8IHJUHUdVbT3+cSAD645p26rJ7a3xweO98RzbqhERdUpGz5vKy8vDe++9h6NHjyIiIgIRERFYvnw5cnJy2iI+IiIiEpkgCAgNDWWubwO/ZBRh3MpfsPaotkCf2M8X8fOH4fmBXVmgExF1UkYX6R4eHpg7dy6OHz+Oq1evYvLkydi0aROCgoIwcuTItoiRiIiIRCSVShEaGoqSkhKxQ+kwSitr8daOJLy4PhE3Sm/Dz9UeG2YMwhdT+sPTmX3PiYg6swfagSQ4OBgLFy7EsmXL0LdvXxw5csRUcREREZEZWb58Od59912kpqaKHYpFEwQBu87mYNTfD2P3uVxIJMBLQ4K0bdV6sa0aERG1Yk16g+PHj+Obb77Bf//7X1RXV+PJJ5/EkiVLTBkbERERmYmpU6eiqqoK/fr1g42NDezt7fWeLy0tFSkyy3GjtArv79Zvq7b0mb7oH9BF5MiIiMicGF2kv//++9i2bRvy8vIwevRorFy5EpMmTYKDg0NbxEdERERmYOXKlWKHYLHq1RqsP56JFQe0bdVsrKR4c1QoZj3KtmpERNSY0UX64cOH8c4772Dy5Mnw8PDQey4pKQkPPfSQqWIjIiIiMzF9+nSxQ7BIqblKLNyVjNRcbVu1h7u5YcnTfdHN00nkyIiIyFwZXaQnJCTo/axUKvHNN9/g66+/xvnz56FWq00WHBEREZmPq1evYsOGDbh69So+//xzKBQK7Nu3D127dtW1ZyOt27Vq/CNe21ZNrRHgYmeFDx7vzV3biYjovlo9x+rgwYOYOnUqfHx88MUXX2DChAk4ffq0KWMjIiIiM3HkyBH07dsXJ0+exK5du1BRUQEASE5OxuLFi0WOzrwcvVyEsSuPIO6Xa1BrBDwe4YP4t4dh8qAAFuhERHRfRo2k5+TkYOPGjVi/fj0qKyvx/PPPo66uDjt37kRYWFhbxUhEREQiW7hwIT755BPMnz8fzs7OuuMjRozA559/LmJk5qO0shaf/C8Nu87mAgB85Hb4ZFI4RvX2EjkyIiKyJAaPpE+YMAFhYWFIS0vDF198gby8PHzxxRdtGRsRERGZiZSUFDz99NONjnt6enb6/umCIGDPuVyMXnEEu85q26rNiAnCgfnDWKATEZHRDB5J379/P9544w28/vrrCA0NbcuYiIiIyMy4uroiPz8fwcHBesfPnTsHPz8/kaIS343SKnywJxW/ZBQBAHp6OWPps30RybZqRETUSgaPpB89ehTl5eUYOHAgBg8ejC+//BJFRUVtGRsRERGZidjYWCxYsAAFBQWQSCTQaDQ4fvw43nnnHbz44otih9dm1BoBJ66W4NukXJy4WgK1RgCgbav29dFrGPuPX/BLRhFsrKR4Z2wPfPfHoSzQiYjogUgEQRCMeUFVVRW2b9+O9evXIzExEWq1GitWrMDMmTP11qiZK5VKBblcDqVSCRcXF7HDISIisojcVFdXhxkzZmD79u0QBAFWVlZQq9WIjY3Fxo0bIZPJxA5Rjynu6b7UfHz0XRryldW6Yz5yO7w0JAjfnc9HSq4SADA42A1Ln2FbNSIiap4xecnoIv1ely5dwrp167B582aUlZVhzJgx2Lt3b2sv1y4s4YsQERF1LpaUm65evYpz585Bo9Ggf//+ZrsE7kHv6b7UfLy+5Sxa+pLkYmeF9ydo26pJpdy1nYiImmdMXmp1CzYA6NmzJ5YvX46cnBxs27btQS5FREREZuzIkSMAgJCQEPzud7/D888/b7YF+oNSawR89F1aiwW6nbUUP731KF6ICmCBTkREJvVARXoDmUyGSZMmmf0oOhEREbXOmDFjEBAQgIULFyI1NVXscNpUYmap3hT3plTXaXC9uKqdIiIios7EJEU6ERERdWx5eXl47733cPToUURERCAiIkI3m66jKSxvuUA39jwiIiJjsEgnIiKi+/Lw8MDcuXNx/PhxXL16FZMnT8amTZsQFBSEkSNHih2eSSmc7Ux6HhERkTFYpBMREZFRgoODsXDhQixbtgx9+/bVrVfvKKKC3eAjt0NzK80l0O7yHhXs1p5hERFRJ8EinYiIiAx2/PhxzJ49Gz4+PoiNjUWfPn3w/fffix2WScmkEiyeGAYAjQr1hp8XTwyDjBvGERFRG2CRTkRERPf1/vvvIzg4GCNHjkRWVhZWrlyJgoICbNmyBePHjxc7PJN7LNwHq6dGwluuP6XdW26H1VMj8Vi4j0iRERFRR2cldgBERERk/g4fPox33nkHkydPhoeHh95zSUlJeOihh8QJrA09Fu6DMWHeSMwsRWF5NRTO2inuHEEnIqK2xJF0IiIiuq+EhATMmTNHV6ArlUqsWrUKkZGRGDBggMHXCQoKgkQiafSYM2cOAKCiogJz586Fv78/7O3t0bt3b6xevbpNPpMhZFIJokPc8dRDfogOcWeBTkREbY4j6URERGSwgwcPYv369di1axcCAwPx7LPPYt26dQa//tSpU1Cr1bqfU1NTMWbMGDz33HMAgLfeeguHDh3Cli1bEBQUhP3792P27Nnw9fXFU089ZfLPQ0REZG5YpBMREVGLcnJysHHjRqxfvx6VlZV4/vnnUVdXh507dyIsLMyoa3l6eur9vGzZMoSEhGDYsGEAgBMnTmD69OkYPnw4AGDWrFlYs2YNTp8+zSKdiIg6BU53JyIiomZNmDABYWFhSEtLwxdffIG8vDx88cUXJrl2bW0ttmzZgpkzZ0Ii0U4jHzp0KPbu3Yvc3FwIgoBDhw4hIyMD48aNa/FaNTU1UKlUeg8iIiJLxJF0IiIiatb+/fvxxhtv4PXXX0doaKhJr71nzx6UlZVhxowZumP//Oc/8corr8Df3x9WVlaQSqX4+uuvMXTo0BavtXTpUnz00UcmjY+IiEgMHEknIiKiZh09ehTl5eUYOHAgBg8ejC+//BJFRUUmufa6deswfvx4+Pr66o7985//xK+//oq9e/fizJkz+Pvf/47Zs2cjPj6+xWstWrQISqVS97hx44ZJYiQiImpvEkEQBLGDaE8qlQpyuRxKpRIuLi5ih0NERGQRuamqqgrbt2/H+vXrkZiYCLVajRUrVmDmzJlwdnY2+npZWVno1q0bdu3apVtrfvv2bcjlcuzevRuPP/647tyXX34ZOTk52Ldvn8HXt4R7SkREnYcxeYkj6URERHRfDg4OmDlzJo4dO4aUlBS8/fbbWLZsGRQKBZ588kmjr7dhwwYoFAq9Yryurg51dXWQSvW/nshkMmg0mgf+DERERJaARToREREZpWfPnli+fDlycnKwbds2o1+v0WiwYcMGTJ8+HVZWd7fHcXFxwbBhw/Duu+/i8OHDyMzMxMaNG7Fp0yY8/fTTpvwIREREZovT3YmIiETW2XLT/v37MW7cOFy6dAk9evTQe66goACLFi3C/v37UVpaisDAQMyaNQtvvfWWbgd4Q3S2e0pERObNmLzE3d2JiIioXY0dOxbNjRF4e3tjw4YN7RwRERGR+eB0dyIiIiIiIiIzwSKdiIiIiIiIyEywSCciIiIiIiIyEyzSiYiIiIiIiMyE6EX6qlWrEBwcDDs7OwwYMABHjx5t8fyamhp88MEHCAwMhK2tLUJCQrB+/fp2ipaIiIiIiIio7Yi6u/uOHTswb948rFq1CkOGDMGaNWswfvx4pKWlISAgoMnXPP/887h58ybWrVuH7t27o7CwEPX19e0cOREREREREZHpidonffDgwYiMjMTq1at1x3r37o1JkyZh6dKljc7ft28fXnjhBVy7dg1ubm6tek/2TSUiInPD3GR6vKdERGROjMlLok13r62txZkzZzB27Fi942PHjkVCQkKTr9m7dy8GDhyI5cuXw8/PDz169MA777yD27dvN/s+NTU1UKlUeg8iIiIiIiIicyTadPfi4mKo1Wp4eXnpHffy8kJBQUGTr7l27RqOHTsGOzs77N69G8XFxZg9ezZKS0ubXZe+dOlSfPTRRyaPn4iIiIiIiMjURN84TiKR6P0sCEKjYw00Gg0kEgm++eYbREVFYcKECVixYgU2btzY7Gj6okWLoFQqdY8bN26YLHa1RsCJqyX4NikXJ66WQK0RbeUAERERERERdQCijaR7eHhAJpM1GjUvLCxsNLrewMfHB35+fpDL5bpjvXv3hiAIyMnJQWhoaKPX2NrawtbW1rTBA9iXmo+PvktDvrL6bnxyOyyeGIbHwn1M/n5ERERERETU8Yk2km5jY4MBAwbgwIEDescPHDiAmJiYJl8zZMgQ5OXloaKiQncsIyMDUqkU/v7+bRrvvfal5uP1LWf1CnQAKFBW4/UtZ7EvNb/dYiEiIiIiIqKOQ9Tp7vPnz8fXX3+N9evXIz09HW+99Rays7Px2muvAdBOVX/xxRd158fGxsLd3R0vvfQS0tLS8Msvv+Ddd9/FzJkzYW9v3y4xqzUCPvouDU1NbG849tF3aZz6TkREREREREYTtU/65MmTUVJSgo8//hj5+fkIDw/HDz/8gMDAQABAfn4+srOzdec7OTnhwIED+OMf/4iBAwfC3d0dzz//PD755JN2izkxs7TRCPq9BAD5ymokZpYiOsS93eIiIiIiIiIiyydqkQ4As2fPxuzZs5t8buPGjY2O9erVq9EU+fZUWN58gX6vwxmF6B/gCjtrWRtHRERERERERB2F6EW6pVE42xl03poj17ApIQtDuntgVG8FRvRUwFtu2GuJiIiIiIioc2KRbqSoYDf4yO1QoKxucl06ADjYyOBiZ4UCVQ3i028iPv0mAKCPrwtG9VJgZG8vRPjJIZU23WqOiIiIiIiIOicW6UaSSSVYPDEMr285CwmgV6g3lNwrnu+HcX28kZ5fjoMXb+LgxUKcu1GGC3kqXMhT4Z8Hr8DDyQYjeiowspcCQ0M94GxnLcKnISIiIiIiInMiEQShU21DrlKpIJfLoVQq4eLi0urrGNsnvaSiBocvFeHgxUL8klGE8pp63XPWMgkGB7tjZC8FRvVWINDdsdVxERGR5TFVbqK7eE+JiMicGJOXWKQ/ALVGQGJmKQrLq6FwtkNUsBtkBkxhr63X4PT1Uvx8sRCHLhbiWnGl3vMhno4Y2UuBkb28MDCoC6xlonbKIyKiNsaC0vR4T4mIyJywSG+BOSbta0UVOHixEAcvFiIxsxT19/RYd7azwrAenhjVW4FhPRRwc7QRMVIiImoL5pibLB3vKRERmRNj8hLXpJuBbp5O6ObphJcf6QZVdR2OZhTj4MVCHLpUiNLKWnyfnI/vk/MhlQCRAV0w4s60+J5ezpBIuPkcERERERFRR8GRdDOm1gg4n1OGg+mF+PliIdLzVXrP+7naa6fF91Ygups7e7ITEVkoS8pNloL3lIiIzAmnu7fAkpN2Xtlt7Qj7xUIcu1KMmnqN7jk7aymGdvfAyF5eGNmLPdmJiCyJJecmc8V7SkRE5oTT3TsoX1d7TH04EFMfDsTtWjVOXCvGz+natez5ymrEpxciPr0QAHuyExERERERWSIW6RbK3kZ2Z9TcC4Ig3Lcn+/CeCoxiT3YiIiIiIiKzxunuHZChPdlH9lIgyIM92YmIxNYZclN74z0lIiJzwjXpLehsSft+Pdm7eTpqp8WzJzsRkWg6W25qD7ynRERkTlikt6CzJ232ZCciMj+dPTe1Bd5TIiIyJ9w4jpplTE/2/gFdMJI92YmIiIiIiNoNR9IJgGE92Uf08sSoXl6IDmFPdiIiU2JuMj3eUyIiMiec7t4CJm3DsCc7EVH7YW4yPd5Togen1qhxtvAsiqqK4OngiUhFJGRSDtQQtQanu9MDM7Yne8Nu8f38XdmTnYiIiMjCxWfFY1niMtysuqk75uXghYVRCzE6cLSIkRF1fBxJJ6M01ZP93j9B7MlORGQ85ibT4z0lar34rHjMPzwfAvTLBAm0AzErhq9goU5kJE53bwGTtmndryd7VLAbRvbywij2ZCciahZzk+nxnhK1jlqjxrid4/RG0O8lgQReDl7Y9+w+Tn0nMgKnu1O7cXeyxbMD/PHsAP8me7Ifv1KC41dK8Nfv09iTnYiIiMhM1Wvqka3Kxo+ZPzZboAOAAAEFVQU4W3gWg7wHtWOERJ0Hi3QyGRsrKWK6eyCmuwf+/ERYo57s14oqca0oE2uPZsLZzgqP9vDEqF4KDO/JnuxERERE7aXkdgkybmXg8q3LyLiVgYxbGbhadhW1mlqDr1FUVdSGERJ1bizSqc3cryf7/5Lz8b/kfEgkQOSdnuwjeynQy5s92YmIiIgeVK26FteU17SFeGmGriAvqS5p8nx7K3v4OPrgmvLafa/9Q+YP6KfoBz8nP1OHTdTpcU06tbv79WT3ldthZG/FfXuyqzUCEjNLUVheDYWzHaKC3SDjzvJEZIGYm0yP95Q6E0EQcLPqpq4IzyjNwOWyy8hUZkItqBudL4EEAS4B6NGlB0K7hKJHlx7o4doDfs5+EAQB43aOQ2FVYaON437LSmKFJ0KewMt9X0agS2BbfTyiDoEbx7WASdv85JXdxqFLhTiYbnhP9n2p+fjouzTkK6t15/rI7bB4YhgeC/dp989ARPQgmJtMj/eUOqqquipcLrusN1U941YGymvLmzzfxcYFPd16agtyV21BHuIaAgdrh2bfo2F3dwB6hXrD7u6zH5qNszfP4kT+CQCAVCLFY0GPYVbELIS4hpjqoxJ1KCzSW8Ckbd6a6sl+rzAfFwS6O+DH1IJGr20YQ189NZKFOhFZFOYm0+M9JUunETTIKc/RK8QzbmXgRvmNJs+3klghSB6kHRW/56FwULRqGWFTfdK9HbyxIGqBrv3a+aLzWJu8FkdyjgDQFvGjA0djVsQs9HLr1YpPTdRxsUhvAZO25RAEARcLynHwYiF+Tr/ZqCd7UyQAvOV2OLZgJKe+E5HFYG4yPd5TsiTKGqWuCG8YIb9SdgW36283eb6nvaeuCG+Yrt5N3g3WMmuTxqXWqHG28CyKqorg6eCJSEVkk23X0kvSEZcch/jseN2x4f7DMStiFvp69jVpTESWikV6C5i0LVdJRQ2+PpqJ1Ueu3vfcba88jOgQ93aIiojowTE3mR7vKZmjOk0driuvN9pZvbmWZ7YyW3R37a5XjId2CYWbnVs7R26Yy7cuY23KWvx0/SdoBO3yxRjfGLwa8SoivSJFjo5IXOyTTh2Su5Mtevk4G3Tu0ctFGBzsBilH04mIiKidCYKAkuoSvR3VM25l4KryKuo19U2+xs/J7+4mbnceAc4BTY5cm6vQLqFY/uhyzO43G2tT1uJ/1/6HhLwEJOQlYJD3ILwa8SqivKPYxYfoPjiSThblxNUSTFn7q0HnBrg5YEpUAH43wB+ezrZtHBkRUesxN5ke7ym1l+r6alxVXtUV5A0j5LdqbjV5vqO1Y6N1491du8PJxqmdI297N8pvYH3qeuy5skf3y4l+nv3wasSrGOo3lMU6dSqc7t4CJm3LptYIGPrZQRQoq5ttCuJgI4MUQEWttuWItUyCsWHeiB0cgOhu7hxdJyKzw9xkerynZGqCICCvMu9uMV6mLcazVFm6qd33kkqkCHQJvLt23DUUPdx6wNfRt9MVpwWVBVifuh47M3aiVlMLAAhzD8OsiFkY0XUEpBKpyBEStT0W6S1g0rZ8+1Lz8fqWswCgV6jfu7v7oz088f35fHyTmI3zN8p05wS53x1dd3fi6DoRmQfmJtPjPaUHUVFbgStlV/Smql++dRkVdRVNnt/Ftot+z3G3HgiRh8DOyq6dIzdvRVVF+PeFf+M/Gf/RbYoX2iUUsyJmYUzAGIua2k9kLBbpLWDS7hiM6ZN+IU+JrSez8W1SHipqtFOtbGRSjAv3RmxUAB7u5tbpfqNNROaFucn0eE/JEGqNGtnl2Y2K8dyK3CbPt5JaIUQeoj9d3a0H3O3c+V3CCKXVpdicthnbLm5DZV0lACBYHoxX+r6C8cHjYSXltlnU8bBIbwGTdseh1ghIzCxFYXk1FM52iAp2a7HtWmVNPb47n4etidlIzlHqjnfzcMSUqAA8O8Afbo427RE6EZEe5ibT4z3tGAxtAWaIW9W3GhXjV8quoEZd0+T5Xg5ejdqcBcmDYC01bZuzzkxZo8TW9K3YnL4Z5bXlAICuzl3xct+XMbHbRJO3lCMSE4v0FjBpEwCk5irxzcls7E3KReWdtes2MinG99WOrkcFc3SdiNoPc5Pp8Z5avviseCxLXKbXnszLwQsLoxZidODoZl9Xp67DNeW1Rm3Oim4XNXm+vZV9ozZnPbr0gNxWbvLPRE2rqK3A9kvbsenCJt2Gez6OPpgZPhNPhz4NWxmXKJLlY5HeAiZtuldFTT2+TcrF1pPZuJCn0h3vrnDSjq5H+sHVgaPrRNS2mJtMj/fUssVnxWP+4fkQfrNNrOTODjQrhq/AqIBRKKwq1Bsdz7iVgevK66gXmm5z1tW5a6Od1f2d/blxmZmoqqvC/2X8HzZe2Iji28UAAE97T8zoMwPP9XwO9lb2IkdI1Hos0lvApE1NEQQBKbnatet7z+ehqmF03UqKJ/r6YMrgAAwM7MLRdSJqE8xNpsd7arnUGjXG7RynN4L+WzZSG9hZ2UFVq2ryeWcb50ZT1UNdQ+Fg7dBWYZMJ1ahrsOvyLqxPXY+CygIAgJudG14MexEv9HoBjtaOIkdIZDwW6S1g0qb7Ka+uw56kPGw9mY30/LvJv4eXdnT9mf7+kDtwjRQRmQ5zk+nxnloeQRBws+omfrr+E/7f6f9n0GtkEhmCXIJ0G7g1FOZeDl78xXoHUKeuw7dXv8XXKV/rNvNzsXHB1LCp+H3v38PFhn+3yXKwSG8BkzYZShAEJN0ow7ZE7eh6dZ22B6qtlRRPRPgidnAAIgNc+SWAiB5YZ8pNQUFByMrKanR89uzZ+Ne//gUASE9Px4IFC3DkyBFoNBr06dMH//nPfxAQEGDw+3Sme2ppKmorkKXKQqYqE1mqLFxXXtf+U3Vd15bLEG9GvolpYdO4XrkTqNfU44fMH7A2eS2uq64DAJysnTCl1xRMC5uGLnZdxA2QyAAs0lvApE2toaquw55z2rXrFwvKdcd7eTsjdnAAJvX3g4sdR9eJqHU6U24qKiqCWq3W/ZyamooxY8bg0KFDGD58OK5evYqoqCj84Q9/wJQpUyCXy5Geno5BgwZBoVAY/D6d6Z6aozpNHXLLc3FddR3Xlde1/1Rpi/GGtcZNkUlk8LD3aHGqe4P149ZjkPcgU4ZNZk6tUeNA1gGsSV6DK2VXAGg3/pvcczKm95kOD3sPkSMkah6L9BYwadODEAQBZ7PLsPVkNr5PzkNNvXZ03c5aiol3Rtcf6srRdSIyTmfOTfPmzcP333+Py5cvQyKR4IUXXoC1tTU2b978QNftzPe0vQiCgOLbxXcLcGWWrhDPKc9pdvM2APCw90CgSyCCXIK0D7n2n37OfpBCinE7x6GwqrDRxnGAdvM4Lwcv7Ht2X6vbsZFl0wgaHMo+hDXJa5Bemg4AsJXZ4tnQZ/FS+EvwdvQWOUKixiyqSF+1ahX+9re/IT8/H3369MHKlSvxyCOPNHnu4cOHMWLEiEbH09PT0atXL4Pej0mbTEVZVYdd53Kw9WQ2LhdW6I739nHRjq4/5Atnjq4TkQE6a26qra2Fr68v5s+fj/fffx8ajQZyuRzvvfcejh07hnPnziE4OBiLFi3CpEmTWrxWTU0Namru9rtWqVTo2rVrp7unbaGqrko3Hb1hZDxLlYUsVRYq6iqafZ29lf3dQlwehECXQAS7BCPAJQDONs4tvmfD7u4A9Ar1e3d3b6kNG3UOgiDgaO5RrEleg+SiZACAtdQak7pPwszwmfB39hc5QqK7LKZI37FjB6ZNm4ZVq1ZhyJAhWLNmDb7++mukpaU1ue6soUi/dOmS3gfz9PSETGbYb1I76xchajuCIOBM1i3t6HpKPmrvjK472MjwZD/t6HqEv6u4QRKRWeusuek///kPYmNjkZ2dDV9fXxQUFMDHxwcODg745JNPMGLECOzbtw/vv/8+Dh06hGHDhjV7rQ8//BAfffRRo+Od7Z62Vr2mHvkV+chUZeqtEb+uuo7CqsJmXyeVSOHn5NdoVDzQJfCBN29rqk+6t4M3FkQtYIFOegRBwMmCk1hzfg1O3zwNQLt04oluT+CViFcQ6BIocoREFlSkDx48GJGRkVi9erXuWO/evTFp0iQsXbq00fkNRfqtW7fg6uraqvfsrF+EqH2UVdVi59lcbD2ZhatFlbrj4X4umBIVgKce8oOTrZWIERKROeqsuWncuHGwsbHBd999BwDIy8uDn58fpkyZgq1bt+rOe/LJJ+Ho6Iht27Y1ey2OpN+fIAgorS5tclQ8uzwb9Zrmp6e72bnpCvFAl0AEyYMQ7BIMf2d/2Mhs2ixmtUaNs4VnUVRVBE8HT0QqIjnFnVp05uYZrDm/BifyTwDQ/iLpsaDH8ErfV9C9S3eRo6POzJhcL1q1UFtbizNnzmDhwoV6x8eOHYuEhIQWX9u/f39UV1cjLCwMf/rTn5qcAt+gqaRN1FZcHWzwh6HBmDkkCImZpdiamI0fUwqQmqvCB7tTseR/6XjyIT/8fnAAwv3kYodLRCSarKwsxMfHY9euXbpjHh4esLKyQlhYmN65vXv3xrFjx1q8nq2tLWxtucs3ANyuv41sVbZufXhDIZ6pykR5bXmzr7OV2SLAJaDROvFAl0DIbcXJWTKpjJvDkVEGeA1A3Ng4JBclIy45DkdyjuCHzB/wQ+YPGBM4BrMiZqGXm2HLZInEIlqRXlxcDLVaDS8vL73jXl5eKCgoaPI1Pj4+iIuLw4ABA1BTU4PNmzdj1KhROHz4MB599NEmX7N06dImp78RtSWJRILB3dwxuJs7Fk+sxa6z2rXr14orsS0xG9sSsxHhL0dsVAAm9vOFI0fXiaiT2bBhAxQKBR5//HHdMRsbGwwaNAiXLl3SOzcjIwOBgZyuei+1Ro2CqoK7O6cr7+6enl+Z3+zrJJDA18m30ah4kEsQvB29IZVI2/FTELWdCM8IfDnqS6SXpCMuOQ7x2fE4kHUAB7IOYLj/cMyKmIW+nn3FDpOoSaJNd2+Y0paQkIDo6Gjd8U8//RSbN2/GxYsXDbrOxIkTIZFIsHfv3iaf5/Q3MheCIODXa9rR9X2p+ahTa//qOdlaYVJ/X0yJCkAfX46uE3VGnW26u0ajQXBwMKZMmYJly5bpPbd7925MnjwZ//rXv3Rr0ufNm4fDhw9j6NChBr9HR7mnZdVleu3LGorxbFU2ajW1zb7OxcZFV3zfu048wDkAdlZ27fgJiMzDlVtXEJcSh5+u/wSNoN0/KMY3Bq9GvIpIr0iRo6POwCKmu3t4eEAmkzUaNS8sLGw0ut6Shx9+GFu2bGn2eU5/I3MhkUgQHeKO6BB3lFSE4b9ncrAtMRvXS6qw5ddsbPk1G/26uuL3UQF4op8PHGw4uk5EHVN8fDyys7Mxc+bMRs89/fTT+Oqrr7B06VK88cYb6NmzJ3bu3GlUgW5patQ1uKG60Wid+HXVdZTVlDX7OmupNQKcA/SmpQfLgxHoEogudl3a7wMQWYDuXbpj+aPLMbvfbHyd8jW+v/Y9EvISkJCXgIFeA/Fqv1cx2Hsw2+iSWRB947gBAwZg1apVumNhYWF46qmnmtw4rim/+93vUFpaioMHDxp0fkf5zTp1DBqNgBPXSrD1ZDZ+ulCAeo32r6OzrRWejvRD7OAA9PLmn1Oijo65yfRMdU9NtXGZRtCgsKoQmcrMuxu33RkVz6vIa7IfeANvR+8md0/3dfTlJmpErZRTnoN1qeuw58oe3aaJ/Tz7YVbELDzi9wiLdTI5i9ndvaEF21dffYXo6GjExcVh7dq1uHDhAgIDA7Fo0SLk5uZi06ZNAICVK1ciKCgIffr0QW1tLbZs2YJly5Zh586deOaZZwx6T34RInNVVF6jG13PLq3SHY8McEXs4EA83tcH9jb8MkbUETE3mZ4p7mlTLcC8HLywMGphsy3AVLUqZCmb7ilera5u9r2crJ30CvCG0fEA5wA4WDu0Kn4iur+CygJsSN2AnZd3okatXSIb5h6GWRGzMKLrCO7TQCZjMUU6AKxatQrLly9Hfn4+wsPD8Y9//EO3CdyMGTNw/fp1HD58GACwfPlyxMXFITc3F/b29ujTpw8WLVqECRMmGPx+/CJE5k6jEXD8ajG2nszGgbSbutF1FzsrPBPpj9jBAejh5SxylERkSsxNpveg9zQ+Kx7zD89vNMItgXZ0bUHUAvg4+jQaFS+tLm32mlYSK/g7++valzUU44EugXC3c+fIHZGIim8X498X/o0dl3bgdv1tAEBol1DM6jsLYwLHcNYKPTCLKtLbG78IkSUpLK/G/53Wjq7n3LqtOz4wsAtiBwdgQl8f2FkzaRBZOuYm03uQe6rWqDFu5zi9EXRjKOwVCJQHNlon7ufkBysp9xshMme3qm9hc9pmbL24FZV1lQCAIJcgvBLxCiYET+DfYWo1Fukt4BchskQajYCjV4qx9WQW4tMLob4zui63t8azkf6IHdwV3RUcXSeyVMxNpvcg9/RUwSnM/Knxpna/FeAcgD4efXRrxRsKc0drx9aGTURmQlmjxNaLW7ElbQtUtSoAgL+TP17u+zKeDHkS1jJrkSMkS8MivQX8IkSW7qaqGv85dQPbT91Abtnd0fWoYDfERgXgsXBvjq4TWRjmJtN7kHv6w7UfsODogvue99kjn2FCN8OX3BGR5amorcD2S9ux6cIm3Kq5BUC7mePM8Jl4JvQZ2MrYRYoMwyK9BfwiRB2FWiPgl8tF2HoyGz+n38SdwXV0cdCOrk8ZHIAQTydxgyQigzA3mV57jKSvH7ceg7wHtTZEIrIgVXVV+G/Gf7HxwkYU3S4CAHjae2JGnxn4XY/fcYNHui8W6S3gFyHqiAqU1dhx6gZ2nMpGnvLu7sEPd3ND7OBAjOvjBVsrjq4TmSvmJtMzxZr0wqrCJlujSSCBl4MX9j27j5tJEXUyNeoa7Lq8C+tT16OgsgAA4Gbnhmlh0zCl1xQud6FmsUhvAb8IUUem1gg4fKkQW09m49ClQt3oupujDZ4b4I8XogIQ7MHkQWRumJtMz1S7uwPQK9QbdndfMXxFs23YiKjjq1PXYe/Vvfg65WvkVOQAAFxsXDA1bCpie8VCbisXOUIyNyzSW8AvQtRZ5JXdxvZTN/CfUzdQoLo7uh4T4o7YwQEYG+YNGyv2/iQyB8xNptdWfdK9HbyxIGoBC3QiAgDUa+rxY+aPiEuOw3XVdQCAk7UTpvSagmlh09DFrou4AZLZYJHeAn4Ros6mXq3BoUtF2HoyC4czitDwN97DyQa/G9AVU6K6ItCdo+tEYmJuMj1T3VO1Ro2zhWdRVFUETwdPRCoiOcWdiBpRa9Q4kHUAa5LX4ErZFQCAvZU9nu/xPGaEz4CHvYfIEZLYWKS3gF+EqDPLuVV1Z+36DRSW1+iOPxLqgdioAIwO84K1jKPrRO2Nucn0eE+JSAwaQYNDNw5hzfk1SC9NBwDYymzxbOizeCn8JXg7eoscIYmFRXoLmLSJgDq1Bj+nF2JrYjaOXr53dN0Wzw/0x5SoAHR14y6lRO2Fucn0eE+JSEyCIOBo7lGsSV6D5KJkAICV1AqTuk/CH8L/AH9nf5EjpPbGIr0FTNpE+m6UVmH7qWzsOJWD4grt6LpEAjwS6onYqACM6q1ocnRdrRGQmFmKwvJqKJztEBXsBplU0t7hE3UIzE2mx3tKROZAEAScLDiJNefX4PTN0wAAmUSGJ7o9gZf7vowgeZC4AVK7YZHeAiZtoqbVqTWIT7t5Z3S9WHdc4WyLyYO6YvKgrvDvoh1d35eaj4++S0P+Pe3efOR2WDwxDI+F+7R77ESWjrnJ9HhPicjcnLl5BnHJcUjISwAASCVSjAsah1l9Z6F7l+4iR0dtjUV6C5i0ie4vq6QS2xJv4L9nbqC4ohaAdnR9eA9P9PR2xpoj1xp1Dm4YQ189NZKFOpGRmJtMj/eUiMxVclEy1iavxeGcw7pjowNGY1bELPR27607xo0rOxYW6S1g0iYyXG29BvvTCrAtMRvHr5Tc93wJAG+5HY4tGMmp70RGYG4yPd5TIjJ3F0svIi45DgeyDuiODfMfhlkRs1BYVdioBaSXgxcWRi1kC0gLxSK9BUzaRK2TWVyJFfsv4bvk/Pueu+2VhxEd4t4OURF1DMxNpsd7SkSW4sqtK1ibshb7ru+DRtA0e57kzrzFFcNXsFC3QMbkJfZaIiKDBHs4YnSYl0Hnvr87BR/uvYBdZ3Nw+WY51JpO9btAIiIiIoN179Idnz36Gb596ls82e3JZs8T7iw2/CzxM6g16vYKj0RgJXYARGQ5FM52Bp2XWVyJzOJK3c8ONjKE+8rR11+OCH85+vrJEeTuCCmnxBMREREBAILkQZgUOgl7r+1t9hwBAgqqCnDm5hlE+US1Y3TUnlikE5HBooLd4CO3Q4GyutHGcYB2TbqHsy0WPdYLqXkqpOSWITVXhapaNRKvlyLxeqnuXGdbK4T73Sna/eWI8HNFVzd7SCQs3ImIiKhzKqoqMui8tw6/hVEBoxDjF4Non2jIbeVtHBm1JxbpRGQwmVSCxRPD8PqWs5AAeoV6Q2n916f64LFwHzwzQPuzWiPgalEFknOUSMkpQ3KuEml5KpTX1OPEtRKcuHZ3Qzq5vbVupD3CX45wPzn8XFm4ExERUefg6eBp0HmqWhV2X9mN3Vd2QwIJwj3CEeMbgyF+Q9DXoy+spCzzLBk3jiMioz1on/Q6tQaXb1YgJbcMKblKpOQokZ5fjlp1481S3BxtdEW79p+u8HKxZeFOHQpzk+nxnhKRJVJr1Bi3cxwKqwp1a9DvJYEECgcFFkcvxon8EziRdwJXyq7oneNk7YTBPoMR4xuDGN8Y+Dv7t1f41ALu7t4CJm0i01BrBCRmlqKwvBoKZztEBbs9UNu12noNMm6Wa0fcc8uQnKPEpYJy1Dex6Zynsy0i/O6ucQ/3kxu8Xp7IHDE3mR7vKRFZqviseMw/PB8A9Ar15nZ3L6gswIm8E0jIS8CJ/BNQ1ij1rhfoEohon2gM8RuCKO8oOFg7tMOnoN9ikd4CJm0iy1Fdp8bFgnLtNPkcJVJylci4WY6mNov3drG7s7ZdW7z39ZPD3cm2/YMmagXmJtPjPSUiSxafFd+oT7q3gzcWRC1osf2aWqNGWkkaEvISkJCXgPNF56EW7u4EbyW1wkOeD2GI3xDE+Magl1svSCVs+NUeWKS3gEmbyLLdrlUjLV87RT75zlT5K0UVaOr/ZH6u9nob0/X1k0PuYN3+QRPdB3OT6fGeEpGlU2vUOFt4FkVVRfB08ESkIhIyqcyoa5TXliOxIBEJuQk4nnccuRW5es+72bnhYZ+HMcRvCKJ9og1eE0/GY5HeAiZtoo6nsqYeF/JUSM65u8b92j0t4O4V6O5wzxp3V4T7ucDZjoU7iYu5yfR4T4mI9AmCgBvlN3A87zgS8hKQmJ+IqvoqvXN6dOmBIb5DEO0bjUivSNjKOCvRVFikt4BJm6hzUFXXITX37oh7aq4SWSVVTZ7bzcNRN0U+wt8VfXxd4GjLXVGp/TA3mR7vKRFRy+rUdUgqSsKJvBM4nnccaSVpes/byeww0Hugdtd43yEIlgdz494HwCK9BUzaRJ1XWVUtUnNVSM4t0xbvOUrklt1udJ5EAnT3dLpnjbsrwnxcYG9j3BQzIkMxN5ke7ykRkXFKq0vxa96vOJ53HCfyTqDotn7Pdm9Hb92O8Q/7PMze7EZikd4CJm0iuldJRY1uinzDGvcCVXWj82RSCUIVTnfWuLsiwk+Ont7OsLNm4U4PjrnJ9HhPiYhaTxAEXC67rFvLfvbmWdRqanXPSyVShLuHI8ZPW7SzN/v9sUhvAZM2Ed1PoaoaKbnakfbUXCXO5yhRXFHT6DwrqQQ9vZ1169sj/OXo4eUMGyvukkrGYW4yPd5TIiLTuV1/G2duntHuGp+bgKvKq3rPO1s7Y7DPYET7alu9+Tn5iRSp+WKR3gImbSIyliAIuKmq0W1M19AOrrSyttG5NjIpevs4391R3l+OUIUTrGQs3Kl5zE2mx3tKRNR2GnqzN0yNV9Wq9J4PcgnSFuy+QzDIexB7s4NFeouYtInIFARBQG7Zbb1p8sk5ZVBV1zc619ZKijBfF9369gh/OUI8nSCTcvMV0mJuMj3eUyKi9tHQm71h1/jkouRGvdn7K/rrNqDr6dazU/ZmZ5HeAiZtImorgiAgu7RKN02+4Z/lNY0LdwcbGfr4uuimyff1lyPY3RFSAwt3tUZAYmYpCsuroXC2Q1SwG4t+C8bcZHq8p0RE4iivLUdifqKuaG+qN3vDKHu0bzQ87D1EirR9sUhvAZM2EbUnjUbA9ZLKu9Pkc5RIzVOiqlbd6FwnWyuE+7kgwt9V18s9wM2hUbuTfan5+Oi7NOQr725w5yO3w+KJYXgs3KfNPxOZHnOT6fGeEhGJTxAEZJdn69aynyw4idv1+p11enbpqd013i8GkYpI2MhsRIq2bbFIbwGTNhGJTa0RcK2oQre2PTmnDBfyVKip1zQ618XO6k4Pd+2Ie2llLf68JxW//R93Qxm/emokC3ULxNxkerynRETmp6E3e0JeAo7nHkd6abre8/ZW9hjoNVBXtAe7dJze7CzSW8CkTUTmqF6tweXCCqQ0FO65SqTnqVCrbly4t8RHbodjC0Zy6ruFYW4yPd5TIiLzV1pdihN5J7Qj7XkJKL5drPe8j6OPrjf7YJ/BFt2bnUV6C5i0ichS1NZrkHGzXDdV/sS1Ylwvrrrv6xxtZfCR28PDyQYeTrbwcLKFp7Ot3s8ezrZwd7Rhn3czwdxkerynRESWRRAEZNzK0BXsTfZm9wjHEN8hiPGNQbhHuEX1ZmeR3gImbSKyVN8m5eLN7UkmvaazndWdwv2eAt7JFh7O9xT4d352sLGcRGhpmJtMj/eUiMiyNfRmP56r3YDumvKa3vPONs542Odh3SZ0vk6+IkVqGGPyEr9xERFZCIWznUHnLX82An5d7FFcUYOi8hoUV9SiuKIGJRV3/724ogZ1agHl1fUor65HZnHlfa/rYCPTFfTuugLeBh7O9xT3d352trXqMGvIiIiIqP3ZW9ljqN9QDPUbCkDbm71hLfuv+b9CVavCgawDOJB1AIC2N3uMbwyG+A3BQK+BFt2bnSPpREQWQq0RMPSzgyhQVjfaOA7Qbh7nbeCadEEQoLpdj6I7BXtxRQ2Ky/WL+Hv/vbrOuLXxNlZS7Qi83hR7G7g72t4p6m3uPG8LVwfrTl/QMzeZHu8pEVHHpdaocaHkAo7nHceJvBNN9maPVETq1rObQ292TndvAZM2EVmyfan5eH3LWQDQK9Tbcnd3QRBQWau+U8RrH0UVtXo/3x2tr0VFE33hW2IllcC9ien2DUX8vc+5OdqYxaZ4pu5Tz9xkerynRESdh6pWhVP5p1rszd5QsBvam12tUeNs4VkUVRXB08ETkYpIyKSt38uHRXoLmLSJyNKZe5/027XqxqPx5Xd/Lrpn5F5VbVxBL5UAbo42+tPrnWzvmXJvo9soz83RBtYy0//WvC3uP3OT6fGeEhF1Tg292RvWsicWJDbqzd7LrZduLXt/Rf9Gvdnjs+KxLHEZblbd1B3zcvDCwqiFGB04ulVxsUhvAZM2EXUEph7JFUtNvRqllbUoLq+9M0LfUMDfO+1eW9zfqqqFsRnL1cG60cZ4D7LTfcNMBlP3qWduMj3eUyIiAu72Zm8o2pvrzT7ET7tr/JVbV/D2kbch/CbbS+5k+xXDV7SqUGeR3gImbSIiy1Sv1qC0UjsSX/LbtfPlDQW+9nhpZS3UGuPS2/12uu/iYIM535xFUUVNk683Zk+A32JuMj3eUyIiakrJ7RKcyD+h68/+297sUokUGqHpvXgkkMDLwQv7nt1n9NR37u5OREQdjpVMCoWLHRQu99/lXqMRcKuqtumN8Mobb4xn7E73TREA5CurkZhZiugQ91Zdg4iIiNqWu707nuj2BJ7o9oReb/bjecdxuuC03gZ0vyVAQEFVAc4WnsUg70FtFqPoRfqqVavwt7/9Dfn5+ejTpw9WrlyJRx555L6vO378OIYNG4bw8HAkJSW1faBERGQxpFIJ3J1s4e5ki55wbvHc5na6L6m8MwX/ztT77NJKlFbW3fe9C8ur73sOERERiU8ikaCnW0/0dOuJl8Jfwu7Lu/GXhL/c93VFVUVtGpeoRfqOHTswb948rFq1CkOGDMGaNWswfvx4pKWlISAgoNnXKZVKvPjiixg1ahRu3rzZ7HlERET3I5FIIHewhtzBGt0VTs2ed+JqCaas/fW+1zO0nz0RERGZF39nf4PO83TwbNM4RG0Wt2LFCvzhD3/Ayy+/jN69e2PlypXo2rUrVq9e3eLrXn31VcTGxiI6Ovq+71FTUwOVSqX3ICIiMlZUsBt85HZobrW5BNpd3qOC3dozLCIiIjKRSEUkvBy8dJvE/ZYEEng7eCNSEdmmcYhWpNfW1uLMmTMYO3as3vGxY8ciISGh2ddt2LABV69exeLFiw16n6VLl0Iul+seXbt2faC4iYioc5JJJVg8MQwAGqXuhp8XTwyzyF32iYiICJBJZVgYtRAAGhXqDT8viFrwQP3SDSFakV5cXAy1Wg0vLy+9415eXigoKGjyNZcvX8bChQvxzTffwMrKsJn6ixYtglKp1D1u3LjxwLETEVHn9Fi4D1ZPjYS3XH9Ku7fcrtXt14iIiMh8jA4cjRXDV0DhoNA77uXg1er2a8YSfeM4iUT/NxSCIDQ6BgBqtRqxsbH46KOP0KNHD4Ovb2trC1tb2weOk4iICNAW6mPCvDtEn3oiIiJqbHTgaIzoOgJnC8+iqKoIng6eiFREtvkIegPRinQPDw/IZLJGo+aFhYWNRtcBoLy8HKdPn8a5c+cwd+5cAIBGo4EgCLCyssL+/fsxcuTIdomdiIg6N5lUwjZrREREHZhMKmvTNmstEW26u42NDQYMGIADBw7oHT9w4ABiYmIane/i4oKUlBQkJSXpHq+99hp69uyJpKQkDB48uL1CJyIiIiIiImoTok53nz9/PqZNm4aBAwciOjoacXFxyM7OxmuvvQZAu548NzcXmzZtglQqRXh4uN7rFQoF7OzsGh0nIiIiIiIiskSitmCbPHkyVq5ciY8//hgPPfQQfvnlF/zwww8IDAwEAOTn5yM7O1vMEImIiMiEgoKCIJFIGj3mzJnT6NxXX30VEokEK1eubP9AiYiIRCIRBEEQO4j2pFKpIJfLoVQq4eLiInY4REREnSo3FRUVQa1W635OTU3FmDFjcOjQIQwfPlx3fM+ePfjwww9RVFSEd999F/PmzTPqfTrTPSUiIvNnTF4SdSSdiIiIOhdPT094e3vrHt9//z1CQkIwbNgw3Tm5ubmYO3cuvvnmG1hbW4sYLRERUfsTvQUbERERdU61tbXYsmUL5s+fr2u/qtFoMG3aNLz77rvo06ePwdeqqalBTU2N7meVSmXyeImIiNoDR9KJiIhIFHv27EFZWRlmzJihO/bZZ5/BysoKb7zxhlHXWrp0KeRyue7RtWtXE0dLRETUPlikExERkSjWrVuH8ePHw9fXFwBw5swZfP7559i4caNuZN1QixYtglKp1D1u3LjRFiETERG1ORbpRERE1O6ysrIQHx+Pl19+WXfs6NGjKCwsREBAAKysrGBlZYWsrCy8/fbbCAoKavF6tra2cHFx0XsQERFZIq5JJyIiona3YcMGKBQKPP7447pj06ZNw+jRo/XOGzduHKZNm4aXXnqpvUMkIiISRacr0hs6znFDGSIiMhcNOamzdEXVaDTYsGEDpk+fDiuru19F3N3d4e7urneutbU1vL290bNnT6Peg/meiIjMiTG5vtMV6eXl5QDADWWIiMjslJeXQy6Xix1Gm4uPj0d2djZmzpzZZu/BfE9ERObIkFwvETrLr+3v0Gg0yMvLg7Ozs9Gb0jRFpVKha9euuHHjhkWuf2P84mL84mL84mL8dwmCgPLycvj6+kIq5XYxpmDKfM8/q+Ji/OJi/OJi/OISK9d3upF0qVQKf39/k1/X0jepYfziYvziYvziYvxanWEEvT21Rb7nn1VxMX5xMX5xMX5xtXeu56/riYiIiIiIiMwEi3QiIiIiIiIiM8Ei/QHZ2tpi8eLFsLW1FTuUVmH84mL84mL84mL8ZCks/b814xcX4xcX4xcX42+dTrdxHBEREREREZG54kg6ERERERERkZlgkU5ERERERERkJlikExEREREREZkJFulEREREREREZoJFeissXboUgwYNgrOzMxQKBSZNmoRLly6JHZbBVq9ejYiICLi4uMDFxQXR0dH48ccfxQ6r1ZYuXQqJRIJ58+aJHYpBPvzwQ0gkEr2Ht7e32GEZJTc3F1OnToW7uzscHBzw0EMP4cyZM2KHZZCgoKBG918ikWDOnDlih2aQ+vp6/OlPf0JwcDDs7e3RrVs3fPzxx9BoNGKHZrDy8nLMmzcPgYGBsLe3R0xMDE6dOiV2WM365ZdfMHHiRPj6+kIikWDPnj16zwuCgA8//BC+vr6wt7fH8OHDceHCBXGCJZOx9FwPdKx8b2m5HmC+FxvzvfgsKd+bW65nkd4KR44cwZw5c/Drr7/iwIEDqK+vx9ixY1FZWSl2aAbx9/fHsmXLcPr0aZw+fRojR47EU089ZZFfKk+dOoW4uDhERESIHYpR+vTpg/z8fN0jJSVF7JAMduvWLQwZMgTW1tb48ccfkZaWhr///e9wdXUVOzSDnDp1Su/eHzhwAADw3HPPiRyZYT777DN89dVX+PLLL5Geno7ly5fjb3/7G7744guxQzPYyy+/jAMHDmDz5s1ISUnB2LFjMXr0aOTm5oodWpMqKyvRr18/fPnll00+v3z5cqxYsQJffvklTp06BW9vb4wZMwbl5eXtHCmZkqXneqDj5HtLzfUA872YmO/FZ0n53uxyvUAPrLCwUAAgHDlyROxQWq1Lly7C119/LXYYRikvLxdCQ0OFAwcOCMOGDRPefPNNsUMyyOLFi4V+/fqJHUarLViwQBg6dKjYYZjMm2++KYSEhAgajUbsUAzy+OOPCzNnztQ79swzzwhTp04VKSLjVFVVCTKZTPj+++/1jvfr10/44IMPRIrKcACE3bt3637WaDSCt7e3sGzZMt2x6upqQS6XC1999ZUIEVJb6Qi5XhAsL99baq4XBOZ7c8N8374sOd+bQ67nSLoJKJVKAICbm5vIkRhPrVZj+/btqKysRHR0tNjhGGXOnDl4/PHHMXr0aLFDMdrly5fh6+uL4OBgvPDCC7h27ZrYIRls7969GDhwIJ577jkoFAr0798fa9euFTusVqmtrcWWLVswc+ZMSCQSscMxyNChQ/Hzzz8jIyMDAHD+/HkcO3YMEyZMEDkyw9TX10OtVsPOzk7vuL29PY4dOyZSVK2XmZmJgoICjB07VnfM1tYWw4YNQ0JCgoiRkalZcq4HLDffW3KuB5jvzQXzffvrSPlejFxv1SZX7UQEQcD8+fMxdOhQhIeHix2OwVJSUhAdHY3q6mo4OTlh9+7dCAsLEzssg23fvh1nz54123UtLRk8eDA2bdqEHj164ObNm/jkk08QExODCxcuwN3dXezw7uvatWtYvXo15s+fj/fffx+JiYl44403YGtrixdffFHs8IyyZ88elJWVYcaMGWKHYrAFCxZAqVSiV69ekMlkUKvV+PTTTzFlyhSxQzOIs7MzoqOj8de//hW9e/eGl5cXtm3bhpMnTyI0NFTs8IxWUFAAAPDy8tI77uXlhaysLDFCojZgqbkesOx8b8m5HmC+NyfM9+2vI+V7MXI9i/QHNHfuXCQnJ1vcb4R69uyJpKQklJWVYefOnZg+fTqOHDliEYn7xo0bePPNN7F///5Gv52zBOPHj9f9e9++fREdHY2QkBD8+9//xvz580WMzDAajQYDBw7EkiVLAAD9+/fHhQsXsHr1aotL2uvWrcP48ePh6+srdigG27FjB7Zs2YKtW7eiT58+SEpKwrx58+Dr64vp06eLHZ5BNm/ejJkzZ8LPzw8ymQyRkZGIjY3F2bNnxQ6t1X47MiMIgsWM1tD9WWquByw331t6rgeY780J8704Olq+b89czyL9Afzxj3/E3r178csvv8Df31/scIxiY2OD7t27AwAGDhyIU6dO4fPPP8eaNWtEjuz+zpw5g8LCQgwYMEB3TK1W45dffsGXX36JmpoayGQyESM0jqOjI/r27YvLly+LHYpBfHx8Gn256927N3bu3ClSRK2TlZWF+Ph47Nq1S+xQjPLuu+9i4cKFeOGFFwBov/hlZWVh6dKlFpO0Q0JCcOTIEVRWVkKlUsHHxweTJ09GcHCw2KEZrWGn5oKCAvj4+OiOFxYWNvqNO1kmS871gOXm+46W6wHme7Ew34uno+R7MXI916S3giAImDt3Lnbt2oWDBw9a3B+0pgiCgJqaGrHDMMioUaOQkpKCpKQk3WPgwIH4/e9/j6SkJItL2jU1NUhPT9f7S2/OhgwZ0qgNUUZGBgIDA0WKqHU2bNgAhUKBxx9/XOxQjFJVVQWpVP9/3TKZzKJasjRwdHSEj48Pbt26hZ9++glPPfWU2CEZLTg4GN7e3rpdgwHt2scjR44gJiZGxMjoQXXEXA9YTr7vaLkeYL4XC/O9+Cw934uR6zmS3gpz5szB1q1b8e2338LZ2Vm3TkEul8Pe3l7k6O7v/fffx/jx49G1a1eUl5dj+/btOHz4MPbt2yd2aAZxdnZutCbQ0dER7u7uFrFW8J133sHEiRMREBCAwsJCfPLJJ1CpVBbzW9G33noLMTExWLJkCZ5//nkkJiYiLi4OcXFxYodmMI1Ggw0bNmD69OmwsrKs/w1OnDgRn376KQICAtCnTx+cO3cOK1aswMyZM8UOzWA//fQTBEFAz549ceXKFbz77rvo2bMnXnrpJbFDa1JFRQWuXLmi+zkzMxNJSUlwc3NDQEAA5s2bhyVLliA0NBShoaFYsmQJHBwcEBsbK2LU9KAsPdcDlp3vLT3XA8z35oD5XlyWlO/NLte3yZ7xHRyAJh8bNmwQOzSDzJw5UwgMDBRsbGwET09PYdSoUcL+/fvFDuuBWFJblsmTJws+Pj6CtbW14OvrKzzzzDPChQsXxA7LKN99950QHh4u2NraCr169RLi4uLEDskoP/30kwBAuHTpktihGE2lUglvvvmmEBAQINjZ2QndunUTPvjgA6Gmpkbs0Ay2Y8cOoVu3boKNjY3g7e0tzJkzRygrKxM7rGYdOnSoyf/nT58+XRAEbWuWxYsXC97e3oKtra3w6KOPCikpKeIGTQ/M0nO9IHS8fG9JuV4QmO/NAfO9uCwp35tbrpcIgiC0TflPRERERERERMbgmnQiIiIiIiIiM8EinYiIiIiIiMhMsEgnIiIiIiIiMhMs0omIiIiIiIjMBIt0IiIiIiIiIjPBIp2IiIiIiIjITLBIJyIiIiIiIjITLNKJiIiIiIiIzASLdCLC9evXIZFIkJSUBAA4fPgwJBIJysrKRI2LiIiITIO5nshysEgnokZiYmKQn58PuVxusmv+9ssBERERiYe5nsh8WYkdABGZHxsbG3h7e4sdBhEREbUR5noi88WRdKJORKPR4LPPPkP37t1ha2uLgIAAfPrpp43Oa2oKXEJCAh599FHY29uja9eueOONN1BZWal7PigoCEuWLMHMmTPh7OyMgIAAxMXF6Z4PDg4GAPTv3x8SiQTDhw/XvVdUVBQcHR3h6uqKIUOGICsrq21uABERUQfHXE9k+VikE3UiixYtwmeffYY///nPSEtLw9atW+Hl5XXf16WkpGDcuHF45plnkJycjB07duDYsWOYO3eu3nl///vfMXDgQJw7dw6zZ8/G66+/josXLwIAEhMTAQDx8fHIz8/Hrl27UF9fj0mTJmHYsGFITk7GiRMnMGvWLEgkEtN/eCIiok6AuZ6oAxCIqFNQqVSCra2tsHbt2kbPZWZmCgCEc+fOCYIgCIcOHRIACLdu3RIEQRCmTZsmzJo1S+81R48eFaRSqXD79m1BEAQhMDBQmDp1qu55jUYjKBQKYfXq1U2+hyAIQklJiQBAOHz4sAk/KRERUefEXE/UMXAknaiTSE9PR01NDUaNGmX0a8+cOYONGzfCyclJ9xg3bhw0Gg0yMzN150VEROj+XSKRwNvbG4WFhc1e183NDTNmzMC4ceMwceJEfP7558jPzzc6PiIiImKuJ+ooWKQTdRL29vatfq1Go8Grr76KpKQk3eP8+fO4fPkyQkJCdOdZW1vrvU4ikUCj0bR47Q0bNuDEiROIiYnBjh070KNHD/z666+tjpWIiKizYq4n6hhYpBN1EqGhobC3t8fPP/9s9GsjIyNx4cIFdO/evdHDxsbGoGs0nKdWqxs9179/fyxatAgJCQkIDw/H1q1bjY6RiIios2OuJ+oY2IKNqJOws7PDggUL8N5778HGxgZDhgxBUVERLly4cN9pcQsWLMDDDz+MOXPm4JVXXoGjoyPS09Nx4MABfPHFFwa9v0KhgL29Pfbt2wd/f3/Y2dmhtLQUcXFxePLJJ+Hr64tLly4hIyMDL774oik+MhERUafCXE/UMXAknagT+fOf/4y3334bf/nLX9C7d29Mnjy5xXVkDSIiInDkyBFcvnwZjzzyCPr3748///nP8PHxMfi9rays8M9//hNr1qyBr68vnnrqKTg4OODixYt49tln0aNHD8yaNQtz587Fq6+++iAfk4iIqNNirieyfBJBEASxgyAiIiIiIiIijqQTERERERERmQ0W6URERERERERmgkU6ERERERERkZlgkU5ERERERERkJlikExEREREREZkJFulEREREREREZoJFOhEREREREZGZYJFOREREREREZCZYpBMRERERERGZCRbpRERERERERGaCRToRERERERGRmfj/6kDAhcnVuPMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_avg(metrics):\n",
    "    avg_loss = {alpha: np.mean(data['losses']) for alpha, data in metrics.items()}\n",
    "    avg_accuracy = {alpha: np.mean(data['accuracy']) for alpha, data in metrics.items()}\n",
    "    return avg_loss, avg_accuracy\n",
    "\n",
    "def print_results(results, title):\n",
    "    print(f\"\\n{title}:\")\n",
    "    for method in results.keys():\n",
    "        avg_loss, avg_accuracy = compute_avg(results[method])\n",
    "        print(f\"{method}:\")\n",
    "        print(\"  Average Loss:\", avg_loss)\n",
    "        print(\"  Average Accuracy:\", avg_accuracy)\n",
    "\n",
    "def plot_results(results, title, filename):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Loss Plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for method in results.keys():\n",
    "        avg_loss, _ = compute_avg(results[method])\n",
    "        plt.plot(avg_loss.keys(), avg_loss.values(), marker='o', label=method)\n",
    "    plt.xlabel('clients')\n",
    "    plt.ylabel('Average Loss')\n",
    "    plt.title(f'{title}')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Accuracy Plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for method in results.keys():\n",
    "        _, avg_accuracy = compute_avg(results[method])\n",
    "        plt.plot(avg_accuracy.keys(), avg_accuracy.values(), marker='o', label=method)\n",
    "    plt.xlabel('clients')\n",
    "    plt.ylabel('Average Accuracy')\n",
    "    plt.title(f'{title}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print_results(results, \"Non-Clustered Results\")\n",
    "plot_results(results, \"Non-Clustered Results\", \"non_clustered_results.png\")\n",
    "print_results(clusteredResults, \"Clustered Results\")\n",
    "plot_results(clusteredResults, \"Clustered Results\", \"clustered_results.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
