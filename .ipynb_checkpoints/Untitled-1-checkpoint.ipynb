{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "from abc import ABC, abstractmethod\n",
    "import time\n",
    "from sklearn.manifold import TSNE\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import keras \n",
    "from keras.datasets import mnist\n",
    "from keras import backend as k\n",
    "from torch.utils.data import Subset\n",
    "import model\n",
    "import partition\n",
    "import model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for second model\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from  model2 import Net\n",
    "import training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x24855600d70>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 3\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1, 28, 28])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "example_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = model2.Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nazek\\Documents\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.319280\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.290954\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.318535\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.261000\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.259137\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.229576\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.196151\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.181698\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.088444\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.014765\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.818533\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 1.822772\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 1.838733\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 1.530556\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 1.738141\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 1.420971\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 1.369238\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 1.335397\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 1.182360\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 1.056649\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.085395\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 1.043788\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.979932\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 1.015183\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.937379\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.882042\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.791246\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.977964\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.990534\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.960740\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.974224\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.952366\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.700648\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.849697\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.644111\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.736555\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.860933\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.615364\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.990704\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.526882\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.730526\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.705984\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.823739\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.845458\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.588147\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.623796\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.793646\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.418977\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.523337\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.552039\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.570690\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.584034\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.683120\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.648872\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.424031\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.732430\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.527461\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.438413\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.681123\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.581277\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.602129\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.525031\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.483108\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.619587\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.545031\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.814483\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.540651\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.560167\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.693479\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.567100\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.463455\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.448500\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.628427\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.456004\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.491407\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.518573\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.400177\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.624805\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.458933\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.376152\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.641488\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.416929\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.353867\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.378969\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.591578\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.416554\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.452524\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.380453\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.758105\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.466998\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.500285\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.322413\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.711488\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.391711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.1923, Accuracy: 9447/10000 (94%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.652653\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.456914\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.243949\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.478922\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.414049\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.719899\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.496854\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.651853\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.485354\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.527071\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.452662\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.352606\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.431488\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.418999\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.362183\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.593213\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.497393\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.347083\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.314499\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.644786\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.606208\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.273107\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.422825\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.458464\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.391089\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.290856\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.617115\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.554005\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.333147\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.363344\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.551056\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.216489\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.374446\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.425693\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.580093\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.249731\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.237703\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.454805\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.460911\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.309818\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.484270\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.422189\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.421368\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.313428\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.436074\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.327006\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.257415\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.467946\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.318619\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.383042\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.341652\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.423280\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.278874\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.356464\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.503462\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.328999\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.205977\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.437264\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.287241\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.521327\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.333104\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.319146\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.219442\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.320120\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.301936\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.292663\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.406404\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.396858\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.488398\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.378265\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.383275\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.191209\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.336352\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.304576\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.474645\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.367355\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.406472\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.470006\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.325577\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.347219\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.257360\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.245894\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.262258\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.331370\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.229092\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.247234\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.357684\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.200174\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.457740\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.145262\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.359273\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.350028\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.295301\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.520333\n",
      "\n",
      "Test set: Avg. loss: 0.1262, Accuracy: 9604/10000 (96%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.211919\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.219050\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.422457\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.263944\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.338227\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.310375\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.256175\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.452109\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.283297\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.268727\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.419239\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.342126\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.305587\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.269896\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.175312\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.286038\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.423057\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.504031\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.364287\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.203552\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.378262\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.181696\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.311217\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.316549\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.299031\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.374663\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.274439\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.391360\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.264657\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.322917\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.242228\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.354692\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.259955\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.571348\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.457933\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.341565\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.430184\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.360649\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.231460\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.234448\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.276404\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.229833\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.222054\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.312953\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.461945\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.228019\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.379396\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.418275\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.277474\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.213255\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.315995\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.371551\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.233203\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.501042\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.392412\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.235351\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.450541\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.133830\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.169669\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.521417\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.278228\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.159234\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.389103\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.225851\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.356990\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.199798\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.282895\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.308215\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.438489\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.202039\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.291836\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.278961\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.201140\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.387804\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.428785\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.336555\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.334912\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.254088\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.404397\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.140403\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.212186\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.285531\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.224946\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.207417\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.231849\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.162679\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.257025\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.254135\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.381463\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.560579\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.262309\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.182540\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.368454\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.169064\n",
      "\n",
      "Test set: Avg. loss: 0.0993, Accuracy: 9672/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "  training.train(epoch,network,train_loader,optimizer,log_interval,train_losses,train_counter)\n",
    "  training.test(network,test_loader,test_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Stuff\n",
    "# Set download to False if already downloaded\n",
    "\"\"\"\"\"\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Load the MNIST dataset \n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=False, transform=transform)\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=False, transform=transform)\n",
    "\n",
    "print(f\"Data: {mnist_trainset.data.shape}, Targets: {mnist_trainset.targets.shape}\")\n",
    "\"\"\"\"\"\n",
    "# test data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "img_rows, img_cols=28, 28\n",
    "\n",
    "if k.image_data_format() == 'channels_first':\n",
    "   x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "   x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "   inpx = (1, img_rows, img_cols)\n",
    "\n",
    "else:\n",
    "   x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "   x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "   inpx = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000,)\n",
      "<class 'numpy.ndarray'>\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "(28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Check data shapes. later create dataloader or something similar to handle data\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(type(y_train))\n",
    "K = np.unique(y_train)\n",
    "print(K)\n",
    "print(inpx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = partition.MNISTDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1446: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Partition \n",
    "\n",
    "partitioned_data = partition.balanced_dirichlet_partition(train_dataset, partitions_number=10, alpha=0.5, num_clusters=5)\n",
    "partition_0_dataset = Subset(train_dataset, partitioned_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Check sizes\n",
    "\n",
    "for i in partitioned_data:\n",
    "    print(len(partitioned_data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Reformatting Subsets, loop for all\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m x_train1, y_train1 \u001b[38;5;241m=\u001b[39m partition\u001b[38;5;241m.\u001b[39mreformat_dataset(partition_0_dataset)\n",
      "File \u001b[1;32m~\\Documents\\Federated-Dimensionality-Reduction\\partition.py:151\u001b[0m, in \u001b[0;36mreformat_dataset\u001b[1;34m(partition_dataset)\u001b[0m\n\u001b[0;32m    148\u001b[0m x_train \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    149\u001b[0m y_train \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 151\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img, label \u001b[38;5;129;01min\u001b[39;00m partition_dataset:\n\u001b[0;32m    152\u001b[0m     x_train\u001b[38;5;241m.\u001b[39mappend(img)\n\u001b[0;32m    153\u001b[0m     y_train\u001b[38;5;241m.\u001b[39mappend(label)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:412\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[1;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]]\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "# Reformatting Subsets, loop for all\n",
    "\n",
    "x_train1, y_train1 = partition.reformat_dataset(partition_0_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# Check target classes of subclasses\n",
    "L = np.unique(y_train1)\n",
    "print(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the labels for model\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train)\n",
    "\n",
    "y_train1 = keras.utils.to_categorical(y_train1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8115, 28, 28, 1)\n",
      "(8115, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(x_train1.shape)\n",
    "print(y_train1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 25ms/step - accuracy: 0.1004 - loss: 2.5246\n",
      "Epoch 2/12\n",
      "\u001b[1m659/938\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.0968 - loss: 2.4220"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model_1\u001b[38;5;241m.\u001b[39mtrain_model()\n",
      "File \u001b[1;32mc:\\Users\\micha\\Downloads\\Federated-Dimensionality-Reduction\\model.py:38\u001b[0m, in \u001b[0;36mClassificationModel.train_model\u001b[1;34m(self, epochs, batch_size)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model has not been built yet. Call build_model() first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train, epochs\u001b[38;5;241m=\u001b[39mepochs, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n",
      "File \u001b[1;32mc:\\Users\\micha\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\micha\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:320\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    319\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 320\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m    321\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32mc:\\Users\\micha\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\micha\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\micha\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[0;32m    880\u001b[0m )\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\micha\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[0;32m    141\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\micha\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\micha\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\micha\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[0;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[0;32m    255\u001b[0m     )\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\micha\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1553\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1554\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   1555\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[0;32m   1556\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1557\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1558\u001b[0m   )\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1567\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\micha\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
