{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset,TensorDataset\n",
    "from autoencoder2 import Autoencoder2, reduce_dimensions2\n",
    "import torchvision\n",
    "from model2 import classification_model\n",
    "import copy\n",
    "import partition\n",
    "from pca import PCADigitReducer\n",
    "from training import train,test, train_fashion,test_fashion\n",
    "from federated_learning import distribute_global_model, federated_averaging\n",
    "from model4 import MultilayerPerceptron\n",
    "import cluster2\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x182df70ddb0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01 # ev. 0.001\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and testing data as dataloaders\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.0,), (1,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.0,), (1,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_pca = copy.copy(train_loader)\n",
    "test_loader_pca = copy.copy(test_loader)\n",
    "\n",
    "train_loader_auto = copy.copy(train_loader)\n",
    "test_loader_auto = copy.copy(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTensorDataset(TensorDataset):\n",
    "    def __init__(self, *tensors):\n",
    "        super().__init__(*tensors)\n",
    "        self.data = tensors[0]\n",
    "        self.targets = tensors[1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder2 = Autoencoder2()\n",
    "auto2_criterion = nn.BCELoss()  \n",
    "auto2_optimizer = optim.Adam(autoencoder2.parameters(), lr=0.001)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.1125\n",
      "Epoch [2/5], Loss: 0.0847\n",
      "Epoch [3/5], Loss: 0.0805\n",
      "Epoch [4/5], Loss: 0.0782\n",
      "Epoch [5/5], Loss: 0.0768\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5 # optimal nach vielen testen\n",
    "for epoch in range(num_epochs):\n",
    "    autoencoder2.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for images, _ in train_loader_auto:\n",
    "        images = images.to(device)\n",
    "\n",
    "        auto2_optimizer.zero_grad()\n",
    "        outputs = autoencoder2(images)\n",
    "        loss = auto2_criterion(outputs, images) \n",
    "        \n",
    "        loss.backward()\n",
    "        auto2_optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader_auto)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_train_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "num_clients = 10\n",
    "num_clusters = [2, 4, 6, 8, 10]\n",
    "results = {\"classic\": {}, \"pca\": {}, \"autoencoder\": {}}\n",
    "clusteredResults = {\"classic\": {}, \"pca\": {}, \"autoencoder\": {}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classic\n",
    "trainingset = train_loader.dataset\n",
    "trial_model = classification_model()\n",
    "global_model_classic = classification_model()\n",
    "rounds_classic = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 2.321368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 2.254162\n",
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 2.225052\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 2.152625\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 2.100670\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 2.057718\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 1.922730\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 1.976943\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 1.844926\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 1.979931\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 1.718920\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 1.916713\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 1.587780\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 1.436871\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 1.584264\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 1.571929\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 1.408770\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 1.432968\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 1.400637\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 1.148945\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.983217\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 1.088014\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 1.112320\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.871167\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.947870\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 1.251548\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.850683\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 1.003018\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.994532\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.779781\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.863530\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.530277\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.670589\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.634696\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.680839\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.684920\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.829117\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.721882\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.540911\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.883751\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.638533\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.647156\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.723603\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.638373\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.681145\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.666971\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.575871\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.805576\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.693841\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.698803\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.544621\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.576051\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.658649\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.453062\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.507810\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.355258\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.440544\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.667967\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.429603\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.529668\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.583329\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.421450\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.580978\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.566031\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.465441\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.402185\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.364254\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.703395\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.233843\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.329116\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.350425\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.447024\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.444584\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.347032\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.606680\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.438844\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.459223\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.530747\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.339594\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.385758\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.253687\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.440126\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.290118\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.343157\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.336257\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.416823\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.526796\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.386241\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.536483\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.310338\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.214276\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.285793\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.462496\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.265679\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.287042\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.269740\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.350402\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.200541\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.453147\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.491816\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.627431\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.407888\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.268597\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.454343\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.427221\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.378794\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.281307\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.327187\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 0.260021\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.351282\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.463577\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.204238\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.260133\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.314550\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.407376\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.388300\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.247581\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.283247\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.653863\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.249496\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.519981\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.115565\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.178159\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.229607\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.428444\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.184270\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.502482\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.412547\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.200249\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.185875\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.243169\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.489486\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.228144\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.202113\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.179337\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.255569\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.203177\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.420383\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.470558\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.258653\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.324202\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.297088\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.349106\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.335748\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.216287\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.135653\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.317195\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.197048\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.245097\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.182303\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.187415\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.288766\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.305357\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.398441\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.154499\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.149198\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.294029\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.653007\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.373017\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.340220\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.224512\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.200490\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.768556\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.409346\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.289519\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.250832\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.386401\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.241620\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.371386\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.253911\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.119916\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.360825\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.296034\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.295022\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.354001\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.356576\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.157017\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.448309\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.290016\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.280540\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/5110 (0%)]\tLoss: 2.294897\n",
      "Train Epoch: 1 [640/5110 (12%)]\tLoss: 2.155674\n",
      "Train Epoch: 1 [1280/5110 (25%)]\tLoss: 1.912393\n",
      "Train Epoch: 1 [1920/5110 (38%)]\tLoss: 1.508052\n",
      "Train Epoch: 1 [2560/5110 (50%)]\tLoss: 1.575232\n",
      "Train Epoch: 1 [3200/5110 (62%)]\tLoss: 1.499963\n",
      "Train Epoch: 1 [3840/5110 (75%)]\tLoss: 1.539235\n",
      "Train Epoch: 1 [4480/5110 (88%)]\tLoss: 1.555068\n",
      "Train Epoch: 2 [0/5110 (0%)]\tLoss: 1.343907\n",
      "Train Epoch: 2 [640/5110 (12%)]\tLoss: 1.336059\n",
      "Train Epoch: 2 [1280/5110 (25%)]\tLoss: 1.402422\n",
      "Train Epoch: 2 [1920/5110 (38%)]\tLoss: 1.138713\n",
      "Train Epoch: 2 [2560/5110 (50%)]\tLoss: 1.343690\n",
      "Train Epoch: 2 [3200/5110 (62%)]\tLoss: 1.199416\n",
      "Train Epoch: 2 [3840/5110 (75%)]\tLoss: 1.060705\n",
      "Train Epoch: 2 [4480/5110 (88%)]\tLoss: 1.005358\n",
      "Train Epoch: 3 [0/5110 (0%)]\tLoss: 1.314641\n",
      "Train Epoch: 3 [640/5110 (12%)]\tLoss: 0.990036\n",
      "Train Epoch: 3 [1280/5110 (25%)]\tLoss: 1.213029\n",
      "Train Epoch: 3 [1920/5110 (38%)]\tLoss: 1.097632\n",
      "Train Epoch: 3 [2560/5110 (50%)]\tLoss: 1.113323\n",
      "Train Epoch: 3 [3200/5110 (62%)]\tLoss: 0.850427\n",
      "Train Epoch: 3 [3840/5110 (75%)]\tLoss: 0.894097\n",
      "Train Epoch: 3 [4480/5110 (88%)]\tLoss: 0.635307\n",
      "Train Epoch: 4 [0/5110 (0%)]\tLoss: 0.686480\n",
      "Train Epoch: 4 [640/5110 (12%)]\tLoss: 0.656098\n",
      "Train Epoch: 4 [1280/5110 (25%)]\tLoss: 0.692605\n",
      "Train Epoch: 4 [1920/5110 (38%)]\tLoss: 0.551513\n",
      "Train Epoch: 4 [2560/5110 (50%)]\tLoss: 0.541644\n",
      "Train Epoch: 4 [3200/5110 (62%)]\tLoss: 0.625957\n",
      "Train Epoch: 4 [3840/5110 (75%)]\tLoss: 0.474103\n",
      "Train Epoch: 4 [4480/5110 (88%)]\tLoss: 0.655045\n",
      "Train Epoch: 5 [0/5110 (0%)]\tLoss: 0.515674\n",
      "Train Epoch: 5 [640/5110 (12%)]\tLoss: 0.564869\n",
      "Train Epoch: 5 [1280/5110 (25%)]\tLoss: 0.634042\n",
      "Train Epoch: 5 [1920/5110 (38%)]\tLoss: 0.318832\n",
      "Train Epoch: 5 [2560/5110 (50%)]\tLoss: 0.513144\n",
      "Train Epoch: 5 [3200/5110 (62%)]\tLoss: 0.464101\n",
      "Train Epoch: 5 [3840/5110 (75%)]\tLoss: 0.523974\n",
      "Train Epoch: 5 [4480/5110 (88%)]\tLoss: 0.435582\n",
      "Train Epoch: 6 [0/5110 (0%)]\tLoss: 0.504788\n",
      "Train Epoch: 6 [640/5110 (12%)]\tLoss: 0.374102\n",
      "Train Epoch: 6 [1280/5110 (25%)]\tLoss: 0.508247\n",
      "Train Epoch: 6 [1920/5110 (38%)]\tLoss: 0.383750\n",
      "Train Epoch: 6 [2560/5110 (50%)]\tLoss: 0.321137\n",
      "Train Epoch: 6 [3200/5110 (62%)]\tLoss: 0.656813\n",
      "Train Epoch: 6 [3840/5110 (75%)]\tLoss: 0.426341\n",
      "Train Epoch: 6 [4480/5110 (88%)]\tLoss: 0.480467\n",
      "Train Epoch: 7 [0/5110 (0%)]\tLoss: 0.774552\n",
      "Train Epoch: 7 [640/5110 (12%)]\tLoss: 0.539925\n",
      "Train Epoch: 7 [1280/5110 (25%)]\tLoss: 0.522679\n",
      "Train Epoch: 7 [1920/5110 (38%)]\tLoss: 0.481835\n",
      "Train Epoch: 7 [2560/5110 (50%)]\tLoss: 0.417542\n",
      "Train Epoch: 7 [3200/5110 (62%)]\tLoss: 0.541319\n",
      "Train Epoch: 7 [3840/5110 (75%)]\tLoss: 0.483958\n",
      "Train Epoch: 7 [4480/5110 (88%)]\tLoss: 0.635146\n",
      "Train Epoch: 8 [0/5110 (0%)]\tLoss: 0.385101\n",
      "Train Epoch: 8 [640/5110 (12%)]\tLoss: 0.412346\n",
      "Train Epoch: 8 [1280/5110 (25%)]\tLoss: 0.359612\n",
      "Train Epoch: 8 [1920/5110 (38%)]\tLoss: 0.480362\n",
      "Train Epoch: 8 [2560/5110 (50%)]\tLoss: 0.418812\n",
      "Train Epoch: 8 [3200/5110 (62%)]\tLoss: 0.244857\n",
      "Train Epoch: 8 [3840/5110 (75%)]\tLoss: 0.396633\n",
      "Train Epoch: 8 [4480/5110 (88%)]\tLoss: 0.196958\n",
      "Train Epoch: 9 [0/5110 (0%)]\tLoss: 0.440042\n",
      "Train Epoch: 9 [640/5110 (12%)]\tLoss: 0.598232\n",
      "Train Epoch: 9 [1280/5110 (25%)]\tLoss: 0.728127\n",
      "Train Epoch: 9 [1920/5110 (38%)]\tLoss: 0.359043\n",
      "Train Epoch: 9 [2560/5110 (50%)]\tLoss: 0.316251\n",
      "Train Epoch: 9 [3200/5110 (62%)]\tLoss: 0.429452\n",
      "Train Epoch: 9 [3840/5110 (75%)]\tLoss: 0.276025\n",
      "Train Epoch: 9 [4480/5110 (88%)]\tLoss: 0.374313\n",
      "Train Epoch: 10 [0/5110 (0%)]\tLoss: 0.157713\n",
      "Train Epoch: 10 [640/5110 (12%)]\tLoss: 0.334234\n",
      "Train Epoch: 10 [1280/5110 (25%)]\tLoss: 0.194850\n",
      "Train Epoch: 10 [1920/5110 (38%)]\tLoss: 0.204211\n",
      "Train Epoch: 10 [2560/5110 (50%)]\tLoss: 0.359606\n",
      "Train Epoch: 10 [3200/5110 (62%)]\tLoss: 0.300290\n",
      "Train Epoch: 10 [3840/5110 (75%)]\tLoss: 0.281936\n",
      "Train Epoch: 10 [4480/5110 (88%)]\tLoss: 0.255381\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6766 (0%)]\tLoss: 2.254122\n",
      "Train Epoch: 1 [640/6766 (9%)]\tLoss: 2.096807\n",
      "Train Epoch: 1 [1280/6766 (19%)]\tLoss: 1.941459\n",
      "Train Epoch: 1 [1920/6766 (28%)]\tLoss: 1.472423\n",
      "Train Epoch: 1 [2560/6766 (38%)]\tLoss: 1.373093\n",
      "Train Epoch: 1 [3200/6766 (47%)]\tLoss: 1.523663\n",
      "Train Epoch: 1 [3840/6766 (57%)]\tLoss: 1.339207\n",
      "Train Epoch: 1 [4480/6766 (66%)]\tLoss: 1.117149\n",
      "Train Epoch: 1 [5120/6766 (75%)]\tLoss: 1.090137\n",
      "Train Epoch: 1 [5760/6766 (85%)]\tLoss: 1.120156\n",
      "Train Epoch: 1 [6400/6766 (94%)]\tLoss: 1.331827\n",
      "Train Epoch: 2 [0/6766 (0%)]\tLoss: 0.990376\n",
      "Train Epoch: 2 [640/6766 (9%)]\tLoss: 1.061106\n",
      "Train Epoch: 2 [1280/6766 (19%)]\tLoss: 1.239607\n",
      "Train Epoch: 2 [1920/6766 (28%)]\tLoss: 1.232776\n",
      "Train Epoch: 2 [2560/6766 (38%)]\tLoss: 1.263573\n",
      "Train Epoch: 2 [3200/6766 (47%)]\tLoss: 1.268096\n",
      "Train Epoch: 2 [3840/6766 (57%)]\tLoss: 0.823760\n",
      "Train Epoch: 2 [4480/6766 (66%)]\tLoss: 0.909640\n",
      "Train Epoch: 2 [5120/6766 (75%)]\tLoss: 0.873602\n",
      "Train Epoch: 2 [5760/6766 (85%)]\tLoss: 0.696161\n",
      "Train Epoch: 2 [6400/6766 (94%)]\tLoss: 1.109332\n",
      "Train Epoch: 3 [0/6766 (0%)]\tLoss: 0.718458\n",
      "Train Epoch: 3 [640/6766 (9%)]\tLoss: 0.631092\n",
      "Train Epoch: 3 [1280/6766 (19%)]\tLoss: 0.495482\n",
      "Train Epoch: 3 [1920/6766 (28%)]\tLoss: 0.709006\n",
      "Train Epoch: 3 [2560/6766 (38%)]\tLoss: 0.676414\n",
      "Train Epoch: 3 [3200/6766 (47%)]\tLoss: 0.652839\n",
      "Train Epoch: 3 [3840/6766 (57%)]\tLoss: 0.442132\n",
      "Train Epoch: 3 [4480/6766 (66%)]\tLoss: 0.545665\n",
      "Train Epoch: 3 [5120/6766 (75%)]\tLoss: 0.589265\n",
      "Train Epoch: 3 [5760/6766 (85%)]\tLoss: 0.596994\n",
      "Train Epoch: 3 [6400/6766 (94%)]\tLoss: 0.678364\n",
      "Train Epoch: 4 [0/6766 (0%)]\tLoss: 0.632754\n",
      "Train Epoch: 4 [640/6766 (9%)]\tLoss: 0.507435\n",
      "Train Epoch: 4 [1280/6766 (19%)]\tLoss: 0.510589\n",
      "Train Epoch: 4 [1920/6766 (28%)]\tLoss: 0.357527\n",
      "Train Epoch: 4 [2560/6766 (38%)]\tLoss: 0.436736\n",
      "Train Epoch: 4 [3200/6766 (47%)]\tLoss: 0.315502\n",
      "Train Epoch: 4 [3840/6766 (57%)]\tLoss: 0.381868\n",
      "Train Epoch: 4 [4480/6766 (66%)]\tLoss: 0.310256\n",
      "Train Epoch: 4 [5120/6766 (75%)]\tLoss: 0.574013\n",
      "Train Epoch: 4 [5760/6766 (85%)]\tLoss: 0.319341\n",
      "Train Epoch: 4 [6400/6766 (94%)]\tLoss: 0.336405\n",
      "Train Epoch: 5 [0/6766 (0%)]\tLoss: 0.890101\n",
      "Train Epoch: 5 [640/6766 (9%)]\tLoss: 0.672390\n",
      "Train Epoch: 5 [1280/6766 (19%)]\tLoss: 0.336629\n",
      "Train Epoch: 5 [1920/6766 (28%)]\tLoss: 0.340262\n",
      "Train Epoch: 5 [2560/6766 (38%)]\tLoss: 0.288841\n",
      "Train Epoch: 5 [3200/6766 (47%)]\tLoss: 0.277425\n",
      "Train Epoch: 5 [3840/6766 (57%)]\tLoss: 0.246979\n",
      "Train Epoch: 5 [4480/6766 (66%)]\tLoss: 0.518586\n",
      "Train Epoch: 5 [5120/6766 (75%)]\tLoss: 0.324169\n",
      "Train Epoch: 5 [5760/6766 (85%)]\tLoss: 0.392844\n",
      "Train Epoch: 5 [6400/6766 (94%)]\tLoss: 0.263626\n",
      "Train Epoch: 6 [0/6766 (0%)]\tLoss: 0.376428\n",
      "Train Epoch: 6 [640/6766 (9%)]\tLoss: 0.461871\n",
      "Train Epoch: 6 [1280/6766 (19%)]\tLoss: 0.262239\n",
      "Train Epoch: 6 [1920/6766 (28%)]\tLoss: 0.553058\n",
      "Train Epoch: 6 [2560/6766 (38%)]\tLoss: 0.172652\n",
      "Train Epoch: 6 [3200/6766 (47%)]\tLoss: 0.321898\n",
      "Train Epoch: 6 [3840/6766 (57%)]\tLoss: 0.392497\n",
      "Train Epoch: 6 [4480/6766 (66%)]\tLoss: 0.295599\n",
      "Train Epoch: 6 [5120/6766 (75%)]\tLoss: 0.229180\n",
      "Train Epoch: 6 [5760/6766 (85%)]\tLoss: 0.214459\n",
      "Train Epoch: 6 [6400/6766 (94%)]\tLoss: 0.228098\n",
      "Train Epoch: 7 [0/6766 (0%)]\tLoss: 0.434070\n",
      "Train Epoch: 7 [640/6766 (9%)]\tLoss: 0.268289\n",
      "Train Epoch: 7 [1280/6766 (19%)]\tLoss: 0.337950\n",
      "Train Epoch: 7 [1920/6766 (28%)]\tLoss: 0.257753\n",
      "Train Epoch: 7 [2560/6766 (38%)]\tLoss: 0.349984\n",
      "Train Epoch: 7 [3200/6766 (47%)]\tLoss: 0.323489\n",
      "Train Epoch: 7 [3840/6766 (57%)]\tLoss: 0.352962\n",
      "Train Epoch: 7 [4480/6766 (66%)]\tLoss: 0.460808\n",
      "Train Epoch: 7 [5120/6766 (75%)]\tLoss: 0.100415\n",
      "Train Epoch: 7 [5760/6766 (85%)]\tLoss: 0.170210\n",
      "Train Epoch: 7 [6400/6766 (94%)]\tLoss: 0.228099\n",
      "Train Epoch: 8 [0/6766 (0%)]\tLoss: 0.461621\n",
      "Train Epoch: 8 [640/6766 (9%)]\tLoss: 0.337943\n",
      "Train Epoch: 8 [1280/6766 (19%)]\tLoss: 0.347348\n",
      "Train Epoch: 8 [1920/6766 (28%)]\tLoss: 0.234174\n",
      "Train Epoch: 8 [2560/6766 (38%)]\tLoss: 0.429233\n",
      "Train Epoch: 8 [3200/6766 (47%)]\tLoss: 0.380276\n",
      "Train Epoch: 8 [3840/6766 (57%)]\tLoss: 0.282935\n",
      "Train Epoch: 8 [4480/6766 (66%)]\tLoss: 0.296049\n",
      "Train Epoch: 8 [5120/6766 (75%)]\tLoss: 0.255291\n",
      "Train Epoch: 8 [5760/6766 (85%)]\tLoss: 0.194114\n",
      "Train Epoch: 8 [6400/6766 (94%)]\tLoss: 0.273907\n",
      "Train Epoch: 9 [0/6766 (0%)]\tLoss: 0.240045\n",
      "Train Epoch: 9 [640/6766 (9%)]\tLoss: 0.196791\n",
      "Train Epoch: 9 [1280/6766 (19%)]\tLoss: 0.276153\n",
      "Train Epoch: 9 [1920/6766 (28%)]\tLoss: 0.215242\n",
      "Train Epoch: 9 [2560/6766 (38%)]\tLoss: 0.163304\n",
      "Train Epoch: 9 [3200/6766 (47%)]\tLoss: 0.262245\n",
      "Train Epoch: 9 [3840/6766 (57%)]\tLoss: 0.288246\n",
      "Train Epoch: 9 [4480/6766 (66%)]\tLoss: 0.212176\n",
      "Train Epoch: 9 [5120/6766 (75%)]\tLoss: 0.092034\n",
      "Train Epoch: 9 [5760/6766 (85%)]\tLoss: 0.188093\n",
      "Train Epoch: 9 [6400/6766 (94%)]\tLoss: 0.164082\n",
      "Train Epoch: 10 [0/6766 (0%)]\tLoss: 0.166315\n",
      "Train Epoch: 10 [640/6766 (9%)]\tLoss: 0.129071\n",
      "Train Epoch: 10 [1280/6766 (19%)]\tLoss: 0.376725\n",
      "Train Epoch: 10 [1920/6766 (28%)]\tLoss: 0.128361\n",
      "Train Epoch: 10 [2560/6766 (38%)]\tLoss: 0.267459\n",
      "Train Epoch: 10 [3200/6766 (47%)]\tLoss: 0.101033\n",
      "Train Epoch: 10 [3840/6766 (57%)]\tLoss: 0.250110\n",
      "Train Epoch: 10 [4480/6766 (66%)]\tLoss: 0.402663\n",
      "Train Epoch: 10 [5120/6766 (75%)]\tLoss: 0.264301\n",
      "Train Epoch: 10 [5760/6766 (85%)]\tLoss: 0.254932\n",
      "Train Epoch: 10 [6400/6766 (94%)]\tLoss: 0.418487\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 2.361228\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 2.265939\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 2.178211\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 2.023906\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 1.834339\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 1.816396\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 1.641122\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 1.497507\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 1.549410\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 1.395608\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 1.340745\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 1.102709\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 1.471341\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 1.139727\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 1.184130\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 1.198548\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 1.322127\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.985997\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.805335\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.946051\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.765568\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.748308\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.707462\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.802381\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.912618\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.756531\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.778779\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.680702\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.645544\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.493875\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.538688\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.628967\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.558639\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.600959\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.611840\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.511781\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.440531\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.511197\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.486108\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.492469\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.382620\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.469428\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.554306\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.397071\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.674486\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.464769\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.301933\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.309274\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.610515\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.399326\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.575889\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.471113\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.455097\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.430937\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.452604\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.323173\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.426896\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.331848\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.433739\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.422148\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.449150\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.382240\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.396449\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.423311\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.390273\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.334241\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.205393\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.269107\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.408352\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.472247\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.247896\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.605258\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.417206\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.368340\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.472922\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.454641\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.319394\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.435419\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.347855\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.283504\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.408091\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.287101\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.492338\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.382530\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.469576\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.245805\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.401973\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.181694\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.375378\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.423186\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.292531\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.359158\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.387336\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.263429\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.174172\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.374563\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.382332\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.359464\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.313150\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.308965\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.360598\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.290160\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.188827\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.160411\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.351649\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.207457\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.215980\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.393922\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.477153\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.317730\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.235528\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.310190\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.261200\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.254595\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.249483\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.356794\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.492851\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.213236\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.205152\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.319949\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.400978\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.222502\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.266955\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.218567\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.322117\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.260953\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.299801\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.286764\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.138674\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.183025\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.239003\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.195496\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.316460\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.247076\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.236154\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.483497\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.256662\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.351741\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.315363\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.291697\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.248677\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.240694\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.319087\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.323814\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.135525\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.288652\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.250800\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.128943\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.117959\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.255211\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.304953\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.304249\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.542486\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.179615\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.153880\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.291328\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.225612\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.207865\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.131059\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.177984\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/3910 (0%)]\tLoss: 2.239805\n",
      "Train Epoch: 1 [640/3910 (16%)]\tLoss: 2.131834\n",
      "Train Epoch: 1 [1280/3910 (32%)]\tLoss: 1.894077\n",
      "Train Epoch: 1 [1920/3910 (48%)]\tLoss: 1.719185\n",
      "Train Epoch: 1 [2560/3910 (65%)]\tLoss: 1.449105\n",
      "Train Epoch: 1 [3200/3910 (81%)]\tLoss: 1.459275\n",
      "Train Epoch: 1 [3840/3910 (97%)]\tLoss: 1.628700\n",
      "Train Epoch: 2 [0/3910 (0%)]\tLoss: 1.502386\n",
      "Train Epoch: 2 [640/3910 (16%)]\tLoss: 1.277283\n",
      "Train Epoch: 2 [1280/3910 (32%)]\tLoss: 1.267644\n",
      "Train Epoch: 2 [1920/3910 (48%)]\tLoss: 1.213197\n",
      "Train Epoch: 2 [2560/3910 (65%)]\tLoss: 1.238228\n",
      "Train Epoch: 2 [3200/3910 (81%)]\tLoss: 1.388208\n",
      "Train Epoch: 2 [3840/3910 (97%)]\tLoss: 1.283051\n",
      "Train Epoch: 3 [0/3910 (0%)]\tLoss: 1.067103\n",
      "Train Epoch: 3 [640/3910 (16%)]\tLoss: 1.316416\n",
      "Train Epoch: 3 [1280/3910 (32%)]\tLoss: 1.165719\n",
      "Train Epoch: 3 [1920/3910 (48%)]\tLoss: 1.111950\n",
      "Train Epoch: 3 [2560/3910 (65%)]\tLoss: 1.152112\n",
      "Train Epoch: 3 [3200/3910 (81%)]\tLoss: 1.084878\n",
      "Train Epoch: 3 [3840/3910 (97%)]\tLoss: 0.886474\n",
      "Train Epoch: 4 [0/3910 (0%)]\tLoss: 0.993753\n",
      "Train Epoch: 4 [640/3910 (16%)]\tLoss: 1.028895\n",
      "Train Epoch: 4 [1280/3910 (32%)]\tLoss: 0.858261\n",
      "Train Epoch: 4 [1920/3910 (48%)]\tLoss: 1.179344\n",
      "Train Epoch: 4 [2560/3910 (65%)]\tLoss: 0.704925\n",
      "Train Epoch: 4 [3200/3910 (81%)]\tLoss: 0.789017\n",
      "Train Epoch: 4 [3840/3910 (97%)]\tLoss: 0.817765\n",
      "Train Epoch: 5 [0/3910 (0%)]\tLoss: 0.760513\n",
      "Train Epoch: 5 [640/3910 (16%)]\tLoss: 0.940012\n",
      "Train Epoch: 5 [1280/3910 (32%)]\tLoss: 0.668623\n",
      "Train Epoch: 5 [1920/3910 (48%)]\tLoss: 0.830560\n",
      "Train Epoch: 5 [2560/3910 (65%)]\tLoss: 0.589793\n",
      "Train Epoch: 5 [3200/3910 (81%)]\tLoss: 0.600457\n",
      "Train Epoch: 5 [3840/3910 (97%)]\tLoss: 0.632839\n",
      "Train Epoch: 6 [0/3910 (0%)]\tLoss: 0.510592\n",
      "Train Epoch: 6 [640/3910 (16%)]\tLoss: 0.523935\n",
      "Train Epoch: 6 [1280/3910 (32%)]\tLoss: 0.913239\n",
      "Train Epoch: 6 [1920/3910 (48%)]\tLoss: 0.782757\n",
      "Train Epoch: 6 [2560/3910 (65%)]\tLoss: 0.413459\n",
      "Train Epoch: 6 [3200/3910 (81%)]\tLoss: 0.545897\n",
      "Train Epoch: 6 [3840/3910 (97%)]\tLoss: 0.570547\n",
      "Train Epoch: 7 [0/3910 (0%)]\tLoss: 0.578734\n",
      "Train Epoch: 7 [640/3910 (16%)]\tLoss: 0.619963\n",
      "Train Epoch: 7 [1280/3910 (32%)]\tLoss: 0.414620\n",
      "Train Epoch: 7 [1920/3910 (48%)]\tLoss: 0.326866\n",
      "Train Epoch: 7 [2560/3910 (65%)]\tLoss: 0.449979\n",
      "Train Epoch: 7 [3200/3910 (81%)]\tLoss: 0.319210\n",
      "Train Epoch: 7 [3840/3910 (97%)]\tLoss: 0.460549\n",
      "Train Epoch: 8 [0/3910 (0%)]\tLoss: 0.360433\n",
      "Train Epoch: 8 [640/3910 (16%)]\tLoss: 0.509028\n",
      "Train Epoch: 8 [1280/3910 (32%)]\tLoss: 0.482094\n",
      "Train Epoch: 8 [1920/3910 (48%)]\tLoss: 0.444172\n",
      "Train Epoch: 8 [2560/3910 (65%)]\tLoss: 0.572747\n",
      "Train Epoch: 8 [3200/3910 (81%)]\tLoss: 0.539144\n",
      "Train Epoch: 8 [3840/3910 (97%)]\tLoss: 0.628783\n",
      "Train Epoch: 9 [0/3910 (0%)]\tLoss: 0.417560\n",
      "Train Epoch: 9 [640/3910 (16%)]\tLoss: 0.388293\n",
      "Train Epoch: 9 [1280/3910 (32%)]\tLoss: 0.290008\n",
      "Train Epoch: 9 [1920/3910 (48%)]\tLoss: 0.240683\n",
      "Train Epoch: 9 [2560/3910 (65%)]\tLoss: 0.545318\n",
      "Train Epoch: 9 [3200/3910 (81%)]\tLoss: 0.414388\n",
      "Train Epoch: 9 [3840/3910 (97%)]\tLoss: 0.284150\n",
      "Train Epoch: 10 [0/3910 (0%)]\tLoss: 0.192354\n",
      "Train Epoch: 10 [640/3910 (16%)]\tLoss: 0.611607\n",
      "Train Epoch: 10 [1280/3910 (32%)]\tLoss: 0.423491\n",
      "Train Epoch: 10 [1920/3910 (48%)]\tLoss: 0.699043\n",
      "Train Epoch: 10 [2560/3910 (65%)]\tLoss: 0.452978\n",
      "Train Epoch: 10 [3200/3910 (81%)]\tLoss: 0.379105\n",
      "Train Epoch: 10 [3840/3910 (97%)]\tLoss: 0.229163\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 2.305761\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 2.185378\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 1.935385\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 1.562588\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 1.403570\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 1.307285\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 1.329724\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 1.212965\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 1.075140\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 1.056031\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.903408\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.926737\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 1.187688\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 1.158115\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 1.114933\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.881029\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.738838\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.990758\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.454184\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.625829\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.573238\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.592736\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.635621\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.511871\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.423526\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.670695\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.608904\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.347426\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.545707\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.532389\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.532529\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.697953\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.450788\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.576525\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.480939\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.327941\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.695965\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.288289\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.551495\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.576528\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.583872\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.180151\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.677189\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.523430\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.511998\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.508640\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.323498\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.318354\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.467863\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.518639\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.427003\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.275174\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.435577\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.423759\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.337101\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.204039\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.423506\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.529444\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.258193\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.274538\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.406565\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.190932\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.364909\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.306931\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.394672\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.266075\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.636244\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.435315\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.191050\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.282792\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.481987\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.221720\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.332828\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.288905\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.128876\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.255088\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.168898\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.614788\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.180609\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.232002\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.359671\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.268254\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.240050\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.459710\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.173027\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.341671\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.288264\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.246701\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.332684\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.118817\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.157533\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.164961\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.203476\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.477889\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.249305\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.404954\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.303558\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.169897\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.273230\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.162920\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.289307\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.207303\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.286413\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.246478\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.193523\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.316696\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.287186\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.152368\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.255888\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.318384\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.316396\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.237252\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.247922\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.225508\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.224208\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.136974\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.195656\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.162034\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.179053\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.505947\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/5096 (0%)]\tLoss: 2.293896\n",
      "Train Epoch: 1 [640/5096 (12%)]\tLoss: 2.111773\n",
      "Train Epoch: 1 [1280/5096 (25%)]\tLoss: 1.530355\n",
      "Train Epoch: 1 [1920/5096 (38%)]\tLoss: 1.034441\n",
      "Train Epoch: 1 [2560/5096 (50%)]\tLoss: 0.798751\n",
      "Train Epoch: 1 [3200/5096 (62%)]\tLoss: 0.889472\n",
      "Train Epoch: 1 [3840/5096 (75%)]\tLoss: 1.061163\n",
      "Train Epoch: 1 [4480/5096 (88%)]\tLoss: 0.952654\n",
      "Train Epoch: 2 [0/5096 (0%)]\tLoss: 1.088557\n",
      "Train Epoch: 2 [640/5096 (12%)]\tLoss: 0.917145\n",
      "Train Epoch: 2 [1280/5096 (25%)]\tLoss: 0.964512\n",
      "Train Epoch: 2 [1920/5096 (38%)]\tLoss: 0.866836\n",
      "Train Epoch: 2 [2560/5096 (50%)]\tLoss: 1.109380\n",
      "Train Epoch: 2 [3200/5096 (62%)]\tLoss: 1.054086\n",
      "Train Epoch: 2 [3840/5096 (75%)]\tLoss: 1.080418\n",
      "Train Epoch: 2 [4480/5096 (88%)]\tLoss: 1.286224\n",
      "Train Epoch: 3 [0/5096 (0%)]\tLoss: 1.181026\n",
      "Train Epoch: 3 [640/5096 (12%)]\tLoss: 0.667845\n",
      "Train Epoch: 3 [1280/5096 (25%)]\tLoss: 1.110492\n",
      "Train Epoch: 3 [1920/5096 (38%)]\tLoss: 0.842790\n",
      "Train Epoch: 3 [2560/5096 (50%)]\tLoss: 0.789239\n",
      "Train Epoch: 3 [3200/5096 (62%)]\tLoss: 0.923215\n",
      "Train Epoch: 3 [3840/5096 (75%)]\tLoss: 0.821913\n",
      "Train Epoch: 3 [4480/5096 (88%)]\tLoss: 0.898386\n",
      "Train Epoch: 4 [0/5096 (0%)]\tLoss: 0.782722\n",
      "Train Epoch: 4 [640/5096 (12%)]\tLoss: 0.707203\n",
      "Train Epoch: 4 [1280/5096 (25%)]\tLoss: 0.649098\n",
      "Train Epoch: 4 [1920/5096 (38%)]\tLoss: 0.486856\n",
      "Train Epoch: 4 [2560/5096 (50%)]\tLoss: 0.626601\n",
      "Train Epoch: 4 [3200/5096 (62%)]\tLoss: 0.659311\n",
      "Train Epoch: 4 [3840/5096 (75%)]\tLoss: 0.619041\n",
      "Train Epoch: 4 [4480/5096 (88%)]\tLoss: 0.659099\n",
      "Train Epoch: 5 [0/5096 (0%)]\tLoss: 0.950598\n",
      "Train Epoch: 5 [640/5096 (12%)]\tLoss: 0.461008\n",
      "Train Epoch: 5 [1280/5096 (25%)]\tLoss: 0.516561\n",
      "Train Epoch: 5 [1920/5096 (38%)]\tLoss: 0.402840\n",
      "Train Epoch: 5 [2560/5096 (50%)]\tLoss: 0.779585\n",
      "Train Epoch: 5 [3200/5096 (62%)]\tLoss: 0.548250\n",
      "Train Epoch: 5 [3840/5096 (75%)]\tLoss: 0.314896\n",
      "Train Epoch: 5 [4480/5096 (88%)]\tLoss: 0.400005\n",
      "Train Epoch: 6 [0/5096 (0%)]\tLoss: 0.412655\n",
      "Train Epoch: 6 [640/5096 (12%)]\tLoss: 0.599782\n",
      "Train Epoch: 6 [1280/5096 (25%)]\tLoss: 0.521129\n",
      "Train Epoch: 6 [1920/5096 (38%)]\tLoss: 0.574726\n",
      "Train Epoch: 6 [2560/5096 (50%)]\tLoss: 0.188656\n",
      "Train Epoch: 6 [3200/5096 (62%)]\tLoss: 0.705578\n",
      "Train Epoch: 6 [3840/5096 (75%)]\tLoss: 0.429112\n",
      "Train Epoch: 6 [4480/5096 (88%)]\tLoss: 0.181204\n",
      "Train Epoch: 7 [0/5096 (0%)]\tLoss: 0.327167\n",
      "Train Epoch: 7 [640/5096 (12%)]\tLoss: 0.314276\n",
      "Train Epoch: 7 [1280/5096 (25%)]\tLoss: 0.329262\n",
      "Train Epoch: 7 [1920/5096 (38%)]\tLoss: 0.327961\n",
      "Train Epoch: 7 [2560/5096 (50%)]\tLoss: 0.342852\n",
      "Train Epoch: 7 [3200/5096 (62%)]\tLoss: 0.463863\n",
      "Train Epoch: 7 [3840/5096 (75%)]\tLoss: 0.427769\n",
      "Train Epoch: 7 [4480/5096 (88%)]\tLoss: 0.417436\n",
      "Train Epoch: 8 [0/5096 (0%)]\tLoss: 0.262153\n",
      "Train Epoch: 8 [640/5096 (12%)]\tLoss: 0.217472\n",
      "Train Epoch: 8 [1280/5096 (25%)]\tLoss: 0.468109\n",
      "Train Epoch: 8 [1920/5096 (38%)]\tLoss: 0.332537\n",
      "Train Epoch: 8 [2560/5096 (50%)]\tLoss: 0.208874\n",
      "Train Epoch: 8 [3200/5096 (62%)]\tLoss: 0.349892\n",
      "Train Epoch: 8 [3840/5096 (75%)]\tLoss: 0.215864\n",
      "Train Epoch: 8 [4480/5096 (88%)]\tLoss: 0.303546\n",
      "Train Epoch: 9 [0/5096 (0%)]\tLoss: 0.336114\n",
      "Train Epoch: 9 [640/5096 (12%)]\tLoss: 0.338111\n",
      "Train Epoch: 9 [1280/5096 (25%)]\tLoss: 0.382984\n",
      "Train Epoch: 9 [1920/5096 (38%)]\tLoss: 0.359215\n",
      "Train Epoch: 9 [2560/5096 (50%)]\tLoss: 0.298921\n",
      "Train Epoch: 9 [3200/5096 (62%)]\tLoss: 0.218492\n",
      "Train Epoch: 9 [3840/5096 (75%)]\tLoss: 0.264558\n",
      "Train Epoch: 9 [4480/5096 (88%)]\tLoss: 0.356681\n",
      "Train Epoch: 10 [0/5096 (0%)]\tLoss: 0.462653\n",
      "Train Epoch: 10 [640/5096 (12%)]\tLoss: 0.341174\n",
      "Train Epoch: 10 [1280/5096 (25%)]\tLoss: 0.230564\n",
      "Train Epoch: 10 [1920/5096 (38%)]\tLoss: 0.358675\n",
      "Train Epoch: 10 [2560/5096 (50%)]\tLoss: 0.360942\n",
      "Train Epoch: 10 [3200/5096 (62%)]\tLoss: 0.197271\n",
      "Train Epoch: 10 [3840/5096 (75%)]\tLoss: 0.319709\n",
      "Train Epoch: 10 [4480/5096 (88%)]\tLoss: 0.257582\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/1599 (0%)]\tLoss: 2.250093\n",
      "Train Epoch: 1 [640/1599 (40%)]\tLoss: 2.140404\n",
      "Train Epoch: 1 [1280/1599 (80%)]\tLoss: 1.890833\n",
      "Train Epoch: 2 [0/1599 (0%)]\tLoss: 1.766469\n",
      "Train Epoch: 2 [640/1599 (40%)]\tLoss: 1.537447\n",
      "Train Epoch: 2 [1280/1599 (80%)]\tLoss: 1.399942\n",
      "Train Epoch: 3 [0/1599 (0%)]\tLoss: 1.646832\n",
      "Train Epoch: 3 [640/1599 (40%)]\tLoss: 1.376273\n",
      "Train Epoch: 3 [1280/1599 (80%)]\tLoss: 1.353951\n",
      "Train Epoch: 4 [0/1599 (0%)]\tLoss: 1.496523\n",
      "Train Epoch: 4 [640/1599 (40%)]\tLoss: 1.073843\n",
      "Train Epoch: 4 [1280/1599 (80%)]\tLoss: 1.262072\n",
      "Train Epoch: 5 [0/1599 (0%)]\tLoss: 1.332629\n",
      "Train Epoch: 5 [640/1599 (40%)]\tLoss: 0.969088\n",
      "Train Epoch: 5 [1280/1599 (80%)]\tLoss: 1.210946\n",
      "Train Epoch: 6 [0/1599 (0%)]\tLoss: 1.034822\n",
      "Train Epoch: 6 [640/1599 (40%)]\tLoss: 1.102785\n",
      "Train Epoch: 6 [1280/1599 (80%)]\tLoss: 1.292626\n",
      "Train Epoch: 7 [0/1599 (0%)]\tLoss: 1.248920\n",
      "Train Epoch: 7 [640/1599 (40%)]\tLoss: 1.075395\n",
      "Train Epoch: 7 [1280/1599 (80%)]\tLoss: 0.987488\n",
      "Train Epoch: 8 [0/1599 (0%)]\tLoss: 0.872609\n",
      "Train Epoch: 8 [640/1599 (40%)]\tLoss: 1.124091\n",
      "Train Epoch: 8 [1280/1599 (80%)]\tLoss: 1.020328\n",
      "Train Epoch: 9 [0/1599 (0%)]\tLoss: 1.090736\n",
      "Train Epoch: 9 [640/1599 (40%)]\tLoss: 1.084389\n",
      "Train Epoch: 9 [1280/1599 (80%)]\tLoss: 0.716230\n",
      "Train Epoch: 10 [0/1599 (0%)]\tLoss: 1.047720\n",
      "Train Epoch: 10 [640/1599 (40%)]\tLoss: 0.670101\n",
      "Train Epoch: 10 [1280/1599 (80%)]\tLoss: 0.746020\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/5266 (0%)]\tLoss: 2.344172\n",
      "Train Epoch: 1 [640/5266 (12%)]\tLoss: 1.875157\n",
      "Train Epoch: 1 [1280/5266 (24%)]\tLoss: 0.766982\n",
      "Train Epoch: 1 [1920/5266 (36%)]\tLoss: 0.503612\n",
      "Train Epoch: 1 [2560/5266 (48%)]\tLoss: 0.640794\n",
      "Train Epoch: 1 [3200/5266 (60%)]\tLoss: 0.350580\n",
      "Train Epoch: 1 [3840/5266 (72%)]\tLoss: 0.446372\n",
      "Train Epoch: 1 [4480/5266 (84%)]\tLoss: 0.621570\n",
      "Train Epoch: 1 [5120/5266 (96%)]\tLoss: 0.471032\n",
      "Train Epoch: 2 [0/5266 (0%)]\tLoss: 0.849293\n",
      "Train Epoch: 2 [640/5266 (12%)]\tLoss: 0.957363\n",
      "Train Epoch: 2 [1280/5266 (24%)]\tLoss: 0.557781\n",
      "Train Epoch: 2 [1920/5266 (36%)]\tLoss: 0.449628\n",
      "Train Epoch: 2 [2560/5266 (48%)]\tLoss: 0.611096\n",
      "Train Epoch: 2 [3200/5266 (60%)]\tLoss: 0.731822\n",
      "Train Epoch: 2 [3840/5266 (72%)]\tLoss: 0.514214\n",
      "Train Epoch: 2 [4480/5266 (84%)]\tLoss: 0.638107\n",
      "Train Epoch: 2 [5120/5266 (96%)]\tLoss: 0.567767\n",
      "Train Epoch: 3 [0/5266 (0%)]\tLoss: 0.522736\n",
      "Train Epoch: 3 [640/5266 (12%)]\tLoss: 0.594396\n",
      "Train Epoch: 3 [1280/5266 (24%)]\tLoss: 0.574023\n",
      "Train Epoch: 3 [1920/5266 (36%)]\tLoss: 0.222299\n",
      "Train Epoch: 3 [2560/5266 (48%)]\tLoss: 0.560836\n",
      "Train Epoch: 3 [3200/5266 (60%)]\tLoss: 0.429687\n",
      "Train Epoch: 3 [3840/5266 (72%)]\tLoss: 0.636538\n",
      "Train Epoch: 3 [4480/5266 (84%)]\tLoss: 0.306417\n",
      "Train Epoch: 3 [5120/5266 (96%)]\tLoss: 0.432469\n",
      "Train Epoch: 4 [0/5266 (0%)]\tLoss: 0.430351\n",
      "Train Epoch: 4 [640/5266 (12%)]\tLoss: 0.372787\n",
      "Train Epoch: 4 [1280/5266 (24%)]\tLoss: 0.496591\n",
      "Train Epoch: 4 [1920/5266 (36%)]\tLoss: 0.322808\n",
      "Train Epoch: 4 [2560/5266 (48%)]\tLoss: 0.440614\n",
      "Train Epoch: 4 [3200/5266 (60%)]\tLoss: 0.556274\n",
      "Train Epoch: 4 [3840/5266 (72%)]\tLoss: 0.605890\n",
      "Train Epoch: 4 [4480/5266 (84%)]\tLoss: 0.438327\n",
      "Train Epoch: 4 [5120/5266 (96%)]\tLoss: 0.318026\n",
      "Train Epoch: 5 [0/5266 (0%)]\tLoss: 0.499870\n",
      "Train Epoch: 5 [640/5266 (12%)]\tLoss: 0.276407\n",
      "Train Epoch: 5 [1280/5266 (24%)]\tLoss: 0.454930\n",
      "Train Epoch: 5 [1920/5266 (36%)]\tLoss: 0.278348\n",
      "Train Epoch: 5 [2560/5266 (48%)]\tLoss: 0.271635\n",
      "Train Epoch: 5 [3200/5266 (60%)]\tLoss: 0.180080\n",
      "Train Epoch: 5 [3840/5266 (72%)]\tLoss: 0.239630\n",
      "Train Epoch: 5 [4480/5266 (84%)]\tLoss: 0.297226\n",
      "Train Epoch: 5 [5120/5266 (96%)]\tLoss: 0.340795\n",
      "Train Epoch: 6 [0/5266 (0%)]\tLoss: 0.311595\n",
      "Train Epoch: 6 [640/5266 (12%)]\tLoss: 0.190858\n",
      "Train Epoch: 6 [1280/5266 (24%)]\tLoss: 0.274660\n",
      "Train Epoch: 6 [1920/5266 (36%)]\tLoss: 0.080174\n",
      "Train Epoch: 6 [2560/5266 (48%)]\tLoss: 0.278334\n",
      "Train Epoch: 6 [3200/5266 (60%)]\tLoss: 0.175380\n",
      "Train Epoch: 6 [3840/5266 (72%)]\tLoss: 0.175357\n",
      "Train Epoch: 6 [4480/5266 (84%)]\tLoss: 0.187473\n",
      "Train Epoch: 6 [5120/5266 (96%)]\tLoss: 0.265828\n",
      "Train Epoch: 7 [0/5266 (0%)]\tLoss: 0.269773\n",
      "Train Epoch: 7 [640/5266 (12%)]\tLoss: 0.277392\n",
      "Train Epoch: 7 [1280/5266 (24%)]\tLoss: 0.215471\n",
      "Train Epoch: 7 [1920/5266 (36%)]\tLoss: 0.297965\n",
      "Train Epoch: 7 [2560/5266 (48%)]\tLoss: 0.227193\n",
      "Train Epoch: 7 [3200/5266 (60%)]\tLoss: 0.160891\n",
      "Train Epoch: 7 [3840/5266 (72%)]\tLoss: 0.258302\n",
      "Train Epoch: 7 [4480/5266 (84%)]\tLoss: 0.114510\n",
      "Train Epoch: 7 [5120/5266 (96%)]\tLoss: 0.175571\n",
      "Train Epoch: 8 [0/5266 (0%)]\tLoss: 0.315386\n",
      "Train Epoch: 8 [640/5266 (12%)]\tLoss: 0.090907\n",
      "Train Epoch: 8 [1280/5266 (24%)]\tLoss: 0.295841\n",
      "Train Epoch: 8 [1920/5266 (36%)]\tLoss: 0.169144\n",
      "Train Epoch: 8 [2560/5266 (48%)]\tLoss: 0.244140\n",
      "Train Epoch: 8 [3200/5266 (60%)]\tLoss: 0.175500\n",
      "Train Epoch: 8 [3840/5266 (72%)]\tLoss: 0.180363\n",
      "Train Epoch: 8 [4480/5266 (84%)]\tLoss: 0.192739\n",
      "Train Epoch: 8 [5120/5266 (96%)]\tLoss: 0.253215\n",
      "Train Epoch: 9 [0/5266 (0%)]\tLoss: 0.142344\n",
      "Train Epoch: 9 [640/5266 (12%)]\tLoss: 0.292638\n",
      "Train Epoch: 9 [1280/5266 (24%)]\tLoss: 0.388554\n",
      "Train Epoch: 9 [1920/5266 (36%)]\tLoss: 0.080053\n",
      "Train Epoch: 9 [2560/5266 (48%)]\tLoss: 0.132212\n",
      "Train Epoch: 9 [3200/5266 (60%)]\tLoss: 0.232124\n",
      "Train Epoch: 9 [3840/5266 (72%)]\tLoss: 0.249981\n",
      "Train Epoch: 9 [4480/5266 (84%)]\tLoss: 0.406839\n",
      "Train Epoch: 9 [5120/5266 (96%)]\tLoss: 0.073996\n",
      "Train Epoch: 10 [0/5266 (0%)]\tLoss: 0.424461\n",
      "Train Epoch: 10 [640/5266 (12%)]\tLoss: 0.065154\n",
      "Train Epoch: 10 [1280/5266 (24%)]\tLoss: 0.451923\n",
      "Train Epoch: 10 [1920/5266 (36%)]\tLoss: 0.178155\n",
      "Train Epoch: 10 [2560/5266 (48%)]\tLoss: 0.212757\n",
      "Train Epoch: 10 [3200/5266 (60%)]\tLoss: 0.075585\n",
      "Train Epoch: 10 [3840/5266 (72%)]\tLoss: 0.315726\n",
      "Train Epoch: 10 [4480/5266 (84%)]\tLoss: 0.310735\n",
      "Train Epoch: 10 [5120/5266 (96%)]\tLoss: 0.238204\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/3530 (0%)]\tLoss: 2.319996\n",
      "Train Epoch: 1 [640/3530 (18%)]\tLoss: 2.210991\n",
      "Train Epoch: 1 [1280/3530 (36%)]\tLoss: 1.972694\n",
      "Train Epoch: 1 [1920/3530 (54%)]\tLoss: 1.688770\n",
      "Train Epoch: 1 [2560/3530 (71%)]\tLoss: 1.466042\n",
      "Train Epoch: 1 [3200/3530 (89%)]\tLoss: 1.498443\n",
      "Train Epoch: 2 [0/3530 (0%)]\tLoss: 1.396880\n",
      "Train Epoch: 2 [640/3530 (18%)]\tLoss: 1.489736\n",
      "Train Epoch: 2 [1280/3530 (36%)]\tLoss: 1.320602\n",
      "Train Epoch: 2 [1920/3530 (54%)]\tLoss: 1.356959\n",
      "Train Epoch: 2 [2560/3530 (71%)]\tLoss: 1.521443\n",
      "Train Epoch: 2 [3200/3530 (89%)]\tLoss: 1.191690\n",
      "Train Epoch: 3 [0/3530 (0%)]\tLoss: 1.254543\n",
      "Train Epoch: 3 [640/3530 (18%)]\tLoss: 1.305856\n",
      "Train Epoch: 3 [1280/3530 (36%)]\tLoss: 1.267860\n",
      "Train Epoch: 3 [1920/3530 (54%)]\tLoss: 1.075200\n",
      "Train Epoch: 3 [2560/3530 (71%)]\tLoss: 0.927335\n",
      "Train Epoch: 3 [3200/3530 (89%)]\tLoss: 0.897852\n",
      "Train Epoch: 4 [0/3530 (0%)]\tLoss: 0.870605\n",
      "Train Epoch: 4 [640/3530 (18%)]\tLoss: 0.853265\n",
      "Train Epoch: 4 [1280/3530 (36%)]\tLoss: 0.771547\n",
      "Train Epoch: 4 [1920/3530 (54%)]\tLoss: 0.775259\n",
      "Train Epoch: 4 [2560/3530 (71%)]\tLoss: 0.704614\n",
      "Train Epoch: 4 [3200/3530 (89%)]\tLoss: 0.721876\n",
      "Train Epoch: 5 [0/3530 (0%)]\tLoss: 0.370221\n",
      "Train Epoch: 5 [640/3530 (18%)]\tLoss: 0.645248\n",
      "Train Epoch: 5 [1280/3530 (36%)]\tLoss: 0.621313\n",
      "Train Epoch: 5 [1920/3530 (54%)]\tLoss: 0.813756\n",
      "Train Epoch: 5 [2560/3530 (71%)]\tLoss: 0.608116\n",
      "Train Epoch: 5 [3200/3530 (89%)]\tLoss: 0.380177\n",
      "Train Epoch: 6 [0/3530 (0%)]\tLoss: 0.449696\n",
      "Train Epoch: 6 [640/3530 (18%)]\tLoss: 0.648800\n",
      "Train Epoch: 6 [1280/3530 (36%)]\tLoss: 0.730110\n",
      "Train Epoch: 6 [1920/3530 (54%)]\tLoss: 0.646763\n",
      "Train Epoch: 6 [2560/3530 (71%)]\tLoss: 0.619426\n",
      "Train Epoch: 6 [3200/3530 (89%)]\tLoss: 0.573719\n",
      "Train Epoch: 7 [0/3530 (0%)]\tLoss: 0.793917\n",
      "Train Epoch: 7 [640/3530 (18%)]\tLoss: 0.454587\n",
      "Train Epoch: 7 [1280/3530 (36%)]\tLoss: 0.407545\n",
      "Train Epoch: 7 [1920/3530 (54%)]\tLoss: 0.485403\n",
      "Train Epoch: 7 [2560/3530 (71%)]\tLoss: 0.607345\n",
      "Train Epoch: 7 [3200/3530 (89%)]\tLoss: 0.513534\n",
      "Train Epoch: 8 [0/3530 (0%)]\tLoss: 0.521681\n",
      "Train Epoch: 8 [640/3530 (18%)]\tLoss: 0.549744\n",
      "Train Epoch: 8 [1280/3530 (36%)]\tLoss: 0.454834\n",
      "Train Epoch: 8 [1920/3530 (54%)]\tLoss: 0.615903\n",
      "Train Epoch: 8 [2560/3530 (71%)]\tLoss: 0.559618\n",
      "Train Epoch: 8 [3200/3530 (89%)]\tLoss: 0.586743\n",
      "Train Epoch: 9 [0/3530 (0%)]\tLoss: 0.457477\n",
      "Train Epoch: 9 [640/3530 (18%)]\tLoss: 0.430816\n",
      "Train Epoch: 9 [1280/3530 (36%)]\tLoss: 0.530320\n",
      "Train Epoch: 9 [1920/3530 (54%)]\tLoss: 0.551561\n",
      "Train Epoch: 9 [2560/3530 (71%)]\tLoss: 0.429065\n",
      "Train Epoch: 9 [3200/3530 (89%)]\tLoss: 0.550031\n",
      "Train Epoch: 10 [0/3530 (0%)]\tLoss: 0.551018\n",
      "Train Epoch: 10 [640/3530 (18%)]\tLoss: 0.467109\n",
      "Train Epoch: 10 [1280/3530 (36%)]\tLoss: 0.311540\n",
      "Train Epoch: 10 [1920/3530 (54%)]\tLoss: 0.485640\n",
      "Train Epoch: 10 [2560/3530 (71%)]\tLoss: 0.437782\n",
      "Train Epoch: 10 [3200/3530 (89%)]\tLoss: 0.509092\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 1.6448, Accuracy: 5089/10000 (51%)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 1.855741\n",
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 1.245102\n",
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 0.931898\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 0.705256\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 0.746199\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 0.820231\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 0.564205\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 0.555267\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 0.590234\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 0.348299\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 0.473845\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 0.404349\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 0.386397\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 0.321653\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 0.438132\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 0.523321\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 0.483891\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 0.789871\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 0.537975\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 0.359440\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.244708\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 0.304125\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 0.227163\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.466454\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.333839\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 0.457453\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.432154\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 0.178419\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.537886\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.603776\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.279876\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.475809\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.307439\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.328873\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.396190\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.432625\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.340464\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.273307\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.182562\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.223403\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.357211\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.251947\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.354470\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.408822\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.287235\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.319917\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.230243\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.291989\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.266515\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.347288\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.385295\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.331435\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.095218\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.479936\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.288607\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.175873\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.319781\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.321994\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.344704\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.183059\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.180390\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.245379\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.145456\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.333183\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.212870\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.364977\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.349490\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.314089\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.244165\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.436987\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.424966\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.150903\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.248875\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.228735\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.249102\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.137668\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.319178\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.188842\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.284889\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.283074\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.167307\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.623545\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.158244\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.303894\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.133869\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.306679\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.124659\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.208675\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.204027\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.239696\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.207259\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.287744\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.304775\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.290447\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.234894\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.254810\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.237895\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.371855\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.243917\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.242964\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.454915\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.270964\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.066968\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.359861\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.158412\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.138492\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.187515\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.227139\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 0.195081\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.266007\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.334464\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.236914\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.261793\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.210151\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.193630\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.205694\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.221730\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.198948\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.326866\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.365791\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.209701\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.138274\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.220548\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.059157\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.281074\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.193179\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.260631\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.170370\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.167278\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.165008\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.263922\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.101141\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.176254\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.143721\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.417979\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.040602\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.204258\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.065832\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.163767\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.168778\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.289241\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.527378\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.126669\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.196835\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.076853\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.186114\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.192037\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.128935\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.176567\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.387691\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.165163\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.181841\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.248308\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.184359\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.309227\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.318328\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.192335\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.388984\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.371306\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.409120\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.235550\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.495315\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.378189\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.131982\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.138462\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.297504\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.326732\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.257243\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.374235\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.377296\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.253395\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.199306\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.352028\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.242302\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.155965\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.120538\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.204524\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.263716\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.235582\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.290116\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/5110 (0%)]\tLoss: 1.393540\n",
      "Train Epoch: 1 [640/5110 (12%)]\tLoss: 0.886709\n",
      "Train Epoch: 1 [1280/5110 (25%)]\tLoss: 0.577677\n",
      "Train Epoch: 1 [1920/5110 (38%)]\tLoss: 0.501240\n",
      "Train Epoch: 1 [2560/5110 (50%)]\tLoss: 0.698155\n",
      "Train Epoch: 1 [3200/5110 (62%)]\tLoss: 0.533952\n",
      "Train Epoch: 1 [3840/5110 (75%)]\tLoss: 0.566038\n",
      "Train Epoch: 1 [4480/5110 (88%)]\tLoss: 0.697306\n",
      "Train Epoch: 2 [0/5110 (0%)]\tLoss: 0.477378\n",
      "Train Epoch: 2 [640/5110 (12%)]\tLoss: 0.449871\n",
      "Train Epoch: 2 [1280/5110 (25%)]\tLoss: 0.501847\n",
      "Train Epoch: 2 [1920/5110 (38%)]\tLoss: 0.579044\n",
      "Train Epoch: 2 [2560/5110 (50%)]\tLoss: 0.374038\n",
      "Train Epoch: 2 [3200/5110 (62%)]\tLoss: 0.461118\n",
      "Train Epoch: 2 [3840/5110 (75%)]\tLoss: 0.387814\n",
      "Train Epoch: 2 [4480/5110 (88%)]\tLoss: 0.493216\n",
      "Train Epoch: 3 [0/5110 (0%)]\tLoss: 0.306287\n",
      "Train Epoch: 3 [640/5110 (12%)]\tLoss: 0.353390\n",
      "Train Epoch: 3 [1280/5110 (25%)]\tLoss: 0.505523\n",
      "Train Epoch: 3 [1920/5110 (38%)]\tLoss: 0.448416\n",
      "Train Epoch: 3 [2560/5110 (50%)]\tLoss: 0.540471\n",
      "Train Epoch: 3 [3200/5110 (62%)]\tLoss: 0.263685\n",
      "Train Epoch: 3 [3840/5110 (75%)]\tLoss: 0.440704\n",
      "Train Epoch: 3 [4480/5110 (88%)]\tLoss: 0.282054\n",
      "Train Epoch: 4 [0/5110 (0%)]\tLoss: 0.365409\n",
      "Train Epoch: 4 [640/5110 (12%)]\tLoss: 0.535811\n",
      "Train Epoch: 4 [1280/5110 (25%)]\tLoss: 0.307453\n",
      "Train Epoch: 4 [1920/5110 (38%)]\tLoss: 0.250637\n",
      "Train Epoch: 4 [2560/5110 (50%)]\tLoss: 0.302097\n",
      "Train Epoch: 4 [3200/5110 (62%)]\tLoss: 0.192355\n",
      "Train Epoch: 4 [3840/5110 (75%)]\tLoss: 0.364259\n",
      "Train Epoch: 4 [4480/5110 (88%)]\tLoss: 0.313702\n",
      "Train Epoch: 5 [0/5110 (0%)]\tLoss: 0.388179\n",
      "Train Epoch: 5 [640/5110 (12%)]\tLoss: 0.259221\n",
      "Train Epoch: 5 [1280/5110 (25%)]\tLoss: 0.158845\n",
      "Train Epoch: 5 [1920/5110 (38%)]\tLoss: 0.418549\n",
      "Train Epoch: 5 [2560/5110 (50%)]\tLoss: 0.337281\n",
      "Train Epoch: 5 [3200/5110 (62%)]\tLoss: 0.277262\n",
      "Train Epoch: 5 [3840/5110 (75%)]\tLoss: 0.247857\n",
      "Train Epoch: 5 [4480/5110 (88%)]\tLoss: 0.274596\n",
      "Train Epoch: 6 [0/5110 (0%)]\tLoss: 0.260828\n",
      "Train Epoch: 6 [640/5110 (12%)]\tLoss: 0.293268\n",
      "Train Epoch: 6 [1280/5110 (25%)]\tLoss: 0.374734\n",
      "Train Epoch: 6 [1920/5110 (38%)]\tLoss: 0.161043\n",
      "Train Epoch: 6 [2560/5110 (50%)]\tLoss: 0.342279\n",
      "Train Epoch: 6 [3200/5110 (62%)]\tLoss: 0.240542\n",
      "Train Epoch: 6 [3840/5110 (75%)]\tLoss: 0.322792\n",
      "Train Epoch: 6 [4480/5110 (88%)]\tLoss: 0.401391\n",
      "Train Epoch: 7 [0/5110 (0%)]\tLoss: 0.386908\n",
      "Train Epoch: 7 [640/5110 (12%)]\tLoss: 0.324405\n",
      "Train Epoch: 7 [1280/5110 (25%)]\tLoss: 0.358469\n",
      "Train Epoch: 7 [1920/5110 (38%)]\tLoss: 0.220272\n",
      "Train Epoch: 7 [2560/5110 (50%)]\tLoss: 0.102386\n",
      "Train Epoch: 7 [3200/5110 (62%)]\tLoss: 0.259114\n",
      "Train Epoch: 7 [3840/5110 (75%)]\tLoss: 0.273271\n",
      "Train Epoch: 7 [4480/5110 (88%)]\tLoss: 0.346774\n",
      "Train Epoch: 8 [0/5110 (0%)]\tLoss: 0.337544\n",
      "Train Epoch: 8 [640/5110 (12%)]\tLoss: 0.340973\n",
      "Train Epoch: 8 [1280/5110 (25%)]\tLoss: 0.310007\n",
      "Train Epoch: 8 [1920/5110 (38%)]\tLoss: 0.268196\n",
      "Train Epoch: 8 [2560/5110 (50%)]\tLoss: 0.258153\n",
      "Train Epoch: 8 [3200/5110 (62%)]\tLoss: 0.320142\n",
      "Train Epoch: 8 [3840/5110 (75%)]\tLoss: 0.318031\n",
      "Train Epoch: 8 [4480/5110 (88%)]\tLoss: 0.364016\n",
      "Train Epoch: 9 [0/5110 (0%)]\tLoss: 0.144884\n",
      "Train Epoch: 9 [640/5110 (12%)]\tLoss: 0.243476\n",
      "Train Epoch: 9 [1280/5110 (25%)]\tLoss: 0.243312\n",
      "Train Epoch: 9 [1920/5110 (38%)]\tLoss: 0.315257\n",
      "Train Epoch: 9 [2560/5110 (50%)]\tLoss: 0.137491\n",
      "Train Epoch: 9 [3200/5110 (62%)]\tLoss: 0.273951\n",
      "Train Epoch: 9 [3840/5110 (75%)]\tLoss: 0.178883\n",
      "Train Epoch: 9 [4480/5110 (88%)]\tLoss: 0.481379\n",
      "Train Epoch: 10 [0/5110 (0%)]\tLoss: 0.320011\n",
      "Train Epoch: 10 [640/5110 (12%)]\tLoss: 0.287572\n",
      "Train Epoch: 10 [1280/5110 (25%)]\tLoss: 0.183032\n",
      "Train Epoch: 10 [1920/5110 (38%)]\tLoss: 0.253448\n",
      "Train Epoch: 10 [2560/5110 (50%)]\tLoss: 0.132132\n",
      "Train Epoch: 10 [3200/5110 (62%)]\tLoss: 0.397640\n",
      "Train Epoch: 10 [3840/5110 (75%)]\tLoss: 0.209213\n",
      "Train Epoch: 10 [4480/5110 (88%)]\tLoss: 0.116887\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6766 (0%)]\tLoss: 1.641656\n",
      "Train Epoch: 1 [640/6766 (9%)]\tLoss: 0.710133\n",
      "Train Epoch: 1 [1280/6766 (19%)]\tLoss: 0.725144\n",
      "Train Epoch: 1 [1920/6766 (28%)]\tLoss: 0.825148\n",
      "Train Epoch: 1 [2560/6766 (38%)]\tLoss: 0.481763\n",
      "Train Epoch: 1 [3200/6766 (47%)]\tLoss: 0.420090\n",
      "Train Epoch: 1 [3840/6766 (57%)]\tLoss: 0.478548\n",
      "Train Epoch: 1 [4480/6766 (66%)]\tLoss: 0.357797\n",
      "Train Epoch: 1 [5120/6766 (75%)]\tLoss: 0.496096\n",
      "Train Epoch: 1 [5760/6766 (85%)]\tLoss: 0.252306\n",
      "Train Epoch: 1 [6400/6766 (94%)]\tLoss: 0.490169\n",
      "Train Epoch: 2 [0/6766 (0%)]\tLoss: 0.223275\n",
      "Train Epoch: 2 [640/6766 (9%)]\tLoss: 0.371929\n",
      "Train Epoch: 2 [1280/6766 (19%)]\tLoss: 0.391911\n",
      "Train Epoch: 2 [1920/6766 (28%)]\tLoss: 0.265179\n",
      "Train Epoch: 2 [2560/6766 (38%)]\tLoss: 0.279017\n",
      "Train Epoch: 2 [3200/6766 (47%)]\tLoss: 0.255620\n",
      "Train Epoch: 2 [3840/6766 (57%)]\tLoss: 0.330132\n",
      "Train Epoch: 2 [4480/6766 (66%)]\tLoss: 0.294647\n",
      "Train Epoch: 2 [5120/6766 (75%)]\tLoss: 0.220764\n",
      "Train Epoch: 2 [5760/6766 (85%)]\tLoss: 0.274217\n",
      "Train Epoch: 2 [6400/6766 (94%)]\tLoss: 0.599422\n",
      "Train Epoch: 3 [0/6766 (0%)]\tLoss: 0.363471\n",
      "Train Epoch: 3 [640/6766 (9%)]\tLoss: 0.224258\n",
      "Train Epoch: 3 [1280/6766 (19%)]\tLoss: 0.236161\n",
      "Train Epoch: 3 [1920/6766 (28%)]\tLoss: 0.187794\n",
      "Train Epoch: 3 [2560/6766 (38%)]\tLoss: 0.113499\n",
      "Train Epoch: 3 [3200/6766 (47%)]\tLoss: 0.220139\n",
      "Train Epoch: 3 [3840/6766 (57%)]\tLoss: 0.248698\n",
      "Train Epoch: 3 [4480/6766 (66%)]\tLoss: 0.260296\n",
      "Train Epoch: 3 [5120/6766 (75%)]\tLoss: 0.370413\n",
      "Train Epoch: 3 [5760/6766 (85%)]\tLoss: 0.180037\n",
      "Train Epoch: 3 [6400/6766 (94%)]\tLoss: 0.134712\n",
      "Train Epoch: 4 [0/6766 (0%)]\tLoss: 0.343612\n",
      "Train Epoch: 4 [640/6766 (9%)]\tLoss: 0.199651\n",
      "Train Epoch: 4 [1280/6766 (19%)]\tLoss: 0.222406\n",
      "Train Epoch: 4 [1920/6766 (28%)]\tLoss: 0.230597\n",
      "Train Epoch: 4 [2560/6766 (38%)]\tLoss: 0.256711\n",
      "Train Epoch: 4 [3200/6766 (47%)]\tLoss: 0.191868\n",
      "Train Epoch: 4 [3840/6766 (57%)]\tLoss: 0.288450\n",
      "Train Epoch: 4 [4480/6766 (66%)]\tLoss: 0.211721\n",
      "Train Epoch: 4 [5120/6766 (75%)]\tLoss: 0.428202\n",
      "Train Epoch: 4 [5760/6766 (85%)]\tLoss: 0.242689\n",
      "Train Epoch: 4 [6400/6766 (94%)]\tLoss: 0.117761\n",
      "Train Epoch: 5 [0/6766 (0%)]\tLoss: 0.200516\n",
      "Train Epoch: 5 [640/6766 (9%)]\tLoss: 0.270371\n",
      "Train Epoch: 5 [1280/6766 (19%)]\tLoss: 0.270024\n",
      "Train Epoch: 5 [1920/6766 (28%)]\tLoss: 0.169371\n",
      "Train Epoch: 5 [2560/6766 (38%)]\tLoss: 0.239683\n",
      "Train Epoch: 5 [3200/6766 (47%)]\tLoss: 0.070212\n",
      "Train Epoch: 5 [3840/6766 (57%)]\tLoss: 0.300678\n",
      "Train Epoch: 5 [4480/6766 (66%)]\tLoss: 0.113436\n",
      "Train Epoch: 5 [5120/6766 (75%)]\tLoss: 0.106302\n",
      "Train Epoch: 5 [5760/6766 (85%)]\tLoss: 0.203961\n",
      "Train Epoch: 5 [6400/6766 (94%)]\tLoss: 0.319777\n",
      "Train Epoch: 6 [0/6766 (0%)]\tLoss: 0.155095\n",
      "Train Epoch: 6 [640/6766 (9%)]\tLoss: 0.263518\n",
      "Train Epoch: 6 [1280/6766 (19%)]\tLoss: 0.272966\n",
      "Train Epoch: 6 [1920/6766 (28%)]\tLoss: 0.448487\n",
      "Train Epoch: 6 [2560/6766 (38%)]\tLoss: 0.314756\n",
      "Train Epoch: 6 [3200/6766 (47%)]\tLoss: 0.281456\n",
      "Train Epoch: 6 [3840/6766 (57%)]\tLoss: 0.465028\n",
      "Train Epoch: 6 [4480/6766 (66%)]\tLoss: 0.174885\n",
      "Train Epoch: 6 [5120/6766 (75%)]\tLoss: 0.190673\n",
      "Train Epoch: 6 [5760/6766 (85%)]\tLoss: 0.342244\n",
      "Train Epoch: 6 [6400/6766 (94%)]\tLoss: 0.235525\n",
      "Train Epoch: 7 [0/6766 (0%)]\tLoss: 0.211056\n",
      "Train Epoch: 7 [640/6766 (9%)]\tLoss: 0.286627\n",
      "Train Epoch: 7 [1280/6766 (19%)]\tLoss: 0.180877\n",
      "Train Epoch: 7 [1920/6766 (28%)]\tLoss: 0.295238\n",
      "Train Epoch: 7 [2560/6766 (38%)]\tLoss: 0.130479\n",
      "Train Epoch: 7 [3200/6766 (47%)]\tLoss: 0.276456\n",
      "Train Epoch: 7 [3840/6766 (57%)]\tLoss: 0.131083\n",
      "Train Epoch: 7 [4480/6766 (66%)]\tLoss: 0.431939\n",
      "Train Epoch: 7 [5120/6766 (75%)]\tLoss: 0.312959\n",
      "Train Epoch: 7 [5760/6766 (85%)]\tLoss: 0.146379\n",
      "Train Epoch: 7 [6400/6766 (94%)]\tLoss: 0.158775\n",
      "Train Epoch: 8 [0/6766 (0%)]\tLoss: 0.146183\n",
      "Train Epoch: 8 [640/6766 (9%)]\tLoss: 0.292373\n",
      "Train Epoch: 8 [1280/6766 (19%)]\tLoss: 0.296766\n",
      "Train Epoch: 8 [1920/6766 (28%)]\tLoss: 0.118860\n",
      "Train Epoch: 8 [2560/6766 (38%)]\tLoss: 0.379262\n",
      "Train Epoch: 8 [3200/6766 (47%)]\tLoss: 0.450534\n",
      "Train Epoch: 8 [3840/6766 (57%)]\tLoss: 0.248213\n",
      "Train Epoch: 8 [4480/6766 (66%)]\tLoss: 0.197521\n",
      "Train Epoch: 8 [5120/6766 (75%)]\tLoss: 0.238574\n",
      "Train Epoch: 8 [5760/6766 (85%)]\tLoss: 0.098421\n",
      "Train Epoch: 8 [6400/6766 (94%)]\tLoss: 0.257339\n",
      "Train Epoch: 9 [0/6766 (0%)]\tLoss: 0.113828\n",
      "Train Epoch: 9 [640/6766 (9%)]\tLoss: 0.220823\n",
      "Train Epoch: 9 [1280/6766 (19%)]\tLoss: 0.168534\n",
      "Train Epoch: 9 [1920/6766 (28%)]\tLoss: 0.268570\n",
      "Train Epoch: 9 [2560/6766 (38%)]\tLoss: 0.236474\n",
      "Train Epoch: 9 [3200/6766 (47%)]\tLoss: 0.164528\n",
      "Train Epoch: 9 [3840/6766 (57%)]\tLoss: 0.194456\n",
      "Train Epoch: 9 [4480/6766 (66%)]\tLoss: 0.214708\n",
      "Train Epoch: 9 [5120/6766 (75%)]\tLoss: 0.209939\n",
      "Train Epoch: 9 [5760/6766 (85%)]\tLoss: 0.258174\n",
      "Train Epoch: 9 [6400/6766 (94%)]\tLoss: 0.163110\n",
      "Train Epoch: 10 [0/6766 (0%)]\tLoss: 0.176065\n",
      "Train Epoch: 10 [640/6766 (9%)]\tLoss: 0.202896\n",
      "Train Epoch: 10 [1280/6766 (19%)]\tLoss: 0.176780\n",
      "Train Epoch: 10 [1920/6766 (28%)]\tLoss: 0.165211\n",
      "Train Epoch: 10 [2560/6766 (38%)]\tLoss: 0.180001\n",
      "Train Epoch: 10 [3200/6766 (47%)]\tLoss: 0.217662\n",
      "Train Epoch: 10 [3840/6766 (57%)]\tLoss: 0.136242\n",
      "Train Epoch: 10 [4480/6766 (66%)]\tLoss: 0.194160\n",
      "Train Epoch: 10 [5120/6766 (75%)]\tLoss: 0.112684\n",
      "Train Epoch: 10 [5760/6766 (85%)]\tLoss: 0.139761\n",
      "Train Epoch: 10 [6400/6766 (94%)]\tLoss: 0.276564\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 1.714197\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 0.815779\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 0.505886\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 0.620659\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 0.784674\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 0.480910\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 0.936675\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 0.668500\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 0.491186\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 0.446450\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 0.338626\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 0.276690\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 0.638799\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 0.309344\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 0.289011\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 0.265685\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 0.274553\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.395730\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.428001\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.624613\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.213689\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.240133\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.327069\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.328659\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.432447\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.366674\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.218445\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.309329\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.481344\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.227676\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.400565\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.135956\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.368222\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.251102\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.292810\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.438438\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.262079\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.223355\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.375668\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.495131\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.220350\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.201921\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.248805\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.274893\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.249319\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.331623\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.393251\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.159128\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.246092\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.178855\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.433971\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.230719\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.413261\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.162407\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.339328\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.459650\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.162037\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.263615\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.262687\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.179725\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.153465\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.365616\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.466217\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.251655\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.245626\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.173625\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.165535\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.297004\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.103519\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.161705\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.220790\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.243256\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.214183\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.485103\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.172489\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.231765\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.743896\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.288107\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.167435\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.144797\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.140479\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.103835\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.160596\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.222607\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.165550\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.202845\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.159368\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.142395\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.195015\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.192768\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.186008\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.234825\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.102301\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.259240\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.310142\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.224585\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.195567\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.153554\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.226603\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.178589\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.155669\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.211488\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.293862\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.130384\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.163688\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.210806\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.269768\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.221585\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.156706\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.388074\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.214772\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.192897\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.134686\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.210332\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.206246\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.130328\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.376868\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.148464\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.179459\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.213817\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.222882\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.163160\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.270269\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.236702\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.231060\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.157306\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.147006\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.118053\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.144545\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.215246\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.228852\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.191019\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.085411\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.259125\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.123448\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.142602\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.141100\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.163834\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.182736\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.066416\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.096195\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.137667\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.270968\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.216643\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.170953\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.208341\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.160217\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.175924\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.164172\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.170471\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.347270\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.057475\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.123771\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.167302\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.544460\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.103166\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.166855\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.160925\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.080249\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.190480\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/3910 (0%)]\tLoss: 1.780594\n",
      "Train Epoch: 1 [640/3910 (16%)]\tLoss: 1.009796\n",
      "Train Epoch: 1 [1280/3910 (32%)]\tLoss: 0.713118\n",
      "Train Epoch: 1 [1920/3910 (48%)]\tLoss: 0.665320\n",
      "Train Epoch: 1 [2560/3910 (65%)]\tLoss: 0.618417\n",
      "Train Epoch: 1 [3200/3910 (81%)]\tLoss: 0.392855\n",
      "Train Epoch: 1 [3840/3910 (97%)]\tLoss: 0.497233\n",
      "Train Epoch: 2 [0/3910 (0%)]\tLoss: 0.579589\n",
      "Train Epoch: 2 [640/3910 (16%)]\tLoss: 0.449308\n",
      "Train Epoch: 2 [1280/3910 (32%)]\tLoss: 0.616828\n",
      "Train Epoch: 2 [1920/3910 (48%)]\tLoss: 0.593225\n",
      "Train Epoch: 2 [2560/3910 (65%)]\tLoss: 0.681823\n",
      "Train Epoch: 2 [3200/3910 (81%)]\tLoss: 0.369905\n",
      "Train Epoch: 2 [3840/3910 (97%)]\tLoss: 0.209878\n",
      "Train Epoch: 3 [0/3910 (0%)]\tLoss: 0.682818\n",
      "Train Epoch: 3 [640/3910 (16%)]\tLoss: 0.288922\n",
      "Train Epoch: 3 [1280/3910 (32%)]\tLoss: 0.449829\n",
      "Train Epoch: 3 [1920/3910 (48%)]\tLoss: 0.365341\n",
      "Train Epoch: 3 [2560/3910 (65%)]\tLoss: 0.351644\n",
      "Train Epoch: 3 [3200/3910 (81%)]\tLoss: 0.310733\n",
      "Train Epoch: 3 [3840/3910 (97%)]\tLoss: 0.314468\n",
      "Train Epoch: 4 [0/3910 (0%)]\tLoss: 0.306241\n",
      "Train Epoch: 4 [640/3910 (16%)]\tLoss: 0.369257\n",
      "Train Epoch: 4 [1280/3910 (32%)]\tLoss: 0.160721\n",
      "Train Epoch: 4 [1920/3910 (48%)]\tLoss: 0.405701\n",
      "Train Epoch: 4 [2560/3910 (65%)]\tLoss: 0.462845\n",
      "Train Epoch: 4 [3200/3910 (81%)]\tLoss: 0.106238\n",
      "Train Epoch: 4 [3840/3910 (97%)]\tLoss: 0.363220\n",
      "Train Epoch: 5 [0/3910 (0%)]\tLoss: 0.258867\n",
      "Train Epoch: 5 [640/3910 (16%)]\tLoss: 0.471912\n",
      "Train Epoch: 5 [1280/3910 (32%)]\tLoss: 0.546396\n",
      "Train Epoch: 5 [1920/3910 (48%)]\tLoss: 0.304418\n",
      "Train Epoch: 5 [2560/3910 (65%)]\tLoss: 0.440677\n",
      "Train Epoch: 5 [3200/3910 (81%)]\tLoss: 0.218148\n",
      "Train Epoch: 5 [3840/3910 (97%)]\tLoss: 0.285923\n",
      "Train Epoch: 6 [0/3910 (0%)]\tLoss: 0.278585\n",
      "Train Epoch: 6 [640/3910 (16%)]\tLoss: 0.393295\n",
      "Train Epoch: 6 [1280/3910 (32%)]\tLoss: 0.372900\n",
      "Train Epoch: 6 [1920/3910 (48%)]\tLoss: 0.478983\n",
      "Train Epoch: 6 [2560/3910 (65%)]\tLoss: 0.240026\n",
      "Train Epoch: 6 [3200/3910 (81%)]\tLoss: 0.376509\n",
      "Train Epoch: 6 [3840/3910 (97%)]\tLoss: 0.321319\n",
      "Train Epoch: 7 [0/3910 (0%)]\tLoss: 0.330691\n",
      "Train Epoch: 7 [640/3910 (16%)]\tLoss: 0.421838\n",
      "Train Epoch: 7 [1280/3910 (32%)]\tLoss: 0.129228\n",
      "Train Epoch: 7 [1920/3910 (48%)]\tLoss: 0.261247\n",
      "Train Epoch: 7 [2560/3910 (65%)]\tLoss: 0.299225\n",
      "Train Epoch: 7 [3200/3910 (81%)]\tLoss: 0.411081\n",
      "Train Epoch: 7 [3840/3910 (97%)]\tLoss: 0.205874\n",
      "Train Epoch: 8 [0/3910 (0%)]\tLoss: 0.330049\n",
      "Train Epoch: 8 [640/3910 (16%)]\tLoss: 0.139032\n",
      "Train Epoch: 8 [1280/3910 (32%)]\tLoss: 0.191100\n",
      "Train Epoch: 8 [1920/3910 (48%)]\tLoss: 0.360632\n",
      "Train Epoch: 8 [2560/3910 (65%)]\tLoss: 0.237518\n",
      "Train Epoch: 8 [3200/3910 (81%)]\tLoss: 0.268459\n",
      "Train Epoch: 8 [3840/3910 (97%)]\tLoss: 0.431058\n",
      "Train Epoch: 9 [0/3910 (0%)]\tLoss: 0.264639\n",
      "Train Epoch: 9 [640/3910 (16%)]\tLoss: 0.328641\n",
      "Train Epoch: 9 [1280/3910 (32%)]\tLoss: 0.293784\n",
      "Train Epoch: 9 [1920/3910 (48%)]\tLoss: 0.195866\n",
      "Train Epoch: 9 [2560/3910 (65%)]\tLoss: 0.177762\n",
      "Train Epoch: 9 [3200/3910 (81%)]\tLoss: 0.148377\n",
      "Train Epoch: 9 [3840/3910 (97%)]\tLoss: 0.184163\n",
      "Train Epoch: 10 [0/3910 (0%)]\tLoss: 0.396921\n",
      "Train Epoch: 10 [640/3910 (16%)]\tLoss: 0.268788\n",
      "Train Epoch: 10 [1280/3910 (32%)]\tLoss: 0.167101\n",
      "Train Epoch: 10 [1920/3910 (48%)]\tLoss: 0.439966\n",
      "Train Epoch: 10 [2560/3910 (65%)]\tLoss: 0.377613\n",
      "Train Epoch: 10 [3200/3910 (81%)]\tLoss: 0.292939\n",
      "Train Epoch: 10 [3840/3910 (97%)]\tLoss: 0.295360\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 2.105862\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 0.972243\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 0.779751\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 0.658390\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 0.367110\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 0.642600\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 0.597121\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 0.467148\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 0.342285\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 0.521697\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.281313\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.346917\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 0.383950\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 0.690973\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 0.247416\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.397286\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.315658\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.456084\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.235492\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.159113\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.213101\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.200459\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.275907\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.480052\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.126742\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.407021\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.331936\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.190352\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.343828\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.462067\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.294903\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.521415\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.475069\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.170434\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.415905\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.086145\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.159447\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.150671\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.298897\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.168862\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.317091\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.263900\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.183511\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.240382\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.149646\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.285501\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.208146\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.108435\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.251539\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.272501\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.278234\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.083521\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.361436\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.079847\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.250728\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.211764\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.327270\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.192091\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.073219\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.120041\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.164188\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.151823\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.458557\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.156647\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.061897\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.323176\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.232005\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.100280\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.196763\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.129998\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.235872\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.094760\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.226717\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.215608\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.042215\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.206228\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.141262\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.193414\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.085613\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.089291\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.102022\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.227479\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.301962\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.088722\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.270444\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.197939\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.231040\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.258794\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.163185\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.207802\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.252664\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.298728\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.249926\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.208524\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.117544\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.214551\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.137186\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.193944\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.228788\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.144860\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.106867\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.148584\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.160171\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.180613\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.160092\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.368071\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.138388\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.230016\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.171629\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.275866\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.185531\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.119482\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.118739\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.181828\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.244323\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.054883\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.100039\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.171675\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.132099\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.170727\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/5096 (0%)]\tLoss: 1.785138\n",
      "Train Epoch: 1 [640/5096 (12%)]\tLoss: 0.754286\n",
      "Train Epoch: 1 [1280/5096 (25%)]\tLoss: 0.639945\n",
      "Train Epoch: 1 [1920/5096 (38%)]\tLoss: 0.744547\n",
      "Train Epoch: 1 [2560/5096 (50%)]\tLoss: 0.478956\n",
      "Train Epoch: 1 [3200/5096 (62%)]\tLoss: 0.379175\n",
      "Train Epoch: 1 [3840/5096 (75%)]\tLoss: 0.379362\n",
      "Train Epoch: 1 [4480/5096 (88%)]\tLoss: 0.305518\n",
      "Train Epoch: 2 [0/5096 (0%)]\tLoss: 0.304146\n",
      "Train Epoch: 2 [640/5096 (12%)]\tLoss: 0.339215\n",
      "Train Epoch: 2 [1280/5096 (25%)]\tLoss: 0.431744\n",
      "Train Epoch: 2 [1920/5096 (38%)]\tLoss: 0.375778\n",
      "Train Epoch: 2 [2560/5096 (50%)]\tLoss: 0.332786\n",
      "Train Epoch: 2 [3200/5096 (62%)]\tLoss: 0.273784\n",
      "Train Epoch: 2 [3840/5096 (75%)]\tLoss: 0.417607\n",
      "Train Epoch: 2 [4480/5096 (88%)]\tLoss: 0.269950\n",
      "Train Epoch: 3 [0/5096 (0%)]\tLoss: 0.494341\n",
      "Train Epoch: 3 [640/5096 (12%)]\tLoss: 0.224302\n",
      "Train Epoch: 3 [1280/5096 (25%)]\tLoss: 0.324838\n",
      "Train Epoch: 3 [1920/5096 (38%)]\tLoss: 0.318108\n",
      "Train Epoch: 3 [2560/5096 (50%)]\tLoss: 0.279142\n",
      "Train Epoch: 3 [3200/5096 (62%)]\tLoss: 0.390582\n",
      "Train Epoch: 3 [3840/5096 (75%)]\tLoss: 0.200515\n",
      "Train Epoch: 3 [4480/5096 (88%)]\tLoss: 0.360861\n",
      "Train Epoch: 4 [0/5096 (0%)]\tLoss: 0.275999\n",
      "Train Epoch: 4 [640/5096 (12%)]\tLoss: 0.488387\n",
      "Train Epoch: 4 [1280/5096 (25%)]\tLoss: 0.214603\n",
      "Train Epoch: 4 [1920/5096 (38%)]\tLoss: 0.249302\n",
      "Train Epoch: 4 [2560/5096 (50%)]\tLoss: 0.268560\n",
      "Train Epoch: 4 [3200/5096 (62%)]\tLoss: 0.121041\n",
      "Train Epoch: 4 [3840/5096 (75%)]\tLoss: 0.144764\n",
      "Train Epoch: 4 [4480/5096 (88%)]\tLoss: 0.081317\n",
      "Train Epoch: 5 [0/5096 (0%)]\tLoss: 0.137392\n",
      "Train Epoch: 5 [640/5096 (12%)]\tLoss: 0.320529\n",
      "Train Epoch: 5 [1280/5096 (25%)]\tLoss: 0.119093\n",
      "Train Epoch: 5 [1920/5096 (38%)]\tLoss: 0.292452\n",
      "Train Epoch: 5 [2560/5096 (50%)]\tLoss: 0.369905\n",
      "Train Epoch: 5 [3200/5096 (62%)]\tLoss: 0.143128\n",
      "Train Epoch: 5 [3840/5096 (75%)]\tLoss: 0.362205\n",
      "Train Epoch: 5 [4480/5096 (88%)]\tLoss: 0.086297\n",
      "Train Epoch: 6 [0/5096 (0%)]\tLoss: 0.291940\n",
      "Train Epoch: 6 [640/5096 (12%)]\tLoss: 0.173647\n",
      "Train Epoch: 6 [1280/5096 (25%)]\tLoss: 0.181161\n",
      "Train Epoch: 6 [1920/5096 (38%)]\tLoss: 0.173603\n",
      "Train Epoch: 6 [2560/5096 (50%)]\tLoss: 0.197287\n",
      "Train Epoch: 6 [3200/5096 (62%)]\tLoss: 0.185385\n",
      "Train Epoch: 6 [3840/5096 (75%)]\tLoss: 0.134170\n",
      "Train Epoch: 6 [4480/5096 (88%)]\tLoss: 0.337919\n",
      "Train Epoch: 7 [0/5096 (0%)]\tLoss: 0.304779\n",
      "Train Epoch: 7 [640/5096 (12%)]\tLoss: 0.299209\n",
      "Train Epoch: 7 [1280/5096 (25%)]\tLoss: 0.155377\n",
      "Train Epoch: 7 [1920/5096 (38%)]\tLoss: 0.190484\n",
      "Train Epoch: 7 [2560/5096 (50%)]\tLoss: 0.194279\n",
      "Train Epoch: 7 [3200/5096 (62%)]\tLoss: 0.138638\n",
      "Train Epoch: 7 [3840/5096 (75%)]\tLoss: 0.140939\n",
      "Train Epoch: 7 [4480/5096 (88%)]\tLoss: 0.188513\n",
      "Train Epoch: 8 [0/5096 (0%)]\tLoss: 0.130769\n",
      "Train Epoch: 8 [640/5096 (12%)]\tLoss: 0.034207\n",
      "Train Epoch: 8 [1280/5096 (25%)]\tLoss: 0.107406\n",
      "Train Epoch: 8 [1920/5096 (38%)]\tLoss: 0.138035\n",
      "Train Epoch: 8 [2560/5096 (50%)]\tLoss: 0.234271\n",
      "Train Epoch: 8 [3200/5096 (62%)]\tLoss: 0.170705\n",
      "Train Epoch: 8 [3840/5096 (75%)]\tLoss: 0.138756\n",
      "Train Epoch: 8 [4480/5096 (88%)]\tLoss: 0.124802\n",
      "Train Epoch: 9 [0/5096 (0%)]\tLoss: 0.362816\n",
      "Train Epoch: 9 [640/5096 (12%)]\tLoss: 0.205202\n",
      "Train Epoch: 9 [1280/5096 (25%)]\tLoss: 0.163081\n",
      "Train Epoch: 9 [1920/5096 (38%)]\tLoss: 0.145409\n",
      "Train Epoch: 9 [2560/5096 (50%)]\tLoss: 0.059679\n",
      "Train Epoch: 9 [3200/5096 (62%)]\tLoss: 0.204112\n",
      "Train Epoch: 9 [3840/5096 (75%)]\tLoss: 0.103117\n",
      "Train Epoch: 9 [4480/5096 (88%)]\tLoss: 0.176336\n",
      "Train Epoch: 10 [0/5096 (0%)]\tLoss: 0.176911\n",
      "Train Epoch: 10 [640/5096 (12%)]\tLoss: 0.127555\n",
      "Train Epoch: 10 [1280/5096 (25%)]\tLoss: 0.156245\n",
      "Train Epoch: 10 [1920/5096 (38%)]\tLoss: 0.192756\n",
      "Train Epoch: 10 [2560/5096 (50%)]\tLoss: 0.150489\n",
      "Train Epoch: 10 [3200/5096 (62%)]\tLoss: 0.176216\n",
      "Train Epoch: 10 [3840/5096 (75%)]\tLoss: 0.392263\n",
      "Train Epoch: 10 [4480/5096 (88%)]\tLoss: 0.188265\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/1599 (0%)]\tLoss: 1.530753\n",
      "Train Epoch: 1 [640/1599 (40%)]\tLoss: 0.759669\n",
      "Train Epoch: 1 [1280/1599 (80%)]\tLoss: 0.676297\n",
      "Train Epoch: 2 [0/1599 (0%)]\tLoss: 0.629409\n",
      "Train Epoch: 2 [640/1599 (40%)]\tLoss: 0.763266\n",
      "Train Epoch: 2 [1280/1599 (80%)]\tLoss: 0.611095\n",
      "Train Epoch: 3 [0/1599 (0%)]\tLoss: 0.536874\n",
      "Train Epoch: 3 [640/1599 (40%)]\tLoss: 0.866742\n",
      "Train Epoch: 3 [1280/1599 (80%)]\tLoss: 0.460122\n",
      "Train Epoch: 4 [0/1599 (0%)]\tLoss: 0.625470\n",
      "Train Epoch: 4 [640/1599 (40%)]\tLoss: 0.592160\n",
      "Train Epoch: 4 [1280/1599 (80%)]\tLoss: 0.626335\n",
      "Train Epoch: 5 [0/1599 (0%)]\tLoss: 0.623305\n",
      "Train Epoch: 5 [640/1599 (40%)]\tLoss: 0.312773\n",
      "Train Epoch: 5 [1280/1599 (80%)]\tLoss: 0.538524\n",
      "Train Epoch: 6 [0/1599 (0%)]\tLoss: 0.676467\n",
      "Train Epoch: 6 [640/1599 (40%)]\tLoss: 0.676854\n",
      "Train Epoch: 6 [1280/1599 (80%)]\tLoss: 0.485822\n",
      "Train Epoch: 7 [0/1599 (0%)]\tLoss: 0.373465\n",
      "Train Epoch: 7 [640/1599 (40%)]\tLoss: 0.523419\n",
      "Train Epoch: 7 [1280/1599 (80%)]\tLoss: 0.505398\n",
      "Train Epoch: 8 [0/1599 (0%)]\tLoss: 0.464194\n",
      "Train Epoch: 8 [640/1599 (40%)]\tLoss: 0.605596\n",
      "Train Epoch: 8 [1280/1599 (80%)]\tLoss: 0.394841\n",
      "Train Epoch: 9 [0/1599 (0%)]\tLoss: 0.416505\n",
      "Train Epoch: 9 [640/1599 (40%)]\tLoss: 0.286069\n",
      "Train Epoch: 9 [1280/1599 (80%)]\tLoss: 0.485651\n",
      "Train Epoch: 10 [0/1599 (0%)]\tLoss: 0.771975\n",
      "Train Epoch: 10 [640/1599 (40%)]\tLoss: 0.424468\n",
      "Train Epoch: 10 [1280/1599 (80%)]\tLoss: 0.400459\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/5266 (0%)]\tLoss: 2.009797\n",
      "Train Epoch: 1 [640/5266 (12%)]\tLoss: 0.581383\n",
      "Train Epoch: 1 [1280/5266 (24%)]\tLoss: 0.541588\n",
      "Train Epoch: 1 [1920/5266 (36%)]\tLoss: 0.302818\n",
      "Train Epoch: 1 [2560/5266 (48%)]\tLoss: 0.409454\n",
      "Train Epoch: 1 [3200/5266 (60%)]\tLoss: 0.203261\n",
      "Train Epoch: 1 [3840/5266 (72%)]\tLoss: 0.362786\n",
      "Train Epoch: 1 [4480/5266 (84%)]\tLoss: 0.129610\n",
      "Train Epoch: 1 [5120/5266 (96%)]\tLoss: 0.155415\n",
      "Train Epoch: 2 [0/5266 (0%)]\tLoss: 0.179911\n",
      "Train Epoch: 2 [640/5266 (12%)]\tLoss: 0.138850\n",
      "Train Epoch: 2 [1280/5266 (24%)]\tLoss: 0.199415\n",
      "Train Epoch: 2 [1920/5266 (36%)]\tLoss: 0.242116\n",
      "Train Epoch: 2 [2560/5266 (48%)]\tLoss: 0.253025\n",
      "Train Epoch: 2 [3200/5266 (60%)]\tLoss: 0.333666\n",
      "Train Epoch: 2 [3840/5266 (72%)]\tLoss: 0.255744\n",
      "Train Epoch: 2 [4480/5266 (84%)]\tLoss: 0.286157\n",
      "Train Epoch: 2 [5120/5266 (96%)]\tLoss: 0.454533\n",
      "Train Epoch: 3 [0/5266 (0%)]\tLoss: 0.183466\n",
      "Train Epoch: 3 [640/5266 (12%)]\tLoss: 0.128122\n",
      "Train Epoch: 3 [1280/5266 (24%)]\tLoss: 0.107519\n",
      "Train Epoch: 3 [1920/5266 (36%)]\tLoss: 0.222493\n",
      "Train Epoch: 3 [2560/5266 (48%)]\tLoss: 0.395937\n",
      "Train Epoch: 3 [3200/5266 (60%)]\tLoss: 0.197575\n",
      "Train Epoch: 3 [3840/5266 (72%)]\tLoss: 0.232349\n",
      "Train Epoch: 3 [4480/5266 (84%)]\tLoss: 0.135176\n",
      "Train Epoch: 3 [5120/5266 (96%)]\tLoss: 0.365583\n",
      "Train Epoch: 4 [0/5266 (0%)]\tLoss: 0.234399\n",
      "Train Epoch: 4 [640/5266 (12%)]\tLoss: 0.273960\n",
      "Train Epoch: 4 [1280/5266 (24%)]\tLoss: 0.054405\n",
      "Train Epoch: 4 [1920/5266 (36%)]\tLoss: 0.073918\n",
      "Train Epoch: 4 [2560/5266 (48%)]\tLoss: 0.253192\n",
      "Train Epoch: 4 [3200/5266 (60%)]\tLoss: 0.111407\n",
      "Train Epoch: 4 [3840/5266 (72%)]\tLoss: 0.134782\n",
      "Train Epoch: 4 [4480/5266 (84%)]\tLoss: 0.102357\n",
      "Train Epoch: 4 [5120/5266 (96%)]\tLoss: 0.451395\n",
      "Train Epoch: 5 [0/5266 (0%)]\tLoss: 0.150298\n",
      "Train Epoch: 5 [640/5266 (12%)]\tLoss: 0.118488\n",
      "Train Epoch: 5 [1280/5266 (24%)]\tLoss: 0.213066\n",
      "Train Epoch: 5 [1920/5266 (36%)]\tLoss: 0.074448\n",
      "Train Epoch: 5 [2560/5266 (48%)]\tLoss: 0.079154\n",
      "Train Epoch: 5 [3200/5266 (60%)]\tLoss: 0.130653\n",
      "Train Epoch: 5 [3840/5266 (72%)]\tLoss: 0.224617\n",
      "Train Epoch: 5 [4480/5266 (84%)]\tLoss: 0.170526\n",
      "Train Epoch: 5 [5120/5266 (96%)]\tLoss: 0.068168\n",
      "Train Epoch: 6 [0/5266 (0%)]\tLoss: 0.161085\n",
      "Train Epoch: 6 [640/5266 (12%)]\tLoss: 0.216526\n",
      "Train Epoch: 6 [1280/5266 (24%)]\tLoss: 0.118539\n",
      "Train Epoch: 6 [1920/5266 (36%)]\tLoss: 0.094242\n",
      "Train Epoch: 6 [2560/5266 (48%)]\tLoss: 0.111293\n",
      "Train Epoch: 6 [3200/5266 (60%)]\tLoss: 0.259112\n",
      "Train Epoch: 6 [3840/5266 (72%)]\tLoss: 0.209984\n",
      "Train Epoch: 6 [4480/5266 (84%)]\tLoss: 0.169448\n",
      "Train Epoch: 6 [5120/5266 (96%)]\tLoss: 0.150887\n",
      "Train Epoch: 7 [0/5266 (0%)]\tLoss: 0.227799\n",
      "Train Epoch: 7 [640/5266 (12%)]\tLoss: 0.173562\n",
      "Train Epoch: 7 [1280/5266 (24%)]\tLoss: 0.139242\n",
      "Train Epoch: 7 [1920/5266 (36%)]\tLoss: 0.199833\n",
      "Train Epoch: 7 [2560/5266 (48%)]\tLoss: 0.094020\n",
      "Train Epoch: 7 [3200/5266 (60%)]\tLoss: 0.243390\n",
      "Train Epoch: 7 [3840/5266 (72%)]\tLoss: 0.160875\n",
      "Train Epoch: 7 [4480/5266 (84%)]\tLoss: 0.085937\n",
      "Train Epoch: 7 [5120/5266 (96%)]\tLoss: 0.122539\n",
      "Train Epoch: 8 [0/5266 (0%)]\tLoss: 0.080326\n",
      "Train Epoch: 8 [640/5266 (12%)]\tLoss: 0.107620\n",
      "Train Epoch: 8 [1280/5266 (24%)]\tLoss: 0.066628\n",
      "Train Epoch: 8 [1920/5266 (36%)]\tLoss: 0.157820\n",
      "Train Epoch: 8 [2560/5266 (48%)]\tLoss: 0.163079\n",
      "Train Epoch: 8 [3200/5266 (60%)]\tLoss: 0.133124\n",
      "Train Epoch: 8 [3840/5266 (72%)]\tLoss: 0.219455\n",
      "Train Epoch: 8 [4480/5266 (84%)]\tLoss: 0.267600\n",
      "Train Epoch: 8 [5120/5266 (96%)]\tLoss: 0.031500\n",
      "Train Epoch: 9 [0/5266 (0%)]\tLoss: 0.167963\n",
      "Train Epoch: 9 [640/5266 (12%)]\tLoss: 0.180710\n",
      "Train Epoch: 9 [1280/5266 (24%)]\tLoss: 0.311849\n",
      "Train Epoch: 9 [1920/5266 (36%)]\tLoss: 0.188380\n",
      "Train Epoch: 9 [2560/5266 (48%)]\tLoss: 0.115061\n",
      "Train Epoch: 9 [3200/5266 (60%)]\tLoss: 0.074918\n",
      "Train Epoch: 9 [3840/5266 (72%)]\tLoss: 0.061259\n",
      "Train Epoch: 9 [4480/5266 (84%)]\tLoss: 0.109967\n",
      "Train Epoch: 9 [5120/5266 (96%)]\tLoss: 0.115979\n",
      "Train Epoch: 10 [0/5266 (0%)]\tLoss: 0.155838\n",
      "Train Epoch: 10 [640/5266 (12%)]\tLoss: 0.175910\n",
      "Train Epoch: 10 [1280/5266 (24%)]\tLoss: 0.034237\n",
      "Train Epoch: 10 [1920/5266 (36%)]\tLoss: 0.083033\n",
      "Train Epoch: 10 [2560/5266 (48%)]\tLoss: 0.061532\n",
      "Train Epoch: 10 [3200/5266 (60%)]\tLoss: 0.088976\n",
      "Train Epoch: 10 [3840/5266 (72%)]\tLoss: 0.205026\n",
      "Train Epoch: 10 [4480/5266 (84%)]\tLoss: 0.253520\n",
      "Train Epoch: 10 [5120/5266 (96%)]\tLoss: 0.061095\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/3530 (0%)]\tLoss: 1.501861\n",
      "Train Epoch: 1 [640/3530 (18%)]\tLoss: 0.862698\n",
      "Train Epoch: 1 [1280/3530 (36%)]\tLoss: 0.811908\n",
      "Train Epoch: 1 [1920/3530 (54%)]\tLoss: 0.607042\n",
      "Train Epoch: 1 [2560/3530 (71%)]\tLoss: 0.729771\n",
      "Train Epoch: 1 [3200/3530 (89%)]\tLoss: 0.678143\n",
      "Train Epoch: 2 [0/3530 (0%)]\tLoss: 0.394504\n",
      "Train Epoch: 2 [640/3530 (18%)]\tLoss: 0.474735\n",
      "Train Epoch: 2 [1280/3530 (36%)]\tLoss: 0.717533\n",
      "Train Epoch: 2 [1920/3530 (54%)]\tLoss: 0.440297\n",
      "Train Epoch: 2 [2560/3530 (71%)]\tLoss: 0.429805\n",
      "Train Epoch: 2 [3200/3530 (89%)]\tLoss: 0.432517\n",
      "Train Epoch: 3 [0/3530 (0%)]\tLoss: 0.383839\n",
      "Train Epoch: 3 [640/3530 (18%)]\tLoss: 0.474687\n",
      "Train Epoch: 3 [1280/3530 (36%)]\tLoss: 0.176573\n",
      "Train Epoch: 3 [1920/3530 (54%)]\tLoss: 0.795800\n",
      "Train Epoch: 3 [2560/3530 (71%)]\tLoss: 0.419947\n",
      "Train Epoch: 3 [3200/3530 (89%)]\tLoss: 0.710613\n",
      "Train Epoch: 4 [0/3530 (0%)]\tLoss: 0.999189\n",
      "Train Epoch: 4 [640/3530 (18%)]\tLoss: 0.456514\n",
      "Train Epoch: 4 [1280/3530 (36%)]\tLoss: 0.292320\n",
      "Train Epoch: 4 [1920/3530 (54%)]\tLoss: 0.411110\n",
      "Train Epoch: 4 [2560/3530 (71%)]\tLoss: 0.255605\n",
      "Train Epoch: 4 [3200/3530 (89%)]\tLoss: 0.289355\n",
      "Train Epoch: 5 [0/3530 (0%)]\tLoss: 0.259627\n",
      "Train Epoch: 5 [640/3530 (18%)]\tLoss: 0.317274\n",
      "Train Epoch: 5 [1280/3530 (36%)]\tLoss: 0.388027\n",
      "Train Epoch: 5 [1920/3530 (54%)]\tLoss: 0.458962\n",
      "Train Epoch: 5 [2560/3530 (71%)]\tLoss: 0.459022\n",
      "Train Epoch: 5 [3200/3530 (89%)]\tLoss: 0.364015\n",
      "Train Epoch: 6 [0/3530 (0%)]\tLoss: 0.238048\n",
      "Train Epoch: 6 [640/3530 (18%)]\tLoss: 0.323744\n",
      "Train Epoch: 6 [1280/3530 (36%)]\tLoss: 0.350833\n",
      "Train Epoch: 6 [1920/3530 (54%)]\tLoss: 0.216476\n",
      "Train Epoch: 6 [2560/3530 (71%)]\tLoss: 0.175811\n",
      "Train Epoch: 6 [3200/3530 (89%)]\tLoss: 0.226217\n",
      "Train Epoch: 7 [0/3530 (0%)]\tLoss: 0.471948\n",
      "Train Epoch: 7 [640/3530 (18%)]\tLoss: 0.369172\n",
      "Train Epoch: 7 [1280/3530 (36%)]\tLoss: 0.312060\n",
      "Train Epoch: 7 [1920/3530 (54%)]\tLoss: 0.330574\n",
      "Train Epoch: 7 [2560/3530 (71%)]\tLoss: 0.458620\n",
      "Train Epoch: 7 [3200/3530 (89%)]\tLoss: 0.457463\n",
      "Train Epoch: 8 [0/3530 (0%)]\tLoss: 0.261685\n",
      "Train Epoch: 8 [640/3530 (18%)]\tLoss: 0.286614\n",
      "Train Epoch: 8 [1280/3530 (36%)]\tLoss: 0.246301\n",
      "Train Epoch: 8 [1920/3530 (54%)]\tLoss: 0.310814\n",
      "Train Epoch: 8 [2560/3530 (71%)]\tLoss: 0.185467\n",
      "Train Epoch: 8 [3200/3530 (89%)]\tLoss: 0.234433\n",
      "Train Epoch: 9 [0/3530 (0%)]\tLoss: 0.141037\n",
      "Train Epoch: 9 [640/3530 (18%)]\tLoss: 0.315655\n",
      "Train Epoch: 9 [1280/3530 (36%)]\tLoss: 0.209089\n",
      "Train Epoch: 9 [1920/3530 (54%)]\tLoss: 0.205647\n",
      "Train Epoch: 9 [2560/3530 (71%)]\tLoss: 0.229191\n",
      "Train Epoch: 9 [3200/3530 (89%)]\tLoss: 0.396730\n",
      "Train Epoch: 10 [0/3530 (0%)]\tLoss: 0.088526\n",
      "Train Epoch: 10 [640/3530 (18%)]\tLoss: 0.384984\n",
      "Train Epoch: 10 [1280/3530 (36%)]\tLoss: 0.217952\n",
      "Train Epoch: 10 [1920/3530 (54%)]\tLoss: 0.235965\n",
      "Train Epoch: 10 [2560/3530 (71%)]\tLoss: 0.204037\n",
      "Train Epoch: 10 [3200/3530 (89%)]\tLoss: 0.394044\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.5684, Accuracy: 8442/10000 (84%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 0.883138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 0.774885\n",
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 0.366518\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 0.382864\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 0.362376\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 0.287010\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 0.435753\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 0.631718\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 0.482178\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 0.210459\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 0.307730\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 0.508103\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 0.412525\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 0.476915\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 0.274458\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 0.485390\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 0.375592\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 0.218317\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 0.155292\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 0.426319\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.360527\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 0.228847\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 0.456318\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.302269\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.229024\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 0.353848\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.306732\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 0.239663\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.241016\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.250535\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.241371\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.232680\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.360245\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.411810\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.246628\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.161091\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.323007\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.379523\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.315010\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.187674\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.486241\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.311458\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.232289\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.260386\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.119659\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.372130\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.222934\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.185092\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.188327\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.250491\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.133289\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.153435\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.316423\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.242877\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.121651\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.253607\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.112446\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.411731\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.451777\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.101624\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.263461\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.219828\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.331667\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.284918\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.167769\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.169043\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.162788\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.268652\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.203394\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.344288\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.129372\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.337032\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.328079\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.135304\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.113818\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.291349\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.210472\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.172870\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.244684\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.178962\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.230566\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.221932\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.185522\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.092477\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.181562\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.204128\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.182641\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.293448\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.178748\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.333503\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.089162\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.221976\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.125352\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.084582\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.155919\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.188164\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.230304\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.173362\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.178861\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.408100\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.159671\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.093169\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.349752\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.527243\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.186696\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.276046\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.205646\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.174400\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 0.180084\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.081516\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.080031\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.206708\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.162355\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.118235\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.339901\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.208924\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.167150\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.267557\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.148343\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.230185\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.141079\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.067909\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.098155\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.141354\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.351213\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.165042\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.140306\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.350537\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.125162\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.180440\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.166011\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.353496\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.254756\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.186879\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.172627\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.136593\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.241288\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.176397\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.281686\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.131273\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.129340\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.720983\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.202767\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.132268\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.159925\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.158050\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.127512\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.151871\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.301550\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.148126\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.255775\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.191584\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.199151\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.093026\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.067059\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.257111\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.176760\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.221086\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.211409\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.158356\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.139033\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.136558\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.351229\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.118095\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.199588\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.140256\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.230509\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.214771\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.175383\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.103898\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.066820\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.182910\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.142625\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.146825\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.162561\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.148671\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.227197\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.186959\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.211336\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.186500\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/5110 (0%)]\tLoss: 0.808303\n",
      "Train Epoch: 1 [640/5110 (12%)]\tLoss: 0.525964\n",
      "Train Epoch: 1 [1280/5110 (25%)]\tLoss: 0.531754\n",
      "Train Epoch: 1 [1920/5110 (38%)]\tLoss: 0.471768\n",
      "Train Epoch: 1 [2560/5110 (50%)]\tLoss: 0.425030\n",
      "Train Epoch: 1 [3200/5110 (62%)]\tLoss: 0.386114\n",
      "Train Epoch: 1 [3840/5110 (75%)]\tLoss: 0.188200\n",
      "Train Epoch: 1 [4480/5110 (88%)]\tLoss: 0.427278\n",
      "Train Epoch: 2 [0/5110 (0%)]\tLoss: 0.570904\n",
      "Train Epoch: 2 [640/5110 (12%)]\tLoss: 0.235088\n",
      "Train Epoch: 2 [1280/5110 (25%)]\tLoss: 0.361244\n",
      "Train Epoch: 2 [1920/5110 (38%)]\tLoss: 0.271136\n",
      "Train Epoch: 2 [2560/5110 (50%)]\tLoss: 0.301549\n",
      "Train Epoch: 2 [3200/5110 (62%)]\tLoss: 0.291702\n",
      "Train Epoch: 2 [3840/5110 (75%)]\tLoss: 0.207077\n",
      "Train Epoch: 2 [4480/5110 (88%)]\tLoss: 0.227491\n",
      "Train Epoch: 3 [0/5110 (0%)]\tLoss: 0.177849\n",
      "Train Epoch: 3 [640/5110 (12%)]\tLoss: 0.263351\n",
      "Train Epoch: 3 [1280/5110 (25%)]\tLoss: 0.368895\n",
      "Train Epoch: 3 [1920/5110 (38%)]\tLoss: 0.383819\n",
      "Train Epoch: 3 [2560/5110 (50%)]\tLoss: 0.255949\n",
      "Train Epoch: 3 [3200/5110 (62%)]\tLoss: 0.199606\n",
      "Train Epoch: 3 [3840/5110 (75%)]\tLoss: 0.201005\n",
      "Train Epoch: 3 [4480/5110 (88%)]\tLoss: 0.250645\n",
      "Train Epoch: 4 [0/5110 (0%)]\tLoss: 0.305814\n",
      "Train Epoch: 4 [640/5110 (12%)]\tLoss: 0.358598\n",
      "Train Epoch: 4 [1280/5110 (25%)]\tLoss: 0.248826\n",
      "Train Epoch: 4 [1920/5110 (38%)]\tLoss: 0.221240\n",
      "Train Epoch: 4 [2560/5110 (50%)]\tLoss: 0.186439\n",
      "Train Epoch: 4 [3200/5110 (62%)]\tLoss: 0.289582\n",
      "Train Epoch: 4 [3840/5110 (75%)]\tLoss: 0.292251\n",
      "Train Epoch: 4 [4480/5110 (88%)]\tLoss: 0.257601\n",
      "Train Epoch: 5 [0/5110 (0%)]\tLoss: 0.173858\n",
      "Train Epoch: 5 [640/5110 (12%)]\tLoss: 0.359844\n",
      "Train Epoch: 5 [1280/5110 (25%)]\tLoss: 0.331119\n",
      "Train Epoch: 5 [1920/5110 (38%)]\tLoss: 0.316259\n",
      "Train Epoch: 5 [2560/5110 (50%)]\tLoss: 0.261003\n",
      "Train Epoch: 5 [3200/5110 (62%)]\tLoss: 0.222553\n",
      "Train Epoch: 5 [3840/5110 (75%)]\tLoss: 0.245028\n",
      "Train Epoch: 5 [4480/5110 (88%)]\tLoss: 0.217668\n",
      "Train Epoch: 6 [0/5110 (0%)]\tLoss: 0.167807\n",
      "Train Epoch: 6 [640/5110 (12%)]\tLoss: 0.257615\n",
      "Train Epoch: 6 [1280/5110 (25%)]\tLoss: 0.219070\n",
      "Train Epoch: 6 [1920/5110 (38%)]\tLoss: 0.152803\n",
      "Train Epoch: 6 [2560/5110 (50%)]\tLoss: 0.260532\n",
      "Train Epoch: 6 [3200/5110 (62%)]\tLoss: 0.163394\n",
      "Train Epoch: 6 [3840/5110 (75%)]\tLoss: 0.244100\n",
      "Train Epoch: 6 [4480/5110 (88%)]\tLoss: 0.145759\n",
      "Train Epoch: 7 [0/5110 (0%)]\tLoss: 0.462165\n",
      "Train Epoch: 7 [640/5110 (12%)]\tLoss: 0.202755\n",
      "Train Epoch: 7 [1280/5110 (25%)]\tLoss: 0.329401\n",
      "Train Epoch: 7 [1920/5110 (38%)]\tLoss: 0.201635\n",
      "Train Epoch: 7 [2560/5110 (50%)]\tLoss: 0.239137\n",
      "Train Epoch: 7 [3200/5110 (62%)]\tLoss: 0.177198\n",
      "Train Epoch: 7 [3840/5110 (75%)]\tLoss: 0.259472\n",
      "Train Epoch: 7 [4480/5110 (88%)]\tLoss: 0.273646\n",
      "Train Epoch: 8 [0/5110 (0%)]\tLoss: 0.262331\n",
      "Train Epoch: 8 [640/5110 (12%)]\tLoss: 0.246463\n",
      "Train Epoch: 8 [1280/5110 (25%)]\tLoss: 0.274212\n",
      "Train Epoch: 8 [1920/5110 (38%)]\tLoss: 0.162569\n",
      "Train Epoch: 8 [2560/5110 (50%)]\tLoss: 0.149512\n",
      "Train Epoch: 8 [3200/5110 (62%)]\tLoss: 0.220911\n",
      "Train Epoch: 8 [3840/5110 (75%)]\tLoss: 0.277517\n",
      "Train Epoch: 8 [4480/5110 (88%)]\tLoss: 0.169420\n",
      "Train Epoch: 9 [0/5110 (0%)]\tLoss: 0.139991\n",
      "Train Epoch: 9 [640/5110 (12%)]\tLoss: 0.259499\n",
      "Train Epoch: 9 [1280/5110 (25%)]\tLoss: 0.366118\n",
      "Train Epoch: 9 [1920/5110 (38%)]\tLoss: 0.268400\n",
      "Train Epoch: 9 [2560/5110 (50%)]\tLoss: 0.179742\n",
      "Train Epoch: 9 [3200/5110 (62%)]\tLoss: 0.246300\n",
      "Train Epoch: 9 [3840/5110 (75%)]\tLoss: 0.353933\n",
      "Train Epoch: 9 [4480/5110 (88%)]\tLoss: 0.243940\n",
      "Train Epoch: 10 [0/5110 (0%)]\tLoss: 0.139870\n",
      "Train Epoch: 10 [640/5110 (12%)]\tLoss: 0.256770\n",
      "Train Epoch: 10 [1280/5110 (25%)]\tLoss: 0.245471\n",
      "Train Epoch: 10 [1920/5110 (38%)]\tLoss: 0.208752\n",
      "Train Epoch: 10 [2560/5110 (50%)]\tLoss: 0.126653\n",
      "Train Epoch: 10 [3200/5110 (62%)]\tLoss: 0.159566\n",
      "Train Epoch: 10 [3840/5110 (75%)]\tLoss: 0.185848\n",
      "Train Epoch: 10 [4480/5110 (88%)]\tLoss: 0.123156\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6766 (0%)]\tLoss: 0.943593\n",
      "Train Epoch: 1 [640/6766 (9%)]\tLoss: 0.253276\n",
      "Train Epoch: 1 [1280/6766 (19%)]\tLoss: 0.234915\n",
      "Train Epoch: 1 [1920/6766 (28%)]\tLoss: 0.270333\n",
      "Train Epoch: 1 [2560/6766 (38%)]\tLoss: 0.163618\n",
      "Train Epoch: 1 [3200/6766 (47%)]\tLoss: 0.303834\n",
      "Train Epoch: 1 [3840/6766 (57%)]\tLoss: 0.312739\n",
      "Train Epoch: 1 [4480/6766 (66%)]\tLoss: 0.243766\n",
      "Train Epoch: 1 [5120/6766 (75%)]\tLoss: 0.167185\n",
      "Train Epoch: 1 [5760/6766 (85%)]\tLoss: 0.191336\n",
      "Train Epoch: 1 [6400/6766 (94%)]\tLoss: 0.230085\n",
      "Train Epoch: 2 [0/6766 (0%)]\tLoss: 0.212538\n",
      "Train Epoch: 2 [640/6766 (9%)]\tLoss: 0.216682\n",
      "Train Epoch: 2 [1280/6766 (19%)]\tLoss: 0.288753\n",
      "Train Epoch: 2 [1920/6766 (28%)]\tLoss: 0.192932\n",
      "Train Epoch: 2 [2560/6766 (38%)]\tLoss: 0.182353\n",
      "Train Epoch: 2 [3200/6766 (47%)]\tLoss: 0.253474\n",
      "Train Epoch: 2 [3840/6766 (57%)]\tLoss: 0.136551\n",
      "Train Epoch: 2 [4480/6766 (66%)]\tLoss: 0.221817\n",
      "Train Epoch: 2 [5120/6766 (75%)]\tLoss: 0.131402\n",
      "Train Epoch: 2 [5760/6766 (85%)]\tLoss: 0.109896\n",
      "Train Epoch: 2 [6400/6766 (94%)]\tLoss: 0.193451\n",
      "Train Epoch: 3 [0/6766 (0%)]\tLoss: 0.272491\n",
      "Train Epoch: 3 [640/6766 (9%)]\tLoss: 0.416532\n",
      "Train Epoch: 3 [1280/6766 (19%)]\tLoss: 0.384066\n",
      "Train Epoch: 3 [1920/6766 (28%)]\tLoss: 0.234110\n",
      "Train Epoch: 3 [2560/6766 (38%)]\tLoss: 0.096520\n",
      "Train Epoch: 3 [3200/6766 (47%)]\tLoss: 0.344400\n",
      "Train Epoch: 3 [3840/6766 (57%)]\tLoss: 0.080549\n",
      "Train Epoch: 3 [4480/6766 (66%)]\tLoss: 0.096544\n",
      "Train Epoch: 3 [5120/6766 (75%)]\tLoss: 0.141235\n",
      "Train Epoch: 3 [5760/6766 (85%)]\tLoss: 0.074205\n",
      "Train Epoch: 3 [6400/6766 (94%)]\tLoss: 0.168430\n",
      "Train Epoch: 4 [0/6766 (0%)]\tLoss: 0.188009\n",
      "Train Epoch: 4 [640/6766 (9%)]\tLoss: 0.217488\n",
      "Train Epoch: 4 [1280/6766 (19%)]\tLoss: 0.287836\n",
      "Train Epoch: 4 [1920/6766 (28%)]\tLoss: 0.507598\n",
      "Train Epoch: 4 [2560/6766 (38%)]\tLoss: 0.138447\n",
      "Train Epoch: 4 [3200/6766 (47%)]\tLoss: 0.203252\n",
      "Train Epoch: 4 [3840/6766 (57%)]\tLoss: 0.130805\n",
      "Train Epoch: 4 [4480/6766 (66%)]\tLoss: 0.241844\n",
      "Train Epoch: 4 [5120/6766 (75%)]\tLoss: 0.118050\n",
      "Train Epoch: 4 [5760/6766 (85%)]\tLoss: 0.249137\n",
      "Train Epoch: 4 [6400/6766 (94%)]\tLoss: 0.175540\n",
      "Train Epoch: 5 [0/6766 (0%)]\tLoss: 0.322710\n",
      "Train Epoch: 5 [640/6766 (9%)]\tLoss: 0.169271\n",
      "Train Epoch: 5 [1280/6766 (19%)]\tLoss: 0.210092\n",
      "Train Epoch: 5 [1920/6766 (28%)]\tLoss: 0.097139\n",
      "Train Epoch: 5 [2560/6766 (38%)]\tLoss: 0.186651\n",
      "Train Epoch: 5 [3200/6766 (47%)]\tLoss: 0.198272\n",
      "Train Epoch: 5 [3840/6766 (57%)]\tLoss: 0.224389\n",
      "Train Epoch: 5 [4480/6766 (66%)]\tLoss: 0.094478\n",
      "Train Epoch: 5 [5120/6766 (75%)]\tLoss: 0.159594\n",
      "Train Epoch: 5 [5760/6766 (85%)]\tLoss: 0.255602\n",
      "Train Epoch: 5 [6400/6766 (94%)]\tLoss: 0.115287\n",
      "Train Epoch: 6 [0/6766 (0%)]\tLoss: 0.178839\n",
      "Train Epoch: 6 [640/6766 (9%)]\tLoss: 0.134960\n",
      "Train Epoch: 6 [1280/6766 (19%)]\tLoss: 0.245979\n",
      "Train Epoch: 6 [1920/6766 (28%)]\tLoss: 0.076289\n",
      "Train Epoch: 6 [2560/6766 (38%)]\tLoss: 0.157127\n",
      "Train Epoch: 6 [3200/6766 (47%)]\tLoss: 0.260292\n",
      "Train Epoch: 6 [3840/6766 (57%)]\tLoss: 0.253369\n",
      "Train Epoch: 6 [4480/6766 (66%)]\tLoss: 0.154784\n",
      "Train Epoch: 6 [5120/6766 (75%)]\tLoss: 0.049948\n",
      "Train Epoch: 6 [5760/6766 (85%)]\tLoss: 0.129418\n",
      "Train Epoch: 6 [6400/6766 (94%)]\tLoss: 0.213147\n",
      "Train Epoch: 7 [0/6766 (0%)]\tLoss: 0.145083\n",
      "Train Epoch: 7 [640/6766 (9%)]\tLoss: 0.212956\n",
      "Train Epoch: 7 [1280/6766 (19%)]\tLoss: 0.253111\n",
      "Train Epoch: 7 [1920/6766 (28%)]\tLoss: 0.131710\n",
      "Train Epoch: 7 [2560/6766 (38%)]\tLoss: 0.059473\n",
      "Train Epoch: 7 [3200/6766 (47%)]\tLoss: 0.124561\n",
      "Train Epoch: 7 [3840/6766 (57%)]\tLoss: 0.118743\n",
      "Train Epoch: 7 [4480/6766 (66%)]\tLoss: 0.110505\n",
      "Train Epoch: 7 [5120/6766 (75%)]\tLoss: 0.214810\n",
      "Train Epoch: 7 [5760/6766 (85%)]\tLoss: 0.116343\n",
      "Train Epoch: 7 [6400/6766 (94%)]\tLoss: 0.283958\n",
      "Train Epoch: 8 [0/6766 (0%)]\tLoss: 0.116767\n",
      "Train Epoch: 8 [640/6766 (9%)]\tLoss: 0.119754\n",
      "Train Epoch: 8 [1280/6766 (19%)]\tLoss: 0.044324\n",
      "Train Epoch: 8 [1920/6766 (28%)]\tLoss: 0.106876\n",
      "Train Epoch: 8 [2560/6766 (38%)]\tLoss: 0.266586\n",
      "Train Epoch: 8 [3200/6766 (47%)]\tLoss: 0.122973\n",
      "Train Epoch: 8 [3840/6766 (57%)]\tLoss: 0.078416\n",
      "Train Epoch: 8 [4480/6766 (66%)]\tLoss: 0.203147\n",
      "Train Epoch: 8 [5120/6766 (75%)]\tLoss: 0.191660\n",
      "Train Epoch: 8 [5760/6766 (85%)]\tLoss: 0.145842\n",
      "Train Epoch: 8 [6400/6766 (94%)]\tLoss: 0.172233\n",
      "Train Epoch: 9 [0/6766 (0%)]\tLoss: 0.100306\n",
      "Train Epoch: 9 [640/6766 (9%)]\tLoss: 0.091406\n",
      "Train Epoch: 9 [1280/6766 (19%)]\tLoss: 0.108784\n",
      "Train Epoch: 9 [1920/6766 (28%)]\tLoss: 0.145239\n",
      "Train Epoch: 9 [2560/6766 (38%)]\tLoss: 0.114783\n",
      "Train Epoch: 9 [3200/6766 (47%)]\tLoss: 0.230698\n",
      "Train Epoch: 9 [3840/6766 (57%)]\tLoss: 0.082437\n",
      "Train Epoch: 9 [4480/6766 (66%)]\tLoss: 0.084615\n",
      "Train Epoch: 9 [5120/6766 (75%)]\tLoss: 0.120581\n",
      "Train Epoch: 9 [5760/6766 (85%)]\tLoss: 0.063614\n",
      "Train Epoch: 9 [6400/6766 (94%)]\tLoss: 0.117557\n",
      "Train Epoch: 10 [0/6766 (0%)]\tLoss: 0.122994\n",
      "Train Epoch: 10 [640/6766 (9%)]\tLoss: 0.084763\n",
      "Train Epoch: 10 [1280/6766 (19%)]\tLoss: 0.235124\n",
      "Train Epoch: 10 [1920/6766 (28%)]\tLoss: 0.101787\n",
      "Train Epoch: 10 [2560/6766 (38%)]\tLoss: 0.045150\n",
      "Train Epoch: 10 [3200/6766 (47%)]\tLoss: 0.190885\n",
      "Train Epoch: 10 [3840/6766 (57%)]\tLoss: 0.096610\n",
      "Train Epoch: 10 [4480/6766 (66%)]\tLoss: 0.298377\n",
      "Train Epoch: 10 [5120/6766 (75%)]\tLoss: 0.301910\n",
      "Train Epoch: 10 [5760/6766 (85%)]\tLoss: 0.253803\n",
      "Train Epoch: 10 [6400/6766 (94%)]\tLoss: 0.087473\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 0.640340\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 0.353785\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 0.438267\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 0.374448\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 0.291922\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 0.396410\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 0.286011\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 0.240678\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 0.373174\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 0.473520\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 0.347647\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 0.261114\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 0.165725\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 0.149795\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 0.311526\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 0.196518\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 0.212526\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.251909\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.327184\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.313673\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.285912\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.188070\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.272235\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.299835\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.316098\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.211040\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.247721\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.287994\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.238401\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.273117\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.312322\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.186219\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.330776\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.139988\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.319236\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.292642\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.116229\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.206366\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.185944\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.224464\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.313376\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.339212\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.213082\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.178148\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.114085\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.173296\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.260900\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.188305\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.196021\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.232634\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.171547\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.145093\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.206713\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.131129\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.184535\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.063287\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.151488\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.133825\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.497779\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.177270\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.219567\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.223136\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.125308\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.261984\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.119219\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.118059\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.300953\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.236375\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.170063\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.109550\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.172989\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.268367\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.243506\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.118992\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.132645\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.402396\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.143700\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.086910\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.110219\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.204768\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.208150\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.050390\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.258014\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.183219\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.094200\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.088441\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.211445\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.220728\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.181236\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.197934\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.266886\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.191089\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.180827\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.180699\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.193997\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.193871\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.226113\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.116064\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.143841\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.217382\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.170716\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.095093\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.081386\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.148610\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.122841\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.203549\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.092076\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.143898\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.191837\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.131662\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.169045\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.195027\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.246692\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.183621\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.165583\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.171763\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.244531\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.140189\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.185916\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.274191\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.140727\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.136863\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.135682\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.158129\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.195954\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.132533\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.164150\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.075548\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.195977\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.238581\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.189183\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.255589\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.205839\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.176437\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.154639\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.115836\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.340334\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.106864\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.125111\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.140809\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.204493\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.105747\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.061101\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.161843\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.101867\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.204665\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.177772\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.075059\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.122635\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.272767\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.099132\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.145557\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.161549\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.302435\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.336307\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.232961\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.171192\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.094458\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.333238\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.268474\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/3910 (0%)]\tLoss: 1.242034\n",
      "Train Epoch: 1 [640/3910 (16%)]\tLoss: 0.342569\n",
      "Train Epoch: 1 [1280/3910 (32%)]\tLoss: 0.416877\n",
      "Train Epoch: 1 [1920/3910 (48%)]\tLoss: 0.307403\n",
      "Train Epoch: 1 [2560/3910 (65%)]\tLoss: 0.354519\n",
      "Train Epoch: 1 [3200/3910 (81%)]\tLoss: 0.160298\n",
      "Train Epoch: 1 [3840/3910 (97%)]\tLoss: 0.231478\n",
      "Train Epoch: 2 [0/3910 (0%)]\tLoss: 0.313114\n",
      "Train Epoch: 2 [640/3910 (16%)]\tLoss: 0.280220\n",
      "Train Epoch: 2 [1280/3910 (32%)]\tLoss: 0.228818\n",
      "Train Epoch: 2 [1920/3910 (48%)]\tLoss: 0.189232\n",
      "Train Epoch: 2 [2560/3910 (65%)]\tLoss: 0.269831\n",
      "Train Epoch: 2 [3200/3910 (81%)]\tLoss: 0.425002\n",
      "Train Epoch: 2 [3840/3910 (97%)]\tLoss: 0.195676\n",
      "Train Epoch: 3 [0/3910 (0%)]\tLoss: 0.337631\n",
      "Train Epoch: 3 [640/3910 (16%)]\tLoss: 0.277809\n",
      "Train Epoch: 3 [1280/3910 (32%)]\tLoss: 0.124783\n",
      "Train Epoch: 3 [1920/3910 (48%)]\tLoss: 0.354432\n",
      "Train Epoch: 3 [2560/3910 (65%)]\tLoss: 0.324747\n",
      "Train Epoch: 3 [3200/3910 (81%)]\tLoss: 0.202541\n",
      "Train Epoch: 3 [3840/3910 (97%)]\tLoss: 0.299971\n",
      "Train Epoch: 4 [0/3910 (0%)]\tLoss: 0.199821\n",
      "Train Epoch: 4 [640/3910 (16%)]\tLoss: 0.514945\n",
      "Train Epoch: 4 [1280/3910 (32%)]\tLoss: 0.260262\n",
      "Train Epoch: 4 [1920/3910 (48%)]\tLoss: 0.189351\n",
      "Train Epoch: 4 [2560/3910 (65%)]\tLoss: 0.285662\n",
      "Train Epoch: 4 [3200/3910 (81%)]\tLoss: 0.205727\n",
      "Train Epoch: 4 [3840/3910 (97%)]\tLoss: 0.485195\n",
      "Train Epoch: 5 [0/3910 (0%)]\tLoss: 0.252176\n",
      "Train Epoch: 5 [640/3910 (16%)]\tLoss: 0.131265\n",
      "Train Epoch: 5 [1280/3910 (32%)]\tLoss: 0.252948\n",
      "Train Epoch: 5 [1920/3910 (48%)]\tLoss: 0.325433\n",
      "Train Epoch: 5 [2560/3910 (65%)]\tLoss: 0.261944\n",
      "Train Epoch: 5 [3200/3910 (81%)]\tLoss: 0.286207\n",
      "Train Epoch: 5 [3840/3910 (97%)]\tLoss: 0.178286\n",
      "Train Epoch: 6 [0/3910 (0%)]\tLoss: 0.339563\n",
      "Train Epoch: 6 [640/3910 (16%)]\tLoss: 0.344093\n",
      "Train Epoch: 6 [1280/3910 (32%)]\tLoss: 0.277883\n",
      "Train Epoch: 6 [1920/3910 (48%)]\tLoss: 0.346922\n",
      "Train Epoch: 6 [2560/3910 (65%)]\tLoss: 0.222318\n",
      "Train Epoch: 6 [3200/3910 (81%)]\tLoss: 0.236997\n",
      "Train Epoch: 6 [3840/3910 (97%)]\tLoss: 0.323828\n",
      "Train Epoch: 7 [0/3910 (0%)]\tLoss: 0.288924\n",
      "Train Epoch: 7 [640/3910 (16%)]\tLoss: 0.205606\n",
      "Train Epoch: 7 [1280/3910 (32%)]\tLoss: 0.189783\n",
      "Train Epoch: 7 [1920/3910 (48%)]\tLoss: 0.296079\n",
      "Train Epoch: 7 [2560/3910 (65%)]\tLoss: 0.080693\n",
      "Train Epoch: 7 [3200/3910 (81%)]\tLoss: 0.114373\n",
      "Train Epoch: 7 [3840/3910 (97%)]\tLoss: 0.422227\n",
      "Train Epoch: 8 [0/3910 (0%)]\tLoss: 0.212391\n",
      "Train Epoch: 8 [640/3910 (16%)]\tLoss: 0.281770\n",
      "Train Epoch: 8 [1280/3910 (32%)]\tLoss: 0.384518\n",
      "Train Epoch: 8 [1920/3910 (48%)]\tLoss: 0.221054\n",
      "Train Epoch: 8 [2560/3910 (65%)]\tLoss: 0.278998\n",
      "Train Epoch: 8 [3200/3910 (81%)]\tLoss: 0.240365\n",
      "Train Epoch: 8 [3840/3910 (97%)]\tLoss: 0.154453\n",
      "Train Epoch: 9 [0/3910 (0%)]\tLoss: 0.183441\n",
      "Train Epoch: 9 [640/3910 (16%)]\tLoss: 0.181393\n",
      "Train Epoch: 9 [1280/3910 (32%)]\tLoss: 0.234823\n",
      "Train Epoch: 9 [1920/3910 (48%)]\tLoss: 0.221211\n",
      "Train Epoch: 9 [2560/3910 (65%)]\tLoss: 0.304594\n",
      "Train Epoch: 9 [3200/3910 (81%)]\tLoss: 0.391626\n",
      "Train Epoch: 9 [3840/3910 (97%)]\tLoss: 0.170385\n",
      "Train Epoch: 10 [0/3910 (0%)]\tLoss: 0.318909\n",
      "Train Epoch: 10 [640/3910 (16%)]\tLoss: 0.135339\n",
      "Train Epoch: 10 [1280/3910 (32%)]\tLoss: 0.357460\n",
      "Train Epoch: 10 [1920/3910 (48%)]\tLoss: 0.235131\n",
      "Train Epoch: 10 [2560/3910 (65%)]\tLoss: 0.188542\n",
      "Train Epoch: 10 [3200/3910 (81%)]\tLoss: 0.139762\n",
      "Train Epoch: 10 [3840/3910 (97%)]\tLoss: 0.108292\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 1.247170\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 0.338612\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 0.219497\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 0.522781\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 0.260227\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 0.364063\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 0.213920\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 0.366346\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 0.105358\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 0.357266\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.145390\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.296328\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 0.245340\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 0.146646\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 0.176674\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.094305\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.255896\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.140989\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.283260\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.400447\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.328227\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.181024\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.220243\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.185651\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.189350\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.112803\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.258781\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.229304\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.381336\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.237586\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.317272\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.161034\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.118091\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.067510\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.172116\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.148205\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.207573\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.093407\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.181002\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.137047\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.230679\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.090980\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.240874\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.246361\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.180576\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.065336\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.245853\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.219514\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.144853\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.132254\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.159803\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.044691\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.050421\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.291431\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.072678\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.237903\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.184328\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.232440\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.128780\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.376801\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.146740\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.160248\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.230398\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.127530\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.279310\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.135611\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.165338\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.102340\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.102853\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.226038\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.109848\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.209226\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.186589\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.157307\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.157987\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.247526\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.025341\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.100985\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.205711\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.123638\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.088132\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.120388\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.043662\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.165858\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.275394\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.126435\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.215807\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.145931\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.123047\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.074635\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.050442\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.356005\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.136878\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.068786\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.107621\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.052837\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.258488\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.186805\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.115665\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.200201\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.108298\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.063955\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.129187\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.113639\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.159379\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.178949\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.043218\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.075974\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.082826\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.081853\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.131670\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.161025\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.176931\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.105564\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.099125\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.105431\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.053842\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.166983\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.094680\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.365099\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/5096 (0%)]\tLoss: 0.408032\n",
      "Train Epoch: 1 [640/5096 (12%)]\tLoss: 0.375680\n",
      "Train Epoch: 1 [1280/5096 (25%)]\tLoss: 0.282315\n",
      "Train Epoch: 1 [1920/5096 (38%)]\tLoss: 0.237327\n",
      "Train Epoch: 1 [2560/5096 (50%)]\tLoss: 0.124214\n",
      "Train Epoch: 1 [3200/5096 (62%)]\tLoss: 0.095374\n",
      "Train Epoch: 1 [3840/5096 (75%)]\tLoss: 0.187762\n",
      "Train Epoch: 1 [4480/5096 (88%)]\tLoss: 0.082942\n",
      "Train Epoch: 2 [0/5096 (0%)]\tLoss: 0.164600\n",
      "Train Epoch: 2 [640/5096 (12%)]\tLoss: 0.143655\n",
      "Train Epoch: 2 [1280/5096 (25%)]\tLoss: 0.073835\n",
      "Train Epoch: 2 [1920/5096 (38%)]\tLoss: 0.184158\n",
      "Train Epoch: 2 [2560/5096 (50%)]\tLoss: 0.100432\n",
      "Train Epoch: 2 [3200/5096 (62%)]\tLoss: 0.099706\n",
      "Train Epoch: 2 [3840/5096 (75%)]\tLoss: 0.334937\n",
      "Train Epoch: 2 [4480/5096 (88%)]\tLoss: 0.330499\n",
      "Train Epoch: 3 [0/5096 (0%)]\tLoss: 0.279613\n",
      "Train Epoch: 3 [640/5096 (12%)]\tLoss: 0.153089\n",
      "Train Epoch: 3 [1280/5096 (25%)]\tLoss: 0.098781\n",
      "Train Epoch: 3 [1920/5096 (38%)]\tLoss: 0.109688\n",
      "Train Epoch: 3 [2560/5096 (50%)]\tLoss: 0.174881\n",
      "Train Epoch: 3 [3200/5096 (62%)]\tLoss: 0.259698\n",
      "Train Epoch: 3 [3840/5096 (75%)]\tLoss: 0.128276\n",
      "Train Epoch: 3 [4480/5096 (88%)]\tLoss: 0.293210\n",
      "Train Epoch: 4 [0/5096 (0%)]\tLoss: 0.255015\n",
      "Train Epoch: 4 [640/5096 (12%)]\tLoss: 0.089099\n",
      "Train Epoch: 4 [1280/5096 (25%)]\tLoss: 0.221885\n",
      "Train Epoch: 4 [1920/5096 (38%)]\tLoss: 0.275041\n",
      "Train Epoch: 4 [2560/5096 (50%)]\tLoss: 0.185923\n",
      "Train Epoch: 4 [3200/5096 (62%)]\tLoss: 0.132496\n",
      "Train Epoch: 4 [3840/5096 (75%)]\tLoss: 0.111044\n",
      "Train Epoch: 4 [4480/5096 (88%)]\tLoss: 0.133191\n",
      "Train Epoch: 5 [0/5096 (0%)]\tLoss: 0.115184\n",
      "Train Epoch: 5 [640/5096 (12%)]\tLoss: 0.161513\n",
      "Train Epoch: 5 [1280/5096 (25%)]\tLoss: 0.273367\n",
      "Train Epoch: 5 [1920/5096 (38%)]\tLoss: 0.071853\n",
      "Train Epoch: 5 [2560/5096 (50%)]\tLoss: 0.158164\n",
      "Train Epoch: 5 [3200/5096 (62%)]\tLoss: 0.134319\n",
      "Train Epoch: 5 [3840/5096 (75%)]\tLoss: 0.156409\n",
      "Train Epoch: 5 [4480/5096 (88%)]\tLoss: 0.084843\n",
      "Train Epoch: 6 [0/5096 (0%)]\tLoss: 0.220540\n",
      "Train Epoch: 6 [640/5096 (12%)]\tLoss: 0.265852\n",
      "Train Epoch: 6 [1280/5096 (25%)]\tLoss: 0.191496\n",
      "Train Epoch: 6 [1920/5096 (38%)]\tLoss: 0.093377\n",
      "Train Epoch: 6 [2560/5096 (50%)]\tLoss: 0.181672\n",
      "Train Epoch: 6 [3200/5096 (62%)]\tLoss: 0.074271\n",
      "Train Epoch: 6 [3840/5096 (75%)]\tLoss: 0.061810\n",
      "Train Epoch: 6 [4480/5096 (88%)]\tLoss: 0.203243\n",
      "Train Epoch: 7 [0/5096 (0%)]\tLoss: 0.099127\n",
      "Train Epoch: 7 [640/5096 (12%)]\tLoss: 0.133502\n",
      "Train Epoch: 7 [1280/5096 (25%)]\tLoss: 0.143868\n",
      "Train Epoch: 7 [1920/5096 (38%)]\tLoss: 0.106999\n",
      "Train Epoch: 7 [2560/5096 (50%)]\tLoss: 0.116892\n",
      "Train Epoch: 7 [3200/5096 (62%)]\tLoss: 0.170408\n",
      "Train Epoch: 7 [3840/5096 (75%)]\tLoss: 0.083666\n",
      "Train Epoch: 7 [4480/5096 (88%)]\tLoss: 0.113793\n",
      "Train Epoch: 8 [0/5096 (0%)]\tLoss: 0.125293\n",
      "Train Epoch: 8 [640/5096 (12%)]\tLoss: 0.236141\n",
      "Train Epoch: 8 [1280/5096 (25%)]\tLoss: 0.194448\n",
      "Train Epoch: 8 [1920/5096 (38%)]\tLoss: 0.073867\n",
      "Train Epoch: 8 [2560/5096 (50%)]\tLoss: 0.028679\n",
      "Train Epoch: 8 [3200/5096 (62%)]\tLoss: 0.137285\n",
      "Train Epoch: 8 [3840/5096 (75%)]\tLoss: 0.058003\n",
      "Train Epoch: 8 [4480/5096 (88%)]\tLoss: 0.231136\n",
      "Train Epoch: 9 [0/5096 (0%)]\tLoss: 0.101573\n",
      "Train Epoch: 9 [640/5096 (12%)]\tLoss: 0.129896\n",
      "Train Epoch: 9 [1280/5096 (25%)]\tLoss: 0.271951\n",
      "Train Epoch: 9 [1920/5096 (38%)]\tLoss: 0.161430\n",
      "Train Epoch: 9 [2560/5096 (50%)]\tLoss: 0.192259\n",
      "Train Epoch: 9 [3200/5096 (62%)]\tLoss: 0.112208\n",
      "Train Epoch: 9 [3840/5096 (75%)]\tLoss: 0.213617\n",
      "Train Epoch: 9 [4480/5096 (88%)]\tLoss: 0.197671\n",
      "Train Epoch: 10 [0/5096 (0%)]\tLoss: 0.020637\n",
      "Train Epoch: 10 [640/5096 (12%)]\tLoss: 0.057288\n",
      "Train Epoch: 10 [1280/5096 (25%)]\tLoss: 0.056880\n",
      "Train Epoch: 10 [1920/5096 (38%)]\tLoss: 0.150828\n",
      "Train Epoch: 10 [2560/5096 (50%)]\tLoss: 0.194320\n",
      "Train Epoch: 10 [3200/5096 (62%)]\tLoss: 0.308354\n",
      "Train Epoch: 10 [3840/5096 (75%)]\tLoss: 0.148245\n",
      "Train Epoch: 10 [4480/5096 (88%)]\tLoss: 0.136733\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/1599 (0%)]\tLoss: 0.873113\n",
      "Train Epoch: 1 [640/1599 (40%)]\tLoss: 0.469131\n",
      "Train Epoch: 1 [1280/1599 (80%)]\tLoss: 0.427805\n",
      "Train Epoch: 2 [0/1599 (0%)]\tLoss: 0.313530\n",
      "Train Epoch: 2 [640/1599 (40%)]\tLoss: 0.329867\n",
      "Train Epoch: 2 [1280/1599 (80%)]\tLoss: 0.424831\n",
      "Train Epoch: 3 [0/1599 (0%)]\tLoss: 0.304306\n",
      "Train Epoch: 3 [640/1599 (40%)]\tLoss: 0.231626\n",
      "Train Epoch: 3 [1280/1599 (80%)]\tLoss: 0.323699\n",
      "Train Epoch: 4 [0/1599 (0%)]\tLoss: 0.324144\n",
      "Train Epoch: 4 [640/1599 (40%)]\tLoss: 0.309177\n",
      "Train Epoch: 4 [1280/1599 (80%)]\tLoss: 0.301593\n",
      "Train Epoch: 5 [0/1599 (0%)]\tLoss: 0.477852\n",
      "Train Epoch: 5 [640/1599 (40%)]\tLoss: 0.277052\n",
      "Train Epoch: 5 [1280/1599 (80%)]\tLoss: 0.466853\n",
      "Train Epoch: 6 [0/1599 (0%)]\tLoss: 0.376896\n",
      "Train Epoch: 6 [640/1599 (40%)]\tLoss: 0.275136\n",
      "Train Epoch: 6 [1280/1599 (80%)]\tLoss: 0.240659\n",
      "Train Epoch: 7 [0/1599 (0%)]\tLoss: 0.321484\n",
      "Train Epoch: 7 [640/1599 (40%)]\tLoss: 0.251993\n",
      "Train Epoch: 7 [1280/1599 (80%)]\tLoss: 0.461354\n",
      "Train Epoch: 8 [0/1599 (0%)]\tLoss: 0.434426\n",
      "Train Epoch: 8 [640/1599 (40%)]\tLoss: 0.257102\n",
      "Train Epoch: 8 [1280/1599 (80%)]\tLoss: 0.286702\n",
      "Train Epoch: 9 [0/1599 (0%)]\tLoss: 0.474849\n",
      "Train Epoch: 9 [640/1599 (40%)]\tLoss: 0.456417\n",
      "Train Epoch: 9 [1280/1599 (80%)]\tLoss: 0.109316\n",
      "Train Epoch: 10 [0/1599 (0%)]\tLoss: 0.542197\n",
      "Train Epoch: 10 [640/1599 (40%)]\tLoss: 0.234995\n",
      "Train Epoch: 10 [1280/1599 (80%)]\tLoss: 0.241865\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/5266 (0%)]\tLoss: 0.860855\n",
      "Train Epoch: 1 [640/5266 (12%)]\tLoss: 0.236181\n",
      "Train Epoch: 1 [1280/5266 (24%)]\tLoss: 0.108269\n",
      "Train Epoch: 1 [1920/5266 (36%)]\tLoss: 0.149482\n",
      "Train Epoch: 1 [2560/5266 (48%)]\tLoss: 0.155538\n",
      "Train Epoch: 1 [3200/5266 (60%)]\tLoss: 0.157237\n",
      "Train Epoch: 1 [3840/5266 (72%)]\tLoss: 0.123611\n",
      "Train Epoch: 1 [4480/5266 (84%)]\tLoss: 0.103663\n",
      "Train Epoch: 1 [5120/5266 (96%)]\tLoss: 0.138481\n",
      "Train Epoch: 2 [0/5266 (0%)]\tLoss: 0.216637\n",
      "Train Epoch: 2 [640/5266 (12%)]\tLoss: 0.054690\n",
      "Train Epoch: 2 [1280/5266 (24%)]\tLoss: 0.115135\n",
      "Train Epoch: 2 [1920/5266 (36%)]\tLoss: 0.129060\n",
      "Train Epoch: 2 [2560/5266 (48%)]\tLoss: 0.170052\n",
      "Train Epoch: 2 [3200/5266 (60%)]\tLoss: 0.099214\n",
      "Train Epoch: 2 [3840/5266 (72%)]\tLoss: 0.082890\n",
      "Train Epoch: 2 [4480/5266 (84%)]\tLoss: 0.166323\n",
      "Train Epoch: 2 [5120/5266 (96%)]\tLoss: 0.159105\n",
      "Train Epoch: 3 [0/5266 (0%)]\tLoss: 0.042198\n",
      "Train Epoch: 3 [640/5266 (12%)]\tLoss: 0.235946\n",
      "Train Epoch: 3 [1280/5266 (24%)]\tLoss: 0.091956\n",
      "Train Epoch: 3 [1920/5266 (36%)]\tLoss: 0.090712\n",
      "Train Epoch: 3 [2560/5266 (48%)]\tLoss: 0.040080\n",
      "Train Epoch: 3 [3200/5266 (60%)]\tLoss: 0.043448\n",
      "Train Epoch: 3 [3840/5266 (72%)]\tLoss: 0.081702\n",
      "Train Epoch: 3 [4480/5266 (84%)]\tLoss: 0.045967\n",
      "Train Epoch: 3 [5120/5266 (96%)]\tLoss: 0.097051\n",
      "Train Epoch: 4 [0/5266 (0%)]\tLoss: 0.224394\n",
      "Train Epoch: 4 [640/5266 (12%)]\tLoss: 0.370109\n",
      "Train Epoch: 4 [1280/5266 (24%)]\tLoss: 0.136564\n",
      "Train Epoch: 4 [1920/5266 (36%)]\tLoss: 0.109249\n",
      "Train Epoch: 4 [2560/5266 (48%)]\tLoss: 0.076055\n",
      "Train Epoch: 4 [3200/5266 (60%)]\tLoss: 0.160553\n",
      "Train Epoch: 4 [3840/5266 (72%)]\tLoss: 0.153900\n",
      "Train Epoch: 4 [4480/5266 (84%)]\tLoss: 0.080791\n",
      "Train Epoch: 4 [5120/5266 (96%)]\tLoss: 0.041239\n",
      "Train Epoch: 5 [0/5266 (0%)]\tLoss: 0.112527\n",
      "Train Epoch: 5 [640/5266 (12%)]\tLoss: 0.058907\n",
      "Train Epoch: 5 [1280/5266 (24%)]\tLoss: 0.060807\n",
      "Train Epoch: 5 [1920/5266 (36%)]\tLoss: 0.043711\n",
      "Train Epoch: 5 [2560/5266 (48%)]\tLoss: 0.122315\n",
      "Train Epoch: 5 [3200/5266 (60%)]\tLoss: 0.088698\n",
      "Train Epoch: 5 [3840/5266 (72%)]\tLoss: 0.159424\n",
      "Train Epoch: 5 [4480/5266 (84%)]\tLoss: 0.213082\n",
      "Train Epoch: 5 [5120/5266 (96%)]\tLoss: 0.095345\n",
      "Train Epoch: 6 [0/5266 (0%)]\tLoss: 0.075581\n",
      "Train Epoch: 6 [640/5266 (12%)]\tLoss: 0.082127\n",
      "Train Epoch: 6 [1280/5266 (24%)]\tLoss: 0.192825\n",
      "Train Epoch: 6 [1920/5266 (36%)]\tLoss: 0.105039\n",
      "Train Epoch: 6 [2560/5266 (48%)]\tLoss: 0.046619\n",
      "Train Epoch: 6 [3200/5266 (60%)]\tLoss: 0.043135\n",
      "Train Epoch: 6 [3840/5266 (72%)]\tLoss: 0.102129\n",
      "Train Epoch: 6 [4480/5266 (84%)]\tLoss: 0.161640\n",
      "Train Epoch: 6 [5120/5266 (96%)]\tLoss: 0.058693\n",
      "Train Epoch: 7 [0/5266 (0%)]\tLoss: 0.102078\n",
      "Train Epoch: 7 [640/5266 (12%)]\tLoss: 0.081152\n",
      "Train Epoch: 7 [1280/5266 (24%)]\tLoss: 0.034673\n",
      "Train Epoch: 7 [1920/5266 (36%)]\tLoss: 0.141877\n",
      "Train Epoch: 7 [2560/5266 (48%)]\tLoss: 0.171158\n",
      "Train Epoch: 7 [3200/5266 (60%)]\tLoss: 0.135784\n",
      "Train Epoch: 7 [3840/5266 (72%)]\tLoss: 0.027650\n",
      "Train Epoch: 7 [4480/5266 (84%)]\tLoss: 0.174362\n",
      "Train Epoch: 7 [5120/5266 (96%)]\tLoss: 0.078826\n",
      "Train Epoch: 8 [0/5266 (0%)]\tLoss: 0.189983\n",
      "Train Epoch: 8 [640/5266 (12%)]\tLoss: 0.023640\n",
      "Train Epoch: 8 [1280/5266 (24%)]\tLoss: 0.053793\n",
      "Train Epoch: 8 [1920/5266 (36%)]\tLoss: 0.259217\n",
      "Train Epoch: 8 [2560/5266 (48%)]\tLoss: 0.090821\n",
      "Train Epoch: 8 [3200/5266 (60%)]\tLoss: 0.157247\n",
      "Train Epoch: 8 [3840/5266 (72%)]\tLoss: 0.028398\n",
      "Train Epoch: 8 [4480/5266 (84%)]\tLoss: 0.072116\n",
      "Train Epoch: 8 [5120/5266 (96%)]\tLoss: 0.014744\n",
      "Train Epoch: 9 [0/5266 (0%)]\tLoss: 0.197619\n",
      "Train Epoch: 9 [640/5266 (12%)]\tLoss: 0.089144\n",
      "Train Epoch: 9 [1280/5266 (24%)]\tLoss: 0.051316\n",
      "Train Epoch: 9 [1920/5266 (36%)]\tLoss: 0.045767\n",
      "Train Epoch: 9 [2560/5266 (48%)]\tLoss: 0.081646\n",
      "Train Epoch: 9 [3200/5266 (60%)]\tLoss: 0.089190\n",
      "Train Epoch: 9 [3840/5266 (72%)]\tLoss: 0.092631\n",
      "Train Epoch: 9 [4480/5266 (84%)]\tLoss: 0.028197\n",
      "Train Epoch: 9 [5120/5266 (96%)]\tLoss: 0.094780\n",
      "Train Epoch: 10 [0/5266 (0%)]\tLoss: 0.152001\n",
      "Train Epoch: 10 [640/5266 (12%)]\tLoss: 0.078809\n",
      "Train Epoch: 10 [1280/5266 (24%)]\tLoss: 0.094145\n",
      "Train Epoch: 10 [1920/5266 (36%)]\tLoss: 0.101852\n",
      "Train Epoch: 10 [2560/5266 (48%)]\tLoss: 0.207194\n",
      "Train Epoch: 10 [3200/5266 (60%)]\tLoss: 0.075898\n",
      "Train Epoch: 10 [3840/5266 (72%)]\tLoss: 0.081435\n",
      "Train Epoch: 10 [4480/5266 (84%)]\tLoss: 0.123053\n",
      "Train Epoch: 10 [5120/5266 (96%)]\tLoss: 0.032225\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/3530 (0%)]\tLoss: 0.844773\n",
      "Train Epoch: 1 [640/3530 (18%)]\tLoss: 0.548766\n",
      "Train Epoch: 1 [1280/3530 (36%)]\tLoss: 0.289798\n",
      "Train Epoch: 1 [1920/3530 (54%)]\tLoss: 0.353449\n",
      "Train Epoch: 1 [2560/3530 (71%)]\tLoss: 0.343281\n",
      "Train Epoch: 1 [3200/3530 (89%)]\tLoss: 0.614201\n",
      "Train Epoch: 2 [0/3530 (0%)]\tLoss: 0.376638\n",
      "Train Epoch: 2 [640/3530 (18%)]\tLoss: 0.348517\n",
      "Train Epoch: 2 [1280/3530 (36%)]\tLoss: 0.401882\n",
      "Train Epoch: 2 [1920/3530 (54%)]\tLoss: 0.401171\n",
      "Train Epoch: 2 [2560/3530 (71%)]\tLoss: 0.301953\n",
      "Train Epoch: 2 [3200/3530 (89%)]\tLoss: 0.207859\n",
      "Train Epoch: 3 [0/3530 (0%)]\tLoss: 0.213628\n",
      "Train Epoch: 3 [640/3530 (18%)]\tLoss: 0.222750\n",
      "Train Epoch: 3 [1280/3530 (36%)]\tLoss: 0.282688\n",
      "Train Epoch: 3 [1920/3530 (54%)]\tLoss: 0.256580\n",
      "Train Epoch: 3 [2560/3530 (71%)]\tLoss: 0.310497\n",
      "Train Epoch: 3 [3200/3530 (89%)]\tLoss: 0.236869\n",
      "Train Epoch: 4 [0/3530 (0%)]\tLoss: 0.314101\n",
      "Train Epoch: 4 [640/3530 (18%)]\tLoss: 0.198698\n",
      "Train Epoch: 4 [1280/3530 (36%)]\tLoss: 0.181320\n",
      "Train Epoch: 4 [1920/3530 (54%)]\tLoss: 0.282002\n",
      "Train Epoch: 4 [2560/3530 (71%)]\tLoss: 0.237958\n",
      "Train Epoch: 4 [3200/3530 (89%)]\tLoss: 0.268127\n",
      "Train Epoch: 5 [0/3530 (0%)]\tLoss: 0.279270\n",
      "Train Epoch: 5 [640/3530 (18%)]\tLoss: 0.121188\n",
      "Train Epoch: 5 [1280/3530 (36%)]\tLoss: 0.292035\n",
      "Train Epoch: 5 [1920/3530 (54%)]\tLoss: 0.170380\n",
      "Train Epoch: 5 [2560/3530 (71%)]\tLoss: 0.382155\n",
      "Train Epoch: 5 [3200/3530 (89%)]\tLoss: 0.326176\n",
      "Train Epoch: 6 [0/3530 (0%)]\tLoss: 0.267868\n",
      "Train Epoch: 6 [640/3530 (18%)]\tLoss: 0.210124\n",
      "Train Epoch: 6 [1280/3530 (36%)]\tLoss: 0.475258\n",
      "Train Epoch: 6 [1920/3530 (54%)]\tLoss: 0.300558\n",
      "Train Epoch: 6 [2560/3530 (71%)]\tLoss: 0.213845\n",
      "Train Epoch: 6 [3200/3530 (89%)]\tLoss: 0.322332\n",
      "Train Epoch: 7 [0/3530 (0%)]\tLoss: 0.183223\n",
      "Train Epoch: 7 [640/3530 (18%)]\tLoss: 0.207477\n",
      "Train Epoch: 7 [1280/3530 (36%)]\tLoss: 0.258171\n",
      "Train Epoch: 7 [1920/3530 (54%)]\tLoss: 0.175967\n",
      "Train Epoch: 7 [2560/3530 (71%)]\tLoss: 0.270534\n",
      "Train Epoch: 7 [3200/3530 (89%)]\tLoss: 0.183109\n",
      "Train Epoch: 8 [0/3530 (0%)]\tLoss: 0.223186\n",
      "Train Epoch: 8 [640/3530 (18%)]\tLoss: 0.264797\n",
      "Train Epoch: 8 [1280/3530 (36%)]\tLoss: 0.340467\n",
      "Train Epoch: 8 [1920/3530 (54%)]\tLoss: 0.090870\n",
      "Train Epoch: 8 [2560/3530 (71%)]\tLoss: 0.339935\n",
      "Train Epoch: 8 [3200/3530 (89%)]\tLoss: 0.224845\n",
      "Train Epoch: 9 [0/3530 (0%)]\tLoss: 0.227138\n",
      "Train Epoch: 9 [640/3530 (18%)]\tLoss: 0.263832\n",
      "Train Epoch: 9 [1280/3530 (36%)]\tLoss: 0.143880\n",
      "Train Epoch: 9 [1920/3530 (54%)]\tLoss: 0.257895\n",
      "Train Epoch: 9 [2560/3530 (71%)]\tLoss: 0.152742\n",
      "Train Epoch: 9 [3200/3530 (89%)]\tLoss: 0.326828\n",
      "Train Epoch: 10 [0/3530 (0%)]\tLoss: 0.256734\n",
      "Train Epoch: 10 [640/3530 (18%)]\tLoss: 0.164700\n",
      "Train Epoch: 10 [1280/3530 (36%)]\tLoss: 0.176350\n",
      "Train Epoch: 10 [1920/3530 (54%)]\tLoss: 0.222897\n",
      "Train Epoch: 10 [2560/3530 (71%)]\tLoss: 0.226051\n",
      "Train Epoch: 10 [3200/3530 (89%)]\tLoss: 0.383387\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.3255, Accuracy: 9097/10000 (91%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 0.631453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 0.478668\n",
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 0.259439\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 0.314512\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 0.355186\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 0.307330\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 0.239076\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 0.404418\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 0.212018\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 0.320273\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 0.278264\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 0.150392\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 0.265122\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 0.372814\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 0.145400\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 0.389899\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 0.379063\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 0.314205\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 0.722804\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 0.368491\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.460874\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 0.488492\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 0.243201\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.259575\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.242629\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 0.347058\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.211791\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 0.147170\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.331304\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.371308\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.216677\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.166019\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.251482\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.170352\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.404819\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.276628\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.265721\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.366698\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.239046\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.146154\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.258340\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.233060\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.160957\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.340028\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.331390\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.218715\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.208498\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.095594\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.291784\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.185382\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.184716\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.241792\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.208974\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.392080\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.165486\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.235007\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.168939\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.204652\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.167436\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.298887\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.164147\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.305129\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.199982\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.149337\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.194173\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.270489\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.229490\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.231875\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.139532\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.293687\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.200992\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.093487\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.130526\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.158578\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.339444\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.133854\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.147493\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.205102\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.163754\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.182080\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.267423\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.185351\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.128125\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.158709\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.115522\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.122373\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.169282\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.319992\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.209741\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.154291\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.139401\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.140185\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.107740\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.253548\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.255024\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.130423\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.083951\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.209576\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.181338\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.124325\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.234065\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.219625\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.373226\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.179582\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.253276\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.186110\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.145575\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.117997\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 0.055660\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.108989\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.304459\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.098256\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.114807\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.159380\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.175217\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.244876\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.128280\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.114540\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.279366\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.169298\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.273179\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.193946\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.164612\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.133661\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.271354\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.159559\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.208722\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.142773\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.157873\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.256825\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.282535\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.204840\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.179654\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.209133\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.234922\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.110674\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.190991\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.115806\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.228304\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.097464\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.267739\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.119984\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.253042\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.395837\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.156707\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.256037\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.052393\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.222102\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.219287\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.504154\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.267799\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.201426\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.599846\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.115120\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.042766\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.256594\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.032664\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.147913\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.103614\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.041351\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.142818\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.159444\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.263456\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.210825\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.299877\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.198228\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.055558\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.247803\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.091586\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.068780\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.232508\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.087558\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.229694\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.211057\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.264688\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.162637\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.088391\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.181938\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.294460\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.076962\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/5110 (0%)]\tLoss: 0.481561\n",
      "Train Epoch: 1 [640/5110 (12%)]\tLoss: 0.488164\n",
      "Train Epoch: 1 [1280/5110 (25%)]\tLoss: 0.402881\n",
      "Train Epoch: 1 [1920/5110 (38%)]\tLoss: 0.215787\n",
      "Train Epoch: 1 [2560/5110 (50%)]\tLoss: 0.189220\n",
      "Train Epoch: 1 [3200/5110 (62%)]\tLoss: 0.225984\n",
      "Train Epoch: 1 [3840/5110 (75%)]\tLoss: 0.172642\n",
      "Train Epoch: 1 [4480/5110 (88%)]\tLoss: 0.491653\n",
      "Train Epoch: 2 [0/5110 (0%)]\tLoss: 0.254810\n",
      "Train Epoch: 2 [640/5110 (12%)]\tLoss: 0.127349\n",
      "Train Epoch: 2 [1280/5110 (25%)]\tLoss: 0.143162\n",
      "Train Epoch: 2 [1920/5110 (38%)]\tLoss: 0.300297\n",
      "Train Epoch: 2 [2560/5110 (50%)]\tLoss: 0.190496\n",
      "Train Epoch: 2 [3200/5110 (62%)]\tLoss: 0.403201\n",
      "Train Epoch: 2 [3840/5110 (75%)]\tLoss: 0.296306\n",
      "Train Epoch: 2 [4480/5110 (88%)]\tLoss: 0.232626\n",
      "Train Epoch: 3 [0/5110 (0%)]\tLoss: 0.117229\n",
      "Train Epoch: 3 [640/5110 (12%)]\tLoss: 0.221952\n",
      "Train Epoch: 3 [1280/5110 (25%)]\tLoss: 0.340141\n",
      "Train Epoch: 3 [1920/5110 (38%)]\tLoss: 0.296743\n",
      "Train Epoch: 3 [2560/5110 (50%)]\tLoss: 0.150258\n",
      "Train Epoch: 3 [3200/5110 (62%)]\tLoss: 0.161924\n",
      "Train Epoch: 3 [3840/5110 (75%)]\tLoss: 0.194997\n",
      "Train Epoch: 3 [4480/5110 (88%)]\tLoss: 0.121831\n",
      "Train Epoch: 4 [0/5110 (0%)]\tLoss: 0.321143\n",
      "Train Epoch: 4 [640/5110 (12%)]\tLoss: 0.273044\n",
      "Train Epoch: 4 [1280/5110 (25%)]\tLoss: 0.198756\n",
      "Train Epoch: 4 [1920/5110 (38%)]\tLoss: 0.234605\n",
      "Train Epoch: 4 [2560/5110 (50%)]\tLoss: 0.399642\n",
      "Train Epoch: 4 [3200/5110 (62%)]\tLoss: 0.120012\n",
      "Train Epoch: 4 [3840/5110 (75%)]\tLoss: 0.175577\n",
      "Train Epoch: 4 [4480/5110 (88%)]\tLoss: 0.285404\n",
      "Train Epoch: 5 [0/5110 (0%)]\tLoss: 0.249607\n",
      "Train Epoch: 5 [640/5110 (12%)]\tLoss: 0.161663\n",
      "Train Epoch: 5 [1280/5110 (25%)]\tLoss: 0.171264\n",
      "Train Epoch: 5 [1920/5110 (38%)]\tLoss: 0.209352\n",
      "Train Epoch: 5 [2560/5110 (50%)]\tLoss: 0.210629\n",
      "Train Epoch: 5 [3200/5110 (62%)]\tLoss: 0.156026\n",
      "Train Epoch: 5 [3840/5110 (75%)]\tLoss: 0.120117\n",
      "Train Epoch: 5 [4480/5110 (88%)]\tLoss: 0.182233\n",
      "Train Epoch: 6 [0/5110 (0%)]\tLoss: 0.165684\n",
      "Train Epoch: 6 [640/5110 (12%)]\tLoss: 0.222531\n",
      "Train Epoch: 6 [1280/5110 (25%)]\tLoss: 0.242229\n",
      "Train Epoch: 6 [1920/5110 (38%)]\tLoss: 0.121315\n",
      "Train Epoch: 6 [2560/5110 (50%)]\tLoss: 0.277282\n",
      "Train Epoch: 6 [3200/5110 (62%)]\tLoss: 0.273000\n",
      "Train Epoch: 6 [3840/5110 (75%)]\tLoss: 0.117735\n",
      "Train Epoch: 6 [4480/5110 (88%)]\tLoss: 0.127176\n",
      "Train Epoch: 7 [0/5110 (0%)]\tLoss: 0.213320\n",
      "Train Epoch: 7 [640/5110 (12%)]\tLoss: 0.240881\n",
      "Train Epoch: 7 [1280/5110 (25%)]\tLoss: 0.115089\n",
      "Train Epoch: 7 [1920/5110 (38%)]\tLoss: 0.409616\n",
      "Train Epoch: 7 [2560/5110 (50%)]\tLoss: 0.114355\n",
      "Train Epoch: 7 [3200/5110 (62%)]\tLoss: 0.108422\n",
      "Train Epoch: 7 [3840/5110 (75%)]\tLoss: 0.161923\n",
      "Train Epoch: 7 [4480/5110 (88%)]\tLoss: 0.411148\n",
      "Train Epoch: 8 [0/5110 (0%)]\tLoss: 0.135429\n",
      "Train Epoch: 8 [640/5110 (12%)]\tLoss: 0.187557\n",
      "Train Epoch: 8 [1280/5110 (25%)]\tLoss: 0.141140\n",
      "Train Epoch: 8 [1920/5110 (38%)]\tLoss: 0.187261\n",
      "Train Epoch: 8 [2560/5110 (50%)]\tLoss: 0.143319\n",
      "Train Epoch: 8 [3200/5110 (62%)]\tLoss: 0.163605\n",
      "Train Epoch: 8 [3840/5110 (75%)]\tLoss: 0.147829\n",
      "Train Epoch: 8 [4480/5110 (88%)]\tLoss: 0.184116\n",
      "Train Epoch: 9 [0/5110 (0%)]\tLoss: 0.190934\n",
      "Train Epoch: 9 [640/5110 (12%)]\tLoss: 0.153783\n",
      "Train Epoch: 9 [1280/5110 (25%)]\tLoss: 0.148927\n",
      "Train Epoch: 9 [1920/5110 (38%)]\tLoss: 0.148035\n",
      "Train Epoch: 9 [2560/5110 (50%)]\tLoss: 0.169705\n",
      "Train Epoch: 9 [3200/5110 (62%)]\tLoss: 0.244553\n",
      "Train Epoch: 9 [3840/5110 (75%)]\tLoss: 0.131388\n",
      "Train Epoch: 9 [4480/5110 (88%)]\tLoss: 0.127754\n",
      "Train Epoch: 10 [0/5110 (0%)]\tLoss: 0.282635\n",
      "Train Epoch: 10 [640/5110 (12%)]\tLoss: 0.133157\n",
      "Train Epoch: 10 [1280/5110 (25%)]\tLoss: 0.180953\n",
      "Train Epoch: 10 [1920/5110 (38%)]\tLoss: 0.159167\n",
      "Train Epoch: 10 [2560/5110 (50%)]\tLoss: 0.102121\n",
      "Train Epoch: 10 [3200/5110 (62%)]\tLoss: 0.213503\n",
      "Train Epoch: 10 [3840/5110 (75%)]\tLoss: 0.176239\n",
      "Train Epoch: 10 [4480/5110 (88%)]\tLoss: 0.125788\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6766 (0%)]\tLoss: 0.416790\n",
      "Train Epoch: 1 [640/6766 (9%)]\tLoss: 0.231990\n",
      "Train Epoch: 1 [1280/6766 (19%)]\tLoss: 0.324735\n",
      "Train Epoch: 1 [1920/6766 (28%)]\tLoss: 0.228828\n",
      "Train Epoch: 1 [2560/6766 (38%)]\tLoss: 0.205094\n",
      "Train Epoch: 1 [3200/6766 (47%)]\tLoss: 0.125641\n",
      "Train Epoch: 1 [3840/6766 (57%)]\tLoss: 0.311027\n",
      "Train Epoch: 1 [4480/6766 (66%)]\tLoss: 0.109478\n",
      "Train Epoch: 1 [5120/6766 (75%)]\tLoss: 0.138127\n",
      "Train Epoch: 1 [5760/6766 (85%)]\tLoss: 0.243943\n",
      "Train Epoch: 1 [6400/6766 (94%)]\tLoss: 0.119804\n",
      "Train Epoch: 2 [0/6766 (0%)]\tLoss: 0.259379\n",
      "Train Epoch: 2 [640/6766 (9%)]\tLoss: 0.274007\n",
      "Train Epoch: 2 [1280/6766 (19%)]\tLoss: 0.157106\n",
      "Train Epoch: 2 [1920/6766 (28%)]\tLoss: 0.347174\n",
      "Train Epoch: 2 [2560/6766 (38%)]\tLoss: 0.058329\n",
      "Train Epoch: 2 [3200/6766 (47%)]\tLoss: 0.121466\n",
      "Train Epoch: 2 [3840/6766 (57%)]\tLoss: 0.281252\n",
      "Train Epoch: 2 [4480/6766 (66%)]\tLoss: 0.231291\n",
      "Train Epoch: 2 [5120/6766 (75%)]\tLoss: 0.175993\n",
      "Train Epoch: 2 [5760/6766 (85%)]\tLoss: 0.288480\n",
      "Train Epoch: 2 [6400/6766 (94%)]\tLoss: 0.141470\n",
      "Train Epoch: 3 [0/6766 (0%)]\tLoss: 0.131686\n",
      "Train Epoch: 3 [640/6766 (9%)]\tLoss: 0.151298\n",
      "Train Epoch: 3 [1280/6766 (19%)]\tLoss: 0.306654\n",
      "Train Epoch: 3 [1920/6766 (28%)]\tLoss: 0.224591\n",
      "Train Epoch: 3 [2560/6766 (38%)]\tLoss: 0.279826\n",
      "Train Epoch: 3 [3200/6766 (47%)]\tLoss: 0.365543\n",
      "Train Epoch: 3 [3840/6766 (57%)]\tLoss: 0.269213\n",
      "Train Epoch: 3 [4480/6766 (66%)]\tLoss: 0.157408\n",
      "Train Epoch: 3 [5120/6766 (75%)]\tLoss: 0.123079\n",
      "Train Epoch: 3 [5760/6766 (85%)]\tLoss: 0.130279\n",
      "Train Epoch: 3 [6400/6766 (94%)]\tLoss: 0.333167\n",
      "Train Epoch: 4 [0/6766 (0%)]\tLoss: 0.202578\n",
      "Train Epoch: 4 [640/6766 (9%)]\tLoss: 0.125347\n",
      "Train Epoch: 4 [1280/6766 (19%)]\tLoss: 0.095200\n",
      "Train Epoch: 4 [1920/6766 (28%)]\tLoss: 0.145900\n",
      "Train Epoch: 4 [2560/6766 (38%)]\tLoss: 0.276669\n",
      "Train Epoch: 4 [3200/6766 (47%)]\tLoss: 0.168479\n",
      "Train Epoch: 4 [3840/6766 (57%)]\tLoss: 0.143769\n",
      "Train Epoch: 4 [4480/6766 (66%)]\tLoss: 0.341160\n",
      "Train Epoch: 4 [5120/6766 (75%)]\tLoss: 0.181485\n",
      "Train Epoch: 4 [5760/6766 (85%)]\tLoss: 0.076984\n",
      "Train Epoch: 4 [6400/6766 (94%)]\tLoss: 0.247609\n",
      "Train Epoch: 5 [0/6766 (0%)]\tLoss: 0.243422\n",
      "Train Epoch: 5 [640/6766 (9%)]\tLoss: 0.211304\n",
      "Train Epoch: 5 [1280/6766 (19%)]\tLoss: 0.271081\n",
      "Train Epoch: 5 [1920/6766 (28%)]\tLoss: 0.120345\n",
      "Train Epoch: 5 [2560/6766 (38%)]\tLoss: 0.064178\n",
      "Train Epoch: 5 [3200/6766 (47%)]\tLoss: 0.162569\n",
      "Train Epoch: 5 [3840/6766 (57%)]\tLoss: 0.247699\n",
      "Train Epoch: 5 [4480/6766 (66%)]\tLoss: 0.159797\n",
      "Train Epoch: 5 [5120/6766 (75%)]\tLoss: 0.097225\n",
      "Train Epoch: 5 [5760/6766 (85%)]\tLoss: 0.102708\n",
      "Train Epoch: 5 [6400/6766 (94%)]\tLoss: 0.072469\n",
      "Train Epoch: 6 [0/6766 (0%)]\tLoss: 0.116063\n",
      "Train Epoch: 6 [640/6766 (9%)]\tLoss: 0.257413\n",
      "Train Epoch: 6 [1280/6766 (19%)]\tLoss: 0.248304\n",
      "Train Epoch: 6 [1920/6766 (28%)]\tLoss: 0.040974\n",
      "Train Epoch: 6 [2560/6766 (38%)]\tLoss: 0.232296\n",
      "Train Epoch: 6 [3200/6766 (47%)]\tLoss: 0.133319\n",
      "Train Epoch: 6 [3840/6766 (57%)]\tLoss: 0.187962\n",
      "Train Epoch: 6 [4480/6766 (66%)]\tLoss: 0.243738\n",
      "Train Epoch: 6 [5120/6766 (75%)]\tLoss: 0.158751\n",
      "Train Epoch: 6 [5760/6766 (85%)]\tLoss: 0.170944\n",
      "Train Epoch: 6 [6400/6766 (94%)]\tLoss: 0.136258\n",
      "Train Epoch: 7 [0/6766 (0%)]\tLoss: 0.119656\n",
      "Train Epoch: 7 [640/6766 (9%)]\tLoss: 0.108641\n",
      "Train Epoch: 7 [1280/6766 (19%)]\tLoss: 0.068646\n",
      "Train Epoch: 7 [1920/6766 (28%)]\tLoss: 0.146357\n",
      "Train Epoch: 7 [2560/6766 (38%)]\tLoss: 0.302038\n",
      "Train Epoch: 7 [3200/6766 (47%)]\tLoss: 0.212899\n",
      "Train Epoch: 7 [3840/6766 (57%)]\tLoss: 0.078317\n",
      "Train Epoch: 7 [4480/6766 (66%)]\tLoss: 0.275919\n",
      "Train Epoch: 7 [5120/6766 (75%)]\tLoss: 0.092869\n",
      "Train Epoch: 7 [5760/6766 (85%)]\tLoss: 0.066452\n",
      "Train Epoch: 7 [6400/6766 (94%)]\tLoss: 0.134618\n",
      "Train Epoch: 8 [0/6766 (0%)]\tLoss: 0.083292\n",
      "Train Epoch: 8 [640/6766 (9%)]\tLoss: 0.109123\n",
      "Train Epoch: 8 [1280/6766 (19%)]\tLoss: 0.194097\n",
      "Train Epoch: 8 [1920/6766 (28%)]\tLoss: 0.268390\n",
      "Train Epoch: 8 [2560/6766 (38%)]\tLoss: 0.056518\n",
      "Train Epoch: 8 [3200/6766 (47%)]\tLoss: 0.191934\n",
      "Train Epoch: 8 [3840/6766 (57%)]\tLoss: 0.081758\n",
      "Train Epoch: 8 [4480/6766 (66%)]\tLoss: 0.057250\n",
      "Train Epoch: 8 [5120/6766 (75%)]\tLoss: 0.112052\n",
      "Train Epoch: 8 [5760/6766 (85%)]\tLoss: 0.333537\n",
      "Train Epoch: 8 [6400/6766 (94%)]\tLoss: 0.048810\n",
      "Train Epoch: 9 [0/6766 (0%)]\tLoss: 0.036456\n",
      "Train Epoch: 9 [640/6766 (9%)]\tLoss: 0.123685\n",
      "Train Epoch: 9 [1280/6766 (19%)]\tLoss: 0.160923\n",
      "Train Epoch: 9 [1920/6766 (28%)]\tLoss: 0.147020\n",
      "Train Epoch: 9 [2560/6766 (38%)]\tLoss: 0.155815\n",
      "Train Epoch: 9 [3200/6766 (47%)]\tLoss: 0.202491\n",
      "Train Epoch: 9 [3840/6766 (57%)]\tLoss: 0.157047\n",
      "Train Epoch: 9 [4480/6766 (66%)]\tLoss: 0.041512\n",
      "Train Epoch: 9 [5120/6766 (75%)]\tLoss: 0.221464\n",
      "Train Epoch: 9 [5760/6766 (85%)]\tLoss: 0.150984\n",
      "Train Epoch: 9 [6400/6766 (94%)]\tLoss: 0.092034\n",
      "Train Epoch: 10 [0/6766 (0%)]\tLoss: 0.200619\n",
      "Train Epoch: 10 [640/6766 (9%)]\tLoss: 0.174699\n",
      "Train Epoch: 10 [1280/6766 (19%)]\tLoss: 0.166250\n",
      "Train Epoch: 10 [1920/6766 (28%)]\tLoss: 0.219137\n",
      "Train Epoch: 10 [2560/6766 (38%)]\tLoss: 0.144554\n",
      "Train Epoch: 10 [3200/6766 (47%)]\tLoss: 0.079530\n",
      "Train Epoch: 10 [3840/6766 (57%)]\tLoss: 0.030252\n",
      "Train Epoch: 10 [4480/6766 (66%)]\tLoss: 0.116210\n",
      "Train Epoch: 10 [5120/6766 (75%)]\tLoss: 0.043609\n",
      "Train Epoch: 10 [5760/6766 (85%)]\tLoss: 0.145650\n",
      "Train Epoch: 10 [6400/6766 (94%)]\tLoss: 0.194561\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 0.642531\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 0.307325\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 0.257673\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 0.355812\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 0.174829\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 0.184034\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 0.368768\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 0.178802\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 0.155916\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 0.335885\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 0.150950\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 0.340202\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 0.276314\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 0.223873\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 0.281855\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 0.253359\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 0.159828\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.316549\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.159751\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.281054\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.216681\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.261780\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.169745\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.198400\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.135739\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.115460\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.143651\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.195883\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.175644\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.111912\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.191926\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.220757\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.074358\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.350662\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.196895\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.340746\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.308261\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.191723\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.137961\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.125831\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.144443\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.127119\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.104300\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.167610\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.271392\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.141282\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.144805\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.227300\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.168309\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.233381\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.211497\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.371128\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.178979\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.232685\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.095639\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.081915\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.446965\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.107645\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.279673\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.075965\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.148607\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.115570\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.381601\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.085842\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.210987\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.109597\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.243079\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.060015\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.245403\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.275694\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.135104\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.211332\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.360512\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.154790\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.143532\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.205756\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.113792\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.229707\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.114393\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.103191\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.171153\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.176478\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.286871\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.167721\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.085856\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.200313\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.169790\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.093071\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.196185\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.173053\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.192919\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.344944\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.412696\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.045810\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.100409\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.180611\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.142392\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.106453\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.196178\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.235687\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.180823\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.183682\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.191880\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.259322\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.147394\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.223052\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.075560\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.046985\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.059205\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.250217\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.264320\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.211934\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.158640\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.166000\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.101058\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.183120\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.159864\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.047098\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.359613\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.207716\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.356712\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.270124\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.085070\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.073481\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.189519\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.087167\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.125958\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.139404\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.082968\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.110022\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.254417\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.170288\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.078181\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.089466\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.183789\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.232237\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.078711\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.273097\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.032722\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.096885\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.179251\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.115543\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.179929\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.194795\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.111582\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.133448\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.144828\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.086698\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.256805\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.097859\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.101788\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.170613\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.282516\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.118052\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.023789\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.052227\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.147987\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.411228\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.192123\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.118452\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/3910 (0%)]\tLoss: 0.660743\n",
      "Train Epoch: 1 [640/3910 (16%)]\tLoss: 0.231213\n",
      "Train Epoch: 1 [1280/3910 (32%)]\tLoss: 0.199945\n",
      "Train Epoch: 1 [1920/3910 (48%)]\tLoss: 0.287065\n",
      "Train Epoch: 1 [2560/3910 (65%)]\tLoss: 0.135447\n",
      "Train Epoch: 1 [3200/3910 (81%)]\tLoss: 0.276987\n",
      "Train Epoch: 1 [3840/3910 (97%)]\tLoss: 0.172175\n",
      "Train Epoch: 2 [0/3910 (0%)]\tLoss: 0.118057\n",
      "Train Epoch: 2 [640/3910 (16%)]\tLoss: 0.270752\n",
      "Train Epoch: 2 [1280/3910 (32%)]\tLoss: 0.314206\n",
      "Train Epoch: 2 [1920/3910 (48%)]\tLoss: 0.213486\n",
      "Train Epoch: 2 [2560/3910 (65%)]\tLoss: 0.423202\n",
      "Train Epoch: 2 [3200/3910 (81%)]\tLoss: 0.208020\n",
      "Train Epoch: 2 [3840/3910 (97%)]\tLoss: 0.227302\n",
      "Train Epoch: 3 [0/3910 (0%)]\tLoss: 0.143403\n",
      "Train Epoch: 3 [640/3910 (16%)]\tLoss: 0.105245\n",
      "Train Epoch: 3 [1280/3910 (32%)]\tLoss: 0.120441\n",
      "Train Epoch: 3 [1920/3910 (48%)]\tLoss: 0.155854\n",
      "Train Epoch: 3 [2560/3910 (65%)]\tLoss: 0.208061\n",
      "Train Epoch: 3 [3200/3910 (81%)]\tLoss: 0.721115\n",
      "Train Epoch: 3 [3840/3910 (97%)]\tLoss: 0.241099\n",
      "Train Epoch: 4 [0/3910 (0%)]\tLoss: 0.233259\n",
      "Train Epoch: 4 [640/3910 (16%)]\tLoss: 0.347593\n",
      "Train Epoch: 4 [1280/3910 (32%)]\tLoss: 0.217143\n",
      "Train Epoch: 4 [1920/3910 (48%)]\tLoss: 0.187667\n",
      "Train Epoch: 4 [2560/3910 (65%)]\tLoss: 0.251078\n",
      "Train Epoch: 4 [3200/3910 (81%)]\tLoss: 0.132235\n",
      "Train Epoch: 4 [3840/3910 (97%)]\tLoss: 0.105576\n",
      "Train Epoch: 5 [0/3910 (0%)]\tLoss: 0.251757\n",
      "Train Epoch: 5 [640/3910 (16%)]\tLoss: 0.260351\n",
      "Train Epoch: 5 [1280/3910 (32%)]\tLoss: 0.346139\n",
      "Train Epoch: 5 [1920/3910 (48%)]\tLoss: 0.286157\n",
      "Train Epoch: 5 [2560/3910 (65%)]\tLoss: 0.034676\n",
      "Train Epoch: 5 [3200/3910 (81%)]\tLoss: 0.264224\n",
      "Train Epoch: 5 [3840/3910 (97%)]\tLoss: 0.140010\n",
      "Train Epoch: 6 [0/3910 (0%)]\tLoss: 0.279050\n",
      "Train Epoch: 6 [640/3910 (16%)]\tLoss: 0.187212\n",
      "Train Epoch: 6 [1280/3910 (32%)]\tLoss: 0.486212\n",
      "Train Epoch: 6 [1920/3910 (48%)]\tLoss: 0.215178\n",
      "Train Epoch: 6 [2560/3910 (65%)]\tLoss: 0.145448\n",
      "Train Epoch: 6 [3200/3910 (81%)]\tLoss: 0.254666\n",
      "Train Epoch: 6 [3840/3910 (97%)]\tLoss: 0.141991\n",
      "Train Epoch: 7 [0/3910 (0%)]\tLoss: 0.310003\n",
      "Train Epoch: 7 [640/3910 (16%)]\tLoss: 0.191066\n",
      "Train Epoch: 7 [1280/3910 (32%)]\tLoss: 0.210202\n",
      "Train Epoch: 7 [1920/3910 (48%)]\tLoss: 0.166960\n",
      "Train Epoch: 7 [2560/3910 (65%)]\tLoss: 0.259015\n",
      "Train Epoch: 7 [3200/3910 (81%)]\tLoss: 0.242103\n",
      "Train Epoch: 7 [3840/3910 (97%)]\tLoss: 0.208005\n",
      "Train Epoch: 8 [0/3910 (0%)]\tLoss: 0.111430\n",
      "Train Epoch: 8 [640/3910 (16%)]\tLoss: 0.178089\n",
      "Train Epoch: 8 [1280/3910 (32%)]\tLoss: 0.189888\n",
      "Train Epoch: 8 [1920/3910 (48%)]\tLoss: 0.280522\n",
      "Train Epoch: 8 [2560/3910 (65%)]\tLoss: 0.189589\n",
      "Train Epoch: 8 [3200/3910 (81%)]\tLoss: 0.413257\n",
      "Train Epoch: 8 [3840/3910 (97%)]\tLoss: 0.147226\n",
      "Train Epoch: 9 [0/3910 (0%)]\tLoss: 0.103866\n",
      "Train Epoch: 9 [640/3910 (16%)]\tLoss: 0.227848\n",
      "Train Epoch: 9 [1280/3910 (32%)]\tLoss: 0.192725\n",
      "Train Epoch: 9 [1920/3910 (48%)]\tLoss: 0.288558\n",
      "Train Epoch: 9 [2560/3910 (65%)]\tLoss: 0.348500\n",
      "Train Epoch: 9 [3200/3910 (81%)]\tLoss: 0.074129\n",
      "Train Epoch: 9 [3840/3910 (97%)]\tLoss: 0.130632\n",
      "Train Epoch: 10 [0/3910 (0%)]\tLoss: 0.134781\n",
      "Train Epoch: 10 [640/3910 (16%)]\tLoss: 0.227358\n",
      "Train Epoch: 10 [1280/3910 (32%)]\tLoss: 0.072745\n",
      "Train Epoch: 10 [1920/3910 (48%)]\tLoss: 0.103992\n",
      "Train Epoch: 10 [2560/3910 (65%)]\tLoss: 0.070587\n",
      "Train Epoch: 10 [3200/3910 (81%)]\tLoss: 0.304639\n",
      "Train Epoch: 10 [3840/3910 (97%)]\tLoss: 0.187709\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 0.944348\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 0.363491\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 0.247980\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 0.381532\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 0.232895\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 0.483471\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 0.317749\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 0.272498\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 0.316749\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 0.182032\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.128675\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.209492\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 0.137880\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 0.117007\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 0.216727\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.182018\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.213296\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.103011\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.172347\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.198961\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.123419\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.066810\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.135168\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.116112\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.199907\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.115938\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.053900\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.367553\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.071406\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.102512\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.112680\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.049682\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.243016\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.181650\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.166346\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.173852\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.183539\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.112565\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.043294\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.258187\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.116501\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.281869\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.117783\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.051222\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.132737\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.070494\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.100199\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.101103\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.031786\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.109795\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.144098\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.110213\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.208582\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.069171\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.190884\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.165705\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.069245\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.154103\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.091970\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.102818\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.188613\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.179855\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.118433\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.413845\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.157908\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.060289\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.085220\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.065820\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.120840\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.090949\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.195066\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.138948\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.044183\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.078694\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.135990\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.058871\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.076764\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.169668\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.145666\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.120097\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.225827\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.383896\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.090815\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.133241\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.242744\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.063798\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.093059\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.173427\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.062652\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.236652\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.085727\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.086343\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.026182\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.064460\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.125952\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.053089\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.203905\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.081330\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.215906\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.269318\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.097221\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.135126\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.134052\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.346785\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.061578\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.060401\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.017864\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.138840\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.144323\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.078783\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.155719\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.100529\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.087751\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.081314\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.109910\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.223642\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.133112\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.137124\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.126631\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.113653\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/5096 (0%)]\tLoss: 0.351645\n",
      "Train Epoch: 1 [640/5096 (12%)]\tLoss: 0.151957\n",
      "Train Epoch: 1 [1280/5096 (25%)]\tLoss: 0.072931\n",
      "Train Epoch: 1 [1920/5096 (38%)]\tLoss: 0.155656\n",
      "Train Epoch: 1 [2560/5096 (50%)]\tLoss: 0.126271\n",
      "Train Epoch: 1 [3200/5096 (62%)]\tLoss: 0.356463\n",
      "Train Epoch: 1 [3840/5096 (75%)]\tLoss: 0.234585\n",
      "Train Epoch: 1 [4480/5096 (88%)]\tLoss: 0.118272\n",
      "Train Epoch: 2 [0/5096 (0%)]\tLoss: 0.063104\n",
      "Train Epoch: 2 [640/5096 (12%)]\tLoss: 0.096197\n",
      "Train Epoch: 2 [1280/5096 (25%)]\tLoss: 0.351118\n",
      "Train Epoch: 2 [1920/5096 (38%)]\tLoss: 0.100624\n",
      "Train Epoch: 2 [2560/5096 (50%)]\tLoss: 0.158847\n",
      "Train Epoch: 2 [3200/5096 (62%)]\tLoss: 0.179470\n",
      "Train Epoch: 2 [3840/5096 (75%)]\tLoss: 0.355407\n",
      "Train Epoch: 2 [4480/5096 (88%)]\tLoss: 0.204671\n",
      "Train Epoch: 3 [0/5096 (0%)]\tLoss: 0.248405\n",
      "Train Epoch: 3 [640/5096 (12%)]\tLoss: 0.291495\n",
      "Train Epoch: 3 [1280/5096 (25%)]\tLoss: 0.131480\n",
      "Train Epoch: 3 [1920/5096 (38%)]\tLoss: 0.066399\n",
      "Train Epoch: 3 [2560/5096 (50%)]\tLoss: 0.073418\n",
      "Train Epoch: 3 [3200/5096 (62%)]\tLoss: 0.121189\n",
      "Train Epoch: 3 [3840/5096 (75%)]\tLoss: 0.151623\n",
      "Train Epoch: 3 [4480/5096 (88%)]\tLoss: 0.041844\n",
      "Train Epoch: 4 [0/5096 (0%)]\tLoss: 0.122396\n",
      "Train Epoch: 4 [640/5096 (12%)]\tLoss: 0.193880\n",
      "Train Epoch: 4 [1280/5096 (25%)]\tLoss: 0.108064\n",
      "Train Epoch: 4 [1920/5096 (38%)]\tLoss: 0.044703\n",
      "Train Epoch: 4 [2560/5096 (50%)]\tLoss: 0.057610\n",
      "Train Epoch: 4 [3200/5096 (62%)]\tLoss: 0.197418\n",
      "Train Epoch: 4 [3840/5096 (75%)]\tLoss: 0.233362\n",
      "Train Epoch: 4 [4480/5096 (88%)]\tLoss: 0.144658\n",
      "Train Epoch: 5 [0/5096 (0%)]\tLoss: 0.095102\n",
      "Train Epoch: 5 [640/5096 (12%)]\tLoss: 0.080072\n",
      "Train Epoch: 5 [1280/5096 (25%)]\tLoss: 0.067132\n",
      "Train Epoch: 5 [1920/5096 (38%)]\tLoss: 0.152764\n",
      "Train Epoch: 5 [2560/5096 (50%)]\tLoss: 0.163376\n",
      "Train Epoch: 5 [3200/5096 (62%)]\tLoss: 0.122968\n",
      "Train Epoch: 5 [3840/5096 (75%)]\tLoss: 0.154124\n",
      "Train Epoch: 5 [4480/5096 (88%)]\tLoss: 0.098971\n",
      "Train Epoch: 6 [0/5096 (0%)]\tLoss: 0.120660\n",
      "Train Epoch: 6 [640/5096 (12%)]\tLoss: 0.069440\n",
      "Train Epoch: 6 [1280/5096 (25%)]\tLoss: 0.277858\n",
      "Train Epoch: 6 [1920/5096 (38%)]\tLoss: 0.111214\n",
      "Train Epoch: 6 [2560/5096 (50%)]\tLoss: 0.044367\n",
      "Train Epoch: 6 [3200/5096 (62%)]\tLoss: 0.190993\n",
      "Train Epoch: 6 [3840/5096 (75%)]\tLoss: 0.080152\n",
      "Train Epoch: 6 [4480/5096 (88%)]\tLoss: 0.131081\n",
      "Train Epoch: 7 [0/5096 (0%)]\tLoss: 0.298147\n",
      "Train Epoch: 7 [640/5096 (12%)]\tLoss: 0.148890\n",
      "Train Epoch: 7 [1280/5096 (25%)]\tLoss: 0.085367\n",
      "Train Epoch: 7 [1920/5096 (38%)]\tLoss: 0.075013\n",
      "Train Epoch: 7 [2560/5096 (50%)]\tLoss: 0.083435\n",
      "Train Epoch: 7 [3200/5096 (62%)]\tLoss: 0.114941\n",
      "Train Epoch: 7 [3840/5096 (75%)]\tLoss: 0.072087\n",
      "Train Epoch: 7 [4480/5096 (88%)]\tLoss: 0.094554\n",
      "Train Epoch: 8 [0/5096 (0%)]\tLoss: 0.123693\n",
      "Train Epoch: 8 [640/5096 (12%)]\tLoss: 0.183455\n",
      "Train Epoch: 8 [1280/5096 (25%)]\tLoss: 0.255554\n",
      "Train Epoch: 8 [1920/5096 (38%)]\tLoss: 0.107131\n",
      "Train Epoch: 8 [2560/5096 (50%)]\tLoss: 0.065751\n",
      "Train Epoch: 8 [3200/5096 (62%)]\tLoss: 0.030446\n",
      "Train Epoch: 8 [3840/5096 (75%)]\tLoss: 0.113430\n",
      "Train Epoch: 8 [4480/5096 (88%)]\tLoss: 0.107149\n",
      "Train Epoch: 9 [0/5096 (0%)]\tLoss: 0.032629\n",
      "Train Epoch: 9 [640/5096 (12%)]\tLoss: 0.194436\n",
      "Train Epoch: 9 [1280/5096 (25%)]\tLoss: 0.187311\n",
      "Train Epoch: 9 [1920/5096 (38%)]\tLoss: 0.097166\n",
      "Train Epoch: 9 [2560/5096 (50%)]\tLoss: 0.094885\n",
      "Train Epoch: 9 [3200/5096 (62%)]\tLoss: 0.011943\n",
      "Train Epoch: 9 [3840/5096 (75%)]\tLoss: 0.111020\n",
      "Train Epoch: 9 [4480/5096 (88%)]\tLoss: 0.153819\n",
      "Train Epoch: 10 [0/5096 (0%)]\tLoss: 0.090124\n",
      "Train Epoch: 10 [640/5096 (12%)]\tLoss: 0.080915\n",
      "Train Epoch: 10 [1280/5096 (25%)]\tLoss: 0.125737\n",
      "Train Epoch: 10 [1920/5096 (38%)]\tLoss: 0.045135\n",
      "Train Epoch: 10 [2560/5096 (50%)]\tLoss: 0.022665\n",
      "Train Epoch: 10 [3200/5096 (62%)]\tLoss: 0.146903\n",
      "Train Epoch: 10 [3840/5096 (75%)]\tLoss: 0.058601\n",
      "Train Epoch: 10 [4480/5096 (88%)]\tLoss: 0.059449\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/1599 (0%)]\tLoss: 0.776924\n",
      "Train Epoch: 1 [640/1599 (40%)]\tLoss: 0.446636\n",
      "Train Epoch: 1 [1280/1599 (80%)]\tLoss: 0.332473\n",
      "Train Epoch: 2 [0/1599 (0%)]\tLoss: 0.303392\n",
      "Train Epoch: 2 [640/1599 (40%)]\tLoss: 0.252525\n",
      "Train Epoch: 2 [1280/1599 (80%)]\tLoss: 0.388435\n",
      "Train Epoch: 3 [0/1599 (0%)]\tLoss: 0.252741\n",
      "Train Epoch: 3 [640/1599 (40%)]\tLoss: 0.358142\n",
      "Train Epoch: 3 [1280/1599 (80%)]\tLoss: 0.254671\n",
      "Train Epoch: 4 [0/1599 (0%)]\tLoss: 0.471122\n",
      "Train Epoch: 4 [640/1599 (40%)]\tLoss: 0.513226\n",
      "Train Epoch: 4 [1280/1599 (80%)]\tLoss: 0.328115\n",
      "Train Epoch: 5 [0/1599 (0%)]\tLoss: 0.325757\n",
      "Train Epoch: 5 [640/1599 (40%)]\tLoss: 0.427984\n",
      "Train Epoch: 5 [1280/1599 (80%)]\tLoss: 0.129954\n",
      "Train Epoch: 6 [0/1599 (0%)]\tLoss: 0.130360\n",
      "Train Epoch: 6 [640/1599 (40%)]\tLoss: 0.272226\n",
      "Train Epoch: 6 [1280/1599 (80%)]\tLoss: 0.324787\n",
      "Train Epoch: 7 [0/1599 (0%)]\tLoss: 0.270565\n",
      "Train Epoch: 7 [640/1599 (40%)]\tLoss: 0.215687\n",
      "Train Epoch: 7 [1280/1599 (80%)]\tLoss: 0.215079\n",
      "Train Epoch: 8 [0/1599 (0%)]\tLoss: 0.313042\n",
      "Train Epoch: 8 [640/1599 (40%)]\tLoss: 0.242137\n",
      "Train Epoch: 8 [1280/1599 (80%)]\tLoss: 0.338884\n",
      "Train Epoch: 9 [0/1599 (0%)]\tLoss: 0.186324\n",
      "Train Epoch: 9 [640/1599 (40%)]\tLoss: 0.454461\n",
      "Train Epoch: 9 [1280/1599 (80%)]\tLoss: 0.143376\n",
      "Train Epoch: 10 [0/1599 (0%)]\tLoss: 0.173118\n",
      "Train Epoch: 10 [640/1599 (40%)]\tLoss: 0.247568\n",
      "Train Epoch: 10 [1280/1599 (80%)]\tLoss: 0.189691\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/5266 (0%)]\tLoss: 0.339747\n",
      "Train Epoch: 1 [640/5266 (12%)]\tLoss: 0.284980\n",
      "Train Epoch: 1 [1280/5266 (24%)]\tLoss: 0.202670\n",
      "Train Epoch: 1 [1920/5266 (36%)]\tLoss: 0.291131\n",
      "Train Epoch: 1 [2560/5266 (48%)]\tLoss: 0.078568\n",
      "Train Epoch: 1 [3200/5266 (60%)]\tLoss: 0.116255\n",
      "Train Epoch: 1 [3840/5266 (72%)]\tLoss: 0.089399\n",
      "Train Epoch: 1 [4480/5266 (84%)]\tLoss: 0.153916\n",
      "Train Epoch: 1 [5120/5266 (96%)]\tLoss: 0.161867\n",
      "Train Epoch: 2 [0/5266 (0%)]\tLoss: 0.101728\n",
      "Train Epoch: 2 [640/5266 (12%)]\tLoss: 0.149921\n",
      "Train Epoch: 2 [1280/5266 (24%)]\tLoss: 0.137974\n",
      "Train Epoch: 2 [1920/5266 (36%)]\tLoss: 0.191589\n",
      "Train Epoch: 2 [2560/5266 (48%)]\tLoss: 0.241018\n",
      "Train Epoch: 2 [3200/5266 (60%)]\tLoss: 0.069966\n",
      "Train Epoch: 2 [3840/5266 (72%)]\tLoss: 0.072650\n",
      "Train Epoch: 2 [4480/5266 (84%)]\tLoss: 0.088381\n",
      "Train Epoch: 2 [5120/5266 (96%)]\tLoss: 0.090998\n",
      "Train Epoch: 3 [0/5266 (0%)]\tLoss: 0.153102\n",
      "Train Epoch: 3 [640/5266 (12%)]\tLoss: 0.063254\n",
      "Train Epoch: 3 [1280/5266 (24%)]\tLoss: 0.120113\n",
      "Train Epoch: 3 [1920/5266 (36%)]\tLoss: 0.095771\n",
      "Train Epoch: 3 [2560/5266 (48%)]\tLoss: 0.035211\n",
      "Train Epoch: 3 [3200/5266 (60%)]\tLoss: 0.116888\n",
      "Train Epoch: 3 [3840/5266 (72%)]\tLoss: 0.104520\n",
      "Train Epoch: 3 [4480/5266 (84%)]\tLoss: 0.134135\n",
      "Train Epoch: 3 [5120/5266 (96%)]\tLoss: 0.100979\n",
      "Train Epoch: 4 [0/5266 (0%)]\tLoss: 0.152833\n",
      "Train Epoch: 4 [640/5266 (12%)]\tLoss: 0.143672\n",
      "Train Epoch: 4 [1280/5266 (24%)]\tLoss: 0.057733\n",
      "Train Epoch: 4 [1920/5266 (36%)]\tLoss: 0.068474\n",
      "Train Epoch: 4 [2560/5266 (48%)]\tLoss: 0.029753\n",
      "Train Epoch: 4 [3200/5266 (60%)]\tLoss: 0.111311\n",
      "Train Epoch: 4 [3840/5266 (72%)]\tLoss: 0.076703\n",
      "Train Epoch: 4 [4480/5266 (84%)]\tLoss: 0.040149\n",
      "Train Epoch: 4 [5120/5266 (96%)]\tLoss: 0.024839\n",
      "Train Epoch: 5 [0/5266 (0%)]\tLoss: 0.083596\n",
      "Train Epoch: 5 [640/5266 (12%)]\tLoss: 0.105912\n",
      "Train Epoch: 5 [1280/5266 (24%)]\tLoss: 0.115400\n",
      "Train Epoch: 5 [1920/5266 (36%)]\tLoss: 0.136898\n",
      "Train Epoch: 5 [2560/5266 (48%)]\tLoss: 0.028996\n",
      "Train Epoch: 5 [3200/5266 (60%)]\tLoss: 0.126613\n",
      "Train Epoch: 5 [3840/5266 (72%)]\tLoss: 0.020210\n",
      "Train Epoch: 5 [4480/5266 (84%)]\tLoss: 0.219013\n",
      "Train Epoch: 5 [5120/5266 (96%)]\tLoss: 0.121835\n",
      "Train Epoch: 6 [0/5266 (0%)]\tLoss: 0.078766\n",
      "Train Epoch: 6 [640/5266 (12%)]\tLoss: 0.099863\n",
      "Train Epoch: 6 [1280/5266 (24%)]\tLoss: 0.088352\n",
      "Train Epoch: 6 [1920/5266 (36%)]\tLoss: 0.218881\n",
      "Train Epoch: 6 [2560/5266 (48%)]\tLoss: 0.186754\n",
      "Train Epoch: 6 [3200/5266 (60%)]\tLoss: 0.118451\n",
      "Train Epoch: 6 [3840/5266 (72%)]\tLoss: 0.026102\n",
      "Train Epoch: 6 [4480/5266 (84%)]\tLoss: 0.058533\n",
      "Train Epoch: 6 [5120/5266 (96%)]\tLoss: 0.135642\n",
      "Train Epoch: 7 [0/5266 (0%)]\tLoss: 0.082887\n",
      "Train Epoch: 7 [640/5266 (12%)]\tLoss: 0.105194\n",
      "Train Epoch: 7 [1280/5266 (24%)]\tLoss: 0.117668\n",
      "Train Epoch: 7 [1920/5266 (36%)]\tLoss: 0.046996\n",
      "Train Epoch: 7 [2560/5266 (48%)]\tLoss: 0.101536\n",
      "Train Epoch: 7 [3200/5266 (60%)]\tLoss: 0.131221\n",
      "Train Epoch: 7 [3840/5266 (72%)]\tLoss: 0.055029\n",
      "Train Epoch: 7 [4480/5266 (84%)]\tLoss: 0.072773\n",
      "Train Epoch: 7 [5120/5266 (96%)]\tLoss: 0.068888\n",
      "Train Epoch: 8 [0/5266 (0%)]\tLoss: 0.197296\n",
      "Train Epoch: 8 [640/5266 (12%)]\tLoss: 0.023089\n",
      "Train Epoch: 8 [1280/5266 (24%)]\tLoss: 0.101764\n",
      "Train Epoch: 8 [1920/5266 (36%)]\tLoss: 0.142162\n",
      "Train Epoch: 8 [2560/5266 (48%)]\tLoss: 0.071336\n",
      "Train Epoch: 8 [3200/5266 (60%)]\tLoss: 0.050913\n",
      "Train Epoch: 8 [3840/5266 (72%)]\tLoss: 0.140522\n",
      "Train Epoch: 8 [4480/5266 (84%)]\tLoss: 0.087002\n",
      "Train Epoch: 8 [5120/5266 (96%)]\tLoss: 0.122417\n",
      "Train Epoch: 9 [0/5266 (0%)]\tLoss: 0.066875\n",
      "Train Epoch: 9 [640/5266 (12%)]\tLoss: 0.037207\n",
      "Train Epoch: 9 [1280/5266 (24%)]\tLoss: 0.036677\n",
      "Train Epoch: 9 [1920/5266 (36%)]\tLoss: 0.107550\n",
      "Train Epoch: 9 [2560/5266 (48%)]\tLoss: 0.016612\n",
      "Train Epoch: 9 [3200/5266 (60%)]\tLoss: 0.062294\n",
      "Train Epoch: 9 [3840/5266 (72%)]\tLoss: 0.043471\n",
      "Train Epoch: 9 [4480/5266 (84%)]\tLoss: 0.139472\n",
      "Train Epoch: 9 [5120/5266 (96%)]\tLoss: 0.028208\n",
      "Train Epoch: 10 [0/5266 (0%)]\tLoss: 0.030736\n",
      "Train Epoch: 10 [640/5266 (12%)]\tLoss: 0.123811\n",
      "Train Epoch: 10 [1280/5266 (24%)]\tLoss: 0.197747\n",
      "Train Epoch: 10 [1920/5266 (36%)]\tLoss: 0.080296\n",
      "Train Epoch: 10 [2560/5266 (48%)]\tLoss: 0.060904\n",
      "Train Epoch: 10 [3200/5266 (60%)]\tLoss: 0.072397\n",
      "Train Epoch: 10 [3840/5266 (72%)]\tLoss: 0.116888\n",
      "Train Epoch: 10 [4480/5266 (84%)]\tLoss: 0.054202\n",
      "Train Epoch: 10 [5120/5266 (96%)]\tLoss: 0.142110\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/3530 (0%)]\tLoss: 0.495290\n",
      "Train Epoch: 1 [640/3530 (18%)]\tLoss: 0.281488\n",
      "Train Epoch: 1 [1280/3530 (36%)]\tLoss: 0.314674\n",
      "Train Epoch: 1 [1920/3530 (54%)]\tLoss: 0.532382\n",
      "Train Epoch: 1 [2560/3530 (71%)]\tLoss: 0.326561\n",
      "Train Epoch: 1 [3200/3530 (89%)]\tLoss: 0.180052\n",
      "Train Epoch: 2 [0/3530 (0%)]\tLoss: 0.542465\n",
      "Train Epoch: 2 [640/3530 (18%)]\tLoss: 0.312551\n",
      "Train Epoch: 2 [1280/3530 (36%)]\tLoss: 0.390792\n",
      "Train Epoch: 2 [1920/3530 (54%)]\tLoss: 0.176782\n",
      "Train Epoch: 2 [2560/3530 (71%)]\tLoss: 0.260585\n",
      "Train Epoch: 2 [3200/3530 (89%)]\tLoss: 0.451414\n",
      "Train Epoch: 3 [0/3530 (0%)]\tLoss: 0.163729\n",
      "Train Epoch: 3 [640/3530 (18%)]\tLoss: 0.391141\n",
      "Train Epoch: 3 [1280/3530 (36%)]\tLoss: 0.279421\n",
      "Train Epoch: 3 [1920/3530 (54%)]\tLoss: 0.264316\n",
      "Train Epoch: 3 [2560/3530 (71%)]\tLoss: 0.228981\n",
      "Train Epoch: 3 [3200/3530 (89%)]\tLoss: 0.125329\n",
      "Train Epoch: 4 [0/3530 (0%)]\tLoss: 0.228187\n",
      "Train Epoch: 4 [640/3530 (18%)]\tLoss: 0.248111\n",
      "Train Epoch: 4 [1280/3530 (36%)]\tLoss: 0.157721\n",
      "Train Epoch: 4 [1920/3530 (54%)]\tLoss: 0.216919\n",
      "Train Epoch: 4 [2560/3530 (71%)]\tLoss: 0.232084\n",
      "Train Epoch: 4 [3200/3530 (89%)]\tLoss: 0.237595\n",
      "Train Epoch: 5 [0/3530 (0%)]\tLoss: 0.187647\n",
      "Train Epoch: 5 [640/3530 (18%)]\tLoss: 0.130426\n",
      "Train Epoch: 5 [1280/3530 (36%)]\tLoss: 0.247007\n",
      "Train Epoch: 5 [1920/3530 (54%)]\tLoss: 0.189243\n",
      "Train Epoch: 5 [2560/3530 (71%)]\tLoss: 0.169714\n",
      "Train Epoch: 5 [3200/3530 (89%)]\tLoss: 0.386849\n",
      "Train Epoch: 6 [0/3530 (0%)]\tLoss: 0.144306\n",
      "Train Epoch: 6 [640/3530 (18%)]\tLoss: 0.191913\n",
      "Train Epoch: 6 [1280/3530 (36%)]\tLoss: 0.199821\n",
      "Train Epoch: 6 [1920/3530 (54%)]\tLoss: 0.234751\n",
      "Train Epoch: 6 [2560/3530 (71%)]\tLoss: 0.086916\n",
      "Train Epoch: 6 [3200/3530 (89%)]\tLoss: 0.416500\n",
      "Train Epoch: 7 [0/3530 (0%)]\tLoss: 0.062036\n",
      "Train Epoch: 7 [640/3530 (18%)]\tLoss: 0.386028\n",
      "Train Epoch: 7 [1280/3530 (36%)]\tLoss: 0.218511\n",
      "Train Epoch: 7 [1920/3530 (54%)]\tLoss: 0.250240\n",
      "Train Epoch: 7 [2560/3530 (71%)]\tLoss: 0.154794\n",
      "Train Epoch: 7 [3200/3530 (89%)]\tLoss: 0.156531\n",
      "Train Epoch: 8 [0/3530 (0%)]\tLoss: 0.149423\n",
      "Train Epoch: 8 [640/3530 (18%)]\tLoss: 0.134125\n",
      "Train Epoch: 8 [1280/3530 (36%)]\tLoss: 0.273503\n",
      "Train Epoch: 8 [1920/3530 (54%)]\tLoss: 0.173101\n",
      "Train Epoch: 8 [2560/3530 (71%)]\tLoss: 0.289792\n",
      "Train Epoch: 8 [3200/3530 (89%)]\tLoss: 0.237651\n",
      "Train Epoch: 9 [0/3530 (0%)]\tLoss: 0.315879\n",
      "Train Epoch: 9 [640/3530 (18%)]\tLoss: 0.291205\n",
      "Train Epoch: 9 [1280/3530 (36%)]\tLoss: 0.167334\n",
      "Train Epoch: 9 [1920/3530 (54%)]\tLoss: 0.107217\n",
      "Train Epoch: 9 [2560/3530 (71%)]\tLoss: 0.264054\n",
      "Train Epoch: 9 [3200/3530 (89%)]\tLoss: 0.371309\n",
      "Train Epoch: 10 [0/3530 (0%)]\tLoss: 0.073081\n",
      "Train Epoch: 10 [640/3530 (18%)]\tLoss: 0.444558\n",
      "Train Epoch: 10 [1280/3530 (36%)]\tLoss: 0.189788\n",
      "Train Epoch: 10 [1920/3530 (54%)]\tLoss: 0.292532\n",
      "Train Epoch: 10 [2560/3530 (71%)]\tLoss: 0.091423\n",
      "Train Epoch: 10 [3200/3530 (89%)]\tLoss: 0.235161\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.2450, Accuracy: 9290/10000 (93%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/37519 (0%)]\tLoss: 0.439506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [640/37519 (2%)]\tLoss: 0.358101\n",
      "Train Epoch: 1 [1280/37519 (3%)]\tLoss: 0.491016\n",
      "Train Epoch: 1 [1920/37519 (5%)]\tLoss: 0.408512\n",
      "Train Epoch: 1 [2560/37519 (7%)]\tLoss: 0.280301\n",
      "Train Epoch: 1 [3200/37519 (9%)]\tLoss: 0.265765\n",
      "Train Epoch: 1 [3840/37519 (10%)]\tLoss: 0.381487\n",
      "Train Epoch: 1 [4480/37519 (12%)]\tLoss: 0.237898\n",
      "Train Epoch: 1 [5120/37519 (14%)]\tLoss: 0.420676\n",
      "Train Epoch: 1 [5760/37519 (15%)]\tLoss: 0.478874\n",
      "Train Epoch: 1 [6400/37519 (17%)]\tLoss: 0.289958\n",
      "Train Epoch: 1 [7040/37519 (19%)]\tLoss: 0.267838\n",
      "Train Epoch: 1 [7680/37519 (20%)]\tLoss: 0.363784\n",
      "Train Epoch: 1 [8320/37519 (22%)]\tLoss: 0.174742\n",
      "Train Epoch: 1 [8960/37519 (24%)]\tLoss: 0.269068\n",
      "Train Epoch: 1 [9600/37519 (26%)]\tLoss: 0.267111\n",
      "Train Epoch: 1 [10240/37519 (27%)]\tLoss: 0.422995\n",
      "Train Epoch: 1 [10880/37519 (29%)]\tLoss: 0.320953\n",
      "Train Epoch: 1 [11520/37519 (31%)]\tLoss: 0.459425\n",
      "Train Epoch: 1 [12160/37519 (32%)]\tLoss: 0.338334\n",
      "Train Epoch: 1 [12800/37519 (34%)]\tLoss: 0.506632\n",
      "Train Epoch: 1 [13440/37519 (36%)]\tLoss: 0.257334\n",
      "Train Epoch: 1 [14080/37519 (37%)]\tLoss: 0.273053\n",
      "Train Epoch: 1 [14720/37519 (39%)]\tLoss: 0.237745\n",
      "Train Epoch: 1 [15360/37519 (41%)]\tLoss: 0.294643\n",
      "Train Epoch: 1 [16000/37519 (43%)]\tLoss: 0.399529\n",
      "Train Epoch: 1 [16640/37519 (44%)]\tLoss: 0.237691\n",
      "Train Epoch: 1 [17280/37519 (46%)]\tLoss: 0.344556\n",
      "Train Epoch: 1 [17920/37519 (48%)]\tLoss: 0.338075\n",
      "Train Epoch: 1 [18560/37519 (49%)]\tLoss: 0.318020\n",
      "Train Epoch: 1 [19200/37519 (51%)]\tLoss: 0.456639\n",
      "Train Epoch: 1 [19840/37519 (53%)]\tLoss: 0.251594\n",
      "Train Epoch: 1 [20480/37519 (55%)]\tLoss: 0.235917\n",
      "Train Epoch: 1 [21120/37519 (56%)]\tLoss: 0.337727\n",
      "Train Epoch: 1 [21760/37519 (58%)]\tLoss: 0.264475\n",
      "Train Epoch: 1 [22400/37519 (60%)]\tLoss: 0.378555\n",
      "Train Epoch: 1 [23040/37519 (61%)]\tLoss: 0.539055\n",
      "Train Epoch: 1 [23680/37519 (63%)]\tLoss: 0.322543\n",
      "Train Epoch: 1 [24320/37519 (65%)]\tLoss: 0.294878\n",
      "Train Epoch: 1 [24960/37519 (66%)]\tLoss: 0.312211\n",
      "Train Epoch: 1 [25600/37519 (68%)]\tLoss: 0.322961\n",
      "Train Epoch: 1 [26240/37519 (70%)]\tLoss: 0.328196\n",
      "Train Epoch: 1 [26880/37519 (72%)]\tLoss: 0.294411\n",
      "Train Epoch: 1 [27520/37519 (73%)]\tLoss: 0.294189\n",
      "Train Epoch: 1 [28160/37519 (75%)]\tLoss: 0.443420\n",
      "Train Epoch: 1 [28800/37519 (77%)]\tLoss: 0.215544\n",
      "Train Epoch: 1 [29440/37519 (78%)]\tLoss: 0.318734\n",
      "Train Epoch: 1 [30080/37519 (80%)]\tLoss: 0.545805\n",
      "Train Epoch: 1 [30720/37519 (82%)]\tLoss: 0.382339\n",
      "Train Epoch: 1 [31360/37519 (83%)]\tLoss: 0.171345\n",
      "Train Epoch: 1 [32000/37519 (85%)]\tLoss: 0.699480\n",
      "Train Epoch: 1 [32640/37519 (87%)]\tLoss: 0.289938\n",
      "Train Epoch: 1 [33280/37519 (89%)]\tLoss: 0.290734\n",
      "Train Epoch: 1 [33920/37519 (90%)]\tLoss: 0.151031\n",
      "Train Epoch: 1 [34560/37519 (92%)]\tLoss: 0.347199\n",
      "Train Epoch: 1 [35200/37519 (94%)]\tLoss: 0.399808\n",
      "Train Epoch: 1 [35840/37519 (95%)]\tLoss: 0.310968\n",
      "Train Epoch: 1 [36480/37519 (97%)]\tLoss: 0.281403\n",
      "Train Epoch: 1 [37120/37519 (99%)]\tLoss: 0.264335\n",
      "Train Epoch: 2 [0/37519 (0%)]\tLoss: 0.301715\n",
      "Train Epoch: 2 [640/37519 (2%)]\tLoss: 0.393579\n",
      "Train Epoch: 2 [1280/37519 (3%)]\tLoss: 0.391543\n",
      "Train Epoch: 2 [1920/37519 (5%)]\tLoss: 0.277431\n",
      "Train Epoch: 2 [2560/37519 (7%)]\tLoss: 0.219060\n",
      "Train Epoch: 2 [3200/37519 (9%)]\tLoss: 0.306843\n",
      "Train Epoch: 2 [3840/37519 (10%)]\tLoss: 0.183887\n",
      "Train Epoch: 2 [4480/37519 (12%)]\tLoss: 0.179228\n",
      "Train Epoch: 2 [5120/37519 (14%)]\tLoss: 0.209656\n",
      "Train Epoch: 2 [5760/37519 (15%)]\tLoss: 0.163060\n",
      "Train Epoch: 2 [6400/37519 (17%)]\tLoss: 0.467399\n",
      "Train Epoch: 2 [7040/37519 (19%)]\tLoss: 0.248812\n",
      "Train Epoch: 2 [7680/37519 (20%)]\tLoss: 0.355917\n",
      "Train Epoch: 2 [8320/37519 (22%)]\tLoss: 0.262278\n",
      "Train Epoch: 2 [8960/37519 (24%)]\tLoss: 0.316850\n",
      "Train Epoch: 2 [9600/37519 (26%)]\tLoss: 0.220186\n",
      "Train Epoch: 2 [10240/37519 (27%)]\tLoss: 0.239516\n",
      "Train Epoch: 2 [10880/37519 (29%)]\tLoss: 0.337102\n",
      "Train Epoch: 2 [11520/37519 (31%)]\tLoss: 0.147468\n",
      "Train Epoch: 2 [12160/37519 (32%)]\tLoss: 0.244473\n",
      "Train Epoch: 2 [12800/37519 (34%)]\tLoss: 0.292983\n",
      "Train Epoch: 2 [13440/37519 (36%)]\tLoss: 0.398586\n",
      "Train Epoch: 2 [14080/37519 (37%)]\tLoss: 0.214046\n",
      "Train Epoch: 2 [14720/37519 (39%)]\tLoss: 0.313121\n",
      "Train Epoch: 2 [15360/37519 (41%)]\tLoss: 0.206147\n",
      "Train Epoch: 2 [16000/37519 (43%)]\tLoss: 0.383772\n",
      "Train Epoch: 2 [16640/37519 (44%)]\tLoss: 0.235141\n",
      "Train Epoch: 2 [17280/37519 (46%)]\tLoss: 0.245166\n",
      "Train Epoch: 2 [17920/37519 (48%)]\tLoss: 0.446004\n",
      "Train Epoch: 2 [18560/37519 (49%)]\tLoss: 0.179567\n",
      "Train Epoch: 2 [19200/37519 (51%)]\tLoss: 0.194822\n",
      "Train Epoch: 2 [19840/37519 (53%)]\tLoss: 0.250482\n",
      "Train Epoch: 2 [20480/37519 (55%)]\tLoss: 0.304274\n",
      "Train Epoch: 2 [21120/37519 (56%)]\tLoss: 0.271019\n",
      "Train Epoch: 2 [21760/37519 (58%)]\tLoss: 0.137407\n",
      "Train Epoch: 2 [22400/37519 (60%)]\tLoss: 0.337194\n",
      "Train Epoch: 2 [23040/37519 (61%)]\tLoss: 0.360472\n",
      "Train Epoch: 2 [23680/37519 (63%)]\tLoss: 0.196622\n",
      "Train Epoch: 2 [24320/37519 (65%)]\tLoss: 0.468367\n",
      "Train Epoch: 2 [24960/37519 (66%)]\tLoss: 0.319768\n",
      "Train Epoch: 2 [25600/37519 (68%)]\tLoss: 0.342290\n",
      "Train Epoch: 2 [26240/37519 (70%)]\tLoss: 0.560706\n",
      "Train Epoch: 2 [26880/37519 (72%)]\tLoss: 0.186527\n",
      "Train Epoch: 2 [27520/37519 (73%)]\tLoss: 0.209063\n",
      "Train Epoch: 2 [28160/37519 (75%)]\tLoss: 0.506053\n",
      "Train Epoch: 2 [28800/37519 (77%)]\tLoss: 0.454873\n",
      "Train Epoch: 2 [29440/37519 (78%)]\tLoss: 0.244156\n",
      "Train Epoch: 2 [30080/37519 (80%)]\tLoss: 0.305694\n",
      "Train Epoch: 2 [30720/37519 (82%)]\tLoss: 0.423714\n",
      "Train Epoch: 2 [31360/37519 (83%)]\tLoss: 0.338207\n",
      "Train Epoch: 2 [32000/37519 (85%)]\tLoss: 0.368621\n",
      "Train Epoch: 2 [32640/37519 (87%)]\tLoss: 0.226792\n",
      "Train Epoch: 2 [33280/37519 (89%)]\tLoss: 0.136691\n",
      "Train Epoch: 2 [33920/37519 (90%)]\tLoss: 0.298902\n",
      "Train Epoch: 2 [34560/37519 (92%)]\tLoss: 0.214978\n",
      "Train Epoch: 2 [35200/37519 (94%)]\tLoss: 0.212844\n",
      "Train Epoch: 2 [35840/37519 (95%)]\tLoss: 0.255628\n",
      "Train Epoch: 2 [36480/37519 (97%)]\tLoss: 0.188654\n",
      "Train Epoch: 2 [37120/37519 (99%)]\tLoss: 0.297766\n",
      "Train Epoch: 3 [0/37519 (0%)]\tLoss: 0.358857\n",
      "Train Epoch: 3 [640/37519 (2%)]\tLoss: 0.197015\n",
      "Train Epoch: 3 [1280/37519 (3%)]\tLoss: 0.319454\n",
      "Train Epoch: 3 [1920/37519 (5%)]\tLoss: 0.361843\n",
      "Train Epoch: 3 [2560/37519 (7%)]\tLoss: 0.264516\n",
      "Train Epoch: 3 [3200/37519 (9%)]\tLoss: 0.283100\n",
      "Train Epoch: 3 [3840/37519 (10%)]\tLoss: 0.178862\n",
      "Train Epoch: 3 [4480/37519 (12%)]\tLoss: 0.342568\n",
      "Train Epoch: 3 [5120/37519 (14%)]\tLoss: 0.188860\n",
      "Train Epoch: 3 [5760/37519 (15%)]\tLoss: 0.311219\n",
      "Train Epoch: 3 [6400/37519 (17%)]\tLoss: 0.313268\n",
      "Train Epoch: 3 [7040/37519 (19%)]\tLoss: 0.218512\n",
      "Train Epoch: 3 [7680/37519 (20%)]\tLoss: 0.428708\n",
      "Train Epoch: 3 [8320/37519 (22%)]\tLoss: 0.277870\n",
      "Train Epoch: 3 [8960/37519 (24%)]\tLoss: 0.248394\n",
      "Train Epoch: 3 [9600/37519 (26%)]\tLoss: 0.242300\n",
      "Train Epoch: 3 [10240/37519 (27%)]\tLoss: 0.549011\n",
      "Train Epoch: 3 [10880/37519 (29%)]\tLoss: 0.215896\n",
      "Train Epoch: 3 [11520/37519 (31%)]\tLoss: 0.222249\n",
      "Train Epoch: 3 [12160/37519 (32%)]\tLoss: 0.228587\n",
      "Train Epoch: 3 [12800/37519 (34%)]\tLoss: 0.399203\n",
      "Train Epoch: 3 [13440/37519 (36%)]\tLoss: 0.254351\n",
      "Train Epoch: 3 [14080/37519 (37%)]\tLoss: 0.263457\n",
      "Train Epoch: 3 [14720/37519 (39%)]\tLoss: 0.178705\n",
      "Train Epoch: 3 [15360/37519 (41%)]\tLoss: 0.368452\n",
      "Train Epoch: 3 [16000/37519 (43%)]\tLoss: 0.295285\n",
      "Train Epoch: 3 [16640/37519 (44%)]\tLoss: 0.414380\n",
      "Train Epoch: 3 [17280/37519 (46%)]\tLoss: 0.505917\n",
      "Train Epoch: 3 [17920/37519 (48%)]\tLoss: 0.190114\n",
      "Train Epoch: 3 [18560/37519 (49%)]\tLoss: 0.176115\n",
      "Train Epoch: 3 [19200/37519 (51%)]\tLoss: 0.333912\n",
      "Train Epoch: 3 [19840/37519 (53%)]\tLoss: 0.226065\n",
      "Train Epoch: 3 [20480/37519 (55%)]\tLoss: 0.141831\n",
      "Train Epoch: 3 [21120/37519 (56%)]\tLoss: 0.306404\n",
      "Train Epoch: 3 [21760/37519 (58%)]\tLoss: 0.287731\n",
      "Train Epoch: 3 [22400/37519 (60%)]\tLoss: 0.389515\n",
      "Train Epoch: 3 [23040/37519 (61%)]\tLoss: 0.374233\n",
      "Train Epoch: 3 [23680/37519 (63%)]\tLoss: 0.272398\n",
      "Train Epoch: 3 [24320/37519 (65%)]\tLoss: 0.214124\n",
      "Train Epoch: 3 [24960/37519 (66%)]\tLoss: 0.425634\n",
      "Train Epoch: 3 [25600/37519 (68%)]\tLoss: 0.253906\n",
      "Train Epoch: 3 [26240/37519 (70%)]\tLoss: 0.213755\n",
      "Train Epoch: 3 [26880/37519 (72%)]\tLoss: 0.198177\n",
      "Train Epoch: 3 [27520/37519 (73%)]\tLoss: 0.378652\n",
      "Train Epoch: 3 [28160/37519 (75%)]\tLoss: 0.220522\n",
      "Train Epoch: 3 [28800/37519 (77%)]\tLoss: 0.490212\n",
      "Train Epoch: 3 [29440/37519 (78%)]\tLoss: 0.301880\n",
      "Train Epoch: 3 [30080/37519 (80%)]\tLoss: 0.201068\n",
      "Train Epoch: 3 [30720/37519 (82%)]\tLoss: 0.211822\n",
      "Train Epoch: 3 [31360/37519 (83%)]\tLoss: 0.210204\n",
      "Train Epoch: 3 [32000/37519 (85%)]\tLoss: 0.268256\n",
      "Train Epoch: 3 [32640/37519 (87%)]\tLoss: 0.231621\n",
      "Train Epoch: 3 [33280/37519 (89%)]\tLoss: 0.216057\n",
      "Train Epoch: 3 [33920/37519 (90%)]\tLoss: 0.255413\n",
      "Train Epoch: 3 [34560/37519 (92%)]\tLoss: 0.149507\n",
      "Train Epoch: 3 [35200/37519 (94%)]\tLoss: 0.204622\n",
      "Train Epoch: 3 [35840/37519 (95%)]\tLoss: 0.390385\n",
      "Train Epoch: 3 [36480/37519 (97%)]\tLoss: 0.155064\n",
      "Train Epoch: 3 [37120/37519 (99%)]\tLoss: 0.197331\n",
      "Train Epoch: 4 [0/37519 (0%)]\tLoss: 0.145048\n",
      "Train Epoch: 4 [640/37519 (2%)]\tLoss: 0.224719\n",
      "Train Epoch: 4 [1280/37519 (3%)]\tLoss: 0.255448\n",
      "Train Epoch: 4 [1920/37519 (5%)]\tLoss: 0.186841\n",
      "Train Epoch: 4 [2560/37519 (7%)]\tLoss: 0.190630\n",
      "Train Epoch: 4 [3200/37519 (9%)]\tLoss: 0.126199\n",
      "Train Epoch: 4 [3840/37519 (10%)]\tLoss: 0.433517\n",
      "Train Epoch: 4 [4480/37519 (12%)]\tLoss: 0.206183\n",
      "Train Epoch: 4 [5120/37519 (14%)]\tLoss: 0.217018\n",
      "Train Epoch: 4 [5760/37519 (15%)]\tLoss: 0.127696\n",
      "Train Epoch: 4 [6400/37519 (17%)]\tLoss: 0.273000\n",
      "Train Epoch: 4 [7040/37519 (19%)]\tLoss: 0.127298\n",
      "Train Epoch: 4 [7680/37519 (20%)]\tLoss: 0.265545\n",
      "Train Epoch: 4 [8320/37519 (22%)]\tLoss: 0.387051\n",
      "Train Epoch: 4 [8960/37519 (24%)]\tLoss: 0.357172\n",
      "Train Epoch: 4 [9600/37519 (26%)]\tLoss: 0.226747\n",
      "Train Epoch: 4 [10240/37519 (27%)]\tLoss: 0.311315\n",
      "Train Epoch: 4 [10880/37519 (29%)]\tLoss: 0.439477\n",
      "Train Epoch: 4 [11520/37519 (31%)]\tLoss: 0.169952\n",
      "Train Epoch: 4 [12160/37519 (32%)]\tLoss: 0.336606\n",
      "Train Epoch: 4 [12800/37519 (34%)]\tLoss: 0.201060\n",
      "Train Epoch: 4 [13440/37519 (36%)]\tLoss: 0.288960\n",
      "Train Epoch: 4 [14080/37519 (37%)]\tLoss: 0.148508\n",
      "Train Epoch: 4 [14720/37519 (39%)]\tLoss: 0.306702\n",
      "Train Epoch: 4 [15360/37519 (41%)]\tLoss: 0.214449\n",
      "Train Epoch: 4 [16000/37519 (43%)]\tLoss: 0.268801\n",
      "Train Epoch: 4 [16640/37519 (44%)]\tLoss: 0.283269\n",
      "Train Epoch: 4 [17280/37519 (46%)]\tLoss: 0.369392\n",
      "Train Epoch: 4 [17920/37519 (48%)]\tLoss: 0.149927\n",
      "Train Epoch: 4 [18560/37519 (49%)]\tLoss: 0.080612\n",
      "Train Epoch: 4 [19200/37519 (51%)]\tLoss: 0.282283\n",
      "Train Epoch: 4 [19840/37519 (53%)]\tLoss: 0.198449\n",
      "Train Epoch: 4 [20480/37519 (55%)]\tLoss: 0.223910\n",
      "Train Epoch: 4 [21120/37519 (56%)]\tLoss: 0.242708\n",
      "Train Epoch: 4 [21760/37519 (58%)]\tLoss: 0.274935\n",
      "Train Epoch: 4 [22400/37519 (60%)]\tLoss: 0.422435\n",
      "Train Epoch: 4 [23040/37519 (61%)]\tLoss: 0.269677\n",
      "Train Epoch: 4 [23680/37519 (63%)]\tLoss: 0.098092\n",
      "Train Epoch: 4 [24320/37519 (65%)]\tLoss: 0.311942\n",
      "Train Epoch: 4 [24960/37519 (66%)]\tLoss: 0.318846\n",
      "Train Epoch: 4 [25600/37519 (68%)]\tLoss: 0.240472\n",
      "Train Epoch: 4 [26240/37519 (70%)]\tLoss: 0.192702\n",
      "Train Epoch: 4 [26880/37519 (72%)]\tLoss: 0.228257\n",
      "Train Epoch: 4 [27520/37519 (73%)]\tLoss: 0.168228\n",
      "Train Epoch: 4 [28160/37519 (75%)]\tLoss: 0.096617\n",
      "Train Epoch: 4 [28800/37519 (77%)]\tLoss: 0.203825\n",
      "Train Epoch: 4 [29440/37519 (78%)]\tLoss: 0.119176\n",
      "Train Epoch: 4 [30080/37519 (80%)]\tLoss: 0.149245\n",
      "Train Epoch: 4 [30720/37519 (82%)]\tLoss: 0.150176\n",
      "Train Epoch: 4 [31360/37519 (83%)]\tLoss: 0.126215\n",
      "Train Epoch: 4 [32000/37519 (85%)]\tLoss: 0.214063\n",
      "Train Epoch: 4 [32640/37519 (87%)]\tLoss: 0.126364\n",
      "Train Epoch: 4 [33280/37519 (89%)]\tLoss: 0.305463\n",
      "Train Epoch: 4 [33920/37519 (90%)]\tLoss: 0.299453\n",
      "Train Epoch: 4 [34560/37519 (92%)]\tLoss: 0.101701\n",
      "Train Epoch: 4 [35200/37519 (94%)]\tLoss: 0.165860\n",
      "Train Epoch: 4 [35840/37519 (95%)]\tLoss: 0.284462\n",
      "Train Epoch: 4 [36480/37519 (97%)]\tLoss: 0.131678\n",
      "Train Epoch: 4 [37120/37519 (99%)]\tLoss: 0.199178\n",
      "Train Epoch: 5 [0/37519 (0%)]\tLoss: 0.298432\n",
      "Train Epoch: 5 [640/37519 (2%)]\tLoss: 0.215660\n",
      "Train Epoch: 5 [1280/37519 (3%)]\tLoss: 0.177605\n",
      "Train Epoch: 5 [1920/37519 (5%)]\tLoss: 0.181961\n",
      "Train Epoch: 5 [2560/37519 (7%)]\tLoss: 0.266754\n",
      "Train Epoch: 5 [3200/37519 (9%)]\tLoss: 0.320457\n",
      "Train Epoch: 5 [3840/37519 (10%)]\tLoss: 0.372281\n",
      "Train Epoch: 5 [4480/37519 (12%)]\tLoss: 0.358389\n",
      "Train Epoch: 5 [5120/37519 (14%)]\tLoss: 0.526891\n",
      "Train Epoch: 5 [5760/37519 (15%)]\tLoss: 0.259043\n",
      "Train Epoch: 5 [6400/37519 (17%)]\tLoss: 0.236796\n",
      "Train Epoch: 5 [7040/37519 (19%)]\tLoss: 0.284891\n",
      "Train Epoch: 5 [7680/37519 (20%)]\tLoss: 0.383111\n",
      "Train Epoch: 5 [8320/37519 (22%)]\tLoss: 0.311108\n",
      "Train Epoch: 5 [8960/37519 (24%)]\tLoss: 0.298786\n",
      "Train Epoch: 5 [9600/37519 (26%)]\tLoss: 0.326044\n",
      "Train Epoch: 5 [10240/37519 (27%)]\tLoss: 0.260613\n",
      "Train Epoch: 5 [10880/37519 (29%)]\tLoss: 0.371440\n",
      "Train Epoch: 5 [11520/37519 (31%)]\tLoss: 0.129452\n",
      "Train Epoch: 5 [12160/37519 (32%)]\tLoss: 0.251126\n",
      "Train Epoch: 5 [12800/37519 (34%)]\tLoss: 0.139108\n",
      "Train Epoch: 5 [13440/37519 (36%)]\tLoss: 0.514328\n",
      "Train Epoch: 5 [14080/37519 (37%)]\tLoss: 0.207114\n",
      "Train Epoch: 5 [14720/37519 (39%)]\tLoss: 0.272876\n",
      "Train Epoch: 5 [15360/37519 (41%)]\tLoss: 0.127272\n",
      "Train Epoch: 5 [16000/37519 (43%)]\tLoss: 0.093095\n",
      "Train Epoch: 5 [16640/37519 (44%)]\tLoss: 0.153219\n",
      "Train Epoch: 5 [17280/37519 (46%)]\tLoss: 0.178090\n",
      "Train Epoch: 5 [17920/37519 (48%)]\tLoss: 0.088095\n",
      "Train Epoch: 5 [18560/37519 (49%)]\tLoss: 0.245145\n",
      "Train Epoch: 5 [19200/37519 (51%)]\tLoss: 0.119405\n",
      "Train Epoch: 5 [19840/37519 (53%)]\tLoss: 0.270004\n",
      "Train Epoch: 5 [20480/37519 (55%)]\tLoss: 0.147964\n",
      "Train Epoch: 5 [21120/37519 (56%)]\tLoss: 0.166206\n",
      "Train Epoch: 5 [21760/37519 (58%)]\tLoss: 0.289998\n",
      "Train Epoch: 5 [22400/37519 (60%)]\tLoss: 0.293095\n",
      "Train Epoch: 5 [23040/37519 (61%)]\tLoss: 0.234680\n",
      "Train Epoch: 5 [23680/37519 (63%)]\tLoss: 0.265878\n",
      "Train Epoch: 5 [24320/37519 (65%)]\tLoss: 0.336794\n",
      "Train Epoch: 5 [24960/37519 (66%)]\tLoss: 0.341468\n",
      "Train Epoch: 5 [25600/37519 (68%)]\tLoss: 0.071045\n",
      "Train Epoch: 5 [26240/37519 (70%)]\tLoss: 0.111144\n",
      "Train Epoch: 5 [26880/37519 (72%)]\tLoss: 0.087222\n",
      "Train Epoch: 5 [27520/37519 (73%)]\tLoss: 0.207702\n",
      "Train Epoch: 5 [28160/37519 (75%)]\tLoss: 0.070250\n",
      "Train Epoch: 5 [28800/37519 (77%)]\tLoss: 0.243299\n",
      "Train Epoch: 5 [29440/37519 (78%)]\tLoss: 0.127562\n",
      "Train Epoch: 5 [30080/37519 (80%)]\tLoss: 0.322774\n",
      "Train Epoch: 5 [30720/37519 (82%)]\tLoss: 0.156342\n",
      "Train Epoch: 5 [31360/37519 (83%)]\tLoss: 0.130241\n",
      "Train Epoch: 5 [32000/37519 (85%)]\tLoss: 0.365164\n",
      "Train Epoch: 5 [32640/37519 (87%)]\tLoss: 0.210466\n",
      "Train Epoch: 5 [33280/37519 (89%)]\tLoss: 0.177743\n",
      "Train Epoch: 5 [33920/37519 (90%)]\tLoss: 0.213960\n",
      "Train Epoch: 5 [34560/37519 (92%)]\tLoss: 0.230191\n",
      "Train Epoch: 5 [35200/37519 (94%)]\tLoss: 0.237598\n",
      "Train Epoch: 5 [35840/37519 (95%)]\tLoss: 0.256477\n",
      "Train Epoch: 5 [36480/37519 (97%)]\tLoss: 0.274924\n",
      "Train Epoch: 5 [37120/37519 (99%)]\tLoss: 0.163891\n",
      "Train Epoch: 6 [0/37519 (0%)]\tLoss: 0.242329\n",
      "Train Epoch: 6 [640/37519 (2%)]\tLoss: 0.298927\n",
      "Train Epoch: 6 [1280/37519 (3%)]\tLoss: 0.155719\n",
      "Train Epoch: 6 [1920/37519 (5%)]\tLoss: 0.199906\n",
      "Train Epoch: 6 [2560/37519 (7%)]\tLoss: 0.243829\n",
      "Train Epoch: 6 [3200/37519 (9%)]\tLoss: 0.280113\n",
      "Train Epoch: 6 [3840/37519 (10%)]\tLoss: 0.424044\n",
      "Train Epoch: 6 [4480/37519 (12%)]\tLoss: 0.157305\n",
      "Train Epoch: 6 [5120/37519 (14%)]\tLoss: 0.083400\n",
      "Train Epoch: 6 [5760/37519 (15%)]\tLoss: 0.195599\n",
      "Train Epoch: 6 [6400/37519 (17%)]\tLoss: 0.191153\n",
      "Train Epoch: 6 [7040/37519 (19%)]\tLoss: 0.395793\n",
      "Train Epoch: 6 [7680/37519 (20%)]\tLoss: 0.110997\n",
      "Train Epoch: 6 [8320/37519 (22%)]\tLoss: 0.295960\n",
      "Train Epoch: 6 [8960/37519 (24%)]\tLoss: 0.259551\n",
      "Train Epoch: 6 [9600/37519 (26%)]\tLoss: 0.224519\n",
      "Train Epoch: 6 [10240/37519 (27%)]\tLoss: 0.127116\n",
      "Train Epoch: 6 [10880/37519 (29%)]\tLoss: 0.244913\n",
      "Train Epoch: 6 [11520/37519 (31%)]\tLoss: 0.113316\n",
      "Train Epoch: 6 [12160/37519 (32%)]\tLoss: 0.168353\n",
      "Train Epoch: 6 [12800/37519 (34%)]\tLoss: 0.152531\n",
      "Train Epoch: 6 [13440/37519 (36%)]\tLoss: 0.105552\n",
      "Train Epoch: 6 [14080/37519 (37%)]\tLoss: 0.131303\n",
      "Train Epoch: 6 [14720/37519 (39%)]\tLoss: 0.221809\n",
      "Train Epoch: 6 [15360/37519 (41%)]\tLoss: 0.174404\n",
      "Train Epoch: 6 [16000/37519 (43%)]\tLoss: 0.152180\n",
      "Train Epoch: 6 [16640/37519 (44%)]\tLoss: 0.578327\n",
      "Train Epoch: 6 [17280/37519 (46%)]\tLoss: 0.335803\n",
      "Train Epoch: 6 [17920/37519 (48%)]\tLoss: 0.076373\n",
      "Train Epoch: 6 [18560/37519 (49%)]\tLoss: 0.156702\n",
      "Train Epoch: 6 [19200/37519 (51%)]\tLoss: 0.133974\n",
      "Train Epoch: 6 [19840/37519 (53%)]\tLoss: 0.339272\n",
      "Train Epoch: 6 [20480/37519 (55%)]\tLoss: 0.260973\n",
      "Train Epoch: 6 [21120/37519 (56%)]\tLoss: 0.217246\n",
      "Train Epoch: 6 [21760/37519 (58%)]\tLoss: 0.541001\n",
      "Train Epoch: 6 [22400/37519 (60%)]\tLoss: 0.160928\n",
      "Train Epoch: 6 [23040/37519 (61%)]\tLoss: 0.174232\n",
      "Train Epoch: 6 [23680/37519 (63%)]\tLoss: 0.446426\n",
      "Train Epoch: 6 [24320/37519 (65%)]\tLoss: 0.150047\n",
      "Train Epoch: 6 [24960/37519 (66%)]\tLoss: 0.374872\n",
      "Train Epoch: 6 [25600/37519 (68%)]\tLoss: 0.230916\n",
      "Train Epoch: 6 [26240/37519 (70%)]\tLoss: 0.139589\n",
      "Train Epoch: 6 [26880/37519 (72%)]\tLoss: 0.224089\n",
      "Train Epoch: 6 [27520/37519 (73%)]\tLoss: 0.156910\n",
      "Train Epoch: 6 [28160/37519 (75%)]\tLoss: 0.374681\n",
      "Train Epoch: 6 [28800/37519 (77%)]\tLoss: 0.262842\n",
      "Train Epoch: 6 [29440/37519 (78%)]\tLoss: 0.247455\n",
      "Train Epoch: 6 [30080/37519 (80%)]\tLoss: 0.173239\n",
      "Train Epoch: 6 [30720/37519 (82%)]\tLoss: 0.105664\n",
      "Train Epoch: 6 [31360/37519 (83%)]\tLoss: 0.139659\n",
      "Train Epoch: 6 [32000/37519 (85%)]\tLoss: 0.253468\n",
      "Train Epoch: 6 [32640/37519 (87%)]\tLoss: 0.212325\n",
      "Train Epoch: 6 [33280/37519 (89%)]\tLoss: 0.481677\n",
      "Train Epoch: 6 [33920/37519 (90%)]\tLoss: 0.227646\n",
      "Train Epoch: 6 [34560/37519 (92%)]\tLoss: 0.171109\n",
      "Train Epoch: 6 [35200/37519 (94%)]\tLoss: 0.259265\n",
      "Train Epoch: 6 [35840/37519 (95%)]\tLoss: 0.190424\n",
      "Train Epoch: 6 [36480/37519 (97%)]\tLoss: 0.190047\n",
      "Train Epoch: 6 [37120/37519 (99%)]\tLoss: 0.149612\n",
      "Train Epoch: 7 [0/37519 (0%)]\tLoss: 0.277610\n",
      "Train Epoch: 7 [640/37519 (2%)]\tLoss: 0.569241\n",
      "Train Epoch: 7 [1280/37519 (3%)]\tLoss: 0.295761\n",
      "Train Epoch: 7 [1920/37519 (5%)]\tLoss: 0.216091\n",
      "Train Epoch: 7 [2560/37519 (7%)]\tLoss: 0.132878\n",
      "Train Epoch: 7 [3200/37519 (9%)]\tLoss: 0.217354\n",
      "Train Epoch: 7 [3840/37519 (10%)]\tLoss: 0.201966\n",
      "Train Epoch: 7 [4480/37519 (12%)]\tLoss: 0.148135\n",
      "Train Epoch: 7 [5120/37519 (14%)]\tLoss: 0.175088\n",
      "Train Epoch: 7 [5760/37519 (15%)]\tLoss: 0.141040\n",
      "Train Epoch: 7 [6400/37519 (17%)]\tLoss: 0.170297\n",
      "Train Epoch: 7 [7040/37519 (19%)]\tLoss: 0.249103\n",
      "Train Epoch: 7 [7680/37519 (20%)]\tLoss: 0.180419\n",
      "Train Epoch: 7 [8320/37519 (22%)]\tLoss: 0.179176\n",
      "Train Epoch: 7 [8960/37519 (24%)]\tLoss: 0.162287\n",
      "Train Epoch: 7 [9600/37519 (26%)]\tLoss: 0.260071\n",
      "Train Epoch: 7 [10240/37519 (27%)]\tLoss: 0.168357\n",
      "Train Epoch: 7 [10880/37519 (29%)]\tLoss: 0.260122\n",
      "Train Epoch: 7 [11520/37519 (31%)]\tLoss: 0.129832\n",
      "Train Epoch: 7 [12160/37519 (32%)]\tLoss: 0.103789\n",
      "Train Epoch: 7 [12800/37519 (34%)]\tLoss: 0.228309\n",
      "Train Epoch: 7 [13440/37519 (36%)]\tLoss: 0.102001\n",
      "Train Epoch: 7 [14080/37519 (37%)]\tLoss: 0.117195\n",
      "Train Epoch: 7 [14720/37519 (39%)]\tLoss: 0.376627\n",
      "Train Epoch: 7 [15360/37519 (41%)]\tLoss: 0.243434\n",
      "Train Epoch: 7 [16000/37519 (43%)]\tLoss: 0.268535\n",
      "Train Epoch: 7 [16640/37519 (44%)]\tLoss: 0.140477\n",
      "Train Epoch: 7 [17280/37519 (46%)]\tLoss: 0.243029\n",
      "Train Epoch: 7 [17920/37519 (48%)]\tLoss: 0.306348\n",
      "Train Epoch: 7 [18560/37519 (49%)]\tLoss: 0.303628\n",
      "Train Epoch: 7 [19200/37519 (51%)]\tLoss: 0.224511\n",
      "Train Epoch: 7 [19840/37519 (53%)]\tLoss: 0.200998\n",
      "Train Epoch: 7 [20480/37519 (55%)]\tLoss: 0.345376\n",
      "Train Epoch: 7 [21120/37519 (56%)]\tLoss: 0.248544\n",
      "Train Epoch: 7 [21760/37519 (58%)]\tLoss: 0.119910\n",
      "Train Epoch: 7 [22400/37519 (60%)]\tLoss: 0.257667\n",
      "Train Epoch: 7 [23040/37519 (61%)]\tLoss: 0.097772\n",
      "Train Epoch: 7 [23680/37519 (63%)]\tLoss: 0.066143\n",
      "Train Epoch: 7 [24320/37519 (65%)]\tLoss: 0.410075\n",
      "Train Epoch: 7 [24960/37519 (66%)]\tLoss: 0.303169\n",
      "Train Epoch: 7 [25600/37519 (68%)]\tLoss: 0.149454\n",
      "Train Epoch: 7 [26240/37519 (70%)]\tLoss: 0.365033\n",
      "Train Epoch: 7 [26880/37519 (72%)]\tLoss: 0.240647\n",
      "Train Epoch: 7 [27520/37519 (73%)]\tLoss: 0.190546\n",
      "Train Epoch: 7 [28160/37519 (75%)]\tLoss: 0.225365\n",
      "Train Epoch: 7 [28800/37519 (77%)]\tLoss: 0.165651\n",
      "Train Epoch: 7 [29440/37519 (78%)]\tLoss: 0.197786\n",
      "Train Epoch: 7 [30080/37519 (80%)]\tLoss: 0.151974\n",
      "Train Epoch: 7 [30720/37519 (82%)]\tLoss: 0.196415\n",
      "Train Epoch: 7 [31360/37519 (83%)]\tLoss: 0.282052\n",
      "Train Epoch: 7 [32000/37519 (85%)]\tLoss: 0.399970\n",
      "Train Epoch: 7 [32640/37519 (87%)]\tLoss: 0.208323\n",
      "Train Epoch: 7 [33280/37519 (89%)]\tLoss: 0.182893\n",
      "Train Epoch: 7 [33920/37519 (90%)]\tLoss: 0.243518\n",
      "Train Epoch: 7 [34560/37519 (92%)]\tLoss: 0.198469\n",
      "Train Epoch: 7 [35200/37519 (94%)]\tLoss: 0.354924\n",
      "Train Epoch: 7 [35840/37519 (95%)]\tLoss: 0.297980\n",
      "Train Epoch: 7 [36480/37519 (97%)]\tLoss: 0.236629\n",
      "Train Epoch: 7 [37120/37519 (99%)]\tLoss: 0.304466\n",
      "Train Epoch: 8 [0/37519 (0%)]\tLoss: 0.430333\n",
      "Train Epoch: 8 [640/37519 (2%)]\tLoss: 0.116337\n",
      "Train Epoch: 8 [1280/37519 (3%)]\tLoss: 0.152689\n",
      "Train Epoch: 8 [1920/37519 (5%)]\tLoss: 0.155837\n",
      "Train Epoch: 8 [2560/37519 (7%)]\tLoss: 0.165222\n",
      "Train Epoch: 8 [3200/37519 (9%)]\tLoss: 0.131202\n",
      "Train Epoch: 8 [3840/37519 (10%)]\tLoss: 0.167680\n",
      "Train Epoch: 8 [4480/37519 (12%)]\tLoss: 0.238780\n",
      "Train Epoch: 8 [5120/37519 (14%)]\tLoss: 0.312348\n",
      "Train Epoch: 8 [5760/37519 (15%)]\tLoss: 0.378604\n",
      "Train Epoch: 8 [6400/37519 (17%)]\tLoss: 0.268741\n",
      "Train Epoch: 8 [7040/37519 (19%)]\tLoss: 0.195864\n",
      "Train Epoch: 8 [7680/37519 (20%)]\tLoss: 0.224728\n",
      "Train Epoch: 8 [8320/37519 (22%)]\tLoss: 0.202566\n",
      "Train Epoch: 8 [8960/37519 (24%)]\tLoss: 0.248103\n",
      "Train Epoch: 8 [9600/37519 (26%)]\tLoss: 0.224452\n",
      "Train Epoch: 8 [10240/37519 (27%)]\tLoss: 0.116916\n",
      "Train Epoch: 8 [10880/37519 (29%)]\tLoss: 0.315168\n",
      "Train Epoch: 8 [11520/37519 (31%)]\tLoss: 0.178200\n",
      "Train Epoch: 8 [12160/37519 (32%)]\tLoss: 0.234849\n",
      "Train Epoch: 8 [12800/37519 (34%)]\tLoss: 0.113955\n",
      "Train Epoch: 8 [13440/37519 (36%)]\tLoss: 0.263086\n",
      "Train Epoch: 8 [14080/37519 (37%)]\tLoss: 0.303807\n",
      "Train Epoch: 8 [14720/37519 (39%)]\tLoss: 0.178054\n",
      "Train Epoch: 8 [15360/37519 (41%)]\tLoss: 0.340574\n",
      "Train Epoch: 8 [16000/37519 (43%)]\tLoss: 0.242062\n",
      "Train Epoch: 8 [16640/37519 (44%)]\tLoss: 0.174143\n",
      "Train Epoch: 8 [17280/37519 (46%)]\tLoss: 0.235720\n",
      "Train Epoch: 8 [17920/37519 (48%)]\tLoss: 0.072977\n",
      "Train Epoch: 8 [18560/37519 (49%)]\tLoss: 0.193040\n",
      "Train Epoch: 8 [19200/37519 (51%)]\tLoss: 0.117667\n",
      "Train Epoch: 8 [19840/37519 (53%)]\tLoss: 0.175735\n",
      "Train Epoch: 8 [20480/37519 (55%)]\tLoss: 0.157487\n",
      "Train Epoch: 8 [21120/37519 (56%)]\tLoss: 0.122997\n",
      "Train Epoch: 8 [21760/37519 (58%)]\tLoss: 0.160278\n",
      "Train Epoch: 8 [22400/37519 (60%)]\tLoss: 0.179821\n",
      "Train Epoch: 8 [23040/37519 (61%)]\tLoss: 0.323059\n",
      "Train Epoch: 8 [23680/37519 (63%)]\tLoss: 0.305492\n",
      "Train Epoch: 8 [24320/37519 (65%)]\tLoss: 0.143172\n",
      "Train Epoch: 8 [24960/37519 (66%)]\tLoss: 0.108919\n",
      "Train Epoch: 8 [25600/37519 (68%)]\tLoss: 0.268878\n",
      "Train Epoch: 8 [26240/37519 (70%)]\tLoss: 0.180924\n",
      "Train Epoch: 8 [26880/37519 (72%)]\tLoss: 0.152749\n",
      "Train Epoch: 8 [27520/37519 (73%)]\tLoss: 0.218447\n",
      "Train Epoch: 8 [28160/37519 (75%)]\tLoss: 0.067063\n",
      "Train Epoch: 8 [28800/37519 (77%)]\tLoss: 0.153816\n",
      "Train Epoch: 8 [29440/37519 (78%)]\tLoss: 0.055595\n",
      "Train Epoch: 8 [30080/37519 (80%)]\tLoss: 0.065906\n",
      "Train Epoch: 8 [30720/37519 (82%)]\tLoss: 0.152416\n",
      "Train Epoch: 8 [31360/37519 (83%)]\tLoss: 0.436346\n",
      "Train Epoch: 8 [32000/37519 (85%)]\tLoss: 0.265332\n",
      "Train Epoch: 8 [32640/37519 (87%)]\tLoss: 0.137946\n",
      "Train Epoch: 8 [33280/37519 (89%)]\tLoss: 0.456975\n",
      "Train Epoch: 8 [33920/37519 (90%)]\tLoss: 0.199783\n",
      "Train Epoch: 8 [34560/37519 (92%)]\tLoss: 0.227198\n",
      "Train Epoch: 8 [35200/37519 (94%)]\tLoss: 0.181669\n",
      "Train Epoch: 8 [35840/37519 (95%)]\tLoss: 0.222993\n",
      "Train Epoch: 8 [36480/37519 (97%)]\tLoss: 0.182617\n",
      "Train Epoch: 8 [37120/37519 (99%)]\tLoss: 0.061787\n",
      "Train Epoch: 9 [0/37519 (0%)]\tLoss: 0.206093\n",
      "Train Epoch: 9 [640/37519 (2%)]\tLoss: 0.385145\n",
      "Train Epoch: 9 [1280/37519 (3%)]\tLoss: 0.173845\n",
      "Train Epoch: 9 [1920/37519 (5%)]\tLoss: 0.202614\n",
      "Train Epoch: 9 [2560/37519 (7%)]\tLoss: 0.204642\n",
      "Train Epoch: 9 [3200/37519 (9%)]\tLoss: 0.139089\n",
      "Train Epoch: 9 [3840/37519 (10%)]\tLoss: 0.270270\n",
      "Train Epoch: 9 [4480/37519 (12%)]\tLoss: 0.165781\n",
      "Train Epoch: 9 [5120/37519 (14%)]\tLoss: 0.094021\n",
      "Train Epoch: 9 [5760/37519 (15%)]\tLoss: 0.121266\n",
      "Train Epoch: 9 [6400/37519 (17%)]\tLoss: 0.150027\n",
      "Train Epoch: 9 [7040/37519 (19%)]\tLoss: 0.154819\n",
      "Train Epoch: 9 [7680/37519 (20%)]\tLoss: 0.430862\n",
      "Train Epoch: 9 [8320/37519 (22%)]\tLoss: 0.341308\n",
      "Train Epoch: 9 [8960/37519 (24%)]\tLoss: 0.233125\n",
      "Train Epoch: 9 [9600/37519 (26%)]\tLoss: 0.268338\n",
      "Train Epoch: 9 [10240/37519 (27%)]\tLoss: 0.202603\n",
      "Train Epoch: 9 [10880/37519 (29%)]\tLoss: 0.137783\n",
      "Train Epoch: 9 [11520/37519 (31%)]\tLoss: 0.104944\n",
      "Train Epoch: 9 [12160/37519 (32%)]\tLoss: 0.184736\n",
      "Train Epoch: 9 [12800/37519 (34%)]\tLoss: 0.187459\n",
      "Train Epoch: 9 [13440/37519 (36%)]\tLoss: 0.260735\n",
      "Train Epoch: 9 [14080/37519 (37%)]\tLoss: 0.268334\n",
      "Train Epoch: 9 [14720/37519 (39%)]\tLoss: 0.194187\n",
      "Train Epoch: 9 [15360/37519 (41%)]\tLoss: 0.222700\n",
      "Train Epoch: 9 [16000/37519 (43%)]\tLoss: 0.213645\n",
      "Train Epoch: 9 [16640/37519 (44%)]\tLoss: 0.161992\n",
      "Train Epoch: 9 [17280/37519 (46%)]\tLoss: 0.200891\n",
      "Train Epoch: 9 [17920/37519 (48%)]\tLoss: 0.324650\n",
      "Train Epoch: 9 [18560/37519 (49%)]\tLoss: 0.142939\n",
      "Train Epoch: 9 [19200/37519 (51%)]\tLoss: 0.247149\n",
      "Train Epoch: 9 [19840/37519 (53%)]\tLoss: 0.057021\n",
      "Train Epoch: 9 [20480/37519 (55%)]\tLoss: 0.217778\n",
      "Train Epoch: 9 [21120/37519 (56%)]\tLoss: 0.124962\n",
      "Train Epoch: 9 [21760/37519 (58%)]\tLoss: 0.242204\n",
      "Train Epoch: 9 [22400/37519 (60%)]\tLoss: 0.141456\n",
      "Train Epoch: 9 [23040/37519 (61%)]\tLoss: 0.183484\n",
      "Train Epoch: 9 [23680/37519 (63%)]\tLoss: 0.256067\n",
      "Train Epoch: 9 [24320/37519 (65%)]\tLoss: 0.206714\n",
      "Train Epoch: 9 [24960/37519 (66%)]\tLoss: 0.106252\n",
      "Train Epoch: 9 [25600/37519 (68%)]\tLoss: 0.273288\n",
      "Train Epoch: 9 [26240/37519 (70%)]\tLoss: 0.130677\n",
      "Train Epoch: 9 [26880/37519 (72%)]\tLoss: 0.101517\n",
      "Train Epoch: 9 [27520/37519 (73%)]\tLoss: 0.135838\n",
      "Train Epoch: 9 [28160/37519 (75%)]\tLoss: 0.145126\n",
      "Train Epoch: 9 [28800/37519 (77%)]\tLoss: 0.258241\n",
      "Train Epoch: 9 [29440/37519 (78%)]\tLoss: 0.365879\n",
      "Train Epoch: 9 [30080/37519 (80%)]\tLoss: 0.257232\n",
      "Train Epoch: 9 [30720/37519 (82%)]\tLoss: 0.205037\n",
      "Train Epoch: 9 [31360/37519 (83%)]\tLoss: 0.138267\n",
      "Train Epoch: 9 [32000/37519 (85%)]\tLoss: 0.066590\n",
      "Train Epoch: 9 [32640/37519 (87%)]\tLoss: 0.241327\n",
      "Train Epoch: 9 [33280/37519 (89%)]\tLoss: 0.106944\n",
      "Train Epoch: 9 [33920/37519 (90%)]\tLoss: 0.566645\n",
      "Train Epoch: 9 [34560/37519 (92%)]\tLoss: 0.452110\n",
      "Train Epoch: 9 [35200/37519 (94%)]\tLoss: 0.093529\n",
      "Train Epoch: 9 [35840/37519 (95%)]\tLoss: 0.200547\n",
      "Train Epoch: 9 [36480/37519 (97%)]\tLoss: 0.219033\n",
      "Train Epoch: 9 [37120/37519 (99%)]\tLoss: 0.228942\n",
      "Train Epoch: 10 [0/37519 (0%)]\tLoss: 0.241459\n",
      "Train Epoch: 10 [640/37519 (2%)]\tLoss: 0.190109\n",
      "Train Epoch: 10 [1280/37519 (3%)]\tLoss: 0.214608\n",
      "Train Epoch: 10 [1920/37519 (5%)]\tLoss: 0.207938\n",
      "Train Epoch: 10 [2560/37519 (7%)]\tLoss: 0.103849\n",
      "Train Epoch: 10 [3200/37519 (9%)]\tLoss: 0.135812\n",
      "Train Epoch: 10 [3840/37519 (10%)]\tLoss: 0.403766\n",
      "Train Epoch: 10 [4480/37519 (12%)]\tLoss: 0.183568\n",
      "Train Epoch: 10 [5120/37519 (14%)]\tLoss: 0.196697\n",
      "Train Epoch: 10 [5760/37519 (15%)]\tLoss: 0.250029\n",
      "Train Epoch: 10 [6400/37519 (17%)]\tLoss: 0.400997\n",
      "Train Epoch: 10 [7040/37519 (19%)]\tLoss: 0.101119\n",
      "Train Epoch: 10 [7680/37519 (20%)]\tLoss: 0.097521\n",
      "Train Epoch: 10 [8320/37519 (22%)]\tLoss: 0.198655\n",
      "Train Epoch: 10 [8960/37519 (24%)]\tLoss: 0.110224\n",
      "Train Epoch: 10 [9600/37519 (26%)]\tLoss: 0.300361\n",
      "Train Epoch: 10 [10240/37519 (27%)]\tLoss: 0.141284\n",
      "Train Epoch: 10 [10880/37519 (29%)]\tLoss: 0.131595\n",
      "Train Epoch: 10 [11520/37519 (31%)]\tLoss: 0.252839\n",
      "Train Epoch: 10 [12160/37519 (32%)]\tLoss: 0.160410\n",
      "Train Epoch: 10 [12800/37519 (34%)]\tLoss: 0.167355\n",
      "Train Epoch: 10 [13440/37519 (36%)]\tLoss: 0.093040\n",
      "Train Epoch: 10 [14080/37519 (37%)]\tLoss: 0.129959\n",
      "Train Epoch: 10 [14720/37519 (39%)]\tLoss: 0.225642\n",
      "Train Epoch: 10 [15360/37519 (41%)]\tLoss: 0.105425\n",
      "Train Epoch: 10 [16000/37519 (43%)]\tLoss: 0.175307\n",
      "Train Epoch: 10 [16640/37519 (44%)]\tLoss: 0.153260\n",
      "Train Epoch: 10 [17280/37519 (46%)]\tLoss: 0.193884\n",
      "Train Epoch: 10 [17920/37519 (48%)]\tLoss: 0.134039\n",
      "Train Epoch: 10 [18560/37519 (49%)]\tLoss: 0.088709\n",
      "Train Epoch: 10 [19200/37519 (51%)]\tLoss: 0.106772\n",
      "Train Epoch: 10 [19840/37519 (53%)]\tLoss: 0.102181\n",
      "Train Epoch: 10 [20480/37519 (55%)]\tLoss: 0.057813\n",
      "Train Epoch: 10 [21120/37519 (56%)]\tLoss: 0.222117\n",
      "Train Epoch: 10 [21760/37519 (58%)]\tLoss: 0.331393\n",
      "Train Epoch: 10 [22400/37519 (60%)]\tLoss: 0.256337\n",
      "Train Epoch: 10 [23040/37519 (61%)]\tLoss: 0.153340\n",
      "Train Epoch: 10 [23680/37519 (63%)]\tLoss: 0.177037\n",
      "Train Epoch: 10 [24320/37519 (65%)]\tLoss: 0.133296\n",
      "Train Epoch: 10 [24960/37519 (66%)]\tLoss: 0.109838\n",
      "Train Epoch: 10 [25600/37519 (68%)]\tLoss: 0.320351\n",
      "Train Epoch: 10 [26240/37519 (70%)]\tLoss: 0.641322\n",
      "Train Epoch: 10 [26880/37519 (72%)]\tLoss: 0.078451\n",
      "Train Epoch: 10 [27520/37519 (73%)]\tLoss: 0.125371\n",
      "Train Epoch: 10 [28160/37519 (75%)]\tLoss: 0.049070\n",
      "Train Epoch: 10 [28800/37519 (77%)]\tLoss: 0.080824\n",
      "Train Epoch: 10 [29440/37519 (78%)]\tLoss: 0.260945\n",
      "Train Epoch: 10 [30080/37519 (80%)]\tLoss: 0.048315\n",
      "Train Epoch: 10 [30720/37519 (82%)]\tLoss: 0.309766\n",
      "Train Epoch: 10 [31360/37519 (83%)]\tLoss: 0.156074\n",
      "Train Epoch: 10 [32000/37519 (85%)]\tLoss: 0.175181\n",
      "Train Epoch: 10 [32640/37519 (87%)]\tLoss: 0.058900\n",
      "Train Epoch: 10 [33280/37519 (89%)]\tLoss: 0.241498\n",
      "Train Epoch: 10 [33920/37519 (90%)]\tLoss: 0.201057\n",
      "Train Epoch: 10 [34560/37519 (92%)]\tLoss: 0.073544\n",
      "Train Epoch: 10 [35200/37519 (94%)]\tLoss: 0.167175\n",
      "Train Epoch: 10 [35840/37519 (95%)]\tLoss: 0.164218\n",
      "Train Epoch: 10 [36480/37519 (97%)]\tLoss: 0.207869\n",
      "Train Epoch: 10 [37120/37519 (99%)]\tLoss: 0.170886\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/22481 (0%)]\tLoss: 0.395607\n",
      "Train Epoch: 1 [640/22481 (3%)]\tLoss: 0.247177\n",
      "Train Epoch: 1 [1280/22481 (6%)]\tLoss: 0.273739\n",
      "Train Epoch: 1 [1920/22481 (9%)]\tLoss: 0.266193\n",
      "Train Epoch: 1 [2560/22481 (11%)]\tLoss: 0.423305\n",
      "Train Epoch: 1 [3200/22481 (14%)]\tLoss: 0.499470\n",
      "Train Epoch: 1 [3840/22481 (17%)]\tLoss: 0.455527\n",
      "Train Epoch: 1 [4480/22481 (20%)]\tLoss: 0.316680\n",
      "Train Epoch: 1 [5120/22481 (23%)]\tLoss: 0.298340\n",
      "Train Epoch: 1 [5760/22481 (26%)]\tLoss: 0.457541\n",
      "Train Epoch: 1 [6400/22481 (28%)]\tLoss: 0.426969\n",
      "Train Epoch: 1 [7040/22481 (31%)]\tLoss: 0.343908\n",
      "Train Epoch: 1 [7680/22481 (34%)]\tLoss: 0.257623\n",
      "Train Epoch: 1 [8320/22481 (37%)]\tLoss: 0.421278\n",
      "Train Epoch: 1 [8960/22481 (40%)]\tLoss: 0.148030\n",
      "Train Epoch: 1 [9600/22481 (43%)]\tLoss: 0.284648\n",
      "Train Epoch: 1 [10240/22481 (45%)]\tLoss: 0.338727\n",
      "Train Epoch: 1 [10880/22481 (48%)]\tLoss: 0.353648\n",
      "Train Epoch: 1 [11520/22481 (51%)]\tLoss: 0.386609\n",
      "Train Epoch: 1 [12160/22481 (54%)]\tLoss: 0.326044\n",
      "Train Epoch: 1 [12800/22481 (57%)]\tLoss: 0.393842\n",
      "Train Epoch: 1 [13440/22481 (60%)]\tLoss: 0.325782\n",
      "Train Epoch: 1 [14080/22481 (62%)]\tLoss: 0.230285\n",
      "Train Epoch: 1 [14720/22481 (65%)]\tLoss: 0.226389\n",
      "Train Epoch: 1 [15360/22481 (68%)]\tLoss: 0.329154\n",
      "Train Epoch: 1 [16000/22481 (71%)]\tLoss: 0.403832\n",
      "Train Epoch: 1 [16640/22481 (74%)]\tLoss: 0.416935\n",
      "Train Epoch: 1 [17280/22481 (77%)]\tLoss: 0.249653\n",
      "Train Epoch: 1 [17920/22481 (80%)]\tLoss: 0.281920\n",
      "Train Epoch: 1 [18560/22481 (82%)]\tLoss: 0.190487\n",
      "Train Epoch: 1 [19200/22481 (85%)]\tLoss: 0.361136\n",
      "Train Epoch: 1 [19840/22481 (88%)]\tLoss: 0.159102\n",
      "Train Epoch: 1 [20480/22481 (91%)]\tLoss: 0.126017\n",
      "Train Epoch: 1 [21120/22481 (94%)]\tLoss: 0.182244\n",
      "Train Epoch: 1 [21760/22481 (97%)]\tLoss: 0.236100\n",
      "Train Epoch: 1 [22400/22481 (99%)]\tLoss: 0.425045\n",
      "Train Epoch: 2 [0/22481 (0%)]\tLoss: 0.453889\n",
      "Train Epoch: 2 [640/22481 (3%)]\tLoss: 0.200648\n",
      "Train Epoch: 2 [1280/22481 (6%)]\tLoss: 0.192562\n",
      "Train Epoch: 2 [1920/22481 (9%)]\tLoss: 0.270885\n",
      "Train Epoch: 2 [2560/22481 (11%)]\tLoss: 0.510388\n",
      "Train Epoch: 2 [3200/22481 (14%)]\tLoss: 0.345101\n",
      "Train Epoch: 2 [3840/22481 (17%)]\tLoss: 0.247013\n",
      "Train Epoch: 2 [4480/22481 (20%)]\tLoss: 0.378597\n",
      "Train Epoch: 2 [5120/22481 (23%)]\tLoss: 0.329181\n",
      "Train Epoch: 2 [5760/22481 (26%)]\tLoss: 0.478610\n",
      "Train Epoch: 2 [6400/22481 (28%)]\tLoss: 0.177226\n",
      "Train Epoch: 2 [7040/22481 (31%)]\tLoss: 0.143579\n",
      "Train Epoch: 2 [7680/22481 (34%)]\tLoss: 0.108015\n",
      "Train Epoch: 2 [8320/22481 (37%)]\tLoss: 0.245945\n",
      "Train Epoch: 2 [8960/22481 (40%)]\tLoss: 0.498572\n",
      "Train Epoch: 2 [9600/22481 (43%)]\tLoss: 0.301642\n",
      "Train Epoch: 2 [10240/22481 (45%)]\tLoss: 0.278403\n",
      "Train Epoch: 2 [10880/22481 (48%)]\tLoss: 0.246020\n",
      "Train Epoch: 2 [11520/22481 (51%)]\tLoss: 0.189006\n",
      "Train Epoch: 2 [12160/22481 (54%)]\tLoss: 0.133014\n",
      "Train Epoch: 2 [12800/22481 (57%)]\tLoss: 0.283227\n",
      "Train Epoch: 2 [13440/22481 (60%)]\tLoss: 0.226695\n",
      "Train Epoch: 2 [14080/22481 (62%)]\tLoss: 0.407376\n",
      "Train Epoch: 2 [14720/22481 (65%)]\tLoss: 0.325544\n",
      "Train Epoch: 2 [15360/22481 (68%)]\tLoss: 0.258334\n",
      "Train Epoch: 2 [16000/22481 (71%)]\tLoss: 0.213900\n",
      "Train Epoch: 2 [16640/22481 (74%)]\tLoss: 0.122077\n",
      "Train Epoch: 2 [17280/22481 (77%)]\tLoss: 0.305946\n",
      "Train Epoch: 2 [17920/22481 (80%)]\tLoss: 0.379864\n",
      "Train Epoch: 2 [18560/22481 (82%)]\tLoss: 0.224217\n",
      "Train Epoch: 2 [19200/22481 (85%)]\tLoss: 0.341457\n",
      "Train Epoch: 2 [19840/22481 (88%)]\tLoss: 0.273094\n",
      "Train Epoch: 2 [20480/22481 (91%)]\tLoss: 0.321838\n",
      "Train Epoch: 2 [21120/22481 (94%)]\tLoss: 0.220168\n",
      "Train Epoch: 2 [21760/22481 (97%)]\tLoss: 0.203141\n",
      "Train Epoch: 2 [22400/22481 (99%)]\tLoss: 0.198127\n",
      "Train Epoch: 3 [0/22481 (0%)]\tLoss: 0.110997\n",
      "Train Epoch: 3 [640/22481 (3%)]\tLoss: 0.153364\n",
      "Train Epoch: 3 [1280/22481 (6%)]\tLoss: 0.200336\n",
      "Train Epoch: 3 [1920/22481 (9%)]\tLoss: 0.348268\n",
      "Train Epoch: 3 [2560/22481 (11%)]\tLoss: 0.235437\n",
      "Train Epoch: 3 [3200/22481 (14%)]\tLoss: 0.234439\n",
      "Train Epoch: 3 [3840/22481 (17%)]\tLoss: 0.216643\n",
      "Train Epoch: 3 [4480/22481 (20%)]\tLoss: 0.090431\n",
      "Train Epoch: 3 [5120/22481 (23%)]\tLoss: 0.334273\n",
      "Train Epoch: 3 [5760/22481 (26%)]\tLoss: 0.244298\n",
      "Train Epoch: 3 [6400/22481 (28%)]\tLoss: 0.225413\n",
      "Train Epoch: 3 [7040/22481 (31%)]\tLoss: 0.457533\n",
      "Train Epoch: 3 [7680/22481 (34%)]\tLoss: 0.208521\n",
      "Train Epoch: 3 [8320/22481 (37%)]\tLoss: 0.225194\n",
      "Train Epoch: 3 [8960/22481 (40%)]\tLoss: 0.255685\n",
      "Train Epoch: 3 [9600/22481 (43%)]\tLoss: 0.115964\n",
      "Train Epoch: 3 [10240/22481 (45%)]\tLoss: 0.249977\n",
      "Train Epoch: 3 [10880/22481 (48%)]\tLoss: 0.389535\n",
      "Train Epoch: 3 [11520/22481 (51%)]\tLoss: 0.281343\n",
      "Train Epoch: 3 [12160/22481 (54%)]\tLoss: 0.183831\n",
      "Train Epoch: 3 [12800/22481 (57%)]\tLoss: 0.284521\n",
      "Train Epoch: 3 [13440/22481 (60%)]\tLoss: 0.462917\n",
      "Train Epoch: 3 [14080/22481 (62%)]\tLoss: 0.074900\n",
      "Train Epoch: 3 [14720/22481 (65%)]\tLoss: 0.155960\n",
      "Train Epoch: 3 [15360/22481 (68%)]\tLoss: 0.286139\n",
      "Train Epoch: 3 [16000/22481 (71%)]\tLoss: 0.207648\n",
      "Train Epoch: 3 [16640/22481 (74%)]\tLoss: 0.166309\n",
      "Train Epoch: 3 [17280/22481 (77%)]\tLoss: 0.337482\n",
      "Train Epoch: 3 [17920/22481 (80%)]\tLoss: 0.152063\n",
      "Train Epoch: 3 [18560/22481 (82%)]\tLoss: 0.252249\n",
      "Train Epoch: 3 [19200/22481 (85%)]\tLoss: 0.321149\n",
      "Train Epoch: 3 [19840/22481 (88%)]\tLoss: 0.290998\n",
      "Train Epoch: 3 [20480/22481 (91%)]\tLoss: 0.174008\n",
      "Train Epoch: 3 [21120/22481 (94%)]\tLoss: 0.317351\n",
      "Train Epoch: 3 [21760/22481 (97%)]\tLoss: 0.369487\n",
      "Train Epoch: 3 [22400/22481 (99%)]\tLoss: 0.142610\n",
      "Train Epoch: 4 [0/22481 (0%)]\tLoss: 0.280883\n",
      "Train Epoch: 4 [640/22481 (3%)]\tLoss: 0.179265\n",
      "Train Epoch: 4 [1280/22481 (6%)]\tLoss: 0.321289\n",
      "Train Epoch: 4 [1920/22481 (9%)]\tLoss: 0.119571\n",
      "Train Epoch: 4 [2560/22481 (11%)]\tLoss: 0.463827\n",
      "Train Epoch: 4 [3200/22481 (14%)]\tLoss: 0.210680\n",
      "Train Epoch: 4 [3840/22481 (17%)]\tLoss: 0.231307\n",
      "Train Epoch: 4 [4480/22481 (20%)]\tLoss: 0.278150\n",
      "Train Epoch: 4 [5120/22481 (23%)]\tLoss: 0.121857\n",
      "Train Epoch: 4 [5760/22481 (26%)]\tLoss: 0.194842\n",
      "Train Epoch: 4 [6400/22481 (28%)]\tLoss: 0.289309\n",
      "Train Epoch: 4 [7040/22481 (31%)]\tLoss: 0.186850\n",
      "Train Epoch: 4 [7680/22481 (34%)]\tLoss: 0.191421\n",
      "Train Epoch: 4 [8320/22481 (37%)]\tLoss: 0.110220\n",
      "Train Epoch: 4 [8960/22481 (40%)]\tLoss: 0.236509\n",
      "Train Epoch: 4 [9600/22481 (43%)]\tLoss: 0.217569\n",
      "Train Epoch: 4 [10240/22481 (45%)]\tLoss: 0.158497\n",
      "Train Epoch: 4 [10880/22481 (48%)]\tLoss: 0.230795\n",
      "Train Epoch: 4 [11520/22481 (51%)]\tLoss: 0.252651\n",
      "Train Epoch: 4 [12160/22481 (54%)]\tLoss: 0.279349\n",
      "Train Epoch: 4 [12800/22481 (57%)]\tLoss: 0.298824\n",
      "Train Epoch: 4 [13440/22481 (60%)]\tLoss: 0.160549\n",
      "Train Epoch: 4 [14080/22481 (62%)]\tLoss: 0.134339\n",
      "Train Epoch: 4 [14720/22481 (65%)]\tLoss: 0.081083\n",
      "Train Epoch: 4 [15360/22481 (68%)]\tLoss: 0.106106\n",
      "Train Epoch: 4 [16000/22481 (71%)]\tLoss: 0.102189\n",
      "Train Epoch: 4 [16640/22481 (74%)]\tLoss: 0.113680\n",
      "Train Epoch: 4 [17280/22481 (77%)]\tLoss: 0.155908\n",
      "Train Epoch: 4 [17920/22481 (80%)]\tLoss: 0.128317\n",
      "Train Epoch: 4 [18560/22481 (82%)]\tLoss: 0.230577\n",
      "Train Epoch: 4 [19200/22481 (85%)]\tLoss: 0.206290\n",
      "Train Epoch: 4 [19840/22481 (88%)]\tLoss: 0.357070\n",
      "Train Epoch: 4 [20480/22481 (91%)]\tLoss: 0.263454\n",
      "Train Epoch: 4 [21120/22481 (94%)]\tLoss: 0.224214\n",
      "Train Epoch: 4 [21760/22481 (97%)]\tLoss: 0.371512\n",
      "Train Epoch: 4 [22400/22481 (99%)]\tLoss: 0.293168\n",
      "Train Epoch: 5 [0/22481 (0%)]\tLoss: 0.271143\n",
      "Train Epoch: 5 [640/22481 (3%)]\tLoss: 0.191666\n",
      "Train Epoch: 5 [1280/22481 (6%)]\tLoss: 0.127932\n",
      "Train Epoch: 5 [1920/22481 (9%)]\tLoss: 0.253360\n",
      "Train Epoch: 5 [2560/22481 (11%)]\tLoss: 0.212364\n",
      "Train Epoch: 5 [3200/22481 (14%)]\tLoss: 0.339792\n",
      "Train Epoch: 5 [3840/22481 (17%)]\tLoss: 0.230425\n",
      "Train Epoch: 5 [4480/22481 (20%)]\tLoss: 0.288007\n",
      "Train Epoch: 5 [5120/22481 (23%)]\tLoss: 0.119967\n",
      "Train Epoch: 5 [5760/22481 (26%)]\tLoss: 0.165712\n",
      "Train Epoch: 5 [6400/22481 (28%)]\tLoss: 0.197412\n",
      "Train Epoch: 5 [7040/22481 (31%)]\tLoss: 0.162977\n",
      "Train Epoch: 5 [7680/22481 (34%)]\tLoss: 0.371993\n",
      "Train Epoch: 5 [8320/22481 (37%)]\tLoss: 0.100403\n",
      "Train Epoch: 5 [8960/22481 (40%)]\tLoss: 0.176705\n",
      "Train Epoch: 5 [9600/22481 (43%)]\tLoss: 0.107160\n",
      "Train Epoch: 5 [10240/22481 (45%)]\tLoss: 0.240912\n",
      "Train Epoch: 5 [10880/22481 (48%)]\tLoss: 0.171217\n",
      "Train Epoch: 5 [11520/22481 (51%)]\tLoss: 0.215512\n",
      "Train Epoch: 5 [12160/22481 (54%)]\tLoss: 0.117245\n",
      "Train Epoch: 5 [12800/22481 (57%)]\tLoss: 0.190379\n",
      "Train Epoch: 5 [13440/22481 (60%)]\tLoss: 0.150120\n",
      "Train Epoch: 5 [14080/22481 (62%)]\tLoss: 0.157023\n",
      "Train Epoch: 5 [14720/22481 (65%)]\tLoss: 0.203921\n",
      "Train Epoch: 5 [15360/22481 (68%)]\tLoss: 0.104845\n",
      "Train Epoch: 5 [16000/22481 (71%)]\tLoss: 0.142690\n",
      "Train Epoch: 5 [16640/22481 (74%)]\tLoss: 0.140355\n",
      "Train Epoch: 5 [17280/22481 (77%)]\tLoss: 0.224957\n",
      "Train Epoch: 5 [17920/22481 (80%)]\tLoss: 0.170825\n",
      "Train Epoch: 5 [18560/22481 (82%)]\tLoss: 0.094334\n",
      "Train Epoch: 5 [19200/22481 (85%)]\tLoss: 0.250552\n",
      "Train Epoch: 5 [19840/22481 (88%)]\tLoss: 0.130178\n",
      "Train Epoch: 5 [20480/22481 (91%)]\tLoss: 0.179259\n",
      "Train Epoch: 5 [21120/22481 (94%)]\tLoss: 0.088487\n",
      "Train Epoch: 5 [21760/22481 (97%)]\tLoss: 0.429146\n",
      "Train Epoch: 5 [22400/22481 (99%)]\tLoss: 0.411006\n",
      "Train Epoch: 6 [0/22481 (0%)]\tLoss: 0.240196\n",
      "Train Epoch: 6 [640/22481 (3%)]\tLoss: 0.172592\n",
      "Train Epoch: 6 [1280/22481 (6%)]\tLoss: 0.109249\n",
      "Train Epoch: 6 [1920/22481 (9%)]\tLoss: 0.175243\n",
      "Train Epoch: 6 [2560/22481 (11%)]\tLoss: 0.051534\n",
      "Train Epoch: 6 [3200/22481 (14%)]\tLoss: 0.287615\n",
      "Train Epoch: 6 [3840/22481 (17%)]\tLoss: 0.231661\n",
      "Train Epoch: 6 [4480/22481 (20%)]\tLoss: 0.064918\n",
      "Train Epoch: 6 [5120/22481 (23%)]\tLoss: 0.044120\n",
      "Train Epoch: 6 [5760/22481 (26%)]\tLoss: 0.165229\n",
      "Train Epoch: 6 [6400/22481 (28%)]\tLoss: 0.221777\n",
      "Train Epoch: 6 [7040/22481 (31%)]\tLoss: 0.197570\n",
      "Train Epoch: 6 [7680/22481 (34%)]\tLoss: 0.287016\n",
      "Train Epoch: 6 [8320/22481 (37%)]\tLoss: 0.149047\n",
      "Train Epoch: 6 [8960/22481 (40%)]\tLoss: 0.113616\n",
      "Train Epoch: 6 [9600/22481 (43%)]\tLoss: 0.298694\n",
      "Train Epoch: 6 [10240/22481 (45%)]\tLoss: 0.240033\n",
      "Train Epoch: 6 [10880/22481 (48%)]\tLoss: 0.304257\n",
      "Train Epoch: 6 [11520/22481 (51%)]\tLoss: 0.143791\n",
      "Train Epoch: 6 [12160/22481 (54%)]\tLoss: 0.359551\n",
      "Train Epoch: 6 [12800/22481 (57%)]\tLoss: 0.142398\n",
      "Train Epoch: 6 [13440/22481 (60%)]\tLoss: 0.171151\n",
      "Train Epoch: 6 [14080/22481 (62%)]\tLoss: 0.094407\n",
      "Train Epoch: 6 [14720/22481 (65%)]\tLoss: 0.075170\n",
      "Train Epoch: 6 [15360/22481 (68%)]\tLoss: 0.265431\n",
      "Train Epoch: 6 [16000/22481 (71%)]\tLoss: 0.105259\n",
      "Train Epoch: 6 [16640/22481 (74%)]\tLoss: 0.205172\n",
      "Train Epoch: 6 [17280/22481 (77%)]\tLoss: 0.103416\n",
      "Train Epoch: 6 [17920/22481 (80%)]\tLoss: 0.090999\n",
      "Train Epoch: 6 [18560/22481 (82%)]\tLoss: 0.134051\n",
      "Train Epoch: 6 [19200/22481 (85%)]\tLoss: 0.155440\n",
      "Train Epoch: 6 [19840/22481 (88%)]\tLoss: 0.164356\n",
      "Train Epoch: 6 [20480/22481 (91%)]\tLoss: 0.210751\n",
      "Train Epoch: 6 [21120/22481 (94%)]\tLoss: 0.441187\n",
      "Train Epoch: 6 [21760/22481 (97%)]\tLoss: 0.204094\n",
      "Train Epoch: 6 [22400/22481 (99%)]\tLoss: 0.224530\n",
      "Train Epoch: 7 [0/22481 (0%)]\tLoss: 0.145043\n",
      "Train Epoch: 7 [640/22481 (3%)]\tLoss: 0.213004\n",
      "Train Epoch: 7 [1280/22481 (6%)]\tLoss: 0.189697\n",
      "Train Epoch: 7 [1920/22481 (9%)]\tLoss: 0.277203\n",
      "Train Epoch: 7 [2560/22481 (11%)]\tLoss: 0.041530\n",
      "Train Epoch: 7 [3200/22481 (14%)]\tLoss: 0.150957\n",
      "Train Epoch: 7 [3840/22481 (17%)]\tLoss: 0.256334\n",
      "Train Epoch: 7 [4480/22481 (20%)]\tLoss: 0.123898\n",
      "Train Epoch: 7 [5120/22481 (23%)]\tLoss: 0.275517\n",
      "Train Epoch: 7 [5760/22481 (26%)]\tLoss: 0.156876\n",
      "Train Epoch: 7 [6400/22481 (28%)]\tLoss: 0.111251\n",
      "Train Epoch: 7 [7040/22481 (31%)]\tLoss: 0.249416\n",
      "Train Epoch: 7 [7680/22481 (34%)]\tLoss: 0.271646\n",
      "Train Epoch: 7 [8320/22481 (37%)]\tLoss: 0.227401\n",
      "Train Epoch: 7 [8960/22481 (40%)]\tLoss: 0.101936\n",
      "Train Epoch: 7 [9600/22481 (43%)]\tLoss: 0.187733\n",
      "Train Epoch: 7 [10240/22481 (45%)]\tLoss: 0.103378\n",
      "Train Epoch: 7 [10880/22481 (48%)]\tLoss: 0.148396\n",
      "Train Epoch: 7 [11520/22481 (51%)]\tLoss: 0.066595\n",
      "Train Epoch: 7 [12160/22481 (54%)]\tLoss: 0.185840\n",
      "Train Epoch: 7 [12800/22481 (57%)]\tLoss: 0.243736\n",
      "Train Epoch: 7 [13440/22481 (60%)]\tLoss: 0.074675\n",
      "Train Epoch: 7 [14080/22481 (62%)]\tLoss: 0.181551\n",
      "Train Epoch: 7 [14720/22481 (65%)]\tLoss: 0.110690\n",
      "Train Epoch: 7 [15360/22481 (68%)]\tLoss: 0.216119\n",
      "Train Epoch: 7 [16000/22481 (71%)]\tLoss: 0.130996\n",
      "Train Epoch: 7 [16640/22481 (74%)]\tLoss: 0.115230\n",
      "Train Epoch: 7 [17280/22481 (77%)]\tLoss: 0.259903\n",
      "Train Epoch: 7 [17920/22481 (80%)]\tLoss: 0.216153\n",
      "Train Epoch: 7 [18560/22481 (82%)]\tLoss: 0.362788\n",
      "Train Epoch: 7 [19200/22481 (85%)]\tLoss: 0.156889\n",
      "Train Epoch: 7 [19840/22481 (88%)]\tLoss: 0.139226\n",
      "Train Epoch: 7 [20480/22481 (91%)]\tLoss: 0.134532\n",
      "Train Epoch: 7 [21120/22481 (94%)]\tLoss: 0.240631\n",
      "Train Epoch: 7 [21760/22481 (97%)]\tLoss: 0.135010\n",
      "Train Epoch: 7 [22400/22481 (99%)]\tLoss: 0.192183\n",
      "Train Epoch: 8 [0/22481 (0%)]\tLoss: 0.156731\n",
      "Train Epoch: 8 [640/22481 (3%)]\tLoss: 0.157266\n",
      "Train Epoch: 8 [1280/22481 (6%)]\tLoss: 0.230974\n",
      "Train Epoch: 8 [1920/22481 (9%)]\tLoss: 0.071308\n",
      "Train Epoch: 8 [2560/22481 (11%)]\tLoss: 0.173067\n",
      "Train Epoch: 8 [3200/22481 (14%)]\tLoss: 0.158755\n",
      "Train Epoch: 8 [3840/22481 (17%)]\tLoss: 0.256784\n",
      "Train Epoch: 8 [4480/22481 (20%)]\tLoss: 0.135615\n",
      "Train Epoch: 8 [5120/22481 (23%)]\tLoss: 0.070564\n",
      "Train Epoch: 8 [5760/22481 (26%)]\tLoss: 0.160760\n",
      "Train Epoch: 8 [6400/22481 (28%)]\tLoss: 0.242989\n",
      "Train Epoch: 8 [7040/22481 (31%)]\tLoss: 0.095775\n",
      "Train Epoch: 8 [7680/22481 (34%)]\tLoss: 0.098050\n",
      "Train Epoch: 8 [8320/22481 (37%)]\tLoss: 0.134159\n",
      "Train Epoch: 8 [8960/22481 (40%)]\tLoss: 0.145983\n",
      "Train Epoch: 8 [9600/22481 (43%)]\tLoss: 0.207458\n",
      "Train Epoch: 8 [10240/22481 (45%)]\tLoss: 0.219584\n",
      "Train Epoch: 8 [10880/22481 (48%)]\tLoss: 0.182790\n",
      "Train Epoch: 8 [11520/22481 (51%)]\tLoss: 0.158684\n",
      "Train Epoch: 8 [12160/22481 (54%)]\tLoss: 0.188957\n",
      "Train Epoch: 8 [12800/22481 (57%)]\tLoss: 0.120504\n",
      "Train Epoch: 8 [13440/22481 (60%)]\tLoss: 0.355627\n",
      "Train Epoch: 8 [14080/22481 (62%)]\tLoss: 0.080041\n",
      "Train Epoch: 8 [14720/22481 (65%)]\tLoss: 0.101599\n",
      "Train Epoch: 8 [15360/22481 (68%)]\tLoss: 0.093637\n",
      "Train Epoch: 8 [16000/22481 (71%)]\tLoss: 0.462681\n",
      "Train Epoch: 8 [16640/22481 (74%)]\tLoss: 0.110230\n",
      "Train Epoch: 8 [17280/22481 (77%)]\tLoss: 0.099123\n",
      "Train Epoch: 8 [17920/22481 (80%)]\tLoss: 0.129911\n",
      "Train Epoch: 8 [18560/22481 (82%)]\tLoss: 0.215290\n",
      "Train Epoch: 8 [19200/22481 (85%)]\tLoss: 0.279366\n",
      "Train Epoch: 8 [19840/22481 (88%)]\tLoss: 0.215096\n",
      "Train Epoch: 8 [20480/22481 (91%)]\tLoss: 0.165134\n",
      "Train Epoch: 8 [21120/22481 (94%)]\tLoss: 0.172897\n",
      "Train Epoch: 8 [21760/22481 (97%)]\tLoss: 0.080269\n",
      "Train Epoch: 8 [22400/22481 (99%)]\tLoss: 0.184030\n",
      "Train Epoch: 9 [0/22481 (0%)]\tLoss: 0.085952\n",
      "Train Epoch: 9 [640/22481 (3%)]\tLoss: 0.098535\n",
      "Train Epoch: 9 [1280/22481 (6%)]\tLoss: 0.328552\n",
      "Train Epoch: 9 [1920/22481 (9%)]\tLoss: 0.248158\n",
      "Train Epoch: 9 [2560/22481 (11%)]\tLoss: 0.098622\n",
      "Train Epoch: 9 [3200/22481 (14%)]\tLoss: 0.098038\n",
      "Train Epoch: 9 [3840/22481 (17%)]\tLoss: 0.270997\n",
      "Train Epoch: 9 [4480/22481 (20%)]\tLoss: 0.243694\n",
      "Train Epoch: 9 [5120/22481 (23%)]\tLoss: 0.137358\n",
      "Train Epoch: 9 [5760/22481 (26%)]\tLoss: 0.082899\n",
      "Train Epoch: 9 [6400/22481 (28%)]\tLoss: 0.115604\n",
      "Train Epoch: 9 [7040/22481 (31%)]\tLoss: 0.235402\n",
      "Train Epoch: 9 [7680/22481 (34%)]\tLoss: 0.316672\n",
      "Train Epoch: 9 [8320/22481 (37%)]\tLoss: 0.213783\n",
      "Train Epoch: 9 [8960/22481 (40%)]\tLoss: 0.139903\n",
      "Train Epoch: 9 [9600/22481 (43%)]\tLoss: 0.211000\n",
      "Train Epoch: 9 [10240/22481 (45%)]\tLoss: 0.120988\n",
      "Train Epoch: 9 [10880/22481 (48%)]\tLoss: 0.231412\n",
      "Train Epoch: 9 [11520/22481 (51%)]\tLoss: 0.516801\n",
      "Train Epoch: 9 [12160/22481 (54%)]\tLoss: 0.084410\n",
      "Train Epoch: 9 [12800/22481 (57%)]\tLoss: 0.081963\n",
      "Train Epoch: 9 [13440/22481 (60%)]\tLoss: 0.123240\n",
      "Train Epoch: 9 [14080/22481 (62%)]\tLoss: 0.078429\n",
      "Train Epoch: 9 [14720/22481 (65%)]\tLoss: 0.049192\n",
      "Train Epoch: 9 [15360/22481 (68%)]\tLoss: 0.192329\n",
      "Train Epoch: 9 [16000/22481 (71%)]\tLoss: 0.140136\n",
      "Train Epoch: 9 [16640/22481 (74%)]\tLoss: 0.227506\n",
      "Train Epoch: 9 [17280/22481 (77%)]\tLoss: 0.212013\n",
      "Train Epoch: 9 [17920/22481 (80%)]\tLoss: 0.192993\n",
      "Train Epoch: 9 [18560/22481 (82%)]\tLoss: 0.115902\n",
      "Train Epoch: 9 [19200/22481 (85%)]\tLoss: 0.186464\n",
      "Train Epoch: 9 [19840/22481 (88%)]\tLoss: 0.394010\n",
      "Train Epoch: 9 [20480/22481 (91%)]\tLoss: 0.074570\n",
      "Train Epoch: 9 [21120/22481 (94%)]\tLoss: 0.257245\n",
      "Train Epoch: 9 [21760/22481 (97%)]\tLoss: 0.271293\n",
      "Train Epoch: 9 [22400/22481 (99%)]\tLoss: 0.155983\n",
      "Train Epoch: 10 [0/22481 (0%)]\tLoss: 0.198771\n",
      "Train Epoch: 10 [640/22481 (3%)]\tLoss: 0.358278\n",
      "Train Epoch: 10 [1280/22481 (6%)]\tLoss: 0.062248\n",
      "Train Epoch: 10 [1920/22481 (9%)]\tLoss: 0.095129\n",
      "Train Epoch: 10 [2560/22481 (11%)]\tLoss: 0.232776\n",
      "Train Epoch: 10 [3200/22481 (14%)]\tLoss: 0.111009\n",
      "Train Epoch: 10 [3840/22481 (17%)]\tLoss: 0.220722\n",
      "Train Epoch: 10 [4480/22481 (20%)]\tLoss: 0.188170\n",
      "Train Epoch: 10 [5120/22481 (23%)]\tLoss: 0.215920\n",
      "Train Epoch: 10 [5760/22481 (26%)]\tLoss: 0.295171\n",
      "Train Epoch: 10 [6400/22481 (28%)]\tLoss: 0.164263\n",
      "Train Epoch: 10 [7040/22481 (31%)]\tLoss: 0.062848\n",
      "Train Epoch: 10 [7680/22481 (34%)]\tLoss: 0.237293\n",
      "Train Epoch: 10 [8320/22481 (37%)]\tLoss: 0.203137\n",
      "Train Epoch: 10 [8960/22481 (40%)]\tLoss: 0.112607\n",
      "Train Epoch: 10 [9600/22481 (43%)]\tLoss: 0.210269\n",
      "Train Epoch: 10 [10240/22481 (45%)]\tLoss: 0.157062\n",
      "Train Epoch: 10 [10880/22481 (48%)]\tLoss: 0.242838\n",
      "Train Epoch: 10 [11520/22481 (51%)]\tLoss: 0.187433\n",
      "Train Epoch: 10 [12160/22481 (54%)]\tLoss: 0.135064\n",
      "Train Epoch: 10 [12800/22481 (57%)]\tLoss: 0.173149\n",
      "Train Epoch: 10 [13440/22481 (60%)]\tLoss: 0.224457\n",
      "Train Epoch: 10 [14080/22481 (62%)]\tLoss: 0.176104\n",
      "Train Epoch: 10 [14720/22481 (65%)]\tLoss: 0.149048\n",
      "Train Epoch: 10 [15360/22481 (68%)]\tLoss: 0.370435\n",
      "Train Epoch: 10 [16000/22481 (71%)]\tLoss: 0.293938\n",
      "Train Epoch: 10 [16640/22481 (74%)]\tLoss: 0.120061\n",
      "Train Epoch: 10 [17280/22481 (77%)]\tLoss: 0.232551\n",
      "Train Epoch: 10 [17920/22481 (80%)]\tLoss: 0.180755\n",
      "Train Epoch: 10 [18560/22481 (82%)]\tLoss: 0.254926\n",
      "Train Epoch: 10 [19200/22481 (85%)]\tLoss: 0.042551\n",
      "Train Epoch: 10 [19840/22481 (88%)]\tLoss: 0.385164\n",
      "Train Epoch: 10 [20480/22481 (91%)]\tLoss: 0.244881\n",
      "Train Epoch: 10 [21120/22481 (94%)]\tLoss: 0.215037\n",
      "Train Epoch: 10 [21760/22481 (97%)]\tLoss: 0.206188\n",
      "Train Epoch: 10 [22400/22481 (99%)]\tLoss: 0.110963\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.1205, Accuracy: 9627/10000 (96%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/37519 (0%)]\tLoss: 0.321539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [640/37519 (2%)]\tLoss: 0.343194\n",
      "Train Epoch: 1 [1280/37519 (3%)]\tLoss: 0.247093\n",
      "Train Epoch: 1 [1920/37519 (5%)]\tLoss: 0.415553\n",
      "Train Epoch: 1 [2560/37519 (7%)]\tLoss: 0.163176\n",
      "Train Epoch: 1 [3200/37519 (9%)]\tLoss: 0.291163\n",
      "Train Epoch: 1 [3840/37519 (10%)]\tLoss: 0.145428\n",
      "Train Epoch: 1 [4480/37519 (12%)]\tLoss: 0.311284\n",
      "Train Epoch: 1 [5120/37519 (14%)]\tLoss: 0.297041\n",
      "Train Epoch: 1 [5760/37519 (15%)]\tLoss: 0.176913\n",
      "Train Epoch: 1 [6400/37519 (17%)]\tLoss: 0.243336\n",
      "Train Epoch: 1 [7040/37519 (19%)]\tLoss: 0.188966\n",
      "Train Epoch: 1 [7680/37519 (20%)]\tLoss: 0.188353\n",
      "Train Epoch: 1 [8320/37519 (22%)]\tLoss: 0.060175\n",
      "Train Epoch: 1 [8960/37519 (24%)]\tLoss: 0.151955\n",
      "Train Epoch: 1 [9600/37519 (26%)]\tLoss: 0.166274\n",
      "Train Epoch: 1 [10240/37519 (27%)]\tLoss: 0.430083\n",
      "Train Epoch: 1 [10880/37519 (29%)]\tLoss: 0.265744\n",
      "Train Epoch: 1 [11520/37519 (31%)]\tLoss: 0.099401\n",
      "Train Epoch: 1 [12160/37519 (32%)]\tLoss: 0.188829\n",
      "Train Epoch: 1 [12800/37519 (34%)]\tLoss: 0.116957\n",
      "Train Epoch: 1 [13440/37519 (36%)]\tLoss: 0.130827\n",
      "Train Epoch: 1 [14080/37519 (37%)]\tLoss: 0.137417\n",
      "Train Epoch: 1 [14720/37519 (39%)]\tLoss: 0.170072\n",
      "Train Epoch: 1 [15360/37519 (41%)]\tLoss: 0.275766\n",
      "Train Epoch: 1 [16000/37519 (43%)]\tLoss: 0.110009\n",
      "Train Epoch: 1 [16640/37519 (44%)]\tLoss: 0.180469\n",
      "Train Epoch: 1 [17280/37519 (46%)]\tLoss: 0.122137\n",
      "Train Epoch: 1 [17920/37519 (48%)]\tLoss: 0.225552\n",
      "Train Epoch: 1 [18560/37519 (49%)]\tLoss: 0.225635\n",
      "Train Epoch: 1 [19200/37519 (51%)]\tLoss: 0.130420\n",
      "Train Epoch: 1 [19840/37519 (53%)]\tLoss: 0.482534\n",
      "Train Epoch: 1 [20480/37519 (55%)]\tLoss: 0.306418\n",
      "Train Epoch: 1 [21120/37519 (56%)]\tLoss: 0.167082\n",
      "Train Epoch: 1 [21760/37519 (58%)]\tLoss: 0.336579\n",
      "Train Epoch: 1 [22400/37519 (60%)]\tLoss: 0.355263\n",
      "Train Epoch: 1 [23040/37519 (61%)]\tLoss: 0.227770\n",
      "Train Epoch: 1 [23680/37519 (63%)]\tLoss: 0.310051\n",
      "Train Epoch: 1 [24320/37519 (65%)]\tLoss: 0.297928\n",
      "Train Epoch: 1 [24960/37519 (66%)]\tLoss: 0.102451\n",
      "Train Epoch: 1 [25600/37519 (68%)]\tLoss: 0.139656\n",
      "Train Epoch: 1 [26240/37519 (70%)]\tLoss: 0.318092\n",
      "Train Epoch: 1 [26880/37519 (72%)]\tLoss: 0.289366\n",
      "Train Epoch: 1 [27520/37519 (73%)]\tLoss: 0.118519\n",
      "Train Epoch: 1 [28160/37519 (75%)]\tLoss: 0.225106\n",
      "Train Epoch: 1 [28800/37519 (77%)]\tLoss: 0.169627\n",
      "Train Epoch: 1 [29440/37519 (78%)]\tLoss: 0.137278\n",
      "Train Epoch: 1 [30080/37519 (80%)]\tLoss: 0.132256\n",
      "Train Epoch: 1 [30720/37519 (82%)]\tLoss: 0.250159\n",
      "Train Epoch: 1 [31360/37519 (83%)]\tLoss: 0.144182\n",
      "Train Epoch: 1 [32000/37519 (85%)]\tLoss: 0.225128\n",
      "Train Epoch: 1 [32640/37519 (87%)]\tLoss: 0.257975\n",
      "Train Epoch: 1 [33280/37519 (89%)]\tLoss: 0.125987\n",
      "Train Epoch: 1 [33920/37519 (90%)]\tLoss: 0.100930\n",
      "Train Epoch: 1 [34560/37519 (92%)]\tLoss: 0.275901\n",
      "Train Epoch: 1 [35200/37519 (94%)]\tLoss: 0.123882\n",
      "Train Epoch: 1 [35840/37519 (95%)]\tLoss: 0.154832\n",
      "Train Epoch: 1 [36480/37519 (97%)]\tLoss: 0.171453\n",
      "Train Epoch: 1 [37120/37519 (99%)]\tLoss: 0.305656\n",
      "Train Epoch: 2 [0/37519 (0%)]\tLoss: 0.174189\n",
      "Train Epoch: 2 [640/37519 (2%)]\tLoss: 0.295754\n",
      "Train Epoch: 2 [1280/37519 (3%)]\tLoss: 0.097923\n",
      "Train Epoch: 2 [1920/37519 (5%)]\tLoss: 0.671600\n",
      "Train Epoch: 2 [2560/37519 (7%)]\tLoss: 0.252239\n",
      "Train Epoch: 2 [3200/37519 (9%)]\tLoss: 0.391488\n",
      "Train Epoch: 2 [3840/37519 (10%)]\tLoss: 0.161739\n",
      "Train Epoch: 2 [4480/37519 (12%)]\tLoss: 0.140683\n",
      "Train Epoch: 2 [5120/37519 (14%)]\tLoss: 0.241776\n",
      "Train Epoch: 2 [5760/37519 (15%)]\tLoss: 0.213673\n",
      "Train Epoch: 2 [6400/37519 (17%)]\tLoss: 0.169205\n",
      "Train Epoch: 2 [7040/37519 (19%)]\tLoss: 0.218667\n",
      "Train Epoch: 2 [7680/37519 (20%)]\tLoss: 0.140249\n",
      "Train Epoch: 2 [8320/37519 (22%)]\tLoss: 0.131104\n",
      "Train Epoch: 2 [8960/37519 (24%)]\tLoss: 0.130712\n",
      "Train Epoch: 2 [9600/37519 (26%)]\tLoss: 0.199443\n",
      "Train Epoch: 2 [10240/37519 (27%)]\tLoss: 0.283743\n",
      "Train Epoch: 2 [10880/37519 (29%)]\tLoss: 0.096634\n",
      "Train Epoch: 2 [11520/37519 (31%)]\tLoss: 0.227434\n",
      "Train Epoch: 2 [12160/37519 (32%)]\tLoss: 0.199002\n",
      "Train Epoch: 2 [12800/37519 (34%)]\tLoss: 0.396443\n",
      "Train Epoch: 2 [13440/37519 (36%)]\tLoss: 0.264014\n",
      "Train Epoch: 2 [14080/37519 (37%)]\tLoss: 0.196941\n",
      "Train Epoch: 2 [14720/37519 (39%)]\tLoss: 0.112295\n",
      "Train Epoch: 2 [15360/37519 (41%)]\tLoss: 0.292517\n",
      "Train Epoch: 2 [16000/37519 (43%)]\tLoss: 0.189302\n",
      "Train Epoch: 2 [16640/37519 (44%)]\tLoss: 0.241171\n",
      "Train Epoch: 2 [17280/37519 (46%)]\tLoss: 0.241721\n",
      "Train Epoch: 2 [17920/37519 (48%)]\tLoss: 0.045851\n",
      "Train Epoch: 2 [18560/37519 (49%)]\tLoss: 0.154739\n",
      "Train Epoch: 2 [19200/37519 (51%)]\tLoss: 0.110326\n",
      "Train Epoch: 2 [19840/37519 (53%)]\tLoss: 0.210625\n",
      "Train Epoch: 2 [20480/37519 (55%)]\tLoss: 0.137219\n",
      "Train Epoch: 2 [21120/37519 (56%)]\tLoss: 0.296616\n",
      "Train Epoch: 2 [21760/37519 (58%)]\tLoss: 0.227332\n",
      "Train Epoch: 2 [22400/37519 (60%)]\tLoss: 0.108684\n",
      "Train Epoch: 2 [23040/37519 (61%)]\tLoss: 0.306048\n",
      "Train Epoch: 2 [23680/37519 (63%)]\tLoss: 0.152132\n",
      "Train Epoch: 2 [24320/37519 (65%)]\tLoss: 0.220416\n",
      "Train Epoch: 2 [24960/37519 (66%)]\tLoss: 0.182772\n",
      "Train Epoch: 2 [25600/37519 (68%)]\tLoss: 0.117069\n",
      "Train Epoch: 2 [26240/37519 (70%)]\tLoss: 0.334159\n",
      "Train Epoch: 2 [26880/37519 (72%)]\tLoss: 0.113953\n",
      "Train Epoch: 2 [27520/37519 (73%)]\tLoss: 0.448622\n",
      "Train Epoch: 2 [28160/37519 (75%)]\tLoss: 0.099231\n",
      "Train Epoch: 2 [28800/37519 (77%)]\tLoss: 0.204785\n",
      "Train Epoch: 2 [29440/37519 (78%)]\tLoss: 0.132666\n",
      "Train Epoch: 2 [30080/37519 (80%)]\tLoss: 0.265333\n",
      "Train Epoch: 2 [30720/37519 (82%)]\tLoss: 0.088350\n",
      "Train Epoch: 2 [31360/37519 (83%)]\tLoss: 0.212569\n",
      "Train Epoch: 2 [32000/37519 (85%)]\tLoss: 0.260000\n",
      "Train Epoch: 2 [32640/37519 (87%)]\tLoss: 0.104772\n",
      "Train Epoch: 2 [33280/37519 (89%)]\tLoss: 0.149338\n",
      "Train Epoch: 2 [33920/37519 (90%)]\tLoss: 0.212467\n",
      "Train Epoch: 2 [34560/37519 (92%)]\tLoss: 0.060280\n",
      "Train Epoch: 2 [35200/37519 (94%)]\tLoss: 0.064633\n",
      "Train Epoch: 2 [35840/37519 (95%)]\tLoss: 0.168427\n",
      "Train Epoch: 2 [36480/37519 (97%)]\tLoss: 0.158208\n",
      "Train Epoch: 2 [37120/37519 (99%)]\tLoss: 0.110499\n",
      "Train Epoch: 3 [0/37519 (0%)]\tLoss: 0.243786\n",
      "Train Epoch: 3 [640/37519 (2%)]\tLoss: 0.077936\n",
      "Train Epoch: 3 [1280/37519 (3%)]\tLoss: 0.128376\n",
      "Train Epoch: 3 [1920/37519 (5%)]\tLoss: 0.215712\n",
      "Train Epoch: 3 [2560/37519 (7%)]\tLoss: 0.234780\n",
      "Train Epoch: 3 [3200/37519 (9%)]\tLoss: 0.097890\n",
      "Train Epoch: 3 [3840/37519 (10%)]\tLoss: 0.097046\n",
      "Train Epoch: 3 [4480/37519 (12%)]\tLoss: 0.195626\n",
      "Train Epoch: 3 [5120/37519 (14%)]\tLoss: 0.259289\n",
      "Train Epoch: 3 [5760/37519 (15%)]\tLoss: 0.367562\n",
      "Train Epoch: 3 [6400/37519 (17%)]\tLoss: 0.295959\n",
      "Train Epoch: 3 [7040/37519 (19%)]\tLoss: 0.228833\n",
      "Train Epoch: 3 [7680/37519 (20%)]\tLoss: 0.277096\n",
      "Train Epoch: 3 [8320/37519 (22%)]\tLoss: 0.085851\n",
      "Train Epoch: 3 [8960/37519 (24%)]\tLoss: 0.107643\n",
      "Train Epoch: 3 [9600/37519 (26%)]\tLoss: 0.307286\n",
      "Train Epoch: 3 [10240/37519 (27%)]\tLoss: 0.248174\n",
      "Train Epoch: 3 [10880/37519 (29%)]\tLoss: 0.286397\n",
      "Train Epoch: 3 [11520/37519 (31%)]\tLoss: 0.311235\n",
      "Train Epoch: 3 [12160/37519 (32%)]\tLoss: 0.343459\n",
      "Train Epoch: 3 [12800/37519 (34%)]\tLoss: 0.149832\n",
      "Train Epoch: 3 [13440/37519 (36%)]\tLoss: 0.075725\n",
      "Train Epoch: 3 [14080/37519 (37%)]\tLoss: 0.151932\n",
      "Train Epoch: 3 [14720/37519 (39%)]\tLoss: 0.215274\n",
      "Train Epoch: 3 [15360/37519 (41%)]\tLoss: 0.117495\n",
      "Train Epoch: 3 [16000/37519 (43%)]\tLoss: 0.148144\n",
      "Train Epoch: 3 [16640/37519 (44%)]\tLoss: 0.110740\n",
      "Train Epoch: 3 [17280/37519 (46%)]\tLoss: 0.167889\n",
      "Train Epoch: 3 [17920/37519 (48%)]\tLoss: 0.163124\n",
      "Train Epoch: 3 [18560/37519 (49%)]\tLoss: 0.057495\n",
      "Train Epoch: 3 [19200/37519 (51%)]\tLoss: 0.181514\n",
      "Train Epoch: 3 [19840/37519 (53%)]\tLoss: 0.344958\n",
      "Train Epoch: 3 [20480/37519 (55%)]\tLoss: 0.289677\n",
      "Train Epoch: 3 [21120/37519 (56%)]\tLoss: 0.200764\n",
      "Train Epoch: 3 [21760/37519 (58%)]\tLoss: 0.251607\n",
      "Train Epoch: 3 [22400/37519 (60%)]\tLoss: 0.267218\n",
      "Train Epoch: 3 [23040/37519 (61%)]\tLoss: 0.274074\n",
      "Train Epoch: 3 [23680/37519 (63%)]\tLoss: 0.359875\n",
      "Train Epoch: 3 [24320/37519 (65%)]\tLoss: 0.148965\n",
      "Train Epoch: 3 [24960/37519 (66%)]\tLoss: 0.106498\n",
      "Train Epoch: 3 [25600/37519 (68%)]\tLoss: 0.172135\n",
      "Train Epoch: 3 [26240/37519 (70%)]\tLoss: 0.168022\n",
      "Train Epoch: 3 [26880/37519 (72%)]\tLoss: 0.172796\n",
      "Train Epoch: 3 [27520/37519 (73%)]\tLoss: 0.128743\n",
      "Train Epoch: 3 [28160/37519 (75%)]\tLoss: 0.241858\n",
      "Train Epoch: 3 [28800/37519 (77%)]\tLoss: 0.327760\n",
      "Train Epoch: 3 [29440/37519 (78%)]\tLoss: 0.059552\n",
      "Train Epoch: 3 [30080/37519 (80%)]\tLoss: 0.156914\n",
      "Train Epoch: 3 [30720/37519 (82%)]\tLoss: 0.196966\n",
      "Train Epoch: 3 [31360/37519 (83%)]\tLoss: 0.100697\n",
      "Train Epoch: 3 [32000/37519 (85%)]\tLoss: 0.105692\n",
      "Train Epoch: 3 [32640/37519 (87%)]\tLoss: 0.283329\n",
      "Train Epoch: 3 [33280/37519 (89%)]\tLoss: 0.066214\n",
      "Train Epoch: 3 [33920/37519 (90%)]\tLoss: 0.148443\n",
      "Train Epoch: 3 [34560/37519 (92%)]\tLoss: 0.172642\n",
      "Train Epoch: 3 [35200/37519 (94%)]\tLoss: 0.255514\n",
      "Train Epoch: 3 [35840/37519 (95%)]\tLoss: 0.113284\n",
      "Train Epoch: 3 [36480/37519 (97%)]\tLoss: 0.312485\n",
      "Train Epoch: 3 [37120/37519 (99%)]\tLoss: 0.242494\n",
      "Train Epoch: 4 [0/37519 (0%)]\tLoss: 0.261089\n",
      "Train Epoch: 4 [640/37519 (2%)]\tLoss: 0.146806\n",
      "Train Epoch: 4 [1280/37519 (3%)]\tLoss: 0.112426\n",
      "Train Epoch: 4 [1920/37519 (5%)]\tLoss: 0.050147\n",
      "Train Epoch: 4 [2560/37519 (7%)]\tLoss: 0.136696\n",
      "Train Epoch: 4 [3200/37519 (9%)]\tLoss: 0.048311\n",
      "Train Epoch: 4 [3840/37519 (10%)]\tLoss: 0.401520\n",
      "Train Epoch: 4 [4480/37519 (12%)]\tLoss: 0.105492\n",
      "Train Epoch: 4 [5120/37519 (14%)]\tLoss: 0.276408\n",
      "Train Epoch: 4 [5760/37519 (15%)]\tLoss: 0.151634\n",
      "Train Epoch: 4 [6400/37519 (17%)]\tLoss: 0.251273\n",
      "Train Epoch: 4 [7040/37519 (19%)]\tLoss: 0.151401\n",
      "Train Epoch: 4 [7680/37519 (20%)]\tLoss: 0.255650\n",
      "Train Epoch: 4 [8320/37519 (22%)]\tLoss: 0.177088\n",
      "Train Epoch: 4 [8960/37519 (24%)]\tLoss: 0.200130\n",
      "Train Epoch: 4 [9600/37519 (26%)]\tLoss: 0.241466\n",
      "Train Epoch: 4 [10240/37519 (27%)]\tLoss: 0.135443\n",
      "Train Epoch: 4 [10880/37519 (29%)]\tLoss: 0.132193\n",
      "Train Epoch: 4 [11520/37519 (31%)]\tLoss: 0.195867\n",
      "Train Epoch: 4 [12160/37519 (32%)]\tLoss: 0.447074\n",
      "Train Epoch: 4 [12800/37519 (34%)]\tLoss: 0.110768\n",
      "Train Epoch: 4 [13440/37519 (36%)]\tLoss: 0.170581\n",
      "Train Epoch: 4 [14080/37519 (37%)]\tLoss: 0.110725\n",
      "Train Epoch: 4 [14720/37519 (39%)]\tLoss: 0.375607\n",
      "Train Epoch: 4 [15360/37519 (41%)]\tLoss: 0.131096\n",
      "Train Epoch: 4 [16000/37519 (43%)]\tLoss: 0.104942\n",
      "Train Epoch: 4 [16640/37519 (44%)]\tLoss: 0.156111\n",
      "Train Epoch: 4 [17280/37519 (46%)]\tLoss: 0.199634\n",
      "Train Epoch: 4 [17920/37519 (48%)]\tLoss: 0.079596\n",
      "Train Epoch: 4 [18560/37519 (49%)]\tLoss: 0.243713\n",
      "Train Epoch: 4 [19200/37519 (51%)]\tLoss: 0.505395\n",
      "Train Epoch: 4 [19840/37519 (53%)]\tLoss: 0.384816\n",
      "Train Epoch: 4 [20480/37519 (55%)]\tLoss: 0.353717\n",
      "Train Epoch: 4 [21120/37519 (56%)]\tLoss: 0.095528\n",
      "Train Epoch: 4 [21760/37519 (58%)]\tLoss: 0.220951\n",
      "Train Epoch: 4 [22400/37519 (60%)]\tLoss: 0.193150\n",
      "Train Epoch: 4 [23040/37519 (61%)]\tLoss: 0.162915\n",
      "Train Epoch: 4 [23680/37519 (63%)]\tLoss: 0.110471\n",
      "Train Epoch: 4 [24320/37519 (65%)]\tLoss: 0.148155\n",
      "Train Epoch: 4 [24960/37519 (66%)]\tLoss: 0.248679\n",
      "Train Epoch: 4 [25600/37519 (68%)]\tLoss: 0.282601\n",
      "Train Epoch: 4 [26240/37519 (70%)]\tLoss: 0.136595\n",
      "Train Epoch: 4 [26880/37519 (72%)]\tLoss: 0.167291\n",
      "Train Epoch: 4 [27520/37519 (73%)]\tLoss: 0.060414\n",
      "Train Epoch: 4 [28160/37519 (75%)]\tLoss: 0.311546\n",
      "Train Epoch: 4 [28800/37519 (77%)]\tLoss: 0.075879\n",
      "Train Epoch: 4 [29440/37519 (78%)]\tLoss: 0.077468\n",
      "Train Epoch: 4 [30080/37519 (80%)]\tLoss: 0.108571\n",
      "Train Epoch: 4 [30720/37519 (82%)]\tLoss: 0.229301\n",
      "Train Epoch: 4 [31360/37519 (83%)]\tLoss: 0.300448\n",
      "Train Epoch: 4 [32000/37519 (85%)]\tLoss: 0.112667\n",
      "Train Epoch: 4 [32640/37519 (87%)]\tLoss: 0.154603\n",
      "Train Epoch: 4 [33280/37519 (89%)]\tLoss: 0.182553\n",
      "Train Epoch: 4 [33920/37519 (90%)]\tLoss: 0.132873\n",
      "Train Epoch: 4 [34560/37519 (92%)]\tLoss: 0.083774\n",
      "Train Epoch: 4 [35200/37519 (94%)]\tLoss: 0.168894\n",
      "Train Epoch: 4 [35840/37519 (95%)]\tLoss: 0.101993\n",
      "Train Epoch: 4 [36480/37519 (97%)]\tLoss: 0.321012\n",
      "Train Epoch: 4 [37120/37519 (99%)]\tLoss: 0.069936\n",
      "Train Epoch: 5 [0/37519 (0%)]\tLoss: 0.120878\n",
      "Train Epoch: 5 [640/37519 (2%)]\tLoss: 0.217752\n",
      "Train Epoch: 5 [1280/37519 (3%)]\tLoss: 0.290074\n",
      "Train Epoch: 5 [1920/37519 (5%)]\tLoss: 0.089449\n",
      "Train Epoch: 5 [2560/37519 (7%)]\tLoss: 0.305575\n",
      "Train Epoch: 5 [3200/37519 (9%)]\tLoss: 0.268900\n",
      "Train Epoch: 5 [3840/37519 (10%)]\tLoss: 0.152204\n",
      "Train Epoch: 5 [4480/37519 (12%)]\tLoss: 0.205585\n",
      "Train Epoch: 5 [5120/37519 (14%)]\tLoss: 0.148508\n",
      "Train Epoch: 5 [5760/37519 (15%)]\tLoss: 0.092045\n",
      "Train Epoch: 5 [6400/37519 (17%)]\tLoss: 0.104415\n",
      "Train Epoch: 5 [7040/37519 (19%)]\tLoss: 0.190931\n",
      "Train Epoch: 5 [7680/37519 (20%)]\tLoss: 0.323593\n",
      "Train Epoch: 5 [8320/37519 (22%)]\tLoss: 0.114166\n",
      "Train Epoch: 5 [8960/37519 (24%)]\tLoss: 0.117822\n",
      "Train Epoch: 5 [9600/37519 (26%)]\tLoss: 0.053578\n",
      "Train Epoch: 5 [10240/37519 (27%)]\tLoss: 0.190590\n",
      "Train Epoch: 5 [10880/37519 (29%)]\tLoss: 0.467612\n",
      "Train Epoch: 5 [11520/37519 (31%)]\tLoss: 0.235975\n",
      "Train Epoch: 5 [12160/37519 (32%)]\tLoss: 0.253501\n",
      "Train Epoch: 5 [12800/37519 (34%)]\tLoss: 0.184110\n",
      "Train Epoch: 5 [13440/37519 (36%)]\tLoss: 0.102727\n",
      "Train Epoch: 5 [14080/37519 (37%)]\tLoss: 0.130230\n",
      "Train Epoch: 5 [14720/37519 (39%)]\tLoss: 0.224330\n",
      "Train Epoch: 5 [15360/37519 (41%)]\tLoss: 0.168040\n",
      "Train Epoch: 5 [16000/37519 (43%)]\tLoss: 0.175814\n",
      "Train Epoch: 5 [16640/37519 (44%)]\tLoss: 0.104633\n",
      "Train Epoch: 5 [17280/37519 (46%)]\tLoss: 0.159658\n",
      "Train Epoch: 5 [17920/37519 (48%)]\tLoss: 0.265919\n",
      "Train Epoch: 5 [18560/37519 (49%)]\tLoss: 0.137238\n",
      "Train Epoch: 5 [19200/37519 (51%)]\tLoss: 0.100973\n",
      "Train Epoch: 5 [19840/37519 (53%)]\tLoss: 0.171537\n",
      "Train Epoch: 5 [20480/37519 (55%)]\tLoss: 0.171311\n",
      "Train Epoch: 5 [21120/37519 (56%)]\tLoss: 0.153637\n",
      "Train Epoch: 5 [21760/37519 (58%)]\tLoss: 0.170573\n",
      "Train Epoch: 5 [22400/37519 (60%)]\tLoss: 0.159671\n",
      "Train Epoch: 5 [23040/37519 (61%)]\tLoss: 0.140648\n",
      "Train Epoch: 5 [23680/37519 (63%)]\tLoss: 0.073040\n",
      "Train Epoch: 5 [24320/37519 (65%)]\tLoss: 0.211988\n",
      "Train Epoch: 5 [24960/37519 (66%)]\tLoss: 0.274745\n",
      "Train Epoch: 5 [25600/37519 (68%)]\tLoss: 0.099642\n",
      "Train Epoch: 5 [26240/37519 (70%)]\tLoss: 0.183196\n",
      "Train Epoch: 5 [26880/37519 (72%)]\tLoss: 0.197906\n",
      "Train Epoch: 5 [27520/37519 (73%)]\tLoss: 0.272028\n",
      "Train Epoch: 5 [28160/37519 (75%)]\tLoss: 0.076294\n",
      "Train Epoch: 5 [28800/37519 (77%)]\tLoss: 0.225584\n",
      "Train Epoch: 5 [29440/37519 (78%)]\tLoss: 0.229045\n",
      "Train Epoch: 5 [30080/37519 (80%)]\tLoss: 0.196802\n",
      "Train Epoch: 5 [30720/37519 (82%)]\tLoss: 0.122895\n",
      "Train Epoch: 5 [31360/37519 (83%)]\tLoss: 0.284038\n",
      "Train Epoch: 5 [32000/37519 (85%)]\tLoss: 0.187621\n",
      "Train Epoch: 5 [32640/37519 (87%)]\tLoss: 0.229723\n",
      "Train Epoch: 5 [33280/37519 (89%)]\tLoss: 0.160301\n",
      "Train Epoch: 5 [33920/37519 (90%)]\tLoss: 0.150593\n",
      "Train Epoch: 5 [34560/37519 (92%)]\tLoss: 0.328936\n",
      "Train Epoch: 5 [35200/37519 (94%)]\tLoss: 0.086183\n",
      "Train Epoch: 5 [35840/37519 (95%)]\tLoss: 0.202433\n",
      "Train Epoch: 5 [36480/37519 (97%)]\tLoss: 0.117667\n",
      "Train Epoch: 5 [37120/37519 (99%)]\tLoss: 0.297698\n",
      "Train Epoch: 6 [0/37519 (0%)]\tLoss: 0.129659\n",
      "Train Epoch: 6 [640/37519 (2%)]\tLoss: 0.141549\n",
      "Train Epoch: 6 [1280/37519 (3%)]\tLoss: 0.083226\n",
      "Train Epoch: 6 [1920/37519 (5%)]\tLoss: 0.196761\n",
      "Train Epoch: 6 [2560/37519 (7%)]\tLoss: 0.244915\n",
      "Train Epoch: 6 [3200/37519 (9%)]\tLoss: 0.109417\n",
      "Train Epoch: 6 [3840/37519 (10%)]\tLoss: 0.146864\n",
      "Train Epoch: 6 [4480/37519 (12%)]\tLoss: 0.087723\n",
      "Train Epoch: 6 [5120/37519 (14%)]\tLoss: 0.161656\n",
      "Train Epoch: 6 [5760/37519 (15%)]\tLoss: 0.231881\n",
      "Train Epoch: 6 [6400/37519 (17%)]\tLoss: 0.285694\n",
      "Train Epoch: 6 [7040/37519 (19%)]\tLoss: 0.096473\n",
      "Train Epoch: 6 [7680/37519 (20%)]\tLoss: 0.171767\n",
      "Train Epoch: 6 [8320/37519 (22%)]\tLoss: 0.292162\n",
      "Train Epoch: 6 [8960/37519 (24%)]\tLoss: 0.140561\n",
      "Train Epoch: 6 [9600/37519 (26%)]\tLoss: 0.117224\n",
      "Train Epoch: 6 [10240/37519 (27%)]\tLoss: 0.072867\n",
      "Train Epoch: 6 [10880/37519 (29%)]\tLoss: 0.305195\n",
      "Train Epoch: 6 [11520/37519 (31%)]\tLoss: 0.262779\n",
      "Train Epoch: 6 [12160/37519 (32%)]\tLoss: 0.064931\n",
      "Train Epoch: 6 [12800/37519 (34%)]\tLoss: 0.155851\n",
      "Train Epoch: 6 [13440/37519 (36%)]\tLoss: 0.305740\n",
      "Train Epoch: 6 [14080/37519 (37%)]\tLoss: 0.260488\n",
      "Train Epoch: 6 [14720/37519 (39%)]\tLoss: 0.347865\n",
      "Train Epoch: 6 [15360/37519 (41%)]\tLoss: 0.163627\n",
      "Train Epoch: 6 [16000/37519 (43%)]\tLoss: 0.213250\n",
      "Train Epoch: 6 [16640/37519 (44%)]\tLoss: 0.112951\n",
      "Train Epoch: 6 [17280/37519 (46%)]\tLoss: 0.123825\n",
      "Train Epoch: 6 [17920/37519 (48%)]\tLoss: 0.063184\n",
      "Train Epoch: 6 [18560/37519 (49%)]\tLoss: 0.274981\n",
      "Train Epoch: 6 [19200/37519 (51%)]\tLoss: 0.138034\n",
      "Train Epoch: 6 [19840/37519 (53%)]\tLoss: 0.195351\n",
      "Train Epoch: 6 [20480/37519 (55%)]\tLoss: 0.163654\n",
      "Train Epoch: 6 [21120/37519 (56%)]\tLoss: 0.097274\n",
      "Train Epoch: 6 [21760/37519 (58%)]\tLoss: 0.216160\n",
      "Train Epoch: 6 [22400/37519 (60%)]\tLoss: 0.127406\n",
      "Train Epoch: 6 [23040/37519 (61%)]\tLoss: 0.130610\n",
      "Train Epoch: 6 [23680/37519 (63%)]\tLoss: 0.110853\n",
      "Train Epoch: 6 [24320/37519 (65%)]\tLoss: 0.135361\n",
      "Train Epoch: 6 [24960/37519 (66%)]\tLoss: 0.195540\n",
      "Train Epoch: 6 [25600/37519 (68%)]\tLoss: 0.198097\n",
      "Train Epoch: 6 [26240/37519 (70%)]\tLoss: 0.141948\n",
      "Train Epoch: 6 [26880/37519 (72%)]\tLoss: 0.315627\n",
      "Train Epoch: 6 [27520/37519 (73%)]\tLoss: 0.138349\n",
      "Train Epoch: 6 [28160/37519 (75%)]\tLoss: 0.084731\n",
      "Train Epoch: 6 [28800/37519 (77%)]\tLoss: 0.150020\n",
      "Train Epoch: 6 [29440/37519 (78%)]\tLoss: 0.099330\n",
      "Train Epoch: 6 [30080/37519 (80%)]\tLoss: 0.144902\n",
      "Train Epoch: 6 [30720/37519 (82%)]\tLoss: 0.030549\n",
      "Train Epoch: 6 [31360/37519 (83%)]\tLoss: 0.168882\n",
      "Train Epoch: 6 [32000/37519 (85%)]\tLoss: 0.200506\n",
      "Train Epoch: 6 [32640/37519 (87%)]\tLoss: 0.131584\n",
      "Train Epoch: 6 [33280/37519 (89%)]\tLoss: 0.076254\n",
      "Train Epoch: 6 [33920/37519 (90%)]\tLoss: 0.184062\n",
      "Train Epoch: 6 [34560/37519 (92%)]\tLoss: 0.168946\n",
      "Train Epoch: 6 [35200/37519 (94%)]\tLoss: 0.161839\n",
      "Train Epoch: 6 [35840/37519 (95%)]\tLoss: 0.226390\n",
      "Train Epoch: 6 [36480/37519 (97%)]\tLoss: 0.171507\n",
      "Train Epoch: 6 [37120/37519 (99%)]\tLoss: 0.115250\n",
      "Train Epoch: 7 [0/37519 (0%)]\tLoss: 0.171431\n",
      "Train Epoch: 7 [640/37519 (2%)]\tLoss: 0.155370\n",
      "Train Epoch: 7 [1280/37519 (3%)]\tLoss: 0.047339\n",
      "Train Epoch: 7 [1920/37519 (5%)]\tLoss: 0.218031\n",
      "Train Epoch: 7 [2560/37519 (7%)]\tLoss: 0.122593\n",
      "Train Epoch: 7 [3200/37519 (9%)]\tLoss: 0.123766\n",
      "Train Epoch: 7 [3840/37519 (10%)]\tLoss: 0.064124\n",
      "Train Epoch: 7 [4480/37519 (12%)]\tLoss: 0.160733\n",
      "Train Epoch: 7 [5120/37519 (14%)]\tLoss: 0.086665\n",
      "Train Epoch: 7 [5760/37519 (15%)]\tLoss: 0.104627\n",
      "Train Epoch: 7 [6400/37519 (17%)]\tLoss: 0.177044\n",
      "Train Epoch: 7 [7040/37519 (19%)]\tLoss: 0.143168\n",
      "Train Epoch: 7 [7680/37519 (20%)]\tLoss: 0.057456\n",
      "Train Epoch: 7 [8320/37519 (22%)]\tLoss: 0.210241\n",
      "Train Epoch: 7 [8960/37519 (24%)]\tLoss: 0.160728\n",
      "Train Epoch: 7 [9600/37519 (26%)]\tLoss: 0.321875\n",
      "Train Epoch: 7 [10240/37519 (27%)]\tLoss: 0.223853\n",
      "Train Epoch: 7 [10880/37519 (29%)]\tLoss: 0.220950\n",
      "Train Epoch: 7 [11520/37519 (31%)]\tLoss: 0.197869\n",
      "Train Epoch: 7 [12160/37519 (32%)]\tLoss: 0.061359\n",
      "Train Epoch: 7 [12800/37519 (34%)]\tLoss: 0.155035\n",
      "Train Epoch: 7 [13440/37519 (36%)]\tLoss: 0.091287\n",
      "Train Epoch: 7 [14080/37519 (37%)]\tLoss: 0.069423\n",
      "Train Epoch: 7 [14720/37519 (39%)]\tLoss: 0.209651\n",
      "Train Epoch: 7 [15360/37519 (41%)]\tLoss: 0.136863\n",
      "Train Epoch: 7 [16000/37519 (43%)]\tLoss: 0.278182\n",
      "Train Epoch: 7 [16640/37519 (44%)]\tLoss: 0.053309\n",
      "Train Epoch: 7 [17280/37519 (46%)]\tLoss: 0.071753\n",
      "Train Epoch: 7 [17920/37519 (48%)]\tLoss: 0.273690\n",
      "Train Epoch: 7 [18560/37519 (49%)]\tLoss: 0.098656\n",
      "Train Epoch: 7 [19200/37519 (51%)]\tLoss: 0.090437\n",
      "Train Epoch: 7 [19840/37519 (53%)]\tLoss: 0.100411\n",
      "Train Epoch: 7 [20480/37519 (55%)]\tLoss: 0.314878\n",
      "Train Epoch: 7 [21120/37519 (56%)]\tLoss: 0.101404\n",
      "Train Epoch: 7 [21760/37519 (58%)]\tLoss: 0.152238\n",
      "Train Epoch: 7 [22400/37519 (60%)]\tLoss: 0.174248\n",
      "Train Epoch: 7 [23040/37519 (61%)]\tLoss: 0.090332\n",
      "Train Epoch: 7 [23680/37519 (63%)]\tLoss: 0.149093\n",
      "Train Epoch: 7 [24320/37519 (65%)]\tLoss: 0.140809\n",
      "Train Epoch: 7 [24960/37519 (66%)]\tLoss: 0.102045\n",
      "Train Epoch: 7 [25600/37519 (68%)]\tLoss: 0.168962\n",
      "Train Epoch: 7 [26240/37519 (70%)]\tLoss: 0.269127\n",
      "Train Epoch: 7 [26880/37519 (72%)]\tLoss: 0.137340\n",
      "Train Epoch: 7 [27520/37519 (73%)]\tLoss: 0.232695\n",
      "Train Epoch: 7 [28160/37519 (75%)]\tLoss: 0.105109\n",
      "Train Epoch: 7 [28800/37519 (77%)]\tLoss: 0.084038\n",
      "Train Epoch: 7 [29440/37519 (78%)]\tLoss: 0.164677\n",
      "Train Epoch: 7 [30080/37519 (80%)]\tLoss: 0.181694\n",
      "Train Epoch: 7 [30720/37519 (82%)]\tLoss: 0.144722\n",
      "Train Epoch: 7 [31360/37519 (83%)]\tLoss: 0.243236\n",
      "Train Epoch: 7 [32000/37519 (85%)]\tLoss: 0.198848\n",
      "Train Epoch: 7 [32640/37519 (87%)]\tLoss: 0.095224\n",
      "Train Epoch: 7 [33280/37519 (89%)]\tLoss: 0.138556\n",
      "Train Epoch: 7 [33920/37519 (90%)]\tLoss: 0.398220\n",
      "Train Epoch: 7 [34560/37519 (92%)]\tLoss: 0.212481\n",
      "Train Epoch: 7 [35200/37519 (94%)]\tLoss: 0.159174\n",
      "Train Epoch: 7 [35840/37519 (95%)]\tLoss: 0.209930\n",
      "Train Epoch: 7 [36480/37519 (97%)]\tLoss: 0.189471\n",
      "Train Epoch: 7 [37120/37519 (99%)]\tLoss: 0.194913\n",
      "Train Epoch: 8 [0/37519 (0%)]\tLoss: 0.111963\n",
      "Train Epoch: 8 [640/37519 (2%)]\tLoss: 0.164150\n",
      "Train Epoch: 8 [1280/37519 (3%)]\tLoss: 0.119377\n",
      "Train Epoch: 8 [1920/37519 (5%)]\tLoss: 0.106129\n",
      "Train Epoch: 8 [2560/37519 (7%)]\tLoss: 0.048925\n",
      "Train Epoch: 8 [3200/37519 (9%)]\tLoss: 0.146234\n",
      "Train Epoch: 8 [3840/37519 (10%)]\tLoss: 0.301697\n",
      "Train Epoch: 8 [4480/37519 (12%)]\tLoss: 0.100065\n",
      "Train Epoch: 8 [5120/37519 (14%)]\tLoss: 0.187646\n",
      "Train Epoch: 8 [5760/37519 (15%)]\tLoss: 0.222393\n",
      "Train Epoch: 8 [6400/37519 (17%)]\tLoss: 0.182554\n",
      "Train Epoch: 8 [7040/37519 (19%)]\tLoss: 0.132470\n",
      "Train Epoch: 8 [7680/37519 (20%)]\tLoss: 0.191170\n",
      "Train Epoch: 8 [8320/37519 (22%)]\tLoss: 0.161900\n",
      "Train Epoch: 8 [8960/37519 (24%)]\tLoss: 0.121643\n",
      "Train Epoch: 8 [9600/37519 (26%)]\tLoss: 0.072997\n",
      "Train Epoch: 8 [10240/37519 (27%)]\tLoss: 0.082754\n",
      "Train Epoch: 8 [10880/37519 (29%)]\tLoss: 0.156148\n",
      "Train Epoch: 8 [11520/37519 (31%)]\tLoss: 0.247755\n",
      "Train Epoch: 8 [12160/37519 (32%)]\tLoss: 0.201193\n",
      "Train Epoch: 8 [12800/37519 (34%)]\tLoss: 0.179294\n",
      "Train Epoch: 8 [13440/37519 (36%)]\tLoss: 0.051207\n",
      "Train Epoch: 8 [14080/37519 (37%)]\tLoss: 0.108226\n",
      "Train Epoch: 8 [14720/37519 (39%)]\tLoss: 0.091864\n",
      "Train Epoch: 8 [15360/37519 (41%)]\tLoss: 0.168615\n",
      "Train Epoch: 8 [16000/37519 (43%)]\tLoss: 0.286839\n",
      "Train Epoch: 8 [16640/37519 (44%)]\tLoss: 0.144321\n",
      "Train Epoch: 8 [17280/37519 (46%)]\tLoss: 0.104501\n",
      "Train Epoch: 8 [17920/37519 (48%)]\tLoss: 0.232736\n",
      "Train Epoch: 8 [18560/37519 (49%)]\tLoss: 0.236133\n",
      "Train Epoch: 8 [19200/37519 (51%)]\tLoss: 0.159193\n",
      "Train Epoch: 8 [19840/37519 (53%)]\tLoss: 0.138290\n",
      "Train Epoch: 8 [20480/37519 (55%)]\tLoss: 0.200314\n",
      "Train Epoch: 8 [21120/37519 (56%)]\tLoss: 0.146067\n",
      "Train Epoch: 8 [21760/37519 (58%)]\tLoss: 0.352762\n",
      "Train Epoch: 8 [22400/37519 (60%)]\tLoss: 0.109750\n",
      "Train Epoch: 8 [23040/37519 (61%)]\tLoss: 0.183798\n",
      "Train Epoch: 8 [23680/37519 (63%)]\tLoss: 0.098161\n",
      "Train Epoch: 8 [24320/37519 (65%)]\tLoss: 0.222782\n",
      "Train Epoch: 8 [24960/37519 (66%)]\tLoss: 0.077802\n",
      "Train Epoch: 8 [25600/37519 (68%)]\tLoss: 0.123008\n",
      "Train Epoch: 8 [26240/37519 (70%)]\tLoss: 0.228359\n",
      "Train Epoch: 8 [26880/37519 (72%)]\tLoss: 0.061120\n",
      "Train Epoch: 8 [27520/37519 (73%)]\tLoss: 0.187705\n",
      "Train Epoch: 8 [28160/37519 (75%)]\tLoss: 0.359883\n",
      "Train Epoch: 8 [28800/37519 (77%)]\tLoss: 0.089059\n",
      "Train Epoch: 8 [29440/37519 (78%)]\tLoss: 0.158891\n",
      "Train Epoch: 8 [30080/37519 (80%)]\tLoss: 0.211025\n",
      "Train Epoch: 8 [30720/37519 (82%)]\tLoss: 0.233919\n",
      "Train Epoch: 8 [31360/37519 (83%)]\tLoss: 0.165965\n",
      "Train Epoch: 8 [32000/37519 (85%)]\tLoss: 0.057416\n",
      "Train Epoch: 8 [32640/37519 (87%)]\tLoss: 0.324025\n",
      "Train Epoch: 8 [33280/37519 (89%)]\tLoss: 0.117020\n",
      "Train Epoch: 8 [33920/37519 (90%)]\tLoss: 0.377453\n",
      "Train Epoch: 8 [34560/37519 (92%)]\tLoss: 0.286769\n",
      "Train Epoch: 8 [35200/37519 (94%)]\tLoss: 0.105510\n",
      "Train Epoch: 8 [35840/37519 (95%)]\tLoss: 0.130766\n",
      "Train Epoch: 8 [36480/37519 (97%)]\tLoss: 0.197074\n",
      "Train Epoch: 8 [37120/37519 (99%)]\tLoss: 0.121921\n",
      "Train Epoch: 9 [0/37519 (0%)]\tLoss: 0.366287\n",
      "Train Epoch: 9 [640/37519 (2%)]\tLoss: 0.093117\n",
      "Train Epoch: 9 [1280/37519 (3%)]\tLoss: 0.101575\n",
      "Train Epoch: 9 [1920/37519 (5%)]\tLoss: 0.326040\n",
      "Train Epoch: 9 [2560/37519 (7%)]\tLoss: 0.251844\n",
      "Train Epoch: 9 [3200/37519 (9%)]\tLoss: 0.210627\n",
      "Train Epoch: 9 [3840/37519 (10%)]\tLoss: 0.040464\n",
      "Train Epoch: 9 [4480/37519 (12%)]\tLoss: 0.158291\n",
      "Train Epoch: 9 [5120/37519 (14%)]\tLoss: 0.110167\n",
      "Train Epoch: 9 [5760/37519 (15%)]\tLoss: 0.138597\n",
      "Train Epoch: 9 [6400/37519 (17%)]\tLoss: 0.227199\n",
      "Train Epoch: 9 [7040/37519 (19%)]\tLoss: 0.223360\n",
      "Train Epoch: 9 [7680/37519 (20%)]\tLoss: 0.191809\n",
      "Train Epoch: 9 [8320/37519 (22%)]\tLoss: 0.109889\n",
      "Train Epoch: 9 [8960/37519 (24%)]\tLoss: 0.153468\n",
      "Train Epoch: 9 [9600/37519 (26%)]\tLoss: 0.051608\n",
      "Train Epoch: 9 [10240/37519 (27%)]\tLoss: 0.047936\n",
      "Train Epoch: 9 [10880/37519 (29%)]\tLoss: 0.167746\n",
      "Train Epoch: 9 [11520/37519 (31%)]\tLoss: 0.171998\n",
      "Train Epoch: 9 [12160/37519 (32%)]\tLoss: 0.140853\n",
      "Train Epoch: 9 [12800/37519 (34%)]\tLoss: 0.076365\n",
      "Train Epoch: 9 [13440/37519 (36%)]\tLoss: 0.112660\n",
      "Train Epoch: 9 [14080/37519 (37%)]\tLoss: 0.088294\n",
      "Train Epoch: 9 [14720/37519 (39%)]\tLoss: 0.097345\n",
      "Train Epoch: 9 [15360/37519 (41%)]\tLoss: 0.139754\n",
      "Train Epoch: 9 [16000/37519 (43%)]\tLoss: 0.085730\n",
      "Train Epoch: 9 [16640/37519 (44%)]\tLoss: 0.123148\n",
      "Train Epoch: 9 [17280/37519 (46%)]\tLoss: 0.130650\n",
      "Train Epoch: 9 [17920/37519 (48%)]\tLoss: 0.182487\n",
      "Train Epoch: 9 [18560/37519 (49%)]\tLoss: 0.069562\n",
      "Train Epoch: 9 [19200/37519 (51%)]\tLoss: 0.045378\n",
      "Train Epoch: 9 [19840/37519 (53%)]\tLoss: 0.243701\n",
      "Train Epoch: 9 [20480/37519 (55%)]\tLoss: 0.136822\n",
      "Train Epoch: 9 [21120/37519 (56%)]\tLoss: 0.113829\n",
      "Train Epoch: 9 [21760/37519 (58%)]\tLoss: 0.074044\n",
      "Train Epoch: 9 [22400/37519 (60%)]\tLoss: 0.059373\n",
      "Train Epoch: 9 [23040/37519 (61%)]\tLoss: 0.222726\n",
      "Train Epoch: 9 [23680/37519 (63%)]\tLoss: 0.071757\n",
      "Train Epoch: 9 [24320/37519 (65%)]\tLoss: 0.316929\n",
      "Train Epoch: 9 [24960/37519 (66%)]\tLoss: 0.219130\n",
      "Train Epoch: 9 [25600/37519 (68%)]\tLoss: 0.070556\n",
      "Train Epoch: 9 [26240/37519 (70%)]\tLoss: 0.135024\n",
      "Train Epoch: 9 [26880/37519 (72%)]\tLoss: 0.122142\n",
      "Train Epoch: 9 [27520/37519 (73%)]\tLoss: 0.111346\n",
      "Train Epoch: 9 [28160/37519 (75%)]\tLoss: 0.190162\n",
      "Train Epoch: 9 [28800/37519 (77%)]\tLoss: 0.251235\n",
      "Train Epoch: 9 [29440/37519 (78%)]\tLoss: 0.441582\n",
      "Train Epoch: 9 [30080/37519 (80%)]\tLoss: 0.200892\n",
      "Train Epoch: 9 [30720/37519 (82%)]\tLoss: 0.183433\n",
      "Train Epoch: 9 [31360/37519 (83%)]\tLoss: 0.073141\n",
      "Train Epoch: 9 [32000/37519 (85%)]\tLoss: 0.248953\n",
      "Train Epoch: 9 [32640/37519 (87%)]\tLoss: 0.328863\n",
      "Train Epoch: 9 [33280/37519 (89%)]\tLoss: 0.358281\n",
      "Train Epoch: 9 [33920/37519 (90%)]\tLoss: 0.142438\n",
      "Train Epoch: 9 [34560/37519 (92%)]\tLoss: 0.097938\n",
      "Train Epoch: 9 [35200/37519 (94%)]\tLoss: 0.085186\n",
      "Train Epoch: 9 [35840/37519 (95%)]\tLoss: 0.106745\n",
      "Train Epoch: 9 [36480/37519 (97%)]\tLoss: 0.166301\n",
      "Train Epoch: 9 [37120/37519 (99%)]\tLoss: 0.087301\n",
      "Train Epoch: 10 [0/37519 (0%)]\tLoss: 0.194384\n",
      "Train Epoch: 10 [640/37519 (2%)]\tLoss: 0.220595\n",
      "Train Epoch: 10 [1280/37519 (3%)]\tLoss: 0.160026\n",
      "Train Epoch: 10 [1920/37519 (5%)]\tLoss: 0.074001\n",
      "Train Epoch: 10 [2560/37519 (7%)]\tLoss: 0.136244\n",
      "Train Epoch: 10 [3200/37519 (9%)]\tLoss: 0.352988\n",
      "Train Epoch: 10 [3840/37519 (10%)]\tLoss: 0.115714\n",
      "Train Epoch: 10 [4480/37519 (12%)]\tLoss: 0.172854\n",
      "Train Epoch: 10 [5120/37519 (14%)]\tLoss: 0.167911\n",
      "Train Epoch: 10 [5760/37519 (15%)]\tLoss: 0.315380\n",
      "Train Epoch: 10 [6400/37519 (17%)]\tLoss: 0.047003\n",
      "Train Epoch: 10 [7040/37519 (19%)]\tLoss: 0.339916\n",
      "Train Epoch: 10 [7680/37519 (20%)]\tLoss: 0.149448\n",
      "Train Epoch: 10 [8320/37519 (22%)]\tLoss: 0.239073\n",
      "Train Epoch: 10 [8960/37519 (24%)]\tLoss: 0.216251\n",
      "Train Epoch: 10 [9600/37519 (26%)]\tLoss: 0.184772\n",
      "Train Epoch: 10 [10240/37519 (27%)]\tLoss: 0.104004\n",
      "Train Epoch: 10 [10880/37519 (29%)]\tLoss: 0.136103\n",
      "Train Epoch: 10 [11520/37519 (31%)]\tLoss: 0.105263\n",
      "Train Epoch: 10 [12160/37519 (32%)]\tLoss: 0.090449\n",
      "Train Epoch: 10 [12800/37519 (34%)]\tLoss: 0.197713\n",
      "Train Epoch: 10 [13440/37519 (36%)]\tLoss: 0.091037\n",
      "Train Epoch: 10 [14080/37519 (37%)]\tLoss: 0.128539\n",
      "Train Epoch: 10 [14720/37519 (39%)]\tLoss: 0.151271\n",
      "Train Epoch: 10 [15360/37519 (41%)]\tLoss: 0.131099\n",
      "Train Epoch: 10 [16000/37519 (43%)]\tLoss: 0.141973\n",
      "Train Epoch: 10 [16640/37519 (44%)]\tLoss: 0.132073\n",
      "Train Epoch: 10 [17280/37519 (46%)]\tLoss: 0.114989\n",
      "Train Epoch: 10 [17920/37519 (48%)]\tLoss: 0.262804\n",
      "Train Epoch: 10 [18560/37519 (49%)]\tLoss: 0.088468\n",
      "Train Epoch: 10 [19200/37519 (51%)]\tLoss: 0.185841\n",
      "Train Epoch: 10 [19840/37519 (53%)]\tLoss: 0.123994\n",
      "Train Epoch: 10 [20480/37519 (55%)]\tLoss: 0.087676\n",
      "Train Epoch: 10 [21120/37519 (56%)]\tLoss: 0.126278\n",
      "Train Epoch: 10 [21760/37519 (58%)]\tLoss: 0.101867\n",
      "Train Epoch: 10 [22400/37519 (60%)]\tLoss: 0.250878\n",
      "Train Epoch: 10 [23040/37519 (61%)]\tLoss: 0.100351\n",
      "Train Epoch: 10 [23680/37519 (63%)]\tLoss: 0.288670\n",
      "Train Epoch: 10 [24320/37519 (65%)]\tLoss: 0.181132\n",
      "Train Epoch: 10 [24960/37519 (66%)]\tLoss: 0.285259\n",
      "Train Epoch: 10 [25600/37519 (68%)]\tLoss: 0.078679\n",
      "Train Epoch: 10 [26240/37519 (70%)]\tLoss: 0.157029\n",
      "Train Epoch: 10 [26880/37519 (72%)]\tLoss: 0.294216\n",
      "Train Epoch: 10 [27520/37519 (73%)]\tLoss: 0.193797\n",
      "Train Epoch: 10 [28160/37519 (75%)]\tLoss: 0.170305\n",
      "Train Epoch: 10 [28800/37519 (77%)]\tLoss: 0.168575\n",
      "Train Epoch: 10 [29440/37519 (78%)]\tLoss: 0.145700\n",
      "Train Epoch: 10 [30080/37519 (80%)]\tLoss: 0.163269\n",
      "Train Epoch: 10 [30720/37519 (82%)]\tLoss: 0.239308\n",
      "Train Epoch: 10 [31360/37519 (83%)]\tLoss: 0.069586\n",
      "Train Epoch: 10 [32000/37519 (85%)]\tLoss: 0.204777\n",
      "Train Epoch: 10 [32640/37519 (87%)]\tLoss: 0.060237\n",
      "Train Epoch: 10 [33280/37519 (89%)]\tLoss: 0.094603\n",
      "Train Epoch: 10 [33920/37519 (90%)]\tLoss: 0.125975\n",
      "Train Epoch: 10 [34560/37519 (92%)]\tLoss: 0.145766\n",
      "Train Epoch: 10 [35200/37519 (94%)]\tLoss: 0.177638\n",
      "Train Epoch: 10 [35840/37519 (95%)]\tLoss: 0.107244\n",
      "Train Epoch: 10 [36480/37519 (97%)]\tLoss: 0.123932\n",
      "Train Epoch: 10 [37120/37519 (99%)]\tLoss: 0.182785\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/22481 (0%)]\tLoss: 0.245768\n",
      "Train Epoch: 1 [640/22481 (3%)]\tLoss: 0.152767\n",
      "Train Epoch: 1 [1280/22481 (6%)]\tLoss: 0.243138\n",
      "Train Epoch: 1 [1920/22481 (9%)]\tLoss: 0.570799\n",
      "Train Epoch: 1 [2560/22481 (11%)]\tLoss: 0.134172\n",
      "Train Epoch: 1 [3200/22481 (14%)]\tLoss: 0.115685\n",
      "Train Epoch: 1 [3840/22481 (17%)]\tLoss: 0.262861\n",
      "Train Epoch: 1 [4480/22481 (20%)]\tLoss: 0.101683\n",
      "Train Epoch: 1 [5120/22481 (23%)]\tLoss: 0.171371\n",
      "Train Epoch: 1 [5760/22481 (26%)]\tLoss: 0.096838\n",
      "Train Epoch: 1 [6400/22481 (28%)]\tLoss: 0.121185\n",
      "Train Epoch: 1 [7040/22481 (31%)]\tLoss: 0.154029\n",
      "Train Epoch: 1 [7680/22481 (34%)]\tLoss: 0.132846\n",
      "Train Epoch: 1 [8320/22481 (37%)]\tLoss: 0.115949\n",
      "Train Epoch: 1 [8960/22481 (40%)]\tLoss: 0.098814\n",
      "Train Epoch: 1 [9600/22481 (43%)]\tLoss: 0.319742\n",
      "Train Epoch: 1 [10240/22481 (45%)]\tLoss: 0.233080\n",
      "Train Epoch: 1 [10880/22481 (48%)]\tLoss: 0.427203\n",
      "Train Epoch: 1 [11520/22481 (51%)]\tLoss: 0.261363\n",
      "Train Epoch: 1 [12160/22481 (54%)]\tLoss: 0.196333\n",
      "Train Epoch: 1 [12800/22481 (57%)]\tLoss: 0.127409\n",
      "Train Epoch: 1 [13440/22481 (60%)]\tLoss: 0.080176\n",
      "Train Epoch: 1 [14080/22481 (62%)]\tLoss: 0.178744\n",
      "Train Epoch: 1 [14720/22481 (65%)]\tLoss: 0.146670\n",
      "Train Epoch: 1 [15360/22481 (68%)]\tLoss: 0.155992\n",
      "Train Epoch: 1 [16000/22481 (71%)]\tLoss: 0.266538\n",
      "Train Epoch: 1 [16640/22481 (74%)]\tLoss: 0.190630\n",
      "Train Epoch: 1 [17280/22481 (77%)]\tLoss: 0.180828\n",
      "Train Epoch: 1 [17920/22481 (80%)]\tLoss: 0.304625\n",
      "Train Epoch: 1 [18560/22481 (82%)]\tLoss: 0.272226\n",
      "Train Epoch: 1 [19200/22481 (85%)]\tLoss: 0.135318\n",
      "Train Epoch: 1 [19840/22481 (88%)]\tLoss: 0.190752\n",
      "Train Epoch: 1 [20480/22481 (91%)]\tLoss: 0.237079\n",
      "Train Epoch: 1 [21120/22481 (94%)]\tLoss: 0.089392\n",
      "Train Epoch: 1 [21760/22481 (97%)]\tLoss: 0.245935\n",
      "Train Epoch: 1 [22400/22481 (99%)]\tLoss: 0.128184\n",
      "Train Epoch: 2 [0/22481 (0%)]\tLoss: 0.222143\n",
      "Train Epoch: 2 [640/22481 (3%)]\tLoss: 0.062481\n",
      "Train Epoch: 2 [1280/22481 (6%)]\tLoss: 0.246927\n",
      "Train Epoch: 2 [1920/22481 (9%)]\tLoss: 0.190242\n",
      "Train Epoch: 2 [2560/22481 (11%)]\tLoss: 0.265963\n",
      "Train Epoch: 2 [3200/22481 (14%)]\tLoss: 0.073247\n",
      "Train Epoch: 2 [3840/22481 (17%)]\tLoss: 0.274744\n",
      "Train Epoch: 2 [4480/22481 (20%)]\tLoss: 0.086961\n",
      "Train Epoch: 2 [5120/22481 (23%)]\tLoss: 0.167912\n",
      "Train Epoch: 2 [5760/22481 (26%)]\tLoss: 0.182663\n",
      "Train Epoch: 2 [6400/22481 (28%)]\tLoss: 0.094638\n",
      "Train Epoch: 2 [7040/22481 (31%)]\tLoss: 0.176732\n",
      "Train Epoch: 2 [7680/22481 (34%)]\tLoss: 0.343008\n",
      "Train Epoch: 2 [8320/22481 (37%)]\tLoss: 0.142352\n",
      "Train Epoch: 2 [8960/22481 (40%)]\tLoss: 0.167475\n",
      "Train Epoch: 2 [9600/22481 (43%)]\tLoss: 0.210208\n",
      "Train Epoch: 2 [10240/22481 (45%)]\tLoss: 0.090846\n",
      "Train Epoch: 2 [10880/22481 (48%)]\tLoss: 0.198292\n",
      "Train Epoch: 2 [11520/22481 (51%)]\tLoss: 0.114567\n",
      "Train Epoch: 2 [12160/22481 (54%)]\tLoss: 0.127892\n",
      "Train Epoch: 2 [12800/22481 (57%)]\tLoss: 0.104794\n",
      "Train Epoch: 2 [13440/22481 (60%)]\tLoss: 0.146650\n",
      "Train Epoch: 2 [14080/22481 (62%)]\tLoss: 0.214495\n",
      "Train Epoch: 2 [14720/22481 (65%)]\tLoss: 0.184998\n",
      "Train Epoch: 2 [15360/22481 (68%)]\tLoss: 0.150645\n",
      "Train Epoch: 2 [16000/22481 (71%)]\tLoss: 0.310533\n",
      "Train Epoch: 2 [16640/22481 (74%)]\tLoss: 0.122496\n",
      "Train Epoch: 2 [17280/22481 (77%)]\tLoss: 0.103843\n",
      "Train Epoch: 2 [17920/22481 (80%)]\tLoss: 0.239086\n",
      "Train Epoch: 2 [18560/22481 (82%)]\tLoss: 0.079542\n",
      "Train Epoch: 2 [19200/22481 (85%)]\tLoss: 0.164926\n",
      "Train Epoch: 2 [19840/22481 (88%)]\tLoss: 0.211689\n",
      "Train Epoch: 2 [20480/22481 (91%)]\tLoss: 0.154467\n",
      "Train Epoch: 2 [21120/22481 (94%)]\tLoss: 0.089974\n",
      "Train Epoch: 2 [21760/22481 (97%)]\tLoss: 0.053091\n",
      "Train Epoch: 2 [22400/22481 (99%)]\tLoss: 0.129452\n",
      "Train Epoch: 3 [0/22481 (0%)]\tLoss: 0.127213\n",
      "Train Epoch: 3 [640/22481 (3%)]\tLoss: 0.092109\n",
      "Train Epoch: 3 [1280/22481 (6%)]\tLoss: 0.254159\n",
      "Train Epoch: 3 [1920/22481 (9%)]\tLoss: 0.110588\n",
      "Train Epoch: 3 [2560/22481 (11%)]\tLoss: 0.210472\n",
      "Train Epoch: 3 [3200/22481 (14%)]\tLoss: 0.185098\n",
      "Train Epoch: 3 [3840/22481 (17%)]\tLoss: 0.069813\n",
      "Train Epoch: 3 [4480/22481 (20%)]\tLoss: 0.117247\n",
      "Train Epoch: 3 [5120/22481 (23%)]\tLoss: 0.115388\n",
      "Train Epoch: 3 [5760/22481 (26%)]\tLoss: 0.087492\n",
      "Train Epoch: 3 [6400/22481 (28%)]\tLoss: 0.214674\n",
      "Train Epoch: 3 [7040/22481 (31%)]\tLoss: 0.205256\n",
      "Train Epoch: 3 [7680/22481 (34%)]\tLoss: 0.430179\n",
      "Train Epoch: 3 [8320/22481 (37%)]\tLoss: 0.236437\n",
      "Train Epoch: 3 [8960/22481 (40%)]\tLoss: 0.104688\n",
      "Train Epoch: 3 [9600/22481 (43%)]\tLoss: 0.237773\n",
      "Train Epoch: 3 [10240/22481 (45%)]\tLoss: 0.106902\n",
      "Train Epoch: 3 [10880/22481 (48%)]\tLoss: 0.199162\n",
      "Train Epoch: 3 [11520/22481 (51%)]\tLoss: 0.118613\n",
      "Train Epoch: 3 [12160/22481 (54%)]\tLoss: 0.172157\n",
      "Train Epoch: 3 [12800/22481 (57%)]\tLoss: 0.325923\n",
      "Train Epoch: 3 [13440/22481 (60%)]\tLoss: 0.143896\n",
      "Train Epoch: 3 [14080/22481 (62%)]\tLoss: 0.132123\n",
      "Train Epoch: 3 [14720/22481 (65%)]\tLoss: 0.116707\n",
      "Train Epoch: 3 [15360/22481 (68%)]\tLoss: 0.169886\n",
      "Train Epoch: 3 [16000/22481 (71%)]\tLoss: 0.143441\n",
      "Train Epoch: 3 [16640/22481 (74%)]\tLoss: 0.143730\n",
      "Train Epoch: 3 [17280/22481 (77%)]\tLoss: 0.091281\n",
      "Train Epoch: 3 [17920/22481 (80%)]\tLoss: 0.064366\n",
      "Train Epoch: 3 [18560/22481 (82%)]\tLoss: 0.058137\n",
      "Train Epoch: 3 [19200/22481 (85%)]\tLoss: 0.154159\n",
      "Train Epoch: 3 [19840/22481 (88%)]\tLoss: 0.177233\n",
      "Train Epoch: 3 [20480/22481 (91%)]\tLoss: 0.277979\n",
      "Train Epoch: 3 [21120/22481 (94%)]\tLoss: 0.139943\n",
      "Train Epoch: 3 [21760/22481 (97%)]\tLoss: 0.285529\n",
      "Train Epoch: 3 [22400/22481 (99%)]\tLoss: 0.176210\n",
      "Train Epoch: 4 [0/22481 (0%)]\tLoss: 0.047700\n",
      "Train Epoch: 4 [640/22481 (3%)]\tLoss: 0.164551\n",
      "Train Epoch: 4 [1280/22481 (6%)]\tLoss: 0.183937\n",
      "Train Epoch: 4 [1920/22481 (9%)]\tLoss: 0.115123\n",
      "Train Epoch: 4 [2560/22481 (11%)]\tLoss: 0.054112\n",
      "Train Epoch: 4 [3200/22481 (14%)]\tLoss: 0.198994\n",
      "Train Epoch: 4 [3840/22481 (17%)]\tLoss: 0.071112\n",
      "Train Epoch: 4 [4480/22481 (20%)]\tLoss: 0.109685\n",
      "Train Epoch: 4 [5120/22481 (23%)]\tLoss: 0.286625\n",
      "Train Epoch: 4 [5760/22481 (26%)]\tLoss: 0.148463\n",
      "Train Epoch: 4 [6400/22481 (28%)]\tLoss: 0.157785\n",
      "Train Epoch: 4 [7040/22481 (31%)]\tLoss: 0.105460\n",
      "Train Epoch: 4 [7680/22481 (34%)]\tLoss: 0.193306\n",
      "Train Epoch: 4 [8320/22481 (37%)]\tLoss: 0.135127\n",
      "Train Epoch: 4 [8960/22481 (40%)]\tLoss: 0.060632\n",
      "Train Epoch: 4 [9600/22481 (43%)]\tLoss: 0.050934\n",
      "Train Epoch: 4 [10240/22481 (45%)]\tLoss: 0.074948\n",
      "Train Epoch: 4 [10880/22481 (48%)]\tLoss: 0.255122\n",
      "Train Epoch: 4 [11520/22481 (51%)]\tLoss: 0.149619\n",
      "Train Epoch: 4 [12160/22481 (54%)]\tLoss: 0.265028\n",
      "Train Epoch: 4 [12800/22481 (57%)]\tLoss: 0.183987\n",
      "Train Epoch: 4 [13440/22481 (60%)]\tLoss: 0.233364\n",
      "Train Epoch: 4 [14080/22481 (62%)]\tLoss: 0.092491\n",
      "Train Epoch: 4 [14720/22481 (65%)]\tLoss: 0.103842\n",
      "Train Epoch: 4 [15360/22481 (68%)]\tLoss: 0.309500\n",
      "Train Epoch: 4 [16000/22481 (71%)]\tLoss: 0.103631\n",
      "Train Epoch: 4 [16640/22481 (74%)]\tLoss: 0.199427\n",
      "Train Epoch: 4 [17280/22481 (77%)]\tLoss: 0.374087\n",
      "Train Epoch: 4 [17920/22481 (80%)]\tLoss: 0.122323\n",
      "Train Epoch: 4 [18560/22481 (82%)]\tLoss: 0.117616\n",
      "Train Epoch: 4 [19200/22481 (85%)]\tLoss: 0.114480\n",
      "Train Epoch: 4 [19840/22481 (88%)]\tLoss: 0.203133\n",
      "Train Epoch: 4 [20480/22481 (91%)]\tLoss: 0.154571\n",
      "Train Epoch: 4 [21120/22481 (94%)]\tLoss: 0.256084\n",
      "Train Epoch: 4 [21760/22481 (97%)]\tLoss: 0.407521\n",
      "Train Epoch: 4 [22400/22481 (99%)]\tLoss: 0.213297\n",
      "Train Epoch: 5 [0/22481 (0%)]\tLoss: 0.118028\n",
      "Train Epoch: 5 [640/22481 (3%)]\tLoss: 0.116111\n",
      "Train Epoch: 5 [1280/22481 (6%)]\tLoss: 0.173727\n",
      "Train Epoch: 5 [1920/22481 (9%)]\tLoss: 0.071680\n",
      "Train Epoch: 5 [2560/22481 (11%)]\tLoss: 0.084657\n",
      "Train Epoch: 5 [3200/22481 (14%)]\tLoss: 0.113787\n",
      "Train Epoch: 5 [3840/22481 (17%)]\tLoss: 0.119295\n",
      "Train Epoch: 5 [4480/22481 (20%)]\tLoss: 0.120742\n",
      "Train Epoch: 5 [5120/22481 (23%)]\tLoss: 0.095156\n",
      "Train Epoch: 5 [5760/22481 (26%)]\tLoss: 0.080806\n",
      "Train Epoch: 5 [6400/22481 (28%)]\tLoss: 0.064816\n",
      "Train Epoch: 5 [7040/22481 (31%)]\tLoss: 0.124407\n",
      "Train Epoch: 5 [7680/22481 (34%)]\tLoss: 0.171950\n",
      "Train Epoch: 5 [8320/22481 (37%)]\tLoss: 0.097780\n",
      "Train Epoch: 5 [8960/22481 (40%)]\tLoss: 0.086094\n",
      "Train Epoch: 5 [9600/22481 (43%)]\tLoss: 0.094682\n",
      "Train Epoch: 5 [10240/22481 (45%)]\tLoss: 0.095738\n",
      "Train Epoch: 5 [10880/22481 (48%)]\tLoss: 0.101357\n",
      "Train Epoch: 5 [11520/22481 (51%)]\tLoss: 0.185209\n",
      "Train Epoch: 5 [12160/22481 (54%)]\tLoss: 0.100788\n",
      "Train Epoch: 5 [12800/22481 (57%)]\tLoss: 0.099959\n",
      "Train Epoch: 5 [13440/22481 (60%)]\tLoss: 0.118049\n",
      "Train Epoch: 5 [14080/22481 (62%)]\tLoss: 0.135899\n",
      "Train Epoch: 5 [14720/22481 (65%)]\tLoss: 0.154999\n",
      "Train Epoch: 5 [15360/22481 (68%)]\tLoss: 0.218445\n",
      "Train Epoch: 5 [16000/22481 (71%)]\tLoss: 0.140779\n",
      "Train Epoch: 5 [16640/22481 (74%)]\tLoss: 0.095759\n",
      "Train Epoch: 5 [17280/22481 (77%)]\tLoss: 0.223196\n",
      "Train Epoch: 5 [17920/22481 (80%)]\tLoss: 0.120749\n",
      "Train Epoch: 5 [18560/22481 (82%)]\tLoss: 0.111543\n",
      "Train Epoch: 5 [19200/22481 (85%)]\tLoss: 0.155772\n",
      "Train Epoch: 5 [19840/22481 (88%)]\tLoss: 0.157490\n",
      "Train Epoch: 5 [20480/22481 (91%)]\tLoss: 0.035729\n",
      "Train Epoch: 5 [21120/22481 (94%)]\tLoss: 0.087269\n",
      "Train Epoch: 5 [21760/22481 (97%)]\tLoss: 0.070815\n",
      "Train Epoch: 5 [22400/22481 (99%)]\tLoss: 0.129623\n",
      "Train Epoch: 6 [0/22481 (0%)]\tLoss: 0.045589\n",
      "Train Epoch: 6 [640/22481 (3%)]\tLoss: 0.130112\n",
      "Train Epoch: 6 [1280/22481 (6%)]\tLoss: 0.127446\n",
      "Train Epoch: 6 [1920/22481 (9%)]\tLoss: 0.102119\n",
      "Train Epoch: 6 [2560/22481 (11%)]\tLoss: 0.040062\n",
      "Train Epoch: 6 [3200/22481 (14%)]\tLoss: 0.104250\n",
      "Train Epoch: 6 [3840/22481 (17%)]\tLoss: 0.047634\n",
      "Train Epoch: 6 [4480/22481 (20%)]\tLoss: 0.150515\n",
      "Train Epoch: 6 [5120/22481 (23%)]\tLoss: 0.132501\n",
      "Train Epoch: 6 [5760/22481 (26%)]\tLoss: 0.186634\n",
      "Train Epoch: 6 [6400/22481 (28%)]\tLoss: 0.180002\n",
      "Train Epoch: 6 [7040/22481 (31%)]\tLoss: 0.041721\n",
      "Train Epoch: 6 [7680/22481 (34%)]\tLoss: 0.138821\n",
      "Train Epoch: 6 [8320/22481 (37%)]\tLoss: 0.077326\n",
      "Train Epoch: 6 [8960/22481 (40%)]\tLoss: 0.085586\n",
      "Train Epoch: 6 [9600/22481 (43%)]\tLoss: 0.278230\n",
      "Train Epoch: 6 [10240/22481 (45%)]\tLoss: 0.146101\n",
      "Train Epoch: 6 [10880/22481 (48%)]\tLoss: 0.098719\n",
      "Train Epoch: 6 [11520/22481 (51%)]\tLoss: 0.092711\n",
      "Train Epoch: 6 [12160/22481 (54%)]\tLoss: 0.098584\n",
      "Train Epoch: 6 [12800/22481 (57%)]\tLoss: 0.086218\n",
      "Train Epoch: 6 [13440/22481 (60%)]\tLoss: 0.139051\n",
      "Train Epoch: 6 [14080/22481 (62%)]\tLoss: 0.069254\n",
      "Train Epoch: 6 [14720/22481 (65%)]\tLoss: 0.287910\n",
      "Train Epoch: 6 [15360/22481 (68%)]\tLoss: 0.108768\n",
      "Train Epoch: 6 [16000/22481 (71%)]\tLoss: 0.065126\n",
      "Train Epoch: 6 [16640/22481 (74%)]\tLoss: 0.110784\n",
      "Train Epoch: 6 [17280/22481 (77%)]\tLoss: 0.085383\n",
      "Train Epoch: 6 [17920/22481 (80%)]\tLoss: 0.390817\n",
      "Train Epoch: 6 [18560/22481 (82%)]\tLoss: 0.187307\n",
      "Train Epoch: 6 [19200/22481 (85%)]\tLoss: 0.200822\n",
      "Train Epoch: 6 [19840/22481 (88%)]\tLoss: 0.119025\n",
      "Train Epoch: 6 [20480/22481 (91%)]\tLoss: 0.104006\n",
      "Train Epoch: 6 [21120/22481 (94%)]\tLoss: 0.166966\n",
      "Train Epoch: 6 [21760/22481 (97%)]\tLoss: 0.365089\n",
      "Train Epoch: 6 [22400/22481 (99%)]\tLoss: 0.140583\n",
      "Train Epoch: 7 [0/22481 (0%)]\tLoss: 0.254466\n",
      "Train Epoch: 7 [640/22481 (3%)]\tLoss: 0.088967\n",
      "Train Epoch: 7 [1280/22481 (6%)]\tLoss: 0.272840\n",
      "Train Epoch: 7 [1920/22481 (9%)]\tLoss: 0.144236\n",
      "Train Epoch: 7 [2560/22481 (11%)]\tLoss: 0.191825\n",
      "Train Epoch: 7 [3200/22481 (14%)]\tLoss: 0.157156\n",
      "Train Epoch: 7 [3840/22481 (17%)]\tLoss: 0.268187\n",
      "Train Epoch: 7 [4480/22481 (20%)]\tLoss: 0.153375\n",
      "Train Epoch: 7 [5120/22481 (23%)]\tLoss: 0.159911\n",
      "Train Epoch: 7 [5760/22481 (26%)]\tLoss: 0.070775\n",
      "Train Epoch: 7 [6400/22481 (28%)]\tLoss: 0.162342\n",
      "Train Epoch: 7 [7040/22481 (31%)]\tLoss: 0.451074\n",
      "Train Epoch: 7 [7680/22481 (34%)]\tLoss: 0.323026\n",
      "Train Epoch: 7 [8320/22481 (37%)]\tLoss: 0.032146\n",
      "Train Epoch: 7 [8960/22481 (40%)]\tLoss: 0.034513\n",
      "Train Epoch: 7 [9600/22481 (43%)]\tLoss: 0.151812\n",
      "Train Epoch: 7 [10240/22481 (45%)]\tLoss: 0.122442\n",
      "Train Epoch: 7 [10880/22481 (48%)]\tLoss: 0.159446\n",
      "Train Epoch: 7 [11520/22481 (51%)]\tLoss: 0.123189\n",
      "Train Epoch: 7 [12160/22481 (54%)]\tLoss: 0.111219\n",
      "Train Epoch: 7 [12800/22481 (57%)]\tLoss: 0.137971\n",
      "Train Epoch: 7 [13440/22481 (60%)]\tLoss: 0.156495\n",
      "Train Epoch: 7 [14080/22481 (62%)]\tLoss: 0.170796\n",
      "Train Epoch: 7 [14720/22481 (65%)]\tLoss: 0.200060\n",
      "Train Epoch: 7 [15360/22481 (68%)]\tLoss: 0.033413\n",
      "Train Epoch: 7 [16000/22481 (71%)]\tLoss: 0.336716\n",
      "Train Epoch: 7 [16640/22481 (74%)]\tLoss: 0.111281\n",
      "Train Epoch: 7 [17280/22481 (77%)]\tLoss: 0.093472\n",
      "Train Epoch: 7 [17920/22481 (80%)]\tLoss: 0.254588\n",
      "Train Epoch: 7 [18560/22481 (82%)]\tLoss: 0.091257\n",
      "Train Epoch: 7 [19200/22481 (85%)]\tLoss: 0.094699\n",
      "Train Epoch: 7 [19840/22481 (88%)]\tLoss: 0.085274\n",
      "Train Epoch: 7 [20480/22481 (91%)]\tLoss: 0.262073\n",
      "Train Epoch: 7 [21120/22481 (94%)]\tLoss: 0.082841\n",
      "Train Epoch: 7 [21760/22481 (97%)]\tLoss: 0.154982\n",
      "Train Epoch: 7 [22400/22481 (99%)]\tLoss: 0.039232\n",
      "Train Epoch: 8 [0/22481 (0%)]\tLoss: 0.137376\n",
      "Train Epoch: 8 [640/22481 (3%)]\tLoss: 0.200440\n",
      "Train Epoch: 8 [1280/22481 (6%)]\tLoss: 0.130249\n",
      "Train Epoch: 8 [1920/22481 (9%)]\tLoss: 0.090549\n",
      "Train Epoch: 8 [2560/22481 (11%)]\tLoss: 0.308564\n",
      "Train Epoch: 8 [3200/22481 (14%)]\tLoss: 0.116832\n",
      "Train Epoch: 8 [3840/22481 (17%)]\tLoss: 0.332784\n",
      "Train Epoch: 8 [4480/22481 (20%)]\tLoss: 0.178615\n",
      "Train Epoch: 8 [5120/22481 (23%)]\tLoss: 0.126684\n",
      "Train Epoch: 8 [5760/22481 (26%)]\tLoss: 0.109358\n",
      "Train Epoch: 8 [6400/22481 (28%)]\tLoss: 0.044845\n",
      "Train Epoch: 8 [7040/22481 (31%)]\tLoss: 0.114485\n",
      "Train Epoch: 8 [7680/22481 (34%)]\tLoss: 0.151705\n",
      "Train Epoch: 8 [8320/22481 (37%)]\tLoss: 0.155852\n",
      "Train Epoch: 8 [8960/22481 (40%)]\tLoss: 0.069399\n",
      "Train Epoch: 8 [9600/22481 (43%)]\tLoss: 0.190836\n",
      "Train Epoch: 8 [10240/22481 (45%)]\tLoss: 0.157192\n",
      "Train Epoch: 8 [10880/22481 (48%)]\tLoss: 0.164605\n",
      "Train Epoch: 8 [11520/22481 (51%)]\tLoss: 0.116504\n",
      "Train Epoch: 8 [12160/22481 (54%)]\tLoss: 0.047570\n",
      "Train Epoch: 8 [12800/22481 (57%)]\tLoss: 0.079226\n",
      "Train Epoch: 8 [13440/22481 (60%)]\tLoss: 0.139102\n",
      "Train Epoch: 8 [14080/22481 (62%)]\tLoss: 0.216160\n",
      "Train Epoch: 8 [14720/22481 (65%)]\tLoss: 0.068667\n",
      "Train Epoch: 8 [15360/22481 (68%)]\tLoss: 0.148184\n",
      "Train Epoch: 8 [16000/22481 (71%)]\tLoss: 0.106159\n",
      "Train Epoch: 8 [16640/22481 (74%)]\tLoss: 0.068408\n",
      "Train Epoch: 8 [17280/22481 (77%)]\tLoss: 0.094992\n",
      "Train Epoch: 8 [17920/22481 (80%)]\tLoss: 0.210016\n",
      "Train Epoch: 8 [18560/22481 (82%)]\tLoss: 0.116249\n",
      "Train Epoch: 8 [19200/22481 (85%)]\tLoss: 0.185521\n",
      "Train Epoch: 8 [19840/22481 (88%)]\tLoss: 0.243562\n",
      "Train Epoch: 8 [20480/22481 (91%)]\tLoss: 0.045365\n",
      "Train Epoch: 8 [21120/22481 (94%)]\tLoss: 0.133417\n",
      "Train Epoch: 8 [21760/22481 (97%)]\tLoss: 0.088585\n",
      "Train Epoch: 8 [22400/22481 (99%)]\tLoss: 0.184298\n",
      "Train Epoch: 9 [0/22481 (0%)]\tLoss: 0.104596\n",
      "Train Epoch: 9 [640/22481 (3%)]\tLoss: 0.061336\n",
      "Train Epoch: 9 [1280/22481 (6%)]\tLoss: 0.094243\n",
      "Train Epoch: 9 [1920/22481 (9%)]\tLoss: 0.105288\n",
      "Train Epoch: 9 [2560/22481 (11%)]\tLoss: 0.167496\n",
      "Train Epoch: 9 [3200/22481 (14%)]\tLoss: 0.111669\n",
      "Train Epoch: 9 [3840/22481 (17%)]\tLoss: 0.162880\n",
      "Train Epoch: 9 [4480/22481 (20%)]\tLoss: 0.082974\n",
      "Train Epoch: 9 [5120/22481 (23%)]\tLoss: 0.212193\n",
      "Train Epoch: 9 [5760/22481 (26%)]\tLoss: 0.068633\n",
      "Train Epoch: 9 [6400/22481 (28%)]\tLoss: 0.232498\n",
      "Train Epoch: 9 [7040/22481 (31%)]\tLoss: 0.140836\n",
      "Train Epoch: 9 [7680/22481 (34%)]\tLoss: 0.116086\n",
      "Train Epoch: 9 [8320/22481 (37%)]\tLoss: 0.063531\n",
      "Train Epoch: 9 [8960/22481 (40%)]\tLoss: 0.087838\n",
      "Train Epoch: 9 [9600/22481 (43%)]\tLoss: 0.303567\n",
      "Train Epoch: 9 [10240/22481 (45%)]\tLoss: 0.128744\n",
      "Train Epoch: 9 [10880/22481 (48%)]\tLoss: 0.066448\n",
      "Train Epoch: 9 [11520/22481 (51%)]\tLoss: 0.168731\n",
      "Train Epoch: 9 [12160/22481 (54%)]\tLoss: 0.054948\n",
      "Train Epoch: 9 [12800/22481 (57%)]\tLoss: 0.253933\n",
      "Train Epoch: 9 [13440/22481 (60%)]\tLoss: 0.093234\n",
      "Train Epoch: 9 [14080/22481 (62%)]\tLoss: 0.170646\n",
      "Train Epoch: 9 [14720/22481 (65%)]\tLoss: 0.161911\n",
      "Train Epoch: 9 [15360/22481 (68%)]\tLoss: 0.064429\n",
      "Train Epoch: 9 [16000/22481 (71%)]\tLoss: 0.216565\n",
      "Train Epoch: 9 [16640/22481 (74%)]\tLoss: 0.061767\n",
      "Train Epoch: 9 [17280/22481 (77%)]\tLoss: 0.067920\n",
      "Train Epoch: 9 [17920/22481 (80%)]\tLoss: 0.134678\n",
      "Train Epoch: 9 [18560/22481 (82%)]\tLoss: 0.115612\n",
      "Train Epoch: 9 [19200/22481 (85%)]\tLoss: 0.149781\n",
      "Train Epoch: 9 [19840/22481 (88%)]\tLoss: 0.075962\n",
      "Train Epoch: 9 [20480/22481 (91%)]\tLoss: 0.194634\n",
      "Train Epoch: 9 [21120/22481 (94%)]\tLoss: 0.112847\n",
      "Train Epoch: 9 [21760/22481 (97%)]\tLoss: 0.229192\n",
      "Train Epoch: 9 [22400/22481 (99%)]\tLoss: 0.158379\n",
      "Train Epoch: 10 [0/22481 (0%)]\tLoss: 0.106679\n",
      "Train Epoch: 10 [640/22481 (3%)]\tLoss: 0.149713\n",
      "Train Epoch: 10 [1280/22481 (6%)]\tLoss: 0.244468\n",
      "Train Epoch: 10 [1920/22481 (9%)]\tLoss: 0.068551\n",
      "Train Epoch: 10 [2560/22481 (11%)]\tLoss: 0.079078\n",
      "Train Epoch: 10 [3200/22481 (14%)]\tLoss: 0.138510\n",
      "Train Epoch: 10 [3840/22481 (17%)]\tLoss: 0.076327\n",
      "Train Epoch: 10 [4480/22481 (20%)]\tLoss: 0.066480\n",
      "Train Epoch: 10 [5120/22481 (23%)]\tLoss: 0.106681\n",
      "Train Epoch: 10 [5760/22481 (26%)]\tLoss: 0.124851\n",
      "Train Epoch: 10 [6400/22481 (28%)]\tLoss: 0.110180\n",
      "Train Epoch: 10 [7040/22481 (31%)]\tLoss: 0.211219\n",
      "Train Epoch: 10 [7680/22481 (34%)]\tLoss: 0.311608\n",
      "Train Epoch: 10 [8320/22481 (37%)]\tLoss: 0.198203\n",
      "Train Epoch: 10 [8960/22481 (40%)]\tLoss: 0.135301\n",
      "Train Epoch: 10 [9600/22481 (43%)]\tLoss: 0.136172\n",
      "Train Epoch: 10 [10240/22481 (45%)]\tLoss: 0.125916\n",
      "Train Epoch: 10 [10880/22481 (48%)]\tLoss: 0.063560\n",
      "Train Epoch: 10 [11520/22481 (51%)]\tLoss: 0.238076\n",
      "Train Epoch: 10 [12160/22481 (54%)]\tLoss: 0.096160\n",
      "Train Epoch: 10 [12800/22481 (57%)]\tLoss: 0.479045\n",
      "Train Epoch: 10 [13440/22481 (60%)]\tLoss: 0.177308\n",
      "Train Epoch: 10 [14080/22481 (62%)]\tLoss: 0.086172\n",
      "Train Epoch: 10 [14720/22481 (65%)]\tLoss: 0.034590\n",
      "Train Epoch: 10 [15360/22481 (68%)]\tLoss: 0.201342\n",
      "Train Epoch: 10 [16000/22481 (71%)]\tLoss: 0.083082\n",
      "Train Epoch: 10 [16640/22481 (74%)]\tLoss: 0.118590\n",
      "Train Epoch: 10 [17280/22481 (77%)]\tLoss: 0.145650\n",
      "Train Epoch: 10 [17920/22481 (80%)]\tLoss: 0.106152\n",
      "Train Epoch: 10 [18560/22481 (82%)]\tLoss: 0.062819\n",
      "Train Epoch: 10 [19200/22481 (85%)]\tLoss: 0.186436\n",
      "Train Epoch: 10 [19840/22481 (88%)]\tLoss: 0.071575\n",
      "Train Epoch: 10 [20480/22481 (91%)]\tLoss: 0.083579\n",
      "Train Epoch: 10 [21120/22481 (94%)]\tLoss: 0.142205\n",
      "Train Epoch: 10 [21760/22481 (97%)]\tLoss: 0.193991\n",
      "Train Epoch: 10 [22400/22481 (99%)]\tLoss: 0.124138\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0875, Accuracy: 9719/10000 (97%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/37519 (0%)]\tLoss: 0.256361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [640/37519 (2%)]\tLoss: 0.257438\n",
      "Train Epoch: 1 [1280/37519 (3%)]\tLoss: 0.117740\n",
      "Train Epoch: 1 [1920/37519 (5%)]\tLoss: 0.172869\n",
      "Train Epoch: 1 [2560/37519 (7%)]\tLoss: 0.187357\n",
      "Train Epoch: 1 [3200/37519 (9%)]\tLoss: 0.192296\n",
      "Train Epoch: 1 [3840/37519 (10%)]\tLoss: 0.219180\n",
      "Train Epoch: 1 [4480/37519 (12%)]\tLoss: 0.156605\n",
      "Train Epoch: 1 [5120/37519 (14%)]\tLoss: 0.236134\n",
      "Train Epoch: 1 [5760/37519 (15%)]\tLoss: 0.287349\n",
      "Train Epoch: 1 [6400/37519 (17%)]\tLoss: 0.372908\n",
      "Train Epoch: 1 [7040/37519 (19%)]\tLoss: 0.217291\n",
      "Train Epoch: 1 [7680/37519 (20%)]\tLoss: 0.111678\n",
      "Train Epoch: 1 [8320/37519 (22%)]\tLoss: 0.112427\n",
      "Train Epoch: 1 [8960/37519 (24%)]\tLoss: 0.092645\n",
      "Train Epoch: 1 [9600/37519 (26%)]\tLoss: 0.088817\n",
      "Train Epoch: 1 [10240/37519 (27%)]\tLoss: 0.201081\n",
      "Train Epoch: 1 [10880/37519 (29%)]\tLoss: 0.127409\n",
      "Train Epoch: 1 [11520/37519 (31%)]\tLoss: 0.157716\n",
      "Train Epoch: 1 [12160/37519 (32%)]\tLoss: 0.165577\n",
      "Train Epoch: 1 [12800/37519 (34%)]\tLoss: 0.164363\n",
      "Train Epoch: 1 [13440/37519 (36%)]\tLoss: 0.166694\n",
      "Train Epoch: 1 [14080/37519 (37%)]\tLoss: 0.115186\n",
      "Train Epoch: 1 [14720/37519 (39%)]\tLoss: 0.254973\n",
      "Train Epoch: 1 [15360/37519 (41%)]\tLoss: 0.222884\n",
      "Train Epoch: 1 [16000/37519 (43%)]\tLoss: 0.303162\n",
      "Train Epoch: 1 [16640/37519 (44%)]\tLoss: 0.267288\n",
      "Train Epoch: 1 [17280/37519 (46%)]\tLoss: 0.218899\n",
      "Train Epoch: 1 [17920/37519 (48%)]\tLoss: 0.250348\n",
      "Train Epoch: 1 [18560/37519 (49%)]\tLoss: 0.228388\n",
      "Train Epoch: 1 [19200/37519 (51%)]\tLoss: 0.156407\n",
      "Train Epoch: 1 [19840/37519 (53%)]\tLoss: 0.037840\n",
      "Train Epoch: 1 [20480/37519 (55%)]\tLoss: 0.090248\n",
      "Train Epoch: 1 [21120/37519 (56%)]\tLoss: 0.195688\n",
      "Train Epoch: 1 [21760/37519 (58%)]\tLoss: 0.244937\n",
      "Train Epoch: 1 [22400/37519 (60%)]\tLoss: 0.067296\n",
      "Train Epoch: 1 [23040/37519 (61%)]\tLoss: 0.043366\n",
      "Train Epoch: 1 [23680/37519 (63%)]\tLoss: 0.116393\n",
      "Train Epoch: 1 [24320/37519 (65%)]\tLoss: 0.224073\n",
      "Train Epoch: 1 [24960/37519 (66%)]\tLoss: 0.196596\n",
      "Train Epoch: 1 [25600/37519 (68%)]\tLoss: 0.324940\n",
      "Train Epoch: 1 [26240/37519 (70%)]\tLoss: 0.144713\n",
      "Train Epoch: 1 [26880/37519 (72%)]\tLoss: 0.187598\n",
      "Train Epoch: 1 [27520/37519 (73%)]\tLoss: 0.068572\n",
      "Train Epoch: 1 [28160/37519 (75%)]\tLoss: 0.192751\n",
      "Train Epoch: 1 [28800/37519 (77%)]\tLoss: 0.075985\n",
      "Train Epoch: 1 [29440/37519 (78%)]\tLoss: 0.235941\n",
      "Train Epoch: 1 [30080/37519 (80%)]\tLoss: 0.185043\n",
      "Train Epoch: 1 [30720/37519 (82%)]\tLoss: 0.110454\n",
      "Train Epoch: 1 [31360/37519 (83%)]\tLoss: 0.108433\n",
      "Train Epoch: 1 [32000/37519 (85%)]\tLoss: 0.386899\n",
      "Train Epoch: 1 [32640/37519 (87%)]\tLoss: 0.047295\n",
      "Train Epoch: 1 [33280/37519 (89%)]\tLoss: 0.191258\n",
      "Train Epoch: 1 [33920/37519 (90%)]\tLoss: 0.200426\n",
      "Train Epoch: 1 [34560/37519 (92%)]\tLoss: 0.197371\n",
      "Train Epoch: 1 [35200/37519 (94%)]\tLoss: 0.113866\n",
      "Train Epoch: 1 [35840/37519 (95%)]\tLoss: 0.237744\n",
      "Train Epoch: 1 [36480/37519 (97%)]\tLoss: 0.327405\n",
      "Train Epoch: 1 [37120/37519 (99%)]\tLoss: 0.138369\n",
      "Train Epoch: 2 [0/37519 (0%)]\tLoss: 0.228877\n",
      "Train Epoch: 2 [640/37519 (2%)]\tLoss: 0.291664\n",
      "Train Epoch: 2 [1280/37519 (3%)]\tLoss: 0.118011\n",
      "Train Epoch: 2 [1920/37519 (5%)]\tLoss: 0.104657\n",
      "Train Epoch: 2 [2560/37519 (7%)]\tLoss: 0.144332\n",
      "Train Epoch: 2 [3200/37519 (9%)]\tLoss: 0.129808\n",
      "Train Epoch: 2 [3840/37519 (10%)]\tLoss: 0.134274\n",
      "Train Epoch: 2 [4480/37519 (12%)]\tLoss: 0.075764\n",
      "Train Epoch: 2 [5120/37519 (14%)]\tLoss: 0.142244\n",
      "Train Epoch: 2 [5760/37519 (15%)]\tLoss: 0.280447\n",
      "Train Epoch: 2 [6400/37519 (17%)]\tLoss: 0.342815\n",
      "Train Epoch: 2 [7040/37519 (19%)]\tLoss: 0.162335\n",
      "Train Epoch: 2 [7680/37519 (20%)]\tLoss: 0.292966\n",
      "Train Epoch: 2 [8320/37519 (22%)]\tLoss: 0.249597\n",
      "Train Epoch: 2 [8960/37519 (24%)]\tLoss: 0.317528\n",
      "Train Epoch: 2 [9600/37519 (26%)]\tLoss: 0.262862\n",
      "Train Epoch: 2 [10240/37519 (27%)]\tLoss: 0.269962\n",
      "Train Epoch: 2 [10880/37519 (29%)]\tLoss: 0.256360\n",
      "Train Epoch: 2 [11520/37519 (31%)]\tLoss: 0.091083\n",
      "Train Epoch: 2 [12160/37519 (32%)]\tLoss: 0.190258\n",
      "Train Epoch: 2 [12800/37519 (34%)]\tLoss: 0.142709\n",
      "Train Epoch: 2 [13440/37519 (36%)]\tLoss: 0.397940\n",
      "Train Epoch: 2 [14080/37519 (37%)]\tLoss: 0.251004\n",
      "Train Epoch: 2 [14720/37519 (39%)]\tLoss: 0.102842\n",
      "Train Epoch: 2 [15360/37519 (41%)]\tLoss: 0.076733\n",
      "Train Epoch: 2 [16000/37519 (43%)]\tLoss: 0.233904\n",
      "Train Epoch: 2 [16640/37519 (44%)]\tLoss: 0.030200\n",
      "Train Epoch: 2 [17280/37519 (46%)]\tLoss: 0.128420\n",
      "Train Epoch: 2 [17920/37519 (48%)]\tLoss: 0.393090\n",
      "Train Epoch: 2 [18560/37519 (49%)]\tLoss: 0.160412\n",
      "Train Epoch: 2 [19200/37519 (51%)]\tLoss: 0.160451\n",
      "Train Epoch: 2 [19840/37519 (53%)]\tLoss: 0.239257\n",
      "Train Epoch: 2 [20480/37519 (55%)]\tLoss: 0.086682\n",
      "Train Epoch: 2 [21120/37519 (56%)]\tLoss: 0.125224\n",
      "Train Epoch: 2 [21760/37519 (58%)]\tLoss: 0.172663\n",
      "Train Epoch: 2 [22400/37519 (60%)]\tLoss: 0.253389\n",
      "Train Epoch: 2 [23040/37519 (61%)]\tLoss: 0.328467\n",
      "Train Epoch: 2 [23680/37519 (63%)]\tLoss: 0.126062\n",
      "Train Epoch: 2 [24320/37519 (65%)]\tLoss: 0.290355\n",
      "Train Epoch: 2 [24960/37519 (66%)]\tLoss: 0.332586\n",
      "Train Epoch: 2 [25600/37519 (68%)]\tLoss: 0.057017\n",
      "Train Epoch: 2 [26240/37519 (70%)]\tLoss: 0.117927\n",
      "Train Epoch: 2 [26880/37519 (72%)]\tLoss: 0.273351\n",
      "Train Epoch: 2 [27520/37519 (73%)]\tLoss: 0.366840\n",
      "Train Epoch: 2 [28160/37519 (75%)]\tLoss: 0.179690\n",
      "Train Epoch: 2 [28800/37519 (77%)]\tLoss: 0.225584\n",
      "Train Epoch: 2 [29440/37519 (78%)]\tLoss: 0.127484\n",
      "Train Epoch: 2 [30080/37519 (80%)]\tLoss: 0.166356\n",
      "Train Epoch: 2 [30720/37519 (82%)]\tLoss: 0.165345\n",
      "Train Epoch: 2 [31360/37519 (83%)]\tLoss: 0.204007\n",
      "Train Epoch: 2 [32000/37519 (85%)]\tLoss: 0.217551\n",
      "Train Epoch: 2 [32640/37519 (87%)]\tLoss: 0.183509\n",
      "Train Epoch: 2 [33280/37519 (89%)]\tLoss: 0.214489\n",
      "Train Epoch: 2 [33920/37519 (90%)]\tLoss: 0.141092\n",
      "Train Epoch: 2 [34560/37519 (92%)]\tLoss: 0.234011\n",
      "Train Epoch: 2 [35200/37519 (94%)]\tLoss: 0.099802\n",
      "Train Epoch: 2 [35840/37519 (95%)]\tLoss: 0.229828\n",
      "Train Epoch: 2 [36480/37519 (97%)]\tLoss: 0.263214\n",
      "Train Epoch: 2 [37120/37519 (99%)]\tLoss: 0.074119\n",
      "Train Epoch: 3 [0/37519 (0%)]\tLoss: 0.088928\n",
      "Train Epoch: 3 [640/37519 (2%)]\tLoss: 0.243375\n",
      "Train Epoch: 3 [1280/37519 (3%)]\tLoss: 0.118952\n",
      "Train Epoch: 3 [1920/37519 (5%)]\tLoss: 0.058355\n",
      "Train Epoch: 3 [2560/37519 (7%)]\tLoss: 0.142192\n",
      "Train Epoch: 3 [3200/37519 (9%)]\tLoss: 0.076281\n",
      "Train Epoch: 3 [3840/37519 (10%)]\tLoss: 0.255223\n",
      "Train Epoch: 3 [4480/37519 (12%)]\tLoss: 0.193836\n",
      "Train Epoch: 3 [5120/37519 (14%)]\tLoss: 0.039786\n",
      "Train Epoch: 3 [5760/37519 (15%)]\tLoss: 0.222425\n",
      "Train Epoch: 3 [6400/37519 (17%)]\tLoss: 0.056895\n",
      "Train Epoch: 3 [7040/37519 (19%)]\tLoss: 0.123911\n",
      "Train Epoch: 3 [7680/37519 (20%)]\tLoss: 0.128022\n",
      "Train Epoch: 3 [8320/37519 (22%)]\tLoss: 0.076668\n",
      "Train Epoch: 3 [8960/37519 (24%)]\tLoss: 0.306817\n",
      "Train Epoch: 3 [9600/37519 (26%)]\tLoss: 0.128521\n",
      "Train Epoch: 3 [10240/37519 (27%)]\tLoss: 0.072026\n",
      "Train Epoch: 3 [10880/37519 (29%)]\tLoss: 0.492742\n",
      "Train Epoch: 3 [11520/37519 (31%)]\tLoss: 0.066970\n",
      "Train Epoch: 3 [12160/37519 (32%)]\tLoss: 0.087747\n",
      "Train Epoch: 3 [12800/37519 (34%)]\tLoss: 0.183943\n",
      "Train Epoch: 3 [13440/37519 (36%)]\tLoss: 0.270111\n",
      "Train Epoch: 3 [14080/37519 (37%)]\tLoss: 0.277873\n",
      "Train Epoch: 3 [14720/37519 (39%)]\tLoss: 0.048714\n",
      "Train Epoch: 3 [15360/37519 (41%)]\tLoss: 0.054498\n",
      "Train Epoch: 3 [16000/37519 (43%)]\tLoss: 0.115863\n",
      "Train Epoch: 3 [16640/37519 (44%)]\tLoss: 0.308546\n",
      "Train Epoch: 3 [17280/37519 (46%)]\tLoss: 0.086773\n",
      "Train Epoch: 3 [17920/37519 (48%)]\tLoss: 0.036305\n",
      "Train Epoch: 3 [18560/37519 (49%)]\tLoss: 0.457752\n",
      "Train Epoch: 3 [19200/37519 (51%)]\tLoss: 0.176745\n",
      "Train Epoch: 3 [19840/37519 (53%)]\tLoss: 0.259231\n",
      "Train Epoch: 3 [20480/37519 (55%)]\tLoss: 0.193188\n",
      "Train Epoch: 3 [21120/37519 (56%)]\tLoss: 0.182294\n",
      "Train Epoch: 3 [21760/37519 (58%)]\tLoss: 0.185483\n",
      "Train Epoch: 3 [22400/37519 (60%)]\tLoss: 0.236069\n",
      "Train Epoch: 3 [23040/37519 (61%)]\tLoss: 0.230810\n",
      "Train Epoch: 3 [23680/37519 (63%)]\tLoss: 0.118581\n",
      "Train Epoch: 3 [24320/37519 (65%)]\tLoss: 0.111903\n",
      "Train Epoch: 3 [24960/37519 (66%)]\tLoss: 0.057835\n",
      "Train Epoch: 3 [25600/37519 (68%)]\tLoss: 0.181702\n",
      "Train Epoch: 3 [26240/37519 (70%)]\tLoss: 0.078459\n",
      "Train Epoch: 3 [26880/37519 (72%)]\tLoss: 0.162732\n",
      "Train Epoch: 3 [27520/37519 (73%)]\tLoss: 0.069860\n",
      "Train Epoch: 3 [28160/37519 (75%)]\tLoss: 0.146259\n",
      "Train Epoch: 3 [28800/37519 (77%)]\tLoss: 0.059966\n",
      "Train Epoch: 3 [29440/37519 (78%)]\tLoss: 0.302809\n",
      "Train Epoch: 3 [30080/37519 (80%)]\tLoss: 0.081639\n",
      "Train Epoch: 3 [30720/37519 (82%)]\tLoss: 0.069056\n",
      "Train Epoch: 3 [31360/37519 (83%)]\tLoss: 0.216095\n",
      "Train Epoch: 3 [32000/37519 (85%)]\tLoss: 0.078760\n",
      "Train Epoch: 3 [32640/37519 (87%)]\tLoss: 0.125400\n",
      "Train Epoch: 3 [33280/37519 (89%)]\tLoss: 0.286005\n",
      "Train Epoch: 3 [33920/37519 (90%)]\tLoss: 0.159068\n",
      "Train Epoch: 3 [34560/37519 (92%)]\tLoss: 0.257388\n",
      "Train Epoch: 3 [35200/37519 (94%)]\tLoss: 0.329599\n",
      "Train Epoch: 3 [35840/37519 (95%)]\tLoss: 0.165925\n",
      "Train Epoch: 3 [36480/37519 (97%)]\tLoss: 0.206881\n",
      "Train Epoch: 3 [37120/37519 (99%)]\tLoss: 0.122041\n",
      "Train Epoch: 4 [0/37519 (0%)]\tLoss: 0.151608\n",
      "Train Epoch: 4 [640/37519 (2%)]\tLoss: 0.153670\n",
      "Train Epoch: 4 [1280/37519 (3%)]\tLoss: 0.119243\n",
      "Train Epoch: 4 [1920/37519 (5%)]\tLoss: 0.072544\n",
      "Train Epoch: 4 [2560/37519 (7%)]\tLoss: 0.258881\n",
      "Train Epoch: 4 [3200/37519 (9%)]\tLoss: 0.152248\n",
      "Train Epoch: 4 [3840/37519 (10%)]\tLoss: 0.215670\n",
      "Train Epoch: 4 [4480/37519 (12%)]\tLoss: 0.188567\n",
      "Train Epoch: 4 [5120/37519 (14%)]\tLoss: 0.095602\n",
      "Train Epoch: 4 [5760/37519 (15%)]\tLoss: 0.165367\n",
      "Train Epoch: 4 [6400/37519 (17%)]\tLoss: 0.101124\n",
      "Train Epoch: 4 [7040/37519 (19%)]\tLoss: 0.078124\n",
      "Train Epoch: 4 [7680/37519 (20%)]\tLoss: 0.161076\n",
      "Train Epoch: 4 [8320/37519 (22%)]\tLoss: 0.090770\n",
      "Train Epoch: 4 [8960/37519 (24%)]\tLoss: 0.171678\n",
      "Train Epoch: 4 [9600/37519 (26%)]\tLoss: 0.280732\n",
      "Train Epoch: 4 [10240/37519 (27%)]\tLoss: 0.130678\n",
      "Train Epoch: 4 [10880/37519 (29%)]\tLoss: 0.116758\n",
      "Train Epoch: 4 [11520/37519 (31%)]\tLoss: 0.178093\n",
      "Train Epoch: 4 [12160/37519 (32%)]\tLoss: 0.118287\n",
      "Train Epoch: 4 [12800/37519 (34%)]\tLoss: 0.160577\n",
      "Train Epoch: 4 [13440/37519 (36%)]\tLoss: 0.123839\n",
      "Train Epoch: 4 [14080/37519 (37%)]\tLoss: 0.143849\n",
      "Train Epoch: 4 [14720/37519 (39%)]\tLoss: 0.342670\n",
      "Train Epoch: 4 [15360/37519 (41%)]\tLoss: 0.398418\n",
      "Train Epoch: 4 [16000/37519 (43%)]\tLoss: 0.147504\n",
      "Train Epoch: 4 [16640/37519 (44%)]\tLoss: 0.134410\n",
      "Train Epoch: 4 [17280/37519 (46%)]\tLoss: 0.044580\n",
      "Train Epoch: 4 [17920/37519 (48%)]\tLoss: 0.082425\n",
      "Train Epoch: 4 [18560/37519 (49%)]\tLoss: 0.200003\n",
      "Train Epoch: 4 [19200/37519 (51%)]\tLoss: 0.071612\n",
      "Train Epoch: 4 [19840/37519 (53%)]\tLoss: 0.271757\n",
      "Train Epoch: 4 [20480/37519 (55%)]\tLoss: 0.159659\n",
      "Train Epoch: 4 [21120/37519 (56%)]\tLoss: 0.198420\n",
      "Train Epoch: 4 [21760/37519 (58%)]\tLoss: 0.083253\n",
      "Train Epoch: 4 [22400/37519 (60%)]\tLoss: 0.062257\n",
      "Train Epoch: 4 [23040/37519 (61%)]\tLoss: 0.151686\n",
      "Train Epoch: 4 [23680/37519 (63%)]\tLoss: 0.133416\n",
      "Train Epoch: 4 [24320/37519 (65%)]\tLoss: 0.149968\n",
      "Train Epoch: 4 [24960/37519 (66%)]\tLoss: 0.176505\n",
      "Train Epoch: 4 [25600/37519 (68%)]\tLoss: 0.104199\n",
      "Train Epoch: 4 [26240/37519 (70%)]\tLoss: 0.115239\n",
      "Train Epoch: 4 [26880/37519 (72%)]\tLoss: 0.138321\n",
      "Train Epoch: 4 [27520/37519 (73%)]\tLoss: 0.270377\n",
      "Train Epoch: 4 [28160/37519 (75%)]\tLoss: 0.095629\n",
      "Train Epoch: 4 [28800/37519 (77%)]\tLoss: 0.109140\n",
      "Train Epoch: 4 [29440/37519 (78%)]\tLoss: 0.150161\n",
      "Train Epoch: 4 [30080/37519 (80%)]\tLoss: 0.045522\n",
      "Train Epoch: 4 [30720/37519 (82%)]\tLoss: 0.298482\n",
      "Train Epoch: 4 [31360/37519 (83%)]\tLoss: 0.267994\n",
      "Train Epoch: 4 [32000/37519 (85%)]\tLoss: 0.313741\n",
      "Train Epoch: 4 [32640/37519 (87%)]\tLoss: 0.110810\n",
      "Train Epoch: 4 [33280/37519 (89%)]\tLoss: 0.178517\n",
      "Train Epoch: 4 [33920/37519 (90%)]\tLoss: 0.096910\n",
      "Train Epoch: 4 [34560/37519 (92%)]\tLoss: 0.093294\n",
      "Train Epoch: 4 [35200/37519 (94%)]\tLoss: 0.371373\n",
      "Train Epoch: 4 [35840/37519 (95%)]\tLoss: 0.185450\n",
      "Train Epoch: 4 [36480/37519 (97%)]\tLoss: 0.217186\n",
      "Train Epoch: 4 [37120/37519 (99%)]\tLoss: 0.066326\n",
      "Train Epoch: 5 [0/37519 (0%)]\tLoss: 0.134489\n",
      "Train Epoch: 5 [640/37519 (2%)]\tLoss: 0.130688\n",
      "Train Epoch: 5 [1280/37519 (3%)]\tLoss: 0.171517\n",
      "Train Epoch: 5 [1920/37519 (5%)]\tLoss: 0.323700\n",
      "Train Epoch: 5 [2560/37519 (7%)]\tLoss: 0.071043\n",
      "Train Epoch: 5 [3200/37519 (9%)]\tLoss: 0.041511\n",
      "Train Epoch: 5 [3840/37519 (10%)]\tLoss: 0.125985\n",
      "Train Epoch: 5 [4480/37519 (12%)]\tLoss: 0.085629\n",
      "Train Epoch: 5 [5120/37519 (14%)]\tLoss: 0.135068\n",
      "Train Epoch: 5 [5760/37519 (15%)]\tLoss: 0.061411\n",
      "Train Epoch: 5 [6400/37519 (17%)]\tLoss: 0.086715\n",
      "Train Epoch: 5 [7040/37519 (19%)]\tLoss: 0.184066\n",
      "Train Epoch: 5 [7680/37519 (20%)]\tLoss: 0.099606\n",
      "Train Epoch: 5 [8320/37519 (22%)]\tLoss: 0.286660\n",
      "Train Epoch: 5 [8960/37519 (24%)]\tLoss: 0.118925\n",
      "Train Epoch: 5 [9600/37519 (26%)]\tLoss: 0.145540\n",
      "Train Epoch: 5 [10240/37519 (27%)]\tLoss: 0.086856\n",
      "Train Epoch: 5 [10880/37519 (29%)]\tLoss: 0.053558\n",
      "Train Epoch: 5 [11520/37519 (31%)]\tLoss: 0.106920\n",
      "Train Epoch: 5 [12160/37519 (32%)]\tLoss: 0.307352\n",
      "Train Epoch: 5 [12800/37519 (34%)]\tLoss: 0.135667\n",
      "Train Epoch: 5 [13440/37519 (36%)]\tLoss: 0.234780\n",
      "Train Epoch: 5 [14080/37519 (37%)]\tLoss: 0.151556\n",
      "Train Epoch: 5 [14720/37519 (39%)]\tLoss: 0.132473\n",
      "Train Epoch: 5 [15360/37519 (41%)]\tLoss: 0.209306\n",
      "Train Epoch: 5 [16000/37519 (43%)]\tLoss: 0.086186\n",
      "Train Epoch: 5 [16640/37519 (44%)]\tLoss: 0.117716\n",
      "Train Epoch: 5 [17280/37519 (46%)]\tLoss: 0.246900\n",
      "Train Epoch: 5 [17920/37519 (48%)]\tLoss: 0.094638\n",
      "Train Epoch: 5 [18560/37519 (49%)]\tLoss: 0.223520\n",
      "Train Epoch: 5 [19200/37519 (51%)]\tLoss: 0.111108\n",
      "Train Epoch: 5 [19840/37519 (53%)]\tLoss: 0.195886\n",
      "Train Epoch: 5 [20480/37519 (55%)]\tLoss: 0.186170\n",
      "Train Epoch: 5 [21120/37519 (56%)]\tLoss: 0.286369\n",
      "Train Epoch: 5 [21760/37519 (58%)]\tLoss: 0.071913\n",
      "Train Epoch: 5 [22400/37519 (60%)]\tLoss: 0.166936\n",
      "Train Epoch: 5 [23040/37519 (61%)]\tLoss: 0.120524\n",
      "Train Epoch: 5 [23680/37519 (63%)]\tLoss: 0.133862\n",
      "Train Epoch: 5 [24320/37519 (65%)]\tLoss: 0.194142\n",
      "Train Epoch: 5 [24960/37519 (66%)]\tLoss: 0.250826\n",
      "Train Epoch: 5 [25600/37519 (68%)]\tLoss: 0.174461\n",
      "Train Epoch: 5 [26240/37519 (70%)]\tLoss: 0.096859\n",
      "Train Epoch: 5 [26880/37519 (72%)]\tLoss: 0.279297\n",
      "Train Epoch: 5 [27520/37519 (73%)]\tLoss: 0.251374\n",
      "Train Epoch: 5 [28160/37519 (75%)]\tLoss: 0.080102\n",
      "Train Epoch: 5 [28800/37519 (77%)]\tLoss: 0.076788\n",
      "Train Epoch: 5 [29440/37519 (78%)]\tLoss: 0.147941\n",
      "Train Epoch: 5 [30080/37519 (80%)]\tLoss: 0.106791\n",
      "Train Epoch: 5 [30720/37519 (82%)]\tLoss: 0.061448\n",
      "Train Epoch: 5 [31360/37519 (83%)]\tLoss: 0.122503\n",
      "Train Epoch: 5 [32000/37519 (85%)]\tLoss: 0.226375\n",
      "Train Epoch: 5 [32640/37519 (87%)]\tLoss: 0.161083\n",
      "Train Epoch: 5 [33280/37519 (89%)]\tLoss: 0.075657\n",
      "Train Epoch: 5 [33920/37519 (90%)]\tLoss: 0.058024\n",
      "Train Epoch: 5 [34560/37519 (92%)]\tLoss: 0.072550\n",
      "Train Epoch: 5 [35200/37519 (94%)]\tLoss: 0.093915\n",
      "Train Epoch: 5 [35840/37519 (95%)]\tLoss: 0.121556\n",
      "Train Epoch: 5 [36480/37519 (97%)]\tLoss: 0.120764\n",
      "Train Epoch: 5 [37120/37519 (99%)]\tLoss: 0.176235\n",
      "Train Epoch: 6 [0/37519 (0%)]\tLoss: 0.341700\n",
      "Train Epoch: 6 [640/37519 (2%)]\tLoss: 0.146980\n",
      "Train Epoch: 6 [1280/37519 (3%)]\tLoss: 0.105165\n",
      "Train Epoch: 6 [1920/37519 (5%)]\tLoss: 0.217122\n",
      "Train Epoch: 6 [2560/37519 (7%)]\tLoss: 0.405222\n",
      "Train Epoch: 6 [3200/37519 (9%)]\tLoss: 0.076170\n",
      "Train Epoch: 6 [3840/37519 (10%)]\tLoss: 0.058240\n",
      "Train Epoch: 6 [4480/37519 (12%)]\tLoss: 0.243661\n",
      "Train Epoch: 6 [5120/37519 (14%)]\tLoss: 0.144849\n",
      "Train Epoch: 6 [5760/37519 (15%)]\tLoss: 0.138827\n",
      "Train Epoch: 6 [6400/37519 (17%)]\tLoss: 0.149156\n",
      "Train Epoch: 6 [7040/37519 (19%)]\tLoss: 0.084574\n",
      "Train Epoch: 6 [7680/37519 (20%)]\tLoss: 0.206750\n",
      "Train Epoch: 6 [8320/37519 (22%)]\tLoss: 0.054942\n",
      "Train Epoch: 6 [8960/37519 (24%)]\tLoss: 0.228039\n",
      "Train Epoch: 6 [9600/37519 (26%)]\tLoss: 0.232301\n",
      "Train Epoch: 6 [10240/37519 (27%)]\tLoss: 0.240064\n",
      "Train Epoch: 6 [10880/37519 (29%)]\tLoss: 0.057278\n",
      "Train Epoch: 6 [11520/37519 (31%)]\tLoss: 0.257644\n",
      "Train Epoch: 6 [12160/37519 (32%)]\tLoss: 0.146717\n",
      "Train Epoch: 6 [12800/37519 (34%)]\tLoss: 0.067754\n",
      "Train Epoch: 6 [13440/37519 (36%)]\tLoss: 0.138687\n",
      "Train Epoch: 6 [14080/37519 (37%)]\tLoss: 0.133691\n",
      "Train Epoch: 6 [14720/37519 (39%)]\tLoss: 0.108086\n",
      "Train Epoch: 6 [15360/37519 (41%)]\tLoss: 0.437237\n",
      "Train Epoch: 6 [16000/37519 (43%)]\tLoss: 0.113190\n",
      "Train Epoch: 6 [16640/37519 (44%)]\tLoss: 0.295276\n",
      "Train Epoch: 6 [17280/37519 (46%)]\tLoss: 0.269805\n",
      "Train Epoch: 6 [17920/37519 (48%)]\tLoss: 0.068031\n",
      "Train Epoch: 6 [18560/37519 (49%)]\tLoss: 0.163998\n",
      "Train Epoch: 6 [19200/37519 (51%)]\tLoss: 0.104394\n",
      "Train Epoch: 6 [19840/37519 (53%)]\tLoss: 0.051198\n",
      "Train Epoch: 6 [20480/37519 (55%)]\tLoss: 0.117985\n",
      "Train Epoch: 6 [21120/37519 (56%)]\tLoss: 0.238905\n",
      "Train Epoch: 6 [21760/37519 (58%)]\tLoss: 0.304094\n",
      "Train Epoch: 6 [22400/37519 (60%)]\tLoss: 0.064726\n",
      "Train Epoch: 6 [23040/37519 (61%)]\tLoss: 0.199043\n",
      "Train Epoch: 6 [23680/37519 (63%)]\tLoss: 0.181558\n",
      "Train Epoch: 6 [24320/37519 (65%)]\tLoss: 0.086973\n",
      "Train Epoch: 6 [24960/37519 (66%)]\tLoss: 0.180838\n",
      "Train Epoch: 6 [25600/37519 (68%)]\tLoss: 0.227965\n",
      "Train Epoch: 6 [26240/37519 (70%)]\tLoss: 0.034668\n",
      "Train Epoch: 6 [26880/37519 (72%)]\tLoss: 0.104957\n",
      "Train Epoch: 6 [27520/37519 (73%)]\tLoss: 0.289126\n",
      "Train Epoch: 6 [28160/37519 (75%)]\tLoss: 0.156583\n",
      "Train Epoch: 6 [28800/37519 (77%)]\tLoss: 0.106084\n",
      "Train Epoch: 6 [29440/37519 (78%)]\tLoss: 0.127004\n",
      "Train Epoch: 6 [30080/37519 (80%)]\tLoss: 0.184483\n",
      "Train Epoch: 6 [30720/37519 (82%)]\tLoss: 0.071080\n",
      "Train Epoch: 6 [31360/37519 (83%)]\tLoss: 0.043886\n",
      "Train Epoch: 6 [32000/37519 (85%)]\tLoss: 0.233310\n",
      "Train Epoch: 6 [32640/37519 (87%)]\tLoss: 0.219345\n",
      "Train Epoch: 6 [33280/37519 (89%)]\tLoss: 0.357761\n",
      "Train Epoch: 6 [33920/37519 (90%)]\tLoss: 0.093522\n",
      "Train Epoch: 6 [34560/37519 (92%)]\tLoss: 0.248499\n",
      "Train Epoch: 6 [35200/37519 (94%)]\tLoss: 0.076821\n",
      "Train Epoch: 6 [35840/37519 (95%)]\tLoss: 0.122879\n",
      "Train Epoch: 6 [36480/37519 (97%)]\tLoss: 0.097047\n",
      "Train Epoch: 6 [37120/37519 (99%)]\tLoss: 0.150634\n",
      "Train Epoch: 7 [0/37519 (0%)]\tLoss: 0.133409\n",
      "Train Epoch: 7 [640/37519 (2%)]\tLoss: 0.148449\n",
      "Train Epoch: 7 [1280/37519 (3%)]\tLoss: 0.126132\n",
      "Train Epoch: 7 [1920/37519 (5%)]\tLoss: 0.164062\n",
      "Train Epoch: 7 [2560/37519 (7%)]\tLoss: 0.117769\n",
      "Train Epoch: 7 [3200/37519 (9%)]\tLoss: 0.119234\n",
      "Train Epoch: 7 [3840/37519 (10%)]\tLoss: 0.173726\n",
      "Train Epoch: 7 [4480/37519 (12%)]\tLoss: 0.166909\n",
      "Train Epoch: 7 [5120/37519 (14%)]\tLoss: 0.219528\n",
      "Train Epoch: 7 [5760/37519 (15%)]\tLoss: 0.313464\n",
      "Train Epoch: 7 [6400/37519 (17%)]\tLoss: 0.344349\n",
      "Train Epoch: 7 [7040/37519 (19%)]\tLoss: 0.112507\n",
      "Train Epoch: 7 [7680/37519 (20%)]\tLoss: 0.141586\n",
      "Train Epoch: 7 [8320/37519 (22%)]\tLoss: 0.142345\n",
      "Train Epoch: 7 [8960/37519 (24%)]\tLoss: 0.219470\n",
      "Train Epoch: 7 [9600/37519 (26%)]\tLoss: 0.140829\n",
      "Train Epoch: 7 [10240/37519 (27%)]\tLoss: 0.196537\n",
      "Train Epoch: 7 [10880/37519 (29%)]\tLoss: 0.091298\n",
      "Train Epoch: 7 [11520/37519 (31%)]\tLoss: 0.058799\n",
      "Train Epoch: 7 [12160/37519 (32%)]\tLoss: 0.073008\n",
      "Train Epoch: 7 [12800/37519 (34%)]\tLoss: 0.068532\n",
      "Train Epoch: 7 [13440/37519 (36%)]\tLoss: 0.270722\n",
      "Train Epoch: 7 [14080/37519 (37%)]\tLoss: 0.176165\n",
      "Train Epoch: 7 [14720/37519 (39%)]\tLoss: 0.181137\n",
      "Train Epoch: 7 [15360/37519 (41%)]\tLoss: 0.169903\n",
      "Train Epoch: 7 [16000/37519 (43%)]\tLoss: 0.129632\n",
      "Train Epoch: 7 [16640/37519 (44%)]\tLoss: 0.194548\n",
      "Train Epoch: 7 [17280/37519 (46%)]\tLoss: 0.163146\n",
      "Train Epoch: 7 [17920/37519 (48%)]\tLoss: 0.213998\n",
      "Train Epoch: 7 [18560/37519 (49%)]\tLoss: 0.147430\n",
      "Train Epoch: 7 [19200/37519 (51%)]\tLoss: 0.228771\n",
      "Train Epoch: 7 [19840/37519 (53%)]\tLoss: 0.119240\n",
      "Train Epoch: 7 [20480/37519 (55%)]\tLoss: 0.152431\n",
      "Train Epoch: 7 [21120/37519 (56%)]\tLoss: 0.190994\n",
      "Train Epoch: 7 [21760/37519 (58%)]\tLoss: 0.088599\n",
      "Train Epoch: 7 [22400/37519 (60%)]\tLoss: 0.119294\n",
      "Train Epoch: 7 [23040/37519 (61%)]\tLoss: 0.160286\n",
      "Train Epoch: 7 [23680/37519 (63%)]\tLoss: 0.233376\n",
      "Train Epoch: 7 [24320/37519 (65%)]\tLoss: 0.181668\n",
      "Train Epoch: 7 [24960/37519 (66%)]\tLoss: 0.152227\n",
      "Train Epoch: 7 [25600/37519 (68%)]\tLoss: 0.060524\n",
      "Train Epoch: 7 [26240/37519 (70%)]\tLoss: 0.086387\n",
      "Train Epoch: 7 [26880/37519 (72%)]\tLoss: 0.067724\n",
      "Train Epoch: 7 [27520/37519 (73%)]\tLoss: 0.075167\n",
      "Train Epoch: 7 [28160/37519 (75%)]\tLoss: 0.151750\n",
      "Train Epoch: 7 [28800/37519 (77%)]\tLoss: 0.188786\n",
      "Train Epoch: 7 [29440/37519 (78%)]\tLoss: 0.179026\n",
      "Train Epoch: 7 [30080/37519 (80%)]\tLoss: 0.111351\n",
      "Train Epoch: 7 [30720/37519 (82%)]\tLoss: 0.109507\n",
      "Train Epoch: 7 [31360/37519 (83%)]\tLoss: 0.100455\n",
      "Train Epoch: 7 [32000/37519 (85%)]\tLoss: 0.280495\n",
      "Train Epoch: 7 [32640/37519 (87%)]\tLoss: 0.268028\n",
      "Train Epoch: 7 [33280/37519 (89%)]\tLoss: 0.273940\n",
      "Train Epoch: 7 [33920/37519 (90%)]\tLoss: 0.101901\n",
      "Train Epoch: 7 [34560/37519 (92%)]\tLoss: 0.153816\n",
      "Train Epoch: 7 [35200/37519 (94%)]\tLoss: 0.106712\n",
      "Train Epoch: 7 [35840/37519 (95%)]\tLoss: 0.075949\n",
      "Train Epoch: 7 [36480/37519 (97%)]\tLoss: 0.130718\n",
      "Train Epoch: 7 [37120/37519 (99%)]\tLoss: 0.101864\n",
      "Train Epoch: 8 [0/37519 (0%)]\tLoss: 0.121321\n",
      "Train Epoch: 8 [640/37519 (2%)]\tLoss: 0.098772\n",
      "Train Epoch: 8 [1280/37519 (3%)]\tLoss: 0.091529\n",
      "Train Epoch: 8 [1920/37519 (5%)]\tLoss: 0.081297\n",
      "Train Epoch: 8 [2560/37519 (7%)]\tLoss: 0.434629\n",
      "Train Epoch: 8 [3200/37519 (9%)]\tLoss: 0.136527\n",
      "Train Epoch: 8 [3840/37519 (10%)]\tLoss: 0.383871\n",
      "Train Epoch: 8 [4480/37519 (12%)]\tLoss: 0.250578\n",
      "Train Epoch: 8 [5120/37519 (14%)]\tLoss: 0.068566\n",
      "Train Epoch: 8 [5760/37519 (15%)]\tLoss: 0.071986\n",
      "Train Epoch: 8 [6400/37519 (17%)]\tLoss: 0.150462\n",
      "Train Epoch: 8 [7040/37519 (19%)]\tLoss: 0.121750\n",
      "Train Epoch: 8 [7680/37519 (20%)]\tLoss: 0.071750\n",
      "Train Epoch: 8 [8320/37519 (22%)]\tLoss: 0.159848\n",
      "Train Epoch: 8 [8960/37519 (24%)]\tLoss: 0.045040\n",
      "Train Epoch: 8 [9600/37519 (26%)]\tLoss: 0.079116\n",
      "Train Epoch: 8 [10240/37519 (27%)]\tLoss: 0.092812\n",
      "Train Epoch: 8 [10880/37519 (29%)]\tLoss: 0.085569\n",
      "Train Epoch: 8 [11520/37519 (31%)]\tLoss: 0.144518\n",
      "Train Epoch: 8 [12160/37519 (32%)]\tLoss: 0.116141\n",
      "Train Epoch: 8 [12800/37519 (34%)]\tLoss: 0.108939\n",
      "Train Epoch: 8 [13440/37519 (36%)]\tLoss: 0.242678\n",
      "Train Epoch: 8 [14080/37519 (37%)]\tLoss: 0.232670\n",
      "Train Epoch: 8 [14720/37519 (39%)]\tLoss: 0.167282\n",
      "Train Epoch: 8 [15360/37519 (41%)]\tLoss: 0.180998\n",
      "Train Epoch: 8 [16000/37519 (43%)]\tLoss: 0.167443\n",
      "Train Epoch: 8 [16640/37519 (44%)]\tLoss: 0.144619\n",
      "Train Epoch: 8 [17280/37519 (46%)]\tLoss: 0.142493\n",
      "Train Epoch: 8 [17920/37519 (48%)]\tLoss: 0.200949\n",
      "Train Epoch: 8 [18560/37519 (49%)]\tLoss: 0.094061\n",
      "Train Epoch: 8 [19200/37519 (51%)]\tLoss: 0.060501\n",
      "Train Epoch: 8 [19840/37519 (53%)]\tLoss: 0.237331\n",
      "Train Epoch: 8 [20480/37519 (55%)]\tLoss: 0.051497\n",
      "Train Epoch: 8 [21120/37519 (56%)]\tLoss: 0.210492\n",
      "Train Epoch: 8 [21760/37519 (58%)]\tLoss: 0.135303\n",
      "Train Epoch: 8 [22400/37519 (60%)]\tLoss: 0.097011\n",
      "Train Epoch: 8 [23040/37519 (61%)]\tLoss: 0.053203\n",
      "Train Epoch: 8 [23680/37519 (63%)]\tLoss: 0.122137\n",
      "Train Epoch: 8 [24320/37519 (65%)]\tLoss: 0.069529\n",
      "Train Epoch: 8 [24960/37519 (66%)]\tLoss: 0.154389\n",
      "Train Epoch: 8 [25600/37519 (68%)]\tLoss: 0.140488\n",
      "Train Epoch: 8 [26240/37519 (70%)]\tLoss: 0.217844\n",
      "Train Epoch: 8 [26880/37519 (72%)]\tLoss: 0.162652\n",
      "Train Epoch: 8 [27520/37519 (73%)]\tLoss: 0.140632\n",
      "Train Epoch: 8 [28160/37519 (75%)]\tLoss: 0.148830\n",
      "Train Epoch: 8 [28800/37519 (77%)]\tLoss: 0.110831\n",
      "Train Epoch: 8 [29440/37519 (78%)]\tLoss: 0.169411\n",
      "Train Epoch: 8 [30080/37519 (80%)]\tLoss: 0.178185\n",
      "Train Epoch: 8 [30720/37519 (82%)]\tLoss: 0.166380\n",
      "Train Epoch: 8 [31360/37519 (83%)]\tLoss: 0.129879\n",
      "Train Epoch: 8 [32000/37519 (85%)]\tLoss: 0.077667\n",
      "Train Epoch: 8 [32640/37519 (87%)]\tLoss: 0.251699\n",
      "Train Epoch: 8 [33280/37519 (89%)]\tLoss: 0.059078\n",
      "Train Epoch: 8 [33920/37519 (90%)]\tLoss: 0.108025\n",
      "Train Epoch: 8 [34560/37519 (92%)]\tLoss: 0.120468\n",
      "Train Epoch: 8 [35200/37519 (94%)]\tLoss: 0.164494\n",
      "Train Epoch: 8 [35840/37519 (95%)]\tLoss: 0.219841\n",
      "Train Epoch: 8 [36480/37519 (97%)]\tLoss: 0.183127\n",
      "Train Epoch: 8 [37120/37519 (99%)]\tLoss: 0.068526\n",
      "Train Epoch: 9 [0/37519 (0%)]\tLoss: 0.122960\n",
      "Train Epoch: 9 [640/37519 (2%)]\tLoss: 0.066612\n",
      "Train Epoch: 9 [1280/37519 (3%)]\tLoss: 0.146850\n",
      "Train Epoch: 9 [1920/37519 (5%)]\tLoss: 0.041659\n",
      "Train Epoch: 9 [2560/37519 (7%)]\tLoss: 0.104515\n",
      "Train Epoch: 9 [3200/37519 (9%)]\tLoss: 0.069349\n",
      "Train Epoch: 9 [3840/37519 (10%)]\tLoss: 0.218820\n",
      "Train Epoch: 9 [4480/37519 (12%)]\tLoss: 0.107240\n",
      "Train Epoch: 9 [5120/37519 (14%)]\tLoss: 0.120265\n",
      "Train Epoch: 9 [5760/37519 (15%)]\tLoss: 0.490538\n",
      "Train Epoch: 9 [6400/37519 (17%)]\tLoss: 0.105361\n",
      "Train Epoch: 9 [7040/37519 (19%)]\tLoss: 0.138317\n",
      "Train Epoch: 9 [7680/37519 (20%)]\tLoss: 0.166178\n",
      "Train Epoch: 9 [8320/37519 (22%)]\tLoss: 0.076235\n",
      "Train Epoch: 9 [8960/37519 (24%)]\tLoss: 0.203228\n",
      "Train Epoch: 9 [9600/37519 (26%)]\tLoss: 0.148982\n",
      "Train Epoch: 9 [10240/37519 (27%)]\tLoss: 0.078809\n",
      "Train Epoch: 9 [10880/37519 (29%)]\tLoss: 0.082449\n",
      "Train Epoch: 9 [11520/37519 (31%)]\tLoss: 0.162218\n",
      "Train Epoch: 9 [12160/37519 (32%)]\tLoss: 0.193892\n",
      "Train Epoch: 9 [12800/37519 (34%)]\tLoss: 0.123467\n",
      "Train Epoch: 9 [13440/37519 (36%)]\tLoss: 0.091088\n",
      "Train Epoch: 9 [14080/37519 (37%)]\tLoss: 0.097720\n",
      "Train Epoch: 9 [14720/37519 (39%)]\tLoss: 0.036159\n",
      "Train Epoch: 9 [15360/37519 (41%)]\tLoss: 0.084839\n",
      "Train Epoch: 9 [16000/37519 (43%)]\tLoss: 0.112033\n",
      "Train Epoch: 9 [16640/37519 (44%)]\tLoss: 0.119683\n",
      "Train Epoch: 9 [17280/37519 (46%)]\tLoss: 0.127196\n",
      "Train Epoch: 9 [17920/37519 (48%)]\tLoss: 0.056834\n",
      "Train Epoch: 9 [18560/37519 (49%)]\tLoss: 0.049706\n",
      "Train Epoch: 9 [19200/37519 (51%)]\tLoss: 0.118831\n",
      "Train Epoch: 9 [19840/37519 (53%)]\tLoss: 0.125090\n",
      "Train Epoch: 9 [20480/37519 (55%)]\tLoss: 0.210734\n",
      "Train Epoch: 9 [21120/37519 (56%)]\tLoss: 0.245312\n",
      "Train Epoch: 9 [21760/37519 (58%)]\tLoss: 0.139273\n",
      "Train Epoch: 9 [22400/37519 (60%)]\tLoss: 0.113429\n",
      "Train Epoch: 9 [23040/37519 (61%)]\tLoss: 0.159157\n",
      "Train Epoch: 9 [23680/37519 (63%)]\tLoss: 0.112537\n",
      "Train Epoch: 9 [24320/37519 (65%)]\tLoss: 0.105635\n",
      "Train Epoch: 9 [24960/37519 (66%)]\tLoss: 0.120130\n",
      "Train Epoch: 9 [25600/37519 (68%)]\tLoss: 0.111422\n",
      "Train Epoch: 9 [26240/37519 (70%)]\tLoss: 0.047990\n",
      "Train Epoch: 9 [26880/37519 (72%)]\tLoss: 0.048031\n",
      "Train Epoch: 9 [27520/37519 (73%)]\tLoss: 0.290079\n",
      "Train Epoch: 9 [28160/37519 (75%)]\tLoss: 0.160602\n",
      "Train Epoch: 9 [28800/37519 (77%)]\tLoss: 0.081497\n",
      "Train Epoch: 9 [29440/37519 (78%)]\tLoss: 0.074038\n",
      "Train Epoch: 9 [30080/37519 (80%)]\tLoss: 0.125106\n",
      "Train Epoch: 9 [30720/37519 (82%)]\tLoss: 0.115726\n",
      "Train Epoch: 9 [31360/37519 (83%)]\tLoss: 0.145632\n",
      "Train Epoch: 9 [32000/37519 (85%)]\tLoss: 0.083244\n",
      "Train Epoch: 9 [32640/37519 (87%)]\tLoss: 0.082238\n",
      "Train Epoch: 9 [33280/37519 (89%)]\tLoss: 0.138120\n",
      "Train Epoch: 9 [33920/37519 (90%)]\tLoss: 0.125297\n",
      "Train Epoch: 9 [34560/37519 (92%)]\tLoss: 0.181170\n",
      "Train Epoch: 9 [35200/37519 (94%)]\tLoss: 0.166631\n",
      "Train Epoch: 9 [35840/37519 (95%)]\tLoss: 0.089010\n",
      "Train Epoch: 9 [36480/37519 (97%)]\tLoss: 0.090843\n",
      "Train Epoch: 9 [37120/37519 (99%)]\tLoss: 0.132376\n",
      "Train Epoch: 10 [0/37519 (0%)]\tLoss: 0.284591\n",
      "Train Epoch: 10 [640/37519 (2%)]\tLoss: 0.247374\n",
      "Train Epoch: 10 [1280/37519 (3%)]\tLoss: 0.167259\n",
      "Train Epoch: 10 [1920/37519 (5%)]\tLoss: 0.174184\n",
      "Train Epoch: 10 [2560/37519 (7%)]\tLoss: 0.120198\n",
      "Train Epoch: 10 [3200/37519 (9%)]\tLoss: 0.124725\n",
      "Train Epoch: 10 [3840/37519 (10%)]\tLoss: 0.156434\n",
      "Train Epoch: 10 [4480/37519 (12%)]\tLoss: 0.101112\n",
      "Train Epoch: 10 [5120/37519 (14%)]\tLoss: 0.057785\n",
      "Train Epoch: 10 [5760/37519 (15%)]\tLoss: 0.181650\n",
      "Train Epoch: 10 [6400/37519 (17%)]\tLoss: 0.136926\n",
      "Train Epoch: 10 [7040/37519 (19%)]\tLoss: 0.169789\n",
      "Train Epoch: 10 [7680/37519 (20%)]\tLoss: 0.079713\n",
      "Train Epoch: 10 [8320/37519 (22%)]\tLoss: 0.045314\n",
      "Train Epoch: 10 [8960/37519 (24%)]\tLoss: 0.084461\n",
      "Train Epoch: 10 [9600/37519 (26%)]\tLoss: 0.127870\n",
      "Train Epoch: 10 [10240/37519 (27%)]\tLoss: 0.138543\n",
      "Train Epoch: 10 [10880/37519 (29%)]\tLoss: 0.067938\n",
      "Train Epoch: 10 [11520/37519 (31%)]\tLoss: 0.241426\n",
      "Train Epoch: 10 [12160/37519 (32%)]\tLoss: 0.049511\n",
      "Train Epoch: 10 [12800/37519 (34%)]\tLoss: 0.137744\n",
      "Train Epoch: 10 [13440/37519 (36%)]\tLoss: 0.267161\n",
      "Train Epoch: 10 [14080/37519 (37%)]\tLoss: 0.100983\n",
      "Train Epoch: 10 [14720/37519 (39%)]\tLoss: 0.137330\n",
      "Train Epoch: 10 [15360/37519 (41%)]\tLoss: 0.139254\n",
      "Train Epoch: 10 [16000/37519 (43%)]\tLoss: 0.100119\n",
      "Train Epoch: 10 [16640/37519 (44%)]\tLoss: 0.276039\n",
      "Train Epoch: 10 [17280/37519 (46%)]\tLoss: 0.120797\n",
      "Train Epoch: 10 [17920/37519 (48%)]\tLoss: 0.095558\n",
      "Train Epoch: 10 [18560/37519 (49%)]\tLoss: 0.076369\n",
      "Train Epoch: 10 [19200/37519 (51%)]\tLoss: 0.069105\n",
      "Train Epoch: 10 [19840/37519 (53%)]\tLoss: 0.088079\n",
      "Train Epoch: 10 [20480/37519 (55%)]\tLoss: 0.121303\n",
      "Train Epoch: 10 [21120/37519 (56%)]\tLoss: 0.117062\n",
      "Train Epoch: 10 [21760/37519 (58%)]\tLoss: 0.059483\n",
      "Train Epoch: 10 [22400/37519 (60%)]\tLoss: 0.089755\n",
      "Train Epoch: 10 [23040/37519 (61%)]\tLoss: 0.097938\n",
      "Train Epoch: 10 [23680/37519 (63%)]\tLoss: 0.244210\n",
      "Train Epoch: 10 [24320/37519 (65%)]\tLoss: 0.211149\n",
      "Train Epoch: 10 [24960/37519 (66%)]\tLoss: 0.064710\n",
      "Train Epoch: 10 [25600/37519 (68%)]\tLoss: 0.199048\n",
      "Train Epoch: 10 [26240/37519 (70%)]\tLoss: 0.147554\n",
      "Train Epoch: 10 [26880/37519 (72%)]\tLoss: 0.151419\n",
      "Train Epoch: 10 [27520/37519 (73%)]\tLoss: 0.029647\n",
      "Train Epoch: 10 [28160/37519 (75%)]\tLoss: 0.066018\n",
      "Train Epoch: 10 [28800/37519 (77%)]\tLoss: 0.147032\n",
      "Train Epoch: 10 [29440/37519 (78%)]\tLoss: 0.272995\n",
      "Train Epoch: 10 [30080/37519 (80%)]\tLoss: 0.169402\n",
      "Train Epoch: 10 [30720/37519 (82%)]\tLoss: 0.070692\n",
      "Train Epoch: 10 [31360/37519 (83%)]\tLoss: 0.031836\n",
      "Train Epoch: 10 [32000/37519 (85%)]\tLoss: 0.263383\n",
      "Train Epoch: 10 [32640/37519 (87%)]\tLoss: 0.114285\n",
      "Train Epoch: 10 [33280/37519 (89%)]\tLoss: 0.169669\n",
      "Train Epoch: 10 [33920/37519 (90%)]\tLoss: 0.366331\n",
      "Train Epoch: 10 [34560/37519 (92%)]\tLoss: 0.168820\n",
      "Train Epoch: 10 [35200/37519 (94%)]\tLoss: 0.133585\n",
      "Train Epoch: 10 [35840/37519 (95%)]\tLoss: 0.225105\n",
      "Train Epoch: 10 [36480/37519 (97%)]\tLoss: 0.134314\n",
      "Train Epoch: 10 [37120/37519 (99%)]\tLoss: 0.103573\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/22481 (0%)]\tLoss: 0.420782\n",
      "Train Epoch: 1 [640/22481 (3%)]\tLoss: 0.154172\n",
      "Train Epoch: 1 [1280/22481 (6%)]\tLoss: 0.184140\n",
      "Train Epoch: 1 [1920/22481 (9%)]\tLoss: 0.098950\n",
      "Train Epoch: 1 [2560/22481 (11%)]\tLoss: 0.125114\n",
      "Train Epoch: 1 [3200/22481 (14%)]\tLoss: 0.133332\n",
      "Train Epoch: 1 [3840/22481 (17%)]\tLoss: 0.183549\n",
      "Train Epoch: 1 [4480/22481 (20%)]\tLoss: 0.294058\n",
      "Train Epoch: 1 [5120/22481 (23%)]\tLoss: 0.150743\n",
      "Train Epoch: 1 [5760/22481 (26%)]\tLoss: 0.112487\n",
      "Train Epoch: 1 [6400/22481 (28%)]\tLoss: 0.120448\n",
      "Train Epoch: 1 [7040/22481 (31%)]\tLoss: 0.186540\n",
      "Train Epoch: 1 [7680/22481 (34%)]\tLoss: 0.290270\n",
      "Train Epoch: 1 [8320/22481 (37%)]\tLoss: 0.253353\n",
      "Train Epoch: 1 [8960/22481 (40%)]\tLoss: 0.078490\n",
      "Train Epoch: 1 [9600/22481 (43%)]\tLoss: 0.225681\n",
      "Train Epoch: 1 [10240/22481 (45%)]\tLoss: 0.131984\n",
      "Train Epoch: 1 [10880/22481 (48%)]\tLoss: 0.036342\n",
      "Train Epoch: 1 [11520/22481 (51%)]\tLoss: 0.162678\n",
      "Train Epoch: 1 [12160/22481 (54%)]\tLoss: 0.050979\n",
      "Train Epoch: 1 [12800/22481 (57%)]\tLoss: 0.221029\n",
      "Train Epoch: 1 [13440/22481 (60%)]\tLoss: 0.275851\n",
      "Train Epoch: 1 [14080/22481 (62%)]\tLoss: 0.109235\n",
      "Train Epoch: 1 [14720/22481 (65%)]\tLoss: 0.088769\n",
      "Train Epoch: 1 [15360/22481 (68%)]\tLoss: 0.021047\n",
      "Train Epoch: 1 [16000/22481 (71%)]\tLoss: 0.107846\n",
      "Train Epoch: 1 [16640/22481 (74%)]\tLoss: 0.037249\n",
      "Train Epoch: 1 [17280/22481 (77%)]\tLoss: 0.103453\n",
      "Train Epoch: 1 [17920/22481 (80%)]\tLoss: 0.140824\n",
      "Train Epoch: 1 [18560/22481 (82%)]\tLoss: 0.104270\n",
      "Train Epoch: 1 [19200/22481 (85%)]\tLoss: 0.099788\n",
      "Train Epoch: 1 [19840/22481 (88%)]\tLoss: 0.072369\n",
      "Train Epoch: 1 [20480/22481 (91%)]\tLoss: 0.090821\n",
      "Train Epoch: 1 [21120/22481 (94%)]\tLoss: 0.153455\n",
      "Train Epoch: 1 [21760/22481 (97%)]\tLoss: 0.097565\n",
      "Train Epoch: 1 [22400/22481 (99%)]\tLoss: 0.095129\n",
      "Train Epoch: 2 [0/22481 (0%)]\tLoss: 0.128563\n",
      "Train Epoch: 2 [640/22481 (3%)]\tLoss: 0.153617\n",
      "Train Epoch: 2 [1280/22481 (6%)]\tLoss: 0.047690\n",
      "Train Epoch: 2 [1920/22481 (9%)]\tLoss: 0.292438\n",
      "Train Epoch: 2 [2560/22481 (11%)]\tLoss: 0.219023\n",
      "Train Epoch: 2 [3200/22481 (14%)]\tLoss: 0.385536\n",
      "Train Epoch: 2 [3840/22481 (17%)]\tLoss: 0.183981\n",
      "Train Epoch: 2 [4480/22481 (20%)]\tLoss: 0.050746\n",
      "Train Epoch: 2 [5120/22481 (23%)]\tLoss: 0.082277\n",
      "Train Epoch: 2 [5760/22481 (26%)]\tLoss: 0.215438\n",
      "Train Epoch: 2 [6400/22481 (28%)]\tLoss: 0.125994\n",
      "Train Epoch: 2 [7040/22481 (31%)]\tLoss: 0.040262\n",
      "Train Epoch: 2 [7680/22481 (34%)]\tLoss: 0.154389\n",
      "Train Epoch: 2 [8320/22481 (37%)]\tLoss: 0.258629\n",
      "Train Epoch: 2 [8960/22481 (40%)]\tLoss: 0.187404\n",
      "Train Epoch: 2 [9600/22481 (43%)]\tLoss: 0.198813\n",
      "Train Epoch: 2 [10240/22481 (45%)]\tLoss: 0.033700\n",
      "Train Epoch: 2 [10880/22481 (48%)]\tLoss: 0.215834\n",
      "Train Epoch: 2 [11520/22481 (51%)]\tLoss: 0.041555\n",
      "Train Epoch: 2 [12160/22481 (54%)]\tLoss: 0.268479\n",
      "Train Epoch: 2 [12800/22481 (57%)]\tLoss: 0.140247\n",
      "Train Epoch: 2 [13440/22481 (60%)]\tLoss: 0.242003\n",
      "Train Epoch: 2 [14080/22481 (62%)]\tLoss: 0.085999\n",
      "Train Epoch: 2 [14720/22481 (65%)]\tLoss: 0.066210\n",
      "Train Epoch: 2 [15360/22481 (68%)]\tLoss: 0.223877\n",
      "Train Epoch: 2 [16000/22481 (71%)]\tLoss: 0.073492\n",
      "Train Epoch: 2 [16640/22481 (74%)]\tLoss: 0.043006\n",
      "Train Epoch: 2 [17280/22481 (77%)]\tLoss: 0.209868\n",
      "Train Epoch: 2 [17920/22481 (80%)]\tLoss: 0.128632\n",
      "Train Epoch: 2 [18560/22481 (82%)]\tLoss: 0.031496\n",
      "Train Epoch: 2 [19200/22481 (85%)]\tLoss: 0.151739\n",
      "Train Epoch: 2 [19840/22481 (88%)]\tLoss: 0.096998\n",
      "Train Epoch: 2 [20480/22481 (91%)]\tLoss: 0.093665\n",
      "Train Epoch: 2 [21120/22481 (94%)]\tLoss: 0.167370\n",
      "Train Epoch: 2 [21760/22481 (97%)]\tLoss: 0.121714\n",
      "Train Epoch: 2 [22400/22481 (99%)]\tLoss: 0.093016\n",
      "Train Epoch: 3 [0/22481 (0%)]\tLoss: 0.045795\n",
      "Train Epoch: 3 [640/22481 (3%)]\tLoss: 0.105152\n",
      "Train Epoch: 3 [1280/22481 (6%)]\tLoss: 0.108758\n",
      "Train Epoch: 3 [1920/22481 (9%)]\tLoss: 0.084510\n",
      "Train Epoch: 3 [2560/22481 (11%)]\tLoss: 0.082197\n",
      "Train Epoch: 3 [3200/22481 (14%)]\tLoss: 0.318843\n",
      "Train Epoch: 3 [3840/22481 (17%)]\tLoss: 0.164639\n",
      "Train Epoch: 3 [4480/22481 (20%)]\tLoss: 0.160217\n",
      "Train Epoch: 3 [5120/22481 (23%)]\tLoss: 0.094062\n",
      "Train Epoch: 3 [5760/22481 (26%)]\tLoss: 0.107471\n",
      "Train Epoch: 3 [6400/22481 (28%)]\tLoss: 0.097324\n",
      "Train Epoch: 3 [7040/22481 (31%)]\tLoss: 0.087070\n",
      "Train Epoch: 3 [7680/22481 (34%)]\tLoss: 0.280331\n",
      "Train Epoch: 3 [8320/22481 (37%)]\tLoss: 0.192567\n",
      "Train Epoch: 3 [8960/22481 (40%)]\tLoss: 0.081710\n",
      "Train Epoch: 3 [9600/22481 (43%)]\tLoss: 0.179478\n",
      "Train Epoch: 3 [10240/22481 (45%)]\tLoss: 0.171643\n",
      "Train Epoch: 3 [10880/22481 (48%)]\tLoss: 0.184493\n",
      "Train Epoch: 3 [11520/22481 (51%)]\tLoss: 0.174126\n",
      "Train Epoch: 3 [12160/22481 (54%)]\tLoss: 0.246349\n",
      "Train Epoch: 3 [12800/22481 (57%)]\tLoss: 0.088187\n",
      "Train Epoch: 3 [13440/22481 (60%)]\tLoss: 0.093749\n",
      "Train Epoch: 3 [14080/22481 (62%)]\tLoss: 0.291873\n",
      "Train Epoch: 3 [14720/22481 (65%)]\tLoss: 0.207199\n",
      "Train Epoch: 3 [15360/22481 (68%)]\tLoss: 0.113733\n",
      "Train Epoch: 3 [16000/22481 (71%)]\tLoss: 0.288431\n",
      "Train Epoch: 3 [16640/22481 (74%)]\tLoss: 0.062735\n",
      "Train Epoch: 3 [17280/22481 (77%)]\tLoss: 0.117770\n",
      "Train Epoch: 3 [17920/22481 (80%)]\tLoss: 0.046009\n",
      "Train Epoch: 3 [18560/22481 (82%)]\tLoss: 0.060777\n",
      "Train Epoch: 3 [19200/22481 (85%)]\tLoss: 0.100326\n",
      "Train Epoch: 3 [19840/22481 (88%)]\tLoss: 0.150362\n",
      "Train Epoch: 3 [20480/22481 (91%)]\tLoss: 0.191805\n",
      "Train Epoch: 3 [21120/22481 (94%)]\tLoss: 0.096465\n",
      "Train Epoch: 3 [21760/22481 (97%)]\tLoss: 0.306244\n",
      "Train Epoch: 3 [22400/22481 (99%)]\tLoss: 0.106453\n",
      "Train Epoch: 4 [0/22481 (0%)]\tLoss: 0.079330\n",
      "Train Epoch: 4 [640/22481 (3%)]\tLoss: 0.164588\n",
      "Train Epoch: 4 [1280/22481 (6%)]\tLoss: 0.059490\n",
      "Train Epoch: 4 [1920/22481 (9%)]\tLoss: 0.055121\n",
      "Train Epoch: 4 [2560/22481 (11%)]\tLoss: 0.144673\n",
      "Train Epoch: 4 [3200/22481 (14%)]\tLoss: 0.019343\n",
      "Train Epoch: 4 [3840/22481 (17%)]\tLoss: 0.143931\n",
      "Train Epoch: 4 [4480/22481 (20%)]\tLoss: 0.277011\n",
      "Train Epoch: 4 [5120/22481 (23%)]\tLoss: 0.076013\n",
      "Train Epoch: 4 [5760/22481 (26%)]\tLoss: 0.314081\n",
      "Train Epoch: 4 [6400/22481 (28%)]\tLoss: 0.207772\n",
      "Train Epoch: 4 [7040/22481 (31%)]\tLoss: 0.132334\n",
      "Train Epoch: 4 [7680/22481 (34%)]\tLoss: 0.167834\n",
      "Train Epoch: 4 [8320/22481 (37%)]\tLoss: 0.108354\n",
      "Train Epoch: 4 [8960/22481 (40%)]\tLoss: 0.133090\n",
      "Train Epoch: 4 [9600/22481 (43%)]\tLoss: 0.101576\n",
      "Train Epoch: 4 [10240/22481 (45%)]\tLoss: 0.129563\n",
      "Train Epoch: 4 [10880/22481 (48%)]\tLoss: 0.028916\n",
      "Train Epoch: 4 [11520/22481 (51%)]\tLoss: 0.261388\n",
      "Train Epoch: 4 [12160/22481 (54%)]\tLoss: 0.093402\n",
      "Train Epoch: 4 [12800/22481 (57%)]\tLoss: 0.144358\n",
      "Train Epoch: 4 [13440/22481 (60%)]\tLoss: 0.038834\n",
      "Train Epoch: 4 [14080/22481 (62%)]\tLoss: 0.153891\n",
      "Train Epoch: 4 [14720/22481 (65%)]\tLoss: 0.115972\n",
      "Train Epoch: 4 [15360/22481 (68%)]\tLoss: 0.354275\n",
      "Train Epoch: 4 [16000/22481 (71%)]\tLoss: 0.357353\n",
      "Train Epoch: 4 [16640/22481 (74%)]\tLoss: 0.105454\n",
      "Train Epoch: 4 [17280/22481 (77%)]\tLoss: 0.027233\n",
      "Train Epoch: 4 [17920/22481 (80%)]\tLoss: 0.344780\n",
      "Train Epoch: 4 [18560/22481 (82%)]\tLoss: 0.087130\n",
      "Train Epoch: 4 [19200/22481 (85%)]\tLoss: 0.105946\n",
      "Train Epoch: 4 [19840/22481 (88%)]\tLoss: 0.108833\n",
      "Train Epoch: 4 [20480/22481 (91%)]\tLoss: 0.110095\n",
      "Train Epoch: 4 [21120/22481 (94%)]\tLoss: 0.200248\n",
      "Train Epoch: 4 [21760/22481 (97%)]\tLoss: 0.197808\n",
      "Train Epoch: 4 [22400/22481 (99%)]\tLoss: 0.106323\n",
      "Train Epoch: 5 [0/22481 (0%)]\tLoss: 0.044887\n",
      "Train Epoch: 5 [640/22481 (3%)]\tLoss: 0.074859\n",
      "Train Epoch: 5 [1280/22481 (6%)]\tLoss: 0.142928\n",
      "Train Epoch: 5 [1920/22481 (9%)]\tLoss: 0.036973\n",
      "Train Epoch: 5 [2560/22481 (11%)]\tLoss: 0.069726\n",
      "Train Epoch: 5 [3200/22481 (14%)]\tLoss: 0.105941\n",
      "Train Epoch: 5 [3840/22481 (17%)]\tLoss: 0.121639\n",
      "Train Epoch: 5 [4480/22481 (20%)]\tLoss: 0.156844\n",
      "Train Epoch: 5 [5120/22481 (23%)]\tLoss: 0.194392\n",
      "Train Epoch: 5 [5760/22481 (26%)]\tLoss: 0.132886\n",
      "Train Epoch: 5 [6400/22481 (28%)]\tLoss: 0.066842\n",
      "Train Epoch: 5 [7040/22481 (31%)]\tLoss: 0.114160\n",
      "Train Epoch: 5 [7680/22481 (34%)]\tLoss: 0.115742\n",
      "Train Epoch: 5 [8320/22481 (37%)]\tLoss: 0.039658\n",
      "Train Epoch: 5 [8960/22481 (40%)]\tLoss: 0.111779\n",
      "Train Epoch: 5 [9600/22481 (43%)]\tLoss: 0.119429\n",
      "Train Epoch: 5 [10240/22481 (45%)]\tLoss: 0.172044\n",
      "Train Epoch: 5 [10880/22481 (48%)]\tLoss: 0.169539\n",
      "Train Epoch: 5 [11520/22481 (51%)]\tLoss: 0.161721\n",
      "Train Epoch: 5 [12160/22481 (54%)]\tLoss: 0.080451\n",
      "Train Epoch: 5 [12800/22481 (57%)]\tLoss: 0.227994\n",
      "Train Epoch: 5 [13440/22481 (60%)]\tLoss: 0.121732\n",
      "Train Epoch: 5 [14080/22481 (62%)]\tLoss: 0.111531\n",
      "Train Epoch: 5 [14720/22481 (65%)]\tLoss: 0.074213\n",
      "Train Epoch: 5 [15360/22481 (68%)]\tLoss: 0.088532\n",
      "Train Epoch: 5 [16000/22481 (71%)]\tLoss: 0.079146\n",
      "Train Epoch: 5 [16640/22481 (74%)]\tLoss: 0.203240\n",
      "Train Epoch: 5 [17280/22481 (77%)]\tLoss: 0.045792\n",
      "Train Epoch: 5 [17920/22481 (80%)]\tLoss: 0.127453\n",
      "Train Epoch: 5 [18560/22481 (82%)]\tLoss: 0.143878\n",
      "Train Epoch: 5 [19200/22481 (85%)]\tLoss: 0.208291\n",
      "Train Epoch: 5 [19840/22481 (88%)]\tLoss: 0.157675\n",
      "Train Epoch: 5 [20480/22481 (91%)]\tLoss: 0.104352\n",
      "Train Epoch: 5 [21120/22481 (94%)]\tLoss: 0.139445\n",
      "Train Epoch: 5 [21760/22481 (97%)]\tLoss: 0.091196\n",
      "Train Epoch: 5 [22400/22481 (99%)]\tLoss: 0.169848\n",
      "Train Epoch: 6 [0/22481 (0%)]\tLoss: 0.132402\n",
      "Train Epoch: 6 [640/22481 (3%)]\tLoss: 0.220238\n",
      "Train Epoch: 6 [1280/22481 (6%)]\tLoss: 0.039094\n",
      "Train Epoch: 6 [1920/22481 (9%)]\tLoss: 0.076682\n",
      "Train Epoch: 6 [2560/22481 (11%)]\tLoss: 0.173023\n",
      "Train Epoch: 6 [3200/22481 (14%)]\tLoss: 0.172317\n",
      "Train Epoch: 6 [3840/22481 (17%)]\tLoss: 0.108333\n",
      "Train Epoch: 6 [4480/22481 (20%)]\tLoss: 0.074456\n",
      "Train Epoch: 6 [5120/22481 (23%)]\tLoss: 0.047411\n",
      "Train Epoch: 6 [5760/22481 (26%)]\tLoss: 0.115207\n",
      "Train Epoch: 6 [6400/22481 (28%)]\tLoss: 0.100110\n",
      "Train Epoch: 6 [7040/22481 (31%)]\tLoss: 0.094331\n",
      "Train Epoch: 6 [7680/22481 (34%)]\tLoss: 0.147754\n",
      "Train Epoch: 6 [8320/22481 (37%)]\tLoss: 0.056909\n",
      "Train Epoch: 6 [8960/22481 (40%)]\tLoss: 0.176990\n",
      "Train Epoch: 6 [9600/22481 (43%)]\tLoss: 0.071245\n",
      "Train Epoch: 6 [10240/22481 (45%)]\tLoss: 0.081523\n",
      "Train Epoch: 6 [10880/22481 (48%)]\tLoss: 0.079900\n",
      "Train Epoch: 6 [11520/22481 (51%)]\tLoss: 0.137030\n",
      "Train Epoch: 6 [12160/22481 (54%)]\tLoss: 0.296067\n",
      "Train Epoch: 6 [12800/22481 (57%)]\tLoss: 0.163307\n",
      "Train Epoch: 6 [13440/22481 (60%)]\tLoss: 0.093807\n",
      "Train Epoch: 6 [14080/22481 (62%)]\tLoss: 0.280740\n",
      "Train Epoch: 6 [14720/22481 (65%)]\tLoss: 0.201391\n",
      "Train Epoch: 6 [15360/22481 (68%)]\tLoss: 0.134908\n",
      "Train Epoch: 6 [16000/22481 (71%)]\tLoss: 0.090107\n",
      "Train Epoch: 6 [16640/22481 (74%)]\tLoss: 0.140011\n",
      "Train Epoch: 6 [17280/22481 (77%)]\tLoss: 0.046770\n",
      "Train Epoch: 6 [17920/22481 (80%)]\tLoss: 0.122869\n",
      "Train Epoch: 6 [18560/22481 (82%)]\tLoss: 0.069526\n",
      "Train Epoch: 6 [19200/22481 (85%)]\tLoss: 0.213147\n",
      "Train Epoch: 6 [19840/22481 (88%)]\tLoss: 0.097189\n",
      "Train Epoch: 6 [20480/22481 (91%)]\tLoss: 0.052916\n",
      "Train Epoch: 6 [21120/22481 (94%)]\tLoss: 0.106146\n",
      "Train Epoch: 6 [21760/22481 (97%)]\tLoss: 0.186151\n",
      "Train Epoch: 6 [22400/22481 (99%)]\tLoss: 0.116365\n",
      "Train Epoch: 7 [0/22481 (0%)]\tLoss: 0.145239\n",
      "Train Epoch: 7 [640/22481 (3%)]\tLoss: 0.142492\n",
      "Train Epoch: 7 [1280/22481 (6%)]\tLoss: 0.117765\n",
      "Train Epoch: 7 [1920/22481 (9%)]\tLoss: 0.167859\n",
      "Train Epoch: 7 [2560/22481 (11%)]\tLoss: 0.099165\n",
      "Train Epoch: 7 [3200/22481 (14%)]\tLoss: 0.041013\n",
      "Train Epoch: 7 [3840/22481 (17%)]\tLoss: 0.136638\n",
      "Train Epoch: 7 [4480/22481 (20%)]\tLoss: 0.057592\n",
      "Train Epoch: 7 [5120/22481 (23%)]\tLoss: 0.189398\n",
      "Train Epoch: 7 [5760/22481 (26%)]\tLoss: 0.170120\n",
      "Train Epoch: 7 [6400/22481 (28%)]\tLoss: 0.070970\n",
      "Train Epoch: 7 [7040/22481 (31%)]\tLoss: 0.039758\n",
      "Train Epoch: 7 [7680/22481 (34%)]\tLoss: 0.142779\n",
      "Train Epoch: 7 [8320/22481 (37%)]\tLoss: 0.198519\n",
      "Train Epoch: 7 [8960/22481 (40%)]\tLoss: 0.069596\n",
      "Train Epoch: 7 [9600/22481 (43%)]\tLoss: 0.124560\n",
      "Train Epoch: 7 [10240/22481 (45%)]\tLoss: 0.031601\n",
      "Train Epoch: 7 [10880/22481 (48%)]\tLoss: 0.263863\n",
      "Train Epoch: 7 [11520/22481 (51%)]\tLoss: 0.110787\n",
      "Train Epoch: 7 [12160/22481 (54%)]\tLoss: 0.148572\n",
      "Train Epoch: 7 [12800/22481 (57%)]\tLoss: 0.116455\n",
      "Train Epoch: 7 [13440/22481 (60%)]\tLoss: 0.068364\n",
      "Train Epoch: 7 [14080/22481 (62%)]\tLoss: 0.043370\n",
      "Train Epoch: 7 [14720/22481 (65%)]\tLoss: 0.126979\n",
      "Train Epoch: 7 [15360/22481 (68%)]\tLoss: 0.094821\n",
      "Train Epoch: 7 [16000/22481 (71%)]\tLoss: 0.062691\n",
      "Train Epoch: 7 [16640/22481 (74%)]\tLoss: 0.174124\n",
      "Train Epoch: 7 [17280/22481 (77%)]\tLoss: 0.067102\n",
      "Train Epoch: 7 [17920/22481 (80%)]\tLoss: 0.107971\n",
      "Train Epoch: 7 [18560/22481 (82%)]\tLoss: 0.056309\n",
      "Train Epoch: 7 [19200/22481 (85%)]\tLoss: 0.146999\n",
      "Train Epoch: 7 [19840/22481 (88%)]\tLoss: 0.122917\n",
      "Train Epoch: 7 [20480/22481 (91%)]\tLoss: 0.103398\n",
      "Train Epoch: 7 [21120/22481 (94%)]\tLoss: 0.140771\n",
      "Train Epoch: 7 [21760/22481 (97%)]\tLoss: 0.080975\n",
      "Train Epoch: 7 [22400/22481 (99%)]\tLoss: 0.023025\n",
      "Train Epoch: 8 [0/22481 (0%)]\tLoss: 0.091215\n",
      "Train Epoch: 8 [640/22481 (3%)]\tLoss: 0.172865\n",
      "Train Epoch: 8 [1280/22481 (6%)]\tLoss: 0.064761\n",
      "Train Epoch: 8 [1920/22481 (9%)]\tLoss: 0.145568\n",
      "Train Epoch: 8 [2560/22481 (11%)]\tLoss: 0.100817\n",
      "Train Epoch: 8 [3200/22481 (14%)]\tLoss: 0.287447\n",
      "Train Epoch: 8 [3840/22481 (17%)]\tLoss: 0.113560\n",
      "Train Epoch: 8 [4480/22481 (20%)]\tLoss: 0.075982\n",
      "Train Epoch: 8 [5120/22481 (23%)]\tLoss: 0.233701\n",
      "Train Epoch: 8 [5760/22481 (26%)]\tLoss: 0.162979\n",
      "Train Epoch: 8 [6400/22481 (28%)]\tLoss: 0.196406\n",
      "Train Epoch: 8 [7040/22481 (31%)]\tLoss: 0.054649\n",
      "Train Epoch: 8 [7680/22481 (34%)]\tLoss: 0.239796\n",
      "Train Epoch: 8 [8320/22481 (37%)]\tLoss: 0.249162\n",
      "Train Epoch: 8 [8960/22481 (40%)]\tLoss: 0.133981\n",
      "Train Epoch: 8 [9600/22481 (43%)]\tLoss: 0.132691\n",
      "Train Epoch: 8 [10240/22481 (45%)]\tLoss: 0.093271\n",
      "Train Epoch: 8 [10880/22481 (48%)]\tLoss: 0.101282\n",
      "Train Epoch: 8 [11520/22481 (51%)]\tLoss: 0.051454\n",
      "Train Epoch: 8 [12160/22481 (54%)]\tLoss: 0.323382\n",
      "Train Epoch: 8 [12800/22481 (57%)]\tLoss: 0.168330\n",
      "Train Epoch: 8 [13440/22481 (60%)]\tLoss: 0.085857\n",
      "Train Epoch: 8 [14080/22481 (62%)]\tLoss: 0.032874\n",
      "Train Epoch: 8 [14720/22481 (65%)]\tLoss: 0.027893\n",
      "Train Epoch: 8 [15360/22481 (68%)]\tLoss: 0.132222\n",
      "Train Epoch: 8 [16000/22481 (71%)]\tLoss: 0.068659\n",
      "Train Epoch: 8 [16640/22481 (74%)]\tLoss: 0.036951\n",
      "Train Epoch: 8 [17280/22481 (77%)]\tLoss: 0.074708\n",
      "Train Epoch: 8 [17920/22481 (80%)]\tLoss: 0.150057\n",
      "Train Epoch: 8 [18560/22481 (82%)]\tLoss: 0.287901\n",
      "Train Epoch: 8 [19200/22481 (85%)]\tLoss: 0.268325\n",
      "Train Epoch: 8 [19840/22481 (88%)]\tLoss: 0.112672\n",
      "Train Epoch: 8 [20480/22481 (91%)]\tLoss: 0.065923\n",
      "Train Epoch: 8 [21120/22481 (94%)]\tLoss: 0.090549\n",
      "Train Epoch: 8 [21760/22481 (97%)]\tLoss: 0.143759\n",
      "Train Epoch: 8 [22400/22481 (99%)]\tLoss: 0.242193\n",
      "Train Epoch: 9 [0/22481 (0%)]\tLoss: 0.152502\n",
      "Train Epoch: 9 [640/22481 (3%)]\tLoss: 0.257276\n",
      "Train Epoch: 9 [1280/22481 (6%)]\tLoss: 0.099013\n",
      "Train Epoch: 9 [1920/22481 (9%)]\tLoss: 0.075630\n",
      "Train Epoch: 9 [2560/22481 (11%)]\tLoss: 0.048060\n",
      "Train Epoch: 9 [3200/22481 (14%)]\tLoss: 0.072133\n",
      "Train Epoch: 9 [3840/22481 (17%)]\tLoss: 0.077230\n",
      "Train Epoch: 9 [4480/22481 (20%)]\tLoss: 0.197404\n",
      "Train Epoch: 9 [5120/22481 (23%)]\tLoss: 0.131361\n",
      "Train Epoch: 9 [5760/22481 (26%)]\tLoss: 0.020139\n",
      "Train Epoch: 9 [6400/22481 (28%)]\tLoss: 0.155722\n",
      "Train Epoch: 9 [7040/22481 (31%)]\tLoss: 0.303468\n",
      "Train Epoch: 9 [7680/22481 (34%)]\tLoss: 0.035423\n",
      "Train Epoch: 9 [8320/22481 (37%)]\tLoss: 0.039741\n",
      "Train Epoch: 9 [8960/22481 (40%)]\tLoss: 0.034776\n",
      "Train Epoch: 9 [9600/22481 (43%)]\tLoss: 0.158547\n",
      "Train Epoch: 9 [10240/22481 (45%)]\tLoss: 0.032199\n",
      "Train Epoch: 9 [10880/22481 (48%)]\tLoss: 0.143477\n",
      "Train Epoch: 9 [11520/22481 (51%)]\tLoss: 0.063891\n",
      "Train Epoch: 9 [12160/22481 (54%)]\tLoss: 0.094752\n",
      "Train Epoch: 9 [12800/22481 (57%)]\tLoss: 0.173023\n",
      "Train Epoch: 9 [13440/22481 (60%)]\tLoss: 0.052428\n",
      "Train Epoch: 9 [14080/22481 (62%)]\tLoss: 0.106888\n",
      "Train Epoch: 9 [14720/22481 (65%)]\tLoss: 0.151813\n",
      "Train Epoch: 9 [15360/22481 (68%)]\tLoss: 0.080091\n",
      "Train Epoch: 9 [16000/22481 (71%)]\tLoss: 0.120950\n",
      "Train Epoch: 9 [16640/22481 (74%)]\tLoss: 0.106233\n",
      "Train Epoch: 9 [17280/22481 (77%)]\tLoss: 0.177615\n",
      "Train Epoch: 9 [17920/22481 (80%)]\tLoss: 0.149377\n",
      "Train Epoch: 9 [18560/22481 (82%)]\tLoss: 0.153887\n",
      "Train Epoch: 9 [19200/22481 (85%)]\tLoss: 0.149745\n",
      "Train Epoch: 9 [19840/22481 (88%)]\tLoss: 0.272682\n",
      "Train Epoch: 9 [20480/22481 (91%)]\tLoss: 0.215310\n",
      "Train Epoch: 9 [21120/22481 (94%)]\tLoss: 0.136788\n",
      "Train Epoch: 9 [21760/22481 (97%)]\tLoss: 0.084595\n",
      "Train Epoch: 9 [22400/22481 (99%)]\tLoss: 0.107833\n",
      "Train Epoch: 10 [0/22481 (0%)]\tLoss: 0.122241\n",
      "Train Epoch: 10 [640/22481 (3%)]\tLoss: 0.064585\n",
      "Train Epoch: 10 [1280/22481 (6%)]\tLoss: 0.019672\n",
      "Train Epoch: 10 [1920/22481 (9%)]\tLoss: 0.172748\n",
      "Train Epoch: 10 [2560/22481 (11%)]\tLoss: 0.276060\n",
      "Train Epoch: 10 [3200/22481 (14%)]\tLoss: 0.028639\n",
      "Train Epoch: 10 [3840/22481 (17%)]\tLoss: 0.093623\n",
      "Train Epoch: 10 [4480/22481 (20%)]\tLoss: 0.091016\n",
      "Train Epoch: 10 [5120/22481 (23%)]\tLoss: 0.182450\n",
      "Train Epoch: 10 [5760/22481 (26%)]\tLoss: 0.206363\n",
      "Train Epoch: 10 [6400/22481 (28%)]\tLoss: 0.069935\n",
      "Train Epoch: 10 [7040/22481 (31%)]\tLoss: 0.088489\n",
      "Train Epoch: 10 [7680/22481 (34%)]\tLoss: 0.269821\n",
      "Train Epoch: 10 [8320/22481 (37%)]\tLoss: 0.070380\n",
      "Train Epoch: 10 [8960/22481 (40%)]\tLoss: 0.113997\n",
      "Train Epoch: 10 [9600/22481 (43%)]\tLoss: 0.066554\n",
      "Train Epoch: 10 [10240/22481 (45%)]\tLoss: 0.050889\n",
      "Train Epoch: 10 [10880/22481 (48%)]\tLoss: 0.151579\n",
      "Train Epoch: 10 [11520/22481 (51%)]\tLoss: 0.054011\n",
      "Train Epoch: 10 [12160/22481 (54%)]\tLoss: 0.201202\n",
      "Train Epoch: 10 [12800/22481 (57%)]\tLoss: 0.241344\n",
      "Train Epoch: 10 [13440/22481 (60%)]\tLoss: 0.086789\n",
      "Train Epoch: 10 [14080/22481 (62%)]\tLoss: 0.155215\n",
      "Train Epoch: 10 [14720/22481 (65%)]\tLoss: 0.188010\n",
      "Train Epoch: 10 [15360/22481 (68%)]\tLoss: 0.058232\n",
      "Train Epoch: 10 [16000/22481 (71%)]\tLoss: 0.134711\n",
      "Train Epoch: 10 [16640/22481 (74%)]\tLoss: 0.082640\n",
      "Train Epoch: 10 [17280/22481 (77%)]\tLoss: 0.242284\n",
      "Train Epoch: 10 [17920/22481 (80%)]\tLoss: 0.047025\n",
      "Train Epoch: 10 [18560/22481 (82%)]\tLoss: 0.284510\n",
      "Train Epoch: 10 [19200/22481 (85%)]\tLoss: 0.128601\n",
      "Train Epoch: 10 [19840/22481 (88%)]\tLoss: 0.067319\n",
      "Train Epoch: 10 [20480/22481 (91%)]\tLoss: 0.241445\n",
      "Train Epoch: 10 [21120/22481 (94%)]\tLoss: 0.080166\n",
      "Train Epoch: 10 [21760/22481 (97%)]\tLoss: 0.112805\n",
      "Train Epoch: 10 [22400/22481 (99%)]\tLoss: 0.138181\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0725, Accuracy: 9767/10000 (98%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/37519 (0%)]\tLoss: 0.061204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [640/37519 (2%)]\tLoss: 0.375767\n",
      "Train Epoch: 1 [1280/37519 (3%)]\tLoss: 0.245640\n",
      "Train Epoch: 1 [1920/37519 (5%)]\tLoss: 0.088440\n",
      "Train Epoch: 1 [2560/37519 (7%)]\tLoss: 0.229893\n",
      "Train Epoch: 1 [3200/37519 (9%)]\tLoss: 0.354696\n",
      "Train Epoch: 1 [3840/37519 (10%)]\tLoss: 0.198041\n",
      "Train Epoch: 1 [4480/37519 (12%)]\tLoss: 0.178551\n",
      "Train Epoch: 1 [5120/37519 (14%)]\tLoss: 0.109354\n",
      "Train Epoch: 1 [5760/37519 (15%)]\tLoss: 0.136856\n",
      "Train Epoch: 1 [6400/37519 (17%)]\tLoss: 0.095294\n",
      "Train Epoch: 1 [7040/37519 (19%)]\tLoss: 0.075522\n",
      "Train Epoch: 1 [7680/37519 (20%)]\tLoss: 0.160552\n",
      "Train Epoch: 1 [8320/37519 (22%)]\tLoss: 0.133778\n",
      "Train Epoch: 1 [8960/37519 (24%)]\tLoss: 0.265775\n",
      "Train Epoch: 1 [9600/37519 (26%)]\tLoss: 0.163601\n",
      "Train Epoch: 1 [10240/37519 (27%)]\tLoss: 0.079651\n",
      "Train Epoch: 1 [10880/37519 (29%)]\tLoss: 0.088700\n",
      "Train Epoch: 1 [11520/37519 (31%)]\tLoss: 0.108204\n",
      "Train Epoch: 1 [12160/37519 (32%)]\tLoss: 0.502334\n",
      "Train Epoch: 1 [12800/37519 (34%)]\tLoss: 0.082744\n",
      "Train Epoch: 1 [13440/37519 (36%)]\tLoss: 0.244858\n",
      "Train Epoch: 1 [14080/37519 (37%)]\tLoss: 0.174866\n",
      "Train Epoch: 1 [14720/37519 (39%)]\tLoss: 0.158884\n",
      "Train Epoch: 1 [15360/37519 (41%)]\tLoss: 0.258260\n",
      "Train Epoch: 1 [16000/37519 (43%)]\tLoss: 0.185322\n",
      "Train Epoch: 1 [16640/37519 (44%)]\tLoss: 0.101471\n",
      "Train Epoch: 1 [17280/37519 (46%)]\tLoss: 0.229456\n",
      "Train Epoch: 1 [17920/37519 (48%)]\tLoss: 0.114507\n",
      "Train Epoch: 1 [18560/37519 (49%)]\tLoss: 0.150645\n",
      "Train Epoch: 1 [19200/37519 (51%)]\tLoss: 0.306485\n",
      "Train Epoch: 1 [19840/37519 (53%)]\tLoss: 0.052978\n",
      "Train Epoch: 1 [20480/37519 (55%)]\tLoss: 0.192119\n",
      "Train Epoch: 1 [21120/37519 (56%)]\tLoss: 0.063964\n",
      "Train Epoch: 1 [21760/37519 (58%)]\tLoss: 0.182870\n",
      "Train Epoch: 1 [22400/37519 (60%)]\tLoss: 0.116741\n",
      "Train Epoch: 1 [23040/37519 (61%)]\tLoss: 0.161220\n",
      "Train Epoch: 1 [23680/37519 (63%)]\tLoss: 0.117907\n",
      "Train Epoch: 1 [24320/37519 (65%)]\tLoss: 0.078648\n",
      "Train Epoch: 1 [24960/37519 (66%)]\tLoss: 0.115296\n",
      "Train Epoch: 1 [25600/37519 (68%)]\tLoss: 0.231158\n",
      "Train Epoch: 1 [26240/37519 (70%)]\tLoss: 0.088151\n",
      "Train Epoch: 1 [26880/37519 (72%)]\tLoss: 0.062520\n",
      "Train Epoch: 1 [27520/37519 (73%)]\tLoss: 0.255640\n",
      "Train Epoch: 1 [28160/37519 (75%)]\tLoss: 0.376296\n",
      "Train Epoch: 1 [28800/37519 (77%)]\tLoss: 0.280994\n",
      "Train Epoch: 1 [29440/37519 (78%)]\tLoss: 0.148774\n",
      "Train Epoch: 1 [30080/37519 (80%)]\tLoss: 0.081862\n",
      "Train Epoch: 1 [30720/37519 (82%)]\tLoss: 0.095095\n",
      "Train Epoch: 1 [31360/37519 (83%)]\tLoss: 0.186093\n",
      "Train Epoch: 1 [32000/37519 (85%)]\tLoss: 0.174147\n",
      "Train Epoch: 1 [32640/37519 (87%)]\tLoss: 0.127113\n",
      "Train Epoch: 1 [33280/37519 (89%)]\tLoss: 0.195182\n",
      "Train Epoch: 1 [33920/37519 (90%)]\tLoss: 0.085468\n",
      "Train Epoch: 1 [34560/37519 (92%)]\tLoss: 0.182590\n",
      "Train Epoch: 1 [35200/37519 (94%)]\tLoss: 0.152133\n",
      "Train Epoch: 1 [35840/37519 (95%)]\tLoss: 0.322025\n",
      "Train Epoch: 1 [36480/37519 (97%)]\tLoss: 0.229826\n",
      "Train Epoch: 1 [37120/37519 (99%)]\tLoss: 0.098496\n",
      "Train Epoch: 2 [0/37519 (0%)]\tLoss: 0.103186\n",
      "Train Epoch: 2 [640/37519 (2%)]\tLoss: 0.217812\n",
      "Train Epoch: 2 [1280/37519 (3%)]\tLoss: 0.193832\n",
      "Train Epoch: 2 [1920/37519 (5%)]\tLoss: 0.107800\n",
      "Train Epoch: 2 [2560/37519 (7%)]\tLoss: 0.100313\n",
      "Train Epoch: 2 [3200/37519 (9%)]\tLoss: 0.097567\n",
      "Train Epoch: 2 [3840/37519 (10%)]\tLoss: 0.130179\n",
      "Train Epoch: 2 [4480/37519 (12%)]\tLoss: 0.156924\n",
      "Train Epoch: 2 [5120/37519 (14%)]\tLoss: 0.115601\n",
      "Train Epoch: 2 [5760/37519 (15%)]\tLoss: 0.114339\n",
      "Train Epoch: 2 [6400/37519 (17%)]\tLoss: 0.183355\n",
      "Train Epoch: 2 [7040/37519 (19%)]\tLoss: 0.126228\n",
      "Train Epoch: 2 [7680/37519 (20%)]\tLoss: 0.217438\n",
      "Train Epoch: 2 [8320/37519 (22%)]\tLoss: 0.044357\n",
      "Train Epoch: 2 [8960/37519 (24%)]\tLoss: 0.093200\n",
      "Train Epoch: 2 [9600/37519 (26%)]\tLoss: 0.061967\n",
      "Train Epoch: 2 [10240/37519 (27%)]\tLoss: 0.066083\n",
      "Train Epoch: 2 [10880/37519 (29%)]\tLoss: 0.059043\n",
      "Train Epoch: 2 [11520/37519 (31%)]\tLoss: 0.069403\n",
      "Train Epoch: 2 [12160/37519 (32%)]\tLoss: 0.206410\n",
      "Train Epoch: 2 [12800/37519 (34%)]\tLoss: 0.105359\n",
      "Train Epoch: 2 [13440/37519 (36%)]\tLoss: 0.098860\n",
      "Train Epoch: 2 [14080/37519 (37%)]\tLoss: 0.052140\n",
      "Train Epoch: 2 [14720/37519 (39%)]\tLoss: 0.061504\n",
      "Train Epoch: 2 [15360/37519 (41%)]\tLoss: 0.172628\n",
      "Train Epoch: 2 [16000/37519 (43%)]\tLoss: 0.115429\n",
      "Train Epoch: 2 [16640/37519 (44%)]\tLoss: 0.133107\n",
      "Train Epoch: 2 [17280/37519 (46%)]\tLoss: 0.225809\n",
      "Train Epoch: 2 [17920/37519 (48%)]\tLoss: 0.085899\n",
      "Train Epoch: 2 [18560/37519 (49%)]\tLoss: 0.405857\n",
      "Train Epoch: 2 [19200/37519 (51%)]\tLoss: 0.103326\n",
      "Train Epoch: 2 [19840/37519 (53%)]\tLoss: 0.089288\n",
      "Train Epoch: 2 [20480/37519 (55%)]\tLoss: 0.293866\n",
      "Train Epoch: 2 [21120/37519 (56%)]\tLoss: 0.159959\n",
      "Train Epoch: 2 [21760/37519 (58%)]\tLoss: 0.111533\n",
      "Train Epoch: 2 [22400/37519 (60%)]\tLoss: 0.126541\n",
      "Train Epoch: 2 [23040/37519 (61%)]\tLoss: 0.066801\n",
      "Train Epoch: 2 [23680/37519 (63%)]\tLoss: 0.127097\n",
      "Train Epoch: 2 [24320/37519 (65%)]\tLoss: 0.132237\n",
      "Train Epoch: 2 [24960/37519 (66%)]\tLoss: 0.184400\n",
      "Train Epoch: 2 [25600/37519 (68%)]\tLoss: 0.135382\n",
      "Train Epoch: 2 [26240/37519 (70%)]\tLoss: 0.326761\n",
      "Train Epoch: 2 [26880/37519 (72%)]\tLoss: 0.105552\n",
      "Train Epoch: 2 [27520/37519 (73%)]\tLoss: 0.054644\n",
      "Train Epoch: 2 [28160/37519 (75%)]\tLoss: 0.332655\n",
      "Train Epoch: 2 [28800/37519 (77%)]\tLoss: 0.208812\n",
      "Train Epoch: 2 [29440/37519 (78%)]\tLoss: 0.180185\n",
      "Train Epoch: 2 [30080/37519 (80%)]\tLoss: 0.012228\n",
      "Train Epoch: 2 [30720/37519 (82%)]\tLoss: 0.069609\n",
      "Train Epoch: 2 [31360/37519 (83%)]\tLoss: 0.165322\n",
      "Train Epoch: 2 [32000/37519 (85%)]\tLoss: 0.090883\n",
      "Train Epoch: 2 [32640/37519 (87%)]\tLoss: 0.030353\n",
      "Train Epoch: 2 [33280/37519 (89%)]\tLoss: 0.104755\n",
      "Train Epoch: 2 [33920/37519 (90%)]\tLoss: 0.160390\n",
      "Train Epoch: 2 [34560/37519 (92%)]\tLoss: 0.384995\n",
      "Train Epoch: 2 [35200/37519 (94%)]\tLoss: 0.298217\n",
      "Train Epoch: 2 [35840/37519 (95%)]\tLoss: 0.073096\n",
      "Train Epoch: 2 [36480/37519 (97%)]\tLoss: 0.084535\n",
      "Train Epoch: 2 [37120/37519 (99%)]\tLoss: 0.176902\n",
      "Train Epoch: 3 [0/37519 (0%)]\tLoss: 0.024588\n",
      "Train Epoch: 3 [640/37519 (2%)]\tLoss: 0.163998\n",
      "Train Epoch: 3 [1280/37519 (3%)]\tLoss: 0.205010\n",
      "Train Epoch: 3 [1920/37519 (5%)]\tLoss: 0.117682\n",
      "Train Epoch: 3 [2560/37519 (7%)]\tLoss: 0.133451\n",
      "Train Epoch: 3 [3200/37519 (9%)]\tLoss: 0.126273\n",
      "Train Epoch: 3 [3840/37519 (10%)]\tLoss: 0.133062\n",
      "Train Epoch: 3 [4480/37519 (12%)]\tLoss: 0.104791\n",
      "Train Epoch: 3 [5120/37519 (14%)]\tLoss: 0.090672\n",
      "Train Epoch: 3 [5760/37519 (15%)]\tLoss: 0.338646\n",
      "Train Epoch: 3 [6400/37519 (17%)]\tLoss: 0.229757\n",
      "Train Epoch: 3 [7040/37519 (19%)]\tLoss: 0.126557\n",
      "Train Epoch: 3 [7680/37519 (20%)]\tLoss: 0.280458\n",
      "Train Epoch: 3 [8320/37519 (22%)]\tLoss: 0.210103\n",
      "Train Epoch: 3 [8960/37519 (24%)]\tLoss: 0.062746\n",
      "Train Epoch: 3 [9600/37519 (26%)]\tLoss: 0.055123\n",
      "Train Epoch: 3 [10240/37519 (27%)]\tLoss: 0.164140\n",
      "Train Epoch: 3 [10880/37519 (29%)]\tLoss: 0.103032\n",
      "Train Epoch: 3 [11520/37519 (31%)]\tLoss: 0.126381\n",
      "Train Epoch: 3 [12160/37519 (32%)]\tLoss: 0.165241\n",
      "Train Epoch: 3 [12800/37519 (34%)]\tLoss: 0.190952\n",
      "Train Epoch: 3 [13440/37519 (36%)]\tLoss: 0.160873\n",
      "Train Epoch: 3 [14080/37519 (37%)]\tLoss: 0.132095\n",
      "Train Epoch: 3 [14720/37519 (39%)]\tLoss: 0.122173\n",
      "Train Epoch: 3 [15360/37519 (41%)]\tLoss: 0.072952\n",
      "Train Epoch: 3 [16000/37519 (43%)]\tLoss: 0.094562\n",
      "Train Epoch: 3 [16640/37519 (44%)]\tLoss: 0.088962\n",
      "Train Epoch: 3 [17280/37519 (46%)]\tLoss: 0.232860\n",
      "Train Epoch: 3 [17920/37519 (48%)]\tLoss: 0.035776\n",
      "Train Epoch: 3 [18560/37519 (49%)]\tLoss: 0.078833\n",
      "Train Epoch: 3 [19200/37519 (51%)]\tLoss: 0.088838\n",
      "Train Epoch: 3 [19840/37519 (53%)]\tLoss: 0.217155\n",
      "Train Epoch: 3 [20480/37519 (55%)]\tLoss: 0.083566\n",
      "Train Epoch: 3 [21120/37519 (56%)]\tLoss: 0.630561\n",
      "Train Epoch: 3 [21760/37519 (58%)]\tLoss: 0.062391\n",
      "Train Epoch: 3 [22400/37519 (60%)]\tLoss: 0.058400\n",
      "Train Epoch: 3 [23040/37519 (61%)]\tLoss: 0.134877\n",
      "Train Epoch: 3 [23680/37519 (63%)]\tLoss: 0.166431\n",
      "Train Epoch: 3 [24320/37519 (65%)]\tLoss: 0.131574\n",
      "Train Epoch: 3 [24960/37519 (66%)]\tLoss: 0.155948\n",
      "Train Epoch: 3 [25600/37519 (68%)]\tLoss: 0.099859\n",
      "Train Epoch: 3 [26240/37519 (70%)]\tLoss: 0.187329\n",
      "Train Epoch: 3 [26880/37519 (72%)]\tLoss: 0.108880\n",
      "Train Epoch: 3 [27520/37519 (73%)]\tLoss: 0.079548\n",
      "Train Epoch: 3 [28160/37519 (75%)]\tLoss: 0.095121\n",
      "Train Epoch: 3 [28800/37519 (77%)]\tLoss: 0.097592\n",
      "Train Epoch: 3 [29440/37519 (78%)]\tLoss: 0.229623\n",
      "Train Epoch: 3 [30080/37519 (80%)]\tLoss: 0.170967\n",
      "Train Epoch: 3 [30720/37519 (82%)]\tLoss: 0.101651\n",
      "Train Epoch: 3 [31360/37519 (83%)]\tLoss: 0.093996\n",
      "Train Epoch: 3 [32000/37519 (85%)]\tLoss: 0.083312\n",
      "Train Epoch: 3 [32640/37519 (87%)]\tLoss: 0.127175\n",
      "Train Epoch: 3 [33280/37519 (89%)]\tLoss: 0.237407\n",
      "Train Epoch: 3 [33920/37519 (90%)]\tLoss: 0.338780\n",
      "Train Epoch: 3 [34560/37519 (92%)]\tLoss: 0.131125\n",
      "Train Epoch: 3 [35200/37519 (94%)]\tLoss: 0.178852\n",
      "Train Epoch: 3 [35840/37519 (95%)]\tLoss: 0.108020\n",
      "Train Epoch: 3 [36480/37519 (97%)]\tLoss: 0.155547\n",
      "Train Epoch: 3 [37120/37519 (99%)]\tLoss: 0.302788\n",
      "Train Epoch: 4 [0/37519 (0%)]\tLoss: 0.065500\n",
      "Train Epoch: 4 [640/37519 (2%)]\tLoss: 0.190930\n",
      "Train Epoch: 4 [1280/37519 (3%)]\tLoss: 0.141841\n",
      "Train Epoch: 4 [1920/37519 (5%)]\tLoss: 0.240710\n",
      "Train Epoch: 4 [2560/37519 (7%)]\tLoss: 0.101404\n",
      "Train Epoch: 4 [3200/37519 (9%)]\tLoss: 0.122481\n",
      "Train Epoch: 4 [3840/37519 (10%)]\tLoss: 0.081202\n",
      "Train Epoch: 4 [4480/37519 (12%)]\tLoss: 0.123905\n",
      "Train Epoch: 4 [5120/37519 (14%)]\tLoss: 0.036308\n",
      "Train Epoch: 4 [5760/37519 (15%)]\tLoss: 0.110997\n",
      "Train Epoch: 4 [6400/37519 (17%)]\tLoss: 0.132804\n",
      "Train Epoch: 4 [7040/37519 (19%)]\tLoss: 0.071808\n",
      "Train Epoch: 4 [7680/37519 (20%)]\tLoss: 0.183433\n",
      "Train Epoch: 4 [8320/37519 (22%)]\tLoss: 0.168764\n",
      "Train Epoch: 4 [8960/37519 (24%)]\tLoss: 0.112191\n",
      "Train Epoch: 4 [9600/37519 (26%)]\tLoss: 0.027571\n",
      "Train Epoch: 4 [10240/37519 (27%)]\tLoss: 0.456593\n",
      "Train Epoch: 4 [10880/37519 (29%)]\tLoss: 0.270967\n",
      "Train Epoch: 4 [11520/37519 (31%)]\tLoss: 0.095399\n",
      "Train Epoch: 4 [12160/37519 (32%)]\tLoss: 0.188739\n",
      "Train Epoch: 4 [12800/37519 (34%)]\tLoss: 0.143505\n",
      "Train Epoch: 4 [13440/37519 (36%)]\tLoss: 0.124129\n",
      "Train Epoch: 4 [14080/37519 (37%)]\tLoss: 0.064055\n",
      "Train Epoch: 4 [14720/37519 (39%)]\tLoss: 0.271846\n",
      "Train Epoch: 4 [15360/37519 (41%)]\tLoss: 0.085180\n",
      "Train Epoch: 4 [16000/37519 (43%)]\tLoss: 0.160510\n",
      "Train Epoch: 4 [16640/37519 (44%)]\tLoss: 0.128699\n",
      "Train Epoch: 4 [17280/37519 (46%)]\tLoss: 0.149775\n",
      "Train Epoch: 4 [17920/37519 (48%)]\tLoss: 0.133558\n",
      "Train Epoch: 4 [18560/37519 (49%)]\tLoss: 0.136015\n",
      "Train Epoch: 4 [19200/37519 (51%)]\tLoss: 0.149063\n",
      "Train Epoch: 4 [19840/37519 (53%)]\tLoss: 0.299838\n",
      "Train Epoch: 4 [20480/37519 (55%)]\tLoss: 0.167357\n",
      "Train Epoch: 4 [21120/37519 (56%)]\tLoss: 0.042299\n",
      "Train Epoch: 4 [21760/37519 (58%)]\tLoss: 0.091909\n",
      "Train Epoch: 4 [22400/37519 (60%)]\tLoss: 0.080932\n",
      "Train Epoch: 4 [23040/37519 (61%)]\tLoss: 0.133399\n",
      "Train Epoch: 4 [23680/37519 (63%)]\tLoss: 0.172704\n",
      "Train Epoch: 4 [24320/37519 (65%)]\tLoss: 0.204999\n",
      "Train Epoch: 4 [24960/37519 (66%)]\tLoss: 0.075100\n",
      "Train Epoch: 4 [25600/37519 (68%)]\tLoss: 0.206212\n",
      "Train Epoch: 4 [26240/37519 (70%)]\tLoss: 0.066024\n",
      "Train Epoch: 4 [26880/37519 (72%)]\tLoss: 0.099947\n",
      "Train Epoch: 4 [27520/37519 (73%)]\tLoss: 0.183818\n",
      "Train Epoch: 4 [28160/37519 (75%)]\tLoss: 0.069974\n",
      "Train Epoch: 4 [28800/37519 (77%)]\tLoss: 0.205978\n",
      "Train Epoch: 4 [29440/37519 (78%)]\tLoss: 0.206894\n",
      "Train Epoch: 4 [30080/37519 (80%)]\tLoss: 0.157491\n",
      "Train Epoch: 4 [30720/37519 (82%)]\tLoss: 0.161422\n",
      "Train Epoch: 4 [31360/37519 (83%)]\tLoss: 0.085385\n",
      "Train Epoch: 4 [32000/37519 (85%)]\tLoss: 0.140169\n",
      "Train Epoch: 4 [32640/37519 (87%)]\tLoss: 0.066687\n",
      "Train Epoch: 4 [33280/37519 (89%)]\tLoss: 0.188487\n",
      "Train Epoch: 4 [33920/37519 (90%)]\tLoss: 0.216719\n",
      "Train Epoch: 4 [34560/37519 (92%)]\tLoss: 0.190986\n",
      "Train Epoch: 4 [35200/37519 (94%)]\tLoss: 0.301331\n",
      "Train Epoch: 4 [35840/37519 (95%)]\tLoss: 0.135759\n",
      "Train Epoch: 4 [36480/37519 (97%)]\tLoss: 0.258046\n",
      "Train Epoch: 4 [37120/37519 (99%)]\tLoss: 0.153222\n",
      "Train Epoch: 5 [0/37519 (0%)]\tLoss: 0.148325\n",
      "Train Epoch: 5 [640/37519 (2%)]\tLoss: 0.147772\n",
      "Train Epoch: 5 [1280/37519 (3%)]\tLoss: 0.104678\n",
      "Train Epoch: 5 [1920/37519 (5%)]\tLoss: 0.241713\n",
      "Train Epoch: 5 [2560/37519 (7%)]\tLoss: 0.157368\n",
      "Train Epoch: 5 [3200/37519 (9%)]\tLoss: 0.080007\n",
      "Train Epoch: 5 [3840/37519 (10%)]\tLoss: 0.111163\n",
      "Train Epoch: 5 [4480/37519 (12%)]\tLoss: 0.167317\n",
      "Train Epoch: 5 [5120/37519 (14%)]\tLoss: 0.098682\n",
      "Train Epoch: 5 [5760/37519 (15%)]\tLoss: 0.105757\n",
      "Train Epoch: 5 [6400/37519 (17%)]\tLoss: 0.047831\n",
      "Train Epoch: 5 [7040/37519 (19%)]\tLoss: 0.247398\n",
      "Train Epoch: 5 [7680/37519 (20%)]\tLoss: 0.238433\n",
      "Train Epoch: 5 [8320/37519 (22%)]\tLoss: 0.152904\n",
      "Train Epoch: 5 [8960/37519 (24%)]\tLoss: 0.051803\n",
      "Train Epoch: 5 [9600/37519 (26%)]\tLoss: 0.138987\n",
      "Train Epoch: 5 [10240/37519 (27%)]\tLoss: 0.134466\n",
      "Train Epoch: 5 [10880/37519 (29%)]\tLoss: 0.166883\n",
      "Train Epoch: 5 [11520/37519 (31%)]\tLoss: 0.100541\n",
      "Train Epoch: 5 [12160/37519 (32%)]\tLoss: 0.219238\n",
      "Train Epoch: 5 [12800/37519 (34%)]\tLoss: 0.099472\n",
      "Train Epoch: 5 [13440/37519 (36%)]\tLoss: 0.156351\n",
      "Train Epoch: 5 [14080/37519 (37%)]\tLoss: 0.053382\n",
      "Train Epoch: 5 [14720/37519 (39%)]\tLoss: 0.094733\n",
      "Train Epoch: 5 [15360/37519 (41%)]\tLoss: 0.081147\n",
      "Train Epoch: 5 [16000/37519 (43%)]\tLoss: 0.101386\n",
      "Train Epoch: 5 [16640/37519 (44%)]\tLoss: 0.406929\n",
      "Train Epoch: 5 [17280/37519 (46%)]\tLoss: 0.099429\n",
      "Train Epoch: 5 [17920/37519 (48%)]\tLoss: 0.199239\n",
      "Train Epoch: 5 [18560/37519 (49%)]\tLoss: 0.099454\n",
      "Train Epoch: 5 [19200/37519 (51%)]\tLoss: 0.157557\n",
      "Train Epoch: 5 [19840/37519 (53%)]\tLoss: 0.065669\n",
      "Train Epoch: 5 [20480/37519 (55%)]\tLoss: 0.101921\n",
      "Train Epoch: 5 [21120/37519 (56%)]\tLoss: 0.198375\n",
      "Train Epoch: 5 [21760/37519 (58%)]\tLoss: 0.168259\n",
      "Train Epoch: 5 [22400/37519 (60%)]\tLoss: 0.135580\n",
      "Train Epoch: 5 [23040/37519 (61%)]\tLoss: 0.093661\n",
      "Train Epoch: 5 [23680/37519 (63%)]\tLoss: 0.079426\n",
      "Train Epoch: 5 [24320/37519 (65%)]\tLoss: 0.132070\n",
      "Train Epoch: 5 [24960/37519 (66%)]\tLoss: 0.101261\n",
      "Train Epoch: 5 [25600/37519 (68%)]\tLoss: 0.113557\n",
      "Train Epoch: 5 [26240/37519 (70%)]\tLoss: 0.059603\n",
      "Train Epoch: 5 [26880/37519 (72%)]\tLoss: 0.164355\n",
      "Train Epoch: 5 [27520/37519 (73%)]\tLoss: 0.023538\n",
      "Train Epoch: 5 [28160/37519 (75%)]\tLoss: 0.109211\n",
      "Train Epoch: 5 [28800/37519 (77%)]\tLoss: 0.180500\n",
      "Train Epoch: 5 [29440/37519 (78%)]\tLoss: 0.136821\n",
      "Train Epoch: 5 [30080/37519 (80%)]\tLoss: 0.028284\n",
      "Train Epoch: 5 [30720/37519 (82%)]\tLoss: 0.219410\n",
      "Train Epoch: 5 [31360/37519 (83%)]\tLoss: 0.192836\n",
      "Train Epoch: 5 [32000/37519 (85%)]\tLoss: 0.123335\n",
      "Train Epoch: 5 [32640/37519 (87%)]\tLoss: 0.066497\n",
      "Train Epoch: 5 [33280/37519 (89%)]\tLoss: 0.104215\n",
      "Train Epoch: 5 [33920/37519 (90%)]\tLoss: 0.076522\n",
      "Train Epoch: 5 [34560/37519 (92%)]\tLoss: 0.195849\n",
      "Train Epoch: 5 [35200/37519 (94%)]\tLoss: 0.118930\n",
      "Train Epoch: 5 [35840/37519 (95%)]\tLoss: 0.130702\n",
      "Train Epoch: 5 [36480/37519 (97%)]\tLoss: 0.104045\n",
      "Train Epoch: 5 [37120/37519 (99%)]\tLoss: 0.041531\n",
      "Train Epoch: 6 [0/37519 (0%)]\tLoss: 0.193913\n",
      "Train Epoch: 6 [640/37519 (2%)]\tLoss: 0.065181\n",
      "Train Epoch: 6 [1280/37519 (3%)]\tLoss: 0.117062\n",
      "Train Epoch: 6 [1920/37519 (5%)]\tLoss: 0.078348\n",
      "Train Epoch: 6 [2560/37519 (7%)]\tLoss: 0.213897\n",
      "Train Epoch: 6 [3200/37519 (9%)]\tLoss: 0.337960\n",
      "Train Epoch: 6 [3840/37519 (10%)]\tLoss: 0.207878\n",
      "Train Epoch: 6 [4480/37519 (12%)]\tLoss: 0.041918\n",
      "Train Epoch: 6 [5120/37519 (14%)]\tLoss: 0.147009\n",
      "Train Epoch: 6 [5760/37519 (15%)]\tLoss: 0.224560\n",
      "Train Epoch: 6 [6400/37519 (17%)]\tLoss: 0.050414\n",
      "Train Epoch: 6 [7040/37519 (19%)]\tLoss: 0.181186\n",
      "Train Epoch: 6 [7680/37519 (20%)]\tLoss: 0.075280\n",
      "Train Epoch: 6 [8320/37519 (22%)]\tLoss: 0.122454\n",
      "Train Epoch: 6 [8960/37519 (24%)]\tLoss: 0.077063\n",
      "Train Epoch: 6 [9600/37519 (26%)]\tLoss: 0.046647\n",
      "Train Epoch: 6 [10240/37519 (27%)]\tLoss: 0.160992\n",
      "Train Epoch: 6 [10880/37519 (29%)]\tLoss: 0.060101\n",
      "Train Epoch: 6 [11520/37519 (31%)]\tLoss: 0.073983\n",
      "Train Epoch: 6 [12160/37519 (32%)]\tLoss: 0.053387\n",
      "Train Epoch: 6 [12800/37519 (34%)]\tLoss: 0.177731\n",
      "Train Epoch: 6 [13440/37519 (36%)]\tLoss: 0.156133\n",
      "Train Epoch: 6 [14080/37519 (37%)]\tLoss: 0.187647\n",
      "Train Epoch: 6 [14720/37519 (39%)]\tLoss: 0.082195\n",
      "Train Epoch: 6 [15360/37519 (41%)]\tLoss: 0.162669\n",
      "Train Epoch: 6 [16000/37519 (43%)]\tLoss: 0.172961\n",
      "Train Epoch: 6 [16640/37519 (44%)]\tLoss: 0.093348\n",
      "Train Epoch: 6 [17280/37519 (46%)]\tLoss: 0.134327\n",
      "Train Epoch: 6 [17920/37519 (48%)]\tLoss: 0.145557\n",
      "Train Epoch: 6 [18560/37519 (49%)]\tLoss: 0.110059\n",
      "Train Epoch: 6 [19200/37519 (51%)]\tLoss: 0.078309\n",
      "Train Epoch: 6 [19840/37519 (53%)]\tLoss: 0.068976\n",
      "Train Epoch: 6 [20480/37519 (55%)]\tLoss: 0.130841\n",
      "Train Epoch: 6 [21120/37519 (56%)]\tLoss: 0.211447\n",
      "Train Epoch: 6 [21760/37519 (58%)]\tLoss: 0.128653\n",
      "Train Epoch: 6 [22400/37519 (60%)]\tLoss: 0.206770\n",
      "Train Epoch: 6 [23040/37519 (61%)]\tLoss: 0.090002\n",
      "Train Epoch: 6 [23680/37519 (63%)]\tLoss: 0.108799\n",
      "Train Epoch: 6 [24320/37519 (65%)]\tLoss: 0.132312\n",
      "Train Epoch: 6 [24960/37519 (66%)]\tLoss: 0.232750\n",
      "Train Epoch: 6 [25600/37519 (68%)]\tLoss: 0.061794\n",
      "Train Epoch: 6 [26240/37519 (70%)]\tLoss: 0.065136\n",
      "Train Epoch: 6 [26880/37519 (72%)]\tLoss: 0.120586\n",
      "Train Epoch: 6 [27520/37519 (73%)]\tLoss: 0.048641\n",
      "Train Epoch: 6 [28160/37519 (75%)]\tLoss: 0.082514\n",
      "Train Epoch: 6 [28800/37519 (77%)]\tLoss: 0.261749\n",
      "Train Epoch: 6 [29440/37519 (78%)]\tLoss: 0.154184\n",
      "Train Epoch: 6 [30080/37519 (80%)]\tLoss: 0.145857\n",
      "Train Epoch: 6 [30720/37519 (82%)]\tLoss: 0.091359\n",
      "Train Epoch: 6 [31360/37519 (83%)]\tLoss: 0.126337\n",
      "Train Epoch: 6 [32000/37519 (85%)]\tLoss: 0.194540\n",
      "Train Epoch: 6 [32640/37519 (87%)]\tLoss: 0.270161\n",
      "Train Epoch: 6 [33280/37519 (89%)]\tLoss: 0.118971\n",
      "Train Epoch: 6 [33920/37519 (90%)]\tLoss: 0.105166\n",
      "Train Epoch: 6 [34560/37519 (92%)]\tLoss: 0.081755\n",
      "Train Epoch: 6 [35200/37519 (94%)]\tLoss: 0.155427\n",
      "Train Epoch: 6 [35840/37519 (95%)]\tLoss: 0.116641\n",
      "Train Epoch: 6 [36480/37519 (97%)]\tLoss: 0.256045\n",
      "Train Epoch: 6 [37120/37519 (99%)]\tLoss: 0.187255\n",
      "Train Epoch: 7 [0/37519 (0%)]\tLoss: 0.236104\n",
      "Train Epoch: 7 [640/37519 (2%)]\tLoss: 0.157054\n",
      "Train Epoch: 7 [1280/37519 (3%)]\tLoss: 0.158945\n",
      "Train Epoch: 7 [1920/37519 (5%)]\tLoss: 0.197900\n",
      "Train Epoch: 7 [2560/37519 (7%)]\tLoss: 0.118383\n",
      "Train Epoch: 7 [3200/37519 (9%)]\tLoss: 0.132007\n",
      "Train Epoch: 7 [3840/37519 (10%)]\tLoss: 0.101459\n",
      "Train Epoch: 7 [4480/37519 (12%)]\tLoss: 0.045416\n",
      "Train Epoch: 7 [5120/37519 (14%)]\tLoss: 0.107971\n",
      "Train Epoch: 7 [5760/37519 (15%)]\tLoss: 0.111634\n",
      "Train Epoch: 7 [6400/37519 (17%)]\tLoss: 0.061972\n",
      "Train Epoch: 7 [7040/37519 (19%)]\tLoss: 0.052437\n",
      "Train Epoch: 7 [7680/37519 (20%)]\tLoss: 0.088753\n",
      "Train Epoch: 7 [8320/37519 (22%)]\tLoss: 0.061511\n",
      "Train Epoch: 7 [8960/37519 (24%)]\tLoss: 0.211617\n",
      "Train Epoch: 7 [9600/37519 (26%)]\tLoss: 0.136315\n",
      "Train Epoch: 7 [10240/37519 (27%)]\tLoss: 0.083093\n",
      "Train Epoch: 7 [10880/37519 (29%)]\tLoss: 0.176450\n",
      "Train Epoch: 7 [11520/37519 (31%)]\tLoss: 0.034806\n",
      "Train Epoch: 7 [12160/37519 (32%)]\tLoss: 0.064497\n",
      "Train Epoch: 7 [12800/37519 (34%)]\tLoss: 0.127044\n",
      "Train Epoch: 7 [13440/37519 (36%)]\tLoss: 0.325310\n",
      "Train Epoch: 7 [14080/37519 (37%)]\tLoss: 0.133157\n",
      "Train Epoch: 7 [14720/37519 (39%)]\tLoss: 0.152751\n",
      "Train Epoch: 7 [15360/37519 (41%)]\tLoss: 0.108535\n",
      "Train Epoch: 7 [16000/37519 (43%)]\tLoss: 0.133646\n",
      "Train Epoch: 7 [16640/37519 (44%)]\tLoss: 0.077892\n",
      "Train Epoch: 7 [17280/37519 (46%)]\tLoss: 0.080604\n",
      "Train Epoch: 7 [17920/37519 (48%)]\tLoss: 0.104966\n",
      "Train Epoch: 7 [18560/37519 (49%)]\tLoss: 0.067566\n",
      "Train Epoch: 7 [19200/37519 (51%)]\tLoss: 0.119129\n",
      "Train Epoch: 7 [19840/37519 (53%)]\tLoss: 0.042851\n",
      "Train Epoch: 7 [20480/37519 (55%)]\tLoss: 0.071659\n",
      "Train Epoch: 7 [21120/37519 (56%)]\tLoss: 0.073575\n",
      "Train Epoch: 7 [21760/37519 (58%)]\tLoss: 0.087528\n",
      "Train Epoch: 7 [22400/37519 (60%)]\tLoss: 0.061340\n",
      "Train Epoch: 7 [23040/37519 (61%)]\tLoss: 0.124631\n",
      "Train Epoch: 7 [23680/37519 (63%)]\tLoss: 0.173878\n",
      "Train Epoch: 7 [24320/37519 (65%)]\tLoss: 0.271530\n",
      "Train Epoch: 7 [24960/37519 (66%)]\tLoss: 0.174731\n",
      "Train Epoch: 7 [25600/37519 (68%)]\tLoss: 0.190951\n",
      "Train Epoch: 7 [26240/37519 (70%)]\tLoss: 0.209387\n",
      "Train Epoch: 7 [26880/37519 (72%)]\tLoss: 0.308993\n",
      "Train Epoch: 7 [27520/37519 (73%)]\tLoss: 0.278594\n",
      "Train Epoch: 7 [28160/37519 (75%)]\tLoss: 0.095700\n",
      "Train Epoch: 7 [28800/37519 (77%)]\tLoss: 0.236703\n",
      "Train Epoch: 7 [29440/37519 (78%)]\tLoss: 0.065530\n",
      "Train Epoch: 7 [30080/37519 (80%)]\tLoss: 0.264423\n",
      "Train Epoch: 7 [30720/37519 (82%)]\tLoss: 0.122282\n",
      "Train Epoch: 7 [31360/37519 (83%)]\tLoss: 0.083347\n",
      "Train Epoch: 7 [32000/37519 (85%)]\tLoss: 0.134285\n",
      "Train Epoch: 7 [32640/37519 (87%)]\tLoss: 0.078756\n",
      "Train Epoch: 7 [33280/37519 (89%)]\tLoss: 0.075878\n",
      "Train Epoch: 7 [33920/37519 (90%)]\tLoss: 0.083794\n",
      "Train Epoch: 7 [34560/37519 (92%)]\tLoss: 0.156205\n",
      "Train Epoch: 7 [35200/37519 (94%)]\tLoss: 0.065897\n",
      "Train Epoch: 7 [35840/37519 (95%)]\tLoss: 0.174724\n",
      "Train Epoch: 7 [36480/37519 (97%)]\tLoss: 0.022556\n",
      "Train Epoch: 7 [37120/37519 (99%)]\tLoss: 0.165144\n",
      "Train Epoch: 8 [0/37519 (0%)]\tLoss: 0.284188\n",
      "Train Epoch: 8 [640/37519 (2%)]\tLoss: 0.152435\n",
      "Train Epoch: 8 [1280/37519 (3%)]\tLoss: 0.126787\n",
      "Train Epoch: 8 [1920/37519 (5%)]\tLoss: 0.067894\n",
      "Train Epoch: 8 [2560/37519 (7%)]\tLoss: 0.080702\n",
      "Train Epoch: 8 [3200/37519 (9%)]\tLoss: 0.221848\n",
      "Train Epoch: 8 [3840/37519 (10%)]\tLoss: 0.210858\n",
      "Train Epoch: 8 [4480/37519 (12%)]\tLoss: 0.082874\n",
      "Train Epoch: 8 [5120/37519 (14%)]\tLoss: 0.089757\n",
      "Train Epoch: 8 [5760/37519 (15%)]\tLoss: 0.095054\n",
      "Train Epoch: 8 [6400/37519 (17%)]\tLoss: 0.064608\n",
      "Train Epoch: 8 [7040/37519 (19%)]\tLoss: 0.133823\n",
      "Train Epoch: 8 [7680/37519 (20%)]\tLoss: 0.386095\n",
      "Train Epoch: 8 [8320/37519 (22%)]\tLoss: 0.098480\n",
      "Train Epoch: 8 [8960/37519 (24%)]\tLoss: 0.048804\n",
      "Train Epoch: 8 [9600/37519 (26%)]\tLoss: 0.042395\n",
      "Train Epoch: 8 [10240/37519 (27%)]\tLoss: 0.200531\n",
      "Train Epoch: 8 [10880/37519 (29%)]\tLoss: 0.031206\n",
      "Train Epoch: 8 [11520/37519 (31%)]\tLoss: 0.172540\n",
      "Train Epoch: 8 [12160/37519 (32%)]\tLoss: 0.119363\n",
      "Train Epoch: 8 [12800/37519 (34%)]\tLoss: 0.077443\n",
      "Train Epoch: 8 [13440/37519 (36%)]\tLoss: 0.172103\n",
      "Train Epoch: 8 [14080/37519 (37%)]\tLoss: 0.104036\n",
      "Train Epoch: 8 [14720/37519 (39%)]\tLoss: 0.127151\n",
      "Train Epoch: 8 [15360/37519 (41%)]\tLoss: 0.068609\n",
      "Train Epoch: 8 [16000/37519 (43%)]\tLoss: 0.061224\n",
      "Train Epoch: 8 [16640/37519 (44%)]\tLoss: 0.184109\n",
      "Train Epoch: 8 [17280/37519 (46%)]\tLoss: 0.184702\n",
      "Train Epoch: 8 [17920/37519 (48%)]\tLoss: 0.155946\n",
      "Train Epoch: 8 [18560/37519 (49%)]\tLoss: 0.183901\n",
      "Train Epoch: 8 [19200/37519 (51%)]\tLoss: 0.048160\n",
      "Train Epoch: 8 [19840/37519 (53%)]\tLoss: 0.181394\n",
      "Train Epoch: 8 [20480/37519 (55%)]\tLoss: 0.048510\n",
      "Train Epoch: 8 [21120/37519 (56%)]\tLoss: 0.051576\n",
      "Train Epoch: 8 [21760/37519 (58%)]\tLoss: 0.146382\n",
      "Train Epoch: 8 [22400/37519 (60%)]\tLoss: 0.159564\n",
      "Train Epoch: 8 [23040/37519 (61%)]\tLoss: 0.249108\n",
      "Train Epoch: 8 [23680/37519 (63%)]\tLoss: 0.113532\n",
      "Train Epoch: 8 [24320/37519 (65%)]\tLoss: 0.042599\n",
      "Train Epoch: 8 [24960/37519 (66%)]\tLoss: 0.225268\n",
      "Train Epoch: 8 [25600/37519 (68%)]\tLoss: 0.179828\n",
      "Train Epoch: 8 [26240/37519 (70%)]\tLoss: 0.118242\n",
      "Train Epoch: 8 [26880/37519 (72%)]\tLoss: 0.085795\n",
      "Train Epoch: 8 [27520/37519 (73%)]\tLoss: 0.329750\n",
      "Train Epoch: 8 [28160/37519 (75%)]\tLoss: 0.064742\n",
      "Train Epoch: 8 [28800/37519 (77%)]\tLoss: 0.116964\n",
      "Train Epoch: 8 [29440/37519 (78%)]\tLoss: 0.135518\n",
      "Train Epoch: 8 [30080/37519 (80%)]\tLoss: 0.167686\n",
      "Train Epoch: 8 [30720/37519 (82%)]\tLoss: 0.086468\n",
      "Train Epoch: 8 [31360/37519 (83%)]\tLoss: 0.034343\n",
      "Train Epoch: 8 [32000/37519 (85%)]\tLoss: 0.091242\n",
      "Train Epoch: 8 [32640/37519 (87%)]\tLoss: 0.306118\n",
      "Train Epoch: 8 [33280/37519 (89%)]\tLoss: 0.071851\n",
      "Train Epoch: 8 [33920/37519 (90%)]\tLoss: 0.056812\n",
      "Train Epoch: 8 [34560/37519 (92%)]\tLoss: 0.217037\n",
      "Train Epoch: 8 [35200/37519 (94%)]\tLoss: 0.158590\n",
      "Train Epoch: 8 [35840/37519 (95%)]\tLoss: 0.132533\n",
      "Train Epoch: 8 [36480/37519 (97%)]\tLoss: 0.085953\n",
      "Train Epoch: 8 [37120/37519 (99%)]\tLoss: 0.078924\n",
      "Train Epoch: 9 [0/37519 (0%)]\tLoss: 0.148718\n",
      "Train Epoch: 9 [640/37519 (2%)]\tLoss: 0.071114\n",
      "Train Epoch: 9 [1280/37519 (3%)]\tLoss: 0.089024\n",
      "Train Epoch: 9 [1920/37519 (5%)]\tLoss: 0.149806\n",
      "Train Epoch: 9 [2560/37519 (7%)]\tLoss: 0.192718\n",
      "Train Epoch: 9 [3200/37519 (9%)]\tLoss: 0.159364\n",
      "Train Epoch: 9 [3840/37519 (10%)]\tLoss: 0.101243\n",
      "Train Epoch: 9 [4480/37519 (12%)]\tLoss: 0.283083\n",
      "Train Epoch: 9 [5120/37519 (14%)]\tLoss: 0.046971\n",
      "Train Epoch: 9 [5760/37519 (15%)]\tLoss: 0.161018\n",
      "Train Epoch: 9 [6400/37519 (17%)]\tLoss: 0.067634\n",
      "Train Epoch: 9 [7040/37519 (19%)]\tLoss: 0.095589\n",
      "Train Epoch: 9 [7680/37519 (20%)]\tLoss: 0.101328\n",
      "Train Epoch: 9 [8320/37519 (22%)]\tLoss: 0.039722\n",
      "Train Epoch: 9 [8960/37519 (24%)]\tLoss: 0.173968\n",
      "Train Epoch: 9 [9600/37519 (26%)]\tLoss: 0.232012\n",
      "Train Epoch: 9 [10240/37519 (27%)]\tLoss: 0.135450\n",
      "Train Epoch: 9 [10880/37519 (29%)]\tLoss: 0.156153\n",
      "Train Epoch: 9 [11520/37519 (31%)]\tLoss: 0.167851\n",
      "Train Epoch: 9 [12160/37519 (32%)]\tLoss: 0.184351\n",
      "Train Epoch: 9 [12800/37519 (34%)]\tLoss: 0.062228\n",
      "Train Epoch: 9 [13440/37519 (36%)]\tLoss: 0.101151\n",
      "Train Epoch: 9 [14080/37519 (37%)]\tLoss: 0.179227\n",
      "Train Epoch: 9 [14720/37519 (39%)]\tLoss: 0.081478\n",
      "Train Epoch: 9 [15360/37519 (41%)]\tLoss: 0.141553\n",
      "Train Epoch: 9 [16000/37519 (43%)]\tLoss: 0.059130\n",
      "Train Epoch: 9 [16640/37519 (44%)]\tLoss: 0.074739\n",
      "Train Epoch: 9 [17280/37519 (46%)]\tLoss: 0.404904\n",
      "Train Epoch: 9 [17920/37519 (48%)]\tLoss: 0.255594\n",
      "Train Epoch: 9 [18560/37519 (49%)]\tLoss: 0.092272\n",
      "Train Epoch: 9 [19200/37519 (51%)]\tLoss: 0.101439\n",
      "Train Epoch: 9 [19840/37519 (53%)]\tLoss: 0.074768\n",
      "Train Epoch: 9 [20480/37519 (55%)]\tLoss: 0.099711\n",
      "Train Epoch: 9 [21120/37519 (56%)]\tLoss: 0.050310\n",
      "Train Epoch: 9 [21760/37519 (58%)]\tLoss: 0.076051\n",
      "Train Epoch: 9 [22400/37519 (60%)]\tLoss: 0.229465\n",
      "Train Epoch: 9 [23040/37519 (61%)]\tLoss: 0.109314\n",
      "Train Epoch: 9 [23680/37519 (63%)]\tLoss: 0.125922\n",
      "Train Epoch: 9 [24320/37519 (65%)]\tLoss: 0.058490\n",
      "Train Epoch: 9 [24960/37519 (66%)]\tLoss: 0.141206\n",
      "Train Epoch: 9 [25600/37519 (68%)]\tLoss: 0.133207\n",
      "Train Epoch: 9 [26240/37519 (70%)]\tLoss: 0.152873\n",
      "Train Epoch: 9 [26880/37519 (72%)]\tLoss: 0.232539\n",
      "Train Epoch: 9 [27520/37519 (73%)]\tLoss: 0.103657\n",
      "Train Epoch: 9 [28160/37519 (75%)]\tLoss: 0.331946\n",
      "Train Epoch: 9 [28800/37519 (77%)]\tLoss: 0.056510\n",
      "Train Epoch: 9 [29440/37519 (78%)]\tLoss: 0.130224\n",
      "Train Epoch: 9 [30080/37519 (80%)]\tLoss: 0.104851\n",
      "Train Epoch: 9 [30720/37519 (82%)]\tLoss: 0.134563\n",
      "Train Epoch: 9 [31360/37519 (83%)]\tLoss: 0.152884\n",
      "Train Epoch: 9 [32000/37519 (85%)]\tLoss: 0.163644\n",
      "Train Epoch: 9 [32640/37519 (87%)]\tLoss: 0.132301\n",
      "Train Epoch: 9 [33280/37519 (89%)]\tLoss: 0.076688\n",
      "Train Epoch: 9 [33920/37519 (90%)]\tLoss: 0.144061\n",
      "Train Epoch: 9 [34560/37519 (92%)]\tLoss: 0.144849\n",
      "Train Epoch: 9 [35200/37519 (94%)]\tLoss: 0.053311\n",
      "Train Epoch: 9 [35840/37519 (95%)]\tLoss: 0.046888\n",
      "Train Epoch: 9 [36480/37519 (97%)]\tLoss: 0.305268\n",
      "Train Epoch: 9 [37120/37519 (99%)]\tLoss: 0.116032\n",
      "Train Epoch: 10 [0/37519 (0%)]\tLoss: 0.079662\n",
      "Train Epoch: 10 [640/37519 (2%)]\tLoss: 0.253895\n",
      "Train Epoch: 10 [1280/37519 (3%)]\tLoss: 0.142973\n",
      "Train Epoch: 10 [1920/37519 (5%)]\tLoss: 0.075571\n",
      "Train Epoch: 10 [2560/37519 (7%)]\tLoss: 0.105801\n",
      "Train Epoch: 10 [3200/37519 (9%)]\tLoss: 0.058765\n",
      "Train Epoch: 10 [3840/37519 (10%)]\tLoss: 0.226465\n",
      "Train Epoch: 10 [4480/37519 (12%)]\tLoss: 0.052408\n",
      "Train Epoch: 10 [5120/37519 (14%)]\tLoss: 0.086496\n",
      "Train Epoch: 10 [5760/37519 (15%)]\tLoss: 0.147551\n",
      "Train Epoch: 10 [6400/37519 (17%)]\tLoss: 0.014856\n",
      "Train Epoch: 10 [7040/37519 (19%)]\tLoss: 0.126237\n",
      "Train Epoch: 10 [7680/37519 (20%)]\tLoss: 0.134984\n",
      "Train Epoch: 10 [8320/37519 (22%)]\tLoss: 0.070727\n",
      "Train Epoch: 10 [8960/37519 (24%)]\tLoss: 0.081763\n",
      "Train Epoch: 10 [9600/37519 (26%)]\tLoss: 0.194461\n",
      "Train Epoch: 10 [10240/37519 (27%)]\tLoss: 0.251427\n",
      "Train Epoch: 10 [10880/37519 (29%)]\tLoss: 0.062108\n",
      "Train Epoch: 10 [11520/37519 (31%)]\tLoss: 0.063127\n",
      "Train Epoch: 10 [12160/37519 (32%)]\tLoss: 0.033806\n",
      "Train Epoch: 10 [12800/37519 (34%)]\tLoss: 0.119031\n",
      "Train Epoch: 10 [13440/37519 (36%)]\tLoss: 0.114845\n",
      "Train Epoch: 10 [14080/37519 (37%)]\tLoss: 0.204370\n",
      "Train Epoch: 10 [14720/37519 (39%)]\tLoss: 0.091698\n",
      "Train Epoch: 10 [15360/37519 (41%)]\tLoss: 0.180700\n",
      "Train Epoch: 10 [16000/37519 (43%)]\tLoss: 0.104730\n",
      "Train Epoch: 10 [16640/37519 (44%)]\tLoss: 0.190633\n",
      "Train Epoch: 10 [17280/37519 (46%)]\tLoss: 0.079811\n",
      "Train Epoch: 10 [17920/37519 (48%)]\tLoss: 0.104370\n",
      "Train Epoch: 10 [18560/37519 (49%)]\tLoss: 0.101976\n",
      "Train Epoch: 10 [19200/37519 (51%)]\tLoss: 0.038653\n",
      "Train Epoch: 10 [19840/37519 (53%)]\tLoss: 0.106174\n",
      "Train Epoch: 10 [20480/37519 (55%)]\tLoss: 0.086173\n",
      "Train Epoch: 10 [21120/37519 (56%)]\tLoss: 0.088702\n",
      "Train Epoch: 10 [21760/37519 (58%)]\tLoss: 0.140859\n",
      "Train Epoch: 10 [22400/37519 (60%)]\tLoss: 0.087240\n",
      "Train Epoch: 10 [23040/37519 (61%)]\tLoss: 0.089423\n",
      "Train Epoch: 10 [23680/37519 (63%)]\tLoss: 0.064426\n",
      "Train Epoch: 10 [24320/37519 (65%)]\tLoss: 0.125348\n",
      "Train Epoch: 10 [24960/37519 (66%)]\tLoss: 0.085091\n",
      "Train Epoch: 10 [25600/37519 (68%)]\tLoss: 0.167874\n",
      "Train Epoch: 10 [26240/37519 (70%)]\tLoss: 0.174428\n",
      "Train Epoch: 10 [26880/37519 (72%)]\tLoss: 0.174685\n",
      "Train Epoch: 10 [27520/37519 (73%)]\tLoss: 0.201296\n",
      "Train Epoch: 10 [28160/37519 (75%)]\tLoss: 0.052619\n",
      "Train Epoch: 10 [28800/37519 (77%)]\tLoss: 0.227912\n",
      "Train Epoch: 10 [29440/37519 (78%)]\tLoss: 0.243349\n",
      "Train Epoch: 10 [30080/37519 (80%)]\tLoss: 0.199135\n",
      "Train Epoch: 10 [30720/37519 (82%)]\tLoss: 0.149183\n",
      "Train Epoch: 10 [31360/37519 (83%)]\tLoss: 0.095902\n",
      "Train Epoch: 10 [32000/37519 (85%)]\tLoss: 0.092707\n",
      "Train Epoch: 10 [32640/37519 (87%)]\tLoss: 0.491506\n",
      "Train Epoch: 10 [33280/37519 (89%)]\tLoss: 0.085886\n",
      "Train Epoch: 10 [33920/37519 (90%)]\tLoss: 0.132872\n",
      "Train Epoch: 10 [34560/37519 (92%)]\tLoss: 0.094488\n",
      "Train Epoch: 10 [35200/37519 (94%)]\tLoss: 0.118172\n",
      "Train Epoch: 10 [35840/37519 (95%)]\tLoss: 0.071740\n",
      "Train Epoch: 10 [36480/37519 (97%)]\tLoss: 0.072318\n",
      "Train Epoch: 10 [37120/37519 (99%)]\tLoss: 0.188684\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/22481 (0%)]\tLoss: 0.100020\n",
      "Train Epoch: 1 [640/22481 (3%)]\tLoss: 0.185045\n",
      "Train Epoch: 1 [1280/22481 (6%)]\tLoss: 0.098312\n",
      "Train Epoch: 1 [1920/22481 (9%)]\tLoss: 0.224549\n",
      "Train Epoch: 1 [2560/22481 (11%)]\tLoss: 0.125695\n",
      "Train Epoch: 1 [3200/22481 (14%)]\tLoss: 0.131953\n",
      "Train Epoch: 1 [3840/22481 (17%)]\tLoss: 0.185206\n",
      "Train Epoch: 1 [4480/22481 (20%)]\tLoss: 0.158909\n",
      "Train Epoch: 1 [5120/22481 (23%)]\tLoss: 0.260114\n",
      "Train Epoch: 1 [5760/22481 (26%)]\tLoss: 0.208593\n",
      "Train Epoch: 1 [6400/22481 (28%)]\tLoss: 0.178977\n",
      "Train Epoch: 1 [7040/22481 (31%)]\tLoss: 0.098288\n",
      "Train Epoch: 1 [7680/22481 (34%)]\tLoss: 0.314899\n",
      "Train Epoch: 1 [8320/22481 (37%)]\tLoss: 0.109754\n",
      "Train Epoch: 1 [8960/22481 (40%)]\tLoss: 0.086001\n",
      "Train Epoch: 1 [9600/22481 (43%)]\tLoss: 0.296417\n",
      "Train Epoch: 1 [10240/22481 (45%)]\tLoss: 0.134787\n",
      "Train Epoch: 1 [10880/22481 (48%)]\tLoss: 0.093191\n",
      "Train Epoch: 1 [11520/22481 (51%)]\tLoss: 0.145359\n",
      "Train Epoch: 1 [12160/22481 (54%)]\tLoss: 0.125849\n",
      "Train Epoch: 1 [12800/22481 (57%)]\tLoss: 0.060423\n",
      "Train Epoch: 1 [13440/22481 (60%)]\tLoss: 0.059348\n",
      "Train Epoch: 1 [14080/22481 (62%)]\tLoss: 0.114370\n",
      "Train Epoch: 1 [14720/22481 (65%)]\tLoss: 0.101345\n",
      "Train Epoch: 1 [15360/22481 (68%)]\tLoss: 0.224191\n",
      "Train Epoch: 1 [16000/22481 (71%)]\tLoss: 0.028137\n",
      "Train Epoch: 1 [16640/22481 (74%)]\tLoss: 0.270812\n",
      "Train Epoch: 1 [17280/22481 (77%)]\tLoss: 0.134184\n",
      "Train Epoch: 1 [17920/22481 (80%)]\tLoss: 0.149201\n",
      "Train Epoch: 1 [18560/22481 (82%)]\tLoss: 0.087888\n",
      "Train Epoch: 1 [19200/22481 (85%)]\tLoss: 0.202498\n",
      "Train Epoch: 1 [19840/22481 (88%)]\tLoss: 0.079898\n",
      "Train Epoch: 1 [20480/22481 (91%)]\tLoss: 0.195592\n",
      "Train Epoch: 1 [21120/22481 (94%)]\tLoss: 0.243478\n",
      "Train Epoch: 1 [21760/22481 (97%)]\tLoss: 0.080164\n",
      "Train Epoch: 1 [22400/22481 (99%)]\tLoss: 0.062638\n",
      "Train Epoch: 2 [0/22481 (0%)]\tLoss: 0.213520\n",
      "Train Epoch: 2 [640/22481 (3%)]\tLoss: 0.108507\n",
      "Train Epoch: 2 [1280/22481 (6%)]\tLoss: 0.053149\n",
      "Train Epoch: 2 [1920/22481 (9%)]\tLoss: 0.064270\n",
      "Train Epoch: 2 [2560/22481 (11%)]\tLoss: 0.130652\n",
      "Train Epoch: 2 [3200/22481 (14%)]\tLoss: 0.150069\n",
      "Train Epoch: 2 [3840/22481 (17%)]\tLoss: 0.163197\n",
      "Train Epoch: 2 [4480/22481 (20%)]\tLoss: 0.124821\n",
      "Train Epoch: 2 [5120/22481 (23%)]\tLoss: 0.182605\n",
      "Train Epoch: 2 [5760/22481 (26%)]\tLoss: 0.078097\n",
      "Train Epoch: 2 [6400/22481 (28%)]\tLoss: 0.030791\n",
      "Train Epoch: 2 [7040/22481 (31%)]\tLoss: 0.060981\n",
      "Train Epoch: 2 [7680/22481 (34%)]\tLoss: 0.100750\n",
      "Train Epoch: 2 [8320/22481 (37%)]\tLoss: 0.147735\n",
      "Train Epoch: 2 [8960/22481 (40%)]\tLoss: 0.206994\n",
      "Train Epoch: 2 [9600/22481 (43%)]\tLoss: 0.200321\n",
      "Train Epoch: 2 [10240/22481 (45%)]\tLoss: 0.113910\n",
      "Train Epoch: 2 [10880/22481 (48%)]\tLoss: 0.027063\n",
      "Train Epoch: 2 [11520/22481 (51%)]\tLoss: 0.053422\n",
      "Train Epoch: 2 [12160/22481 (54%)]\tLoss: 0.146631\n",
      "Train Epoch: 2 [12800/22481 (57%)]\tLoss: 0.098691\n",
      "Train Epoch: 2 [13440/22481 (60%)]\tLoss: 0.179237\n",
      "Train Epoch: 2 [14080/22481 (62%)]\tLoss: 0.094328\n",
      "Train Epoch: 2 [14720/22481 (65%)]\tLoss: 0.107010\n",
      "Train Epoch: 2 [15360/22481 (68%)]\tLoss: 0.088885\n",
      "Train Epoch: 2 [16000/22481 (71%)]\tLoss: 0.242664\n",
      "Train Epoch: 2 [16640/22481 (74%)]\tLoss: 0.281046\n",
      "Train Epoch: 2 [17280/22481 (77%)]\tLoss: 0.049052\n",
      "Train Epoch: 2 [17920/22481 (80%)]\tLoss: 0.176330\n",
      "Train Epoch: 2 [18560/22481 (82%)]\tLoss: 0.319071\n",
      "Train Epoch: 2 [19200/22481 (85%)]\tLoss: 0.170955\n",
      "Train Epoch: 2 [19840/22481 (88%)]\tLoss: 0.054042\n",
      "Train Epoch: 2 [20480/22481 (91%)]\tLoss: 0.041721\n",
      "Train Epoch: 2 [21120/22481 (94%)]\tLoss: 0.046337\n",
      "Train Epoch: 2 [21760/22481 (97%)]\tLoss: 0.151929\n",
      "Train Epoch: 2 [22400/22481 (99%)]\tLoss: 0.218554\n",
      "Train Epoch: 3 [0/22481 (0%)]\tLoss: 0.074257\n",
      "Train Epoch: 3 [640/22481 (3%)]\tLoss: 0.232951\n",
      "Train Epoch: 3 [1280/22481 (6%)]\tLoss: 0.114366\n",
      "Train Epoch: 3 [1920/22481 (9%)]\tLoss: 0.249441\n",
      "Train Epoch: 3 [2560/22481 (11%)]\tLoss: 0.053879\n",
      "Train Epoch: 3 [3200/22481 (14%)]\tLoss: 0.271951\n",
      "Train Epoch: 3 [3840/22481 (17%)]\tLoss: 0.106486\n",
      "Train Epoch: 3 [4480/22481 (20%)]\tLoss: 0.082398\n",
      "Train Epoch: 3 [5120/22481 (23%)]\tLoss: 0.111772\n",
      "Train Epoch: 3 [5760/22481 (26%)]\tLoss: 0.175607\n",
      "Train Epoch: 3 [6400/22481 (28%)]\tLoss: 0.097687\n",
      "Train Epoch: 3 [7040/22481 (31%)]\tLoss: 0.081633\n",
      "Train Epoch: 3 [7680/22481 (34%)]\tLoss: 0.145759\n",
      "Train Epoch: 3 [8320/22481 (37%)]\tLoss: 0.113313\n",
      "Train Epoch: 3 [8960/22481 (40%)]\tLoss: 0.087069\n",
      "Train Epoch: 3 [9600/22481 (43%)]\tLoss: 0.205922\n",
      "Train Epoch: 3 [10240/22481 (45%)]\tLoss: 0.096880\n",
      "Train Epoch: 3 [10880/22481 (48%)]\tLoss: 0.087838\n",
      "Train Epoch: 3 [11520/22481 (51%)]\tLoss: 0.292635\n",
      "Train Epoch: 3 [12160/22481 (54%)]\tLoss: 0.149075\n",
      "Train Epoch: 3 [12800/22481 (57%)]\tLoss: 0.202083\n",
      "Train Epoch: 3 [13440/22481 (60%)]\tLoss: 0.119105\n",
      "Train Epoch: 3 [14080/22481 (62%)]\tLoss: 0.014268\n",
      "Train Epoch: 3 [14720/22481 (65%)]\tLoss: 0.063638\n",
      "Train Epoch: 3 [15360/22481 (68%)]\tLoss: 0.120967\n",
      "Train Epoch: 3 [16000/22481 (71%)]\tLoss: 0.064700\n",
      "Train Epoch: 3 [16640/22481 (74%)]\tLoss: 0.065138\n",
      "Train Epoch: 3 [17280/22481 (77%)]\tLoss: 0.128644\n",
      "Train Epoch: 3 [17920/22481 (80%)]\tLoss: 0.056709\n",
      "Train Epoch: 3 [18560/22481 (82%)]\tLoss: 0.018763\n",
      "Train Epoch: 3 [19200/22481 (85%)]\tLoss: 0.074446\n",
      "Train Epoch: 3 [19840/22481 (88%)]\tLoss: 0.069274\n",
      "Train Epoch: 3 [20480/22481 (91%)]\tLoss: 0.147972\n",
      "Train Epoch: 3 [21120/22481 (94%)]\tLoss: 0.102988\n",
      "Train Epoch: 3 [21760/22481 (97%)]\tLoss: 0.342194\n",
      "Train Epoch: 3 [22400/22481 (99%)]\tLoss: 0.137292\n",
      "Train Epoch: 4 [0/22481 (0%)]\tLoss: 0.053931\n",
      "Train Epoch: 4 [640/22481 (3%)]\tLoss: 0.088997\n",
      "Train Epoch: 4 [1280/22481 (6%)]\tLoss: 0.172942\n",
      "Train Epoch: 4 [1920/22481 (9%)]\tLoss: 0.053749\n",
      "Train Epoch: 4 [2560/22481 (11%)]\tLoss: 0.140811\n",
      "Train Epoch: 4 [3200/22481 (14%)]\tLoss: 0.239946\n",
      "Train Epoch: 4 [3840/22481 (17%)]\tLoss: 0.088155\n",
      "Train Epoch: 4 [4480/22481 (20%)]\tLoss: 0.152890\n",
      "Train Epoch: 4 [5120/22481 (23%)]\tLoss: 0.073430\n",
      "Train Epoch: 4 [5760/22481 (26%)]\tLoss: 0.075295\n",
      "Train Epoch: 4 [6400/22481 (28%)]\tLoss: 0.069122\n",
      "Train Epoch: 4 [7040/22481 (31%)]\tLoss: 0.080701\n",
      "Train Epoch: 4 [7680/22481 (34%)]\tLoss: 0.136538\n",
      "Train Epoch: 4 [8320/22481 (37%)]\tLoss: 0.342433\n",
      "Train Epoch: 4 [8960/22481 (40%)]\tLoss: 0.160134\n",
      "Train Epoch: 4 [9600/22481 (43%)]\tLoss: 0.097631\n",
      "Train Epoch: 4 [10240/22481 (45%)]\tLoss: 0.226711\n",
      "Train Epoch: 4 [10880/22481 (48%)]\tLoss: 0.145415\n",
      "Train Epoch: 4 [11520/22481 (51%)]\tLoss: 0.053936\n",
      "Train Epoch: 4 [12160/22481 (54%)]\tLoss: 0.141111\n",
      "Train Epoch: 4 [12800/22481 (57%)]\tLoss: 0.112212\n",
      "Train Epoch: 4 [13440/22481 (60%)]\tLoss: 0.070865\n",
      "Train Epoch: 4 [14080/22481 (62%)]\tLoss: 0.060222\n",
      "Train Epoch: 4 [14720/22481 (65%)]\tLoss: 0.222799\n",
      "Train Epoch: 4 [15360/22481 (68%)]\tLoss: 0.033090\n",
      "Train Epoch: 4 [16000/22481 (71%)]\tLoss: 0.075759\n",
      "Train Epoch: 4 [16640/22481 (74%)]\tLoss: 0.241169\n",
      "Train Epoch: 4 [17280/22481 (77%)]\tLoss: 0.042985\n",
      "Train Epoch: 4 [17920/22481 (80%)]\tLoss: 0.059984\n",
      "Train Epoch: 4 [18560/22481 (82%)]\tLoss: 0.009954\n",
      "Train Epoch: 4 [19200/22481 (85%)]\tLoss: 0.088989\n",
      "Train Epoch: 4 [19840/22481 (88%)]\tLoss: 0.142976\n",
      "Train Epoch: 4 [20480/22481 (91%)]\tLoss: 0.035955\n",
      "Train Epoch: 4 [21120/22481 (94%)]\tLoss: 0.074159\n",
      "Train Epoch: 4 [21760/22481 (97%)]\tLoss: 0.126946\n",
      "Train Epoch: 4 [22400/22481 (99%)]\tLoss: 0.132476\n",
      "Train Epoch: 5 [0/22481 (0%)]\tLoss: 0.158495\n",
      "Train Epoch: 5 [640/22481 (3%)]\tLoss: 0.122446\n",
      "Train Epoch: 5 [1280/22481 (6%)]\tLoss: 0.095154\n",
      "Train Epoch: 5 [1920/22481 (9%)]\tLoss: 0.081307\n",
      "Train Epoch: 5 [2560/22481 (11%)]\tLoss: 0.069926\n",
      "Train Epoch: 5 [3200/22481 (14%)]\tLoss: 0.057340\n",
      "Train Epoch: 5 [3840/22481 (17%)]\tLoss: 0.059158\n",
      "Train Epoch: 5 [4480/22481 (20%)]\tLoss: 0.110399\n",
      "Train Epoch: 5 [5120/22481 (23%)]\tLoss: 0.034496\n",
      "Train Epoch: 5 [5760/22481 (26%)]\tLoss: 0.057640\n",
      "Train Epoch: 5 [6400/22481 (28%)]\tLoss: 0.151254\n",
      "Train Epoch: 5 [7040/22481 (31%)]\tLoss: 0.094393\n",
      "Train Epoch: 5 [7680/22481 (34%)]\tLoss: 0.129826\n",
      "Train Epoch: 5 [8320/22481 (37%)]\tLoss: 0.132972\n",
      "Train Epoch: 5 [8960/22481 (40%)]\tLoss: 0.495676\n",
      "Train Epoch: 5 [9600/22481 (43%)]\tLoss: 0.125291\n",
      "Train Epoch: 5 [10240/22481 (45%)]\tLoss: 0.140478\n",
      "Train Epoch: 5 [10880/22481 (48%)]\tLoss: 0.212363\n",
      "Train Epoch: 5 [11520/22481 (51%)]\tLoss: 0.176805\n",
      "Train Epoch: 5 [12160/22481 (54%)]\tLoss: 0.280519\n",
      "Train Epoch: 5 [12800/22481 (57%)]\tLoss: 0.059208\n",
      "Train Epoch: 5 [13440/22481 (60%)]\tLoss: 0.188353\n",
      "Train Epoch: 5 [14080/22481 (62%)]\tLoss: 0.128647\n",
      "Train Epoch: 5 [14720/22481 (65%)]\tLoss: 0.153767\n",
      "Train Epoch: 5 [15360/22481 (68%)]\tLoss: 0.117422\n",
      "Train Epoch: 5 [16000/22481 (71%)]\tLoss: 0.221045\n",
      "Train Epoch: 5 [16640/22481 (74%)]\tLoss: 0.012904\n",
      "Train Epoch: 5 [17280/22481 (77%)]\tLoss: 0.133426\n",
      "Train Epoch: 5 [17920/22481 (80%)]\tLoss: 0.120727\n",
      "Train Epoch: 5 [18560/22481 (82%)]\tLoss: 0.282498\n",
      "Train Epoch: 5 [19200/22481 (85%)]\tLoss: 0.057191\n",
      "Train Epoch: 5 [19840/22481 (88%)]\tLoss: 0.069435\n",
      "Train Epoch: 5 [20480/22481 (91%)]\tLoss: 0.141562\n",
      "Train Epoch: 5 [21120/22481 (94%)]\tLoss: 0.036407\n",
      "Train Epoch: 5 [21760/22481 (97%)]\tLoss: 0.159389\n",
      "Train Epoch: 5 [22400/22481 (99%)]\tLoss: 0.374576\n",
      "Train Epoch: 6 [0/22481 (0%)]\tLoss: 0.106821\n",
      "Train Epoch: 6 [640/22481 (3%)]\tLoss: 0.061170\n",
      "Train Epoch: 6 [1280/22481 (6%)]\tLoss: 0.166380\n",
      "Train Epoch: 6 [1920/22481 (9%)]\tLoss: 0.431408\n",
      "Train Epoch: 6 [2560/22481 (11%)]\tLoss: 0.148499\n",
      "Train Epoch: 6 [3200/22481 (14%)]\tLoss: 0.031544\n",
      "Train Epoch: 6 [3840/22481 (17%)]\tLoss: 0.167984\n",
      "Train Epoch: 6 [4480/22481 (20%)]\tLoss: 0.042038\n",
      "Train Epoch: 6 [5120/22481 (23%)]\tLoss: 0.068839\n",
      "Train Epoch: 6 [5760/22481 (26%)]\tLoss: 0.065281\n",
      "Train Epoch: 6 [6400/22481 (28%)]\tLoss: 0.163761\n",
      "Train Epoch: 6 [7040/22481 (31%)]\tLoss: 0.196810\n",
      "Train Epoch: 6 [7680/22481 (34%)]\tLoss: 0.181174\n",
      "Train Epoch: 6 [8320/22481 (37%)]\tLoss: 0.108042\n",
      "Train Epoch: 6 [8960/22481 (40%)]\tLoss: 0.062225\n",
      "Train Epoch: 6 [9600/22481 (43%)]\tLoss: 0.193473\n",
      "Train Epoch: 6 [10240/22481 (45%)]\tLoss: 0.080662\n",
      "Train Epoch: 6 [10880/22481 (48%)]\tLoss: 0.140720\n",
      "Train Epoch: 6 [11520/22481 (51%)]\tLoss: 0.069544\n",
      "Train Epoch: 6 [12160/22481 (54%)]\tLoss: 0.119789\n",
      "Train Epoch: 6 [12800/22481 (57%)]\tLoss: 0.041130\n",
      "Train Epoch: 6 [13440/22481 (60%)]\tLoss: 0.117035\n",
      "Train Epoch: 6 [14080/22481 (62%)]\tLoss: 0.043381\n",
      "Train Epoch: 6 [14720/22481 (65%)]\tLoss: 0.170461\n",
      "Train Epoch: 6 [15360/22481 (68%)]\tLoss: 0.027902\n",
      "Train Epoch: 6 [16000/22481 (71%)]\tLoss: 0.023303\n",
      "Train Epoch: 6 [16640/22481 (74%)]\tLoss: 0.128089\n",
      "Train Epoch: 6 [17280/22481 (77%)]\tLoss: 0.134811\n",
      "Train Epoch: 6 [17920/22481 (80%)]\tLoss: 0.017472\n",
      "Train Epoch: 6 [18560/22481 (82%)]\tLoss: 0.105872\n",
      "Train Epoch: 6 [19200/22481 (85%)]\tLoss: 0.029248\n",
      "Train Epoch: 6 [19840/22481 (88%)]\tLoss: 0.128945\n",
      "Train Epoch: 6 [20480/22481 (91%)]\tLoss: 0.298564\n",
      "Train Epoch: 6 [21120/22481 (94%)]\tLoss: 0.194331\n",
      "Train Epoch: 6 [21760/22481 (97%)]\tLoss: 0.067525\n",
      "Train Epoch: 6 [22400/22481 (99%)]\tLoss: 0.107153\n",
      "Train Epoch: 7 [0/22481 (0%)]\tLoss: 0.135132\n",
      "Train Epoch: 7 [640/22481 (3%)]\tLoss: 0.052974\n",
      "Train Epoch: 7 [1280/22481 (6%)]\tLoss: 0.083202\n",
      "Train Epoch: 7 [1920/22481 (9%)]\tLoss: 0.233642\n",
      "Train Epoch: 7 [2560/22481 (11%)]\tLoss: 0.337897\n",
      "Train Epoch: 7 [3200/22481 (14%)]\tLoss: 0.133912\n",
      "Train Epoch: 7 [3840/22481 (17%)]\tLoss: 0.059012\n",
      "Train Epoch: 7 [4480/22481 (20%)]\tLoss: 0.240611\n",
      "Train Epoch: 7 [5120/22481 (23%)]\tLoss: 0.074514\n",
      "Train Epoch: 7 [5760/22481 (26%)]\tLoss: 0.133799\n",
      "Train Epoch: 7 [6400/22481 (28%)]\tLoss: 0.122175\n",
      "Train Epoch: 7 [7040/22481 (31%)]\tLoss: 0.133415\n",
      "Train Epoch: 7 [7680/22481 (34%)]\tLoss: 0.125564\n",
      "Train Epoch: 7 [8320/22481 (37%)]\tLoss: 0.044746\n",
      "Train Epoch: 7 [8960/22481 (40%)]\tLoss: 0.112849\n",
      "Train Epoch: 7 [9600/22481 (43%)]\tLoss: 0.172742\n",
      "Train Epoch: 7 [10240/22481 (45%)]\tLoss: 0.231688\n",
      "Train Epoch: 7 [10880/22481 (48%)]\tLoss: 0.066937\n",
      "Train Epoch: 7 [11520/22481 (51%)]\tLoss: 0.045693\n",
      "Train Epoch: 7 [12160/22481 (54%)]\tLoss: 0.313774\n",
      "Train Epoch: 7 [12800/22481 (57%)]\tLoss: 0.078010\n",
      "Train Epoch: 7 [13440/22481 (60%)]\tLoss: 0.120155\n",
      "Train Epoch: 7 [14080/22481 (62%)]\tLoss: 0.084639\n",
      "Train Epoch: 7 [14720/22481 (65%)]\tLoss: 0.222266\n",
      "Train Epoch: 7 [15360/22481 (68%)]\tLoss: 0.090910\n",
      "Train Epoch: 7 [16000/22481 (71%)]\tLoss: 0.026384\n",
      "Train Epoch: 7 [16640/22481 (74%)]\tLoss: 0.108660\n",
      "Train Epoch: 7 [17280/22481 (77%)]\tLoss: 0.009580\n",
      "Train Epoch: 7 [17920/22481 (80%)]\tLoss: 0.065029\n",
      "Train Epoch: 7 [18560/22481 (82%)]\tLoss: 0.110789\n",
      "Train Epoch: 7 [19200/22481 (85%)]\tLoss: 0.102997\n",
      "Train Epoch: 7 [19840/22481 (88%)]\tLoss: 0.068952\n",
      "Train Epoch: 7 [20480/22481 (91%)]\tLoss: 0.063764\n",
      "Train Epoch: 7 [21120/22481 (94%)]\tLoss: 0.053501\n",
      "Train Epoch: 7 [21760/22481 (97%)]\tLoss: 0.081875\n",
      "Train Epoch: 7 [22400/22481 (99%)]\tLoss: 0.187755\n",
      "Train Epoch: 8 [0/22481 (0%)]\tLoss: 0.044233\n",
      "Train Epoch: 8 [640/22481 (3%)]\tLoss: 0.127715\n",
      "Train Epoch: 8 [1280/22481 (6%)]\tLoss: 0.081172\n",
      "Train Epoch: 8 [1920/22481 (9%)]\tLoss: 0.085849\n",
      "Train Epoch: 8 [2560/22481 (11%)]\tLoss: 0.102394\n",
      "Train Epoch: 8 [3200/22481 (14%)]\tLoss: 0.097124\n",
      "Train Epoch: 8 [3840/22481 (17%)]\tLoss: 0.090355\n",
      "Train Epoch: 8 [4480/22481 (20%)]\tLoss: 0.092430\n",
      "Train Epoch: 8 [5120/22481 (23%)]\tLoss: 0.138338\n",
      "Train Epoch: 8 [5760/22481 (26%)]\tLoss: 0.057030\n",
      "Train Epoch: 8 [6400/22481 (28%)]\tLoss: 0.117920\n",
      "Train Epoch: 8 [7040/22481 (31%)]\tLoss: 0.223170\n",
      "Train Epoch: 8 [7680/22481 (34%)]\tLoss: 0.137055\n",
      "Train Epoch: 8 [8320/22481 (37%)]\tLoss: 0.107001\n",
      "Train Epoch: 8 [8960/22481 (40%)]\tLoss: 0.091775\n",
      "Train Epoch: 8 [9600/22481 (43%)]\tLoss: 0.049379\n",
      "Train Epoch: 8 [10240/22481 (45%)]\tLoss: 0.059515\n",
      "Train Epoch: 8 [10880/22481 (48%)]\tLoss: 0.111215\n",
      "Train Epoch: 8 [11520/22481 (51%)]\tLoss: 0.098694\n",
      "Train Epoch: 8 [12160/22481 (54%)]\tLoss: 0.112622\n",
      "Train Epoch: 8 [12800/22481 (57%)]\tLoss: 0.074533\n",
      "Train Epoch: 8 [13440/22481 (60%)]\tLoss: 0.129015\n",
      "Train Epoch: 8 [14080/22481 (62%)]\tLoss: 0.066518\n",
      "Train Epoch: 8 [14720/22481 (65%)]\tLoss: 0.093714\n",
      "Train Epoch: 8 [15360/22481 (68%)]\tLoss: 0.046366\n",
      "Train Epoch: 8 [16000/22481 (71%)]\tLoss: 0.064119\n",
      "Train Epoch: 8 [16640/22481 (74%)]\tLoss: 0.045010\n",
      "Train Epoch: 8 [17280/22481 (77%)]\tLoss: 0.074072\n",
      "Train Epoch: 8 [17920/22481 (80%)]\tLoss: 0.054036\n",
      "Train Epoch: 8 [18560/22481 (82%)]\tLoss: 0.064235\n",
      "Train Epoch: 8 [19200/22481 (85%)]\tLoss: 0.051950\n",
      "Train Epoch: 8 [19840/22481 (88%)]\tLoss: 0.289675\n",
      "Train Epoch: 8 [20480/22481 (91%)]\tLoss: 0.112971\n",
      "Train Epoch: 8 [21120/22481 (94%)]\tLoss: 0.149819\n",
      "Train Epoch: 8 [21760/22481 (97%)]\tLoss: 0.061256\n",
      "Train Epoch: 8 [22400/22481 (99%)]\tLoss: 0.116443\n",
      "Train Epoch: 9 [0/22481 (0%)]\tLoss: 0.060631\n",
      "Train Epoch: 9 [640/22481 (3%)]\tLoss: 0.034751\n",
      "Train Epoch: 9 [1280/22481 (6%)]\tLoss: 0.106922\n",
      "Train Epoch: 9 [1920/22481 (9%)]\tLoss: 0.134390\n",
      "Train Epoch: 9 [2560/22481 (11%)]\tLoss: 0.060660\n",
      "Train Epoch: 9 [3200/22481 (14%)]\tLoss: 0.232587\n",
      "Train Epoch: 9 [3840/22481 (17%)]\tLoss: 0.155189\n",
      "Train Epoch: 9 [4480/22481 (20%)]\tLoss: 0.042179\n",
      "Train Epoch: 9 [5120/22481 (23%)]\tLoss: 0.135276\n",
      "Train Epoch: 9 [5760/22481 (26%)]\tLoss: 0.115761\n",
      "Train Epoch: 9 [6400/22481 (28%)]\tLoss: 0.045836\n",
      "Train Epoch: 9 [7040/22481 (31%)]\tLoss: 0.054407\n",
      "Train Epoch: 9 [7680/22481 (34%)]\tLoss: 0.038428\n",
      "Train Epoch: 9 [8320/22481 (37%)]\tLoss: 0.035179\n",
      "Train Epoch: 9 [8960/22481 (40%)]\tLoss: 0.152629\n",
      "Train Epoch: 9 [9600/22481 (43%)]\tLoss: 0.036048\n",
      "Train Epoch: 9 [10240/22481 (45%)]\tLoss: 0.089172\n",
      "Train Epoch: 9 [10880/22481 (48%)]\tLoss: 0.160382\n",
      "Train Epoch: 9 [11520/22481 (51%)]\tLoss: 0.212224\n",
      "Train Epoch: 9 [12160/22481 (54%)]\tLoss: 0.063189\n",
      "Train Epoch: 9 [12800/22481 (57%)]\tLoss: 0.230517\n",
      "Train Epoch: 9 [13440/22481 (60%)]\tLoss: 0.079598\n",
      "Train Epoch: 9 [14080/22481 (62%)]\tLoss: 0.136308\n",
      "Train Epoch: 9 [14720/22481 (65%)]\tLoss: 0.089893\n",
      "Train Epoch: 9 [15360/22481 (68%)]\tLoss: 0.062271\n",
      "Train Epoch: 9 [16000/22481 (71%)]\tLoss: 0.038016\n",
      "Train Epoch: 9 [16640/22481 (74%)]\tLoss: 0.063310\n",
      "Train Epoch: 9 [17280/22481 (77%)]\tLoss: 0.107060\n",
      "Train Epoch: 9 [17920/22481 (80%)]\tLoss: 0.219873\n",
      "Train Epoch: 9 [18560/22481 (82%)]\tLoss: 0.076463\n",
      "Train Epoch: 9 [19200/22481 (85%)]\tLoss: 0.141507\n",
      "Train Epoch: 9 [19840/22481 (88%)]\tLoss: 0.086974\n",
      "Train Epoch: 9 [20480/22481 (91%)]\tLoss: 0.040809\n",
      "Train Epoch: 9 [21120/22481 (94%)]\tLoss: 0.051575\n",
      "Train Epoch: 9 [21760/22481 (97%)]\tLoss: 0.075333\n",
      "Train Epoch: 9 [22400/22481 (99%)]\tLoss: 0.137092\n",
      "Train Epoch: 10 [0/22481 (0%)]\tLoss: 0.062340\n",
      "Train Epoch: 10 [640/22481 (3%)]\tLoss: 0.079854\n",
      "Train Epoch: 10 [1280/22481 (6%)]\tLoss: 0.061291\n",
      "Train Epoch: 10 [1920/22481 (9%)]\tLoss: 0.118680\n",
      "Train Epoch: 10 [2560/22481 (11%)]\tLoss: 0.093170\n",
      "Train Epoch: 10 [3200/22481 (14%)]\tLoss: 0.215772\n",
      "Train Epoch: 10 [3840/22481 (17%)]\tLoss: 0.036104\n",
      "Train Epoch: 10 [4480/22481 (20%)]\tLoss: 0.020221\n",
      "Train Epoch: 10 [5120/22481 (23%)]\tLoss: 0.085333\n",
      "Train Epoch: 10 [5760/22481 (26%)]\tLoss: 0.122044\n",
      "Train Epoch: 10 [6400/22481 (28%)]\tLoss: 0.055159\n",
      "Train Epoch: 10 [7040/22481 (31%)]\tLoss: 0.084013\n",
      "Train Epoch: 10 [7680/22481 (34%)]\tLoss: 0.096347\n",
      "Train Epoch: 10 [8320/22481 (37%)]\tLoss: 0.070202\n",
      "Train Epoch: 10 [8960/22481 (40%)]\tLoss: 0.113094\n",
      "Train Epoch: 10 [9600/22481 (43%)]\tLoss: 0.021809\n",
      "Train Epoch: 10 [10240/22481 (45%)]\tLoss: 0.157968\n",
      "Train Epoch: 10 [10880/22481 (48%)]\tLoss: 0.112674\n",
      "Train Epoch: 10 [11520/22481 (51%)]\tLoss: 0.164838\n",
      "Train Epoch: 10 [12160/22481 (54%)]\tLoss: 0.090639\n",
      "Train Epoch: 10 [12800/22481 (57%)]\tLoss: 0.174785\n",
      "Train Epoch: 10 [13440/22481 (60%)]\tLoss: 0.054913\n",
      "Train Epoch: 10 [14080/22481 (62%)]\tLoss: 0.100222\n",
      "Train Epoch: 10 [14720/22481 (65%)]\tLoss: 0.049066\n",
      "Train Epoch: 10 [15360/22481 (68%)]\tLoss: 0.044094\n",
      "Train Epoch: 10 [16000/22481 (71%)]\tLoss: 0.040394\n",
      "Train Epoch: 10 [16640/22481 (74%)]\tLoss: 0.072597\n",
      "Train Epoch: 10 [17280/22481 (77%)]\tLoss: 0.039517\n",
      "Train Epoch: 10 [17920/22481 (80%)]\tLoss: 0.089039\n",
      "Train Epoch: 10 [18560/22481 (82%)]\tLoss: 0.182190\n",
      "Train Epoch: 10 [19200/22481 (85%)]\tLoss: 0.090325\n",
      "Train Epoch: 10 [19840/22481 (88%)]\tLoss: 0.171718\n",
      "Train Epoch: 10 [20480/22481 (91%)]\tLoss: 0.157524\n",
      "Train Epoch: 10 [21120/22481 (94%)]\tLoss: 0.077109\n",
      "Train Epoch: 10 [21760/22481 (97%)]\tLoss: 0.108443\n",
      "Train Epoch: 10 [22400/22481 (99%)]\tLoss: 0.185090\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0608, Accuracy: 9814/10000 (98%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/18662 (0%)]\tLoss: 0.243080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [640/18662 (3%)]\tLoss: 0.111780\n",
      "Train Epoch: 1 [1280/18662 (7%)]\tLoss: 0.064580\n",
      "Train Epoch: 1 [1920/18662 (10%)]\tLoss: 0.068523\n",
      "Train Epoch: 1 [2560/18662 (14%)]\tLoss: 0.059840\n",
      "Train Epoch: 1 [3200/18662 (17%)]\tLoss: 0.127855\n",
      "Train Epoch: 1 [3840/18662 (21%)]\tLoss: 0.111412\n",
      "Train Epoch: 1 [4480/18662 (24%)]\tLoss: 0.185078\n",
      "Train Epoch: 1 [5120/18662 (27%)]\tLoss: 0.189730\n",
      "Train Epoch: 1 [5760/18662 (31%)]\tLoss: 0.108250\n",
      "Train Epoch: 1 [6400/18662 (34%)]\tLoss: 0.262335\n",
      "Train Epoch: 1 [7040/18662 (38%)]\tLoss: 0.038459\n",
      "Train Epoch: 1 [7680/18662 (41%)]\tLoss: 0.065056\n",
      "Train Epoch: 1 [8320/18662 (45%)]\tLoss: 0.143644\n",
      "Train Epoch: 1 [8960/18662 (48%)]\tLoss: 0.113351\n",
      "Train Epoch: 1 [9600/18662 (51%)]\tLoss: 0.100093\n",
      "Train Epoch: 1 [10240/18662 (55%)]\tLoss: 0.036720\n",
      "Train Epoch: 1 [10880/18662 (58%)]\tLoss: 0.087962\n",
      "Train Epoch: 1 [11520/18662 (62%)]\tLoss: 0.085151\n",
      "Train Epoch: 1 [12160/18662 (65%)]\tLoss: 0.110197\n",
      "Train Epoch: 1 [12800/18662 (68%)]\tLoss: 0.026393\n",
      "Train Epoch: 1 [13440/18662 (72%)]\tLoss: 0.066275\n",
      "Train Epoch: 1 [14080/18662 (75%)]\tLoss: 0.092473\n",
      "Train Epoch: 1 [14720/18662 (79%)]\tLoss: 0.221234\n",
      "Train Epoch: 1 [15360/18662 (82%)]\tLoss: 0.146703\n",
      "Train Epoch: 1 [16000/18662 (86%)]\tLoss: 0.159715\n",
      "Train Epoch: 1 [16640/18662 (89%)]\tLoss: 0.116732\n",
      "Train Epoch: 1 [17280/18662 (92%)]\tLoss: 0.073583\n",
      "Train Epoch: 1 [17920/18662 (96%)]\tLoss: 0.188288\n",
      "Train Epoch: 1 [18560/18662 (99%)]\tLoss: 0.079854\n",
      "Train Epoch: 2 [0/18662 (0%)]\tLoss: 0.095648\n",
      "Train Epoch: 2 [640/18662 (3%)]\tLoss: 0.035553\n",
      "Train Epoch: 2 [1280/18662 (7%)]\tLoss: 0.033904\n",
      "Train Epoch: 2 [1920/18662 (10%)]\tLoss: 0.099205\n",
      "Train Epoch: 2 [2560/18662 (14%)]\tLoss: 0.056395\n",
      "Train Epoch: 2 [3200/18662 (17%)]\tLoss: 0.039099\n",
      "Train Epoch: 2 [3840/18662 (21%)]\tLoss: 0.108659\n",
      "Train Epoch: 2 [4480/18662 (24%)]\tLoss: 0.033398\n",
      "Train Epoch: 2 [5120/18662 (27%)]\tLoss: 0.092654\n",
      "Train Epoch: 2 [5760/18662 (31%)]\tLoss: 0.255130\n",
      "Train Epoch: 2 [6400/18662 (34%)]\tLoss: 0.068953\n",
      "Train Epoch: 2 [7040/18662 (38%)]\tLoss: 0.099755\n",
      "Train Epoch: 2 [7680/18662 (41%)]\tLoss: 0.042381\n",
      "Train Epoch: 2 [8320/18662 (45%)]\tLoss: 0.459403\n",
      "Train Epoch: 2 [8960/18662 (48%)]\tLoss: 0.131849\n",
      "Train Epoch: 2 [9600/18662 (51%)]\tLoss: 0.057830\n",
      "Train Epoch: 2 [10240/18662 (55%)]\tLoss: 0.075017\n",
      "Train Epoch: 2 [10880/18662 (58%)]\tLoss: 0.068952\n",
      "Train Epoch: 2 [11520/18662 (62%)]\tLoss: 0.090255\n",
      "Train Epoch: 2 [12160/18662 (65%)]\tLoss: 0.272650\n",
      "Train Epoch: 2 [12800/18662 (68%)]\tLoss: 0.064067\n",
      "Train Epoch: 2 [13440/18662 (72%)]\tLoss: 0.098065\n",
      "Train Epoch: 2 [14080/18662 (75%)]\tLoss: 0.086068\n",
      "Train Epoch: 2 [14720/18662 (79%)]\tLoss: 0.060293\n",
      "Train Epoch: 2 [15360/18662 (82%)]\tLoss: 0.072050\n",
      "Train Epoch: 2 [16000/18662 (86%)]\tLoss: 0.018773\n",
      "Train Epoch: 2 [16640/18662 (89%)]\tLoss: 0.100199\n",
      "Train Epoch: 2 [17280/18662 (92%)]\tLoss: 0.124132\n",
      "Train Epoch: 2 [17920/18662 (96%)]\tLoss: 0.090308\n",
      "Train Epoch: 2 [18560/18662 (99%)]\tLoss: 0.025488\n",
      "Train Epoch: 3 [0/18662 (0%)]\tLoss: 0.082430\n",
      "Train Epoch: 3 [640/18662 (3%)]\tLoss: 0.078144\n",
      "Train Epoch: 3 [1280/18662 (7%)]\tLoss: 0.196457\n",
      "Train Epoch: 3 [1920/18662 (10%)]\tLoss: 0.055805\n",
      "Train Epoch: 3 [2560/18662 (14%)]\tLoss: 0.075609\n",
      "Train Epoch: 3 [3200/18662 (17%)]\tLoss: 0.512758\n",
      "Train Epoch: 3 [3840/18662 (21%)]\tLoss: 0.212066\n",
      "Train Epoch: 3 [4480/18662 (24%)]\tLoss: 0.186977\n",
      "Train Epoch: 3 [5120/18662 (27%)]\tLoss: 0.111360\n",
      "Train Epoch: 3 [5760/18662 (31%)]\tLoss: 0.150187\n",
      "Train Epoch: 3 [6400/18662 (34%)]\tLoss: 0.091493\n",
      "Train Epoch: 3 [7040/18662 (38%)]\tLoss: 0.157395\n",
      "Train Epoch: 3 [7680/18662 (41%)]\tLoss: 0.130860\n",
      "Train Epoch: 3 [8320/18662 (45%)]\tLoss: 0.051609\n",
      "Train Epoch: 3 [8960/18662 (48%)]\tLoss: 0.035067\n",
      "Train Epoch: 3 [9600/18662 (51%)]\tLoss: 0.029291\n",
      "Train Epoch: 3 [10240/18662 (55%)]\tLoss: 0.053941\n",
      "Train Epoch: 3 [10880/18662 (58%)]\tLoss: 0.229876\n",
      "Train Epoch: 3 [11520/18662 (62%)]\tLoss: 0.057660\n",
      "Train Epoch: 3 [12160/18662 (65%)]\tLoss: 0.037282\n",
      "Train Epoch: 3 [12800/18662 (68%)]\tLoss: 0.052010\n",
      "Train Epoch: 3 [13440/18662 (72%)]\tLoss: 0.140622\n",
      "Train Epoch: 3 [14080/18662 (75%)]\tLoss: 0.179045\n",
      "Train Epoch: 3 [14720/18662 (79%)]\tLoss: 0.142261\n",
      "Train Epoch: 3 [15360/18662 (82%)]\tLoss: 0.060985\n",
      "Train Epoch: 3 [16000/18662 (86%)]\tLoss: 0.033942\n",
      "Train Epoch: 3 [16640/18662 (89%)]\tLoss: 0.185549\n",
      "Train Epoch: 3 [17280/18662 (92%)]\tLoss: 0.141755\n",
      "Train Epoch: 3 [17920/18662 (96%)]\tLoss: 0.090303\n",
      "Train Epoch: 3 [18560/18662 (99%)]\tLoss: 0.093429\n",
      "Train Epoch: 4 [0/18662 (0%)]\tLoss: 0.025461\n",
      "Train Epoch: 4 [640/18662 (3%)]\tLoss: 0.019730\n",
      "Train Epoch: 4 [1280/18662 (7%)]\tLoss: 0.028834\n",
      "Train Epoch: 4 [1920/18662 (10%)]\tLoss: 0.065720\n",
      "Train Epoch: 4 [2560/18662 (14%)]\tLoss: 0.115699\n",
      "Train Epoch: 4 [3200/18662 (17%)]\tLoss: 0.208451\n",
      "Train Epoch: 4 [3840/18662 (21%)]\tLoss: 0.043574\n",
      "Train Epoch: 4 [4480/18662 (24%)]\tLoss: 0.026953\n",
      "Train Epoch: 4 [5120/18662 (27%)]\tLoss: 0.163973\n",
      "Train Epoch: 4 [5760/18662 (31%)]\tLoss: 0.027680\n",
      "Train Epoch: 4 [6400/18662 (34%)]\tLoss: 0.076800\n",
      "Train Epoch: 4 [7040/18662 (38%)]\tLoss: 0.135009\n",
      "Train Epoch: 4 [7680/18662 (41%)]\tLoss: 0.050025\n",
      "Train Epoch: 4 [8320/18662 (45%)]\tLoss: 0.032323\n",
      "Train Epoch: 4 [8960/18662 (48%)]\tLoss: 0.153148\n",
      "Train Epoch: 4 [9600/18662 (51%)]\tLoss: 0.058791\n",
      "Train Epoch: 4 [10240/18662 (55%)]\tLoss: 0.125564\n",
      "Train Epoch: 4 [10880/18662 (58%)]\tLoss: 0.132400\n",
      "Train Epoch: 4 [11520/18662 (62%)]\tLoss: 0.053998\n",
      "Train Epoch: 4 [12160/18662 (65%)]\tLoss: 0.207255\n",
      "Train Epoch: 4 [12800/18662 (68%)]\tLoss: 0.155866\n",
      "Train Epoch: 4 [13440/18662 (72%)]\tLoss: 0.077688\n",
      "Train Epoch: 4 [14080/18662 (75%)]\tLoss: 0.027103\n",
      "Train Epoch: 4 [14720/18662 (79%)]\tLoss: 0.053041\n",
      "Train Epoch: 4 [15360/18662 (82%)]\tLoss: 0.031690\n",
      "Train Epoch: 4 [16000/18662 (86%)]\tLoss: 0.099953\n",
      "Train Epoch: 4 [16640/18662 (89%)]\tLoss: 0.033939\n",
      "Train Epoch: 4 [17280/18662 (92%)]\tLoss: 0.120070\n",
      "Train Epoch: 4 [17920/18662 (96%)]\tLoss: 0.063168\n",
      "Train Epoch: 4 [18560/18662 (99%)]\tLoss: 0.159893\n",
      "Train Epoch: 5 [0/18662 (0%)]\tLoss: 0.080761\n",
      "Train Epoch: 5 [640/18662 (3%)]\tLoss: 0.013696\n",
      "Train Epoch: 5 [1280/18662 (7%)]\tLoss: 0.025864\n",
      "Train Epoch: 5 [1920/18662 (10%)]\tLoss: 0.149209\n",
      "Train Epoch: 5 [2560/18662 (14%)]\tLoss: 0.049972\n",
      "Train Epoch: 5 [3200/18662 (17%)]\tLoss: 0.081462\n",
      "Train Epoch: 5 [3840/18662 (21%)]\tLoss: 0.026728\n",
      "Train Epoch: 5 [4480/18662 (24%)]\tLoss: 0.056341\n",
      "Train Epoch: 5 [5120/18662 (27%)]\tLoss: 0.071426\n",
      "Train Epoch: 5 [5760/18662 (31%)]\tLoss: 0.060719\n",
      "Train Epoch: 5 [6400/18662 (34%)]\tLoss: 0.116093\n",
      "Train Epoch: 5 [7040/18662 (38%)]\tLoss: 0.153343\n",
      "Train Epoch: 5 [7680/18662 (41%)]\tLoss: 0.044585\n",
      "Train Epoch: 5 [8320/18662 (45%)]\tLoss: 0.029014\n",
      "Train Epoch: 5 [8960/18662 (48%)]\tLoss: 0.030549\n",
      "Train Epoch: 5 [9600/18662 (51%)]\tLoss: 0.061562\n",
      "Train Epoch: 5 [10240/18662 (55%)]\tLoss: 0.048849\n",
      "Train Epoch: 5 [10880/18662 (58%)]\tLoss: 0.101014\n",
      "Train Epoch: 5 [11520/18662 (62%)]\tLoss: 0.155604\n",
      "Train Epoch: 5 [12160/18662 (65%)]\tLoss: 0.101692\n",
      "Train Epoch: 5 [12800/18662 (68%)]\tLoss: 0.120935\n",
      "Train Epoch: 5 [13440/18662 (72%)]\tLoss: 0.023419\n",
      "Train Epoch: 5 [14080/18662 (75%)]\tLoss: 0.122463\n",
      "Train Epoch: 5 [14720/18662 (79%)]\tLoss: 0.058664\n",
      "Train Epoch: 5 [15360/18662 (82%)]\tLoss: 0.079522\n",
      "Train Epoch: 5 [16000/18662 (86%)]\tLoss: 0.018028\n",
      "Train Epoch: 5 [16640/18662 (89%)]\tLoss: 0.137994\n",
      "Train Epoch: 5 [17280/18662 (92%)]\tLoss: 0.038735\n",
      "Train Epoch: 5 [17920/18662 (96%)]\tLoss: 0.170749\n",
      "Train Epoch: 5 [18560/18662 (99%)]\tLoss: 0.134708\n",
      "Train Epoch: 6 [0/18662 (0%)]\tLoss: 0.109019\n",
      "Train Epoch: 6 [640/18662 (3%)]\tLoss: 0.073977\n",
      "Train Epoch: 6 [1280/18662 (7%)]\tLoss: 0.028969\n",
      "Train Epoch: 6 [1920/18662 (10%)]\tLoss: 0.132525\n",
      "Train Epoch: 6 [2560/18662 (14%)]\tLoss: 0.069392\n",
      "Train Epoch: 6 [3200/18662 (17%)]\tLoss: 0.060738\n",
      "Train Epoch: 6 [3840/18662 (21%)]\tLoss: 0.042054\n",
      "Train Epoch: 6 [4480/18662 (24%)]\tLoss: 0.036598\n",
      "Train Epoch: 6 [5120/18662 (27%)]\tLoss: 0.017170\n",
      "Train Epoch: 6 [5760/18662 (31%)]\tLoss: 0.273454\n",
      "Train Epoch: 6 [6400/18662 (34%)]\tLoss: 0.055783\n",
      "Train Epoch: 6 [7040/18662 (38%)]\tLoss: 0.068878\n",
      "Train Epoch: 6 [7680/18662 (41%)]\tLoss: 0.062482\n",
      "Train Epoch: 6 [8320/18662 (45%)]\tLoss: 0.076399\n",
      "Train Epoch: 6 [8960/18662 (48%)]\tLoss: 0.036196\n",
      "Train Epoch: 6 [9600/18662 (51%)]\tLoss: 0.040205\n",
      "Train Epoch: 6 [10240/18662 (55%)]\tLoss: 0.026797\n",
      "Train Epoch: 6 [10880/18662 (58%)]\tLoss: 0.041094\n",
      "Train Epoch: 6 [11520/18662 (62%)]\tLoss: 0.045977\n",
      "Train Epoch: 6 [12160/18662 (65%)]\tLoss: 0.023798\n",
      "Train Epoch: 6 [12800/18662 (68%)]\tLoss: 0.064001\n",
      "Train Epoch: 6 [13440/18662 (72%)]\tLoss: 0.253402\n",
      "Train Epoch: 6 [14080/18662 (75%)]\tLoss: 0.161363\n",
      "Train Epoch: 6 [14720/18662 (79%)]\tLoss: 0.076963\n",
      "Train Epoch: 6 [15360/18662 (82%)]\tLoss: 0.102008\n",
      "Train Epoch: 6 [16000/18662 (86%)]\tLoss: 0.055163\n",
      "Train Epoch: 6 [16640/18662 (89%)]\tLoss: 0.054298\n",
      "Train Epoch: 6 [17280/18662 (92%)]\tLoss: 0.044307\n",
      "Train Epoch: 6 [17920/18662 (96%)]\tLoss: 0.044056\n",
      "Train Epoch: 6 [18560/18662 (99%)]\tLoss: 0.041738\n",
      "Train Epoch: 7 [0/18662 (0%)]\tLoss: 0.054750\n",
      "Train Epoch: 7 [640/18662 (3%)]\tLoss: 0.033521\n",
      "Train Epoch: 7 [1280/18662 (7%)]\tLoss: 0.168712\n",
      "Train Epoch: 7 [1920/18662 (10%)]\tLoss: 0.111968\n",
      "Train Epoch: 7 [2560/18662 (14%)]\tLoss: 0.068359\n",
      "Train Epoch: 7 [3200/18662 (17%)]\tLoss: 0.124529\n",
      "Train Epoch: 7 [3840/18662 (21%)]\tLoss: 0.065201\n",
      "Train Epoch: 7 [4480/18662 (24%)]\tLoss: 0.056339\n",
      "Train Epoch: 7 [5120/18662 (27%)]\tLoss: 0.063284\n",
      "Train Epoch: 7 [5760/18662 (31%)]\tLoss: 0.019736\n",
      "Train Epoch: 7 [6400/18662 (34%)]\tLoss: 0.031741\n",
      "Train Epoch: 7 [7040/18662 (38%)]\tLoss: 0.139724\n",
      "Train Epoch: 7 [7680/18662 (41%)]\tLoss: 0.014127\n",
      "Train Epoch: 7 [8320/18662 (45%)]\tLoss: 0.107945\n",
      "Train Epoch: 7 [8960/18662 (48%)]\tLoss: 0.031390\n",
      "Train Epoch: 7 [9600/18662 (51%)]\tLoss: 0.045150\n",
      "Train Epoch: 7 [10240/18662 (55%)]\tLoss: 0.224804\n",
      "Train Epoch: 7 [10880/18662 (58%)]\tLoss: 0.072978\n",
      "Train Epoch: 7 [11520/18662 (62%)]\tLoss: 0.074014\n",
      "Train Epoch: 7 [12160/18662 (65%)]\tLoss: 0.027965\n",
      "Train Epoch: 7 [12800/18662 (68%)]\tLoss: 0.036819\n",
      "Train Epoch: 7 [13440/18662 (72%)]\tLoss: 0.052229\n",
      "Train Epoch: 7 [14080/18662 (75%)]\tLoss: 0.123916\n",
      "Train Epoch: 7 [14720/18662 (79%)]\tLoss: 0.049720\n",
      "Train Epoch: 7 [15360/18662 (82%)]\tLoss: 0.112422\n",
      "Train Epoch: 7 [16000/18662 (86%)]\tLoss: 0.111116\n",
      "Train Epoch: 7 [16640/18662 (89%)]\tLoss: 0.052101\n",
      "Train Epoch: 7 [17280/18662 (92%)]\tLoss: 0.092993\n",
      "Train Epoch: 7 [17920/18662 (96%)]\tLoss: 0.181276\n",
      "Train Epoch: 7 [18560/18662 (99%)]\tLoss: 0.038915\n",
      "Train Epoch: 8 [0/18662 (0%)]\tLoss: 0.111198\n",
      "Train Epoch: 8 [640/18662 (3%)]\tLoss: 0.097184\n",
      "Train Epoch: 8 [1280/18662 (7%)]\tLoss: 0.108277\n",
      "Train Epoch: 8 [1920/18662 (10%)]\tLoss: 0.036743\n",
      "Train Epoch: 8 [2560/18662 (14%)]\tLoss: 0.075559\n",
      "Train Epoch: 8 [3200/18662 (17%)]\tLoss: 0.037296\n",
      "Train Epoch: 8 [3840/18662 (21%)]\tLoss: 0.103048\n",
      "Train Epoch: 8 [4480/18662 (24%)]\tLoss: 0.014947\n",
      "Train Epoch: 8 [5120/18662 (27%)]\tLoss: 0.065744\n",
      "Train Epoch: 8 [5760/18662 (31%)]\tLoss: 0.036790\n",
      "Train Epoch: 8 [6400/18662 (34%)]\tLoss: 0.103038\n",
      "Train Epoch: 8 [7040/18662 (38%)]\tLoss: 0.079074\n",
      "Train Epoch: 8 [7680/18662 (41%)]\tLoss: 0.079178\n",
      "Train Epoch: 8 [8320/18662 (45%)]\tLoss: 0.138042\n",
      "Train Epoch: 8 [8960/18662 (48%)]\tLoss: 0.105112\n",
      "Train Epoch: 8 [9600/18662 (51%)]\tLoss: 0.071608\n",
      "Train Epoch: 8 [10240/18662 (55%)]\tLoss: 0.166935\n",
      "Train Epoch: 8 [10880/18662 (58%)]\tLoss: 0.117848\n",
      "Train Epoch: 8 [11520/18662 (62%)]\tLoss: 0.084117\n",
      "Train Epoch: 8 [12160/18662 (65%)]\tLoss: 0.107906\n",
      "Train Epoch: 8 [12800/18662 (68%)]\tLoss: 0.027716\n",
      "Train Epoch: 8 [13440/18662 (72%)]\tLoss: 0.104578\n",
      "Train Epoch: 8 [14080/18662 (75%)]\tLoss: 0.112700\n",
      "Train Epoch: 8 [14720/18662 (79%)]\tLoss: 0.055256\n",
      "Train Epoch: 8 [15360/18662 (82%)]\tLoss: 0.054642\n",
      "Train Epoch: 8 [16000/18662 (86%)]\tLoss: 0.028871\n",
      "Train Epoch: 8 [16640/18662 (89%)]\tLoss: 0.178187\n",
      "Train Epoch: 8 [17280/18662 (92%)]\tLoss: 0.059498\n",
      "Train Epoch: 8 [17920/18662 (96%)]\tLoss: 0.102257\n",
      "Train Epoch: 8 [18560/18662 (99%)]\tLoss: 0.059434\n",
      "Train Epoch: 9 [0/18662 (0%)]\tLoss: 0.018840\n",
      "Train Epoch: 9 [640/18662 (3%)]\tLoss: 0.023044\n",
      "Train Epoch: 9 [1280/18662 (7%)]\tLoss: 0.061470\n",
      "Train Epoch: 9 [1920/18662 (10%)]\tLoss: 0.106373\n",
      "Train Epoch: 9 [2560/18662 (14%)]\tLoss: 0.010355\n",
      "Train Epoch: 9 [3200/18662 (17%)]\tLoss: 0.080361\n",
      "Train Epoch: 9 [3840/18662 (21%)]\tLoss: 0.122727\n",
      "Train Epoch: 9 [4480/18662 (24%)]\tLoss: 0.098537\n",
      "Train Epoch: 9 [5120/18662 (27%)]\tLoss: 0.052679\n",
      "Train Epoch: 9 [5760/18662 (31%)]\tLoss: 0.046883\n",
      "Train Epoch: 9 [6400/18662 (34%)]\tLoss: 0.045920\n",
      "Train Epoch: 9 [7040/18662 (38%)]\tLoss: 0.033524\n",
      "Train Epoch: 9 [7680/18662 (41%)]\tLoss: 0.041348\n",
      "Train Epoch: 9 [8320/18662 (45%)]\tLoss: 0.149360\n",
      "Train Epoch: 9 [8960/18662 (48%)]\tLoss: 0.121393\n",
      "Train Epoch: 9 [9600/18662 (51%)]\tLoss: 0.028618\n",
      "Train Epoch: 9 [10240/18662 (55%)]\tLoss: 0.143525\n",
      "Train Epoch: 9 [10880/18662 (58%)]\tLoss: 0.085970\n",
      "Train Epoch: 9 [11520/18662 (62%)]\tLoss: 0.109066\n",
      "Train Epoch: 9 [12160/18662 (65%)]\tLoss: 0.176835\n",
      "Train Epoch: 9 [12800/18662 (68%)]\tLoss: 0.086974\n",
      "Train Epoch: 9 [13440/18662 (72%)]\tLoss: 0.077497\n",
      "Train Epoch: 9 [14080/18662 (75%)]\tLoss: 0.075083\n",
      "Train Epoch: 9 [14720/18662 (79%)]\tLoss: 0.139058\n",
      "Train Epoch: 9 [15360/18662 (82%)]\tLoss: 0.071845\n",
      "Train Epoch: 9 [16000/18662 (86%)]\tLoss: 0.126561\n",
      "Train Epoch: 9 [16640/18662 (89%)]\tLoss: 0.030462\n",
      "Train Epoch: 9 [17280/18662 (92%)]\tLoss: 0.120574\n",
      "Train Epoch: 9 [17920/18662 (96%)]\tLoss: 0.107018\n",
      "Train Epoch: 9 [18560/18662 (99%)]\tLoss: 0.035519\n",
      "Train Epoch: 10 [0/18662 (0%)]\tLoss: 0.110269\n",
      "Train Epoch: 10 [640/18662 (3%)]\tLoss: 0.094056\n",
      "Train Epoch: 10 [1280/18662 (7%)]\tLoss: 0.052590\n",
      "Train Epoch: 10 [1920/18662 (10%)]\tLoss: 0.223049\n",
      "Train Epoch: 10 [2560/18662 (14%)]\tLoss: 0.056867\n",
      "Train Epoch: 10 [3200/18662 (17%)]\tLoss: 0.058280\n",
      "Train Epoch: 10 [3840/18662 (21%)]\tLoss: 0.071892\n",
      "Train Epoch: 10 [4480/18662 (24%)]\tLoss: 0.102031\n",
      "Train Epoch: 10 [5120/18662 (27%)]\tLoss: 0.077834\n",
      "Train Epoch: 10 [5760/18662 (31%)]\tLoss: 0.152776\n",
      "Train Epoch: 10 [6400/18662 (34%)]\tLoss: 0.020052\n",
      "Train Epoch: 10 [7040/18662 (38%)]\tLoss: 0.087173\n",
      "Train Epoch: 10 [7680/18662 (41%)]\tLoss: 0.087564\n",
      "Train Epoch: 10 [8320/18662 (45%)]\tLoss: 0.225283\n",
      "Train Epoch: 10 [8960/18662 (48%)]\tLoss: 0.102742\n",
      "Train Epoch: 10 [9600/18662 (51%)]\tLoss: 0.056022\n",
      "Train Epoch: 10 [10240/18662 (55%)]\tLoss: 0.160808\n",
      "Train Epoch: 10 [10880/18662 (58%)]\tLoss: 0.176390\n",
      "Train Epoch: 10 [11520/18662 (62%)]\tLoss: 0.073137\n",
      "Train Epoch: 10 [12160/18662 (65%)]\tLoss: 0.244697\n",
      "Train Epoch: 10 [12800/18662 (68%)]\tLoss: 0.008487\n",
      "Train Epoch: 10 [13440/18662 (72%)]\tLoss: 0.068014\n",
      "Train Epoch: 10 [14080/18662 (75%)]\tLoss: 0.033273\n",
      "Train Epoch: 10 [14720/18662 (79%)]\tLoss: 0.013728\n",
      "Train Epoch: 10 [15360/18662 (82%)]\tLoss: 0.084880\n",
      "Train Epoch: 10 [16000/18662 (86%)]\tLoss: 0.105229\n",
      "Train Epoch: 10 [16640/18662 (89%)]\tLoss: 0.049996\n",
      "Train Epoch: 10 [17280/18662 (92%)]\tLoss: 0.087863\n",
      "Train Epoch: 10 [17920/18662 (96%)]\tLoss: 0.079183\n",
      "Train Epoch: 10 [18560/18662 (99%)]\tLoss: 0.051282\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/10619 (0%)]\tLoss: 0.274807\n",
      "Train Epoch: 1 [640/10619 (6%)]\tLoss: 0.105653\n",
      "Train Epoch: 1 [1280/10619 (12%)]\tLoss: 0.338735\n",
      "Train Epoch: 1 [1920/10619 (18%)]\tLoss: 0.136808\n",
      "Train Epoch: 1 [2560/10619 (24%)]\tLoss: 0.257913\n",
      "Train Epoch: 1 [3200/10619 (30%)]\tLoss: 0.190333\n",
      "Train Epoch: 1 [3840/10619 (36%)]\tLoss: 0.074088\n",
      "Train Epoch: 1 [4480/10619 (42%)]\tLoss: 0.085669\n",
      "Train Epoch: 1 [5120/10619 (48%)]\tLoss: 0.130575\n",
      "Train Epoch: 1 [5760/10619 (54%)]\tLoss: 0.194325\n",
      "Train Epoch: 1 [6400/10619 (60%)]\tLoss: 0.132841\n",
      "Train Epoch: 1 [7040/10619 (66%)]\tLoss: 0.124107\n",
      "Train Epoch: 1 [7680/10619 (72%)]\tLoss: 0.260174\n",
      "Train Epoch: 1 [8320/10619 (78%)]\tLoss: 0.162882\n",
      "Train Epoch: 1 [8960/10619 (84%)]\tLoss: 0.085078\n",
      "Train Epoch: 1 [9600/10619 (90%)]\tLoss: 0.070747\n",
      "Train Epoch: 1 [10240/10619 (96%)]\tLoss: 0.133801\n",
      "Train Epoch: 2 [0/10619 (0%)]\tLoss: 0.133730\n",
      "Train Epoch: 2 [640/10619 (6%)]\tLoss: 0.075068\n",
      "Train Epoch: 2 [1280/10619 (12%)]\tLoss: 0.055303\n",
      "Train Epoch: 2 [1920/10619 (18%)]\tLoss: 0.097397\n",
      "Train Epoch: 2 [2560/10619 (24%)]\tLoss: 0.038621\n",
      "Train Epoch: 2 [3200/10619 (30%)]\tLoss: 0.037414\n",
      "Train Epoch: 2 [3840/10619 (36%)]\tLoss: 0.061669\n",
      "Train Epoch: 2 [4480/10619 (42%)]\tLoss: 0.061850\n",
      "Train Epoch: 2 [5120/10619 (48%)]\tLoss: 0.020722\n",
      "Train Epoch: 2 [5760/10619 (54%)]\tLoss: 0.054531\n",
      "Train Epoch: 2 [6400/10619 (60%)]\tLoss: 0.047955\n",
      "Train Epoch: 2 [7040/10619 (66%)]\tLoss: 0.056161\n",
      "Train Epoch: 2 [7680/10619 (72%)]\tLoss: 0.172903\n",
      "Train Epoch: 2 [8320/10619 (78%)]\tLoss: 0.083629\n",
      "Train Epoch: 2 [8960/10619 (84%)]\tLoss: 0.036122\n",
      "Train Epoch: 2 [9600/10619 (90%)]\tLoss: 0.057742\n",
      "Train Epoch: 2 [10240/10619 (96%)]\tLoss: 0.186017\n",
      "Train Epoch: 3 [0/10619 (0%)]\tLoss: 0.164999\n",
      "Train Epoch: 3 [640/10619 (6%)]\tLoss: 0.159917\n",
      "Train Epoch: 3 [1280/10619 (12%)]\tLoss: 0.020193\n",
      "Train Epoch: 3 [1920/10619 (18%)]\tLoss: 0.162806\n",
      "Train Epoch: 3 [2560/10619 (24%)]\tLoss: 0.078875\n",
      "Train Epoch: 3 [3200/10619 (30%)]\tLoss: 0.168333\n",
      "Train Epoch: 3 [3840/10619 (36%)]\tLoss: 0.129184\n",
      "Train Epoch: 3 [4480/10619 (42%)]\tLoss: 0.245163\n",
      "Train Epoch: 3 [5120/10619 (48%)]\tLoss: 0.126724\n",
      "Train Epoch: 3 [5760/10619 (54%)]\tLoss: 0.099313\n",
      "Train Epoch: 3 [6400/10619 (60%)]\tLoss: 0.222850\n",
      "Train Epoch: 3 [7040/10619 (66%)]\tLoss: 0.058380\n",
      "Train Epoch: 3 [7680/10619 (72%)]\tLoss: 0.089302\n",
      "Train Epoch: 3 [8320/10619 (78%)]\tLoss: 0.094358\n",
      "Train Epoch: 3 [8960/10619 (84%)]\tLoss: 0.039665\n",
      "Train Epoch: 3 [9600/10619 (90%)]\tLoss: 0.042020\n",
      "Train Epoch: 3 [10240/10619 (96%)]\tLoss: 0.097437\n",
      "Train Epoch: 4 [0/10619 (0%)]\tLoss: 0.055960\n",
      "Train Epoch: 4 [640/10619 (6%)]\tLoss: 0.139730\n",
      "Train Epoch: 4 [1280/10619 (12%)]\tLoss: 0.052000\n",
      "Train Epoch: 4 [1920/10619 (18%)]\tLoss: 0.032228\n",
      "Train Epoch: 4 [2560/10619 (24%)]\tLoss: 0.038781\n",
      "Train Epoch: 4 [3200/10619 (30%)]\tLoss: 0.085703\n",
      "Train Epoch: 4 [3840/10619 (36%)]\tLoss: 0.222102\n",
      "Train Epoch: 4 [4480/10619 (42%)]\tLoss: 0.258851\n",
      "Train Epoch: 4 [5120/10619 (48%)]\tLoss: 0.198029\n",
      "Train Epoch: 4 [5760/10619 (54%)]\tLoss: 0.014125\n",
      "Train Epoch: 4 [6400/10619 (60%)]\tLoss: 0.083575\n",
      "Train Epoch: 4 [7040/10619 (66%)]\tLoss: 0.081965\n",
      "Train Epoch: 4 [7680/10619 (72%)]\tLoss: 0.026055\n",
      "Train Epoch: 4 [8320/10619 (78%)]\tLoss: 0.087646\n",
      "Train Epoch: 4 [8960/10619 (84%)]\tLoss: 0.099259\n",
      "Train Epoch: 4 [9600/10619 (90%)]\tLoss: 0.177190\n",
      "Train Epoch: 4 [10240/10619 (96%)]\tLoss: 0.209841\n",
      "Train Epoch: 5 [0/10619 (0%)]\tLoss: 0.031241\n",
      "Train Epoch: 5 [640/10619 (6%)]\tLoss: 0.044640\n",
      "Train Epoch: 5 [1280/10619 (12%)]\tLoss: 0.084301\n",
      "Train Epoch: 5 [1920/10619 (18%)]\tLoss: 0.051249\n",
      "Train Epoch: 5 [2560/10619 (24%)]\tLoss: 0.182972\n",
      "Train Epoch: 5 [3200/10619 (30%)]\tLoss: 0.064436\n",
      "Train Epoch: 5 [3840/10619 (36%)]\tLoss: 0.093098\n",
      "Train Epoch: 5 [4480/10619 (42%)]\tLoss: 0.107391\n",
      "Train Epoch: 5 [5120/10619 (48%)]\tLoss: 0.087063\n",
      "Train Epoch: 5 [5760/10619 (54%)]\tLoss: 0.035945\n",
      "Train Epoch: 5 [6400/10619 (60%)]\tLoss: 0.196341\n",
      "Train Epoch: 5 [7040/10619 (66%)]\tLoss: 0.077984\n",
      "Train Epoch: 5 [7680/10619 (72%)]\tLoss: 0.110851\n",
      "Train Epoch: 5 [8320/10619 (78%)]\tLoss: 0.059697\n",
      "Train Epoch: 5 [8960/10619 (84%)]\tLoss: 0.015369\n",
      "Train Epoch: 5 [9600/10619 (90%)]\tLoss: 0.160880\n",
      "Train Epoch: 5 [10240/10619 (96%)]\tLoss: 0.041809\n",
      "Train Epoch: 6 [0/10619 (0%)]\tLoss: 0.042490\n",
      "Train Epoch: 6 [640/10619 (6%)]\tLoss: 0.061277\n",
      "Train Epoch: 6 [1280/10619 (12%)]\tLoss: 0.233104\n",
      "Train Epoch: 6 [1920/10619 (18%)]\tLoss: 0.120989\n",
      "Train Epoch: 6 [2560/10619 (24%)]\tLoss: 0.040999\n",
      "Train Epoch: 6 [3200/10619 (30%)]\tLoss: 0.068840\n",
      "Train Epoch: 6 [3840/10619 (36%)]\tLoss: 0.070626\n",
      "Train Epoch: 6 [4480/10619 (42%)]\tLoss: 0.056566\n",
      "Train Epoch: 6 [5120/10619 (48%)]\tLoss: 0.093061\n",
      "Train Epoch: 6 [5760/10619 (54%)]\tLoss: 0.007910\n",
      "Train Epoch: 6 [6400/10619 (60%)]\tLoss: 0.159331\n",
      "Train Epoch: 6 [7040/10619 (66%)]\tLoss: 0.134481\n",
      "Train Epoch: 6 [7680/10619 (72%)]\tLoss: 0.092724\n",
      "Train Epoch: 6 [8320/10619 (78%)]\tLoss: 0.040947\n",
      "Train Epoch: 6 [8960/10619 (84%)]\tLoss: 0.120630\n",
      "Train Epoch: 6 [9600/10619 (90%)]\tLoss: 0.034407\n",
      "Train Epoch: 6 [10240/10619 (96%)]\tLoss: 0.114698\n",
      "Train Epoch: 7 [0/10619 (0%)]\tLoss: 0.035880\n",
      "Train Epoch: 7 [640/10619 (6%)]\tLoss: 0.061102\n",
      "Train Epoch: 7 [1280/10619 (12%)]\tLoss: 0.051975\n",
      "Train Epoch: 7 [1920/10619 (18%)]\tLoss: 0.070582\n",
      "Train Epoch: 7 [2560/10619 (24%)]\tLoss: 0.156073\n",
      "Train Epoch: 7 [3200/10619 (30%)]\tLoss: 0.035987\n",
      "Train Epoch: 7 [3840/10619 (36%)]\tLoss: 0.052431\n",
      "Train Epoch: 7 [4480/10619 (42%)]\tLoss: 0.040335\n",
      "Train Epoch: 7 [5120/10619 (48%)]\tLoss: 0.170288\n",
      "Train Epoch: 7 [5760/10619 (54%)]\tLoss: 0.179969\n",
      "Train Epoch: 7 [6400/10619 (60%)]\tLoss: 0.072248\n",
      "Train Epoch: 7 [7040/10619 (66%)]\tLoss: 0.061509\n",
      "Train Epoch: 7 [7680/10619 (72%)]\tLoss: 0.114215\n",
      "Train Epoch: 7 [8320/10619 (78%)]\tLoss: 0.138458\n",
      "Train Epoch: 7 [8960/10619 (84%)]\tLoss: 0.055460\n",
      "Train Epoch: 7 [9600/10619 (90%)]\tLoss: 0.056409\n",
      "Train Epoch: 7 [10240/10619 (96%)]\tLoss: 0.259226\n",
      "Train Epoch: 8 [0/10619 (0%)]\tLoss: 0.009894\n",
      "Train Epoch: 8 [640/10619 (6%)]\tLoss: 0.034589\n",
      "Train Epoch: 8 [1280/10619 (12%)]\tLoss: 0.064907\n",
      "Train Epoch: 8 [1920/10619 (18%)]\tLoss: 0.056432\n",
      "Train Epoch: 8 [2560/10619 (24%)]\tLoss: 0.159482\n",
      "Train Epoch: 8 [3200/10619 (30%)]\tLoss: 0.021911\n",
      "Train Epoch: 8 [3840/10619 (36%)]\tLoss: 0.081760\n",
      "Train Epoch: 8 [4480/10619 (42%)]\tLoss: 0.038992\n",
      "Train Epoch: 8 [5120/10619 (48%)]\tLoss: 0.145023\n",
      "Train Epoch: 8 [5760/10619 (54%)]\tLoss: 0.022880\n",
      "Train Epoch: 8 [6400/10619 (60%)]\tLoss: 0.086672\n",
      "Train Epoch: 8 [7040/10619 (66%)]\tLoss: 0.110462\n",
      "Train Epoch: 8 [7680/10619 (72%)]\tLoss: 0.095755\n",
      "Train Epoch: 8 [8320/10619 (78%)]\tLoss: 0.073659\n",
      "Train Epoch: 8 [8960/10619 (84%)]\tLoss: 0.063912\n",
      "Train Epoch: 8 [9600/10619 (90%)]\tLoss: 0.030225\n",
      "Train Epoch: 8 [10240/10619 (96%)]\tLoss: 0.048067\n",
      "Train Epoch: 9 [0/10619 (0%)]\tLoss: 0.097382\n",
      "Train Epoch: 9 [640/10619 (6%)]\tLoss: 0.055747\n",
      "Train Epoch: 9 [1280/10619 (12%)]\tLoss: 0.020528\n",
      "Train Epoch: 9 [1920/10619 (18%)]\tLoss: 0.097830\n",
      "Train Epoch: 9 [2560/10619 (24%)]\tLoss: 0.066509\n",
      "Train Epoch: 9 [3200/10619 (30%)]\tLoss: 0.033140\n",
      "Train Epoch: 9 [3840/10619 (36%)]\tLoss: 0.064312\n",
      "Train Epoch: 9 [4480/10619 (42%)]\tLoss: 0.169101\n",
      "Train Epoch: 9 [5120/10619 (48%)]\tLoss: 0.166578\n",
      "Train Epoch: 9 [5760/10619 (54%)]\tLoss: 0.269551\n",
      "Train Epoch: 9 [6400/10619 (60%)]\tLoss: 0.056329\n",
      "Train Epoch: 9 [7040/10619 (66%)]\tLoss: 0.131057\n",
      "Train Epoch: 9 [7680/10619 (72%)]\tLoss: 0.033014\n",
      "Train Epoch: 9 [8320/10619 (78%)]\tLoss: 0.140692\n",
      "Train Epoch: 9 [8960/10619 (84%)]\tLoss: 0.055155\n",
      "Train Epoch: 9 [9600/10619 (90%)]\tLoss: 0.057099\n",
      "Train Epoch: 9 [10240/10619 (96%)]\tLoss: 0.166318\n",
      "Train Epoch: 10 [0/10619 (0%)]\tLoss: 0.037969\n",
      "Train Epoch: 10 [640/10619 (6%)]\tLoss: 0.174221\n",
      "Train Epoch: 10 [1280/10619 (12%)]\tLoss: 0.095738\n",
      "Train Epoch: 10 [1920/10619 (18%)]\tLoss: 0.148947\n",
      "Train Epoch: 10 [2560/10619 (24%)]\tLoss: 0.065272\n",
      "Train Epoch: 10 [3200/10619 (30%)]\tLoss: 0.044586\n",
      "Train Epoch: 10 [3840/10619 (36%)]\tLoss: 0.039321\n",
      "Train Epoch: 10 [4480/10619 (42%)]\tLoss: 0.058018\n",
      "Train Epoch: 10 [5120/10619 (48%)]\tLoss: 0.204286\n",
      "Train Epoch: 10 [5760/10619 (54%)]\tLoss: 0.135646\n",
      "Train Epoch: 10 [6400/10619 (60%)]\tLoss: 0.189664\n",
      "Train Epoch: 10 [7040/10619 (66%)]\tLoss: 0.082763\n",
      "Train Epoch: 10 [7680/10619 (72%)]\tLoss: 0.109626\n",
      "Train Epoch: 10 [8320/10619 (78%)]\tLoss: 0.085208\n",
      "Train Epoch: 10 [8960/10619 (84%)]\tLoss: 0.086919\n",
      "Train Epoch: 10 [9600/10619 (90%)]\tLoss: 0.064096\n",
      "Train Epoch: 10 [10240/10619 (96%)]\tLoss: 0.037091\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/15392 (0%)]\tLoss: 0.177704\n",
      "Train Epoch: 1 [640/15392 (4%)]\tLoss: 0.187173\n",
      "Train Epoch: 1 [1280/15392 (8%)]\tLoss: 0.031465\n",
      "Train Epoch: 1 [1920/15392 (12%)]\tLoss: 0.119326\n",
      "Train Epoch: 1 [2560/15392 (17%)]\tLoss: 0.081313\n",
      "Train Epoch: 1 [3200/15392 (21%)]\tLoss: 0.099667\n",
      "Train Epoch: 1 [3840/15392 (25%)]\tLoss: 0.155660\n",
      "Train Epoch: 1 [4480/15392 (29%)]\tLoss: 0.114461\n",
      "Train Epoch: 1 [5120/15392 (33%)]\tLoss: 0.074934\n",
      "Train Epoch: 1 [5760/15392 (37%)]\tLoss: 0.132554\n",
      "Train Epoch: 1 [6400/15392 (41%)]\tLoss: 0.111043\n",
      "Train Epoch: 1 [7040/15392 (46%)]\tLoss: 0.162857\n",
      "Train Epoch: 1 [7680/15392 (50%)]\tLoss: 0.207201\n",
      "Train Epoch: 1 [8320/15392 (54%)]\tLoss: 0.043243\n",
      "Train Epoch: 1 [8960/15392 (58%)]\tLoss: 0.214698\n",
      "Train Epoch: 1 [9600/15392 (62%)]\tLoss: 0.083626\n",
      "Train Epoch: 1 [10240/15392 (66%)]\tLoss: 0.057141\n",
      "Train Epoch: 1 [10880/15392 (71%)]\tLoss: 0.070053\n",
      "Train Epoch: 1 [11520/15392 (75%)]\tLoss: 0.177441\n",
      "Train Epoch: 1 [12160/15392 (79%)]\tLoss: 0.062258\n",
      "Train Epoch: 1 [12800/15392 (83%)]\tLoss: 0.076713\n",
      "Train Epoch: 1 [13440/15392 (87%)]\tLoss: 0.064807\n",
      "Train Epoch: 1 [14080/15392 (91%)]\tLoss: 0.040786\n",
      "Train Epoch: 1 [14720/15392 (95%)]\tLoss: 0.058539\n",
      "Train Epoch: 1 [7680/15392 (100%)]\tLoss: 0.065980\n",
      "Train Epoch: 2 [0/15392 (0%)]\tLoss: 0.054771\n",
      "Train Epoch: 2 [640/15392 (4%)]\tLoss: 0.020979\n",
      "Train Epoch: 2 [1280/15392 (8%)]\tLoss: 0.022545\n",
      "Train Epoch: 2 [1920/15392 (12%)]\tLoss: 0.048964\n",
      "Train Epoch: 2 [2560/15392 (17%)]\tLoss: 0.088620\n",
      "Train Epoch: 2 [3200/15392 (21%)]\tLoss: 0.072552\n",
      "Train Epoch: 2 [3840/15392 (25%)]\tLoss: 0.032138\n",
      "Train Epoch: 2 [4480/15392 (29%)]\tLoss: 0.056837\n",
      "Train Epoch: 2 [5120/15392 (33%)]\tLoss: 0.283478\n",
      "Train Epoch: 2 [5760/15392 (37%)]\tLoss: 0.130120\n",
      "Train Epoch: 2 [6400/15392 (41%)]\tLoss: 0.058718\n",
      "Train Epoch: 2 [7040/15392 (46%)]\tLoss: 0.060391\n",
      "Train Epoch: 2 [7680/15392 (50%)]\tLoss: 0.065185\n",
      "Train Epoch: 2 [8320/15392 (54%)]\tLoss: 0.080159\n",
      "Train Epoch: 2 [8960/15392 (58%)]\tLoss: 0.089484\n",
      "Train Epoch: 2 [9600/15392 (62%)]\tLoss: 0.349404\n",
      "Train Epoch: 2 [10240/15392 (66%)]\tLoss: 0.090751\n",
      "Train Epoch: 2 [10880/15392 (71%)]\tLoss: 0.007167\n",
      "Train Epoch: 2 [11520/15392 (75%)]\tLoss: 0.165140\n",
      "Train Epoch: 2 [12160/15392 (79%)]\tLoss: 0.055671\n",
      "Train Epoch: 2 [12800/15392 (83%)]\tLoss: 0.116324\n",
      "Train Epoch: 2 [13440/15392 (87%)]\tLoss: 0.029686\n",
      "Train Epoch: 2 [14080/15392 (91%)]\tLoss: 0.020790\n",
      "Train Epoch: 2 [14720/15392 (95%)]\tLoss: 0.135193\n",
      "Train Epoch: 2 [7680/15392 (100%)]\tLoss: 0.100498\n",
      "Train Epoch: 3 [0/15392 (0%)]\tLoss: 0.015499\n",
      "Train Epoch: 3 [640/15392 (4%)]\tLoss: 0.119586\n",
      "Train Epoch: 3 [1280/15392 (8%)]\tLoss: 0.042548\n",
      "Train Epoch: 3 [1920/15392 (12%)]\tLoss: 0.119416\n",
      "Train Epoch: 3 [2560/15392 (17%)]\tLoss: 0.136738\n",
      "Train Epoch: 3 [3200/15392 (21%)]\tLoss: 0.064706\n",
      "Train Epoch: 3 [3840/15392 (25%)]\tLoss: 0.068096\n",
      "Train Epoch: 3 [4480/15392 (29%)]\tLoss: 0.031477\n",
      "Train Epoch: 3 [5120/15392 (33%)]\tLoss: 0.016916\n",
      "Train Epoch: 3 [5760/15392 (37%)]\tLoss: 0.024665\n",
      "Train Epoch: 3 [6400/15392 (41%)]\tLoss: 0.054042\n",
      "Train Epoch: 3 [7040/15392 (46%)]\tLoss: 0.148084\n",
      "Train Epoch: 3 [7680/15392 (50%)]\tLoss: 0.094423\n",
      "Train Epoch: 3 [8320/15392 (54%)]\tLoss: 0.145590\n",
      "Train Epoch: 3 [8960/15392 (58%)]\tLoss: 0.123818\n",
      "Train Epoch: 3 [9600/15392 (62%)]\tLoss: 0.060123\n",
      "Train Epoch: 3 [10240/15392 (66%)]\tLoss: 0.089630\n",
      "Train Epoch: 3 [10880/15392 (71%)]\tLoss: 0.152122\n",
      "Train Epoch: 3 [11520/15392 (75%)]\tLoss: 0.043188\n",
      "Train Epoch: 3 [12160/15392 (79%)]\tLoss: 0.051224\n",
      "Train Epoch: 3 [12800/15392 (83%)]\tLoss: 0.071256\n",
      "Train Epoch: 3 [13440/15392 (87%)]\tLoss: 0.108559\n",
      "Train Epoch: 3 [14080/15392 (91%)]\tLoss: 0.116009\n",
      "Train Epoch: 3 [14720/15392 (95%)]\tLoss: 0.057330\n",
      "Train Epoch: 3 [7680/15392 (100%)]\tLoss: 0.066514\n",
      "Train Epoch: 4 [0/15392 (0%)]\tLoss: 0.059522\n",
      "Train Epoch: 4 [640/15392 (4%)]\tLoss: 0.045100\n",
      "Train Epoch: 4 [1280/15392 (8%)]\tLoss: 0.257715\n",
      "Train Epoch: 4 [1920/15392 (12%)]\tLoss: 0.079307\n",
      "Train Epoch: 4 [2560/15392 (17%)]\tLoss: 0.021317\n",
      "Train Epoch: 4 [3200/15392 (21%)]\tLoss: 0.129031\n",
      "Train Epoch: 4 [3840/15392 (25%)]\tLoss: 0.161811\n",
      "Train Epoch: 4 [4480/15392 (29%)]\tLoss: 0.119434\n",
      "Train Epoch: 4 [5120/15392 (33%)]\tLoss: 0.027013\n",
      "Train Epoch: 4 [5760/15392 (37%)]\tLoss: 0.091084\n",
      "Train Epoch: 4 [6400/15392 (41%)]\tLoss: 0.112498\n",
      "Train Epoch: 4 [7040/15392 (46%)]\tLoss: 0.112306\n",
      "Train Epoch: 4 [7680/15392 (50%)]\tLoss: 0.024405\n",
      "Train Epoch: 4 [8320/15392 (54%)]\tLoss: 0.071799\n",
      "Train Epoch: 4 [8960/15392 (58%)]\tLoss: 0.062949\n",
      "Train Epoch: 4 [9600/15392 (62%)]\tLoss: 0.017136\n",
      "Train Epoch: 4 [10240/15392 (66%)]\tLoss: 0.115490\n",
      "Train Epoch: 4 [10880/15392 (71%)]\tLoss: 0.038164\n",
      "Train Epoch: 4 [11520/15392 (75%)]\tLoss: 0.147101\n",
      "Train Epoch: 4 [12160/15392 (79%)]\tLoss: 0.024474\n",
      "Train Epoch: 4 [12800/15392 (83%)]\tLoss: 0.017759\n",
      "Train Epoch: 4 [13440/15392 (87%)]\tLoss: 0.020994\n",
      "Train Epoch: 4 [14080/15392 (91%)]\tLoss: 0.049974\n",
      "Train Epoch: 4 [14720/15392 (95%)]\tLoss: 0.132324\n",
      "Train Epoch: 4 [7680/15392 (100%)]\tLoss: 0.086285\n",
      "Train Epoch: 5 [0/15392 (0%)]\tLoss: 0.120877\n",
      "Train Epoch: 5 [640/15392 (4%)]\tLoss: 0.036595\n",
      "Train Epoch: 5 [1280/15392 (8%)]\tLoss: 0.101685\n",
      "Train Epoch: 5 [1920/15392 (12%)]\tLoss: 0.054572\n",
      "Train Epoch: 5 [2560/15392 (17%)]\tLoss: 0.030532\n",
      "Train Epoch: 5 [3200/15392 (21%)]\tLoss: 0.013240\n",
      "Train Epoch: 5 [3840/15392 (25%)]\tLoss: 0.054969\n",
      "Train Epoch: 5 [4480/15392 (29%)]\tLoss: 0.062512\n",
      "Train Epoch: 5 [5120/15392 (33%)]\tLoss: 0.087192\n",
      "Train Epoch: 5 [5760/15392 (37%)]\tLoss: 0.071024\n",
      "Train Epoch: 5 [6400/15392 (41%)]\tLoss: 0.040571\n",
      "Train Epoch: 5 [7040/15392 (46%)]\tLoss: 0.026822\n",
      "Train Epoch: 5 [7680/15392 (50%)]\tLoss: 0.130401\n",
      "Train Epoch: 5 [8320/15392 (54%)]\tLoss: 0.129725\n",
      "Train Epoch: 5 [8960/15392 (58%)]\tLoss: 0.040992\n",
      "Train Epoch: 5 [9600/15392 (62%)]\tLoss: 0.072386\n",
      "Train Epoch: 5 [10240/15392 (66%)]\tLoss: 0.132968\n",
      "Train Epoch: 5 [10880/15392 (71%)]\tLoss: 0.017334\n",
      "Train Epoch: 5 [11520/15392 (75%)]\tLoss: 0.049996\n",
      "Train Epoch: 5 [12160/15392 (79%)]\tLoss: 0.118494\n",
      "Train Epoch: 5 [12800/15392 (83%)]\tLoss: 0.018602\n",
      "Train Epoch: 5 [13440/15392 (87%)]\tLoss: 0.069714\n",
      "Train Epoch: 5 [14080/15392 (91%)]\tLoss: 0.228089\n",
      "Train Epoch: 5 [14720/15392 (95%)]\tLoss: 0.062035\n",
      "Train Epoch: 5 [7680/15392 (100%)]\tLoss: 0.014701\n",
      "Train Epoch: 6 [0/15392 (0%)]\tLoss: 0.241851\n",
      "Train Epoch: 6 [640/15392 (4%)]\tLoss: 0.083227\n",
      "Train Epoch: 6 [1280/15392 (8%)]\tLoss: 0.198080\n",
      "Train Epoch: 6 [1920/15392 (12%)]\tLoss: 0.072374\n",
      "Train Epoch: 6 [2560/15392 (17%)]\tLoss: 0.058569\n",
      "Train Epoch: 6 [3200/15392 (21%)]\tLoss: 0.058940\n",
      "Train Epoch: 6 [3840/15392 (25%)]\tLoss: 0.067820\n",
      "Train Epoch: 6 [4480/15392 (29%)]\tLoss: 0.056719\n",
      "Train Epoch: 6 [5120/15392 (33%)]\tLoss: 0.031433\n",
      "Train Epoch: 6 [5760/15392 (37%)]\tLoss: 0.053366\n",
      "Train Epoch: 6 [6400/15392 (41%)]\tLoss: 0.125420\n",
      "Train Epoch: 6 [7040/15392 (46%)]\tLoss: 0.055081\n",
      "Train Epoch: 6 [7680/15392 (50%)]\tLoss: 0.134522\n",
      "Train Epoch: 6 [8320/15392 (54%)]\tLoss: 0.087557\n",
      "Train Epoch: 6 [8960/15392 (58%)]\tLoss: 0.058143\n",
      "Train Epoch: 6 [9600/15392 (62%)]\tLoss: 0.104502\n",
      "Train Epoch: 6 [10240/15392 (66%)]\tLoss: 0.123141\n",
      "Train Epoch: 6 [10880/15392 (71%)]\tLoss: 0.107106\n",
      "Train Epoch: 6 [11520/15392 (75%)]\tLoss: 0.071233\n",
      "Train Epoch: 6 [12160/15392 (79%)]\tLoss: 0.041266\n",
      "Train Epoch: 6 [12800/15392 (83%)]\tLoss: 0.058834\n",
      "Train Epoch: 6 [13440/15392 (87%)]\tLoss: 0.042076\n",
      "Train Epoch: 6 [14080/15392 (91%)]\tLoss: 0.040200\n",
      "Train Epoch: 6 [14720/15392 (95%)]\tLoss: 0.118733\n",
      "Train Epoch: 6 [7680/15392 (100%)]\tLoss: 0.330129\n",
      "Train Epoch: 7 [0/15392 (0%)]\tLoss: 0.052981\n",
      "Train Epoch: 7 [640/15392 (4%)]\tLoss: 0.038917\n",
      "Train Epoch: 7 [1280/15392 (8%)]\tLoss: 0.040601\n",
      "Train Epoch: 7 [1920/15392 (12%)]\tLoss: 0.065834\n",
      "Train Epoch: 7 [2560/15392 (17%)]\tLoss: 0.086484\n",
      "Train Epoch: 7 [3200/15392 (21%)]\tLoss: 0.073371\n",
      "Train Epoch: 7 [3840/15392 (25%)]\tLoss: 0.087408\n",
      "Train Epoch: 7 [4480/15392 (29%)]\tLoss: 0.040351\n",
      "Train Epoch: 7 [5120/15392 (33%)]\tLoss: 0.113795\n",
      "Train Epoch: 7 [5760/15392 (37%)]\tLoss: 0.042392\n",
      "Train Epoch: 7 [6400/15392 (41%)]\tLoss: 0.086465\n",
      "Train Epoch: 7 [7040/15392 (46%)]\tLoss: 0.078119\n",
      "Train Epoch: 7 [7680/15392 (50%)]\tLoss: 0.071009\n",
      "Train Epoch: 7 [8320/15392 (54%)]\tLoss: 0.111719\n",
      "Train Epoch: 7 [8960/15392 (58%)]\tLoss: 0.053524\n",
      "Train Epoch: 7 [9600/15392 (62%)]\tLoss: 0.022998\n",
      "Train Epoch: 7 [10240/15392 (66%)]\tLoss: 0.157311\n",
      "Train Epoch: 7 [10880/15392 (71%)]\tLoss: 0.116849\n",
      "Train Epoch: 7 [11520/15392 (75%)]\tLoss: 0.078498\n",
      "Train Epoch: 7 [12160/15392 (79%)]\tLoss: 0.056193\n",
      "Train Epoch: 7 [12800/15392 (83%)]\tLoss: 0.180369\n",
      "Train Epoch: 7 [13440/15392 (87%)]\tLoss: 0.032559\n",
      "Train Epoch: 7 [14080/15392 (91%)]\tLoss: 0.169638\n",
      "Train Epoch: 7 [14720/15392 (95%)]\tLoss: 0.062350\n",
      "Train Epoch: 7 [7680/15392 (100%)]\tLoss: 0.157594\n",
      "Train Epoch: 8 [0/15392 (0%)]\tLoss: 0.058786\n",
      "Train Epoch: 8 [640/15392 (4%)]\tLoss: 0.112955\n",
      "Train Epoch: 8 [1280/15392 (8%)]\tLoss: 0.064329\n",
      "Train Epoch: 8 [1920/15392 (12%)]\tLoss: 0.066236\n",
      "Train Epoch: 8 [2560/15392 (17%)]\tLoss: 0.051413\n",
      "Train Epoch: 8 [3200/15392 (21%)]\tLoss: 0.106423\n",
      "Train Epoch: 8 [3840/15392 (25%)]\tLoss: 0.169781\n",
      "Train Epoch: 8 [4480/15392 (29%)]\tLoss: 0.120875\n",
      "Train Epoch: 8 [5120/15392 (33%)]\tLoss: 0.039354\n",
      "Train Epoch: 8 [5760/15392 (37%)]\tLoss: 0.030378\n",
      "Train Epoch: 8 [6400/15392 (41%)]\tLoss: 0.037653\n",
      "Train Epoch: 8 [7040/15392 (46%)]\tLoss: 0.028403\n",
      "Train Epoch: 8 [7680/15392 (50%)]\tLoss: 0.029115\n",
      "Train Epoch: 8 [8320/15392 (54%)]\tLoss: 0.094328\n",
      "Train Epoch: 8 [8960/15392 (58%)]\tLoss: 0.177971\n",
      "Train Epoch: 8 [9600/15392 (62%)]\tLoss: 0.073684\n",
      "Train Epoch: 8 [10240/15392 (66%)]\tLoss: 0.217819\n",
      "Train Epoch: 8 [10880/15392 (71%)]\tLoss: 0.123561\n",
      "Train Epoch: 8 [11520/15392 (75%)]\tLoss: 0.030991\n",
      "Train Epoch: 8 [12160/15392 (79%)]\tLoss: 0.072286\n",
      "Train Epoch: 8 [12800/15392 (83%)]\tLoss: 0.049677\n",
      "Train Epoch: 8 [13440/15392 (87%)]\tLoss: 0.152120\n",
      "Train Epoch: 8 [14080/15392 (91%)]\tLoss: 0.103650\n",
      "Train Epoch: 8 [14720/15392 (95%)]\tLoss: 0.074574\n",
      "Train Epoch: 8 [7680/15392 (100%)]\tLoss: 0.033692\n",
      "Train Epoch: 9 [0/15392 (0%)]\tLoss: 0.037423\n",
      "Train Epoch: 9 [640/15392 (4%)]\tLoss: 0.043804\n",
      "Train Epoch: 9 [1280/15392 (8%)]\tLoss: 0.031717\n",
      "Train Epoch: 9 [1920/15392 (12%)]\tLoss: 0.047252\n",
      "Train Epoch: 9 [2560/15392 (17%)]\tLoss: 0.095713\n",
      "Train Epoch: 9 [3200/15392 (21%)]\tLoss: 0.035119\n",
      "Train Epoch: 9 [3840/15392 (25%)]\tLoss: 0.059685\n",
      "Train Epoch: 9 [4480/15392 (29%)]\tLoss: 0.094568\n",
      "Train Epoch: 9 [5120/15392 (33%)]\tLoss: 0.051204\n",
      "Train Epoch: 9 [5760/15392 (37%)]\tLoss: 0.161410\n",
      "Train Epoch: 9 [6400/15392 (41%)]\tLoss: 0.117728\n",
      "Train Epoch: 9 [7040/15392 (46%)]\tLoss: 0.042642\n",
      "Train Epoch: 9 [7680/15392 (50%)]\tLoss: 0.033648\n",
      "Train Epoch: 9 [8320/15392 (54%)]\tLoss: 0.082868\n",
      "Train Epoch: 9 [8960/15392 (58%)]\tLoss: 0.029616\n",
      "Train Epoch: 9 [9600/15392 (62%)]\tLoss: 0.192047\n",
      "Train Epoch: 9 [10240/15392 (66%)]\tLoss: 0.200107\n",
      "Train Epoch: 9 [10880/15392 (71%)]\tLoss: 0.187784\n",
      "Train Epoch: 9 [11520/15392 (75%)]\tLoss: 0.038754\n",
      "Train Epoch: 9 [12160/15392 (79%)]\tLoss: 0.032401\n",
      "Train Epoch: 9 [12800/15392 (83%)]\tLoss: 0.024680\n",
      "Train Epoch: 9 [13440/15392 (87%)]\tLoss: 0.080687\n",
      "Train Epoch: 9 [14080/15392 (91%)]\tLoss: 0.077989\n",
      "Train Epoch: 9 [14720/15392 (95%)]\tLoss: 0.077602\n",
      "Train Epoch: 9 [7680/15392 (100%)]\tLoss: 0.008645\n",
      "Train Epoch: 10 [0/15392 (0%)]\tLoss: 0.141991\n",
      "Train Epoch: 10 [640/15392 (4%)]\tLoss: 0.095288\n",
      "Train Epoch: 10 [1280/15392 (8%)]\tLoss: 0.107721\n",
      "Train Epoch: 10 [1920/15392 (12%)]\tLoss: 0.128341\n",
      "Train Epoch: 10 [2560/15392 (17%)]\tLoss: 0.025079\n",
      "Train Epoch: 10 [3200/15392 (21%)]\tLoss: 0.072587\n",
      "Train Epoch: 10 [3840/15392 (25%)]\tLoss: 0.025991\n",
      "Train Epoch: 10 [4480/15392 (29%)]\tLoss: 0.051644\n",
      "Train Epoch: 10 [5120/15392 (33%)]\tLoss: 0.064021\n",
      "Train Epoch: 10 [5760/15392 (37%)]\tLoss: 0.056215\n",
      "Train Epoch: 10 [6400/15392 (41%)]\tLoss: 0.023889\n",
      "Train Epoch: 10 [7040/15392 (46%)]\tLoss: 0.052528\n",
      "Train Epoch: 10 [7680/15392 (50%)]\tLoss: 0.061777\n",
      "Train Epoch: 10 [8320/15392 (54%)]\tLoss: 0.052539\n",
      "Train Epoch: 10 [8960/15392 (58%)]\tLoss: 0.103444\n",
      "Train Epoch: 10 [9600/15392 (62%)]\tLoss: 0.055423\n",
      "Train Epoch: 10 [10240/15392 (66%)]\tLoss: 0.063228\n",
      "Train Epoch: 10 [10880/15392 (71%)]\tLoss: 0.107085\n",
      "Train Epoch: 10 [11520/15392 (75%)]\tLoss: 0.174897\n",
      "Train Epoch: 10 [12160/15392 (79%)]\tLoss: 0.128205\n",
      "Train Epoch: 10 [12800/15392 (83%)]\tLoss: 0.083238\n",
      "Train Epoch: 10 [13440/15392 (87%)]\tLoss: 0.145704\n",
      "Train Epoch: 10 [14080/15392 (91%)]\tLoss: 0.138793\n",
      "Train Epoch: 10 [14720/15392 (95%)]\tLoss: 0.038134\n",
      "Train Epoch: 10 [7680/15392 (100%)]\tLoss: 0.261420\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/15327 (0%)]\tLoss: 0.113788\n",
      "Train Epoch: 1 [640/15327 (4%)]\tLoss: 0.333526\n",
      "Train Epoch: 1 [1280/15327 (8%)]\tLoss: 0.115842\n",
      "Train Epoch: 1 [1920/15327 (12%)]\tLoss: 0.052067\n",
      "Train Epoch: 1 [2560/15327 (17%)]\tLoss: 0.151150\n",
      "Train Epoch: 1 [3200/15327 (21%)]\tLoss: 0.079212\n",
      "Train Epoch: 1 [3840/15327 (25%)]\tLoss: 0.083377\n",
      "Train Epoch: 1 [4480/15327 (29%)]\tLoss: 0.147247\n",
      "Train Epoch: 1 [5120/15327 (33%)]\tLoss: 0.074095\n",
      "Train Epoch: 1 [5760/15327 (38%)]\tLoss: 0.049476\n",
      "Train Epoch: 1 [6400/15327 (42%)]\tLoss: 0.203475\n",
      "Train Epoch: 1 [7040/15327 (46%)]\tLoss: 0.081827\n",
      "Train Epoch: 1 [7680/15327 (50%)]\tLoss: 0.078510\n",
      "Train Epoch: 1 [8320/15327 (54%)]\tLoss: 0.091343\n",
      "Train Epoch: 1 [8960/15327 (58%)]\tLoss: 0.057082\n",
      "Train Epoch: 1 [9600/15327 (62%)]\tLoss: 0.132051\n",
      "Train Epoch: 1 [10240/15327 (67%)]\tLoss: 0.172307\n",
      "Train Epoch: 1 [10880/15327 (71%)]\tLoss: 0.233530\n",
      "Train Epoch: 1 [11520/15327 (75%)]\tLoss: 0.021234\n",
      "Train Epoch: 1 [12160/15327 (79%)]\tLoss: 0.127646\n",
      "Train Epoch: 1 [12800/15327 (83%)]\tLoss: 0.135313\n",
      "Train Epoch: 1 [13440/15327 (88%)]\tLoss: 0.027846\n",
      "Train Epoch: 1 [14080/15327 (92%)]\tLoss: 0.135324\n",
      "Train Epoch: 1 [14720/15327 (96%)]\tLoss: 0.161240\n",
      "Train Epoch: 2 [0/15327 (0%)]\tLoss: 0.072067\n",
      "Train Epoch: 2 [640/15327 (4%)]\tLoss: 0.082962\n",
      "Train Epoch: 2 [1280/15327 (8%)]\tLoss: 0.210997\n",
      "Train Epoch: 2 [1920/15327 (12%)]\tLoss: 0.194586\n",
      "Train Epoch: 2 [2560/15327 (17%)]\tLoss: 0.251292\n",
      "Train Epoch: 2 [3200/15327 (21%)]\tLoss: 0.155565\n",
      "Train Epoch: 2 [3840/15327 (25%)]\tLoss: 0.108997\n",
      "Train Epoch: 2 [4480/15327 (29%)]\tLoss: 0.228513\n",
      "Train Epoch: 2 [5120/15327 (33%)]\tLoss: 0.262505\n",
      "Train Epoch: 2 [5760/15327 (38%)]\tLoss: 0.075769\n",
      "Train Epoch: 2 [6400/15327 (42%)]\tLoss: 0.074691\n",
      "Train Epoch: 2 [7040/15327 (46%)]\tLoss: 0.037837\n",
      "Train Epoch: 2 [7680/15327 (50%)]\tLoss: 0.102916\n",
      "Train Epoch: 2 [8320/15327 (54%)]\tLoss: 0.086727\n",
      "Train Epoch: 2 [8960/15327 (58%)]\tLoss: 0.046331\n",
      "Train Epoch: 2 [9600/15327 (62%)]\tLoss: 0.170071\n",
      "Train Epoch: 2 [10240/15327 (67%)]\tLoss: 0.083568\n",
      "Train Epoch: 2 [10880/15327 (71%)]\tLoss: 0.151829\n",
      "Train Epoch: 2 [11520/15327 (75%)]\tLoss: 0.105855\n",
      "Train Epoch: 2 [12160/15327 (79%)]\tLoss: 0.010285\n",
      "Train Epoch: 2 [12800/15327 (83%)]\tLoss: 0.161197\n",
      "Train Epoch: 2 [13440/15327 (88%)]\tLoss: 0.060489\n",
      "Train Epoch: 2 [14080/15327 (92%)]\tLoss: 0.103267\n",
      "Train Epoch: 2 [14720/15327 (96%)]\tLoss: 0.038849\n",
      "Train Epoch: 3 [0/15327 (0%)]\tLoss: 0.075106\n",
      "Train Epoch: 3 [640/15327 (4%)]\tLoss: 0.102015\n",
      "Train Epoch: 3 [1280/15327 (8%)]\tLoss: 0.059031\n",
      "Train Epoch: 3 [1920/15327 (12%)]\tLoss: 0.049518\n",
      "Train Epoch: 3 [2560/15327 (17%)]\tLoss: 0.026673\n",
      "Train Epoch: 3 [3200/15327 (21%)]\tLoss: 0.191637\n",
      "Train Epoch: 3 [3840/15327 (25%)]\tLoss: 0.053203\n",
      "Train Epoch: 3 [4480/15327 (29%)]\tLoss: 0.138018\n",
      "Train Epoch: 3 [5120/15327 (33%)]\tLoss: 0.046794\n",
      "Train Epoch: 3 [5760/15327 (38%)]\tLoss: 0.016537\n",
      "Train Epoch: 3 [6400/15327 (42%)]\tLoss: 0.044860\n",
      "Train Epoch: 3 [7040/15327 (46%)]\tLoss: 0.144469\n",
      "Train Epoch: 3 [7680/15327 (50%)]\tLoss: 0.078317\n",
      "Train Epoch: 3 [8320/15327 (54%)]\tLoss: 0.103380\n",
      "Train Epoch: 3 [8960/15327 (58%)]\tLoss: 0.049968\n",
      "Train Epoch: 3 [9600/15327 (62%)]\tLoss: 0.173636\n",
      "Train Epoch: 3 [10240/15327 (67%)]\tLoss: 0.110873\n",
      "Train Epoch: 3 [10880/15327 (71%)]\tLoss: 0.065280\n",
      "Train Epoch: 3 [11520/15327 (75%)]\tLoss: 0.062344\n",
      "Train Epoch: 3 [12160/15327 (79%)]\tLoss: 0.065107\n",
      "Train Epoch: 3 [12800/15327 (83%)]\tLoss: 0.292428\n",
      "Train Epoch: 3 [13440/15327 (88%)]\tLoss: 0.038598\n",
      "Train Epoch: 3 [14080/15327 (92%)]\tLoss: 0.106940\n",
      "Train Epoch: 3 [14720/15327 (96%)]\tLoss: 0.065204\n",
      "Train Epoch: 4 [0/15327 (0%)]\tLoss: 0.185685\n",
      "Train Epoch: 4 [640/15327 (4%)]\tLoss: 0.064692\n",
      "Train Epoch: 4 [1280/15327 (8%)]\tLoss: 0.073471\n",
      "Train Epoch: 4 [1920/15327 (12%)]\tLoss: 0.064968\n",
      "Train Epoch: 4 [2560/15327 (17%)]\tLoss: 0.289913\n",
      "Train Epoch: 4 [3200/15327 (21%)]\tLoss: 0.043653\n",
      "Train Epoch: 4 [3840/15327 (25%)]\tLoss: 0.115947\n",
      "Train Epoch: 4 [4480/15327 (29%)]\tLoss: 0.149941\n",
      "Train Epoch: 4 [5120/15327 (33%)]\tLoss: 0.193764\n",
      "Train Epoch: 4 [5760/15327 (38%)]\tLoss: 0.154656\n",
      "Train Epoch: 4 [6400/15327 (42%)]\tLoss: 0.126859\n",
      "Train Epoch: 4 [7040/15327 (46%)]\tLoss: 0.130408\n",
      "Train Epoch: 4 [7680/15327 (50%)]\tLoss: 0.014721\n",
      "Train Epoch: 4 [8320/15327 (54%)]\tLoss: 0.057495\n",
      "Train Epoch: 4 [8960/15327 (58%)]\tLoss: 0.194073\n",
      "Train Epoch: 4 [9600/15327 (62%)]\tLoss: 0.179880\n",
      "Train Epoch: 4 [10240/15327 (67%)]\tLoss: 0.079109\n",
      "Train Epoch: 4 [10880/15327 (71%)]\tLoss: 0.046485\n",
      "Train Epoch: 4 [11520/15327 (75%)]\tLoss: 0.100498\n",
      "Train Epoch: 4 [12160/15327 (79%)]\tLoss: 0.415610\n",
      "Train Epoch: 4 [12800/15327 (83%)]\tLoss: 0.049138\n",
      "Train Epoch: 4 [13440/15327 (88%)]\tLoss: 0.058049\n",
      "Train Epoch: 4 [14080/15327 (92%)]\tLoss: 0.050376\n",
      "Train Epoch: 4 [14720/15327 (96%)]\tLoss: 0.067966\n",
      "Train Epoch: 5 [0/15327 (0%)]\tLoss: 0.174073\n",
      "Train Epoch: 5 [640/15327 (4%)]\tLoss: 0.059964\n",
      "Train Epoch: 5 [1280/15327 (8%)]\tLoss: 0.075304\n",
      "Train Epoch: 5 [1920/15327 (12%)]\tLoss: 0.036475\n",
      "Train Epoch: 5 [2560/15327 (17%)]\tLoss: 0.103145\n",
      "Train Epoch: 5 [3200/15327 (21%)]\tLoss: 0.169705\n",
      "Train Epoch: 5 [3840/15327 (25%)]\tLoss: 0.060173\n",
      "Train Epoch: 5 [4480/15327 (29%)]\tLoss: 0.109048\n",
      "Train Epoch: 5 [5120/15327 (33%)]\tLoss: 0.195405\n",
      "Train Epoch: 5 [5760/15327 (38%)]\tLoss: 0.091966\n",
      "Train Epoch: 5 [6400/15327 (42%)]\tLoss: 0.064318\n",
      "Train Epoch: 5 [7040/15327 (46%)]\tLoss: 0.089960\n",
      "Train Epoch: 5 [7680/15327 (50%)]\tLoss: 0.022776\n",
      "Train Epoch: 5 [8320/15327 (54%)]\tLoss: 0.037091\n",
      "Train Epoch: 5 [8960/15327 (58%)]\tLoss: 0.111665\n",
      "Train Epoch: 5 [9600/15327 (62%)]\tLoss: 0.087056\n",
      "Train Epoch: 5 [10240/15327 (67%)]\tLoss: 0.135750\n",
      "Train Epoch: 5 [10880/15327 (71%)]\tLoss: 0.054519\n",
      "Train Epoch: 5 [11520/15327 (75%)]\tLoss: 0.165989\n",
      "Train Epoch: 5 [12160/15327 (79%)]\tLoss: 0.095020\n",
      "Train Epoch: 5 [12800/15327 (83%)]\tLoss: 0.085901\n",
      "Train Epoch: 5 [13440/15327 (88%)]\tLoss: 0.101922\n",
      "Train Epoch: 5 [14080/15327 (92%)]\tLoss: 0.070594\n",
      "Train Epoch: 5 [14720/15327 (96%)]\tLoss: 0.179349\n",
      "Train Epoch: 6 [0/15327 (0%)]\tLoss: 0.054668\n",
      "Train Epoch: 6 [640/15327 (4%)]\tLoss: 0.315723\n",
      "Train Epoch: 6 [1280/15327 (8%)]\tLoss: 0.173756\n",
      "Train Epoch: 6 [1920/15327 (12%)]\tLoss: 0.128855\n",
      "Train Epoch: 6 [2560/15327 (17%)]\tLoss: 0.016033\n",
      "Train Epoch: 6 [3200/15327 (21%)]\tLoss: 0.059465\n",
      "Train Epoch: 6 [3840/15327 (25%)]\tLoss: 0.321167\n",
      "Train Epoch: 6 [4480/15327 (29%)]\tLoss: 0.035264\n",
      "Train Epoch: 6 [5120/15327 (33%)]\tLoss: 0.058203\n",
      "Train Epoch: 6 [5760/15327 (38%)]\tLoss: 0.071490\n",
      "Train Epoch: 6 [6400/15327 (42%)]\tLoss: 0.047504\n",
      "Train Epoch: 6 [7040/15327 (46%)]\tLoss: 0.031009\n",
      "Train Epoch: 6 [7680/15327 (50%)]\tLoss: 0.065117\n",
      "Train Epoch: 6 [8320/15327 (54%)]\tLoss: 0.039506\n",
      "Train Epoch: 6 [8960/15327 (58%)]\tLoss: 0.037305\n",
      "Train Epoch: 6 [9600/15327 (62%)]\tLoss: 0.094146\n",
      "Train Epoch: 6 [10240/15327 (67%)]\tLoss: 0.018416\n",
      "Train Epoch: 6 [10880/15327 (71%)]\tLoss: 0.315012\n",
      "Train Epoch: 6 [11520/15327 (75%)]\tLoss: 0.101220\n",
      "Train Epoch: 6 [12160/15327 (79%)]\tLoss: 0.070718\n",
      "Train Epoch: 6 [12800/15327 (83%)]\tLoss: 0.041018\n",
      "Train Epoch: 6 [13440/15327 (88%)]\tLoss: 0.085140\n",
      "Train Epoch: 6 [14080/15327 (92%)]\tLoss: 0.015257\n",
      "Train Epoch: 6 [14720/15327 (96%)]\tLoss: 0.151684\n",
      "Train Epoch: 7 [0/15327 (0%)]\tLoss: 0.062628\n",
      "Train Epoch: 7 [640/15327 (4%)]\tLoss: 0.097936\n",
      "Train Epoch: 7 [1280/15327 (8%)]\tLoss: 0.064375\n",
      "Train Epoch: 7 [1920/15327 (12%)]\tLoss: 0.080693\n",
      "Train Epoch: 7 [2560/15327 (17%)]\tLoss: 0.174177\n",
      "Train Epoch: 7 [3200/15327 (21%)]\tLoss: 0.024819\n",
      "Train Epoch: 7 [3840/15327 (25%)]\tLoss: 0.117343\n",
      "Train Epoch: 7 [4480/15327 (29%)]\tLoss: 0.310319\n",
      "Train Epoch: 7 [5120/15327 (33%)]\tLoss: 0.027759\n",
      "Train Epoch: 7 [5760/15327 (38%)]\tLoss: 0.115901\n",
      "Train Epoch: 7 [6400/15327 (42%)]\tLoss: 0.054791\n",
      "Train Epoch: 7 [7040/15327 (46%)]\tLoss: 0.032461\n",
      "Train Epoch: 7 [7680/15327 (50%)]\tLoss: 0.060628\n",
      "Train Epoch: 7 [8320/15327 (54%)]\tLoss: 0.123200\n",
      "Train Epoch: 7 [8960/15327 (58%)]\tLoss: 0.042121\n",
      "Train Epoch: 7 [9600/15327 (62%)]\tLoss: 0.071700\n",
      "Train Epoch: 7 [10240/15327 (67%)]\tLoss: 0.099998\n",
      "Train Epoch: 7 [10880/15327 (71%)]\tLoss: 0.038214\n",
      "Train Epoch: 7 [11520/15327 (75%)]\tLoss: 0.072010\n",
      "Train Epoch: 7 [12160/15327 (79%)]\tLoss: 0.115630\n",
      "Train Epoch: 7 [12800/15327 (83%)]\tLoss: 0.022549\n",
      "Train Epoch: 7 [13440/15327 (88%)]\tLoss: 0.379230\n",
      "Train Epoch: 7 [14080/15327 (92%)]\tLoss: 0.118050\n",
      "Train Epoch: 7 [14720/15327 (96%)]\tLoss: 0.069584\n",
      "Train Epoch: 8 [0/15327 (0%)]\tLoss: 0.025394\n",
      "Train Epoch: 8 [640/15327 (4%)]\tLoss: 0.127334\n",
      "Train Epoch: 8 [1280/15327 (8%)]\tLoss: 0.033635\n",
      "Train Epoch: 8 [1920/15327 (12%)]\tLoss: 0.105451\n",
      "Train Epoch: 8 [2560/15327 (17%)]\tLoss: 0.170579\n",
      "Train Epoch: 8 [3200/15327 (21%)]\tLoss: 0.135051\n",
      "Train Epoch: 8 [3840/15327 (25%)]\tLoss: 0.131162\n",
      "Train Epoch: 8 [4480/15327 (29%)]\tLoss: 0.036162\n",
      "Train Epoch: 8 [5120/15327 (33%)]\tLoss: 0.147141\n",
      "Train Epoch: 8 [5760/15327 (38%)]\tLoss: 0.063808\n",
      "Train Epoch: 8 [6400/15327 (42%)]\tLoss: 0.076919\n",
      "Train Epoch: 8 [7040/15327 (46%)]\tLoss: 0.027138\n",
      "Train Epoch: 8 [7680/15327 (50%)]\tLoss: 0.131856\n",
      "Train Epoch: 8 [8320/15327 (54%)]\tLoss: 0.038772\n",
      "Train Epoch: 8 [8960/15327 (58%)]\tLoss: 0.260587\n",
      "Train Epoch: 8 [9600/15327 (62%)]\tLoss: 0.070550\n",
      "Train Epoch: 8 [10240/15327 (67%)]\tLoss: 0.031799\n",
      "Train Epoch: 8 [10880/15327 (71%)]\tLoss: 0.095609\n",
      "Train Epoch: 8 [11520/15327 (75%)]\tLoss: 0.179486\n",
      "Train Epoch: 8 [12160/15327 (79%)]\tLoss: 0.076399\n",
      "Train Epoch: 8 [12800/15327 (83%)]\tLoss: 0.506674\n",
      "Train Epoch: 8 [13440/15327 (88%)]\tLoss: 0.060568\n",
      "Train Epoch: 8 [14080/15327 (92%)]\tLoss: 0.034874\n",
      "Train Epoch: 8 [14720/15327 (96%)]\tLoss: 0.086093\n",
      "Train Epoch: 9 [0/15327 (0%)]\tLoss: 0.084807\n",
      "Train Epoch: 9 [640/15327 (4%)]\tLoss: 0.157366\n",
      "Train Epoch: 9 [1280/15327 (8%)]\tLoss: 0.064017\n",
      "Train Epoch: 9 [1920/15327 (12%)]\tLoss: 0.071111\n",
      "Train Epoch: 9 [2560/15327 (17%)]\tLoss: 0.022903\n",
      "Train Epoch: 9 [3200/15327 (21%)]\tLoss: 0.042125\n",
      "Train Epoch: 9 [3840/15327 (25%)]\tLoss: 0.031951\n",
      "Train Epoch: 9 [4480/15327 (29%)]\tLoss: 0.060475\n",
      "Train Epoch: 9 [5120/15327 (33%)]\tLoss: 0.096747\n",
      "Train Epoch: 9 [5760/15327 (38%)]\tLoss: 0.013728\n",
      "Train Epoch: 9 [6400/15327 (42%)]\tLoss: 0.040396\n",
      "Train Epoch: 9 [7040/15327 (46%)]\tLoss: 0.052201\n",
      "Train Epoch: 9 [7680/15327 (50%)]\tLoss: 0.209257\n",
      "Train Epoch: 9 [8320/15327 (54%)]\tLoss: 0.016786\n",
      "Train Epoch: 9 [8960/15327 (58%)]\tLoss: 0.019742\n",
      "Train Epoch: 9 [9600/15327 (62%)]\tLoss: 0.029034\n",
      "Train Epoch: 9 [10240/15327 (67%)]\tLoss: 0.029913\n",
      "Train Epoch: 9 [10880/15327 (71%)]\tLoss: 0.071943\n",
      "Train Epoch: 9 [11520/15327 (75%)]\tLoss: 0.069183\n",
      "Train Epoch: 9 [12160/15327 (79%)]\tLoss: 0.030035\n",
      "Train Epoch: 9 [12800/15327 (83%)]\tLoss: 0.030605\n",
      "Train Epoch: 9 [13440/15327 (88%)]\tLoss: 0.034101\n",
      "Train Epoch: 9 [14080/15327 (92%)]\tLoss: 0.076090\n",
      "Train Epoch: 9 [14720/15327 (96%)]\tLoss: 0.065223\n",
      "Train Epoch: 10 [0/15327 (0%)]\tLoss: 0.037604\n",
      "Train Epoch: 10 [640/15327 (4%)]\tLoss: 0.110945\n",
      "Train Epoch: 10 [1280/15327 (8%)]\tLoss: 0.012518\n",
      "Train Epoch: 10 [1920/15327 (12%)]\tLoss: 0.069366\n",
      "Train Epoch: 10 [2560/15327 (17%)]\tLoss: 0.145297\n",
      "Train Epoch: 10 [3200/15327 (21%)]\tLoss: 0.097506\n",
      "Train Epoch: 10 [3840/15327 (25%)]\tLoss: 0.122760\n",
      "Train Epoch: 10 [4480/15327 (29%)]\tLoss: 0.132909\n",
      "Train Epoch: 10 [5120/15327 (33%)]\tLoss: 0.090326\n",
      "Train Epoch: 10 [5760/15327 (38%)]\tLoss: 0.111371\n",
      "Train Epoch: 10 [6400/15327 (42%)]\tLoss: 0.126355\n",
      "Train Epoch: 10 [7040/15327 (46%)]\tLoss: 0.062361\n",
      "Train Epoch: 10 [7680/15327 (50%)]\tLoss: 0.085878\n",
      "Train Epoch: 10 [8320/15327 (54%)]\tLoss: 0.035092\n",
      "Train Epoch: 10 [8960/15327 (58%)]\tLoss: 0.097276\n",
      "Train Epoch: 10 [9600/15327 (62%)]\tLoss: 0.080035\n",
      "Train Epoch: 10 [10240/15327 (67%)]\tLoss: 0.083579\n",
      "Train Epoch: 10 [10880/15327 (71%)]\tLoss: 0.029677\n",
      "Train Epoch: 10 [11520/15327 (75%)]\tLoss: 0.029837\n",
      "Train Epoch: 10 [12160/15327 (79%)]\tLoss: 0.138620\n",
      "Train Epoch: 10 [12800/15327 (83%)]\tLoss: 0.061824\n",
      "Train Epoch: 10 [13440/15327 (88%)]\tLoss: 0.039762\n",
      "Train Epoch: 10 [14080/15327 (92%)]\tLoss: 0.027035\n",
      "Train Epoch: 10 [14720/15327 (96%)]\tLoss: 0.031605\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0600, Accuracy: 9810/10000 (98%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/18662 (0%)]\tLoss: 0.261872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [640/18662 (3%)]\tLoss: 0.137298\n",
      "Train Epoch: 1 [1280/18662 (7%)]\tLoss: 0.040660\n",
      "Train Epoch: 1 [1920/18662 (10%)]\tLoss: 0.144707\n",
      "Train Epoch: 1 [2560/18662 (14%)]\tLoss: 0.227213\n",
      "Train Epoch: 1 [3200/18662 (17%)]\tLoss: 0.083728\n",
      "Train Epoch: 1 [3840/18662 (21%)]\tLoss: 0.182354\n",
      "Train Epoch: 1 [4480/18662 (24%)]\tLoss: 0.062007\n",
      "Train Epoch: 1 [5120/18662 (27%)]\tLoss: 0.075902\n",
      "Train Epoch: 1 [5760/18662 (31%)]\tLoss: 0.095238\n",
      "Train Epoch: 1 [6400/18662 (34%)]\tLoss: 0.064334\n",
      "Train Epoch: 1 [7040/18662 (38%)]\tLoss: 0.015453\n",
      "Train Epoch: 1 [7680/18662 (41%)]\tLoss: 0.071626\n",
      "Train Epoch: 1 [8320/18662 (45%)]\tLoss: 0.099451\n",
      "Train Epoch: 1 [8960/18662 (48%)]\tLoss: 0.057233\n",
      "Train Epoch: 1 [9600/18662 (51%)]\tLoss: 0.059934\n",
      "Train Epoch: 1 [10240/18662 (55%)]\tLoss: 0.074383\n",
      "Train Epoch: 1 [10880/18662 (58%)]\tLoss: 0.072503\n",
      "Train Epoch: 1 [11520/18662 (62%)]\tLoss: 0.044070\n",
      "Train Epoch: 1 [12160/18662 (65%)]\tLoss: 0.033844\n",
      "Train Epoch: 1 [12800/18662 (68%)]\tLoss: 0.075945\n",
      "Train Epoch: 1 [13440/18662 (72%)]\tLoss: 0.214160\n",
      "Train Epoch: 1 [14080/18662 (75%)]\tLoss: 0.063743\n",
      "Train Epoch: 1 [14720/18662 (79%)]\tLoss: 0.167776\n",
      "Train Epoch: 1 [15360/18662 (82%)]\tLoss: 0.052730\n",
      "Train Epoch: 1 [16000/18662 (86%)]\tLoss: 0.077390\n",
      "Train Epoch: 1 [16640/18662 (89%)]\tLoss: 0.170269\n",
      "Train Epoch: 1 [17280/18662 (92%)]\tLoss: 0.075859\n",
      "Train Epoch: 1 [17920/18662 (96%)]\tLoss: 0.090502\n",
      "Train Epoch: 1 [18560/18662 (99%)]\tLoss: 0.080949\n",
      "Train Epoch: 2 [0/18662 (0%)]\tLoss: 0.129453\n",
      "Train Epoch: 2 [640/18662 (3%)]\tLoss: 0.072590\n",
      "Train Epoch: 2 [1280/18662 (7%)]\tLoss: 0.071783\n",
      "Train Epoch: 2 [1920/18662 (10%)]\tLoss: 0.153617\n",
      "Train Epoch: 2 [2560/18662 (14%)]\tLoss: 0.098828\n",
      "Train Epoch: 2 [3200/18662 (17%)]\tLoss: 0.261512\n",
      "Train Epoch: 2 [3840/18662 (21%)]\tLoss: 0.026664\n",
      "Train Epoch: 2 [4480/18662 (24%)]\tLoss: 0.052708\n",
      "Train Epoch: 2 [5120/18662 (27%)]\tLoss: 0.118787\n",
      "Train Epoch: 2 [5760/18662 (31%)]\tLoss: 0.159298\n",
      "Train Epoch: 2 [6400/18662 (34%)]\tLoss: 0.040930\n",
      "Train Epoch: 2 [7040/18662 (38%)]\tLoss: 0.059313\n",
      "Train Epoch: 2 [7680/18662 (41%)]\tLoss: 0.031117\n",
      "Train Epoch: 2 [8320/18662 (45%)]\tLoss: 0.043775\n",
      "Train Epoch: 2 [8960/18662 (48%)]\tLoss: 0.031711\n",
      "Train Epoch: 2 [9600/18662 (51%)]\tLoss: 0.033806\n",
      "Train Epoch: 2 [10240/18662 (55%)]\tLoss: 0.099156\n",
      "Train Epoch: 2 [10880/18662 (58%)]\tLoss: 0.194189\n",
      "Train Epoch: 2 [11520/18662 (62%)]\tLoss: 0.042325\n",
      "Train Epoch: 2 [12160/18662 (65%)]\tLoss: 0.190350\n",
      "Train Epoch: 2 [12800/18662 (68%)]\tLoss: 0.071401\n",
      "Train Epoch: 2 [13440/18662 (72%)]\tLoss: 0.157769\n",
      "Train Epoch: 2 [14080/18662 (75%)]\tLoss: 0.198646\n",
      "Train Epoch: 2 [14720/18662 (79%)]\tLoss: 0.222043\n",
      "Train Epoch: 2 [15360/18662 (82%)]\tLoss: 0.078941\n",
      "Train Epoch: 2 [16000/18662 (86%)]\tLoss: 0.013143\n",
      "Train Epoch: 2 [16640/18662 (89%)]\tLoss: 0.098876\n",
      "Train Epoch: 2 [17280/18662 (92%)]\tLoss: 0.186777\n",
      "Train Epoch: 2 [17920/18662 (96%)]\tLoss: 0.248298\n",
      "Train Epoch: 2 [18560/18662 (99%)]\tLoss: 0.031899\n",
      "Train Epoch: 3 [0/18662 (0%)]\tLoss: 0.012488\n",
      "Train Epoch: 3 [640/18662 (3%)]\tLoss: 0.036638\n",
      "Train Epoch: 3 [1280/18662 (7%)]\tLoss: 0.069222\n",
      "Train Epoch: 3 [1920/18662 (10%)]\tLoss: 0.151273\n",
      "Train Epoch: 3 [2560/18662 (14%)]\tLoss: 0.159922\n",
      "Train Epoch: 3 [3200/18662 (17%)]\tLoss: 0.087073\n",
      "Train Epoch: 3 [3840/18662 (21%)]\tLoss: 0.032307\n",
      "Train Epoch: 3 [4480/18662 (24%)]\tLoss: 0.095009\n",
      "Train Epoch: 3 [5120/18662 (27%)]\tLoss: 0.123616\n",
      "Train Epoch: 3 [5760/18662 (31%)]\tLoss: 0.074327\n",
      "Train Epoch: 3 [6400/18662 (34%)]\tLoss: 0.215395\n",
      "Train Epoch: 3 [7040/18662 (38%)]\tLoss: 0.048306\n",
      "Train Epoch: 3 [7680/18662 (41%)]\tLoss: 0.062764\n",
      "Train Epoch: 3 [8320/18662 (45%)]\tLoss: 0.107490\n",
      "Train Epoch: 3 [8960/18662 (48%)]\tLoss: 0.034248\n",
      "Train Epoch: 3 [9600/18662 (51%)]\tLoss: 0.010549\n",
      "Train Epoch: 3 [10240/18662 (55%)]\tLoss: 0.085007\n",
      "Train Epoch: 3 [10880/18662 (58%)]\tLoss: 0.067278\n",
      "Train Epoch: 3 [11520/18662 (62%)]\tLoss: 0.068176\n",
      "Train Epoch: 3 [12160/18662 (65%)]\tLoss: 0.057138\n",
      "Train Epoch: 3 [12800/18662 (68%)]\tLoss: 0.037143\n",
      "Train Epoch: 3 [13440/18662 (72%)]\tLoss: 0.186046\n",
      "Train Epoch: 3 [14080/18662 (75%)]\tLoss: 0.087425\n",
      "Train Epoch: 3 [14720/18662 (79%)]\tLoss: 0.034983\n",
      "Train Epoch: 3 [15360/18662 (82%)]\tLoss: 0.238200\n",
      "Train Epoch: 3 [16000/18662 (86%)]\tLoss: 0.060014\n",
      "Train Epoch: 3 [16640/18662 (89%)]\tLoss: 0.168923\n",
      "Train Epoch: 3 [17280/18662 (92%)]\tLoss: 0.067999\n",
      "Train Epoch: 3 [17920/18662 (96%)]\tLoss: 0.033437\n",
      "Train Epoch: 3 [18560/18662 (99%)]\tLoss: 0.036314\n",
      "Train Epoch: 4 [0/18662 (0%)]\tLoss: 0.055831\n",
      "Train Epoch: 4 [640/18662 (3%)]\tLoss: 0.090960\n",
      "Train Epoch: 4 [1280/18662 (7%)]\tLoss: 0.028345\n",
      "Train Epoch: 4 [1920/18662 (10%)]\tLoss: 0.113231\n",
      "Train Epoch: 4 [2560/18662 (14%)]\tLoss: 0.183417\n",
      "Train Epoch: 4 [3200/18662 (17%)]\tLoss: 0.071657\n",
      "Train Epoch: 4 [3840/18662 (21%)]\tLoss: 0.134443\n",
      "Train Epoch: 4 [4480/18662 (24%)]\tLoss: 0.076680\n",
      "Train Epoch: 4 [5120/18662 (27%)]\tLoss: 0.110462\n",
      "Train Epoch: 4 [5760/18662 (31%)]\tLoss: 0.056591\n",
      "Train Epoch: 4 [6400/18662 (34%)]\tLoss: 0.073249\n",
      "Train Epoch: 4 [7040/18662 (38%)]\tLoss: 0.158777\n",
      "Train Epoch: 4 [7680/18662 (41%)]\tLoss: 0.096203\n",
      "Train Epoch: 4 [8320/18662 (45%)]\tLoss: 0.039643\n",
      "Train Epoch: 4 [8960/18662 (48%)]\tLoss: 0.068507\n",
      "Train Epoch: 4 [9600/18662 (51%)]\tLoss: 0.077452\n",
      "Train Epoch: 4 [10240/18662 (55%)]\tLoss: 0.016874\n",
      "Train Epoch: 4 [10880/18662 (58%)]\tLoss: 0.077775\n",
      "Train Epoch: 4 [11520/18662 (62%)]\tLoss: 0.137288\n",
      "Train Epoch: 4 [12160/18662 (65%)]\tLoss: 0.092312\n",
      "Train Epoch: 4 [12800/18662 (68%)]\tLoss: 0.035272\n",
      "Train Epoch: 4 [13440/18662 (72%)]\tLoss: 0.049821\n",
      "Train Epoch: 4 [14080/18662 (75%)]\tLoss: 0.115951\n",
      "Train Epoch: 4 [14720/18662 (79%)]\tLoss: 0.140246\n",
      "Train Epoch: 4 [15360/18662 (82%)]\tLoss: 0.057942\n",
      "Train Epoch: 4 [16000/18662 (86%)]\tLoss: 0.034689\n",
      "Train Epoch: 4 [16640/18662 (89%)]\tLoss: 0.103314\n",
      "Train Epoch: 4 [17280/18662 (92%)]\tLoss: 0.064657\n",
      "Train Epoch: 4 [17920/18662 (96%)]\tLoss: 0.093732\n",
      "Train Epoch: 4 [18560/18662 (99%)]\tLoss: 0.052554\n",
      "Train Epoch: 5 [0/18662 (0%)]\tLoss: 0.049274\n",
      "Train Epoch: 5 [640/18662 (3%)]\tLoss: 0.083072\n",
      "Train Epoch: 5 [1280/18662 (7%)]\tLoss: 0.094641\n",
      "Train Epoch: 5 [1920/18662 (10%)]\tLoss: 0.059923\n",
      "Train Epoch: 5 [2560/18662 (14%)]\tLoss: 0.418569\n",
      "Train Epoch: 5 [3200/18662 (17%)]\tLoss: 0.054041\n",
      "Train Epoch: 5 [3840/18662 (21%)]\tLoss: 0.043612\n",
      "Train Epoch: 5 [4480/18662 (24%)]\tLoss: 0.090181\n",
      "Train Epoch: 5 [5120/18662 (27%)]\tLoss: 0.019887\n",
      "Train Epoch: 5 [5760/18662 (31%)]\tLoss: 0.121723\n",
      "Train Epoch: 5 [6400/18662 (34%)]\tLoss: 0.171886\n",
      "Train Epoch: 5 [7040/18662 (38%)]\tLoss: 0.037358\n",
      "Train Epoch: 5 [7680/18662 (41%)]\tLoss: 0.101460\n",
      "Train Epoch: 5 [8320/18662 (45%)]\tLoss: 0.048145\n",
      "Train Epoch: 5 [8960/18662 (48%)]\tLoss: 0.058123\n",
      "Train Epoch: 5 [9600/18662 (51%)]\tLoss: 0.113303\n",
      "Train Epoch: 5 [10240/18662 (55%)]\tLoss: 0.027546\n",
      "Train Epoch: 5 [10880/18662 (58%)]\tLoss: 0.015785\n",
      "Train Epoch: 5 [11520/18662 (62%)]\tLoss: 0.052975\n",
      "Train Epoch: 5 [12160/18662 (65%)]\tLoss: 0.050337\n",
      "Train Epoch: 5 [12800/18662 (68%)]\tLoss: 0.151825\n",
      "Train Epoch: 5 [13440/18662 (72%)]\tLoss: 0.210023\n",
      "Train Epoch: 5 [14080/18662 (75%)]\tLoss: 0.025709\n",
      "Train Epoch: 5 [14720/18662 (79%)]\tLoss: 0.134494\n",
      "Train Epoch: 5 [15360/18662 (82%)]\tLoss: 0.185837\n",
      "Train Epoch: 5 [16000/18662 (86%)]\tLoss: 0.091843\n",
      "Train Epoch: 5 [16640/18662 (89%)]\tLoss: 0.042401\n",
      "Train Epoch: 5 [17280/18662 (92%)]\tLoss: 0.027338\n",
      "Train Epoch: 5 [17920/18662 (96%)]\tLoss: 0.112827\n",
      "Train Epoch: 5 [18560/18662 (99%)]\tLoss: 0.109103\n",
      "Train Epoch: 6 [0/18662 (0%)]\tLoss: 0.130410\n",
      "Train Epoch: 6 [640/18662 (3%)]\tLoss: 0.077698\n",
      "Train Epoch: 6 [1280/18662 (7%)]\tLoss: 0.034634\n",
      "Train Epoch: 6 [1920/18662 (10%)]\tLoss: 0.147503\n",
      "Train Epoch: 6 [2560/18662 (14%)]\tLoss: 0.099403\n",
      "Train Epoch: 6 [3200/18662 (17%)]\tLoss: 0.132042\n",
      "Train Epoch: 6 [3840/18662 (21%)]\tLoss: 0.049386\n",
      "Train Epoch: 6 [4480/18662 (24%)]\tLoss: 0.038655\n",
      "Train Epoch: 6 [5120/18662 (27%)]\tLoss: 0.014799\n",
      "Train Epoch: 6 [5760/18662 (31%)]\tLoss: 0.031243\n",
      "Train Epoch: 6 [6400/18662 (34%)]\tLoss: 0.103968\n",
      "Train Epoch: 6 [7040/18662 (38%)]\tLoss: 0.013957\n",
      "Train Epoch: 6 [7680/18662 (41%)]\tLoss: 0.033577\n",
      "Train Epoch: 6 [8320/18662 (45%)]\tLoss: 0.056029\n",
      "Train Epoch: 6 [8960/18662 (48%)]\tLoss: 0.045067\n",
      "Train Epoch: 6 [9600/18662 (51%)]\tLoss: 0.045046\n",
      "Train Epoch: 6 [10240/18662 (55%)]\tLoss: 0.027180\n",
      "Train Epoch: 6 [10880/18662 (58%)]\tLoss: 0.109781\n",
      "Train Epoch: 6 [11520/18662 (62%)]\tLoss: 0.028687\n",
      "Train Epoch: 6 [12160/18662 (65%)]\tLoss: 0.141814\n",
      "Train Epoch: 6 [12800/18662 (68%)]\tLoss: 0.039213\n",
      "Train Epoch: 6 [13440/18662 (72%)]\tLoss: 0.104403\n",
      "Train Epoch: 6 [14080/18662 (75%)]\tLoss: 0.039534\n",
      "Train Epoch: 6 [14720/18662 (79%)]\tLoss: 0.040112\n",
      "Train Epoch: 6 [15360/18662 (82%)]\tLoss: 0.067205\n",
      "Train Epoch: 6 [16000/18662 (86%)]\tLoss: 0.008861\n",
      "Train Epoch: 6 [16640/18662 (89%)]\tLoss: 0.572816\n",
      "Train Epoch: 6 [17280/18662 (92%)]\tLoss: 0.140108\n",
      "Train Epoch: 6 [17920/18662 (96%)]\tLoss: 0.049988\n",
      "Train Epoch: 6 [18560/18662 (99%)]\tLoss: 0.081190\n",
      "Train Epoch: 7 [0/18662 (0%)]\tLoss: 0.032076\n",
      "Train Epoch: 7 [640/18662 (3%)]\tLoss: 0.040803\n",
      "Train Epoch: 7 [1280/18662 (7%)]\tLoss: 0.033940\n",
      "Train Epoch: 7 [1920/18662 (10%)]\tLoss: 0.039192\n",
      "Train Epoch: 7 [2560/18662 (14%)]\tLoss: 0.090817\n",
      "Train Epoch: 7 [3200/18662 (17%)]\tLoss: 0.059252\n",
      "Train Epoch: 7 [3840/18662 (21%)]\tLoss: 0.123708\n",
      "Train Epoch: 7 [4480/18662 (24%)]\tLoss: 0.052236\n",
      "Train Epoch: 7 [5120/18662 (27%)]\tLoss: 0.136452\n",
      "Train Epoch: 7 [5760/18662 (31%)]\tLoss: 0.050728\n",
      "Train Epoch: 7 [6400/18662 (34%)]\tLoss: 0.146478\n",
      "Train Epoch: 7 [7040/18662 (38%)]\tLoss: 0.049000\n",
      "Train Epoch: 7 [7680/18662 (41%)]\tLoss: 0.104823\n",
      "Train Epoch: 7 [8320/18662 (45%)]\tLoss: 0.030768\n",
      "Train Epoch: 7 [8960/18662 (48%)]\tLoss: 0.120025\n",
      "Train Epoch: 7 [9600/18662 (51%)]\tLoss: 0.007600\n",
      "Train Epoch: 7 [10240/18662 (55%)]\tLoss: 0.113571\n",
      "Train Epoch: 7 [10880/18662 (58%)]\tLoss: 0.112832\n",
      "Train Epoch: 7 [11520/18662 (62%)]\tLoss: 0.058830\n",
      "Train Epoch: 7 [12160/18662 (65%)]\tLoss: 0.016847\n",
      "Train Epoch: 7 [12800/18662 (68%)]\tLoss: 0.194629\n",
      "Train Epoch: 7 [13440/18662 (72%)]\tLoss: 0.022430\n",
      "Train Epoch: 7 [14080/18662 (75%)]\tLoss: 0.084210\n",
      "Train Epoch: 7 [14720/18662 (79%)]\tLoss: 0.086486\n",
      "Train Epoch: 7 [15360/18662 (82%)]\tLoss: 0.023758\n",
      "Train Epoch: 7 [16000/18662 (86%)]\tLoss: 0.083305\n",
      "Train Epoch: 7 [16640/18662 (89%)]\tLoss: 0.092109\n",
      "Train Epoch: 7 [17280/18662 (92%)]\tLoss: 0.100208\n",
      "Train Epoch: 7 [17920/18662 (96%)]\tLoss: 0.038133\n",
      "Train Epoch: 7 [18560/18662 (99%)]\tLoss: 0.027889\n",
      "Train Epoch: 8 [0/18662 (0%)]\tLoss: 0.094209\n",
      "Train Epoch: 8 [640/18662 (3%)]\tLoss: 0.046348\n",
      "Train Epoch: 8 [1280/18662 (7%)]\tLoss: 0.090976\n",
      "Train Epoch: 8 [1920/18662 (10%)]\tLoss: 0.030273\n",
      "Train Epoch: 8 [2560/18662 (14%)]\tLoss: 0.063553\n",
      "Train Epoch: 8 [3200/18662 (17%)]\tLoss: 0.017938\n",
      "Train Epoch: 8 [3840/18662 (21%)]\tLoss: 0.110682\n",
      "Train Epoch: 8 [4480/18662 (24%)]\tLoss: 0.009564\n",
      "Train Epoch: 8 [5120/18662 (27%)]\tLoss: 0.020588\n",
      "Train Epoch: 8 [5760/18662 (31%)]\tLoss: 0.110126\n",
      "Train Epoch: 8 [6400/18662 (34%)]\tLoss: 0.206147\n",
      "Train Epoch: 8 [7040/18662 (38%)]\tLoss: 0.111230\n",
      "Train Epoch: 8 [7680/18662 (41%)]\tLoss: 0.214933\n",
      "Train Epoch: 8 [8320/18662 (45%)]\tLoss: 0.055555\n",
      "Train Epoch: 8 [8960/18662 (48%)]\tLoss: 0.163317\n",
      "Train Epoch: 8 [9600/18662 (51%)]\tLoss: 0.131511\n",
      "Train Epoch: 8 [10240/18662 (55%)]\tLoss: 0.104130\n",
      "Train Epoch: 8 [10880/18662 (58%)]\tLoss: 0.027651\n",
      "Train Epoch: 8 [11520/18662 (62%)]\tLoss: 0.053978\n",
      "Train Epoch: 8 [12160/18662 (65%)]\tLoss: 0.106085\n",
      "Train Epoch: 8 [12800/18662 (68%)]\tLoss: 0.126827\n",
      "Train Epoch: 8 [13440/18662 (72%)]\tLoss: 0.108690\n",
      "Train Epoch: 8 [14080/18662 (75%)]\tLoss: 0.039373\n",
      "Train Epoch: 8 [14720/18662 (79%)]\tLoss: 0.183832\n",
      "Train Epoch: 8 [15360/18662 (82%)]\tLoss: 0.052325\n",
      "Train Epoch: 8 [16000/18662 (86%)]\tLoss: 0.079182\n",
      "Train Epoch: 8 [16640/18662 (89%)]\tLoss: 0.236183\n",
      "Train Epoch: 8 [17280/18662 (92%)]\tLoss: 0.084219\n",
      "Train Epoch: 8 [17920/18662 (96%)]\tLoss: 0.044409\n",
      "Train Epoch: 8 [18560/18662 (99%)]\tLoss: 0.182382\n",
      "Train Epoch: 9 [0/18662 (0%)]\tLoss: 0.147775\n",
      "Train Epoch: 9 [640/18662 (3%)]\tLoss: 0.071417\n",
      "Train Epoch: 9 [1280/18662 (7%)]\tLoss: 0.150209\n",
      "Train Epoch: 9 [1920/18662 (10%)]\tLoss: 0.031859\n",
      "Train Epoch: 9 [2560/18662 (14%)]\tLoss: 0.114292\n",
      "Train Epoch: 9 [3200/18662 (17%)]\tLoss: 0.012970\n",
      "Train Epoch: 9 [3840/18662 (21%)]\tLoss: 0.028382\n",
      "Train Epoch: 9 [4480/18662 (24%)]\tLoss: 0.027676\n",
      "Train Epoch: 9 [5120/18662 (27%)]\tLoss: 0.006452\n",
      "Train Epoch: 9 [5760/18662 (31%)]\tLoss: 0.085467\n",
      "Train Epoch: 9 [6400/18662 (34%)]\tLoss: 0.063586\n",
      "Train Epoch: 9 [7040/18662 (38%)]\tLoss: 0.057457\n",
      "Train Epoch: 9 [7680/18662 (41%)]\tLoss: 0.012008\n",
      "Train Epoch: 9 [8320/18662 (45%)]\tLoss: 0.010516\n",
      "Train Epoch: 9 [8960/18662 (48%)]\tLoss: 0.066821\n",
      "Train Epoch: 9 [9600/18662 (51%)]\tLoss: 0.041963\n",
      "Train Epoch: 9 [10240/18662 (55%)]\tLoss: 0.037178\n",
      "Train Epoch: 9 [10880/18662 (58%)]\tLoss: 0.080597\n",
      "Train Epoch: 9 [11520/18662 (62%)]\tLoss: 0.072059\n",
      "Train Epoch: 9 [12160/18662 (65%)]\tLoss: 0.037086\n",
      "Train Epoch: 9 [12800/18662 (68%)]\tLoss: 0.088533\n",
      "Train Epoch: 9 [13440/18662 (72%)]\tLoss: 0.060030\n",
      "Train Epoch: 9 [14080/18662 (75%)]\tLoss: 0.019237\n",
      "Train Epoch: 9 [14720/18662 (79%)]\tLoss: 0.083288\n",
      "Train Epoch: 9 [15360/18662 (82%)]\tLoss: 0.179317\n",
      "Train Epoch: 9 [16000/18662 (86%)]\tLoss: 0.123438\n",
      "Train Epoch: 9 [16640/18662 (89%)]\tLoss: 0.119068\n",
      "Train Epoch: 9 [17280/18662 (92%)]\tLoss: 0.065899\n",
      "Train Epoch: 9 [17920/18662 (96%)]\tLoss: 0.169037\n",
      "Train Epoch: 9 [18560/18662 (99%)]\tLoss: 0.087491\n",
      "Train Epoch: 10 [0/18662 (0%)]\tLoss: 0.020378\n",
      "Train Epoch: 10 [640/18662 (3%)]\tLoss: 0.023317\n",
      "Train Epoch: 10 [1280/18662 (7%)]\tLoss: 0.131347\n",
      "Train Epoch: 10 [1920/18662 (10%)]\tLoss: 0.087705\n",
      "Train Epoch: 10 [2560/18662 (14%)]\tLoss: 0.091992\n",
      "Train Epoch: 10 [3200/18662 (17%)]\tLoss: 0.009013\n",
      "Train Epoch: 10 [3840/18662 (21%)]\tLoss: 0.037626\n",
      "Train Epoch: 10 [4480/18662 (24%)]\tLoss: 0.208771\n",
      "Train Epoch: 10 [5120/18662 (27%)]\tLoss: 0.041494\n",
      "Train Epoch: 10 [5760/18662 (31%)]\tLoss: 0.153155\n",
      "Train Epoch: 10 [6400/18662 (34%)]\tLoss: 0.085410\n",
      "Train Epoch: 10 [7040/18662 (38%)]\tLoss: 0.022447\n",
      "Train Epoch: 10 [7680/18662 (41%)]\tLoss: 0.081759\n",
      "Train Epoch: 10 [8320/18662 (45%)]\tLoss: 0.150196\n",
      "Train Epoch: 10 [8960/18662 (48%)]\tLoss: 0.138134\n",
      "Train Epoch: 10 [9600/18662 (51%)]\tLoss: 0.018111\n",
      "Train Epoch: 10 [10240/18662 (55%)]\tLoss: 0.085194\n",
      "Train Epoch: 10 [10880/18662 (58%)]\tLoss: 0.100516\n",
      "Train Epoch: 10 [11520/18662 (62%)]\tLoss: 0.229167\n",
      "Train Epoch: 10 [12160/18662 (65%)]\tLoss: 0.116697\n",
      "Train Epoch: 10 [12800/18662 (68%)]\tLoss: 0.022913\n",
      "Train Epoch: 10 [13440/18662 (72%)]\tLoss: 0.056093\n",
      "Train Epoch: 10 [14080/18662 (75%)]\tLoss: 0.020118\n",
      "Train Epoch: 10 [14720/18662 (79%)]\tLoss: 0.034648\n",
      "Train Epoch: 10 [15360/18662 (82%)]\tLoss: 0.224492\n",
      "Train Epoch: 10 [16000/18662 (86%)]\tLoss: 0.077988\n",
      "Train Epoch: 10 [16640/18662 (89%)]\tLoss: 0.083018\n",
      "Train Epoch: 10 [17280/18662 (92%)]\tLoss: 0.076137\n",
      "Train Epoch: 10 [17920/18662 (96%)]\tLoss: 0.071966\n",
      "Train Epoch: 10 [18560/18662 (99%)]\tLoss: 0.011918\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/10619 (0%)]\tLoss: 0.308716\n",
      "Train Epoch: 1 [640/10619 (6%)]\tLoss: 0.043450\n",
      "Train Epoch: 1 [1280/10619 (12%)]\tLoss: 0.093986\n",
      "Train Epoch: 1 [1920/10619 (18%)]\tLoss: 0.104783\n",
      "Train Epoch: 1 [2560/10619 (24%)]\tLoss: 0.359779\n",
      "Train Epoch: 1 [3200/10619 (30%)]\tLoss: 0.228162\n",
      "Train Epoch: 1 [3840/10619 (36%)]\tLoss: 0.119401\n",
      "Train Epoch: 1 [4480/10619 (42%)]\tLoss: 0.037876\n",
      "Train Epoch: 1 [5120/10619 (48%)]\tLoss: 0.192131\n",
      "Train Epoch: 1 [5760/10619 (54%)]\tLoss: 0.024622\n",
      "Train Epoch: 1 [6400/10619 (60%)]\tLoss: 0.121389\n",
      "Train Epoch: 1 [7040/10619 (66%)]\tLoss: 0.071790\n",
      "Train Epoch: 1 [7680/10619 (72%)]\tLoss: 0.248284\n",
      "Train Epoch: 1 [8320/10619 (78%)]\tLoss: 0.176430\n",
      "Train Epoch: 1 [8960/10619 (84%)]\tLoss: 0.091612\n",
      "Train Epoch: 1 [9600/10619 (90%)]\tLoss: 0.203799\n",
      "Train Epoch: 1 [10240/10619 (96%)]\tLoss: 0.048639\n",
      "Train Epoch: 2 [0/10619 (0%)]\tLoss: 0.064063\n",
      "Train Epoch: 2 [640/10619 (6%)]\tLoss: 0.083554\n",
      "Train Epoch: 2 [1280/10619 (12%)]\tLoss: 0.087838\n",
      "Train Epoch: 2 [1920/10619 (18%)]\tLoss: 0.126155\n",
      "Train Epoch: 2 [2560/10619 (24%)]\tLoss: 0.056416\n",
      "Train Epoch: 2 [3200/10619 (30%)]\tLoss: 0.216063\n",
      "Train Epoch: 2 [3840/10619 (36%)]\tLoss: 0.125611\n",
      "Train Epoch: 2 [4480/10619 (42%)]\tLoss: 0.124275\n",
      "Train Epoch: 2 [5120/10619 (48%)]\tLoss: 0.069545\n",
      "Train Epoch: 2 [5760/10619 (54%)]\tLoss: 0.115388\n",
      "Train Epoch: 2 [6400/10619 (60%)]\tLoss: 0.325961\n",
      "Train Epoch: 2 [7040/10619 (66%)]\tLoss: 0.090823\n",
      "Train Epoch: 2 [7680/10619 (72%)]\tLoss: 0.182813\n",
      "Train Epoch: 2 [8320/10619 (78%)]\tLoss: 0.123221\n",
      "Train Epoch: 2 [8960/10619 (84%)]\tLoss: 0.085857\n",
      "Train Epoch: 2 [9600/10619 (90%)]\tLoss: 0.057610\n",
      "Train Epoch: 2 [10240/10619 (96%)]\tLoss: 0.076382\n",
      "Train Epoch: 3 [0/10619 (0%)]\tLoss: 0.043794\n",
      "Train Epoch: 3 [640/10619 (6%)]\tLoss: 0.054924\n",
      "Train Epoch: 3 [1280/10619 (12%)]\tLoss: 0.125529\n",
      "Train Epoch: 3 [1920/10619 (18%)]\tLoss: 0.117609\n",
      "Train Epoch: 3 [2560/10619 (24%)]\tLoss: 0.061785\n",
      "Train Epoch: 3 [3200/10619 (30%)]\tLoss: 0.129529\n",
      "Train Epoch: 3 [3840/10619 (36%)]\tLoss: 0.138570\n",
      "Train Epoch: 3 [4480/10619 (42%)]\tLoss: 0.200909\n",
      "Train Epoch: 3 [5120/10619 (48%)]\tLoss: 0.105356\n",
      "Train Epoch: 3 [5760/10619 (54%)]\tLoss: 0.185576\n",
      "Train Epoch: 3 [6400/10619 (60%)]\tLoss: 0.128564\n",
      "Train Epoch: 3 [7040/10619 (66%)]\tLoss: 0.108510\n",
      "Train Epoch: 3 [7680/10619 (72%)]\tLoss: 0.117619\n",
      "Train Epoch: 3 [8320/10619 (78%)]\tLoss: 0.068691\n",
      "Train Epoch: 3 [8960/10619 (84%)]\tLoss: 0.183535\n",
      "Train Epoch: 3 [9600/10619 (90%)]\tLoss: 0.015231\n",
      "Train Epoch: 3 [10240/10619 (96%)]\tLoss: 0.083842\n",
      "Train Epoch: 4 [0/10619 (0%)]\tLoss: 0.162138\n",
      "Train Epoch: 4 [640/10619 (6%)]\tLoss: 0.024541\n",
      "Train Epoch: 4 [1280/10619 (12%)]\tLoss: 0.163467\n",
      "Train Epoch: 4 [1920/10619 (18%)]\tLoss: 0.090111\n",
      "Train Epoch: 4 [2560/10619 (24%)]\tLoss: 0.098777\n",
      "Train Epoch: 4 [3200/10619 (30%)]\tLoss: 0.066614\n",
      "Train Epoch: 4 [3840/10619 (36%)]\tLoss: 0.050668\n",
      "Train Epoch: 4 [4480/10619 (42%)]\tLoss: 0.050313\n",
      "Train Epoch: 4 [5120/10619 (48%)]\tLoss: 0.007807\n",
      "Train Epoch: 4 [5760/10619 (54%)]\tLoss: 0.118481\n",
      "Train Epoch: 4 [6400/10619 (60%)]\tLoss: 0.034453\n",
      "Train Epoch: 4 [7040/10619 (66%)]\tLoss: 0.020630\n",
      "Train Epoch: 4 [7680/10619 (72%)]\tLoss: 0.041725\n",
      "Train Epoch: 4 [8320/10619 (78%)]\tLoss: 0.056609\n",
      "Train Epoch: 4 [8960/10619 (84%)]\tLoss: 0.192188\n",
      "Train Epoch: 4 [9600/10619 (90%)]\tLoss: 0.034559\n",
      "Train Epoch: 4 [10240/10619 (96%)]\tLoss: 0.055402\n",
      "Train Epoch: 5 [0/10619 (0%)]\tLoss: 0.053988\n",
      "Train Epoch: 5 [640/10619 (6%)]\tLoss: 0.051994\n",
      "Train Epoch: 5 [1280/10619 (12%)]\tLoss: 0.104204\n",
      "Train Epoch: 5 [1920/10619 (18%)]\tLoss: 0.018560\n",
      "Train Epoch: 5 [2560/10619 (24%)]\tLoss: 0.045220\n",
      "Train Epoch: 5 [3200/10619 (30%)]\tLoss: 0.081281\n",
      "Train Epoch: 5 [3840/10619 (36%)]\tLoss: 0.084707\n",
      "Train Epoch: 5 [4480/10619 (42%)]\tLoss: 0.035226\n",
      "Train Epoch: 5 [5120/10619 (48%)]\tLoss: 0.032764\n",
      "Train Epoch: 5 [5760/10619 (54%)]\tLoss: 0.084147\n",
      "Train Epoch: 5 [6400/10619 (60%)]\tLoss: 0.044928\n",
      "Train Epoch: 5 [7040/10619 (66%)]\tLoss: 0.077454\n",
      "Train Epoch: 5 [7680/10619 (72%)]\tLoss: 0.063234\n",
      "Train Epoch: 5 [8320/10619 (78%)]\tLoss: 0.069053\n",
      "Train Epoch: 5 [8960/10619 (84%)]\tLoss: 0.109959\n",
      "Train Epoch: 5 [9600/10619 (90%)]\tLoss: 0.073279\n",
      "Train Epoch: 5 [10240/10619 (96%)]\tLoss: 0.138210\n",
      "Train Epoch: 6 [0/10619 (0%)]\tLoss: 0.022246\n",
      "Train Epoch: 6 [640/10619 (6%)]\tLoss: 0.066653\n",
      "Train Epoch: 6 [1280/10619 (12%)]\tLoss: 0.055663\n",
      "Train Epoch: 6 [1920/10619 (18%)]\tLoss: 0.064801\n",
      "Train Epoch: 6 [2560/10619 (24%)]\tLoss: 0.150533\n",
      "Train Epoch: 6 [3200/10619 (30%)]\tLoss: 0.071464\n",
      "Train Epoch: 6 [3840/10619 (36%)]\tLoss: 0.055098\n",
      "Train Epoch: 6 [4480/10619 (42%)]\tLoss: 0.029124\n",
      "Train Epoch: 6 [5120/10619 (48%)]\tLoss: 0.051371\n",
      "Train Epoch: 6 [5760/10619 (54%)]\tLoss: 0.273817\n",
      "Train Epoch: 6 [6400/10619 (60%)]\tLoss: 0.095389\n",
      "Train Epoch: 6 [7040/10619 (66%)]\tLoss: 0.044712\n",
      "Train Epoch: 6 [7680/10619 (72%)]\tLoss: 0.215025\n",
      "Train Epoch: 6 [8320/10619 (78%)]\tLoss: 0.088907\n",
      "Train Epoch: 6 [8960/10619 (84%)]\tLoss: 0.044993\n",
      "Train Epoch: 6 [9600/10619 (90%)]\tLoss: 0.148887\n",
      "Train Epoch: 6 [10240/10619 (96%)]\tLoss: 0.126990\n",
      "Train Epoch: 7 [0/10619 (0%)]\tLoss: 0.044420\n",
      "Train Epoch: 7 [640/10619 (6%)]\tLoss: 0.165452\n",
      "Train Epoch: 7 [1280/10619 (12%)]\tLoss: 0.060559\n",
      "Train Epoch: 7 [1920/10619 (18%)]\tLoss: 0.031069\n",
      "Train Epoch: 7 [2560/10619 (24%)]\tLoss: 0.047531\n",
      "Train Epoch: 7 [3200/10619 (30%)]\tLoss: 0.040046\n",
      "Train Epoch: 7 [3840/10619 (36%)]\tLoss: 0.022736\n",
      "Train Epoch: 7 [4480/10619 (42%)]\tLoss: 0.268983\n",
      "Train Epoch: 7 [5120/10619 (48%)]\tLoss: 0.019154\n",
      "Train Epoch: 7 [5760/10619 (54%)]\tLoss: 0.103615\n",
      "Train Epoch: 7 [6400/10619 (60%)]\tLoss: 0.107326\n",
      "Train Epoch: 7 [7040/10619 (66%)]\tLoss: 0.093405\n",
      "Train Epoch: 7 [7680/10619 (72%)]\tLoss: 0.121239\n",
      "Train Epoch: 7 [8320/10619 (78%)]\tLoss: 0.065648\n",
      "Train Epoch: 7 [8960/10619 (84%)]\tLoss: 0.082442\n",
      "Train Epoch: 7 [9600/10619 (90%)]\tLoss: 0.035536\n",
      "Train Epoch: 7 [10240/10619 (96%)]\tLoss: 0.115377\n",
      "Train Epoch: 8 [0/10619 (0%)]\tLoss: 0.068654\n",
      "Train Epoch: 8 [640/10619 (6%)]\tLoss: 0.123635\n",
      "Train Epoch: 8 [1280/10619 (12%)]\tLoss: 0.063195\n",
      "Train Epoch: 8 [1920/10619 (18%)]\tLoss: 0.317957\n",
      "Train Epoch: 8 [2560/10619 (24%)]\tLoss: 0.058178\n",
      "Train Epoch: 8 [3200/10619 (30%)]\tLoss: 0.125126\n",
      "Train Epoch: 8 [3840/10619 (36%)]\tLoss: 0.022638\n",
      "Train Epoch: 8 [4480/10619 (42%)]\tLoss: 0.036618\n",
      "Train Epoch: 8 [5120/10619 (48%)]\tLoss: 0.030430\n",
      "Train Epoch: 8 [5760/10619 (54%)]\tLoss: 0.107922\n",
      "Train Epoch: 8 [6400/10619 (60%)]\tLoss: 0.088905\n",
      "Train Epoch: 8 [7040/10619 (66%)]\tLoss: 0.105761\n",
      "Train Epoch: 8 [7680/10619 (72%)]\tLoss: 0.060893\n",
      "Train Epoch: 8 [8320/10619 (78%)]\tLoss: 0.043918\n",
      "Train Epoch: 8 [8960/10619 (84%)]\tLoss: 0.082327\n",
      "Train Epoch: 8 [9600/10619 (90%)]\tLoss: 0.132510\n",
      "Train Epoch: 8 [10240/10619 (96%)]\tLoss: 0.107131\n",
      "Train Epoch: 9 [0/10619 (0%)]\tLoss: 0.154127\n",
      "Train Epoch: 9 [640/10619 (6%)]\tLoss: 0.042105\n",
      "Train Epoch: 9 [1280/10619 (12%)]\tLoss: 0.182926\n",
      "Train Epoch: 9 [1920/10619 (18%)]\tLoss: 0.048527\n",
      "Train Epoch: 9 [2560/10619 (24%)]\tLoss: 0.102528\n",
      "Train Epoch: 9 [3200/10619 (30%)]\tLoss: 0.183184\n",
      "Train Epoch: 9 [3840/10619 (36%)]\tLoss: 0.249481\n",
      "Train Epoch: 9 [4480/10619 (42%)]\tLoss: 0.043419\n",
      "Train Epoch: 9 [5120/10619 (48%)]\tLoss: 0.035220\n",
      "Train Epoch: 9 [5760/10619 (54%)]\tLoss: 0.052109\n",
      "Train Epoch: 9 [6400/10619 (60%)]\tLoss: 0.017101\n",
      "Train Epoch: 9 [7040/10619 (66%)]\tLoss: 0.085381\n",
      "Train Epoch: 9 [7680/10619 (72%)]\tLoss: 0.165857\n",
      "Train Epoch: 9 [8320/10619 (78%)]\tLoss: 0.014988\n",
      "Train Epoch: 9 [8960/10619 (84%)]\tLoss: 0.118288\n",
      "Train Epoch: 9 [9600/10619 (90%)]\tLoss: 0.147446\n",
      "Train Epoch: 9 [10240/10619 (96%)]\tLoss: 0.133759\n",
      "Train Epoch: 10 [0/10619 (0%)]\tLoss: 0.095098\n",
      "Train Epoch: 10 [640/10619 (6%)]\tLoss: 0.206852\n",
      "Train Epoch: 10 [1280/10619 (12%)]\tLoss: 0.065887\n",
      "Train Epoch: 10 [1920/10619 (18%)]\tLoss: 0.134245\n",
      "Train Epoch: 10 [2560/10619 (24%)]\tLoss: 0.094681\n",
      "Train Epoch: 10 [3200/10619 (30%)]\tLoss: 0.138695\n",
      "Train Epoch: 10 [3840/10619 (36%)]\tLoss: 0.018724\n",
      "Train Epoch: 10 [4480/10619 (42%)]\tLoss: 0.064397\n",
      "Train Epoch: 10 [5120/10619 (48%)]\tLoss: 0.008371\n",
      "Train Epoch: 10 [5760/10619 (54%)]\tLoss: 0.330962\n",
      "Train Epoch: 10 [6400/10619 (60%)]\tLoss: 0.067103\n",
      "Train Epoch: 10 [7040/10619 (66%)]\tLoss: 0.093989\n",
      "Train Epoch: 10 [7680/10619 (72%)]\tLoss: 0.035452\n",
      "Train Epoch: 10 [8320/10619 (78%)]\tLoss: 0.086729\n",
      "Train Epoch: 10 [8960/10619 (84%)]\tLoss: 0.012532\n",
      "Train Epoch: 10 [9600/10619 (90%)]\tLoss: 0.016806\n",
      "Train Epoch: 10 [10240/10619 (96%)]\tLoss: 0.050712\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/15392 (0%)]\tLoss: 0.386742\n",
      "Train Epoch: 1 [640/15392 (4%)]\tLoss: 0.331577\n",
      "Train Epoch: 1 [1280/15392 (8%)]\tLoss: 0.163042\n",
      "Train Epoch: 1 [1920/15392 (12%)]\tLoss: 0.155364\n",
      "Train Epoch: 1 [2560/15392 (17%)]\tLoss: 0.098172\n",
      "Train Epoch: 1 [3200/15392 (21%)]\tLoss: 0.182760\n",
      "Train Epoch: 1 [3840/15392 (25%)]\tLoss: 0.052767\n",
      "Train Epoch: 1 [4480/15392 (29%)]\tLoss: 0.053684\n",
      "Train Epoch: 1 [5120/15392 (33%)]\tLoss: 0.109072\n",
      "Train Epoch: 1 [5760/15392 (37%)]\tLoss: 0.063937\n",
      "Train Epoch: 1 [6400/15392 (41%)]\tLoss: 0.089580\n",
      "Train Epoch: 1 [7040/15392 (46%)]\tLoss: 0.055637\n",
      "Train Epoch: 1 [7680/15392 (50%)]\tLoss: 0.091784\n",
      "Train Epoch: 1 [8320/15392 (54%)]\tLoss: 0.045638\n",
      "Train Epoch: 1 [8960/15392 (58%)]\tLoss: 0.040506\n",
      "Train Epoch: 1 [9600/15392 (62%)]\tLoss: 0.052136\n",
      "Train Epoch: 1 [10240/15392 (66%)]\tLoss: 0.036654\n",
      "Train Epoch: 1 [10880/15392 (71%)]\tLoss: 0.048930\n",
      "Train Epoch: 1 [11520/15392 (75%)]\tLoss: 0.027167\n",
      "Train Epoch: 1 [12160/15392 (79%)]\tLoss: 0.088913\n",
      "Train Epoch: 1 [12800/15392 (83%)]\tLoss: 0.080119\n",
      "Train Epoch: 1 [13440/15392 (87%)]\tLoss: 0.074368\n",
      "Train Epoch: 1 [14080/15392 (91%)]\tLoss: 0.017196\n",
      "Train Epoch: 1 [14720/15392 (95%)]\tLoss: 0.064773\n",
      "Train Epoch: 1 [7680/15392 (100%)]\tLoss: 0.038627\n",
      "Train Epoch: 2 [0/15392 (0%)]\tLoss: 0.054753\n",
      "Train Epoch: 2 [640/15392 (4%)]\tLoss: 0.026043\n",
      "Train Epoch: 2 [1280/15392 (8%)]\tLoss: 0.083103\n",
      "Train Epoch: 2 [1920/15392 (12%)]\tLoss: 0.045589\n",
      "Train Epoch: 2 [2560/15392 (17%)]\tLoss: 0.023880\n",
      "Train Epoch: 2 [3200/15392 (21%)]\tLoss: 0.008402\n",
      "Train Epoch: 2 [3840/15392 (25%)]\tLoss: 0.018932\n",
      "Train Epoch: 2 [4480/15392 (29%)]\tLoss: 0.027828\n",
      "Train Epoch: 2 [5120/15392 (33%)]\tLoss: 0.098144\n",
      "Train Epoch: 2 [5760/15392 (37%)]\tLoss: 0.146829\n",
      "Train Epoch: 2 [6400/15392 (41%)]\tLoss: 0.087914\n",
      "Train Epoch: 2 [7040/15392 (46%)]\tLoss: 0.118569\n",
      "Train Epoch: 2 [7680/15392 (50%)]\tLoss: 0.076923\n",
      "Train Epoch: 2 [8320/15392 (54%)]\tLoss: 0.059327\n",
      "Train Epoch: 2 [8960/15392 (58%)]\tLoss: 0.161936\n",
      "Train Epoch: 2 [9600/15392 (62%)]\tLoss: 0.083456\n",
      "Train Epoch: 2 [10240/15392 (66%)]\tLoss: 0.104526\n",
      "Train Epoch: 2 [10880/15392 (71%)]\tLoss: 0.070483\n",
      "Train Epoch: 2 [11520/15392 (75%)]\tLoss: 0.045287\n",
      "Train Epoch: 2 [12160/15392 (79%)]\tLoss: 0.062785\n",
      "Train Epoch: 2 [12800/15392 (83%)]\tLoss: 0.044472\n",
      "Train Epoch: 2 [13440/15392 (87%)]\tLoss: 0.063732\n",
      "Train Epoch: 2 [14080/15392 (91%)]\tLoss: 0.099950\n",
      "Train Epoch: 2 [14720/15392 (95%)]\tLoss: 0.072658\n",
      "Train Epoch: 2 [7680/15392 (100%)]\tLoss: 0.041345\n",
      "Train Epoch: 3 [0/15392 (0%)]\tLoss: 0.043177\n",
      "Train Epoch: 3 [640/15392 (4%)]\tLoss: 0.089152\n",
      "Train Epoch: 3 [1280/15392 (8%)]\tLoss: 0.098290\n",
      "Train Epoch: 3 [1920/15392 (12%)]\tLoss: 0.043994\n",
      "Train Epoch: 3 [2560/15392 (17%)]\tLoss: 0.024721\n",
      "Train Epoch: 3 [3200/15392 (21%)]\tLoss: 0.146218\n",
      "Train Epoch: 3 [3840/15392 (25%)]\tLoss: 0.030306\n",
      "Train Epoch: 3 [4480/15392 (29%)]\tLoss: 0.024651\n",
      "Train Epoch: 3 [5120/15392 (33%)]\tLoss: 0.037961\n",
      "Train Epoch: 3 [5760/15392 (37%)]\tLoss: 0.140278\n",
      "Train Epoch: 3 [6400/15392 (41%)]\tLoss: 0.093510\n",
      "Train Epoch: 3 [7040/15392 (46%)]\tLoss: 0.065242\n",
      "Train Epoch: 3 [7680/15392 (50%)]\tLoss: 0.024584\n",
      "Train Epoch: 3 [8320/15392 (54%)]\tLoss: 0.138186\n",
      "Train Epoch: 3 [8960/15392 (58%)]\tLoss: 0.181837\n",
      "Train Epoch: 3 [9600/15392 (62%)]\tLoss: 0.045921\n",
      "Train Epoch: 3 [10240/15392 (66%)]\tLoss: 0.095430\n",
      "Train Epoch: 3 [10880/15392 (71%)]\tLoss: 0.022335\n",
      "Train Epoch: 3 [11520/15392 (75%)]\tLoss: 0.014438\n",
      "Train Epoch: 3 [12160/15392 (79%)]\tLoss: 0.044711\n",
      "Train Epoch: 3 [12800/15392 (83%)]\tLoss: 0.015566\n",
      "Train Epoch: 3 [13440/15392 (87%)]\tLoss: 0.101615\n",
      "Train Epoch: 3 [14080/15392 (91%)]\tLoss: 0.088082\n",
      "Train Epoch: 3 [14720/15392 (95%)]\tLoss: 0.147399\n",
      "Train Epoch: 3 [7680/15392 (100%)]\tLoss: 0.050030\n",
      "Train Epoch: 4 [0/15392 (0%)]\tLoss: 0.092452\n",
      "Train Epoch: 4 [640/15392 (4%)]\tLoss: 0.162305\n",
      "Train Epoch: 4 [1280/15392 (8%)]\tLoss: 0.027364\n",
      "Train Epoch: 4 [1920/15392 (12%)]\tLoss: 0.029738\n",
      "Train Epoch: 4 [2560/15392 (17%)]\tLoss: 0.148882\n",
      "Train Epoch: 4 [3200/15392 (21%)]\tLoss: 0.054111\n",
      "Train Epoch: 4 [3840/15392 (25%)]\tLoss: 0.074646\n",
      "Train Epoch: 4 [4480/15392 (29%)]\tLoss: 0.044654\n",
      "Train Epoch: 4 [5120/15392 (33%)]\tLoss: 0.167703\n",
      "Train Epoch: 4 [5760/15392 (37%)]\tLoss: 0.015039\n",
      "Train Epoch: 4 [6400/15392 (41%)]\tLoss: 0.090916\n",
      "Train Epoch: 4 [7040/15392 (46%)]\tLoss: 0.124093\n",
      "Train Epoch: 4 [7680/15392 (50%)]\tLoss: 0.109061\n",
      "Train Epoch: 4 [8320/15392 (54%)]\tLoss: 0.080821\n",
      "Train Epoch: 4 [8960/15392 (58%)]\tLoss: 0.087316\n",
      "Train Epoch: 4 [9600/15392 (62%)]\tLoss: 0.060224\n",
      "Train Epoch: 4 [10240/15392 (66%)]\tLoss: 0.036898\n",
      "Train Epoch: 4 [10880/15392 (71%)]\tLoss: 0.070753\n",
      "Train Epoch: 4 [11520/15392 (75%)]\tLoss: 0.070343\n",
      "Train Epoch: 4 [12160/15392 (79%)]\tLoss: 0.108525\n",
      "Train Epoch: 4 [12800/15392 (83%)]\tLoss: 0.303343\n",
      "Train Epoch: 4 [13440/15392 (87%)]\tLoss: 0.021133\n",
      "Train Epoch: 4 [14080/15392 (91%)]\tLoss: 0.057011\n",
      "Train Epoch: 4 [14720/15392 (95%)]\tLoss: 0.048477\n",
      "Train Epoch: 4 [7680/15392 (100%)]\tLoss: 0.289818\n",
      "Train Epoch: 5 [0/15392 (0%)]\tLoss: 0.089246\n",
      "Train Epoch: 5 [640/15392 (4%)]\tLoss: 0.214967\n",
      "Train Epoch: 5 [1280/15392 (8%)]\tLoss: 0.033283\n",
      "Train Epoch: 5 [1920/15392 (12%)]\tLoss: 0.149178\n",
      "Train Epoch: 5 [2560/15392 (17%)]\tLoss: 0.051848\n",
      "Train Epoch: 5 [3200/15392 (21%)]\tLoss: 0.050390\n",
      "Train Epoch: 5 [3840/15392 (25%)]\tLoss: 0.127342\n",
      "Train Epoch: 5 [4480/15392 (29%)]\tLoss: 0.046542\n",
      "Train Epoch: 5 [5120/15392 (33%)]\tLoss: 0.112360\n",
      "Train Epoch: 5 [5760/15392 (37%)]\tLoss: 0.056886\n",
      "Train Epoch: 5 [6400/15392 (41%)]\tLoss: 0.083154\n",
      "Train Epoch: 5 [7040/15392 (46%)]\tLoss: 0.098488\n",
      "Train Epoch: 5 [7680/15392 (50%)]\tLoss: 0.177864\n",
      "Train Epoch: 5 [8320/15392 (54%)]\tLoss: 0.025687\n",
      "Train Epoch: 5 [8960/15392 (58%)]\tLoss: 0.018036\n",
      "Train Epoch: 5 [9600/15392 (62%)]\tLoss: 0.006738\n",
      "Train Epoch: 5 [10240/15392 (66%)]\tLoss: 0.114116\n",
      "Train Epoch: 5 [10880/15392 (71%)]\tLoss: 0.080745\n",
      "Train Epoch: 5 [11520/15392 (75%)]\tLoss: 0.044076\n",
      "Train Epoch: 5 [12160/15392 (79%)]\tLoss: 0.044588\n",
      "Train Epoch: 5 [12800/15392 (83%)]\tLoss: 0.101118\n",
      "Train Epoch: 5 [13440/15392 (87%)]\tLoss: 0.058088\n",
      "Train Epoch: 5 [14080/15392 (91%)]\tLoss: 0.014320\n",
      "Train Epoch: 5 [14720/15392 (95%)]\tLoss: 0.144457\n",
      "Train Epoch: 5 [7680/15392 (100%)]\tLoss: 0.059169\n",
      "Train Epoch: 6 [0/15392 (0%)]\tLoss: 0.033692\n",
      "Train Epoch: 6 [640/15392 (4%)]\tLoss: 0.018670\n",
      "Train Epoch: 6 [1280/15392 (8%)]\tLoss: 0.021800\n",
      "Train Epoch: 6 [1920/15392 (12%)]\tLoss: 0.078991\n",
      "Train Epoch: 6 [2560/15392 (17%)]\tLoss: 0.065322\n",
      "Train Epoch: 6 [3200/15392 (21%)]\tLoss: 0.140108\n",
      "Train Epoch: 6 [3840/15392 (25%)]\tLoss: 0.105383\n",
      "Train Epoch: 6 [4480/15392 (29%)]\tLoss: 0.030454\n",
      "Train Epoch: 6 [5120/15392 (33%)]\tLoss: 0.052549\n",
      "Train Epoch: 6 [5760/15392 (37%)]\tLoss: 0.055643\n",
      "Train Epoch: 6 [6400/15392 (41%)]\tLoss: 0.057939\n",
      "Train Epoch: 6 [7040/15392 (46%)]\tLoss: 0.086984\n",
      "Train Epoch: 6 [7680/15392 (50%)]\tLoss: 0.049242\n",
      "Train Epoch: 6 [8320/15392 (54%)]\tLoss: 0.036504\n",
      "Train Epoch: 6 [8960/15392 (58%)]\tLoss: 0.074197\n",
      "Train Epoch: 6 [9600/15392 (62%)]\tLoss: 0.085024\n",
      "Train Epoch: 6 [10240/15392 (66%)]\tLoss: 0.192188\n",
      "Train Epoch: 6 [10880/15392 (71%)]\tLoss: 0.086456\n",
      "Train Epoch: 6 [11520/15392 (75%)]\tLoss: 0.104324\n",
      "Train Epoch: 6 [12160/15392 (79%)]\tLoss: 0.244271\n",
      "Train Epoch: 6 [12800/15392 (83%)]\tLoss: 0.157888\n",
      "Train Epoch: 6 [13440/15392 (87%)]\tLoss: 0.107697\n",
      "Train Epoch: 6 [14080/15392 (91%)]\tLoss: 0.041537\n",
      "Train Epoch: 6 [14720/15392 (95%)]\tLoss: 0.011086\n",
      "Train Epoch: 6 [7680/15392 (100%)]\tLoss: 0.226019\n",
      "Train Epoch: 7 [0/15392 (0%)]\tLoss: 0.018730\n",
      "Train Epoch: 7 [640/15392 (4%)]\tLoss: 0.049943\n",
      "Train Epoch: 7 [1280/15392 (8%)]\tLoss: 0.104613\n",
      "Train Epoch: 7 [1920/15392 (12%)]\tLoss: 0.043097\n",
      "Train Epoch: 7 [2560/15392 (17%)]\tLoss: 0.272478\n",
      "Train Epoch: 7 [3200/15392 (21%)]\tLoss: 0.099305\n",
      "Train Epoch: 7 [3840/15392 (25%)]\tLoss: 0.167731\n",
      "Train Epoch: 7 [4480/15392 (29%)]\tLoss: 0.071063\n",
      "Train Epoch: 7 [5120/15392 (33%)]\tLoss: 0.073603\n",
      "Train Epoch: 7 [5760/15392 (37%)]\tLoss: 0.117052\n",
      "Train Epoch: 7 [6400/15392 (41%)]\tLoss: 0.076130\n",
      "Train Epoch: 7 [7040/15392 (46%)]\tLoss: 0.023024\n",
      "Train Epoch: 7 [7680/15392 (50%)]\tLoss: 0.018201\n",
      "Train Epoch: 7 [8320/15392 (54%)]\tLoss: 0.106288\n",
      "Train Epoch: 7 [8960/15392 (58%)]\tLoss: 0.052204\n",
      "Train Epoch: 7 [9600/15392 (62%)]\tLoss: 0.061026\n",
      "Train Epoch: 7 [10240/15392 (66%)]\tLoss: 0.018005\n",
      "Train Epoch: 7 [10880/15392 (71%)]\tLoss: 0.024149\n",
      "Train Epoch: 7 [11520/15392 (75%)]\tLoss: 0.098536\n",
      "Train Epoch: 7 [12160/15392 (79%)]\tLoss: 0.128111\n",
      "Train Epoch: 7 [12800/15392 (83%)]\tLoss: 0.056639\n",
      "Train Epoch: 7 [13440/15392 (87%)]\tLoss: 0.273327\n",
      "Train Epoch: 7 [14080/15392 (91%)]\tLoss: 0.116207\n",
      "Train Epoch: 7 [14720/15392 (95%)]\tLoss: 0.079928\n",
      "Train Epoch: 7 [7680/15392 (100%)]\tLoss: 0.066452\n",
      "Train Epoch: 8 [0/15392 (0%)]\tLoss: 0.095676\n",
      "Train Epoch: 8 [640/15392 (4%)]\tLoss: 0.023644\n",
      "Train Epoch: 8 [1280/15392 (8%)]\tLoss: 0.079715\n",
      "Train Epoch: 8 [1920/15392 (12%)]\tLoss: 0.036371\n",
      "Train Epoch: 8 [2560/15392 (17%)]\tLoss: 0.038463\n",
      "Train Epoch: 8 [3200/15392 (21%)]\tLoss: 0.067143\n",
      "Train Epoch: 8 [3840/15392 (25%)]\tLoss: 0.009350\n",
      "Train Epoch: 8 [4480/15392 (29%)]\tLoss: 0.082163\n",
      "Train Epoch: 8 [5120/15392 (33%)]\tLoss: 0.139403\n",
      "Train Epoch: 8 [5760/15392 (37%)]\tLoss: 0.148997\n",
      "Train Epoch: 8 [6400/15392 (41%)]\tLoss: 0.118869\n",
      "Train Epoch: 8 [7040/15392 (46%)]\tLoss: 0.067877\n",
      "Train Epoch: 8 [7680/15392 (50%)]\tLoss: 0.195354\n",
      "Train Epoch: 8 [8320/15392 (54%)]\tLoss: 0.049621\n",
      "Train Epoch: 8 [8960/15392 (58%)]\tLoss: 0.134560\n",
      "Train Epoch: 8 [9600/15392 (62%)]\tLoss: 0.102591\n",
      "Train Epoch: 8 [10240/15392 (66%)]\tLoss: 0.143780\n",
      "Train Epoch: 8 [10880/15392 (71%)]\tLoss: 0.010800\n",
      "Train Epoch: 8 [11520/15392 (75%)]\tLoss: 0.033986\n",
      "Train Epoch: 8 [12160/15392 (79%)]\tLoss: 0.065507\n",
      "Train Epoch: 8 [12800/15392 (83%)]\tLoss: 0.042798\n",
      "Train Epoch: 8 [13440/15392 (87%)]\tLoss: 0.028142\n",
      "Train Epoch: 8 [14080/15392 (91%)]\tLoss: 0.029666\n",
      "Train Epoch: 8 [14720/15392 (95%)]\tLoss: 0.117704\n",
      "Train Epoch: 8 [7680/15392 (100%)]\tLoss: 0.127145\n",
      "Train Epoch: 9 [0/15392 (0%)]\tLoss: 0.030893\n",
      "Train Epoch: 9 [640/15392 (4%)]\tLoss: 0.020542\n",
      "Train Epoch: 9 [1280/15392 (8%)]\tLoss: 0.101684\n",
      "Train Epoch: 9 [1920/15392 (12%)]\tLoss: 0.045636\n",
      "Train Epoch: 9 [2560/15392 (17%)]\tLoss: 0.073415\n",
      "Train Epoch: 9 [3200/15392 (21%)]\tLoss: 0.066994\n",
      "Train Epoch: 9 [3840/15392 (25%)]\tLoss: 0.097210\n",
      "Train Epoch: 9 [4480/15392 (29%)]\tLoss: 0.024043\n",
      "Train Epoch: 9 [5120/15392 (33%)]\tLoss: 0.132544\n",
      "Train Epoch: 9 [5760/15392 (37%)]\tLoss: 0.030681\n",
      "Train Epoch: 9 [6400/15392 (41%)]\tLoss: 0.009683\n",
      "Train Epoch: 9 [7040/15392 (46%)]\tLoss: 0.079966\n",
      "Train Epoch: 9 [7680/15392 (50%)]\tLoss: 0.018787\n",
      "Train Epoch: 9 [8320/15392 (54%)]\tLoss: 0.012068\n",
      "Train Epoch: 9 [8960/15392 (58%)]\tLoss: 0.082196\n",
      "Train Epoch: 9 [9600/15392 (62%)]\tLoss: 0.045462\n",
      "Train Epoch: 9 [10240/15392 (66%)]\tLoss: 0.079219\n",
      "Train Epoch: 9 [10880/15392 (71%)]\tLoss: 0.143025\n",
      "Train Epoch: 9 [11520/15392 (75%)]\tLoss: 0.130611\n",
      "Train Epoch: 9 [12160/15392 (79%)]\tLoss: 0.115350\n",
      "Train Epoch: 9 [12800/15392 (83%)]\tLoss: 0.055156\n",
      "Train Epoch: 9 [13440/15392 (87%)]\tLoss: 0.037719\n",
      "Train Epoch: 9 [14080/15392 (91%)]\tLoss: 0.029807\n",
      "Train Epoch: 9 [14720/15392 (95%)]\tLoss: 0.195760\n",
      "Train Epoch: 9 [7680/15392 (100%)]\tLoss: 0.005919\n",
      "Train Epoch: 10 [0/15392 (0%)]\tLoss: 0.031193\n",
      "Train Epoch: 10 [640/15392 (4%)]\tLoss: 0.065650\n",
      "Train Epoch: 10 [1280/15392 (8%)]\tLoss: 0.069211\n",
      "Train Epoch: 10 [1920/15392 (12%)]\tLoss: 0.039313\n",
      "Train Epoch: 10 [2560/15392 (17%)]\tLoss: 0.063573\n",
      "Train Epoch: 10 [3200/15392 (21%)]\tLoss: 0.058655\n",
      "Train Epoch: 10 [3840/15392 (25%)]\tLoss: 0.028589\n",
      "Train Epoch: 10 [4480/15392 (29%)]\tLoss: 0.005474\n",
      "Train Epoch: 10 [5120/15392 (33%)]\tLoss: 0.194899\n",
      "Train Epoch: 10 [5760/15392 (37%)]\tLoss: 0.040368\n",
      "Train Epoch: 10 [6400/15392 (41%)]\tLoss: 0.074012\n",
      "Train Epoch: 10 [7040/15392 (46%)]\tLoss: 0.025203\n",
      "Train Epoch: 10 [7680/15392 (50%)]\tLoss: 0.055453\n",
      "Train Epoch: 10 [8320/15392 (54%)]\tLoss: 0.060833\n",
      "Train Epoch: 10 [8960/15392 (58%)]\tLoss: 0.039045\n",
      "Train Epoch: 10 [9600/15392 (62%)]\tLoss: 0.027230\n",
      "Train Epoch: 10 [10240/15392 (66%)]\tLoss: 0.053719\n",
      "Train Epoch: 10 [10880/15392 (71%)]\tLoss: 0.098688\n",
      "Train Epoch: 10 [11520/15392 (75%)]\tLoss: 0.065939\n",
      "Train Epoch: 10 [12160/15392 (79%)]\tLoss: 0.053135\n",
      "Train Epoch: 10 [12800/15392 (83%)]\tLoss: 0.113498\n",
      "Train Epoch: 10 [13440/15392 (87%)]\tLoss: 0.081222\n",
      "Train Epoch: 10 [14080/15392 (91%)]\tLoss: 0.031275\n",
      "Train Epoch: 10 [14720/15392 (95%)]\tLoss: 0.079350\n",
      "Train Epoch: 10 [7680/15392 (100%)]\tLoss: 0.039693\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/15327 (0%)]\tLoss: 0.086128\n",
      "Train Epoch: 1 [640/15327 (4%)]\tLoss: 0.028117\n",
      "Train Epoch: 1 [1280/15327 (8%)]\tLoss: 0.082269\n",
      "Train Epoch: 1 [1920/15327 (12%)]\tLoss: 0.137065\n",
      "Train Epoch: 1 [2560/15327 (17%)]\tLoss: 0.295669\n",
      "Train Epoch: 1 [3200/15327 (21%)]\tLoss: 0.095499\n",
      "Train Epoch: 1 [3840/15327 (25%)]\tLoss: 0.104435\n",
      "Train Epoch: 1 [4480/15327 (29%)]\tLoss: 0.107138\n",
      "Train Epoch: 1 [5120/15327 (33%)]\tLoss: 0.333933\n",
      "Train Epoch: 1 [5760/15327 (38%)]\tLoss: 0.018908\n",
      "Train Epoch: 1 [6400/15327 (42%)]\tLoss: 0.165754\n",
      "Train Epoch: 1 [7040/15327 (46%)]\tLoss: 0.037201\n",
      "Train Epoch: 1 [7680/15327 (50%)]\tLoss: 0.040624\n",
      "Train Epoch: 1 [8320/15327 (54%)]\tLoss: 0.152156\n",
      "Train Epoch: 1 [8960/15327 (58%)]\tLoss: 0.081957\n",
      "Train Epoch: 1 [9600/15327 (62%)]\tLoss: 0.077520\n",
      "Train Epoch: 1 [10240/15327 (67%)]\tLoss: 0.118640\n",
      "Train Epoch: 1 [10880/15327 (71%)]\tLoss: 0.065638\n",
      "Train Epoch: 1 [11520/15327 (75%)]\tLoss: 0.136714\n",
      "Train Epoch: 1 [12160/15327 (79%)]\tLoss: 0.145976\n",
      "Train Epoch: 1 [12800/15327 (83%)]\tLoss: 0.095403\n",
      "Train Epoch: 1 [13440/15327 (88%)]\tLoss: 0.105576\n",
      "Train Epoch: 1 [14080/15327 (92%)]\tLoss: 0.076148\n",
      "Train Epoch: 1 [14720/15327 (96%)]\tLoss: 0.052239\n",
      "Train Epoch: 2 [0/15327 (0%)]\tLoss: 0.208530\n",
      "Train Epoch: 2 [640/15327 (4%)]\tLoss: 0.116863\n",
      "Train Epoch: 2 [1280/15327 (8%)]\tLoss: 0.033851\n",
      "Train Epoch: 2 [1920/15327 (12%)]\tLoss: 0.039345\n",
      "Train Epoch: 2 [2560/15327 (17%)]\tLoss: 0.126821\n",
      "Train Epoch: 2 [3200/15327 (21%)]\tLoss: 0.077512\n",
      "Train Epoch: 2 [3840/15327 (25%)]\tLoss: 0.095834\n",
      "Train Epoch: 2 [4480/15327 (29%)]\tLoss: 0.117116\n",
      "Train Epoch: 2 [5120/15327 (33%)]\tLoss: 0.049840\n",
      "Train Epoch: 2 [5760/15327 (38%)]\tLoss: 0.096968\n",
      "Train Epoch: 2 [6400/15327 (42%)]\tLoss: 0.105203\n",
      "Train Epoch: 2 [7040/15327 (46%)]\tLoss: 0.085445\n",
      "Train Epoch: 2 [7680/15327 (50%)]\tLoss: 0.061960\n",
      "Train Epoch: 2 [8320/15327 (54%)]\tLoss: 0.053723\n",
      "Train Epoch: 2 [8960/15327 (58%)]\tLoss: 0.182986\n",
      "Train Epoch: 2 [9600/15327 (62%)]\tLoss: 0.096414\n",
      "Train Epoch: 2 [10240/15327 (67%)]\tLoss: 0.204521\n",
      "Train Epoch: 2 [10880/15327 (71%)]\tLoss: 0.197858\n",
      "Train Epoch: 2 [11520/15327 (75%)]\tLoss: 0.139565\n",
      "Train Epoch: 2 [12160/15327 (79%)]\tLoss: 0.175651\n",
      "Train Epoch: 2 [12800/15327 (83%)]\tLoss: 0.061153\n",
      "Train Epoch: 2 [13440/15327 (88%)]\tLoss: 0.016967\n",
      "Train Epoch: 2 [14080/15327 (92%)]\tLoss: 0.024561\n",
      "Train Epoch: 2 [14720/15327 (96%)]\tLoss: 0.109029\n",
      "Train Epoch: 3 [0/15327 (0%)]\tLoss: 0.073072\n",
      "Train Epoch: 3 [640/15327 (4%)]\tLoss: 0.069213\n",
      "Train Epoch: 3 [1280/15327 (8%)]\tLoss: 0.060951\n",
      "Train Epoch: 3 [1920/15327 (12%)]\tLoss: 0.133900\n",
      "Train Epoch: 3 [2560/15327 (17%)]\tLoss: 0.048760\n",
      "Train Epoch: 3 [3200/15327 (21%)]\tLoss: 0.076708\n",
      "Train Epoch: 3 [3840/15327 (25%)]\tLoss: 0.190584\n",
      "Train Epoch: 3 [4480/15327 (29%)]\tLoss: 0.174536\n",
      "Train Epoch: 3 [5120/15327 (33%)]\tLoss: 0.094451\n",
      "Train Epoch: 3 [5760/15327 (38%)]\tLoss: 0.056490\n",
      "Train Epoch: 3 [6400/15327 (42%)]\tLoss: 0.163103\n",
      "Train Epoch: 3 [7040/15327 (46%)]\tLoss: 0.072449\n",
      "Train Epoch: 3 [7680/15327 (50%)]\tLoss: 0.072855\n",
      "Train Epoch: 3 [8320/15327 (54%)]\tLoss: 0.078762\n",
      "Train Epoch: 3 [8960/15327 (58%)]\tLoss: 0.051648\n",
      "Train Epoch: 3 [9600/15327 (62%)]\tLoss: 0.096521\n",
      "Train Epoch: 3 [10240/15327 (67%)]\tLoss: 0.049231\n",
      "Train Epoch: 3 [10880/15327 (71%)]\tLoss: 0.054348\n",
      "Train Epoch: 3 [11520/15327 (75%)]\tLoss: 0.098811\n",
      "Train Epoch: 3 [12160/15327 (79%)]\tLoss: 0.145391\n",
      "Train Epoch: 3 [12800/15327 (83%)]\tLoss: 0.075158\n",
      "Train Epoch: 3 [13440/15327 (88%)]\tLoss: 0.251609\n",
      "Train Epoch: 3 [14080/15327 (92%)]\tLoss: 0.154194\n",
      "Train Epoch: 3 [14720/15327 (96%)]\tLoss: 0.043382\n",
      "Train Epoch: 4 [0/15327 (0%)]\tLoss: 0.050298\n",
      "Train Epoch: 4 [640/15327 (4%)]\tLoss: 0.007469\n",
      "Train Epoch: 4 [1280/15327 (8%)]\tLoss: 0.040096\n",
      "Train Epoch: 4 [1920/15327 (12%)]\tLoss: 0.017368\n",
      "Train Epoch: 4 [2560/15327 (17%)]\tLoss: 0.036495\n",
      "Train Epoch: 4 [3200/15327 (21%)]\tLoss: 0.008580\n",
      "Train Epoch: 4 [3840/15327 (25%)]\tLoss: 0.058020\n",
      "Train Epoch: 4 [4480/15327 (29%)]\tLoss: 0.065527\n",
      "Train Epoch: 4 [5120/15327 (33%)]\tLoss: 0.101146\n",
      "Train Epoch: 4 [5760/15327 (38%)]\tLoss: 0.041973\n",
      "Train Epoch: 4 [6400/15327 (42%)]\tLoss: 0.039907\n",
      "Train Epoch: 4 [7040/15327 (46%)]\tLoss: 0.035539\n",
      "Train Epoch: 4 [7680/15327 (50%)]\tLoss: 0.078867\n",
      "Train Epoch: 4 [8320/15327 (54%)]\tLoss: 0.125659\n",
      "Train Epoch: 4 [8960/15327 (58%)]\tLoss: 0.102577\n",
      "Train Epoch: 4 [9600/15327 (62%)]\tLoss: 0.267481\n",
      "Train Epoch: 4 [10240/15327 (67%)]\tLoss: 0.125721\n",
      "Train Epoch: 4 [10880/15327 (71%)]\tLoss: 0.174374\n",
      "Train Epoch: 4 [11520/15327 (75%)]\tLoss: 0.110429\n",
      "Train Epoch: 4 [12160/15327 (79%)]\tLoss: 0.173248\n",
      "Train Epoch: 4 [12800/15327 (83%)]\tLoss: 0.046877\n",
      "Train Epoch: 4 [13440/15327 (88%)]\tLoss: 0.036299\n",
      "Train Epoch: 4 [14080/15327 (92%)]\tLoss: 0.116379\n",
      "Train Epoch: 4 [14720/15327 (96%)]\tLoss: 0.147077\n",
      "Train Epoch: 5 [0/15327 (0%)]\tLoss: 0.101301\n",
      "Train Epoch: 5 [640/15327 (4%)]\tLoss: 0.106407\n",
      "Train Epoch: 5 [1280/15327 (8%)]\tLoss: 0.174145\n",
      "Train Epoch: 5 [1920/15327 (12%)]\tLoss: 0.108222\n",
      "Train Epoch: 5 [2560/15327 (17%)]\tLoss: 0.096219\n",
      "Train Epoch: 5 [3200/15327 (21%)]\tLoss: 0.013744\n",
      "Train Epoch: 5 [3840/15327 (25%)]\tLoss: 0.015603\n",
      "Train Epoch: 5 [4480/15327 (29%)]\tLoss: 0.053735\n",
      "Train Epoch: 5 [5120/15327 (33%)]\tLoss: 0.200564\n",
      "Train Epoch: 5 [5760/15327 (38%)]\tLoss: 0.041404\n",
      "Train Epoch: 5 [6400/15327 (42%)]\tLoss: 0.179934\n",
      "Train Epoch: 5 [7040/15327 (46%)]\tLoss: 0.057083\n",
      "Train Epoch: 5 [7680/15327 (50%)]\tLoss: 0.151073\n",
      "Train Epoch: 5 [8320/15327 (54%)]\tLoss: 0.104575\n",
      "Train Epoch: 5 [8960/15327 (58%)]\tLoss: 0.095693\n",
      "Train Epoch: 5 [9600/15327 (62%)]\tLoss: 0.065606\n",
      "Train Epoch: 5 [10240/15327 (67%)]\tLoss: 0.097109\n",
      "Train Epoch: 5 [10880/15327 (71%)]\tLoss: 0.071010\n",
      "Train Epoch: 5 [11520/15327 (75%)]\tLoss: 0.047165\n",
      "Train Epoch: 5 [12160/15327 (79%)]\tLoss: 0.036279\n",
      "Train Epoch: 5 [12800/15327 (83%)]\tLoss: 0.118405\n",
      "Train Epoch: 5 [13440/15327 (88%)]\tLoss: 0.039220\n",
      "Train Epoch: 5 [14080/15327 (92%)]\tLoss: 0.289721\n",
      "Train Epoch: 5 [14720/15327 (96%)]\tLoss: 0.087947\n",
      "Train Epoch: 6 [0/15327 (0%)]\tLoss: 0.215097\n",
      "Train Epoch: 6 [640/15327 (4%)]\tLoss: 0.029743\n",
      "Train Epoch: 6 [1280/15327 (8%)]\tLoss: 0.332019\n",
      "Train Epoch: 6 [1920/15327 (12%)]\tLoss: 0.332541\n",
      "Train Epoch: 6 [2560/15327 (17%)]\tLoss: 0.098957\n",
      "Train Epoch: 6 [3200/15327 (21%)]\tLoss: 0.083699\n",
      "Train Epoch: 6 [3840/15327 (25%)]\tLoss: 0.071357\n",
      "Train Epoch: 6 [4480/15327 (29%)]\tLoss: 0.097175\n",
      "Train Epoch: 6 [5120/15327 (33%)]\tLoss: 0.032136\n",
      "Train Epoch: 6 [5760/15327 (38%)]\tLoss: 0.113150\n",
      "Train Epoch: 6 [6400/15327 (42%)]\tLoss: 0.047756\n",
      "Train Epoch: 6 [7040/15327 (46%)]\tLoss: 0.072836\n",
      "Train Epoch: 6 [7680/15327 (50%)]\tLoss: 0.043128\n",
      "Train Epoch: 6 [8320/15327 (54%)]\tLoss: 0.159343\n",
      "Train Epoch: 6 [8960/15327 (58%)]\tLoss: 0.048652\n",
      "Train Epoch: 6 [9600/15327 (62%)]\tLoss: 0.054137\n",
      "Train Epoch: 6 [10240/15327 (67%)]\tLoss: 0.042927\n",
      "Train Epoch: 6 [10880/15327 (71%)]\tLoss: 0.281019\n",
      "Train Epoch: 6 [11520/15327 (75%)]\tLoss: 0.071532\n",
      "Train Epoch: 6 [12160/15327 (79%)]\tLoss: 0.017174\n",
      "Train Epoch: 6 [12800/15327 (83%)]\tLoss: 0.033516\n",
      "Train Epoch: 6 [13440/15327 (88%)]\tLoss: 0.066707\n",
      "Train Epoch: 6 [14080/15327 (92%)]\tLoss: 0.019844\n",
      "Train Epoch: 6 [14720/15327 (96%)]\tLoss: 0.093621\n",
      "Train Epoch: 7 [0/15327 (0%)]\tLoss: 0.106423\n",
      "Train Epoch: 7 [640/15327 (4%)]\tLoss: 0.056372\n",
      "Train Epoch: 7 [1280/15327 (8%)]\tLoss: 0.081817\n",
      "Train Epoch: 7 [1920/15327 (12%)]\tLoss: 0.260373\n",
      "Train Epoch: 7 [2560/15327 (17%)]\tLoss: 0.021803\n",
      "Train Epoch: 7 [3200/15327 (21%)]\tLoss: 0.045294\n",
      "Train Epoch: 7 [3840/15327 (25%)]\tLoss: 0.126655\n",
      "Train Epoch: 7 [4480/15327 (29%)]\tLoss: 0.297143\n",
      "Train Epoch: 7 [5120/15327 (33%)]\tLoss: 0.031858\n",
      "Train Epoch: 7 [5760/15327 (38%)]\tLoss: 0.143432\n",
      "Train Epoch: 7 [6400/15327 (42%)]\tLoss: 0.046883\n",
      "Train Epoch: 7 [7040/15327 (46%)]\tLoss: 0.076686\n",
      "Train Epoch: 7 [7680/15327 (50%)]\tLoss: 0.111240\n",
      "Train Epoch: 7 [8320/15327 (54%)]\tLoss: 0.232181\n",
      "Train Epoch: 7 [8960/15327 (58%)]\tLoss: 0.023919\n",
      "Train Epoch: 7 [9600/15327 (62%)]\tLoss: 0.022094\n",
      "Train Epoch: 7 [10240/15327 (67%)]\tLoss: 0.080969\n",
      "Train Epoch: 7 [10880/15327 (71%)]\tLoss: 0.017959\n",
      "Train Epoch: 7 [11520/15327 (75%)]\tLoss: 0.021328\n",
      "Train Epoch: 7 [12160/15327 (79%)]\tLoss: 0.045074\n",
      "Train Epoch: 7 [12800/15327 (83%)]\tLoss: 0.051142\n",
      "Train Epoch: 7 [13440/15327 (88%)]\tLoss: 0.058292\n",
      "Train Epoch: 7 [14080/15327 (92%)]\tLoss: 0.108117\n",
      "Train Epoch: 7 [14720/15327 (96%)]\tLoss: 0.024969\n",
      "Train Epoch: 8 [0/15327 (0%)]\tLoss: 0.110947\n",
      "Train Epoch: 8 [640/15327 (4%)]\tLoss: 0.135025\n",
      "Train Epoch: 8 [1280/15327 (8%)]\tLoss: 0.019731\n",
      "Train Epoch: 8 [1920/15327 (12%)]\tLoss: 0.042405\n",
      "Train Epoch: 8 [2560/15327 (17%)]\tLoss: 0.036647\n",
      "Train Epoch: 8 [3200/15327 (21%)]\tLoss: 0.030665\n",
      "Train Epoch: 8 [3840/15327 (25%)]\tLoss: 0.137000\n",
      "Train Epoch: 8 [4480/15327 (29%)]\tLoss: 0.089552\n",
      "Train Epoch: 8 [5120/15327 (33%)]\tLoss: 0.027507\n",
      "Train Epoch: 8 [5760/15327 (38%)]\tLoss: 0.070100\n",
      "Train Epoch: 8 [6400/15327 (42%)]\tLoss: 0.107267\n",
      "Train Epoch: 8 [7040/15327 (46%)]\tLoss: 0.076379\n",
      "Train Epoch: 8 [7680/15327 (50%)]\tLoss: 0.077458\n",
      "Train Epoch: 8 [8320/15327 (54%)]\tLoss: 0.050715\n",
      "Train Epoch: 8 [8960/15327 (58%)]\tLoss: 0.399989\n",
      "Train Epoch: 8 [9600/15327 (62%)]\tLoss: 0.181375\n",
      "Train Epoch: 8 [10240/15327 (67%)]\tLoss: 0.317259\n",
      "Train Epoch: 8 [10880/15327 (71%)]\tLoss: 0.043462\n",
      "Train Epoch: 8 [11520/15327 (75%)]\tLoss: 0.377315\n",
      "Train Epoch: 8 [12160/15327 (79%)]\tLoss: 0.022452\n",
      "Train Epoch: 8 [12800/15327 (83%)]\tLoss: 0.107281\n",
      "Train Epoch: 8 [13440/15327 (88%)]\tLoss: 0.042653\n",
      "Train Epoch: 8 [14080/15327 (92%)]\tLoss: 0.082196\n",
      "Train Epoch: 8 [14720/15327 (96%)]\tLoss: 0.052963\n",
      "Train Epoch: 9 [0/15327 (0%)]\tLoss: 0.030174\n",
      "Train Epoch: 9 [640/15327 (4%)]\tLoss: 0.203796\n",
      "Train Epoch: 9 [1280/15327 (8%)]\tLoss: 0.049544\n",
      "Train Epoch: 9 [1920/15327 (12%)]\tLoss: 0.087990\n",
      "Train Epoch: 9 [2560/15327 (17%)]\tLoss: 0.087781\n",
      "Train Epoch: 9 [3200/15327 (21%)]\tLoss: 0.078218\n",
      "Train Epoch: 9 [3840/15327 (25%)]\tLoss: 0.053610\n",
      "Train Epoch: 9 [4480/15327 (29%)]\tLoss: 0.313917\n",
      "Train Epoch: 9 [5120/15327 (33%)]\tLoss: 0.118469\n",
      "Train Epoch: 9 [5760/15327 (38%)]\tLoss: 0.032346\n",
      "Train Epoch: 9 [6400/15327 (42%)]\tLoss: 0.033252\n",
      "Train Epoch: 9 [7040/15327 (46%)]\tLoss: 0.097661\n",
      "Train Epoch: 9 [7680/15327 (50%)]\tLoss: 0.082032\n",
      "Train Epoch: 9 [8320/15327 (54%)]\tLoss: 0.085415\n",
      "Train Epoch: 9 [8960/15327 (58%)]\tLoss: 0.044723\n",
      "Train Epoch: 9 [9600/15327 (62%)]\tLoss: 0.143044\n",
      "Train Epoch: 9 [10240/15327 (67%)]\tLoss: 0.120769\n",
      "Train Epoch: 9 [10880/15327 (71%)]\tLoss: 0.120687\n",
      "Train Epoch: 9 [11520/15327 (75%)]\tLoss: 0.058550\n",
      "Train Epoch: 9 [12160/15327 (79%)]\tLoss: 0.152778\n",
      "Train Epoch: 9 [12800/15327 (83%)]\tLoss: 0.066313\n",
      "Train Epoch: 9 [13440/15327 (88%)]\tLoss: 0.043212\n",
      "Train Epoch: 9 [14080/15327 (92%)]\tLoss: 0.181733\n",
      "Train Epoch: 9 [14720/15327 (96%)]\tLoss: 0.174860\n",
      "Train Epoch: 10 [0/15327 (0%)]\tLoss: 0.034758\n",
      "Train Epoch: 10 [640/15327 (4%)]\tLoss: 0.074194\n",
      "Train Epoch: 10 [1280/15327 (8%)]\tLoss: 0.015941\n",
      "Train Epoch: 10 [1920/15327 (12%)]\tLoss: 0.056757\n",
      "Train Epoch: 10 [2560/15327 (17%)]\tLoss: 0.033013\n",
      "Train Epoch: 10 [3200/15327 (21%)]\tLoss: 0.120569\n",
      "Train Epoch: 10 [3840/15327 (25%)]\tLoss: 0.080379\n",
      "Train Epoch: 10 [4480/15327 (29%)]\tLoss: 0.134029\n",
      "Train Epoch: 10 [5120/15327 (33%)]\tLoss: 0.362052\n",
      "Train Epoch: 10 [5760/15327 (38%)]\tLoss: 0.078721\n",
      "Train Epoch: 10 [6400/15327 (42%)]\tLoss: 0.071177\n",
      "Train Epoch: 10 [7040/15327 (46%)]\tLoss: 0.052491\n",
      "Train Epoch: 10 [7680/15327 (50%)]\tLoss: 0.079319\n",
      "Train Epoch: 10 [8320/15327 (54%)]\tLoss: 0.018669\n",
      "Train Epoch: 10 [8960/15327 (58%)]\tLoss: 0.084042\n",
      "Train Epoch: 10 [9600/15327 (62%)]\tLoss: 0.050574\n",
      "Train Epoch: 10 [10240/15327 (67%)]\tLoss: 0.040152\n",
      "Train Epoch: 10 [10880/15327 (71%)]\tLoss: 0.121467\n",
      "Train Epoch: 10 [11520/15327 (75%)]\tLoss: 0.064487\n",
      "Train Epoch: 10 [12160/15327 (79%)]\tLoss: 0.070147\n",
      "Train Epoch: 10 [12800/15327 (83%)]\tLoss: 0.206459\n",
      "Train Epoch: 10 [13440/15327 (88%)]\tLoss: 0.328672\n",
      "Train Epoch: 10 [14080/15327 (92%)]\tLoss: 0.046563\n",
      "Train Epoch: 10 [14720/15327 (96%)]\tLoss: 0.013968\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0584, Accuracy: 9812/10000 (98%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/18662 (0%)]\tLoss: 0.149737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [640/18662 (3%)]\tLoss: 0.139703\n",
      "Train Epoch: 1 [1280/18662 (7%)]\tLoss: 0.042328\n",
      "Train Epoch: 1 [1920/18662 (10%)]\tLoss: 0.031729\n",
      "Train Epoch: 1 [2560/18662 (14%)]\tLoss: 0.023443\n",
      "Train Epoch: 1 [3200/18662 (17%)]\tLoss: 0.085479\n",
      "Train Epoch: 1 [3840/18662 (21%)]\tLoss: 0.062794\n",
      "Train Epoch: 1 [4480/18662 (24%)]\tLoss: 0.126265\n",
      "Train Epoch: 1 [5120/18662 (27%)]\tLoss: 0.088497\n",
      "Train Epoch: 1 [5760/18662 (31%)]\tLoss: 0.079536\n",
      "Train Epoch: 1 [6400/18662 (34%)]\tLoss: 0.177763\n",
      "Train Epoch: 1 [7040/18662 (38%)]\tLoss: 0.145364\n",
      "Train Epoch: 1 [7680/18662 (41%)]\tLoss: 0.160149\n",
      "Train Epoch: 1 [8320/18662 (45%)]\tLoss: 0.144796\n",
      "Train Epoch: 1 [8960/18662 (48%)]\tLoss: 0.255469\n",
      "Train Epoch: 1 [9600/18662 (51%)]\tLoss: 0.094519\n",
      "Train Epoch: 1 [10240/18662 (55%)]\tLoss: 0.082487\n",
      "Train Epoch: 1 [10880/18662 (58%)]\tLoss: 0.307029\n",
      "Train Epoch: 1 [11520/18662 (62%)]\tLoss: 0.026659\n",
      "Train Epoch: 1 [12160/18662 (65%)]\tLoss: 0.084279\n",
      "Train Epoch: 1 [12800/18662 (68%)]\tLoss: 0.146961\n",
      "Train Epoch: 1 [13440/18662 (72%)]\tLoss: 0.031844\n",
      "Train Epoch: 1 [14080/18662 (75%)]\tLoss: 0.178346\n",
      "Train Epoch: 1 [14720/18662 (79%)]\tLoss: 0.086876\n",
      "Train Epoch: 1 [15360/18662 (82%)]\tLoss: 0.065626\n",
      "Train Epoch: 1 [16000/18662 (86%)]\tLoss: 0.105019\n",
      "Train Epoch: 1 [16640/18662 (89%)]\tLoss: 0.062553\n",
      "Train Epoch: 1 [17280/18662 (92%)]\tLoss: 0.030721\n",
      "Train Epoch: 1 [17920/18662 (96%)]\tLoss: 0.102535\n",
      "Train Epoch: 1 [18560/18662 (99%)]\tLoss: 0.117670\n",
      "Train Epoch: 2 [0/18662 (0%)]\tLoss: 0.016446\n",
      "Train Epoch: 2 [640/18662 (3%)]\tLoss: 0.081026\n",
      "Train Epoch: 2 [1280/18662 (7%)]\tLoss: 0.073237\n",
      "Train Epoch: 2 [1920/18662 (10%)]\tLoss: 0.083668\n",
      "Train Epoch: 2 [2560/18662 (14%)]\tLoss: 0.142772\n",
      "Train Epoch: 2 [3200/18662 (17%)]\tLoss: 0.157444\n",
      "Train Epoch: 2 [3840/18662 (21%)]\tLoss: 0.032036\n",
      "Train Epoch: 2 [4480/18662 (24%)]\tLoss: 0.191849\n",
      "Train Epoch: 2 [5120/18662 (27%)]\tLoss: 0.177274\n",
      "Train Epoch: 2 [5760/18662 (31%)]\tLoss: 0.124679\n",
      "Train Epoch: 2 [6400/18662 (34%)]\tLoss: 0.151043\n",
      "Train Epoch: 2 [7040/18662 (38%)]\tLoss: 0.065917\n",
      "Train Epoch: 2 [7680/18662 (41%)]\tLoss: 0.163070\n",
      "Train Epoch: 2 [8320/18662 (45%)]\tLoss: 0.180720\n",
      "Train Epoch: 2 [8960/18662 (48%)]\tLoss: 0.123961\n",
      "Train Epoch: 2 [9600/18662 (51%)]\tLoss: 0.027175\n",
      "Train Epoch: 2 [10240/18662 (55%)]\tLoss: 0.134694\n",
      "Train Epoch: 2 [10880/18662 (58%)]\tLoss: 0.152766\n",
      "Train Epoch: 2 [11520/18662 (62%)]\tLoss: 0.099484\n",
      "Train Epoch: 2 [12160/18662 (65%)]\tLoss: 0.395714\n",
      "Train Epoch: 2 [12800/18662 (68%)]\tLoss: 0.056974\n",
      "Train Epoch: 2 [13440/18662 (72%)]\tLoss: 0.092359\n",
      "Train Epoch: 2 [14080/18662 (75%)]\tLoss: 0.055728\n",
      "Train Epoch: 2 [14720/18662 (79%)]\tLoss: 0.076236\n",
      "Train Epoch: 2 [15360/18662 (82%)]\tLoss: 0.036728\n",
      "Train Epoch: 2 [16000/18662 (86%)]\tLoss: 0.056410\n",
      "Train Epoch: 2 [16640/18662 (89%)]\tLoss: 0.204366\n",
      "Train Epoch: 2 [17280/18662 (92%)]\tLoss: 0.046150\n",
      "Train Epoch: 2 [17920/18662 (96%)]\tLoss: 0.050011\n",
      "Train Epoch: 2 [18560/18662 (99%)]\tLoss: 0.037736\n",
      "Train Epoch: 3 [0/18662 (0%)]\tLoss: 0.108901\n",
      "Train Epoch: 3 [640/18662 (3%)]\tLoss: 0.129557\n",
      "Train Epoch: 3 [1280/18662 (7%)]\tLoss: 0.056707\n",
      "Train Epoch: 3 [1920/18662 (10%)]\tLoss: 0.114542\n",
      "Train Epoch: 3 [2560/18662 (14%)]\tLoss: 0.136061\n",
      "Train Epoch: 3 [3200/18662 (17%)]\tLoss: 0.023172\n",
      "Train Epoch: 3 [3840/18662 (21%)]\tLoss: 0.086883\n",
      "Train Epoch: 3 [4480/18662 (24%)]\tLoss: 0.081088\n",
      "Train Epoch: 3 [5120/18662 (27%)]\tLoss: 0.086391\n",
      "Train Epoch: 3 [5760/18662 (31%)]\tLoss: 0.025275\n",
      "Train Epoch: 3 [6400/18662 (34%)]\tLoss: 0.034549\n",
      "Train Epoch: 3 [7040/18662 (38%)]\tLoss: 0.154693\n",
      "Train Epoch: 3 [7680/18662 (41%)]\tLoss: 0.146334\n",
      "Train Epoch: 3 [8320/18662 (45%)]\tLoss: 0.132243\n",
      "Train Epoch: 3 [8960/18662 (48%)]\tLoss: 0.027089\n",
      "Train Epoch: 3 [9600/18662 (51%)]\tLoss: 0.084618\n",
      "Train Epoch: 3 [10240/18662 (55%)]\tLoss: 0.025995\n",
      "Train Epoch: 3 [10880/18662 (58%)]\tLoss: 0.098328\n",
      "Train Epoch: 3 [11520/18662 (62%)]\tLoss: 0.043693\n",
      "Train Epoch: 3 [12160/18662 (65%)]\tLoss: 0.007435\n",
      "Train Epoch: 3 [12800/18662 (68%)]\tLoss: 0.014308\n",
      "Train Epoch: 3 [13440/18662 (72%)]\tLoss: 0.064981\n",
      "Train Epoch: 3 [14080/18662 (75%)]\tLoss: 0.221593\n",
      "Train Epoch: 3 [14720/18662 (79%)]\tLoss: 0.099988\n",
      "Train Epoch: 3 [15360/18662 (82%)]\tLoss: 0.031107\n",
      "Train Epoch: 3 [16000/18662 (86%)]\tLoss: 0.035401\n",
      "Train Epoch: 3 [16640/18662 (89%)]\tLoss: 0.029302\n",
      "Train Epoch: 3 [17280/18662 (92%)]\tLoss: 0.052113\n",
      "Train Epoch: 3 [17920/18662 (96%)]\tLoss: 0.057780\n",
      "Train Epoch: 3 [18560/18662 (99%)]\tLoss: 0.072186\n",
      "Train Epoch: 4 [0/18662 (0%)]\tLoss: 0.185056\n",
      "Train Epoch: 4 [640/18662 (3%)]\tLoss: 0.050745\n",
      "Train Epoch: 4 [1280/18662 (7%)]\tLoss: 0.039344\n",
      "Train Epoch: 4 [1920/18662 (10%)]\tLoss: 0.092678\n",
      "Train Epoch: 4 [2560/18662 (14%)]\tLoss: 0.085745\n",
      "Train Epoch: 4 [3200/18662 (17%)]\tLoss: 0.060567\n",
      "Train Epoch: 4 [3840/18662 (21%)]\tLoss: 0.060106\n",
      "Train Epoch: 4 [4480/18662 (24%)]\tLoss: 0.039495\n",
      "Train Epoch: 4 [5120/18662 (27%)]\tLoss: 0.032624\n",
      "Train Epoch: 4 [5760/18662 (31%)]\tLoss: 0.100041\n",
      "Train Epoch: 4 [6400/18662 (34%)]\tLoss: 0.145556\n",
      "Train Epoch: 4 [7040/18662 (38%)]\tLoss: 0.009836\n",
      "Train Epoch: 4 [7680/18662 (41%)]\tLoss: 0.017076\n",
      "Train Epoch: 4 [8320/18662 (45%)]\tLoss: 0.054049\n",
      "Train Epoch: 4 [8960/18662 (48%)]\tLoss: 0.042767\n",
      "Train Epoch: 4 [9600/18662 (51%)]\tLoss: 0.100610\n",
      "Train Epoch: 4 [10240/18662 (55%)]\tLoss: 0.039989\n",
      "Train Epoch: 4 [10880/18662 (58%)]\tLoss: 0.248316\n",
      "Train Epoch: 4 [11520/18662 (62%)]\tLoss: 0.017421\n",
      "Train Epoch: 4 [12160/18662 (65%)]\tLoss: 0.191097\n",
      "Train Epoch: 4 [12800/18662 (68%)]\tLoss: 0.029224\n",
      "Train Epoch: 4 [13440/18662 (72%)]\tLoss: 0.073721\n",
      "Train Epoch: 4 [14080/18662 (75%)]\tLoss: 0.044801\n",
      "Train Epoch: 4 [14720/18662 (79%)]\tLoss: 0.047101\n",
      "Train Epoch: 4 [15360/18662 (82%)]\tLoss: 0.169668\n",
      "Train Epoch: 4 [16000/18662 (86%)]\tLoss: 0.056316\n",
      "Train Epoch: 4 [16640/18662 (89%)]\tLoss: 0.086983\n",
      "Train Epoch: 4 [17280/18662 (92%)]\tLoss: 0.040353\n",
      "Train Epoch: 4 [17920/18662 (96%)]\tLoss: 0.167889\n",
      "Train Epoch: 4 [18560/18662 (99%)]\tLoss: 0.026034\n",
      "Train Epoch: 5 [0/18662 (0%)]\tLoss: 0.165895\n",
      "Train Epoch: 5 [640/18662 (3%)]\tLoss: 0.089666\n",
      "Train Epoch: 5 [1280/18662 (7%)]\tLoss: 0.096503\n",
      "Train Epoch: 5 [1920/18662 (10%)]\tLoss: 0.014951\n",
      "Train Epoch: 5 [2560/18662 (14%)]\tLoss: 0.053769\n",
      "Train Epoch: 5 [3200/18662 (17%)]\tLoss: 0.122158\n",
      "Train Epoch: 5 [3840/18662 (21%)]\tLoss: 0.048729\n",
      "Train Epoch: 5 [4480/18662 (24%)]\tLoss: 0.111376\n",
      "Train Epoch: 5 [5120/18662 (27%)]\tLoss: 0.045046\n",
      "Train Epoch: 5 [5760/18662 (31%)]\tLoss: 0.183077\n",
      "Train Epoch: 5 [6400/18662 (34%)]\tLoss: 0.022168\n",
      "Train Epoch: 5 [7040/18662 (38%)]\tLoss: 0.022590\n",
      "Train Epoch: 5 [7680/18662 (41%)]\tLoss: 0.037010\n",
      "Train Epoch: 5 [8320/18662 (45%)]\tLoss: 0.061452\n",
      "Train Epoch: 5 [8960/18662 (48%)]\tLoss: 0.104075\n",
      "Train Epoch: 5 [9600/18662 (51%)]\tLoss: 0.018197\n",
      "Train Epoch: 5 [10240/18662 (55%)]\tLoss: 0.057424\n",
      "Train Epoch: 5 [10880/18662 (58%)]\tLoss: 0.083171\n",
      "Train Epoch: 5 [11520/18662 (62%)]\tLoss: 0.022362\n",
      "Train Epoch: 5 [12160/18662 (65%)]\tLoss: 0.073390\n",
      "Train Epoch: 5 [12800/18662 (68%)]\tLoss: 0.131103\n",
      "Train Epoch: 5 [13440/18662 (72%)]\tLoss: 0.035464\n",
      "Train Epoch: 5 [14080/18662 (75%)]\tLoss: 0.042610\n",
      "Train Epoch: 5 [14720/18662 (79%)]\tLoss: 0.051067\n",
      "Train Epoch: 5 [15360/18662 (82%)]\tLoss: 0.013627\n",
      "Train Epoch: 5 [16000/18662 (86%)]\tLoss: 0.092747\n",
      "Train Epoch: 5 [16640/18662 (89%)]\tLoss: 0.056137\n",
      "Train Epoch: 5 [17280/18662 (92%)]\tLoss: 0.063076\n",
      "Train Epoch: 5 [17920/18662 (96%)]\tLoss: 0.053502\n",
      "Train Epoch: 5 [18560/18662 (99%)]\tLoss: 0.040292\n",
      "Train Epoch: 6 [0/18662 (0%)]\tLoss: 0.011295\n",
      "Train Epoch: 6 [640/18662 (3%)]\tLoss: 0.022442\n",
      "Train Epoch: 6 [1280/18662 (7%)]\tLoss: 0.160351\n",
      "Train Epoch: 6 [1920/18662 (10%)]\tLoss: 0.146850\n",
      "Train Epoch: 6 [2560/18662 (14%)]\tLoss: 0.016269\n",
      "Train Epoch: 6 [3200/18662 (17%)]\tLoss: 0.057714\n",
      "Train Epoch: 6 [3840/18662 (21%)]\tLoss: 0.054556\n",
      "Train Epoch: 6 [4480/18662 (24%)]\tLoss: 0.031283\n",
      "Train Epoch: 6 [5120/18662 (27%)]\tLoss: 0.215310\n",
      "Train Epoch: 6 [5760/18662 (31%)]\tLoss: 0.046707\n",
      "Train Epoch: 6 [6400/18662 (34%)]\tLoss: 0.103883\n",
      "Train Epoch: 6 [7040/18662 (38%)]\tLoss: 0.112393\n",
      "Train Epoch: 6 [7680/18662 (41%)]\tLoss: 0.035533\n",
      "Train Epoch: 6 [8320/18662 (45%)]\tLoss: 0.239638\n",
      "Train Epoch: 6 [8960/18662 (48%)]\tLoss: 0.064554\n",
      "Train Epoch: 6 [9600/18662 (51%)]\tLoss: 0.014409\n",
      "Train Epoch: 6 [10240/18662 (55%)]\tLoss: 0.047737\n",
      "Train Epoch: 6 [10880/18662 (58%)]\tLoss: 0.059122\n",
      "Train Epoch: 6 [11520/18662 (62%)]\tLoss: 0.012424\n",
      "Train Epoch: 6 [12160/18662 (65%)]\tLoss: 0.097473\n",
      "Train Epoch: 6 [12800/18662 (68%)]\tLoss: 0.207841\n",
      "Train Epoch: 6 [13440/18662 (72%)]\tLoss: 0.048062\n",
      "Train Epoch: 6 [14080/18662 (75%)]\tLoss: 0.180911\n",
      "Train Epoch: 6 [14720/18662 (79%)]\tLoss: 0.081799\n",
      "Train Epoch: 6 [15360/18662 (82%)]\tLoss: 0.068051\n",
      "Train Epoch: 6 [16000/18662 (86%)]\tLoss: 0.026209\n",
      "Train Epoch: 6 [16640/18662 (89%)]\tLoss: 0.036526\n",
      "Train Epoch: 6 [17280/18662 (92%)]\tLoss: 0.029712\n",
      "Train Epoch: 6 [17920/18662 (96%)]\tLoss: 0.094238\n",
      "Train Epoch: 6 [18560/18662 (99%)]\tLoss: 0.043263\n",
      "Train Epoch: 7 [0/18662 (0%)]\tLoss: 0.077611\n",
      "Train Epoch: 7 [640/18662 (3%)]\tLoss: 0.024166\n",
      "Train Epoch: 7 [1280/18662 (7%)]\tLoss: 0.056165\n",
      "Train Epoch: 7 [1920/18662 (10%)]\tLoss: 0.015873\n",
      "Train Epoch: 7 [2560/18662 (14%)]\tLoss: 0.061156\n",
      "Train Epoch: 7 [3200/18662 (17%)]\tLoss: 0.154007\n",
      "Train Epoch: 7 [3840/18662 (21%)]\tLoss: 0.036324\n",
      "Train Epoch: 7 [4480/18662 (24%)]\tLoss: 0.067766\n",
      "Train Epoch: 7 [5120/18662 (27%)]\tLoss: 0.068910\n",
      "Train Epoch: 7 [5760/18662 (31%)]\tLoss: 0.189703\n",
      "Train Epoch: 7 [6400/18662 (34%)]\tLoss: 0.182358\n",
      "Train Epoch: 7 [7040/18662 (38%)]\tLoss: 0.058986\n",
      "Train Epoch: 7 [7680/18662 (41%)]\tLoss: 0.109584\n",
      "Train Epoch: 7 [8320/18662 (45%)]\tLoss: 0.056899\n",
      "Train Epoch: 7 [8960/18662 (48%)]\tLoss: 0.062842\n",
      "Train Epoch: 7 [9600/18662 (51%)]\tLoss: 0.104453\n",
      "Train Epoch: 7 [10240/18662 (55%)]\tLoss: 0.027636\n",
      "Train Epoch: 7 [10880/18662 (58%)]\tLoss: 0.017806\n",
      "Train Epoch: 7 [11520/18662 (62%)]\tLoss: 0.118674\n",
      "Train Epoch: 7 [12160/18662 (65%)]\tLoss: 0.163438\n",
      "Train Epoch: 7 [12800/18662 (68%)]\tLoss: 0.090064\n",
      "Train Epoch: 7 [13440/18662 (72%)]\tLoss: 0.021473\n",
      "Train Epoch: 7 [14080/18662 (75%)]\tLoss: 0.046735\n",
      "Train Epoch: 7 [14720/18662 (79%)]\tLoss: 0.111842\n",
      "Train Epoch: 7 [15360/18662 (82%)]\tLoss: 0.033443\n",
      "Train Epoch: 7 [16000/18662 (86%)]\tLoss: 0.065374\n",
      "Train Epoch: 7 [16640/18662 (89%)]\tLoss: 0.098654\n",
      "Train Epoch: 7 [17280/18662 (92%)]\tLoss: 0.121232\n",
      "Train Epoch: 7 [17920/18662 (96%)]\tLoss: 0.019628\n",
      "Train Epoch: 7 [18560/18662 (99%)]\tLoss: 0.078393\n",
      "Train Epoch: 8 [0/18662 (0%)]\tLoss: 0.149611\n",
      "Train Epoch: 8 [640/18662 (3%)]\tLoss: 0.069701\n",
      "Train Epoch: 8 [1280/18662 (7%)]\tLoss: 0.058140\n",
      "Train Epoch: 8 [1920/18662 (10%)]\tLoss: 0.038300\n",
      "Train Epoch: 8 [2560/18662 (14%)]\tLoss: 0.021537\n",
      "Train Epoch: 8 [3200/18662 (17%)]\tLoss: 0.050429\n",
      "Train Epoch: 8 [3840/18662 (21%)]\tLoss: 0.036194\n",
      "Train Epoch: 8 [4480/18662 (24%)]\tLoss: 0.199368\n",
      "Train Epoch: 8 [5120/18662 (27%)]\tLoss: 0.042024\n",
      "Train Epoch: 8 [5760/18662 (31%)]\tLoss: 0.040313\n",
      "Train Epoch: 8 [6400/18662 (34%)]\tLoss: 0.150996\n",
      "Train Epoch: 8 [7040/18662 (38%)]\tLoss: 0.068778\n",
      "Train Epoch: 8 [7680/18662 (41%)]\tLoss: 0.042403\n",
      "Train Epoch: 8 [8320/18662 (45%)]\tLoss: 0.021898\n",
      "Train Epoch: 8 [8960/18662 (48%)]\tLoss: 0.074574\n",
      "Train Epoch: 8 [9600/18662 (51%)]\tLoss: 0.226509\n",
      "Train Epoch: 8 [10240/18662 (55%)]\tLoss: 0.064800\n",
      "Train Epoch: 8 [10880/18662 (58%)]\tLoss: 0.086411\n",
      "Train Epoch: 8 [11520/18662 (62%)]\tLoss: 0.033841\n",
      "Train Epoch: 8 [12160/18662 (65%)]\tLoss: 0.122818\n",
      "Train Epoch: 8 [12800/18662 (68%)]\tLoss: 0.122056\n",
      "Train Epoch: 8 [13440/18662 (72%)]\tLoss: 0.066675\n",
      "Train Epoch: 8 [14080/18662 (75%)]\tLoss: 0.056644\n",
      "Train Epoch: 8 [14720/18662 (79%)]\tLoss: 0.020292\n",
      "Train Epoch: 8 [15360/18662 (82%)]\tLoss: 0.027489\n",
      "Train Epoch: 8 [16000/18662 (86%)]\tLoss: 0.025770\n",
      "Train Epoch: 8 [16640/18662 (89%)]\tLoss: 0.036669\n",
      "Train Epoch: 8 [17280/18662 (92%)]\tLoss: 0.090842\n",
      "Train Epoch: 8 [17920/18662 (96%)]\tLoss: 0.064269\n",
      "Train Epoch: 8 [18560/18662 (99%)]\tLoss: 0.386101\n",
      "Train Epoch: 9 [0/18662 (0%)]\tLoss: 0.061842\n",
      "Train Epoch: 9 [640/18662 (3%)]\tLoss: 0.119166\n",
      "Train Epoch: 9 [1280/18662 (7%)]\tLoss: 0.132607\n",
      "Train Epoch: 9 [1920/18662 (10%)]\tLoss: 0.036539\n",
      "Train Epoch: 9 [2560/18662 (14%)]\tLoss: 0.065528\n",
      "Train Epoch: 9 [3200/18662 (17%)]\tLoss: 0.006222\n",
      "Train Epoch: 9 [3840/18662 (21%)]\tLoss: 0.056984\n",
      "Train Epoch: 9 [4480/18662 (24%)]\tLoss: 0.054475\n",
      "Train Epoch: 9 [5120/18662 (27%)]\tLoss: 0.013283\n",
      "Train Epoch: 9 [5760/18662 (31%)]\tLoss: 0.051945\n",
      "Train Epoch: 9 [6400/18662 (34%)]\tLoss: 0.086929\n",
      "Train Epoch: 9 [7040/18662 (38%)]\tLoss: 0.041159\n",
      "Train Epoch: 9 [7680/18662 (41%)]\tLoss: 0.005379\n",
      "Train Epoch: 9 [8320/18662 (45%)]\tLoss: 0.167318\n",
      "Train Epoch: 9 [8960/18662 (48%)]\tLoss: 0.008572\n",
      "Train Epoch: 9 [9600/18662 (51%)]\tLoss: 0.081433\n",
      "Train Epoch: 9 [10240/18662 (55%)]\tLoss: 0.044003\n",
      "Train Epoch: 9 [10880/18662 (58%)]\tLoss: 0.034319\n",
      "Train Epoch: 9 [11520/18662 (62%)]\tLoss: 0.035072\n",
      "Train Epoch: 9 [12160/18662 (65%)]\tLoss: 0.065034\n",
      "Train Epoch: 9 [12800/18662 (68%)]\tLoss: 0.043070\n",
      "Train Epoch: 9 [13440/18662 (72%)]\tLoss: 0.064995\n",
      "Train Epoch: 9 [14080/18662 (75%)]\tLoss: 0.047862\n",
      "Train Epoch: 9 [14720/18662 (79%)]\tLoss: 0.067266\n",
      "Train Epoch: 9 [15360/18662 (82%)]\tLoss: 0.093729\n",
      "Train Epoch: 9 [16000/18662 (86%)]\tLoss: 0.010673\n",
      "Train Epoch: 9 [16640/18662 (89%)]\tLoss: 0.087006\n",
      "Train Epoch: 9 [17280/18662 (92%)]\tLoss: 0.058568\n",
      "Train Epoch: 9 [17920/18662 (96%)]\tLoss: 0.075349\n",
      "Train Epoch: 9 [18560/18662 (99%)]\tLoss: 0.037148\n",
      "Train Epoch: 10 [0/18662 (0%)]\tLoss: 0.105005\n",
      "Train Epoch: 10 [640/18662 (3%)]\tLoss: 0.102673\n",
      "Train Epoch: 10 [1280/18662 (7%)]\tLoss: 0.033244\n",
      "Train Epoch: 10 [1920/18662 (10%)]\tLoss: 0.157816\n",
      "Train Epoch: 10 [2560/18662 (14%)]\tLoss: 0.070198\n",
      "Train Epoch: 10 [3200/18662 (17%)]\tLoss: 0.142049\n",
      "Train Epoch: 10 [3840/18662 (21%)]\tLoss: 0.068676\n",
      "Train Epoch: 10 [4480/18662 (24%)]\tLoss: 0.049846\n",
      "Train Epoch: 10 [5120/18662 (27%)]\tLoss: 0.019323\n",
      "Train Epoch: 10 [5760/18662 (31%)]\tLoss: 0.082132\n",
      "Train Epoch: 10 [6400/18662 (34%)]\tLoss: 0.031476\n",
      "Train Epoch: 10 [7040/18662 (38%)]\tLoss: 0.016091\n",
      "Train Epoch: 10 [7680/18662 (41%)]\tLoss: 0.041805\n",
      "Train Epoch: 10 [8320/18662 (45%)]\tLoss: 0.206701\n",
      "Train Epoch: 10 [8960/18662 (48%)]\tLoss: 0.081614\n",
      "Train Epoch: 10 [9600/18662 (51%)]\tLoss: 0.070544\n",
      "Train Epoch: 10 [10240/18662 (55%)]\tLoss: 0.052181\n",
      "Train Epoch: 10 [10880/18662 (58%)]\tLoss: 0.234198\n",
      "Train Epoch: 10 [11520/18662 (62%)]\tLoss: 0.035975\n",
      "Train Epoch: 10 [12160/18662 (65%)]\tLoss: 0.118787\n",
      "Train Epoch: 10 [12800/18662 (68%)]\tLoss: 0.155621\n",
      "Train Epoch: 10 [13440/18662 (72%)]\tLoss: 0.054011\n",
      "Train Epoch: 10 [14080/18662 (75%)]\tLoss: 0.033813\n",
      "Train Epoch: 10 [14720/18662 (79%)]\tLoss: 0.014199\n",
      "Train Epoch: 10 [15360/18662 (82%)]\tLoss: 0.099614\n",
      "Train Epoch: 10 [16000/18662 (86%)]\tLoss: 0.087454\n",
      "Train Epoch: 10 [16640/18662 (89%)]\tLoss: 0.116398\n",
      "Train Epoch: 10 [17280/18662 (92%)]\tLoss: 0.024609\n",
      "Train Epoch: 10 [17920/18662 (96%)]\tLoss: 0.084839\n",
      "Train Epoch: 10 [18560/18662 (99%)]\tLoss: 0.173573\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/10619 (0%)]\tLoss: 0.139721\n",
      "Train Epoch: 1 [640/10619 (6%)]\tLoss: 0.144443\n",
      "Train Epoch: 1 [1280/10619 (12%)]\tLoss: 0.055004\n",
      "Train Epoch: 1 [1920/10619 (18%)]\tLoss: 0.098316\n",
      "Train Epoch: 1 [2560/10619 (24%)]\tLoss: 0.138712\n",
      "Train Epoch: 1 [3200/10619 (30%)]\tLoss: 0.217400\n",
      "Train Epoch: 1 [3840/10619 (36%)]\tLoss: 0.022068\n",
      "Train Epoch: 1 [4480/10619 (42%)]\tLoss: 0.065272\n",
      "Train Epoch: 1 [5120/10619 (48%)]\tLoss: 0.224515\n",
      "Train Epoch: 1 [5760/10619 (54%)]\tLoss: 0.111005\n",
      "Train Epoch: 1 [6400/10619 (60%)]\tLoss: 0.142777\n",
      "Train Epoch: 1 [7040/10619 (66%)]\tLoss: 0.208041\n",
      "Train Epoch: 1 [7680/10619 (72%)]\tLoss: 0.107675\n",
      "Train Epoch: 1 [8320/10619 (78%)]\tLoss: 0.178643\n",
      "Train Epoch: 1 [8960/10619 (84%)]\tLoss: 0.046542\n",
      "Train Epoch: 1 [9600/10619 (90%)]\tLoss: 0.153839\n",
      "Train Epoch: 1 [10240/10619 (96%)]\tLoss: 0.088346\n",
      "Train Epoch: 2 [0/10619 (0%)]\tLoss: 0.068668\n",
      "Train Epoch: 2 [640/10619 (6%)]\tLoss: 0.126331\n",
      "Train Epoch: 2 [1280/10619 (12%)]\tLoss: 0.043113\n",
      "Train Epoch: 2 [1920/10619 (18%)]\tLoss: 0.096844\n",
      "Train Epoch: 2 [2560/10619 (24%)]\tLoss: 0.151530\n",
      "Train Epoch: 2 [3200/10619 (30%)]\tLoss: 0.197699\n",
      "Train Epoch: 2 [3840/10619 (36%)]\tLoss: 0.100521\n",
      "Train Epoch: 2 [4480/10619 (42%)]\tLoss: 0.053642\n",
      "Train Epoch: 2 [5120/10619 (48%)]\tLoss: 0.107059\n",
      "Train Epoch: 2 [5760/10619 (54%)]\tLoss: 0.027217\n",
      "Train Epoch: 2 [6400/10619 (60%)]\tLoss: 0.158290\n",
      "Train Epoch: 2 [7040/10619 (66%)]\tLoss: 0.101953\n",
      "Train Epoch: 2 [7680/10619 (72%)]\tLoss: 0.063701\n",
      "Train Epoch: 2 [8320/10619 (78%)]\tLoss: 0.093558\n",
      "Train Epoch: 2 [8960/10619 (84%)]\tLoss: 0.146170\n",
      "Train Epoch: 2 [9600/10619 (90%)]\tLoss: 0.033535\n",
      "Train Epoch: 2 [10240/10619 (96%)]\tLoss: 0.100329\n",
      "Train Epoch: 3 [0/10619 (0%)]\tLoss: 0.131489\n",
      "Train Epoch: 3 [640/10619 (6%)]\tLoss: 0.105604\n",
      "Train Epoch: 3 [1280/10619 (12%)]\tLoss: 0.047782\n",
      "Train Epoch: 3 [1920/10619 (18%)]\tLoss: 0.134235\n",
      "Train Epoch: 3 [2560/10619 (24%)]\tLoss: 0.285340\n",
      "Train Epoch: 3 [3200/10619 (30%)]\tLoss: 0.141337\n",
      "Train Epoch: 3 [3840/10619 (36%)]\tLoss: 0.050568\n",
      "Train Epoch: 3 [4480/10619 (42%)]\tLoss: 0.150377\n",
      "Train Epoch: 3 [5120/10619 (48%)]\tLoss: 0.029554\n",
      "Train Epoch: 3 [5760/10619 (54%)]\tLoss: 0.557228\n",
      "Train Epoch: 3 [6400/10619 (60%)]\tLoss: 0.131766\n",
      "Train Epoch: 3 [7040/10619 (66%)]\tLoss: 0.040859\n",
      "Train Epoch: 3 [7680/10619 (72%)]\tLoss: 0.056850\n",
      "Train Epoch: 3 [8320/10619 (78%)]\tLoss: 0.008434\n",
      "Train Epoch: 3 [8960/10619 (84%)]\tLoss: 0.064356\n",
      "Train Epoch: 3 [9600/10619 (90%)]\tLoss: 0.098386\n",
      "Train Epoch: 3 [10240/10619 (96%)]\tLoss: 0.082771\n",
      "Train Epoch: 4 [0/10619 (0%)]\tLoss: 0.180762\n",
      "Train Epoch: 4 [640/10619 (6%)]\tLoss: 0.135701\n",
      "Train Epoch: 4 [1280/10619 (12%)]\tLoss: 0.067422\n",
      "Train Epoch: 4 [1920/10619 (18%)]\tLoss: 0.026219\n",
      "Train Epoch: 4 [2560/10619 (24%)]\tLoss: 0.127921\n",
      "Train Epoch: 4 [3200/10619 (30%)]\tLoss: 0.081911\n",
      "Train Epoch: 4 [3840/10619 (36%)]\tLoss: 0.206222\n",
      "Train Epoch: 4 [4480/10619 (42%)]\tLoss: 0.038259\n",
      "Train Epoch: 4 [5120/10619 (48%)]\tLoss: 0.064613\n",
      "Train Epoch: 4 [5760/10619 (54%)]\tLoss: 0.169087\n",
      "Train Epoch: 4 [6400/10619 (60%)]\tLoss: 0.088187\n",
      "Train Epoch: 4 [7040/10619 (66%)]\tLoss: 0.054923\n",
      "Train Epoch: 4 [7680/10619 (72%)]\tLoss: 0.036717\n",
      "Train Epoch: 4 [8320/10619 (78%)]\tLoss: 0.068392\n",
      "Train Epoch: 4 [8960/10619 (84%)]\tLoss: 0.024992\n",
      "Train Epoch: 4 [9600/10619 (90%)]\tLoss: 0.071016\n",
      "Train Epoch: 4 [10240/10619 (96%)]\tLoss: 0.099611\n",
      "Train Epoch: 5 [0/10619 (0%)]\tLoss: 0.126651\n",
      "Train Epoch: 5 [640/10619 (6%)]\tLoss: 0.060135\n",
      "Train Epoch: 5 [1280/10619 (12%)]\tLoss: 0.077839\n",
      "Train Epoch: 5 [1920/10619 (18%)]\tLoss: 0.110825\n",
      "Train Epoch: 5 [2560/10619 (24%)]\tLoss: 0.057664\n",
      "Train Epoch: 5 [3200/10619 (30%)]\tLoss: 0.074804\n",
      "Train Epoch: 5 [3840/10619 (36%)]\tLoss: 0.077462\n",
      "Train Epoch: 5 [4480/10619 (42%)]\tLoss: 0.049114\n",
      "Train Epoch: 5 [5120/10619 (48%)]\tLoss: 0.084564\n",
      "Train Epoch: 5 [5760/10619 (54%)]\tLoss: 0.048608\n",
      "Train Epoch: 5 [6400/10619 (60%)]\tLoss: 0.005877\n",
      "Train Epoch: 5 [7040/10619 (66%)]\tLoss: 0.046409\n",
      "Train Epoch: 5 [7680/10619 (72%)]\tLoss: 0.024592\n",
      "Train Epoch: 5 [8320/10619 (78%)]\tLoss: 0.158890\n",
      "Train Epoch: 5 [8960/10619 (84%)]\tLoss: 0.086343\n",
      "Train Epoch: 5 [9600/10619 (90%)]\tLoss: 0.297981\n",
      "Train Epoch: 5 [10240/10619 (96%)]\tLoss: 0.055958\n",
      "Train Epoch: 6 [0/10619 (0%)]\tLoss: 0.049522\n",
      "Train Epoch: 6 [640/10619 (6%)]\tLoss: 0.059072\n",
      "Train Epoch: 6 [1280/10619 (12%)]\tLoss: 0.146658\n",
      "Train Epoch: 6 [1920/10619 (18%)]\tLoss: 0.128933\n",
      "Train Epoch: 6 [2560/10619 (24%)]\tLoss: 0.102748\n",
      "Train Epoch: 6 [3200/10619 (30%)]\tLoss: 0.077428\n",
      "Train Epoch: 6 [3840/10619 (36%)]\tLoss: 0.085532\n",
      "Train Epoch: 6 [4480/10619 (42%)]\tLoss: 0.186783\n",
      "Train Epoch: 6 [5120/10619 (48%)]\tLoss: 0.022730\n",
      "Train Epoch: 6 [5760/10619 (54%)]\tLoss: 0.046858\n",
      "Train Epoch: 6 [6400/10619 (60%)]\tLoss: 0.115210\n",
      "Train Epoch: 6 [7040/10619 (66%)]\tLoss: 0.034289\n",
      "Train Epoch: 6 [7680/10619 (72%)]\tLoss: 0.130948\n",
      "Train Epoch: 6 [8320/10619 (78%)]\tLoss: 0.086817\n",
      "Train Epoch: 6 [8960/10619 (84%)]\tLoss: 0.046494\n",
      "Train Epoch: 6 [9600/10619 (90%)]\tLoss: 0.123093\n",
      "Train Epoch: 6 [10240/10619 (96%)]\tLoss: 0.126839\n",
      "Train Epoch: 7 [0/10619 (0%)]\tLoss: 0.047666\n",
      "Train Epoch: 7 [640/10619 (6%)]\tLoss: 0.030627\n",
      "Train Epoch: 7 [1280/10619 (12%)]\tLoss: 0.283001\n",
      "Train Epoch: 7 [1920/10619 (18%)]\tLoss: 0.072003\n",
      "Train Epoch: 7 [2560/10619 (24%)]\tLoss: 0.033129\n",
      "Train Epoch: 7 [3200/10619 (30%)]\tLoss: 0.136408\n",
      "Train Epoch: 7 [3840/10619 (36%)]\tLoss: 0.165621\n",
      "Train Epoch: 7 [4480/10619 (42%)]\tLoss: 0.124692\n",
      "Train Epoch: 7 [5120/10619 (48%)]\tLoss: 0.043762\n",
      "Train Epoch: 7 [5760/10619 (54%)]\tLoss: 0.061796\n",
      "Train Epoch: 7 [6400/10619 (60%)]\tLoss: 0.119690\n",
      "Train Epoch: 7 [7040/10619 (66%)]\tLoss: 0.038217\n",
      "Train Epoch: 7 [7680/10619 (72%)]\tLoss: 0.064078\n",
      "Train Epoch: 7 [8320/10619 (78%)]\tLoss: 0.046865\n",
      "Train Epoch: 7 [8960/10619 (84%)]\tLoss: 0.133961\n",
      "Train Epoch: 7 [9600/10619 (90%)]\tLoss: 0.108995\n",
      "Train Epoch: 7 [10240/10619 (96%)]\tLoss: 0.030125\n",
      "Train Epoch: 8 [0/10619 (0%)]\tLoss: 0.212869\n",
      "Train Epoch: 8 [640/10619 (6%)]\tLoss: 0.052193\n",
      "Train Epoch: 8 [1280/10619 (12%)]\tLoss: 0.053065\n",
      "Train Epoch: 8 [1920/10619 (18%)]\tLoss: 0.214485\n",
      "Train Epoch: 8 [2560/10619 (24%)]\tLoss: 0.313105\n",
      "Train Epoch: 8 [3200/10619 (30%)]\tLoss: 0.105803\n",
      "Train Epoch: 8 [3840/10619 (36%)]\tLoss: 0.089010\n",
      "Train Epoch: 8 [4480/10619 (42%)]\tLoss: 0.190241\n",
      "Train Epoch: 8 [5120/10619 (48%)]\tLoss: 0.182717\n",
      "Train Epoch: 8 [5760/10619 (54%)]\tLoss: 0.074625\n",
      "Train Epoch: 8 [6400/10619 (60%)]\tLoss: 0.142158\n",
      "Train Epoch: 8 [7040/10619 (66%)]\tLoss: 0.115429\n",
      "Train Epoch: 8 [7680/10619 (72%)]\tLoss: 0.090705\n",
      "Train Epoch: 8 [8320/10619 (78%)]\tLoss: 0.026487\n",
      "Train Epoch: 8 [8960/10619 (84%)]\tLoss: 0.117836\n",
      "Train Epoch: 8 [9600/10619 (90%)]\tLoss: 0.236240\n",
      "Train Epoch: 8 [10240/10619 (96%)]\tLoss: 0.071187\n",
      "Train Epoch: 9 [0/10619 (0%)]\tLoss: 0.045906\n",
      "Train Epoch: 9 [640/10619 (6%)]\tLoss: 0.226471\n",
      "Train Epoch: 9 [1280/10619 (12%)]\tLoss: 0.057668\n",
      "Train Epoch: 9 [1920/10619 (18%)]\tLoss: 0.040895\n",
      "Train Epoch: 9 [2560/10619 (24%)]\tLoss: 0.053176\n",
      "Train Epoch: 9 [3200/10619 (30%)]\tLoss: 0.085446\n",
      "Train Epoch: 9 [3840/10619 (36%)]\tLoss: 0.033227\n",
      "Train Epoch: 9 [4480/10619 (42%)]\tLoss: 0.053509\n",
      "Train Epoch: 9 [5120/10619 (48%)]\tLoss: 0.084123\n",
      "Train Epoch: 9 [5760/10619 (54%)]\tLoss: 0.040268\n",
      "Train Epoch: 9 [6400/10619 (60%)]\tLoss: 0.071510\n",
      "Train Epoch: 9 [7040/10619 (66%)]\tLoss: 0.041300\n",
      "Train Epoch: 9 [7680/10619 (72%)]\tLoss: 0.241319\n",
      "Train Epoch: 9 [8320/10619 (78%)]\tLoss: 0.063061\n",
      "Train Epoch: 9 [8960/10619 (84%)]\tLoss: 0.058430\n",
      "Train Epoch: 9 [9600/10619 (90%)]\tLoss: 0.036102\n",
      "Train Epoch: 9 [10240/10619 (96%)]\tLoss: 0.046660\n",
      "Train Epoch: 10 [0/10619 (0%)]\tLoss: 0.077835\n",
      "Train Epoch: 10 [640/10619 (6%)]\tLoss: 0.186125\n",
      "Train Epoch: 10 [1280/10619 (12%)]\tLoss: 0.093323\n",
      "Train Epoch: 10 [1920/10619 (18%)]\tLoss: 0.006091\n",
      "Train Epoch: 10 [2560/10619 (24%)]\tLoss: 0.023147\n",
      "Train Epoch: 10 [3200/10619 (30%)]\tLoss: 0.079340\n",
      "Train Epoch: 10 [3840/10619 (36%)]\tLoss: 0.328844\n",
      "Train Epoch: 10 [4480/10619 (42%)]\tLoss: 0.136651\n",
      "Train Epoch: 10 [5120/10619 (48%)]\tLoss: 0.047306\n",
      "Train Epoch: 10 [5760/10619 (54%)]\tLoss: 0.177531\n",
      "Train Epoch: 10 [6400/10619 (60%)]\tLoss: 0.044897\n",
      "Train Epoch: 10 [7040/10619 (66%)]\tLoss: 0.076004\n",
      "Train Epoch: 10 [7680/10619 (72%)]\tLoss: 0.158865\n",
      "Train Epoch: 10 [8320/10619 (78%)]\tLoss: 0.043553\n",
      "Train Epoch: 10 [8960/10619 (84%)]\tLoss: 0.111712\n",
      "Train Epoch: 10 [9600/10619 (90%)]\tLoss: 0.082318\n",
      "Train Epoch: 10 [10240/10619 (96%)]\tLoss: 0.132209\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/15392 (0%)]\tLoss: 0.058948\n",
      "Train Epoch: 1 [640/15392 (4%)]\tLoss: 0.183529\n",
      "Train Epoch: 1 [1280/15392 (8%)]\tLoss: 0.103428\n",
      "Train Epoch: 1 [1920/15392 (12%)]\tLoss: 0.159030\n",
      "Train Epoch: 1 [2560/15392 (17%)]\tLoss: 0.089541\n",
      "Train Epoch: 1 [3200/15392 (21%)]\tLoss: 0.033235\n",
      "Train Epoch: 1 [3840/15392 (25%)]\tLoss: 0.076568\n",
      "Train Epoch: 1 [4480/15392 (29%)]\tLoss: 0.075086\n",
      "Train Epoch: 1 [5120/15392 (33%)]\tLoss: 0.121747\n",
      "Train Epoch: 1 [5760/15392 (37%)]\tLoss: 0.051064\n",
      "Train Epoch: 1 [6400/15392 (41%)]\tLoss: 0.075366\n",
      "Train Epoch: 1 [7040/15392 (46%)]\tLoss: 0.104386\n",
      "Train Epoch: 1 [7680/15392 (50%)]\tLoss: 0.109622\n",
      "Train Epoch: 1 [8320/15392 (54%)]\tLoss: 0.086217\n",
      "Train Epoch: 1 [8960/15392 (58%)]\tLoss: 0.086555\n",
      "Train Epoch: 1 [9600/15392 (62%)]\tLoss: 0.046499\n",
      "Train Epoch: 1 [10240/15392 (66%)]\tLoss: 0.063522\n",
      "Train Epoch: 1 [10880/15392 (71%)]\tLoss: 0.090580\n",
      "Train Epoch: 1 [11520/15392 (75%)]\tLoss: 0.007040\n",
      "Train Epoch: 1 [12160/15392 (79%)]\tLoss: 0.067043\n",
      "Train Epoch: 1 [12800/15392 (83%)]\tLoss: 0.046368\n",
      "Train Epoch: 1 [13440/15392 (87%)]\tLoss: 0.086312\n",
      "Train Epoch: 1 [14080/15392 (91%)]\tLoss: 0.061924\n",
      "Train Epoch: 1 [14720/15392 (95%)]\tLoss: 0.105080\n",
      "Train Epoch: 1 [7680/15392 (100%)]\tLoss: 0.036561\n",
      "Train Epoch: 2 [0/15392 (0%)]\tLoss: 0.036477\n",
      "Train Epoch: 2 [640/15392 (4%)]\tLoss: 0.032415\n",
      "Train Epoch: 2 [1280/15392 (8%)]\tLoss: 0.057665\n",
      "Train Epoch: 2 [1920/15392 (12%)]\tLoss: 0.128059\n",
      "Train Epoch: 2 [2560/15392 (17%)]\tLoss: 0.089730\n",
      "Train Epoch: 2 [3200/15392 (21%)]\tLoss: 0.208868\n",
      "Train Epoch: 2 [3840/15392 (25%)]\tLoss: 0.049124\n",
      "Train Epoch: 2 [4480/15392 (29%)]\tLoss: 0.123045\n",
      "Train Epoch: 2 [5120/15392 (33%)]\tLoss: 0.156465\n",
      "Train Epoch: 2 [5760/15392 (37%)]\tLoss: 0.051556\n",
      "Train Epoch: 2 [6400/15392 (41%)]\tLoss: 0.012709\n",
      "Train Epoch: 2 [7040/15392 (46%)]\tLoss: 0.177970\n",
      "Train Epoch: 2 [7680/15392 (50%)]\tLoss: 0.138815\n",
      "Train Epoch: 2 [8320/15392 (54%)]\tLoss: 0.041489\n",
      "Train Epoch: 2 [8960/15392 (58%)]\tLoss: 0.064867\n",
      "Train Epoch: 2 [9600/15392 (62%)]\tLoss: 0.077238\n",
      "Train Epoch: 2 [10240/15392 (66%)]\tLoss: 0.068643\n",
      "Train Epoch: 2 [10880/15392 (71%)]\tLoss: 0.035491\n",
      "Train Epoch: 2 [11520/15392 (75%)]\tLoss: 0.055829\n",
      "Train Epoch: 2 [12160/15392 (79%)]\tLoss: 0.034584\n",
      "Train Epoch: 2 [12800/15392 (83%)]\tLoss: 0.260472\n",
      "Train Epoch: 2 [13440/15392 (87%)]\tLoss: 0.038488\n",
      "Train Epoch: 2 [14080/15392 (91%)]\tLoss: 0.036149\n",
      "Train Epoch: 2 [14720/15392 (95%)]\tLoss: 0.307276\n",
      "Train Epoch: 2 [7680/15392 (100%)]\tLoss: 0.207691\n",
      "Train Epoch: 3 [0/15392 (0%)]\tLoss: 0.150281\n",
      "Train Epoch: 3 [640/15392 (4%)]\tLoss: 0.033435\n",
      "Train Epoch: 3 [1280/15392 (8%)]\tLoss: 0.022078\n",
      "Train Epoch: 3 [1920/15392 (12%)]\tLoss: 0.042847\n",
      "Train Epoch: 3 [2560/15392 (17%)]\tLoss: 0.011709\n",
      "Train Epoch: 3 [3200/15392 (21%)]\tLoss: 0.081607\n",
      "Train Epoch: 3 [3840/15392 (25%)]\tLoss: 0.159757\n",
      "Train Epoch: 3 [4480/15392 (29%)]\tLoss: 0.055662\n",
      "Train Epoch: 3 [5120/15392 (33%)]\tLoss: 0.281611\n",
      "Train Epoch: 3 [5760/15392 (37%)]\tLoss: 0.024254\n",
      "Train Epoch: 3 [6400/15392 (41%)]\tLoss: 0.152815\n",
      "Train Epoch: 3 [7040/15392 (46%)]\tLoss: 0.067205\n",
      "Train Epoch: 3 [7680/15392 (50%)]\tLoss: 0.027715\n",
      "Train Epoch: 3 [8320/15392 (54%)]\tLoss: 0.044641\n",
      "Train Epoch: 3 [8960/15392 (58%)]\tLoss: 0.089708\n",
      "Train Epoch: 3 [9600/15392 (62%)]\tLoss: 0.075531\n",
      "Train Epoch: 3 [10240/15392 (66%)]\tLoss: 0.008195\n",
      "Train Epoch: 3 [10880/15392 (71%)]\tLoss: 0.055026\n",
      "Train Epoch: 3 [11520/15392 (75%)]\tLoss: 0.094583\n",
      "Train Epoch: 3 [12160/15392 (79%)]\tLoss: 0.098033\n",
      "Train Epoch: 3 [12800/15392 (83%)]\tLoss: 0.098273\n",
      "Train Epoch: 3 [13440/15392 (87%)]\tLoss: 0.088680\n",
      "Train Epoch: 3 [14080/15392 (91%)]\tLoss: 0.041892\n",
      "Train Epoch: 3 [14720/15392 (95%)]\tLoss: 0.038874\n",
      "Train Epoch: 3 [7680/15392 (100%)]\tLoss: 0.032532\n",
      "Train Epoch: 4 [0/15392 (0%)]\tLoss: 0.155429\n",
      "Train Epoch: 4 [640/15392 (4%)]\tLoss: 0.040924\n",
      "Train Epoch: 4 [1280/15392 (8%)]\tLoss: 0.023276\n",
      "Train Epoch: 4 [1920/15392 (12%)]\tLoss: 0.094342\n",
      "Train Epoch: 4 [2560/15392 (17%)]\tLoss: 0.006369\n",
      "Train Epoch: 4 [3200/15392 (21%)]\tLoss: 0.079737\n",
      "Train Epoch: 4 [3840/15392 (25%)]\tLoss: 0.069245\n",
      "Train Epoch: 4 [4480/15392 (29%)]\tLoss: 0.097354\n",
      "Train Epoch: 4 [5120/15392 (33%)]\tLoss: 0.039763\n",
      "Train Epoch: 4 [5760/15392 (37%)]\tLoss: 0.030272\n",
      "Train Epoch: 4 [6400/15392 (41%)]\tLoss: 0.081449\n",
      "Train Epoch: 4 [7040/15392 (46%)]\tLoss: 0.094860\n",
      "Train Epoch: 4 [7680/15392 (50%)]\tLoss: 0.114337\n",
      "Train Epoch: 4 [8320/15392 (54%)]\tLoss: 0.161469\n",
      "Train Epoch: 4 [8960/15392 (58%)]\tLoss: 0.088748\n",
      "Train Epoch: 4 [9600/15392 (62%)]\tLoss: 0.112023\n",
      "Train Epoch: 4 [10240/15392 (66%)]\tLoss: 0.110461\n",
      "Train Epoch: 4 [10880/15392 (71%)]\tLoss: 0.066328\n",
      "Train Epoch: 4 [11520/15392 (75%)]\tLoss: 0.073438\n",
      "Train Epoch: 4 [12160/15392 (79%)]\tLoss: 0.038926\n",
      "Train Epoch: 4 [12800/15392 (83%)]\tLoss: 0.062203\n",
      "Train Epoch: 4 [13440/15392 (87%)]\tLoss: 0.140533\n",
      "Train Epoch: 4 [14080/15392 (91%)]\tLoss: 0.041709\n",
      "Train Epoch: 4 [14720/15392 (95%)]\tLoss: 0.126497\n",
      "Train Epoch: 4 [7680/15392 (100%)]\tLoss: 0.330634\n",
      "Train Epoch: 5 [0/15392 (0%)]\tLoss: 0.020275\n",
      "Train Epoch: 5 [640/15392 (4%)]\tLoss: 0.083646\n",
      "Train Epoch: 5 [1280/15392 (8%)]\tLoss: 0.050259\n",
      "Train Epoch: 5 [1920/15392 (12%)]\tLoss: 0.048316\n",
      "Train Epoch: 5 [2560/15392 (17%)]\tLoss: 0.021598\n",
      "Train Epoch: 5 [3200/15392 (21%)]\tLoss: 0.043165\n",
      "Train Epoch: 5 [3840/15392 (25%)]\tLoss: 0.008210\n",
      "Train Epoch: 5 [4480/15392 (29%)]\tLoss: 0.103402\n",
      "Train Epoch: 5 [5120/15392 (33%)]\tLoss: 0.037544\n",
      "Train Epoch: 5 [5760/15392 (37%)]\tLoss: 0.018345\n",
      "Train Epoch: 5 [6400/15392 (41%)]\tLoss: 0.142972\n",
      "Train Epoch: 5 [7040/15392 (46%)]\tLoss: 0.076176\n",
      "Train Epoch: 5 [7680/15392 (50%)]\tLoss: 0.052799\n",
      "Train Epoch: 5 [8320/15392 (54%)]\tLoss: 0.051447\n",
      "Train Epoch: 5 [8960/15392 (58%)]\tLoss: 0.129555\n",
      "Train Epoch: 5 [9600/15392 (62%)]\tLoss: 0.020260\n",
      "Train Epoch: 5 [10240/15392 (66%)]\tLoss: 0.121138\n",
      "Train Epoch: 5 [10880/15392 (71%)]\tLoss: 0.025161\n",
      "Train Epoch: 5 [11520/15392 (75%)]\tLoss: 0.057063\n",
      "Train Epoch: 5 [12160/15392 (79%)]\tLoss: 0.075933\n",
      "Train Epoch: 5 [12800/15392 (83%)]\tLoss: 0.080091\n",
      "Train Epoch: 5 [13440/15392 (87%)]\tLoss: 0.063336\n",
      "Train Epoch: 5 [14080/15392 (91%)]\tLoss: 0.041557\n",
      "Train Epoch: 5 [14720/15392 (95%)]\tLoss: 0.104056\n",
      "Train Epoch: 5 [7680/15392 (100%)]\tLoss: 0.047730\n",
      "Train Epoch: 6 [0/15392 (0%)]\tLoss: 0.096999\n",
      "Train Epoch: 6 [640/15392 (4%)]\tLoss: 0.067165\n",
      "Train Epoch: 6 [1280/15392 (8%)]\tLoss: 0.042576\n",
      "Train Epoch: 6 [1920/15392 (12%)]\tLoss: 0.061663\n",
      "Train Epoch: 6 [2560/15392 (17%)]\tLoss: 0.013589\n",
      "Train Epoch: 6 [3200/15392 (21%)]\tLoss: 0.133937\n",
      "Train Epoch: 6 [3840/15392 (25%)]\tLoss: 0.057812\n",
      "Train Epoch: 6 [4480/15392 (29%)]\tLoss: 0.018229\n",
      "Train Epoch: 6 [5120/15392 (33%)]\tLoss: 0.064043\n",
      "Train Epoch: 6 [5760/15392 (37%)]\tLoss: 0.165695\n",
      "Train Epoch: 6 [6400/15392 (41%)]\tLoss: 0.173016\n",
      "Train Epoch: 6 [7040/15392 (46%)]\tLoss: 0.088131\n",
      "Train Epoch: 6 [7680/15392 (50%)]\tLoss: 0.147674\n",
      "Train Epoch: 6 [8320/15392 (54%)]\tLoss: 0.155205\n",
      "Train Epoch: 6 [8960/15392 (58%)]\tLoss: 0.035794\n",
      "Train Epoch: 6 [9600/15392 (62%)]\tLoss: 0.139196\n",
      "Train Epoch: 6 [10240/15392 (66%)]\tLoss: 0.230138\n",
      "Train Epoch: 6 [10880/15392 (71%)]\tLoss: 0.062238\n",
      "Train Epoch: 6 [11520/15392 (75%)]\tLoss: 0.176493\n",
      "Train Epoch: 6 [12160/15392 (79%)]\tLoss: 0.088635\n",
      "Train Epoch: 6 [12800/15392 (83%)]\tLoss: 0.021586\n",
      "Train Epoch: 6 [13440/15392 (87%)]\tLoss: 0.094658\n",
      "Train Epoch: 6 [14080/15392 (91%)]\tLoss: 0.025539\n",
      "Train Epoch: 6 [14720/15392 (95%)]\tLoss: 0.102410\n",
      "Train Epoch: 6 [7680/15392 (100%)]\tLoss: 0.000953\n",
      "Train Epoch: 7 [0/15392 (0%)]\tLoss: 0.020550\n",
      "Train Epoch: 7 [640/15392 (4%)]\tLoss: 0.056192\n",
      "Train Epoch: 7 [1280/15392 (8%)]\tLoss: 0.065287\n",
      "Train Epoch: 7 [1920/15392 (12%)]\tLoss: 0.010419\n",
      "Train Epoch: 7 [2560/15392 (17%)]\tLoss: 0.126985\n",
      "Train Epoch: 7 [3200/15392 (21%)]\tLoss: 0.111720\n",
      "Train Epoch: 7 [3840/15392 (25%)]\tLoss: 0.039094\n",
      "Train Epoch: 7 [4480/15392 (29%)]\tLoss: 0.150362\n",
      "Train Epoch: 7 [5120/15392 (33%)]\tLoss: 0.093799\n",
      "Train Epoch: 7 [5760/15392 (37%)]\tLoss: 0.168318\n",
      "Train Epoch: 7 [6400/15392 (41%)]\tLoss: 0.033301\n",
      "Train Epoch: 7 [7040/15392 (46%)]\tLoss: 0.036772\n",
      "Train Epoch: 7 [7680/15392 (50%)]\tLoss: 0.108089\n",
      "Train Epoch: 7 [8320/15392 (54%)]\tLoss: 0.015109\n",
      "Train Epoch: 7 [8960/15392 (58%)]\tLoss: 0.034455\n",
      "Train Epoch: 7 [9600/15392 (62%)]\tLoss: 0.146003\n",
      "Train Epoch: 7 [10240/15392 (66%)]\tLoss: 0.239088\n",
      "Train Epoch: 7 [10880/15392 (71%)]\tLoss: 0.116610\n",
      "Train Epoch: 7 [11520/15392 (75%)]\tLoss: 0.108010\n",
      "Train Epoch: 7 [12160/15392 (79%)]\tLoss: 0.057672\n",
      "Train Epoch: 7 [12800/15392 (83%)]\tLoss: 0.147946\n",
      "Train Epoch: 7 [13440/15392 (87%)]\tLoss: 0.053909\n",
      "Train Epoch: 7 [14080/15392 (91%)]\tLoss: 0.045730\n",
      "Train Epoch: 7 [14720/15392 (95%)]\tLoss: 0.060247\n",
      "Train Epoch: 7 [7680/15392 (100%)]\tLoss: 0.040550\n",
      "Train Epoch: 8 [0/15392 (0%)]\tLoss: 0.054512\n",
      "Train Epoch: 8 [640/15392 (4%)]\tLoss: 0.026630\n",
      "Train Epoch: 8 [1280/15392 (8%)]\tLoss: 0.069586\n",
      "Train Epoch: 8 [1920/15392 (12%)]\tLoss: 0.145573\n",
      "Train Epoch: 8 [2560/15392 (17%)]\tLoss: 0.057449\n",
      "Train Epoch: 8 [3200/15392 (21%)]\tLoss: 0.076895\n",
      "Train Epoch: 8 [3840/15392 (25%)]\tLoss: 0.023332\n",
      "Train Epoch: 8 [4480/15392 (29%)]\tLoss: 0.038180\n",
      "Train Epoch: 8 [5120/15392 (33%)]\tLoss: 0.029862\n",
      "Train Epoch: 8 [5760/15392 (37%)]\tLoss: 0.111999\n",
      "Train Epoch: 8 [6400/15392 (41%)]\tLoss: 0.126964\n",
      "Train Epoch: 8 [7040/15392 (46%)]\tLoss: 0.036254\n",
      "Train Epoch: 8 [7680/15392 (50%)]\tLoss: 0.049674\n",
      "Train Epoch: 8 [8320/15392 (54%)]\tLoss: 0.118578\n",
      "Train Epoch: 8 [8960/15392 (58%)]\tLoss: 0.031635\n",
      "Train Epoch: 8 [9600/15392 (62%)]\tLoss: 0.110464\n",
      "Train Epoch: 8 [10240/15392 (66%)]\tLoss: 0.041835\n",
      "Train Epoch: 8 [10880/15392 (71%)]\tLoss: 0.037192\n",
      "Train Epoch: 8 [11520/15392 (75%)]\tLoss: 0.026674\n",
      "Train Epoch: 8 [12160/15392 (79%)]\tLoss: 0.079128\n",
      "Train Epoch: 8 [12800/15392 (83%)]\tLoss: 0.122851\n",
      "Train Epoch: 8 [13440/15392 (87%)]\tLoss: 0.037878\n",
      "Train Epoch: 8 [14080/15392 (91%)]\tLoss: 0.056720\n",
      "Train Epoch: 8 [14720/15392 (95%)]\tLoss: 0.071293\n",
      "Train Epoch: 8 [7680/15392 (100%)]\tLoss: 0.070460\n",
      "Train Epoch: 9 [0/15392 (0%)]\tLoss: 0.005670\n",
      "Train Epoch: 9 [640/15392 (4%)]\tLoss: 0.260671\n",
      "Train Epoch: 9 [1280/15392 (8%)]\tLoss: 0.028960\n",
      "Train Epoch: 9 [1920/15392 (12%)]\tLoss: 0.057440\n",
      "Train Epoch: 9 [2560/15392 (17%)]\tLoss: 0.023061\n",
      "Train Epoch: 9 [3200/15392 (21%)]\tLoss: 0.115846\n",
      "Train Epoch: 9 [3840/15392 (25%)]\tLoss: 0.057045\n",
      "Train Epoch: 9 [4480/15392 (29%)]\tLoss: 0.017524\n",
      "Train Epoch: 9 [5120/15392 (33%)]\tLoss: 0.040977\n",
      "Train Epoch: 9 [5760/15392 (37%)]\tLoss: 0.064407\n",
      "Train Epoch: 9 [6400/15392 (41%)]\tLoss: 0.026827\n",
      "Train Epoch: 9 [7040/15392 (46%)]\tLoss: 0.045776\n",
      "Train Epoch: 9 [7680/15392 (50%)]\tLoss: 0.096915\n",
      "Train Epoch: 9 [8320/15392 (54%)]\tLoss: 0.049554\n",
      "Train Epoch: 9 [8960/15392 (58%)]\tLoss: 0.027129\n",
      "Train Epoch: 9 [9600/15392 (62%)]\tLoss: 0.056095\n",
      "Train Epoch: 9 [10240/15392 (66%)]\tLoss: 0.110535\n",
      "Train Epoch: 9 [10880/15392 (71%)]\tLoss: 0.107342\n",
      "Train Epoch: 9 [11520/15392 (75%)]\tLoss: 0.098780\n",
      "Train Epoch: 9 [12160/15392 (79%)]\tLoss: 0.034726\n",
      "Train Epoch: 9 [12800/15392 (83%)]\tLoss: 0.110234\n",
      "Train Epoch: 9 [13440/15392 (87%)]\tLoss: 0.114694\n",
      "Train Epoch: 9 [14080/15392 (91%)]\tLoss: 0.048047\n",
      "Train Epoch: 9 [14720/15392 (95%)]\tLoss: 0.022814\n",
      "Train Epoch: 9 [7680/15392 (100%)]\tLoss: 0.053203\n",
      "Train Epoch: 10 [0/15392 (0%)]\tLoss: 0.060937\n",
      "Train Epoch: 10 [640/15392 (4%)]\tLoss: 0.047914\n",
      "Train Epoch: 10 [1280/15392 (8%)]\tLoss: 0.058273\n",
      "Train Epoch: 10 [1920/15392 (12%)]\tLoss: 0.100228\n",
      "Train Epoch: 10 [2560/15392 (17%)]\tLoss: 0.034730\n",
      "Train Epoch: 10 [3200/15392 (21%)]\tLoss: 0.014769\n",
      "Train Epoch: 10 [3840/15392 (25%)]\tLoss: 0.016761\n",
      "Train Epoch: 10 [4480/15392 (29%)]\tLoss: 0.106161\n",
      "Train Epoch: 10 [5120/15392 (33%)]\tLoss: 0.117099\n",
      "Train Epoch: 10 [5760/15392 (37%)]\tLoss: 0.011531\n",
      "Train Epoch: 10 [6400/15392 (41%)]\tLoss: 0.043432\n",
      "Train Epoch: 10 [7040/15392 (46%)]\tLoss: 0.022431\n",
      "Train Epoch: 10 [7680/15392 (50%)]\tLoss: 0.016005\n",
      "Train Epoch: 10 [8320/15392 (54%)]\tLoss: 0.049390\n",
      "Train Epoch: 10 [8960/15392 (58%)]\tLoss: 0.022542\n",
      "Train Epoch: 10 [9600/15392 (62%)]\tLoss: 0.066952\n",
      "Train Epoch: 10 [10240/15392 (66%)]\tLoss: 0.191917\n",
      "Train Epoch: 10 [10880/15392 (71%)]\tLoss: 0.027186\n",
      "Train Epoch: 10 [11520/15392 (75%)]\tLoss: 0.101244\n",
      "Train Epoch: 10 [12160/15392 (79%)]\tLoss: 0.128341\n",
      "Train Epoch: 10 [12800/15392 (83%)]\tLoss: 0.077111\n",
      "Train Epoch: 10 [13440/15392 (87%)]\tLoss: 0.103476\n",
      "Train Epoch: 10 [14080/15392 (91%)]\tLoss: 0.013011\n",
      "Train Epoch: 10 [14720/15392 (95%)]\tLoss: 0.078677\n",
      "Train Epoch: 10 [7680/15392 (100%)]\tLoss: 0.206068\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/15327 (0%)]\tLoss: 0.338420\n",
      "Train Epoch: 1 [640/15327 (4%)]\tLoss: 0.100205\n",
      "Train Epoch: 1 [1280/15327 (8%)]\tLoss: 0.225452\n",
      "Train Epoch: 1 [1920/15327 (12%)]\tLoss: 0.075568\n",
      "Train Epoch: 1 [2560/15327 (17%)]\tLoss: 0.168279\n",
      "Train Epoch: 1 [3200/15327 (21%)]\tLoss: 0.040254\n",
      "Train Epoch: 1 [3840/15327 (25%)]\tLoss: 0.072300\n",
      "Train Epoch: 1 [4480/15327 (29%)]\tLoss: 0.109443\n",
      "Train Epoch: 1 [5120/15327 (33%)]\tLoss: 0.080865\n",
      "Train Epoch: 1 [5760/15327 (38%)]\tLoss: 0.122826\n",
      "Train Epoch: 1 [6400/15327 (42%)]\tLoss: 0.033136\n",
      "Train Epoch: 1 [7040/15327 (46%)]\tLoss: 0.075417\n",
      "Train Epoch: 1 [7680/15327 (50%)]\tLoss: 0.094847\n",
      "Train Epoch: 1 [8320/15327 (54%)]\tLoss: 0.086877\n",
      "Train Epoch: 1 [8960/15327 (58%)]\tLoss: 0.105809\n",
      "Train Epoch: 1 [9600/15327 (62%)]\tLoss: 0.029668\n",
      "Train Epoch: 1 [10240/15327 (67%)]\tLoss: 0.099210\n",
      "Train Epoch: 1 [10880/15327 (71%)]\tLoss: 0.113702\n",
      "Train Epoch: 1 [11520/15327 (75%)]\tLoss: 0.033024\n",
      "Train Epoch: 1 [12160/15327 (79%)]\tLoss: 0.081237\n",
      "Train Epoch: 1 [12800/15327 (83%)]\tLoss: 0.175600\n",
      "Train Epoch: 1 [13440/15327 (88%)]\tLoss: 0.166176\n",
      "Train Epoch: 1 [14080/15327 (92%)]\tLoss: 0.077988\n",
      "Train Epoch: 1 [14720/15327 (96%)]\tLoss: 0.123202\n",
      "Train Epoch: 2 [0/15327 (0%)]\tLoss: 0.067255\n",
      "Train Epoch: 2 [640/15327 (4%)]\tLoss: 0.024330\n",
      "Train Epoch: 2 [1280/15327 (8%)]\tLoss: 0.036050\n",
      "Train Epoch: 2 [1920/15327 (12%)]\tLoss: 0.040532\n",
      "Train Epoch: 2 [2560/15327 (17%)]\tLoss: 0.159293\n",
      "Train Epoch: 2 [3200/15327 (21%)]\tLoss: 0.162920\n",
      "Train Epoch: 2 [3840/15327 (25%)]\tLoss: 0.132296\n",
      "Train Epoch: 2 [4480/15327 (29%)]\tLoss: 0.051807\n",
      "Train Epoch: 2 [5120/15327 (33%)]\tLoss: 0.098027\n",
      "Train Epoch: 2 [5760/15327 (38%)]\tLoss: 0.094048\n",
      "Train Epoch: 2 [6400/15327 (42%)]\tLoss: 0.070249\n",
      "Train Epoch: 2 [7040/15327 (46%)]\tLoss: 0.035173\n",
      "Train Epoch: 2 [7680/15327 (50%)]\tLoss: 0.102654\n",
      "Train Epoch: 2 [8320/15327 (54%)]\tLoss: 0.166294\n",
      "Train Epoch: 2 [8960/15327 (58%)]\tLoss: 0.234285\n",
      "Train Epoch: 2 [9600/15327 (62%)]\tLoss: 0.162917\n",
      "Train Epoch: 2 [10240/15327 (67%)]\tLoss: 0.123576\n",
      "Train Epoch: 2 [10880/15327 (71%)]\tLoss: 0.134902\n",
      "Train Epoch: 2 [11520/15327 (75%)]\tLoss: 0.106363\n",
      "Train Epoch: 2 [12160/15327 (79%)]\tLoss: 0.085214\n",
      "Train Epoch: 2 [12800/15327 (83%)]\tLoss: 0.049931\n",
      "Train Epoch: 2 [13440/15327 (88%)]\tLoss: 0.059614\n",
      "Train Epoch: 2 [14080/15327 (92%)]\tLoss: 0.104796\n",
      "Train Epoch: 2 [14720/15327 (96%)]\tLoss: 0.097023\n",
      "Train Epoch: 3 [0/15327 (0%)]\tLoss: 0.022432\n",
      "Train Epoch: 3 [640/15327 (4%)]\tLoss: 0.025629\n",
      "Train Epoch: 3 [1280/15327 (8%)]\tLoss: 0.045599\n",
      "Train Epoch: 3 [1920/15327 (12%)]\tLoss: 0.139975\n",
      "Train Epoch: 3 [2560/15327 (17%)]\tLoss: 0.134608\n",
      "Train Epoch: 3 [3200/15327 (21%)]\tLoss: 0.088441\n",
      "Train Epoch: 3 [3840/15327 (25%)]\tLoss: 0.303000\n",
      "Train Epoch: 3 [4480/15327 (29%)]\tLoss: 0.022069\n",
      "Train Epoch: 3 [5120/15327 (33%)]\tLoss: 0.070099\n",
      "Train Epoch: 3 [5760/15327 (38%)]\tLoss: 0.037740\n",
      "Train Epoch: 3 [6400/15327 (42%)]\tLoss: 0.035641\n",
      "Train Epoch: 3 [7040/15327 (46%)]\tLoss: 0.056477\n",
      "Train Epoch: 3 [7680/15327 (50%)]\tLoss: 0.009505\n",
      "Train Epoch: 3 [8320/15327 (54%)]\tLoss: 0.058941\n",
      "Train Epoch: 3 [8960/15327 (58%)]\tLoss: 0.027744\n",
      "Train Epoch: 3 [9600/15327 (62%)]\tLoss: 0.014596\n",
      "Train Epoch: 3 [10240/15327 (67%)]\tLoss: 0.043204\n",
      "Train Epoch: 3 [10880/15327 (71%)]\tLoss: 0.046500\n",
      "Train Epoch: 3 [11520/15327 (75%)]\tLoss: 0.102849\n",
      "Train Epoch: 3 [12160/15327 (79%)]\tLoss: 0.056371\n",
      "Train Epoch: 3 [12800/15327 (83%)]\tLoss: 0.100985\n",
      "Train Epoch: 3 [13440/15327 (88%)]\tLoss: 0.115219\n",
      "Train Epoch: 3 [14080/15327 (92%)]\tLoss: 0.056579\n",
      "Train Epoch: 3 [14720/15327 (96%)]\tLoss: 0.098388\n",
      "Train Epoch: 4 [0/15327 (0%)]\tLoss: 0.231544\n",
      "Train Epoch: 4 [640/15327 (4%)]\tLoss: 0.252528\n",
      "Train Epoch: 4 [1280/15327 (8%)]\tLoss: 0.040511\n",
      "Train Epoch: 4 [1920/15327 (12%)]\tLoss: 0.018282\n",
      "Train Epoch: 4 [2560/15327 (17%)]\tLoss: 0.111824\n",
      "Train Epoch: 4 [3200/15327 (21%)]\tLoss: 0.132508\n",
      "Train Epoch: 4 [3840/15327 (25%)]\tLoss: 0.035957\n",
      "Train Epoch: 4 [4480/15327 (29%)]\tLoss: 0.091591\n",
      "Train Epoch: 4 [5120/15327 (33%)]\tLoss: 0.057729\n",
      "Train Epoch: 4 [5760/15327 (38%)]\tLoss: 0.030127\n",
      "Train Epoch: 4 [6400/15327 (42%)]\tLoss: 0.045631\n",
      "Train Epoch: 4 [7040/15327 (46%)]\tLoss: 0.158998\n",
      "Train Epoch: 4 [7680/15327 (50%)]\tLoss: 0.105140\n",
      "Train Epoch: 4 [8320/15327 (54%)]\tLoss: 0.090723\n",
      "Train Epoch: 4 [8960/15327 (58%)]\tLoss: 0.063031\n",
      "Train Epoch: 4 [9600/15327 (62%)]\tLoss: 0.130256\n",
      "Train Epoch: 4 [10240/15327 (67%)]\tLoss: 0.069704\n",
      "Train Epoch: 4 [10880/15327 (71%)]\tLoss: 0.144550\n",
      "Train Epoch: 4 [11520/15327 (75%)]\tLoss: 0.062169\n",
      "Train Epoch: 4 [12160/15327 (79%)]\tLoss: 0.044299\n",
      "Train Epoch: 4 [12800/15327 (83%)]\tLoss: 0.072542\n",
      "Train Epoch: 4 [13440/15327 (88%)]\tLoss: 0.139244\n",
      "Train Epoch: 4 [14080/15327 (92%)]\tLoss: 0.075032\n",
      "Train Epoch: 4 [14720/15327 (96%)]\tLoss: 0.139333\n",
      "Train Epoch: 5 [0/15327 (0%)]\tLoss: 0.020114\n",
      "Train Epoch: 5 [640/15327 (4%)]\tLoss: 0.297363\n",
      "Train Epoch: 5 [1280/15327 (8%)]\tLoss: 0.100075\n",
      "Train Epoch: 5 [1920/15327 (12%)]\tLoss: 0.066720\n",
      "Train Epoch: 5 [2560/15327 (17%)]\tLoss: 0.056170\n",
      "Train Epoch: 5 [3200/15327 (21%)]\tLoss: 0.073836\n",
      "Train Epoch: 5 [3840/15327 (25%)]\tLoss: 0.048684\n",
      "Train Epoch: 5 [4480/15327 (29%)]\tLoss: 0.043460\n",
      "Train Epoch: 5 [5120/15327 (33%)]\tLoss: 0.053341\n",
      "Train Epoch: 5 [5760/15327 (38%)]\tLoss: 0.041992\n",
      "Train Epoch: 5 [6400/15327 (42%)]\tLoss: 0.019227\n",
      "Train Epoch: 5 [7040/15327 (46%)]\tLoss: 0.097699\n",
      "Train Epoch: 5 [7680/15327 (50%)]\tLoss: 0.058326\n",
      "Train Epoch: 5 [8320/15327 (54%)]\tLoss: 0.056243\n",
      "Train Epoch: 5 [8960/15327 (58%)]\tLoss: 0.034052\n",
      "Train Epoch: 5 [9600/15327 (62%)]\tLoss: 0.046834\n",
      "Train Epoch: 5 [10240/15327 (67%)]\tLoss: 0.035182\n",
      "Train Epoch: 5 [10880/15327 (71%)]\tLoss: 0.074402\n",
      "Train Epoch: 5 [11520/15327 (75%)]\tLoss: 0.055298\n",
      "Train Epoch: 5 [12160/15327 (79%)]\tLoss: 0.143610\n",
      "Train Epoch: 5 [12800/15327 (83%)]\tLoss: 0.153631\n",
      "Train Epoch: 5 [13440/15327 (88%)]\tLoss: 0.105171\n",
      "Train Epoch: 5 [14080/15327 (92%)]\tLoss: 0.017368\n",
      "Train Epoch: 5 [14720/15327 (96%)]\tLoss: 0.069728\n",
      "Train Epoch: 6 [0/15327 (0%)]\tLoss: 0.063073\n",
      "Train Epoch: 6 [640/15327 (4%)]\tLoss: 0.129848\n",
      "Train Epoch: 6 [1280/15327 (8%)]\tLoss: 0.140212\n",
      "Train Epoch: 6 [1920/15327 (12%)]\tLoss: 0.075753\n",
      "Train Epoch: 6 [2560/15327 (17%)]\tLoss: 0.024201\n",
      "Train Epoch: 6 [3200/15327 (21%)]\tLoss: 0.053603\n",
      "Train Epoch: 6 [3840/15327 (25%)]\tLoss: 0.040627\n",
      "Train Epoch: 6 [4480/15327 (29%)]\tLoss: 0.156870\n",
      "Train Epoch: 6 [5120/15327 (33%)]\tLoss: 0.167948\n",
      "Train Epoch: 6 [5760/15327 (38%)]\tLoss: 0.130338\n",
      "Train Epoch: 6 [6400/15327 (42%)]\tLoss: 0.067989\n",
      "Train Epoch: 6 [7040/15327 (46%)]\tLoss: 0.075174\n",
      "Train Epoch: 6 [7680/15327 (50%)]\tLoss: 0.127721\n",
      "Train Epoch: 6 [8320/15327 (54%)]\tLoss: 0.031134\n",
      "Train Epoch: 6 [8960/15327 (58%)]\tLoss: 0.083535\n",
      "Train Epoch: 6 [9600/15327 (62%)]\tLoss: 0.119254\n",
      "Train Epoch: 6 [10240/15327 (67%)]\tLoss: 0.027782\n",
      "Train Epoch: 6 [10880/15327 (71%)]\tLoss: 0.087822\n",
      "Train Epoch: 6 [11520/15327 (75%)]\tLoss: 0.077727\n",
      "Train Epoch: 6 [12160/15327 (79%)]\tLoss: 0.184390\n",
      "Train Epoch: 6 [12800/15327 (83%)]\tLoss: 0.064742\n",
      "Train Epoch: 6 [13440/15327 (88%)]\tLoss: 0.021866\n",
      "Train Epoch: 6 [14080/15327 (92%)]\tLoss: 0.049348\n",
      "Train Epoch: 6 [14720/15327 (96%)]\tLoss: 0.015095\n",
      "Train Epoch: 7 [0/15327 (0%)]\tLoss: 0.062091\n",
      "Train Epoch: 7 [640/15327 (4%)]\tLoss: 0.189474\n",
      "Train Epoch: 7 [1280/15327 (8%)]\tLoss: 0.057061\n",
      "Train Epoch: 7 [1920/15327 (12%)]\tLoss: 0.100148\n",
      "Train Epoch: 7 [2560/15327 (17%)]\tLoss: 0.058667\n",
      "Train Epoch: 7 [3200/15327 (21%)]\tLoss: 0.045724\n",
      "Train Epoch: 7 [3840/15327 (25%)]\tLoss: 0.013803\n",
      "Train Epoch: 7 [4480/15327 (29%)]\tLoss: 0.052032\n",
      "Train Epoch: 7 [5120/15327 (33%)]\tLoss: 0.027891\n",
      "Train Epoch: 7 [5760/15327 (38%)]\tLoss: 0.012580\n",
      "Train Epoch: 7 [6400/15327 (42%)]\tLoss: 0.049275\n",
      "Train Epoch: 7 [7040/15327 (46%)]\tLoss: 0.057283\n",
      "Train Epoch: 7 [7680/15327 (50%)]\tLoss: 0.055544\n",
      "Train Epoch: 7 [8320/15327 (54%)]\tLoss: 0.147879\n",
      "Train Epoch: 7 [8960/15327 (58%)]\tLoss: 0.044904\n",
      "Train Epoch: 7 [9600/15327 (62%)]\tLoss: 0.114688\n",
      "Train Epoch: 7 [10240/15327 (67%)]\tLoss: 0.475931\n",
      "Train Epoch: 7 [10880/15327 (71%)]\tLoss: 0.119526\n",
      "Train Epoch: 7 [11520/15327 (75%)]\tLoss: 0.025939\n",
      "Train Epoch: 7 [12160/15327 (79%)]\tLoss: 0.063159\n",
      "Train Epoch: 7 [12800/15327 (83%)]\tLoss: 0.094904\n",
      "Train Epoch: 7 [13440/15327 (88%)]\tLoss: 0.028686\n",
      "Train Epoch: 7 [14080/15327 (92%)]\tLoss: 0.092879\n",
      "Train Epoch: 7 [14720/15327 (96%)]\tLoss: 0.023766\n",
      "Train Epoch: 8 [0/15327 (0%)]\tLoss: 0.028281\n",
      "Train Epoch: 8 [640/15327 (4%)]\tLoss: 0.092951\n",
      "Train Epoch: 8 [1280/15327 (8%)]\tLoss: 0.143828\n",
      "Train Epoch: 8 [1920/15327 (12%)]\tLoss: 0.028205\n",
      "Train Epoch: 8 [2560/15327 (17%)]\tLoss: 0.027567\n",
      "Train Epoch: 8 [3200/15327 (21%)]\tLoss: 0.053091\n",
      "Train Epoch: 8 [3840/15327 (25%)]\tLoss: 0.074804\n",
      "Train Epoch: 8 [4480/15327 (29%)]\tLoss: 0.022128\n",
      "Train Epoch: 8 [5120/15327 (33%)]\tLoss: 0.059554\n",
      "Train Epoch: 8 [5760/15327 (38%)]\tLoss: 0.054840\n",
      "Train Epoch: 8 [6400/15327 (42%)]\tLoss: 0.063677\n",
      "Train Epoch: 8 [7040/15327 (46%)]\tLoss: 0.048740\n",
      "Train Epoch: 8 [7680/15327 (50%)]\tLoss: 0.074676\n",
      "Train Epoch: 8 [8320/15327 (54%)]\tLoss: 0.050187\n",
      "Train Epoch: 8 [8960/15327 (58%)]\tLoss: 0.044353\n",
      "Train Epoch: 8 [9600/15327 (62%)]\tLoss: 0.056985\n",
      "Train Epoch: 8 [10240/15327 (67%)]\tLoss: 0.098849\n",
      "Train Epoch: 8 [10880/15327 (71%)]\tLoss: 0.025013\n",
      "Train Epoch: 8 [11520/15327 (75%)]\tLoss: 0.060321\n",
      "Train Epoch: 8 [12160/15327 (79%)]\tLoss: 0.042057\n",
      "Train Epoch: 8 [12800/15327 (83%)]\tLoss: 0.073094\n",
      "Train Epoch: 8 [13440/15327 (88%)]\tLoss: 0.090660\n",
      "Train Epoch: 8 [14080/15327 (92%)]\tLoss: 0.082532\n",
      "Train Epoch: 8 [14720/15327 (96%)]\tLoss: 0.093290\n",
      "Train Epoch: 9 [0/15327 (0%)]\tLoss: 0.022099\n",
      "Train Epoch: 9 [640/15327 (4%)]\tLoss: 0.027261\n",
      "Train Epoch: 9 [1280/15327 (8%)]\tLoss: 0.030541\n",
      "Train Epoch: 9 [1920/15327 (12%)]\tLoss: 0.058732\n",
      "Train Epoch: 9 [2560/15327 (17%)]\tLoss: 0.048686\n",
      "Train Epoch: 9 [3200/15327 (21%)]\tLoss: 0.137107\n",
      "Train Epoch: 9 [3840/15327 (25%)]\tLoss: 0.062969\n",
      "Train Epoch: 9 [4480/15327 (29%)]\tLoss: 0.051709\n",
      "Train Epoch: 9 [5120/15327 (33%)]\tLoss: 0.080874\n",
      "Train Epoch: 9 [5760/15327 (38%)]\tLoss: 0.030301\n",
      "Train Epoch: 9 [6400/15327 (42%)]\tLoss: 0.040858\n",
      "Train Epoch: 9 [7040/15327 (46%)]\tLoss: 0.269159\n",
      "Train Epoch: 9 [7680/15327 (50%)]\tLoss: 0.034849\n",
      "Train Epoch: 9 [8320/15327 (54%)]\tLoss: 0.043942\n",
      "Train Epoch: 9 [8960/15327 (58%)]\tLoss: 0.032147\n",
      "Train Epoch: 9 [9600/15327 (62%)]\tLoss: 0.036119\n",
      "Train Epoch: 9 [10240/15327 (67%)]\tLoss: 0.048781\n",
      "Train Epoch: 9 [10880/15327 (71%)]\tLoss: 0.038474\n",
      "Train Epoch: 9 [11520/15327 (75%)]\tLoss: 0.130398\n",
      "Train Epoch: 9 [12160/15327 (79%)]\tLoss: 0.112744\n",
      "Train Epoch: 9 [12800/15327 (83%)]\tLoss: 0.154763\n",
      "Train Epoch: 9 [13440/15327 (88%)]\tLoss: 0.082165\n",
      "Train Epoch: 9 [14080/15327 (92%)]\tLoss: 0.114202\n",
      "Train Epoch: 9 [14720/15327 (96%)]\tLoss: 0.025397\n",
      "Train Epoch: 10 [0/15327 (0%)]\tLoss: 0.034176\n",
      "Train Epoch: 10 [640/15327 (4%)]\tLoss: 0.061561\n",
      "Train Epoch: 10 [1280/15327 (8%)]\tLoss: 0.020781\n",
      "Train Epoch: 10 [1920/15327 (12%)]\tLoss: 0.059513\n",
      "Train Epoch: 10 [2560/15327 (17%)]\tLoss: 0.081001\n",
      "Train Epoch: 10 [3200/15327 (21%)]\tLoss: 0.144006\n",
      "Train Epoch: 10 [3840/15327 (25%)]\tLoss: 0.043474\n",
      "Train Epoch: 10 [4480/15327 (29%)]\tLoss: 0.029257\n",
      "Train Epoch: 10 [5120/15327 (33%)]\tLoss: 0.039172\n",
      "Train Epoch: 10 [5760/15327 (38%)]\tLoss: 0.025423\n",
      "Train Epoch: 10 [6400/15327 (42%)]\tLoss: 0.194138\n",
      "Train Epoch: 10 [7040/15327 (46%)]\tLoss: 0.074964\n",
      "Train Epoch: 10 [7680/15327 (50%)]\tLoss: 0.235621\n",
      "Train Epoch: 10 [8320/15327 (54%)]\tLoss: 0.072859\n",
      "Train Epoch: 10 [8960/15327 (58%)]\tLoss: 0.037201\n",
      "Train Epoch: 10 [9600/15327 (62%)]\tLoss: 0.202348\n",
      "Train Epoch: 10 [10240/15327 (67%)]\tLoss: 0.084171\n",
      "Train Epoch: 10 [10880/15327 (71%)]\tLoss: 0.081609\n",
      "Train Epoch: 10 [11520/15327 (75%)]\tLoss: 0.160385\n",
      "Train Epoch: 10 [12160/15327 (79%)]\tLoss: 0.048632\n",
      "Train Epoch: 10 [12800/15327 (83%)]\tLoss: 0.163505\n",
      "Train Epoch: 10 [13440/15327 (88%)]\tLoss: 0.076980\n",
      "Train Epoch: 10 [14080/15327 (92%)]\tLoss: 0.088743\n",
      "Train Epoch: 10 [14720/15327 (96%)]\tLoss: 0.088703\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0567, Accuracy: 9819/10000 (98%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/18662 (0%)]\tLoss: 0.209593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [640/18662 (3%)]\tLoss: 0.038160\n",
      "Train Epoch: 1 [1280/18662 (7%)]\tLoss: 0.040569\n",
      "Train Epoch: 1 [1920/18662 (10%)]\tLoss: 0.028167\n",
      "Train Epoch: 1 [2560/18662 (14%)]\tLoss: 0.094809\n",
      "Train Epoch: 1 [3200/18662 (17%)]\tLoss: 0.065822\n",
      "Train Epoch: 1 [3840/18662 (21%)]\tLoss: 0.051706\n",
      "Train Epoch: 1 [4480/18662 (24%)]\tLoss: 0.042569\n",
      "Train Epoch: 1 [5120/18662 (27%)]\tLoss: 0.026668\n",
      "Train Epoch: 1 [5760/18662 (31%)]\tLoss: 0.171902\n",
      "Train Epoch: 1 [6400/18662 (34%)]\tLoss: 0.074271\n",
      "Train Epoch: 1 [7040/18662 (38%)]\tLoss: 0.103579\n",
      "Train Epoch: 1 [7680/18662 (41%)]\tLoss: 0.108176\n",
      "Train Epoch: 1 [8320/18662 (45%)]\tLoss: 0.020384\n",
      "Train Epoch: 1 [8960/18662 (48%)]\tLoss: 0.089042\n",
      "Train Epoch: 1 [9600/18662 (51%)]\tLoss: 0.131873\n",
      "Train Epoch: 1 [10240/18662 (55%)]\tLoss: 0.193767\n",
      "Train Epoch: 1 [10880/18662 (58%)]\tLoss: 0.086088\n",
      "Train Epoch: 1 [11520/18662 (62%)]\tLoss: 0.058328\n",
      "Train Epoch: 1 [12160/18662 (65%)]\tLoss: 0.125292\n",
      "Train Epoch: 1 [12800/18662 (68%)]\tLoss: 0.031078\n",
      "Train Epoch: 1 [13440/18662 (72%)]\tLoss: 0.033218\n",
      "Train Epoch: 1 [14080/18662 (75%)]\tLoss: 0.141119\n",
      "Train Epoch: 1 [14720/18662 (79%)]\tLoss: 0.293987\n",
      "Train Epoch: 1 [15360/18662 (82%)]\tLoss: 0.060663\n",
      "Train Epoch: 1 [16000/18662 (86%)]\tLoss: 0.165048\n",
      "Train Epoch: 1 [16640/18662 (89%)]\tLoss: 0.163433\n",
      "Train Epoch: 1 [17280/18662 (92%)]\tLoss: 0.033228\n",
      "Train Epoch: 1 [17920/18662 (96%)]\tLoss: 0.082250\n",
      "Train Epoch: 1 [18560/18662 (99%)]\tLoss: 0.311019\n",
      "Train Epoch: 2 [0/18662 (0%)]\tLoss: 0.074846\n",
      "Train Epoch: 2 [640/18662 (3%)]\tLoss: 0.068070\n",
      "Train Epoch: 2 [1280/18662 (7%)]\tLoss: 0.042148\n",
      "Train Epoch: 2 [1920/18662 (10%)]\tLoss: 0.038641\n",
      "Train Epoch: 2 [2560/18662 (14%)]\tLoss: 0.095726\n",
      "Train Epoch: 2 [3200/18662 (17%)]\tLoss: 0.056713\n",
      "Train Epoch: 2 [3840/18662 (21%)]\tLoss: 0.085592\n",
      "Train Epoch: 2 [4480/18662 (24%)]\tLoss: 0.152175\n",
      "Train Epoch: 2 [5120/18662 (27%)]\tLoss: 0.111209\n",
      "Train Epoch: 2 [5760/18662 (31%)]\tLoss: 0.211021\n",
      "Train Epoch: 2 [6400/18662 (34%)]\tLoss: 0.040963\n",
      "Train Epoch: 2 [7040/18662 (38%)]\tLoss: 0.249604\n",
      "Train Epoch: 2 [7680/18662 (41%)]\tLoss: 0.248582\n",
      "Train Epoch: 2 [8320/18662 (45%)]\tLoss: 0.085129\n",
      "Train Epoch: 2 [8960/18662 (48%)]\tLoss: 0.080081\n",
      "Train Epoch: 2 [9600/18662 (51%)]\tLoss: 0.022864\n",
      "Train Epoch: 2 [10240/18662 (55%)]\tLoss: 0.105159\n",
      "Train Epoch: 2 [10880/18662 (58%)]\tLoss: 0.057456\n",
      "Train Epoch: 2 [11520/18662 (62%)]\tLoss: 0.111477\n",
      "Train Epoch: 2 [12160/18662 (65%)]\tLoss: 0.131073\n",
      "Train Epoch: 2 [12800/18662 (68%)]\tLoss: 0.050052\n",
      "Train Epoch: 2 [13440/18662 (72%)]\tLoss: 0.088031\n",
      "Train Epoch: 2 [14080/18662 (75%)]\tLoss: 0.056847\n",
      "Train Epoch: 2 [14720/18662 (79%)]\tLoss: 0.042666\n",
      "Train Epoch: 2 [15360/18662 (82%)]\tLoss: 0.018876\n",
      "Train Epoch: 2 [16000/18662 (86%)]\tLoss: 0.135509\n",
      "Train Epoch: 2 [16640/18662 (89%)]\tLoss: 0.059409\n",
      "Train Epoch: 2 [17280/18662 (92%)]\tLoss: 0.090242\n",
      "Train Epoch: 2 [17920/18662 (96%)]\tLoss: 0.078219\n",
      "Train Epoch: 2 [18560/18662 (99%)]\tLoss: 0.069537\n",
      "Train Epoch: 3 [0/18662 (0%)]\tLoss: 0.089877\n",
      "Train Epoch: 3 [640/18662 (3%)]\tLoss: 0.018523\n",
      "Train Epoch: 3 [1280/18662 (7%)]\tLoss: 0.062098\n",
      "Train Epoch: 3 [1920/18662 (10%)]\tLoss: 0.044414\n",
      "Train Epoch: 3 [2560/18662 (14%)]\tLoss: 0.037598\n",
      "Train Epoch: 3 [3200/18662 (17%)]\tLoss: 0.078970\n",
      "Train Epoch: 3 [3840/18662 (21%)]\tLoss: 0.062653\n",
      "Train Epoch: 3 [4480/18662 (24%)]\tLoss: 0.040271\n",
      "Train Epoch: 3 [5120/18662 (27%)]\tLoss: 0.028253\n",
      "Train Epoch: 3 [5760/18662 (31%)]\tLoss: 0.064504\n",
      "Train Epoch: 3 [6400/18662 (34%)]\tLoss: 0.038704\n",
      "Train Epoch: 3 [7040/18662 (38%)]\tLoss: 0.052936\n",
      "Train Epoch: 3 [7680/18662 (41%)]\tLoss: 0.072796\n",
      "Train Epoch: 3 [8320/18662 (45%)]\tLoss: 0.099793\n",
      "Train Epoch: 3 [8960/18662 (48%)]\tLoss: 0.193070\n",
      "Train Epoch: 3 [9600/18662 (51%)]\tLoss: 0.073730\n",
      "Train Epoch: 3 [10240/18662 (55%)]\tLoss: 0.216306\n",
      "Train Epoch: 3 [10880/18662 (58%)]\tLoss: 0.125075\n",
      "Train Epoch: 3 [11520/18662 (62%)]\tLoss: 0.035133\n",
      "Train Epoch: 3 [12160/18662 (65%)]\tLoss: 0.107378\n",
      "Train Epoch: 3 [12800/18662 (68%)]\tLoss: 0.210965\n",
      "Train Epoch: 3 [13440/18662 (72%)]\tLoss: 0.042566\n",
      "Train Epoch: 3 [14080/18662 (75%)]\tLoss: 0.028880\n",
      "Train Epoch: 3 [14720/18662 (79%)]\tLoss: 0.042568\n",
      "Train Epoch: 3 [15360/18662 (82%)]\tLoss: 0.072154\n",
      "Train Epoch: 3 [16000/18662 (86%)]\tLoss: 0.035346\n",
      "Train Epoch: 3 [16640/18662 (89%)]\tLoss: 0.083286\n",
      "Train Epoch: 3 [17280/18662 (92%)]\tLoss: 0.040919\n",
      "Train Epoch: 3 [17920/18662 (96%)]\tLoss: 0.097855\n",
      "Train Epoch: 3 [18560/18662 (99%)]\tLoss: 0.092093\n",
      "Train Epoch: 4 [0/18662 (0%)]\tLoss: 0.029719\n",
      "Train Epoch: 4 [640/18662 (3%)]\tLoss: 0.038164\n",
      "Train Epoch: 4 [1280/18662 (7%)]\tLoss: 0.050256\n",
      "Train Epoch: 4 [1920/18662 (10%)]\tLoss: 0.159988\n",
      "Train Epoch: 4 [2560/18662 (14%)]\tLoss: 0.078231\n",
      "Train Epoch: 4 [3200/18662 (17%)]\tLoss: 0.045826\n",
      "Train Epoch: 4 [3840/18662 (21%)]\tLoss: 0.076399\n",
      "Train Epoch: 4 [4480/18662 (24%)]\tLoss: 0.014926\n",
      "Train Epoch: 4 [5120/18662 (27%)]\tLoss: 0.157871\n",
      "Train Epoch: 4 [5760/18662 (31%)]\tLoss: 0.118434\n",
      "Train Epoch: 4 [6400/18662 (34%)]\tLoss: 0.008882\n",
      "Train Epoch: 4 [7040/18662 (38%)]\tLoss: 0.172291\n",
      "Train Epoch: 4 [7680/18662 (41%)]\tLoss: 0.054455\n",
      "Train Epoch: 4 [8320/18662 (45%)]\tLoss: 0.073216\n",
      "Train Epoch: 4 [8960/18662 (48%)]\tLoss: 0.231268\n",
      "Train Epoch: 4 [9600/18662 (51%)]\tLoss: 0.013630\n",
      "Train Epoch: 4 [10240/18662 (55%)]\tLoss: 0.019028\n",
      "Train Epoch: 4 [10880/18662 (58%)]\tLoss: 0.051144\n",
      "Train Epoch: 4 [11520/18662 (62%)]\tLoss: 0.057737\n",
      "Train Epoch: 4 [12160/18662 (65%)]\tLoss: 0.081594\n",
      "Train Epoch: 4 [12800/18662 (68%)]\tLoss: 0.290302\n",
      "Train Epoch: 4 [13440/18662 (72%)]\tLoss: 0.026938\n",
      "Train Epoch: 4 [14080/18662 (75%)]\tLoss: 0.064842\n",
      "Train Epoch: 4 [14720/18662 (79%)]\tLoss: 0.070176\n",
      "Train Epoch: 4 [15360/18662 (82%)]\tLoss: 0.012276\n",
      "Train Epoch: 4 [16000/18662 (86%)]\tLoss: 0.044747\n",
      "Train Epoch: 4 [16640/18662 (89%)]\tLoss: 0.016273\n",
      "Train Epoch: 4 [17280/18662 (92%)]\tLoss: 0.084331\n",
      "Train Epoch: 4 [17920/18662 (96%)]\tLoss: 0.110169\n",
      "Train Epoch: 4 [18560/18662 (99%)]\tLoss: 0.086348\n",
      "Train Epoch: 5 [0/18662 (0%)]\tLoss: 0.073756\n",
      "Train Epoch: 5 [640/18662 (3%)]\tLoss: 0.032373\n",
      "Train Epoch: 5 [1280/18662 (7%)]\tLoss: 0.043405\n",
      "Train Epoch: 5 [1920/18662 (10%)]\tLoss: 0.026984\n",
      "Train Epoch: 5 [2560/18662 (14%)]\tLoss: 0.209935\n",
      "Train Epoch: 5 [3200/18662 (17%)]\tLoss: 0.047634\n",
      "Train Epoch: 5 [3840/18662 (21%)]\tLoss: 0.113022\n",
      "Train Epoch: 5 [4480/18662 (24%)]\tLoss: 0.060608\n",
      "Train Epoch: 5 [5120/18662 (27%)]\tLoss: 0.171550\n",
      "Train Epoch: 5 [5760/18662 (31%)]\tLoss: 0.038247\n",
      "Train Epoch: 5 [6400/18662 (34%)]\tLoss: 0.048108\n",
      "Train Epoch: 5 [7040/18662 (38%)]\tLoss: 0.083522\n",
      "Train Epoch: 5 [7680/18662 (41%)]\tLoss: 0.085310\n",
      "Train Epoch: 5 [8320/18662 (45%)]\tLoss: 0.063148\n",
      "Train Epoch: 5 [8960/18662 (48%)]\tLoss: 0.090047\n",
      "Train Epoch: 5 [9600/18662 (51%)]\tLoss: 0.096704\n",
      "Train Epoch: 5 [10240/18662 (55%)]\tLoss: 0.023147\n",
      "Train Epoch: 5 [10880/18662 (58%)]\tLoss: 0.052606\n",
      "Train Epoch: 5 [11520/18662 (62%)]\tLoss: 0.042912\n",
      "Train Epoch: 5 [12160/18662 (65%)]\tLoss: 0.152956\n",
      "Train Epoch: 5 [12800/18662 (68%)]\tLoss: 0.056396\n",
      "Train Epoch: 5 [13440/18662 (72%)]\tLoss: 0.086566\n",
      "Train Epoch: 5 [14080/18662 (75%)]\tLoss: 0.024758\n",
      "Train Epoch: 5 [14720/18662 (79%)]\tLoss: 0.072248\n",
      "Train Epoch: 5 [15360/18662 (82%)]\tLoss: 0.178354\n",
      "Train Epoch: 5 [16000/18662 (86%)]\tLoss: 0.142134\n",
      "Train Epoch: 5 [16640/18662 (89%)]\tLoss: 0.079052\n",
      "Train Epoch: 5 [17280/18662 (92%)]\tLoss: 0.143472\n",
      "Train Epoch: 5 [17920/18662 (96%)]\tLoss: 0.032415\n",
      "Train Epoch: 5 [18560/18662 (99%)]\tLoss: 0.125859\n",
      "Train Epoch: 6 [0/18662 (0%)]\tLoss: 0.034958\n",
      "Train Epoch: 6 [640/18662 (3%)]\tLoss: 0.105780\n",
      "Train Epoch: 6 [1280/18662 (7%)]\tLoss: 0.049323\n",
      "Train Epoch: 6 [1920/18662 (10%)]\tLoss: 0.071253\n",
      "Train Epoch: 6 [2560/18662 (14%)]\tLoss: 0.064520\n",
      "Train Epoch: 6 [3200/18662 (17%)]\tLoss: 0.052747\n",
      "Train Epoch: 6 [3840/18662 (21%)]\tLoss: 0.015836\n",
      "Train Epoch: 6 [4480/18662 (24%)]\tLoss: 0.099453\n",
      "Train Epoch: 6 [5120/18662 (27%)]\tLoss: 0.078255\n",
      "Train Epoch: 6 [5760/18662 (31%)]\tLoss: 0.106821\n",
      "Train Epoch: 6 [6400/18662 (34%)]\tLoss: 0.020419\n",
      "Train Epoch: 6 [7040/18662 (38%)]\tLoss: 0.134795\n",
      "Train Epoch: 6 [7680/18662 (41%)]\tLoss: 0.071334\n",
      "Train Epoch: 6 [8320/18662 (45%)]\tLoss: 0.210043\n",
      "Train Epoch: 6 [8960/18662 (48%)]\tLoss: 0.109445\n",
      "Train Epoch: 6 [9600/18662 (51%)]\tLoss: 0.081233\n",
      "Train Epoch: 6 [10240/18662 (55%)]\tLoss: 0.032558\n",
      "Train Epoch: 6 [10880/18662 (58%)]\tLoss: 0.050604\n",
      "Train Epoch: 6 [11520/18662 (62%)]\tLoss: 0.205856\n",
      "Train Epoch: 6 [12160/18662 (65%)]\tLoss: 0.077342\n",
      "Train Epoch: 6 [12800/18662 (68%)]\tLoss: 0.025330\n",
      "Train Epoch: 6 [13440/18662 (72%)]\tLoss: 0.072620\n",
      "Train Epoch: 6 [14080/18662 (75%)]\tLoss: 0.068469\n",
      "Train Epoch: 6 [14720/18662 (79%)]\tLoss: 0.053593\n",
      "Train Epoch: 6 [15360/18662 (82%)]\tLoss: 0.062530\n",
      "Train Epoch: 6 [16000/18662 (86%)]\tLoss: 0.043953\n",
      "Train Epoch: 6 [16640/18662 (89%)]\tLoss: 0.034182\n",
      "Train Epoch: 6 [17280/18662 (92%)]\tLoss: 0.156179\n",
      "Train Epoch: 6 [17920/18662 (96%)]\tLoss: 0.037441\n",
      "Train Epoch: 6 [18560/18662 (99%)]\tLoss: 0.052196\n",
      "Train Epoch: 7 [0/18662 (0%)]\tLoss: 0.058194\n",
      "Train Epoch: 7 [640/18662 (3%)]\tLoss: 0.059615\n",
      "Train Epoch: 7 [1280/18662 (7%)]\tLoss: 0.032315\n",
      "Train Epoch: 7 [1920/18662 (10%)]\tLoss: 0.074101\n",
      "Train Epoch: 7 [2560/18662 (14%)]\tLoss: 0.014323\n",
      "Train Epoch: 7 [3200/18662 (17%)]\tLoss: 0.055583\n",
      "Train Epoch: 7 [3840/18662 (21%)]\tLoss: 0.102762\n",
      "Train Epoch: 7 [4480/18662 (24%)]\tLoss: 0.103544\n",
      "Train Epoch: 7 [5120/18662 (27%)]\tLoss: 0.247157\n",
      "Train Epoch: 7 [5760/18662 (31%)]\tLoss: 0.021961\n",
      "Train Epoch: 7 [6400/18662 (34%)]\tLoss: 0.031728\n",
      "Train Epoch: 7 [7040/18662 (38%)]\tLoss: 0.039167\n",
      "Train Epoch: 7 [7680/18662 (41%)]\tLoss: 0.008093\n",
      "Train Epoch: 7 [8320/18662 (45%)]\tLoss: 0.059709\n",
      "Train Epoch: 7 [8960/18662 (48%)]\tLoss: 0.120370\n",
      "Train Epoch: 7 [9600/18662 (51%)]\tLoss: 0.071795\n",
      "Train Epoch: 7 [10240/18662 (55%)]\tLoss: 0.092273\n",
      "Train Epoch: 7 [10880/18662 (58%)]\tLoss: 0.011168\n",
      "Train Epoch: 7 [11520/18662 (62%)]\tLoss: 0.017615\n",
      "Train Epoch: 7 [12160/18662 (65%)]\tLoss: 0.038605\n",
      "Train Epoch: 7 [12800/18662 (68%)]\tLoss: 0.039108\n",
      "Train Epoch: 7 [13440/18662 (72%)]\tLoss: 0.063149\n",
      "Train Epoch: 7 [14080/18662 (75%)]\tLoss: 0.322392\n",
      "Train Epoch: 7 [14720/18662 (79%)]\tLoss: 0.112617\n",
      "Train Epoch: 7 [15360/18662 (82%)]\tLoss: 0.084638\n",
      "Train Epoch: 7 [16000/18662 (86%)]\tLoss: 0.015865\n",
      "Train Epoch: 7 [16640/18662 (89%)]\tLoss: 0.146901\n",
      "Train Epoch: 7 [17280/18662 (92%)]\tLoss: 0.043131\n",
      "Train Epoch: 7 [17920/18662 (96%)]\tLoss: 0.073979\n",
      "Train Epoch: 7 [18560/18662 (99%)]\tLoss: 0.070614\n",
      "Train Epoch: 8 [0/18662 (0%)]\tLoss: 0.064888\n",
      "Train Epoch: 8 [640/18662 (3%)]\tLoss: 0.080927\n",
      "Train Epoch: 8 [1280/18662 (7%)]\tLoss: 0.034501\n",
      "Train Epoch: 8 [1920/18662 (10%)]\tLoss: 0.041567\n",
      "Train Epoch: 8 [2560/18662 (14%)]\tLoss: 0.096042\n",
      "Train Epoch: 8 [3200/18662 (17%)]\tLoss: 0.012848\n",
      "Train Epoch: 8 [3840/18662 (21%)]\tLoss: 0.055851\n",
      "Train Epoch: 8 [4480/18662 (24%)]\tLoss: 0.059924\n",
      "Train Epoch: 8 [5120/18662 (27%)]\tLoss: 0.034640\n",
      "Train Epoch: 8 [5760/18662 (31%)]\tLoss: 0.045729\n",
      "Train Epoch: 8 [6400/18662 (34%)]\tLoss: 0.041302\n",
      "Train Epoch: 8 [7040/18662 (38%)]\tLoss: 0.120439\n",
      "Train Epoch: 8 [7680/18662 (41%)]\tLoss: 0.074568\n",
      "Train Epoch: 8 [8320/18662 (45%)]\tLoss: 0.057443\n",
      "Train Epoch: 8 [8960/18662 (48%)]\tLoss: 0.176761\n",
      "Train Epoch: 8 [9600/18662 (51%)]\tLoss: 0.048035\n",
      "Train Epoch: 8 [10240/18662 (55%)]\tLoss: 0.104787\n",
      "Train Epoch: 8 [10880/18662 (58%)]\tLoss: 0.103700\n",
      "Train Epoch: 8 [11520/18662 (62%)]\tLoss: 0.179410\n",
      "Train Epoch: 8 [12160/18662 (65%)]\tLoss: 0.073512\n",
      "Train Epoch: 8 [12800/18662 (68%)]\tLoss: 0.017575\n",
      "Train Epoch: 8 [13440/18662 (72%)]\tLoss: 0.115507\n",
      "Train Epoch: 8 [14080/18662 (75%)]\tLoss: 0.077636\n",
      "Train Epoch: 8 [14720/18662 (79%)]\tLoss: 0.073389\n",
      "Train Epoch: 8 [15360/18662 (82%)]\tLoss: 0.067858\n",
      "Train Epoch: 8 [16000/18662 (86%)]\tLoss: 0.060045\n",
      "Train Epoch: 8 [16640/18662 (89%)]\tLoss: 0.110718\n",
      "Train Epoch: 8 [17280/18662 (92%)]\tLoss: 0.114435\n",
      "Train Epoch: 8 [17920/18662 (96%)]\tLoss: 0.024606\n",
      "Train Epoch: 8 [18560/18662 (99%)]\tLoss: 0.057617\n",
      "Train Epoch: 9 [0/18662 (0%)]\tLoss: 0.080837\n",
      "Train Epoch: 9 [640/18662 (3%)]\tLoss: 0.026584\n",
      "Train Epoch: 9 [1280/18662 (7%)]\tLoss: 0.054992\n",
      "Train Epoch: 9 [1920/18662 (10%)]\tLoss: 0.105625\n",
      "Train Epoch: 9 [2560/18662 (14%)]\tLoss: 0.062094\n",
      "Train Epoch: 9 [3200/18662 (17%)]\tLoss: 0.049183\n",
      "Train Epoch: 9 [3840/18662 (21%)]\tLoss: 0.087672\n",
      "Train Epoch: 9 [4480/18662 (24%)]\tLoss: 0.048150\n",
      "Train Epoch: 9 [5120/18662 (27%)]\tLoss: 0.060722\n",
      "Train Epoch: 9 [5760/18662 (31%)]\tLoss: 0.081554\n",
      "Train Epoch: 9 [6400/18662 (34%)]\tLoss: 0.065990\n",
      "Train Epoch: 9 [7040/18662 (38%)]\tLoss: 0.042548\n",
      "Train Epoch: 9 [7680/18662 (41%)]\tLoss: 0.054716\n",
      "Train Epoch: 9 [8320/18662 (45%)]\tLoss: 0.025379\n",
      "Train Epoch: 9 [8960/18662 (48%)]\tLoss: 0.053245\n",
      "Train Epoch: 9 [9600/18662 (51%)]\tLoss: 0.029728\n",
      "Train Epoch: 9 [10240/18662 (55%)]\tLoss: 0.109926\n",
      "Train Epoch: 9 [10880/18662 (58%)]\tLoss: 0.036268\n",
      "Train Epoch: 9 [11520/18662 (62%)]\tLoss: 0.030629\n",
      "Train Epoch: 9 [12160/18662 (65%)]\tLoss: 0.068556\n",
      "Train Epoch: 9 [12800/18662 (68%)]\tLoss: 0.053189\n",
      "Train Epoch: 9 [13440/18662 (72%)]\tLoss: 0.104583\n",
      "Train Epoch: 9 [14080/18662 (75%)]\tLoss: 0.035980\n",
      "Train Epoch: 9 [14720/18662 (79%)]\tLoss: 0.052983\n",
      "Train Epoch: 9 [15360/18662 (82%)]\tLoss: 0.129742\n",
      "Train Epoch: 9 [16000/18662 (86%)]\tLoss: 0.108538\n",
      "Train Epoch: 9 [16640/18662 (89%)]\tLoss: 0.172102\n",
      "Train Epoch: 9 [17280/18662 (92%)]\tLoss: 0.040679\n",
      "Train Epoch: 9 [17920/18662 (96%)]\tLoss: 0.081712\n",
      "Train Epoch: 9 [18560/18662 (99%)]\tLoss: 0.114413\n",
      "Train Epoch: 10 [0/18662 (0%)]\tLoss: 0.035313\n",
      "Train Epoch: 10 [640/18662 (3%)]\tLoss: 0.046188\n",
      "Train Epoch: 10 [1280/18662 (7%)]\tLoss: 0.013610\n",
      "Train Epoch: 10 [1920/18662 (10%)]\tLoss: 0.065949\n",
      "Train Epoch: 10 [2560/18662 (14%)]\tLoss: 0.014437\n",
      "Train Epoch: 10 [3200/18662 (17%)]\tLoss: 0.113740\n",
      "Train Epoch: 10 [3840/18662 (21%)]\tLoss: 0.079521\n",
      "Train Epoch: 10 [4480/18662 (24%)]\tLoss: 0.029405\n",
      "Train Epoch: 10 [5120/18662 (27%)]\tLoss: 0.037264\n",
      "Train Epoch: 10 [5760/18662 (31%)]\tLoss: 0.052789\n",
      "Train Epoch: 10 [6400/18662 (34%)]\tLoss: 0.070041\n",
      "Train Epoch: 10 [7040/18662 (38%)]\tLoss: 0.079077\n",
      "Train Epoch: 10 [7680/18662 (41%)]\tLoss: 0.102252\n",
      "Train Epoch: 10 [8320/18662 (45%)]\tLoss: 0.027842\n",
      "Train Epoch: 10 [8960/18662 (48%)]\tLoss: 0.104511\n",
      "Train Epoch: 10 [9600/18662 (51%)]\tLoss: 0.017970\n",
      "Train Epoch: 10 [10240/18662 (55%)]\tLoss: 0.131091\n",
      "Train Epoch: 10 [10880/18662 (58%)]\tLoss: 0.077858\n",
      "Train Epoch: 10 [11520/18662 (62%)]\tLoss: 0.057123\n",
      "Train Epoch: 10 [12160/18662 (65%)]\tLoss: 0.058220\n",
      "Train Epoch: 10 [12800/18662 (68%)]\tLoss: 0.022235\n",
      "Train Epoch: 10 [13440/18662 (72%)]\tLoss: 0.120315\n",
      "Train Epoch: 10 [14080/18662 (75%)]\tLoss: 0.118108\n",
      "Train Epoch: 10 [14720/18662 (79%)]\tLoss: 0.066158\n",
      "Train Epoch: 10 [15360/18662 (82%)]\tLoss: 0.035011\n",
      "Train Epoch: 10 [16000/18662 (86%)]\tLoss: 0.191970\n",
      "Train Epoch: 10 [16640/18662 (89%)]\tLoss: 0.112790\n",
      "Train Epoch: 10 [17280/18662 (92%)]\tLoss: 0.034271\n",
      "Train Epoch: 10 [17920/18662 (96%)]\tLoss: 0.013190\n",
      "Train Epoch: 10 [18560/18662 (99%)]\tLoss: 0.166396\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/10619 (0%)]\tLoss: 0.212753\n",
      "Train Epoch: 1 [640/10619 (6%)]\tLoss: 0.063707\n",
      "Train Epoch: 1 [1280/10619 (12%)]\tLoss: 0.321285\n",
      "Train Epoch: 1 [1920/10619 (18%)]\tLoss: 0.139979\n",
      "Train Epoch: 1 [2560/10619 (24%)]\tLoss: 0.092940\n",
      "Train Epoch: 1 [3200/10619 (30%)]\tLoss: 0.122779\n",
      "Train Epoch: 1 [3840/10619 (36%)]\tLoss: 0.030706\n",
      "Train Epoch: 1 [4480/10619 (42%)]\tLoss: 0.045784\n",
      "Train Epoch: 1 [5120/10619 (48%)]\tLoss: 0.113816\n",
      "Train Epoch: 1 [5760/10619 (54%)]\tLoss: 0.077260\n",
      "Train Epoch: 1 [6400/10619 (60%)]\tLoss: 0.082561\n",
      "Train Epoch: 1 [7040/10619 (66%)]\tLoss: 0.013107\n",
      "Train Epoch: 1 [7680/10619 (72%)]\tLoss: 0.211954\n",
      "Train Epoch: 1 [8320/10619 (78%)]\tLoss: 0.097467\n",
      "Train Epoch: 1 [8960/10619 (84%)]\tLoss: 0.130328\n",
      "Train Epoch: 1 [9600/10619 (90%)]\tLoss: 0.099969\n",
      "Train Epoch: 1 [10240/10619 (96%)]\tLoss: 0.214953\n",
      "Train Epoch: 2 [0/10619 (0%)]\tLoss: 0.130720\n",
      "Train Epoch: 2 [640/10619 (6%)]\tLoss: 0.048327\n",
      "Train Epoch: 2 [1280/10619 (12%)]\tLoss: 0.126717\n",
      "Train Epoch: 2 [1920/10619 (18%)]\tLoss: 0.118660\n",
      "Train Epoch: 2 [2560/10619 (24%)]\tLoss: 0.061176\n",
      "Train Epoch: 2 [3200/10619 (30%)]\tLoss: 0.055410\n",
      "Train Epoch: 2 [3840/10619 (36%)]\tLoss: 0.111051\n",
      "Train Epoch: 2 [4480/10619 (42%)]\tLoss: 0.104725\n",
      "Train Epoch: 2 [5120/10619 (48%)]\tLoss: 0.190428\n",
      "Train Epoch: 2 [5760/10619 (54%)]\tLoss: 0.171833\n",
      "Train Epoch: 2 [6400/10619 (60%)]\tLoss: 0.077878\n",
      "Train Epoch: 2 [7040/10619 (66%)]\tLoss: 0.099514\n",
      "Train Epoch: 2 [7680/10619 (72%)]\tLoss: 0.086962\n",
      "Train Epoch: 2 [8320/10619 (78%)]\tLoss: 0.073472\n",
      "Train Epoch: 2 [8960/10619 (84%)]\tLoss: 0.084212\n",
      "Train Epoch: 2 [9600/10619 (90%)]\tLoss: 0.107251\n",
      "Train Epoch: 2 [10240/10619 (96%)]\tLoss: 0.162145\n",
      "Train Epoch: 3 [0/10619 (0%)]\tLoss: 0.260798\n",
      "Train Epoch: 3 [640/10619 (6%)]\tLoss: 0.293367\n",
      "Train Epoch: 3 [1280/10619 (12%)]\tLoss: 0.099740\n",
      "Train Epoch: 3 [1920/10619 (18%)]\tLoss: 0.058886\n",
      "Train Epoch: 3 [2560/10619 (24%)]\tLoss: 0.094431\n",
      "Train Epoch: 3 [3200/10619 (30%)]\tLoss: 0.162621\n",
      "Train Epoch: 3 [3840/10619 (36%)]\tLoss: 0.172129\n",
      "Train Epoch: 3 [4480/10619 (42%)]\tLoss: 0.112474\n",
      "Train Epoch: 3 [5120/10619 (48%)]\tLoss: 0.043895\n",
      "Train Epoch: 3 [5760/10619 (54%)]\tLoss: 0.044494\n",
      "Train Epoch: 3 [6400/10619 (60%)]\tLoss: 0.081882\n",
      "Train Epoch: 3 [7040/10619 (66%)]\tLoss: 0.033568\n",
      "Train Epoch: 3 [7680/10619 (72%)]\tLoss: 0.051053\n",
      "Train Epoch: 3 [8320/10619 (78%)]\tLoss: 0.107685\n",
      "Train Epoch: 3 [8960/10619 (84%)]\tLoss: 0.132387\n",
      "Train Epoch: 3 [9600/10619 (90%)]\tLoss: 0.142825\n",
      "Train Epoch: 3 [10240/10619 (96%)]\tLoss: 0.076272\n",
      "Train Epoch: 4 [0/10619 (0%)]\tLoss: 0.060057\n",
      "Train Epoch: 4 [640/10619 (6%)]\tLoss: 0.192910\n",
      "Train Epoch: 4 [1280/10619 (12%)]\tLoss: 0.093839\n",
      "Train Epoch: 4 [1920/10619 (18%)]\tLoss: 0.173752\n",
      "Train Epoch: 4 [2560/10619 (24%)]\tLoss: 0.096448\n",
      "Train Epoch: 4 [3200/10619 (30%)]\tLoss: 0.110579\n",
      "Train Epoch: 4 [3840/10619 (36%)]\tLoss: 0.052422\n",
      "Train Epoch: 4 [4480/10619 (42%)]\tLoss: 0.054645\n",
      "Train Epoch: 4 [5120/10619 (48%)]\tLoss: 0.184507\n",
      "Train Epoch: 4 [5760/10619 (54%)]\tLoss: 0.083469\n",
      "Train Epoch: 4 [6400/10619 (60%)]\tLoss: 0.030345\n",
      "Train Epoch: 4 [7040/10619 (66%)]\tLoss: 0.174826\n",
      "Train Epoch: 4 [7680/10619 (72%)]\tLoss: 0.084414\n",
      "Train Epoch: 4 [8320/10619 (78%)]\tLoss: 0.077332\n",
      "Train Epoch: 4 [8960/10619 (84%)]\tLoss: 0.148114\n",
      "Train Epoch: 4 [9600/10619 (90%)]\tLoss: 0.060833\n",
      "Train Epoch: 4 [10240/10619 (96%)]\tLoss: 0.138704\n",
      "Train Epoch: 5 [0/10619 (0%)]\tLoss: 0.011662\n",
      "Train Epoch: 5 [640/10619 (6%)]\tLoss: 0.049705\n",
      "Train Epoch: 5 [1280/10619 (12%)]\tLoss: 0.200541\n",
      "Train Epoch: 5 [1920/10619 (18%)]\tLoss: 0.092022\n",
      "Train Epoch: 5 [2560/10619 (24%)]\tLoss: 0.108305\n",
      "Train Epoch: 5 [3200/10619 (30%)]\tLoss: 0.101246\n",
      "Train Epoch: 5 [3840/10619 (36%)]\tLoss: 0.044431\n",
      "Train Epoch: 5 [4480/10619 (42%)]\tLoss: 0.195909\n",
      "Train Epoch: 5 [5120/10619 (48%)]\tLoss: 0.047771\n",
      "Train Epoch: 5 [5760/10619 (54%)]\tLoss: 0.174938\n",
      "Train Epoch: 5 [6400/10619 (60%)]\tLoss: 0.038344\n",
      "Train Epoch: 5 [7040/10619 (66%)]\tLoss: 0.120496\n",
      "Train Epoch: 5 [7680/10619 (72%)]\tLoss: 0.091567\n",
      "Train Epoch: 5 [8320/10619 (78%)]\tLoss: 0.040383\n",
      "Train Epoch: 5 [8960/10619 (84%)]\tLoss: 0.096349\n",
      "Train Epoch: 5 [9600/10619 (90%)]\tLoss: 0.087840\n",
      "Train Epoch: 5 [10240/10619 (96%)]\tLoss: 0.045173\n",
      "Train Epoch: 6 [0/10619 (0%)]\tLoss: 0.067966\n",
      "Train Epoch: 6 [640/10619 (6%)]\tLoss: 0.116970\n",
      "Train Epoch: 6 [1280/10619 (12%)]\tLoss: 0.094924\n",
      "Train Epoch: 6 [1920/10619 (18%)]\tLoss: 0.048771\n",
      "Train Epoch: 6 [2560/10619 (24%)]\tLoss: 0.160382\n",
      "Train Epoch: 6 [3200/10619 (30%)]\tLoss: 0.019395\n",
      "Train Epoch: 6 [3840/10619 (36%)]\tLoss: 0.064856\n",
      "Train Epoch: 6 [4480/10619 (42%)]\tLoss: 0.077620\n",
      "Train Epoch: 6 [5120/10619 (48%)]\tLoss: 0.090755\n",
      "Train Epoch: 6 [5760/10619 (54%)]\tLoss: 0.174540\n",
      "Train Epoch: 6 [6400/10619 (60%)]\tLoss: 0.076084\n",
      "Train Epoch: 6 [7040/10619 (66%)]\tLoss: 0.042386\n",
      "Train Epoch: 6 [7680/10619 (72%)]\tLoss: 0.044781\n",
      "Train Epoch: 6 [8320/10619 (78%)]\tLoss: 0.179319\n",
      "Train Epoch: 6 [8960/10619 (84%)]\tLoss: 0.058072\n",
      "Train Epoch: 6 [9600/10619 (90%)]\tLoss: 0.018001\n",
      "Train Epoch: 6 [10240/10619 (96%)]\tLoss: 0.056379\n",
      "Train Epoch: 7 [0/10619 (0%)]\tLoss: 0.022042\n",
      "Train Epoch: 7 [640/10619 (6%)]\tLoss: 0.218077\n",
      "Train Epoch: 7 [1280/10619 (12%)]\tLoss: 0.031243\n",
      "Train Epoch: 7 [1920/10619 (18%)]\tLoss: 0.044252\n",
      "Train Epoch: 7 [2560/10619 (24%)]\tLoss: 0.011233\n",
      "Train Epoch: 7 [3200/10619 (30%)]\tLoss: 0.052101\n",
      "Train Epoch: 7 [3840/10619 (36%)]\tLoss: 0.066843\n",
      "Train Epoch: 7 [4480/10619 (42%)]\tLoss: 0.192976\n",
      "Train Epoch: 7 [5120/10619 (48%)]\tLoss: 0.091834\n",
      "Train Epoch: 7 [5760/10619 (54%)]\tLoss: 0.039650\n",
      "Train Epoch: 7 [6400/10619 (60%)]\tLoss: 0.069736\n",
      "Train Epoch: 7 [7040/10619 (66%)]\tLoss: 0.122258\n",
      "Train Epoch: 7 [7680/10619 (72%)]\tLoss: 0.068115\n",
      "Train Epoch: 7 [8320/10619 (78%)]\tLoss: 0.027560\n",
      "Train Epoch: 7 [8960/10619 (84%)]\tLoss: 0.076027\n",
      "Train Epoch: 7 [9600/10619 (90%)]\tLoss: 0.068936\n",
      "Train Epoch: 7 [10240/10619 (96%)]\tLoss: 0.022097\n",
      "Train Epoch: 8 [0/10619 (0%)]\tLoss: 0.148614\n",
      "Train Epoch: 8 [640/10619 (6%)]\tLoss: 0.020755\n",
      "Train Epoch: 8 [1280/10619 (12%)]\tLoss: 0.158302\n",
      "Train Epoch: 8 [1920/10619 (18%)]\tLoss: 0.062284\n",
      "Train Epoch: 8 [2560/10619 (24%)]\tLoss: 0.222272\n",
      "Train Epoch: 8 [3200/10619 (30%)]\tLoss: 0.018052\n",
      "Train Epoch: 8 [3840/10619 (36%)]\tLoss: 0.172324\n",
      "Train Epoch: 8 [4480/10619 (42%)]\tLoss: 0.075717\n",
      "Train Epoch: 8 [5120/10619 (48%)]\tLoss: 0.060184\n",
      "Train Epoch: 8 [5760/10619 (54%)]\tLoss: 0.136978\n",
      "Train Epoch: 8 [6400/10619 (60%)]\tLoss: 0.087544\n",
      "Train Epoch: 8 [7040/10619 (66%)]\tLoss: 0.063477\n",
      "Train Epoch: 8 [7680/10619 (72%)]\tLoss: 0.069703\n",
      "Train Epoch: 8 [8320/10619 (78%)]\tLoss: 0.029250\n",
      "Train Epoch: 8 [8960/10619 (84%)]\tLoss: 0.041743\n",
      "Train Epoch: 8 [9600/10619 (90%)]\tLoss: 0.087547\n",
      "Train Epoch: 8 [10240/10619 (96%)]\tLoss: 0.078916\n",
      "Train Epoch: 9 [0/10619 (0%)]\tLoss: 0.295528\n",
      "Train Epoch: 9 [640/10619 (6%)]\tLoss: 0.048792\n",
      "Train Epoch: 9 [1280/10619 (12%)]\tLoss: 0.029654\n",
      "Train Epoch: 9 [1920/10619 (18%)]\tLoss: 0.064569\n",
      "Train Epoch: 9 [2560/10619 (24%)]\tLoss: 0.070181\n",
      "Train Epoch: 9 [3200/10619 (30%)]\tLoss: 0.019193\n",
      "Train Epoch: 9 [3840/10619 (36%)]\tLoss: 0.113103\n",
      "Train Epoch: 9 [4480/10619 (42%)]\tLoss: 0.035350\n",
      "Train Epoch: 9 [5120/10619 (48%)]\tLoss: 0.061165\n",
      "Train Epoch: 9 [5760/10619 (54%)]\tLoss: 0.109135\n",
      "Train Epoch: 9 [6400/10619 (60%)]\tLoss: 0.039820\n",
      "Train Epoch: 9 [7040/10619 (66%)]\tLoss: 0.020841\n",
      "Train Epoch: 9 [7680/10619 (72%)]\tLoss: 0.134383\n",
      "Train Epoch: 9 [8320/10619 (78%)]\tLoss: 0.088253\n",
      "Train Epoch: 9 [8960/10619 (84%)]\tLoss: 0.067675\n",
      "Train Epoch: 9 [9600/10619 (90%)]\tLoss: 0.117485\n",
      "Train Epoch: 9 [10240/10619 (96%)]\tLoss: 0.007761\n",
      "Train Epoch: 10 [0/10619 (0%)]\tLoss: 0.048076\n",
      "Train Epoch: 10 [640/10619 (6%)]\tLoss: 0.007197\n",
      "Train Epoch: 10 [1280/10619 (12%)]\tLoss: 0.074549\n",
      "Train Epoch: 10 [1920/10619 (18%)]\tLoss: 0.035012\n",
      "Train Epoch: 10 [2560/10619 (24%)]\tLoss: 0.035664\n",
      "Train Epoch: 10 [3200/10619 (30%)]\tLoss: 0.130733\n",
      "Train Epoch: 10 [3840/10619 (36%)]\tLoss: 0.033823\n",
      "Train Epoch: 10 [4480/10619 (42%)]\tLoss: 0.145686\n",
      "Train Epoch: 10 [5120/10619 (48%)]\tLoss: 0.048850\n",
      "Train Epoch: 10 [5760/10619 (54%)]\tLoss: 0.091640\n",
      "Train Epoch: 10 [6400/10619 (60%)]\tLoss: 0.021069\n",
      "Train Epoch: 10 [7040/10619 (66%)]\tLoss: 0.062571\n",
      "Train Epoch: 10 [7680/10619 (72%)]\tLoss: 0.037406\n",
      "Train Epoch: 10 [8320/10619 (78%)]\tLoss: 0.221629\n",
      "Train Epoch: 10 [8960/10619 (84%)]\tLoss: 0.037390\n",
      "Train Epoch: 10 [9600/10619 (90%)]\tLoss: 0.029908\n",
      "Train Epoch: 10 [10240/10619 (96%)]\tLoss: 0.065805\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/15392 (0%)]\tLoss: 0.077538\n",
      "Train Epoch: 1 [640/15392 (4%)]\tLoss: 0.058751\n",
      "Train Epoch: 1 [1280/15392 (8%)]\tLoss: 0.121766\n",
      "Train Epoch: 1 [1920/15392 (12%)]\tLoss: 0.086752\n",
      "Train Epoch: 1 [2560/15392 (17%)]\tLoss: 0.057183\n",
      "Train Epoch: 1 [3200/15392 (21%)]\tLoss: 0.078952\n",
      "Train Epoch: 1 [3840/15392 (25%)]\tLoss: 0.074901\n",
      "Train Epoch: 1 [4480/15392 (29%)]\tLoss: 0.023153\n",
      "Train Epoch: 1 [5120/15392 (33%)]\tLoss: 0.079928\n",
      "Train Epoch: 1 [5760/15392 (37%)]\tLoss: 0.117061\n",
      "Train Epoch: 1 [6400/15392 (41%)]\tLoss: 0.009291\n",
      "Train Epoch: 1 [7040/15392 (46%)]\tLoss: 0.061014\n",
      "Train Epoch: 1 [7680/15392 (50%)]\tLoss: 0.084920\n",
      "Train Epoch: 1 [8320/15392 (54%)]\tLoss: 0.054628\n",
      "Train Epoch: 1 [8960/15392 (58%)]\tLoss: 0.237857\n",
      "Train Epoch: 1 [9600/15392 (62%)]\tLoss: 0.031180\n",
      "Train Epoch: 1 [10240/15392 (66%)]\tLoss: 0.138552\n",
      "Train Epoch: 1 [10880/15392 (71%)]\tLoss: 0.235240\n",
      "Train Epoch: 1 [11520/15392 (75%)]\tLoss: 0.069317\n",
      "Train Epoch: 1 [12160/15392 (79%)]\tLoss: 0.102186\n",
      "Train Epoch: 1 [12800/15392 (83%)]\tLoss: 0.238232\n",
      "Train Epoch: 1 [13440/15392 (87%)]\tLoss: 0.049523\n",
      "Train Epoch: 1 [14080/15392 (91%)]\tLoss: 0.023026\n",
      "Train Epoch: 1 [14720/15392 (95%)]\tLoss: 0.195691\n",
      "Train Epoch: 1 [7680/15392 (100%)]\tLoss: 0.048137\n",
      "Train Epoch: 2 [0/15392 (0%)]\tLoss: 0.094293\n",
      "Train Epoch: 2 [640/15392 (4%)]\tLoss: 0.043047\n",
      "Train Epoch: 2 [1280/15392 (8%)]\tLoss: 0.057548\n",
      "Train Epoch: 2 [1920/15392 (12%)]\tLoss: 0.047100\n",
      "Train Epoch: 2 [2560/15392 (17%)]\tLoss: 0.051471\n",
      "Train Epoch: 2 [3200/15392 (21%)]\tLoss: 0.039316\n",
      "Train Epoch: 2 [3840/15392 (25%)]\tLoss: 0.028246\n",
      "Train Epoch: 2 [4480/15392 (29%)]\tLoss: 0.048163\n",
      "Train Epoch: 2 [5120/15392 (33%)]\tLoss: 0.081658\n",
      "Train Epoch: 2 [5760/15392 (37%)]\tLoss: 0.129801\n",
      "Train Epoch: 2 [6400/15392 (41%)]\tLoss: 0.171741\n",
      "Train Epoch: 2 [7040/15392 (46%)]\tLoss: 0.023215\n",
      "Train Epoch: 2 [7680/15392 (50%)]\tLoss: 0.081799\n",
      "Train Epoch: 2 [8320/15392 (54%)]\tLoss: 0.098604\n",
      "Train Epoch: 2 [8960/15392 (58%)]\tLoss: 0.219382\n",
      "Train Epoch: 2 [9600/15392 (62%)]\tLoss: 0.246755\n",
      "Train Epoch: 2 [10240/15392 (66%)]\tLoss: 0.069959\n",
      "Train Epoch: 2 [10880/15392 (71%)]\tLoss: 0.029810\n",
      "Train Epoch: 2 [11520/15392 (75%)]\tLoss: 0.019702\n",
      "Train Epoch: 2 [12160/15392 (79%)]\tLoss: 0.047504\n",
      "Train Epoch: 2 [12800/15392 (83%)]\tLoss: 0.012469\n",
      "Train Epoch: 2 [13440/15392 (87%)]\tLoss: 0.042417\n",
      "Train Epoch: 2 [14080/15392 (91%)]\tLoss: 0.053615\n",
      "Train Epoch: 2 [14720/15392 (95%)]\tLoss: 0.116766\n",
      "Train Epoch: 2 [7680/15392 (100%)]\tLoss: 0.019714\n",
      "Train Epoch: 3 [0/15392 (0%)]\tLoss: 0.017465\n",
      "Train Epoch: 3 [640/15392 (4%)]\tLoss: 0.249807\n",
      "Train Epoch: 3 [1280/15392 (8%)]\tLoss: 0.084544\n",
      "Train Epoch: 3 [1920/15392 (12%)]\tLoss: 0.049823\n",
      "Train Epoch: 3 [2560/15392 (17%)]\tLoss: 0.091115\n",
      "Train Epoch: 3 [3200/15392 (21%)]\tLoss: 0.047127\n",
      "Train Epoch: 3 [3840/15392 (25%)]\tLoss: 0.053836\n",
      "Train Epoch: 3 [4480/15392 (29%)]\tLoss: 0.075915\n",
      "Train Epoch: 3 [5120/15392 (33%)]\tLoss: 0.127272\n",
      "Train Epoch: 3 [5760/15392 (37%)]\tLoss: 0.070092\n",
      "Train Epoch: 3 [6400/15392 (41%)]\tLoss: 0.029991\n",
      "Train Epoch: 3 [7040/15392 (46%)]\tLoss: 0.093489\n",
      "Train Epoch: 3 [7680/15392 (50%)]\tLoss: 0.014302\n",
      "Train Epoch: 3 [8320/15392 (54%)]\tLoss: 0.069661\n",
      "Train Epoch: 3 [8960/15392 (58%)]\tLoss: 0.073555\n",
      "Train Epoch: 3 [9600/15392 (62%)]\tLoss: 0.098525\n",
      "Train Epoch: 3 [10240/15392 (66%)]\tLoss: 0.034635\n",
      "Train Epoch: 3 [10880/15392 (71%)]\tLoss: 0.085373\n",
      "Train Epoch: 3 [11520/15392 (75%)]\tLoss: 0.075338\n",
      "Train Epoch: 3 [12160/15392 (79%)]\tLoss: 0.073230\n",
      "Train Epoch: 3 [12800/15392 (83%)]\tLoss: 0.016938\n",
      "Train Epoch: 3 [13440/15392 (87%)]\tLoss: 0.070591\n",
      "Train Epoch: 3 [14080/15392 (91%)]\tLoss: 0.092167\n",
      "Train Epoch: 3 [14720/15392 (95%)]\tLoss: 0.121078\n",
      "Train Epoch: 3 [7680/15392 (100%)]\tLoss: 0.033106\n",
      "Train Epoch: 4 [0/15392 (0%)]\tLoss: 0.033775\n",
      "Train Epoch: 4 [640/15392 (4%)]\tLoss: 0.032795\n",
      "Train Epoch: 4 [1280/15392 (8%)]\tLoss: 0.064658\n",
      "Train Epoch: 4 [1920/15392 (12%)]\tLoss: 0.070093\n",
      "Train Epoch: 4 [2560/15392 (17%)]\tLoss: 0.059593\n",
      "Train Epoch: 4 [3200/15392 (21%)]\tLoss: 0.050240\n",
      "Train Epoch: 4 [3840/15392 (25%)]\tLoss: 0.094112\n",
      "Train Epoch: 4 [4480/15392 (29%)]\tLoss: 0.056941\n",
      "Train Epoch: 4 [5120/15392 (33%)]\tLoss: 0.148368\n",
      "Train Epoch: 4 [5760/15392 (37%)]\tLoss: 0.081301\n",
      "Train Epoch: 4 [6400/15392 (41%)]\tLoss: 0.082094\n",
      "Train Epoch: 4 [7040/15392 (46%)]\tLoss: 0.006746\n",
      "Train Epoch: 4 [7680/15392 (50%)]\tLoss: 0.139227\n",
      "Train Epoch: 4 [8320/15392 (54%)]\tLoss: 0.027681\n",
      "Train Epoch: 4 [8960/15392 (58%)]\tLoss: 0.048441\n",
      "Train Epoch: 4 [9600/15392 (62%)]\tLoss: 0.092622\n",
      "Train Epoch: 4 [10240/15392 (66%)]\tLoss: 0.060975\n",
      "Train Epoch: 4 [10880/15392 (71%)]\tLoss: 0.200343\n",
      "Train Epoch: 4 [11520/15392 (75%)]\tLoss: 0.037264\n",
      "Train Epoch: 4 [12160/15392 (79%)]\tLoss: 0.030881\n",
      "Train Epoch: 4 [12800/15392 (83%)]\tLoss: 0.042527\n",
      "Train Epoch: 4 [13440/15392 (87%)]\tLoss: 0.031140\n",
      "Train Epoch: 4 [14080/15392 (91%)]\tLoss: 0.052485\n",
      "Train Epoch: 4 [14720/15392 (95%)]\tLoss: 0.046067\n",
      "Train Epoch: 4 [7680/15392 (100%)]\tLoss: 0.061376\n",
      "Train Epoch: 5 [0/15392 (0%)]\tLoss: 0.030200\n",
      "Train Epoch: 5 [640/15392 (4%)]\tLoss: 0.010074\n",
      "Train Epoch: 5 [1280/15392 (8%)]\tLoss: 0.164463\n",
      "Train Epoch: 5 [1920/15392 (12%)]\tLoss: 0.073152\n",
      "Train Epoch: 5 [2560/15392 (17%)]\tLoss: 0.044821\n",
      "Train Epoch: 5 [3200/15392 (21%)]\tLoss: 0.090060\n",
      "Train Epoch: 5 [3840/15392 (25%)]\tLoss: 0.080301\n",
      "Train Epoch: 5 [4480/15392 (29%)]\tLoss: 0.024400\n",
      "Train Epoch: 5 [5120/15392 (33%)]\tLoss: 0.017084\n",
      "Train Epoch: 5 [5760/15392 (37%)]\tLoss: 0.057131\n",
      "Train Epoch: 5 [6400/15392 (41%)]\tLoss: 0.225560\n",
      "Train Epoch: 5 [7040/15392 (46%)]\tLoss: 0.118260\n",
      "Train Epoch: 5 [7680/15392 (50%)]\tLoss: 0.121793\n",
      "Train Epoch: 5 [8320/15392 (54%)]\tLoss: 0.107069\n",
      "Train Epoch: 5 [8960/15392 (58%)]\tLoss: 0.069217\n",
      "Train Epoch: 5 [9600/15392 (62%)]\tLoss: 0.067547\n",
      "Train Epoch: 5 [10240/15392 (66%)]\tLoss: 0.014911\n",
      "Train Epoch: 5 [10880/15392 (71%)]\tLoss: 0.027418\n",
      "Train Epoch: 5 [11520/15392 (75%)]\tLoss: 0.079295\n",
      "Train Epoch: 5 [12160/15392 (79%)]\tLoss: 0.114178\n",
      "Train Epoch: 5 [12800/15392 (83%)]\tLoss: 0.090433\n",
      "Train Epoch: 5 [13440/15392 (87%)]\tLoss: 0.083992\n",
      "Train Epoch: 5 [14080/15392 (91%)]\tLoss: 0.124649\n",
      "Train Epoch: 5 [14720/15392 (95%)]\tLoss: 0.048112\n",
      "Train Epoch: 5 [7680/15392 (100%)]\tLoss: 0.238327\n",
      "Train Epoch: 6 [0/15392 (0%)]\tLoss: 0.035914\n",
      "Train Epoch: 6 [640/15392 (4%)]\tLoss: 0.049352\n",
      "Train Epoch: 6 [1280/15392 (8%)]\tLoss: 0.111903\n",
      "Train Epoch: 6 [1920/15392 (12%)]\tLoss: 0.106199\n",
      "Train Epoch: 6 [2560/15392 (17%)]\tLoss: 0.033004\n",
      "Train Epoch: 6 [3200/15392 (21%)]\tLoss: 0.035754\n",
      "Train Epoch: 6 [3840/15392 (25%)]\tLoss: 0.091491\n",
      "Train Epoch: 6 [4480/15392 (29%)]\tLoss: 0.119001\n",
      "Train Epoch: 6 [5120/15392 (33%)]\tLoss: 0.049611\n",
      "Train Epoch: 6 [5760/15392 (37%)]\tLoss: 0.016939\n",
      "Train Epoch: 6 [6400/15392 (41%)]\tLoss: 0.039626\n",
      "Train Epoch: 6 [7040/15392 (46%)]\tLoss: 0.032232\n",
      "Train Epoch: 6 [7680/15392 (50%)]\tLoss: 0.091622\n",
      "Train Epoch: 6 [8320/15392 (54%)]\tLoss: 0.046171\n",
      "Train Epoch: 6 [8960/15392 (58%)]\tLoss: 0.118548\n",
      "Train Epoch: 6 [9600/15392 (62%)]\tLoss: 0.064452\n",
      "Train Epoch: 6 [10240/15392 (66%)]\tLoss: 0.094687\n",
      "Train Epoch: 6 [10880/15392 (71%)]\tLoss: 0.165260\n",
      "Train Epoch: 6 [11520/15392 (75%)]\tLoss: 0.035341\n",
      "Train Epoch: 6 [12160/15392 (79%)]\tLoss: 0.040907\n",
      "Train Epoch: 6 [12800/15392 (83%)]\tLoss: 0.032457\n",
      "Train Epoch: 6 [13440/15392 (87%)]\tLoss: 0.330779\n",
      "Train Epoch: 6 [14080/15392 (91%)]\tLoss: 0.038799\n",
      "Train Epoch: 6 [14720/15392 (95%)]\tLoss: 0.046422\n",
      "Train Epoch: 6 [7680/15392 (100%)]\tLoss: 0.048017\n",
      "Train Epoch: 7 [0/15392 (0%)]\tLoss: 0.068067\n",
      "Train Epoch: 7 [640/15392 (4%)]\tLoss: 0.080515\n",
      "Train Epoch: 7 [1280/15392 (8%)]\tLoss: 0.134454\n",
      "Train Epoch: 7 [1920/15392 (12%)]\tLoss: 0.081929\n",
      "Train Epoch: 7 [2560/15392 (17%)]\tLoss: 0.055784\n",
      "Train Epoch: 7 [3200/15392 (21%)]\tLoss: 0.117390\n",
      "Train Epoch: 7 [3840/15392 (25%)]\tLoss: 0.081993\n",
      "Train Epoch: 7 [4480/15392 (29%)]\tLoss: 0.027495\n",
      "Train Epoch: 7 [5120/15392 (33%)]\tLoss: 0.005860\n",
      "Train Epoch: 7 [5760/15392 (37%)]\tLoss: 0.026610\n",
      "Train Epoch: 7 [6400/15392 (41%)]\tLoss: 0.027665\n",
      "Train Epoch: 7 [7040/15392 (46%)]\tLoss: 0.075569\n",
      "Train Epoch: 7 [7680/15392 (50%)]\tLoss: 0.027120\n",
      "Train Epoch: 7 [8320/15392 (54%)]\tLoss: 0.053857\n",
      "Train Epoch: 7 [8960/15392 (58%)]\tLoss: 0.098688\n",
      "Train Epoch: 7 [9600/15392 (62%)]\tLoss: 0.020926\n",
      "Train Epoch: 7 [10240/15392 (66%)]\tLoss: 0.036297\n",
      "Train Epoch: 7 [10880/15392 (71%)]\tLoss: 0.112245\n",
      "Train Epoch: 7 [11520/15392 (75%)]\tLoss: 0.093429\n",
      "Train Epoch: 7 [12160/15392 (79%)]\tLoss: 0.095528\n",
      "Train Epoch: 7 [12800/15392 (83%)]\tLoss: 0.026193\n",
      "Train Epoch: 7 [13440/15392 (87%)]\tLoss: 0.040732\n",
      "Train Epoch: 7 [14080/15392 (91%)]\tLoss: 0.121389\n",
      "Train Epoch: 7 [14720/15392 (95%)]\tLoss: 0.079068\n",
      "Train Epoch: 7 [7680/15392 (100%)]\tLoss: 0.316026\n",
      "Train Epoch: 8 [0/15392 (0%)]\tLoss: 0.048602\n",
      "Train Epoch: 8 [640/15392 (4%)]\tLoss: 0.047708\n",
      "Train Epoch: 8 [1280/15392 (8%)]\tLoss: 0.024865\n",
      "Train Epoch: 8 [1920/15392 (12%)]\tLoss: 0.053619\n",
      "Train Epoch: 8 [2560/15392 (17%)]\tLoss: 0.067109\n",
      "Train Epoch: 8 [3200/15392 (21%)]\tLoss: 0.254966\n",
      "Train Epoch: 8 [3840/15392 (25%)]\tLoss: 0.071208\n",
      "Train Epoch: 8 [4480/15392 (29%)]\tLoss: 0.100135\n",
      "Train Epoch: 8 [5120/15392 (33%)]\tLoss: 0.020319\n",
      "Train Epoch: 8 [5760/15392 (37%)]\tLoss: 0.025907\n",
      "Train Epoch: 8 [6400/15392 (41%)]\tLoss: 0.088439\n",
      "Train Epoch: 8 [7040/15392 (46%)]\tLoss: 0.038341\n",
      "Train Epoch: 8 [7680/15392 (50%)]\tLoss: 0.057130\n",
      "Train Epoch: 8 [8320/15392 (54%)]\tLoss: 0.035464\n",
      "Train Epoch: 8 [8960/15392 (58%)]\tLoss: 0.233005\n",
      "Train Epoch: 8 [9600/15392 (62%)]\tLoss: 0.143142\n",
      "Train Epoch: 8 [10240/15392 (66%)]\tLoss: 0.040080\n",
      "Train Epoch: 8 [10880/15392 (71%)]\tLoss: 0.077688\n",
      "Train Epoch: 8 [11520/15392 (75%)]\tLoss: 0.016896\n",
      "Train Epoch: 8 [12160/15392 (79%)]\tLoss: 0.022451\n",
      "Train Epoch: 8 [12800/15392 (83%)]\tLoss: 0.013794\n",
      "Train Epoch: 8 [13440/15392 (87%)]\tLoss: 0.084541\n",
      "Train Epoch: 8 [14080/15392 (91%)]\tLoss: 0.034034\n",
      "Train Epoch: 8 [14720/15392 (95%)]\tLoss: 0.051518\n",
      "Train Epoch: 8 [7680/15392 (100%)]\tLoss: 0.007324\n",
      "Train Epoch: 9 [0/15392 (0%)]\tLoss: 0.079881\n",
      "Train Epoch: 9 [640/15392 (4%)]\tLoss: 0.055193\n",
      "Train Epoch: 9 [1280/15392 (8%)]\tLoss: 0.075983\n",
      "Train Epoch: 9 [1920/15392 (12%)]\tLoss: 0.187411\n",
      "Train Epoch: 9 [2560/15392 (17%)]\tLoss: 0.029387\n",
      "Train Epoch: 9 [3200/15392 (21%)]\tLoss: 0.062202\n",
      "Train Epoch: 9 [3840/15392 (25%)]\tLoss: 0.102303\n",
      "Train Epoch: 9 [4480/15392 (29%)]\tLoss: 0.111189\n",
      "Train Epoch: 9 [5120/15392 (33%)]\tLoss: 0.042248\n",
      "Train Epoch: 9 [5760/15392 (37%)]\tLoss: 0.096983\n",
      "Train Epoch: 9 [6400/15392 (41%)]\tLoss: 0.156827\n",
      "Train Epoch: 9 [7040/15392 (46%)]\tLoss: 0.017092\n",
      "Train Epoch: 9 [7680/15392 (50%)]\tLoss: 0.059932\n",
      "Train Epoch: 9 [8320/15392 (54%)]\tLoss: 0.086287\n",
      "Train Epoch: 9 [8960/15392 (58%)]\tLoss: 0.114277\n",
      "Train Epoch: 9 [9600/15392 (62%)]\tLoss: 0.021380\n",
      "Train Epoch: 9 [10240/15392 (66%)]\tLoss: 0.038305\n",
      "Train Epoch: 9 [10880/15392 (71%)]\tLoss: 0.101792\n",
      "Train Epoch: 9 [11520/15392 (75%)]\tLoss: 0.116276\n",
      "Train Epoch: 9 [12160/15392 (79%)]\tLoss: 0.076440\n",
      "Train Epoch: 9 [12800/15392 (83%)]\tLoss: 0.014189\n",
      "Train Epoch: 9 [13440/15392 (87%)]\tLoss: 0.161205\n",
      "Train Epoch: 9 [14080/15392 (91%)]\tLoss: 0.023650\n",
      "Train Epoch: 9 [14720/15392 (95%)]\tLoss: 0.018726\n",
      "Train Epoch: 9 [7680/15392 (100%)]\tLoss: 0.002476\n",
      "Train Epoch: 10 [0/15392 (0%)]\tLoss: 0.084289\n",
      "Train Epoch: 10 [640/15392 (4%)]\tLoss: 0.056430\n",
      "Train Epoch: 10 [1280/15392 (8%)]\tLoss: 0.013742\n",
      "Train Epoch: 10 [1920/15392 (12%)]\tLoss: 0.063365\n",
      "Train Epoch: 10 [2560/15392 (17%)]\tLoss: 0.069016\n",
      "Train Epoch: 10 [3200/15392 (21%)]\tLoss: 0.013534\n",
      "Train Epoch: 10 [3840/15392 (25%)]\tLoss: 0.019256\n",
      "Train Epoch: 10 [4480/15392 (29%)]\tLoss: 0.051445\n",
      "Train Epoch: 10 [5120/15392 (33%)]\tLoss: 0.066746\n",
      "Train Epoch: 10 [5760/15392 (37%)]\tLoss: 0.144535\n",
      "Train Epoch: 10 [6400/15392 (41%)]\tLoss: 0.050843\n",
      "Train Epoch: 10 [7040/15392 (46%)]\tLoss: 0.135990\n",
      "Train Epoch: 10 [7680/15392 (50%)]\tLoss: 0.047275\n",
      "Train Epoch: 10 [8320/15392 (54%)]\tLoss: 0.033521\n",
      "Train Epoch: 10 [8960/15392 (58%)]\tLoss: 0.165069\n",
      "Train Epoch: 10 [9600/15392 (62%)]\tLoss: 0.169664\n",
      "Train Epoch: 10 [10240/15392 (66%)]\tLoss: 0.103580\n",
      "Train Epoch: 10 [10880/15392 (71%)]\tLoss: 0.034635\n",
      "Train Epoch: 10 [11520/15392 (75%)]\tLoss: 0.215821\n",
      "Train Epoch: 10 [12160/15392 (79%)]\tLoss: 0.257782\n",
      "Train Epoch: 10 [12800/15392 (83%)]\tLoss: 0.027219\n",
      "Train Epoch: 10 [13440/15392 (87%)]\tLoss: 0.049323\n",
      "Train Epoch: 10 [14080/15392 (91%)]\tLoss: 0.149190\n",
      "Train Epoch: 10 [14720/15392 (95%)]\tLoss: 0.113341\n",
      "Train Epoch: 10 [7680/15392 (100%)]\tLoss: 0.100002\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/15327 (0%)]\tLoss: 0.078106\n",
      "Train Epoch: 1 [640/15327 (4%)]\tLoss: 0.212586\n",
      "Train Epoch: 1 [1280/15327 (8%)]\tLoss: 0.188221\n",
      "Train Epoch: 1 [1920/15327 (12%)]\tLoss: 0.125829\n",
      "Train Epoch: 1 [2560/15327 (17%)]\tLoss: 0.085139\n",
      "Train Epoch: 1 [3200/15327 (21%)]\tLoss: 0.128966\n",
      "Train Epoch: 1 [3840/15327 (25%)]\tLoss: 0.230420\n",
      "Train Epoch: 1 [4480/15327 (29%)]\tLoss: 0.073867\n",
      "Train Epoch: 1 [5120/15327 (33%)]\tLoss: 0.067195\n",
      "Train Epoch: 1 [5760/15327 (38%)]\tLoss: 0.190986\n",
      "Train Epoch: 1 [6400/15327 (42%)]\tLoss: 0.023084\n",
      "Train Epoch: 1 [7040/15327 (46%)]\tLoss: 0.053049\n",
      "Train Epoch: 1 [7680/15327 (50%)]\tLoss: 0.046481\n",
      "Train Epoch: 1 [8320/15327 (54%)]\tLoss: 0.224568\n",
      "Train Epoch: 1 [8960/15327 (58%)]\tLoss: 0.047566\n",
      "Train Epoch: 1 [9600/15327 (62%)]\tLoss: 0.113922\n",
      "Train Epoch: 1 [10240/15327 (67%)]\tLoss: 0.079821\n",
      "Train Epoch: 1 [10880/15327 (71%)]\tLoss: 0.118295\n",
      "Train Epoch: 1 [11520/15327 (75%)]\tLoss: 0.091529\n",
      "Train Epoch: 1 [12160/15327 (79%)]\tLoss: 0.010591\n",
      "Train Epoch: 1 [12800/15327 (83%)]\tLoss: 0.117917\n",
      "Train Epoch: 1 [13440/15327 (88%)]\tLoss: 0.040769\n",
      "Train Epoch: 1 [14080/15327 (92%)]\tLoss: 0.063025\n",
      "Train Epoch: 1 [14720/15327 (96%)]\tLoss: 0.066693\n",
      "Train Epoch: 2 [0/15327 (0%)]\tLoss: 0.020118\n",
      "Train Epoch: 2 [640/15327 (4%)]\tLoss: 0.081597\n",
      "Train Epoch: 2 [1280/15327 (8%)]\tLoss: 0.101775\n",
      "Train Epoch: 2 [1920/15327 (12%)]\tLoss: 0.028969\n",
      "Train Epoch: 2 [2560/15327 (17%)]\tLoss: 0.056391\n",
      "Train Epoch: 2 [3200/15327 (21%)]\tLoss: 0.271787\n",
      "Train Epoch: 2 [3840/15327 (25%)]\tLoss: 0.094941\n",
      "Train Epoch: 2 [4480/15327 (29%)]\tLoss: 0.043513\n",
      "Train Epoch: 2 [5120/15327 (33%)]\tLoss: 0.183100\n",
      "Train Epoch: 2 [5760/15327 (38%)]\tLoss: 0.124056\n",
      "Train Epoch: 2 [6400/15327 (42%)]\tLoss: 0.137855\n",
      "Train Epoch: 2 [7040/15327 (46%)]\tLoss: 0.069294\n",
      "Train Epoch: 2 [7680/15327 (50%)]\tLoss: 0.129280\n",
      "Train Epoch: 2 [8320/15327 (54%)]\tLoss: 0.078497\n",
      "Train Epoch: 2 [8960/15327 (58%)]\tLoss: 0.035714\n",
      "Train Epoch: 2 [9600/15327 (62%)]\tLoss: 0.013609\n",
      "Train Epoch: 2 [10240/15327 (67%)]\tLoss: 0.086688\n",
      "Train Epoch: 2 [10880/15327 (71%)]\tLoss: 0.032263\n",
      "Train Epoch: 2 [11520/15327 (75%)]\tLoss: 0.113801\n",
      "Train Epoch: 2 [12160/15327 (79%)]\tLoss: 0.074778\n",
      "Train Epoch: 2 [12800/15327 (83%)]\tLoss: 0.128072\n",
      "Train Epoch: 2 [13440/15327 (88%)]\tLoss: 0.064127\n",
      "Train Epoch: 2 [14080/15327 (92%)]\tLoss: 0.018989\n",
      "Train Epoch: 2 [14720/15327 (96%)]\tLoss: 0.283154\n",
      "Train Epoch: 3 [0/15327 (0%)]\tLoss: 0.077990\n",
      "Train Epoch: 3 [640/15327 (4%)]\tLoss: 0.035272\n",
      "Train Epoch: 3 [1280/15327 (8%)]\tLoss: 0.031492\n",
      "Train Epoch: 3 [1920/15327 (12%)]\tLoss: 0.047598\n",
      "Train Epoch: 3 [2560/15327 (17%)]\tLoss: 0.058062\n",
      "Train Epoch: 3 [3200/15327 (21%)]\tLoss: 0.122078\n",
      "Train Epoch: 3 [3840/15327 (25%)]\tLoss: 0.038386\n",
      "Train Epoch: 3 [4480/15327 (29%)]\tLoss: 0.080774\n",
      "Train Epoch: 3 [5120/15327 (33%)]\tLoss: 0.191218\n",
      "Train Epoch: 3 [5760/15327 (38%)]\tLoss: 0.070523\n",
      "Train Epoch: 3 [6400/15327 (42%)]\tLoss: 0.063122\n",
      "Train Epoch: 3 [7040/15327 (46%)]\tLoss: 0.170657\n",
      "Train Epoch: 3 [7680/15327 (50%)]\tLoss: 0.016124\n",
      "Train Epoch: 3 [8320/15327 (54%)]\tLoss: 0.287363\n",
      "Train Epoch: 3 [8960/15327 (58%)]\tLoss: 0.045647\n",
      "Train Epoch: 3 [9600/15327 (62%)]\tLoss: 0.169553\n",
      "Train Epoch: 3 [10240/15327 (67%)]\tLoss: 0.073673\n",
      "Train Epoch: 3 [10880/15327 (71%)]\tLoss: 0.142329\n",
      "Train Epoch: 3 [11520/15327 (75%)]\tLoss: 0.123689\n",
      "Train Epoch: 3 [12160/15327 (79%)]\tLoss: 0.045675\n",
      "Train Epoch: 3 [12800/15327 (83%)]\tLoss: 0.025612\n",
      "Train Epoch: 3 [13440/15327 (88%)]\tLoss: 0.052613\n",
      "Train Epoch: 3 [14080/15327 (92%)]\tLoss: 0.023425\n",
      "Train Epoch: 3 [14720/15327 (96%)]\tLoss: 0.080696\n",
      "Train Epoch: 4 [0/15327 (0%)]\tLoss: 0.058901\n",
      "Train Epoch: 4 [640/15327 (4%)]\tLoss: 0.053295\n",
      "Train Epoch: 4 [1280/15327 (8%)]\tLoss: 0.136222\n",
      "Train Epoch: 4 [1920/15327 (12%)]\tLoss: 0.033347\n",
      "Train Epoch: 4 [2560/15327 (17%)]\tLoss: 0.082322\n",
      "Train Epoch: 4 [3200/15327 (21%)]\tLoss: 0.069094\n",
      "Train Epoch: 4 [3840/15327 (25%)]\tLoss: 0.069520\n",
      "Train Epoch: 4 [4480/15327 (29%)]\tLoss: 0.142466\n",
      "Train Epoch: 4 [5120/15327 (33%)]\tLoss: 0.069717\n",
      "Train Epoch: 4 [5760/15327 (38%)]\tLoss: 0.096906\n",
      "Train Epoch: 4 [6400/15327 (42%)]\tLoss: 0.055820\n",
      "Train Epoch: 4 [7040/15327 (46%)]\tLoss: 0.079829\n",
      "Train Epoch: 4 [7680/15327 (50%)]\tLoss: 0.025146\n",
      "Train Epoch: 4 [8320/15327 (54%)]\tLoss: 0.058643\n",
      "Train Epoch: 4 [8960/15327 (58%)]\tLoss: 0.112893\n",
      "Train Epoch: 4 [9600/15327 (62%)]\tLoss: 0.067396\n",
      "Train Epoch: 4 [10240/15327 (67%)]\tLoss: 0.027710\n",
      "Train Epoch: 4 [10880/15327 (71%)]\tLoss: 0.044266\n",
      "Train Epoch: 4 [11520/15327 (75%)]\tLoss: 0.055976\n",
      "Train Epoch: 4 [12160/15327 (79%)]\tLoss: 0.060244\n",
      "Train Epoch: 4 [12800/15327 (83%)]\tLoss: 0.281935\n",
      "Train Epoch: 4 [13440/15327 (88%)]\tLoss: 0.075451\n",
      "Train Epoch: 4 [14080/15327 (92%)]\tLoss: 0.103927\n",
      "Train Epoch: 4 [14720/15327 (96%)]\tLoss: 0.028983\n",
      "Train Epoch: 5 [0/15327 (0%)]\tLoss: 0.071654\n",
      "Train Epoch: 5 [640/15327 (4%)]\tLoss: 0.097272\n",
      "Train Epoch: 5 [1280/15327 (8%)]\tLoss: 0.009693\n",
      "Train Epoch: 5 [1920/15327 (12%)]\tLoss: 0.128843\n",
      "Train Epoch: 5 [2560/15327 (17%)]\tLoss: 0.104917\n",
      "Train Epoch: 5 [3200/15327 (21%)]\tLoss: 0.060959\n",
      "Train Epoch: 5 [3840/15327 (25%)]\tLoss: 0.022698\n",
      "Train Epoch: 5 [4480/15327 (29%)]\tLoss: 0.053490\n",
      "Train Epoch: 5 [5120/15327 (33%)]\tLoss: 0.033505\n",
      "Train Epoch: 5 [5760/15327 (38%)]\tLoss: 0.038290\n",
      "Train Epoch: 5 [6400/15327 (42%)]\tLoss: 0.168984\n",
      "Train Epoch: 5 [7040/15327 (46%)]\tLoss: 0.038045\n",
      "Train Epoch: 5 [7680/15327 (50%)]\tLoss: 0.040753\n",
      "Train Epoch: 5 [8320/15327 (54%)]\tLoss: 0.019733\n",
      "Train Epoch: 5 [8960/15327 (58%)]\tLoss: 0.124473\n",
      "Train Epoch: 5 [9600/15327 (62%)]\tLoss: 0.039385\n",
      "Train Epoch: 5 [10240/15327 (67%)]\tLoss: 0.041449\n",
      "Train Epoch: 5 [10880/15327 (71%)]\tLoss: 0.086426\n",
      "Train Epoch: 5 [11520/15327 (75%)]\tLoss: 0.080301\n",
      "Train Epoch: 5 [12160/15327 (79%)]\tLoss: 0.056541\n",
      "Train Epoch: 5 [12800/15327 (83%)]\tLoss: 0.073217\n",
      "Train Epoch: 5 [13440/15327 (88%)]\tLoss: 0.019205\n",
      "Train Epoch: 5 [14080/15327 (92%)]\tLoss: 0.069020\n",
      "Train Epoch: 5 [14720/15327 (96%)]\tLoss: 0.121463\n",
      "Train Epoch: 6 [0/15327 (0%)]\tLoss: 0.152508\n",
      "Train Epoch: 6 [640/15327 (4%)]\tLoss: 0.197668\n",
      "Train Epoch: 6 [1280/15327 (8%)]\tLoss: 0.097428\n",
      "Train Epoch: 6 [1920/15327 (12%)]\tLoss: 0.075977\n",
      "Train Epoch: 6 [2560/15327 (17%)]\tLoss: 0.177158\n",
      "Train Epoch: 6 [3200/15327 (21%)]\tLoss: 0.140853\n",
      "Train Epoch: 6 [3840/15327 (25%)]\tLoss: 0.067555\n",
      "Train Epoch: 6 [4480/15327 (29%)]\tLoss: 0.148198\n",
      "Train Epoch: 6 [5120/15327 (33%)]\tLoss: 0.015723\n",
      "Train Epoch: 6 [5760/15327 (38%)]\tLoss: 0.028983\n",
      "Train Epoch: 6 [6400/15327 (42%)]\tLoss: 0.084790\n",
      "Train Epoch: 6 [7040/15327 (46%)]\tLoss: 0.077419\n",
      "Train Epoch: 6 [7680/15327 (50%)]\tLoss: 0.053589\n",
      "Train Epoch: 6 [8320/15327 (54%)]\tLoss: 0.044290\n",
      "Train Epoch: 6 [8960/15327 (58%)]\tLoss: 0.104731\n",
      "Train Epoch: 6 [9600/15327 (62%)]\tLoss: 0.116416\n",
      "Train Epoch: 6 [10240/15327 (67%)]\tLoss: 0.116487\n",
      "Train Epoch: 6 [10880/15327 (71%)]\tLoss: 0.128908\n",
      "Train Epoch: 6 [11520/15327 (75%)]\tLoss: 0.070309\n",
      "Train Epoch: 6 [12160/15327 (79%)]\tLoss: 0.017745\n",
      "Train Epoch: 6 [12800/15327 (83%)]\tLoss: 0.091558\n",
      "Train Epoch: 6 [13440/15327 (88%)]\tLoss: 0.059170\n",
      "Train Epoch: 6 [14080/15327 (92%)]\tLoss: 0.057483\n",
      "Train Epoch: 6 [14720/15327 (96%)]\tLoss: 0.087598\n",
      "Train Epoch: 7 [0/15327 (0%)]\tLoss: 0.087255\n",
      "Train Epoch: 7 [640/15327 (4%)]\tLoss: 0.051507\n",
      "Train Epoch: 7 [1280/15327 (8%)]\tLoss: 0.133738\n",
      "Train Epoch: 7 [1920/15327 (12%)]\tLoss: 0.034362\n",
      "Train Epoch: 7 [2560/15327 (17%)]\tLoss: 0.163768\n",
      "Train Epoch: 7 [3200/15327 (21%)]\tLoss: 0.109202\n",
      "Train Epoch: 7 [3840/15327 (25%)]\tLoss: 0.047837\n",
      "Train Epoch: 7 [4480/15327 (29%)]\tLoss: 0.036227\n",
      "Train Epoch: 7 [5120/15327 (33%)]\tLoss: 0.089814\n",
      "Train Epoch: 7 [5760/15327 (38%)]\tLoss: 0.026457\n",
      "Train Epoch: 7 [6400/15327 (42%)]\tLoss: 0.077323\n",
      "Train Epoch: 7 [7040/15327 (46%)]\tLoss: 0.138428\n",
      "Train Epoch: 7 [7680/15327 (50%)]\tLoss: 0.087919\n",
      "Train Epoch: 7 [8320/15327 (54%)]\tLoss: 0.172463\n",
      "Train Epoch: 7 [8960/15327 (58%)]\tLoss: 0.285812\n",
      "Train Epoch: 7 [9600/15327 (62%)]\tLoss: 0.036420\n",
      "Train Epoch: 7 [10240/15327 (67%)]\tLoss: 0.065976\n",
      "Train Epoch: 7 [10880/15327 (71%)]\tLoss: 0.098801\n",
      "Train Epoch: 7 [11520/15327 (75%)]\tLoss: 0.054731\n",
      "Train Epoch: 7 [12160/15327 (79%)]\tLoss: 0.083534\n",
      "Train Epoch: 7 [12800/15327 (83%)]\tLoss: 0.144063\n",
      "Train Epoch: 7 [13440/15327 (88%)]\tLoss: 0.338336\n",
      "Train Epoch: 7 [14080/15327 (92%)]\tLoss: 0.021822\n",
      "Train Epoch: 7 [14720/15327 (96%)]\tLoss: 0.064647\n",
      "Train Epoch: 8 [0/15327 (0%)]\tLoss: 0.067415\n",
      "Train Epoch: 8 [640/15327 (4%)]\tLoss: 0.040073\n",
      "Train Epoch: 8 [1280/15327 (8%)]\tLoss: 0.114084\n",
      "Train Epoch: 8 [1920/15327 (12%)]\tLoss: 0.065575\n",
      "Train Epoch: 8 [2560/15327 (17%)]\tLoss: 0.030905\n",
      "Train Epoch: 8 [3200/15327 (21%)]\tLoss: 0.104910\n",
      "Train Epoch: 8 [3840/15327 (25%)]\tLoss: 0.058718\n",
      "Train Epoch: 8 [4480/15327 (29%)]\tLoss: 0.046350\n",
      "Train Epoch: 8 [5120/15327 (33%)]\tLoss: 0.124143\n",
      "Train Epoch: 8 [5760/15327 (38%)]\tLoss: 0.151501\n",
      "Train Epoch: 8 [6400/15327 (42%)]\tLoss: 0.190432\n",
      "Train Epoch: 8 [7040/15327 (46%)]\tLoss: 0.060187\n",
      "Train Epoch: 8 [7680/15327 (50%)]\tLoss: 0.142419\n",
      "Train Epoch: 8 [8320/15327 (54%)]\tLoss: 0.052237\n",
      "Train Epoch: 8 [8960/15327 (58%)]\tLoss: 0.061952\n",
      "Train Epoch: 8 [9600/15327 (62%)]\tLoss: 0.173210\n",
      "Train Epoch: 8 [10240/15327 (67%)]\tLoss: 0.081589\n",
      "Train Epoch: 8 [10880/15327 (71%)]\tLoss: 0.060774\n",
      "Train Epoch: 8 [11520/15327 (75%)]\tLoss: 0.009852\n",
      "Train Epoch: 8 [12160/15327 (79%)]\tLoss: 0.106192\n",
      "Train Epoch: 8 [12800/15327 (83%)]\tLoss: 0.025690\n",
      "Train Epoch: 8 [13440/15327 (88%)]\tLoss: 0.135852\n",
      "Train Epoch: 8 [14080/15327 (92%)]\tLoss: 0.201019\n",
      "Train Epoch: 8 [14720/15327 (96%)]\tLoss: 0.044902\n",
      "Train Epoch: 9 [0/15327 (0%)]\tLoss: 0.063592\n",
      "Train Epoch: 9 [640/15327 (4%)]\tLoss: 0.225822\n",
      "Train Epoch: 9 [1280/15327 (8%)]\tLoss: 0.013500\n",
      "Train Epoch: 9 [1920/15327 (12%)]\tLoss: 0.062261\n",
      "Train Epoch: 9 [2560/15327 (17%)]\tLoss: 0.016347\n",
      "Train Epoch: 9 [3200/15327 (21%)]\tLoss: 0.042939\n",
      "Train Epoch: 9 [3840/15327 (25%)]\tLoss: 0.036220\n",
      "Train Epoch: 9 [4480/15327 (29%)]\tLoss: 0.129639\n",
      "Train Epoch: 9 [5120/15327 (33%)]\tLoss: 0.106434\n",
      "Train Epoch: 9 [5760/15327 (38%)]\tLoss: 0.045886\n",
      "Train Epoch: 9 [6400/15327 (42%)]\tLoss: 0.154228\n",
      "Train Epoch: 9 [7040/15327 (46%)]\tLoss: 0.086206\n",
      "Train Epoch: 9 [7680/15327 (50%)]\tLoss: 0.067636\n",
      "Train Epoch: 9 [8320/15327 (54%)]\tLoss: 0.089824\n",
      "Train Epoch: 9 [8960/15327 (58%)]\tLoss: 0.024572\n",
      "Train Epoch: 9 [9600/15327 (62%)]\tLoss: 0.039896\n",
      "Train Epoch: 9 [10240/15327 (67%)]\tLoss: 0.033816\n",
      "Train Epoch: 9 [10880/15327 (71%)]\tLoss: 0.059469\n",
      "Train Epoch: 9 [11520/15327 (75%)]\tLoss: 0.040824\n",
      "Train Epoch: 9 [12160/15327 (79%)]\tLoss: 0.028238\n",
      "Train Epoch: 9 [12800/15327 (83%)]\tLoss: 0.342613\n",
      "Train Epoch: 9 [13440/15327 (88%)]\tLoss: 0.275822\n",
      "Train Epoch: 9 [14080/15327 (92%)]\tLoss: 0.071479\n",
      "Train Epoch: 9 [14720/15327 (96%)]\tLoss: 0.196683\n",
      "Train Epoch: 10 [0/15327 (0%)]\tLoss: 0.035388\n",
      "Train Epoch: 10 [640/15327 (4%)]\tLoss: 0.039784\n",
      "Train Epoch: 10 [1280/15327 (8%)]\tLoss: 0.138904\n",
      "Train Epoch: 10 [1920/15327 (12%)]\tLoss: 0.064228\n",
      "Train Epoch: 10 [2560/15327 (17%)]\tLoss: 0.022133\n",
      "Train Epoch: 10 [3200/15327 (21%)]\tLoss: 0.070497\n",
      "Train Epoch: 10 [3840/15327 (25%)]\tLoss: 0.071583\n",
      "Train Epoch: 10 [4480/15327 (29%)]\tLoss: 0.098334\n",
      "Train Epoch: 10 [5120/15327 (33%)]\tLoss: 0.166699\n",
      "Train Epoch: 10 [5760/15327 (38%)]\tLoss: 0.185356\n",
      "Train Epoch: 10 [6400/15327 (42%)]\tLoss: 0.117996\n",
      "Train Epoch: 10 [7040/15327 (46%)]\tLoss: 0.032217\n",
      "Train Epoch: 10 [7680/15327 (50%)]\tLoss: 0.018480\n",
      "Train Epoch: 10 [8320/15327 (54%)]\tLoss: 0.090803\n",
      "Train Epoch: 10 [8960/15327 (58%)]\tLoss: 0.086173\n",
      "Train Epoch: 10 [9600/15327 (62%)]\tLoss: 0.147313\n",
      "Train Epoch: 10 [10240/15327 (67%)]\tLoss: 0.061662\n",
      "Train Epoch: 10 [10880/15327 (71%)]\tLoss: 0.093125\n",
      "Train Epoch: 10 [11520/15327 (75%)]\tLoss: 0.067527\n",
      "Train Epoch: 10 [12160/15327 (79%)]\tLoss: 0.086935\n",
      "Train Epoch: 10 [12800/15327 (83%)]\tLoss: 0.037767\n",
      "Train Epoch: 10 [13440/15327 (88%)]\tLoss: 0.137090\n",
      "Train Epoch: 10 [14080/15327 (92%)]\tLoss: 0.034241\n",
      "Train Epoch: 10 [14720/15327 (96%)]\tLoss: 0.039564\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0531, Accuracy: 9832/10000 (98%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 0.141727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 0.128378\n",
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 0.093886\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 0.061844\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 0.089514\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 0.082249\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 0.106634\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 0.089307\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 0.125531\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 0.261826\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 0.090161\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 0.039355\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 0.075529\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 0.214002\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 0.084243\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 0.269753\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 0.046773\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 0.160927\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 0.097680\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 0.084612\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.047288\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 0.183802\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 0.082694\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.173718\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.062955\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 0.249832\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.009304\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 0.077120\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.051144\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.129187\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.010717\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.087973\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.109250\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.051911\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.107668\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.029419\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.014520\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.060232\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.159330\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.072835\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.033593\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.139639\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.074199\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.057250\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.118591\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.026557\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.049883\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.077127\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.007135\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.027243\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.119077\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.054403\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.239849\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.058105\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.017795\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.073658\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.087880\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.072706\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.041125\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.039230\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.112954\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.111586\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.067123\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.020715\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.168346\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.070646\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.065761\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.041211\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.212291\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.111194\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.099965\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.021136\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.061905\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.043627\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.022608\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.295116\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.040889\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.075310\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.062489\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.051044\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.029273\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.043561\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.128653\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.019012\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.015687\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.020759\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.035627\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.019299\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.040429\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.082151\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.035376\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.099122\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.108269\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.061334\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.006566\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.027337\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.050481\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.041080\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.015143\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.057723\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.179535\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.169007\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.056930\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.058873\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.260926\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.064457\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.048688\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.056994\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 0.035005\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.084235\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.086571\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.103380\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.038504\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.033209\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.057223\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.015826\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.081438\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.042480\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.114126\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.053200\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.089252\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.036773\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.128681\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.033553\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.055647\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.037135\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.084133\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.013932\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.071883\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.032908\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.088776\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.048920\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.215908\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.084447\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.018675\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.120916\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.063745\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.039301\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.114338\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.145427\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.121204\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.020657\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.061978\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.084753\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.116921\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.040980\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.015787\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.065327\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.077452\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.024997\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.139698\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.086998\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.033406\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.057461\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.050345\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.044931\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.057835\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.010351\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.046280\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.023531\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.025244\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.028018\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.174459\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.011475\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.049118\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.064486\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.131956\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.023950\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.030220\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.049993\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.168031\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.022712\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.007738\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.016256\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.035423\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.031469\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.052659\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.057600\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.031903\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.021510\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/13906 (0%)]\tLoss: 0.136011\n",
      "Train Epoch: 1 [640/13906 (5%)]\tLoss: 0.078822\n",
      "Train Epoch: 1 [1280/13906 (9%)]\tLoss: 0.136017\n",
      "Train Epoch: 1 [1920/13906 (14%)]\tLoss: 0.101081\n",
      "Train Epoch: 1 [2560/13906 (18%)]\tLoss: 0.179781\n",
      "Train Epoch: 1 [3200/13906 (23%)]\tLoss: 0.142821\n",
      "Train Epoch: 1 [3840/13906 (28%)]\tLoss: 0.052737\n",
      "Train Epoch: 1 [4480/13906 (32%)]\tLoss: 0.044058\n",
      "Train Epoch: 1 [5120/13906 (37%)]\tLoss: 0.106168\n",
      "Train Epoch: 1 [5760/13906 (41%)]\tLoss: 0.210912\n",
      "Train Epoch: 1 [6400/13906 (46%)]\tLoss: 0.128593\n",
      "Train Epoch: 1 [7040/13906 (50%)]\tLoss: 0.086374\n",
      "Train Epoch: 1 [7680/13906 (55%)]\tLoss: 0.024931\n",
      "Train Epoch: 1 [8320/13906 (60%)]\tLoss: 0.066048\n",
      "Train Epoch: 1 [8960/13906 (64%)]\tLoss: 0.020417\n",
      "Train Epoch: 1 [9600/13906 (69%)]\tLoss: 0.052626\n",
      "Train Epoch: 1 [10240/13906 (73%)]\tLoss: 0.230360\n",
      "Train Epoch: 1 [10880/13906 (78%)]\tLoss: 0.110766\n",
      "Train Epoch: 1 [11520/13906 (83%)]\tLoss: 0.036632\n",
      "Train Epoch: 1 [12160/13906 (87%)]\tLoss: 0.067852\n",
      "Train Epoch: 1 [12800/13906 (92%)]\tLoss: 0.147277\n",
      "Train Epoch: 1 [13440/13906 (96%)]\tLoss: 0.112076\n",
      "Train Epoch: 2 [0/13906 (0%)]\tLoss: 0.068303\n",
      "Train Epoch: 2 [640/13906 (5%)]\tLoss: 0.080318\n",
      "Train Epoch: 2 [1280/13906 (9%)]\tLoss: 0.073445\n",
      "Train Epoch: 2 [1920/13906 (14%)]\tLoss: 0.152313\n",
      "Train Epoch: 2 [2560/13906 (18%)]\tLoss: 0.063281\n",
      "Train Epoch: 2 [3200/13906 (23%)]\tLoss: 0.150075\n",
      "Train Epoch: 2 [3840/13906 (28%)]\tLoss: 0.069447\n",
      "Train Epoch: 2 [4480/13906 (32%)]\tLoss: 0.117874\n",
      "Train Epoch: 2 [5120/13906 (37%)]\tLoss: 0.188036\n",
      "Train Epoch: 2 [5760/13906 (41%)]\tLoss: 0.074069\n",
      "Train Epoch: 2 [6400/13906 (46%)]\tLoss: 0.072963\n",
      "Train Epoch: 2 [7040/13906 (50%)]\tLoss: 0.029371\n",
      "Train Epoch: 2 [7680/13906 (55%)]\tLoss: 0.049457\n",
      "Train Epoch: 2 [8320/13906 (60%)]\tLoss: 0.034096\n",
      "Train Epoch: 2 [8960/13906 (64%)]\tLoss: 0.043285\n",
      "Train Epoch: 2 [9600/13906 (69%)]\tLoss: 0.028038\n",
      "Train Epoch: 2 [10240/13906 (73%)]\tLoss: 0.087694\n",
      "Train Epoch: 2 [10880/13906 (78%)]\tLoss: 0.232341\n",
      "Train Epoch: 2 [11520/13906 (83%)]\tLoss: 0.097813\n",
      "Train Epoch: 2 [12160/13906 (87%)]\tLoss: 0.119937\n",
      "Train Epoch: 2 [12800/13906 (92%)]\tLoss: 0.085795\n",
      "Train Epoch: 2 [13440/13906 (96%)]\tLoss: 0.170393\n",
      "Train Epoch: 3 [0/13906 (0%)]\tLoss: 0.137140\n",
      "Train Epoch: 3 [640/13906 (5%)]\tLoss: 0.136854\n",
      "Train Epoch: 3 [1280/13906 (9%)]\tLoss: 0.039581\n",
      "Train Epoch: 3 [1920/13906 (14%)]\tLoss: 0.089522\n",
      "Train Epoch: 3 [2560/13906 (18%)]\tLoss: 0.056012\n",
      "Train Epoch: 3 [3200/13906 (23%)]\tLoss: 0.133095\n",
      "Train Epoch: 3 [3840/13906 (28%)]\tLoss: 0.010381\n",
      "Train Epoch: 3 [4480/13906 (32%)]\tLoss: 0.060472\n",
      "Train Epoch: 3 [5120/13906 (37%)]\tLoss: 0.029193\n",
      "Train Epoch: 3 [5760/13906 (41%)]\tLoss: 0.124824\n",
      "Train Epoch: 3 [6400/13906 (46%)]\tLoss: 0.203342\n",
      "Train Epoch: 3 [7040/13906 (50%)]\tLoss: 0.094863\n",
      "Train Epoch: 3 [7680/13906 (55%)]\tLoss: 0.089690\n",
      "Train Epoch: 3 [8320/13906 (60%)]\tLoss: 0.110480\n",
      "Train Epoch: 3 [8960/13906 (64%)]\tLoss: 0.173907\n",
      "Train Epoch: 3 [9600/13906 (69%)]\tLoss: 0.266035\n",
      "Train Epoch: 3 [10240/13906 (73%)]\tLoss: 0.228230\n",
      "Train Epoch: 3 [10880/13906 (78%)]\tLoss: 0.037812\n",
      "Train Epoch: 3 [11520/13906 (83%)]\tLoss: 0.075126\n",
      "Train Epoch: 3 [12160/13906 (87%)]\tLoss: 0.008709\n",
      "Train Epoch: 3 [12800/13906 (92%)]\tLoss: 0.134694\n",
      "Train Epoch: 3 [13440/13906 (96%)]\tLoss: 0.031857\n",
      "Train Epoch: 4 [0/13906 (0%)]\tLoss: 0.128876\n",
      "Train Epoch: 4 [640/13906 (5%)]\tLoss: 0.151505\n",
      "Train Epoch: 4 [1280/13906 (9%)]\tLoss: 0.059949\n",
      "Train Epoch: 4 [1920/13906 (14%)]\tLoss: 0.282618\n",
      "Train Epoch: 4 [2560/13906 (18%)]\tLoss: 0.122799\n",
      "Train Epoch: 4 [3200/13906 (23%)]\tLoss: 0.088741\n",
      "Train Epoch: 4 [3840/13906 (28%)]\tLoss: 0.143150\n",
      "Train Epoch: 4 [4480/13906 (32%)]\tLoss: 0.038354\n",
      "Train Epoch: 4 [5120/13906 (37%)]\tLoss: 0.042335\n",
      "Train Epoch: 4 [5760/13906 (41%)]\tLoss: 0.035166\n",
      "Train Epoch: 4 [6400/13906 (46%)]\tLoss: 0.077206\n",
      "Train Epoch: 4 [7040/13906 (50%)]\tLoss: 0.050129\n",
      "Train Epoch: 4 [7680/13906 (55%)]\tLoss: 0.016785\n",
      "Train Epoch: 4 [8320/13906 (60%)]\tLoss: 0.123256\n",
      "Train Epoch: 4 [8960/13906 (64%)]\tLoss: 0.016172\n",
      "Train Epoch: 4 [9600/13906 (69%)]\tLoss: 0.107940\n",
      "Train Epoch: 4 [10240/13906 (73%)]\tLoss: 0.152844\n",
      "Train Epoch: 4 [10880/13906 (78%)]\tLoss: 0.044574\n",
      "Train Epoch: 4 [11520/13906 (83%)]\tLoss: 0.069198\n",
      "Train Epoch: 4 [12160/13906 (87%)]\tLoss: 0.055355\n",
      "Train Epoch: 4 [12800/13906 (92%)]\tLoss: 0.079186\n",
      "Train Epoch: 4 [13440/13906 (96%)]\tLoss: 0.048950\n",
      "Train Epoch: 5 [0/13906 (0%)]\tLoss: 0.104129\n",
      "Train Epoch: 5 [640/13906 (5%)]\tLoss: 0.142419\n",
      "Train Epoch: 5 [1280/13906 (9%)]\tLoss: 0.095119\n",
      "Train Epoch: 5 [1920/13906 (14%)]\tLoss: 0.046094\n",
      "Train Epoch: 5 [2560/13906 (18%)]\tLoss: 0.013841\n",
      "Train Epoch: 5 [3200/13906 (23%)]\tLoss: 0.101889\n",
      "Train Epoch: 5 [3840/13906 (28%)]\tLoss: 0.037115\n",
      "Train Epoch: 5 [4480/13906 (32%)]\tLoss: 0.062897\n",
      "Train Epoch: 5 [5120/13906 (37%)]\tLoss: 0.141964\n",
      "Train Epoch: 5 [5760/13906 (41%)]\tLoss: 0.042527\n",
      "Train Epoch: 5 [6400/13906 (46%)]\tLoss: 0.019138\n",
      "Train Epoch: 5 [7040/13906 (50%)]\tLoss: 0.049151\n",
      "Train Epoch: 5 [7680/13906 (55%)]\tLoss: 0.014993\n",
      "Train Epoch: 5 [8320/13906 (60%)]\tLoss: 0.158278\n",
      "Train Epoch: 5 [8960/13906 (64%)]\tLoss: 0.055684\n",
      "Train Epoch: 5 [9600/13906 (69%)]\tLoss: 0.054066\n",
      "Train Epoch: 5 [10240/13906 (73%)]\tLoss: 0.142939\n",
      "Train Epoch: 5 [10880/13906 (78%)]\tLoss: 0.034639\n",
      "Train Epoch: 5 [11520/13906 (83%)]\tLoss: 0.009268\n",
      "Train Epoch: 5 [12160/13906 (87%)]\tLoss: 0.070655\n",
      "Train Epoch: 5 [12800/13906 (92%)]\tLoss: 0.079092\n",
      "Train Epoch: 5 [13440/13906 (96%)]\tLoss: 0.056168\n",
      "Train Epoch: 6 [0/13906 (0%)]\tLoss: 0.032232\n",
      "Train Epoch: 6 [640/13906 (5%)]\tLoss: 0.043310\n",
      "Train Epoch: 6 [1280/13906 (9%)]\tLoss: 0.084705\n",
      "Train Epoch: 6 [1920/13906 (14%)]\tLoss: 0.049604\n",
      "Train Epoch: 6 [2560/13906 (18%)]\tLoss: 0.118817\n",
      "Train Epoch: 6 [3200/13906 (23%)]\tLoss: 0.073100\n",
      "Train Epoch: 6 [3840/13906 (28%)]\tLoss: 0.103670\n",
      "Train Epoch: 6 [4480/13906 (32%)]\tLoss: 0.101753\n",
      "Train Epoch: 6 [5120/13906 (37%)]\tLoss: 0.251001\n",
      "Train Epoch: 6 [5760/13906 (41%)]\tLoss: 0.033174\n",
      "Train Epoch: 6 [6400/13906 (46%)]\tLoss: 0.094742\n",
      "Train Epoch: 6 [7040/13906 (50%)]\tLoss: 0.031730\n",
      "Train Epoch: 6 [7680/13906 (55%)]\tLoss: 0.121223\n",
      "Train Epoch: 6 [8320/13906 (60%)]\tLoss: 0.124317\n",
      "Train Epoch: 6 [8960/13906 (64%)]\tLoss: 0.069346\n",
      "Train Epoch: 6 [9600/13906 (69%)]\tLoss: 0.066505\n",
      "Train Epoch: 6 [10240/13906 (73%)]\tLoss: 0.079523\n",
      "Train Epoch: 6 [10880/13906 (78%)]\tLoss: 0.097797\n",
      "Train Epoch: 6 [11520/13906 (83%)]\tLoss: 0.043310\n",
      "Train Epoch: 6 [12160/13906 (87%)]\tLoss: 0.135670\n",
      "Train Epoch: 6 [12800/13906 (92%)]\tLoss: 0.171099\n",
      "Train Epoch: 6 [13440/13906 (96%)]\tLoss: 0.020285\n",
      "Train Epoch: 7 [0/13906 (0%)]\tLoss: 0.064095\n",
      "Train Epoch: 7 [640/13906 (5%)]\tLoss: 0.091285\n",
      "Train Epoch: 7 [1280/13906 (9%)]\tLoss: 0.019503\n",
      "Train Epoch: 7 [1920/13906 (14%)]\tLoss: 0.171136\n",
      "Train Epoch: 7 [2560/13906 (18%)]\tLoss: 0.043728\n",
      "Train Epoch: 7 [3200/13906 (23%)]\tLoss: 0.042684\n",
      "Train Epoch: 7 [3840/13906 (28%)]\tLoss: 0.146446\n",
      "Train Epoch: 7 [4480/13906 (32%)]\tLoss: 0.151878\n",
      "Train Epoch: 7 [5120/13906 (37%)]\tLoss: 0.078181\n",
      "Train Epoch: 7 [5760/13906 (41%)]\tLoss: 0.081136\n",
      "Train Epoch: 7 [6400/13906 (46%)]\tLoss: 0.041124\n",
      "Train Epoch: 7 [7040/13906 (50%)]\tLoss: 0.108551\n",
      "Train Epoch: 7 [7680/13906 (55%)]\tLoss: 0.065797\n",
      "Train Epoch: 7 [8320/13906 (60%)]\tLoss: 0.030716\n",
      "Train Epoch: 7 [8960/13906 (64%)]\tLoss: 0.018257\n",
      "Train Epoch: 7 [9600/13906 (69%)]\tLoss: 0.075863\n",
      "Train Epoch: 7 [10240/13906 (73%)]\tLoss: 0.193758\n",
      "Train Epoch: 7 [10880/13906 (78%)]\tLoss: 0.061525\n",
      "Train Epoch: 7 [11520/13906 (83%)]\tLoss: 0.077349\n",
      "Train Epoch: 7 [12160/13906 (87%)]\tLoss: 0.049329\n",
      "Train Epoch: 7 [12800/13906 (92%)]\tLoss: 0.078362\n",
      "Train Epoch: 7 [13440/13906 (96%)]\tLoss: 0.126041\n",
      "Train Epoch: 8 [0/13906 (0%)]\tLoss: 0.069737\n",
      "Train Epoch: 8 [640/13906 (5%)]\tLoss: 0.109041\n",
      "Train Epoch: 8 [1280/13906 (9%)]\tLoss: 0.040813\n",
      "Train Epoch: 8 [1920/13906 (14%)]\tLoss: 0.068880\n",
      "Train Epoch: 8 [2560/13906 (18%)]\tLoss: 0.073917\n",
      "Train Epoch: 8 [3200/13906 (23%)]\tLoss: 0.008519\n",
      "Train Epoch: 8 [3840/13906 (28%)]\tLoss: 0.081561\n",
      "Train Epoch: 8 [4480/13906 (32%)]\tLoss: 0.135298\n",
      "Train Epoch: 8 [5120/13906 (37%)]\tLoss: 0.323323\n",
      "Train Epoch: 8 [5760/13906 (41%)]\tLoss: 0.072310\n",
      "Train Epoch: 8 [6400/13906 (46%)]\tLoss: 0.126704\n",
      "Train Epoch: 8 [7040/13906 (50%)]\tLoss: 0.047515\n",
      "Train Epoch: 8 [7680/13906 (55%)]\tLoss: 0.073676\n",
      "Train Epoch: 8 [8320/13906 (60%)]\tLoss: 0.031302\n",
      "Train Epoch: 8 [8960/13906 (64%)]\tLoss: 0.023974\n",
      "Train Epoch: 8 [9600/13906 (69%)]\tLoss: 0.091218\n",
      "Train Epoch: 8 [10240/13906 (73%)]\tLoss: 0.023956\n",
      "Train Epoch: 8 [10880/13906 (78%)]\tLoss: 0.033497\n",
      "Train Epoch: 8 [11520/13906 (83%)]\tLoss: 0.128400\n",
      "Train Epoch: 8 [12160/13906 (87%)]\tLoss: 0.047148\n",
      "Train Epoch: 8 [12800/13906 (92%)]\tLoss: 0.117426\n",
      "Train Epoch: 8 [13440/13906 (96%)]\tLoss: 0.044443\n",
      "Train Epoch: 9 [0/13906 (0%)]\tLoss: 0.041433\n",
      "Train Epoch: 9 [640/13906 (5%)]\tLoss: 0.198406\n",
      "Train Epoch: 9 [1280/13906 (9%)]\tLoss: 0.099293\n",
      "Train Epoch: 9 [1920/13906 (14%)]\tLoss: 0.063245\n",
      "Train Epoch: 9 [2560/13906 (18%)]\tLoss: 0.102482\n",
      "Train Epoch: 9 [3200/13906 (23%)]\tLoss: 0.042240\n",
      "Train Epoch: 9 [3840/13906 (28%)]\tLoss: 0.070571\n",
      "Train Epoch: 9 [4480/13906 (32%)]\tLoss: 0.029894\n",
      "Train Epoch: 9 [5120/13906 (37%)]\tLoss: 0.066847\n",
      "Train Epoch: 9 [5760/13906 (41%)]\tLoss: 0.027470\n",
      "Train Epoch: 9 [6400/13906 (46%)]\tLoss: 0.045312\n",
      "Train Epoch: 9 [7040/13906 (50%)]\tLoss: 0.079919\n",
      "Train Epoch: 9 [7680/13906 (55%)]\tLoss: 0.065004\n",
      "Train Epoch: 9 [8320/13906 (60%)]\tLoss: 0.038338\n",
      "Train Epoch: 9 [8960/13906 (64%)]\tLoss: 0.053138\n",
      "Train Epoch: 9 [9600/13906 (69%)]\tLoss: 0.016150\n",
      "Train Epoch: 9 [10240/13906 (73%)]\tLoss: 0.062716\n",
      "Train Epoch: 9 [10880/13906 (78%)]\tLoss: 0.091940\n",
      "Train Epoch: 9 [11520/13906 (83%)]\tLoss: 0.057536\n",
      "Train Epoch: 9 [12160/13906 (87%)]\tLoss: 0.081024\n",
      "Train Epoch: 9 [12800/13906 (92%)]\tLoss: 0.241573\n",
      "Train Epoch: 9 [13440/13906 (96%)]\tLoss: 0.253480\n",
      "Train Epoch: 10 [0/13906 (0%)]\tLoss: 0.029508\n",
      "Train Epoch: 10 [640/13906 (5%)]\tLoss: 0.097708\n",
      "Train Epoch: 10 [1280/13906 (9%)]\tLoss: 0.097947\n",
      "Train Epoch: 10 [1920/13906 (14%)]\tLoss: 0.084426\n",
      "Train Epoch: 10 [2560/13906 (18%)]\tLoss: 0.027828\n",
      "Train Epoch: 10 [3200/13906 (23%)]\tLoss: 0.312063\n",
      "Train Epoch: 10 [3840/13906 (28%)]\tLoss: 0.063080\n",
      "Train Epoch: 10 [4480/13906 (32%)]\tLoss: 0.070435\n",
      "Train Epoch: 10 [5120/13906 (37%)]\tLoss: 0.036898\n",
      "Train Epoch: 10 [5760/13906 (41%)]\tLoss: 0.010472\n",
      "Train Epoch: 10 [6400/13906 (46%)]\tLoss: 0.027476\n",
      "Train Epoch: 10 [7040/13906 (50%)]\tLoss: 0.034261\n",
      "Train Epoch: 10 [7680/13906 (55%)]\tLoss: 0.088298\n",
      "Train Epoch: 10 [8320/13906 (60%)]\tLoss: 0.140595\n",
      "Train Epoch: 10 [8960/13906 (64%)]\tLoss: 0.278756\n",
      "Train Epoch: 10 [9600/13906 (69%)]\tLoss: 0.181905\n",
      "Train Epoch: 10 [10240/13906 (73%)]\tLoss: 0.097083\n",
      "Train Epoch: 10 [10880/13906 (78%)]\tLoss: 0.030478\n",
      "Train Epoch: 10 [11520/13906 (83%)]\tLoss: 0.091349\n",
      "Train Epoch: 10 [12160/13906 (87%)]\tLoss: 0.017809\n",
      "Train Epoch: 10 [12800/13906 (92%)]\tLoss: 0.125543\n",
      "Train Epoch: 10 [13440/13906 (96%)]\tLoss: 0.090951\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/11862 (0%)]\tLoss: 0.205990\n",
      "Train Epoch: 1 [640/11862 (5%)]\tLoss: 0.156218\n",
      "Train Epoch: 1 [1280/11862 (11%)]\tLoss: 0.074337\n",
      "Train Epoch: 1 [1920/11862 (16%)]\tLoss: 0.006520\n",
      "Train Epoch: 1 [2560/11862 (22%)]\tLoss: 0.027280\n",
      "Train Epoch: 1 [3200/11862 (27%)]\tLoss: 0.125453\n",
      "Train Epoch: 1 [3840/11862 (32%)]\tLoss: 0.174633\n",
      "Train Epoch: 1 [4480/11862 (38%)]\tLoss: 0.020686\n",
      "Train Epoch: 1 [5120/11862 (43%)]\tLoss: 0.022759\n",
      "Train Epoch: 1 [5760/11862 (48%)]\tLoss: 0.075922\n",
      "Train Epoch: 1 [6400/11862 (54%)]\tLoss: 0.129423\n",
      "Train Epoch: 1 [7040/11862 (59%)]\tLoss: 0.050342\n",
      "Train Epoch: 1 [7680/11862 (65%)]\tLoss: 0.454667\n",
      "Train Epoch: 1 [8320/11862 (70%)]\tLoss: 0.061225\n",
      "Train Epoch: 1 [8960/11862 (75%)]\tLoss: 0.096192\n",
      "Train Epoch: 1 [9600/11862 (81%)]\tLoss: 0.078093\n",
      "Train Epoch: 1 [10240/11862 (86%)]\tLoss: 0.137352\n",
      "Train Epoch: 1 [10880/11862 (91%)]\tLoss: 0.078460\n",
      "Train Epoch: 1 [11520/11862 (97%)]\tLoss: 0.003999\n",
      "Train Epoch: 2 [0/11862 (0%)]\tLoss: 0.029089\n",
      "Train Epoch: 2 [640/11862 (5%)]\tLoss: 0.100922\n",
      "Train Epoch: 2 [1280/11862 (11%)]\tLoss: 0.061575\n",
      "Train Epoch: 2 [1920/11862 (16%)]\tLoss: 0.101250\n",
      "Train Epoch: 2 [2560/11862 (22%)]\tLoss: 0.052286\n",
      "Train Epoch: 2 [3200/11862 (27%)]\tLoss: 0.140167\n",
      "Train Epoch: 2 [3840/11862 (32%)]\tLoss: 0.144021\n",
      "Train Epoch: 2 [4480/11862 (38%)]\tLoss: 0.243612\n",
      "Train Epoch: 2 [5120/11862 (43%)]\tLoss: 0.051392\n",
      "Train Epoch: 2 [5760/11862 (48%)]\tLoss: 0.200453\n",
      "Train Epoch: 2 [6400/11862 (54%)]\tLoss: 0.050665\n",
      "Train Epoch: 2 [7040/11862 (59%)]\tLoss: 0.052336\n",
      "Train Epoch: 2 [7680/11862 (65%)]\tLoss: 0.064767\n",
      "Train Epoch: 2 [8320/11862 (70%)]\tLoss: 0.162154\n",
      "Train Epoch: 2 [8960/11862 (75%)]\tLoss: 0.059136\n",
      "Train Epoch: 2 [9600/11862 (81%)]\tLoss: 0.093080\n",
      "Train Epoch: 2 [10240/11862 (86%)]\tLoss: 0.145079\n",
      "Train Epoch: 2 [10880/11862 (91%)]\tLoss: 0.091872\n",
      "Train Epoch: 2 [11520/11862 (97%)]\tLoss: 0.101981\n",
      "Train Epoch: 3 [0/11862 (0%)]\tLoss: 0.068296\n",
      "Train Epoch: 3 [640/11862 (5%)]\tLoss: 0.110138\n",
      "Train Epoch: 3 [1280/11862 (11%)]\tLoss: 0.055522\n",
      "Train Epoch: 3 [1920/11862 (16%)]\tLoss: 0.051803\n",
      "Train Epoch: 3 [2560/11862 (22%)]\tLoss: 0.014361\n",
      "Train Epoch: 3 [3200/11862 (27%)]\tLoss: 0.024410\n",
      "Train Epoch: 3 [3840/11862 (32%)]\tLoss: 0.020737\n",
      "Train Epoch: 3 [4480/11862 (38%)]\tLoss: 0.009345\n",
      "Train Epoch: 3 [5120/11862 (43%)]\tLoss: 0.029922\n",
      "Train Epoch: 3 [5760/11862 (48%)]\tLoss: 0.205496\n",
      "Train Epoch: 3 [6400/11862 (54%)]\tLoss: 0.037318\n",
      "Train Epoch: 3 [7040/11862 (59%)]\tLoss: 0.086842\n",
      "Train Epoch: 3 [7680/11862 (65%)]\tLoss: 0.060394\n",
      "Train Epoch: 3 [8320/11862 (70%)]\tLoss: 0.094510\n",
      "Train Epoch: 3 [8960/11862 (75%)]\tLoss: 0.064842\n",
      "Train Epoch: 3 [9600/11862 (81%)]\tLoss: 0.073678\n",
      "Train Epoch: 3 [10240/11862 (86%)]\tLoss: 0.132378\n",
      "Train Epoch: 3 [10880/11862 (91%)]\tLoss: 0.078226\n",
      "Train Epoch: 3 [11520/11862 (97%)]\tLoss: 0.188577\n",
      "Train Epoch: 4 [0/11862 (0%)]\tLoss: 0.096144\n",
      "Train Epoch: 4 [640/11862 (5%)]\tLoss: 0.127458\n",
      "Train Epoch: 4 [1280/11862 (11%)]\tLoss: 0.038944\n",
      "Train Epoch: 4 [1920/11862 (16%)]\tLoss: 0.052236\n",
      "Train Epoch: 4 [2560/11862 (22%)]\tLoss: 0.020128\n",
      "Train Epoch: 4 [3200/11862 (27%)]\tLoss: 0.073859\n",
      "Train Epoch: 4 [3840/11862 (32%)]\tLoss: 0.018824\n",
      "Train Epoch: 4 [4480/11862 (38%)]\tLoss: 0.050019\n",
      "Train Epoch: 4 [5120/11862 (43%)]\tLoss: 0.078310\n",
      "Train Epoch: 4 [5760/11862 (48%)]\tLoss: 0.032665\n",
      "Train Epoch: 4 [6400/11862 (54%)]\tLoss: 0.052719\n",
      "Train Epoch: 4 [7040/11862 (59%)]\tLoss: 0.168987\n",
      "Train Epoch: 4 [7680/11862 (65%)]\tLoss: 0.126626\n",
      "Train Epoch: 4 [8320/11862 (70%)]\tLoss: 0.017766\n",
      "Train Epoch: 4 [8960/11862 (75%)]\tLoss: 0.021395\n",
      "Train Epoch: 4 [9600/11862 (81%)]\tLoss: 0.014576\n",
      "Train Epoch: 4 [10240/11862 (86%)]\tLoss: 0.008047\n",
      "Train Epoch: 4 [10880/11862 (91%)]\tLoss: 0.033589\n",
      "Train Epoch: 4 [11520/11862 (97%)]\tLoss: 0.299392\n",
      "Train Epoch: 5 [0/11862 (0%)]\tLoss: 0.021650\n",
      "Train Epoch: 5 [640/11862 (5%)]\tLoss: 0.051718\n",
      "Train Epoch: 5 [1280/11862 (11%)]\tLoss: 0.015620\n",
      "Train Epoch: 5 [1920/11862 (16%)]\tLoss: 0.080482\n",
      "Train Epoch: 5 [2560/11862 (22%)]\tLoss: 0.027935\n",
      "Train Epoch: 5 [3200/11862 (27%)]\tLoss: 0.049877\n",
      "Train Epoch: 5 [3840/11862 (32%)]\tLoss: 0.023353\n",
      "Train Epoch: 5 [4480/11862 (38%)]\tLoss: 0.142428\n",
      "Train Epoch: 5 [5120/11862 (43%)]\tLoss: 0.015676\n",
      "Train Epoch: 5 [5760/11862 (48%)]\tLoss: 0.047969\n",
      "Train Epoch: 5 [6400/11862 (54%)]\tLoss: 0.160244\n",
      "Train Epoch: 5 [7040/11862 (59%)]\tLoss: 0.064152\n",
      "Train Epoch: 5 [7680/11862 (65%)]\tLoss: 0.072604\n",
      "Train Epoch: 5 [8320/11862 (70%)]\tLoss: 0.109203\n",
      "Train Epoch: 5 [8960/11862 (75%)]\tLoss: 0.004226\n",
      "Train Epoch: 5 [9600/11862 (81%)]\tLoss: 0.022952\n",
      "Train Epoch: 5 [10240/11862 (86%)]\tLoss: 0.030787\n",
      "Train Epoch: 5 [10880/11862 (91%)]\tLoss: 0.031159\n",
      "Train Epoch: 5 [11520/11862 (97%)]\tLoss: 0.059002\n",
      "Train Epoch: 6 [0/11862 (0%)]\tLoss: 0.008916\n",
      "Train Epoch: 6 [640/11862 (5%)]\tLoss: 0.036541\n",
      "Train Epoch: 6 [1280/11862 (11%)]\tLoss: 0.071978\n",
      "Train Epoch: 6 [1920/11862 (16%)]\tLoss: 0.045203\n",
      "Train Epoch: 6 [2560/11862 (22%)]\tLoss: 0.115915\n",
      "Train Epoch: 6 [3200/11862 (27%)]\tLoss: 0.038148\n",
      "Train Epoch: 6 [3840/11862 (32%)]\tLoss: 0.052758\n",
      "Train Epoch: 6 [4480/11862 (38%)]\tLoss: 0.048231\n",
      "Train Epoch: 6 [5120/11862 (43%)]\tLoss: 0.032345\n",
      "Train Epoch: 6 [5760/11862 (48%)]\tLoss: 0.077628\n",
      "Train Epoch: 6 [6400/11862 (54%)]\tLoss: 0.044015\n",
      "Train Epoch: 6 [7040/11862 (59%)]\tLoss: 0.053703\n",
      "Train Epoch: 6 [7680/11862 (65%)]\tLoss: 0.013818\n",
      "Train Epoch: 6 [8320/11862 (70%)]\tLoss: 0.021295\n",
      "Train Epoch: 6 [8960/11862 (75%)]\tLoss: 0.014443\n",
      "Train Epoch: 6 [9600/11862 (81%)]\tLoss: 0.021361\n",
      "Train Epoch: 6 [10240/11862 (86%)]\tLoss: 0.020239\n",
      "Train Epoch: 6 [10880/11862 (91%)]\tLoss: 0.132144\n",
      "Train Epoch: 6 [11520/11862 (97%)]\tLoss: 0.008092\n",
      "Train Epoch: 7 [0/11862 (0%)]\tLoss: 0.019437\n",
      "Train Epoch: 7 [640/11862 (5%)]\tLoss: 0.071745\n",
      "Train Epoch: 7 [1280/11862 (11%)]\tLoss: 0.055305\n",
      "Train Epoch: 7 [1920/11862 (16%)]\tLoss: 0.111665\n",
      "Train Epoch: 7 [2560/11862 (22%)]\tLoss: 0.059408\n",
      "Train Epoch: 7 [3200/11862 (27%)]\tLoss: 0.080207\n",
      "Train Epoch: 7 [3840/11862 (32%)]\tLoss: 0.032928\n",
      "Train Epoch: 7 [4480/11862 (38%)]\tLoss: 0.114337\n",
      "Train Epoch: 7 [5120/11862 (43%)]\tLoss: 0.155105\n",
      "Train Epoch: 7 [5760/11862 (48%)]\tLoss: 0.014292\n",
      "Train Epoch: 7 [6400/11862 (54%)]\tLoss: 0.037912\n",
      "Train Epoch: 7 [7040/11862 (59%)]\tLoss: 0.092957\n",
      "Train Epoch: 7 [7680/11862 (65%)]\tLoss: 0.015174\n",
      "Train Epoch: 7 [8320/11862 (70%)]\tLoss: 0.028799\n",
      "Train Epoch: 7 [8960/11862 (75%)]\tLoss: 0.060692\n",
      "Train Epoch: 7 [9600/11862 (81%)]\tLoss: 0.017446\n",
      "Train Epoch: 7 [10240/11862 (86%)]\tLoss: 0.050391\n",
      "Train Epoch: 7 [10880/11862 (91%)]\tLoss: 0.032615\n",
      "Train Epoch: 7 [11520/11862 (97%)]\tLoss: 0.188500\n",
      "Train Epoch: 8 [0/11862 (0%)]\tLoss: 0.077876\n",
      "Train Epoch: 8 [640/11862 (5%)]\tLoss: 0.010220\n",
      "Train Epoch: 8 [1280/11862 (11%)]\tLoss: 0.095390\n",
      "Train Epoch: 8 [1920/11862 (16%)]\tLoss: 0.012581\n",
      "Train Epoch: 8 [2560/11862 (22%)]\tLoss: 0.096599\n",
      "Train Epoch: 8 [3200/11862 (27%)]\tLoss: 0.112201\n",
      "Train Epoch: 8 [3840/11862 (32%)]\tLoss: 0.153441\n",
      "Train Epoch: 8 [4480/11862 (38%)]\tLoss: 0.114852\n",
      "Train Epoch: 8 [5120/11862 (43%)]\tLoss: 0.026540\n",
      "Train Epoch: 8 [5760/11862 (48%)]\tLoss: 0.118198\n",
      "Train Epoch: 8 [6400/11862 (54%)]\tLoss: 0.014159\n",
      "Train Epoch: 8 [7040/11862 (59%)]\tLoss: 0.080403\n",
      "Train Epoch: 8 [7680/11862 (65%)]\tLoss: 0.018363\n",
      "Train Epoch: 8 [8320/11862 (70%)]\tLoss: 0.086983\n",
      "Train Epoch: 8 [8960/11862 (75%)]\tLoss: 0.109817\n",
      "Train Epoch: 8 [9600/11862 (81%)]\tLoss: 0.022493\n",
      "Train Epoch: 8 [10240/11862 (86%)]\tLoss: 0.032628\n",
      "Train Epoch: 8 [10880/11862 (91%)]\tLoss: 0.019682\n",
      "Train Epoch: 8 [11520/11862 (97%)]\tLoss: 0.101438\n",
      "Train Epoch: 9 [0/11862 (0%)]\tLoss: 0.006066\n",
      "Train Epoch: 9 [640/11862 (5%)]\tLoss: 0.058913\n",
      "Train Epoch: 9 [1280/11862 (11%)]\tLoss: 0.012116\n",
      "Train Epoch: 9 [1920/11862 (16%)]\tLoss: 0.059325\n",
      "Train Epoch: 9 [2560/11862 (22%)]\tLoss: 0.104665\n",
      "Train Epoch: 9 [3200/11862 (27%)]\tLoss: 0.020956\n",
      "Train Epoch: 9 [3840/11862 (32%)]\tLoss: 0.092524\n",
      "Train Epoch: 9 [4480/11862 (38%)]\tLoss: 0.051249\n",
      "Train Epoch: 9 [5120/11862 (43%)]\tLoss: 0.051032\n",
      "Train Epoch: 9 [5760/11862 (48%)]\tLoss: 0.064128\n",
      "Train Epoch: 9 [6400/11862 (54%)]\tLoss: 0.128951\n",
      "Train Epoch: 9 [7040/11862 (59%)]\tLoss: 0.001741\n",
      "Train Epoch: 9 [7680/11862 (65%)]\tLoss: 0.037625\n",
      "Train Epoch: 9 [8320/11862 (70%)]\tLoss: 0.040684\n",
      "Train Epoch: 9 [8960/11862 (75%)]\tLoss: 0.012174\n",
      "Train Epoch: 9 [9600/11862 (81%)]\tLoss: 0.042781\n",
      "Train Epoch: 9 [10240/11862 (86%)]\tLoss: 0.012604\n",
      "Train Epoch: 9 [10880/11862 (91%)]\tLoss: 0.012519\n",
      "Train Epoch: 9 [11520/11862 (97%)]\tLoss: 0.010842\n",
      "Train Epoch: 10 [0/11862 (0%)]\tLoss: 0.062869\n",
      "Train Epoch: 10 [640/11862 (5%)]\tLoss: 0.060263\n",
      "Train Epoch: 10 [1280/11862 (11%)]\tLoss: 0.016429\n",
      "Train Epoch: 10 [1920/11862 (16%)]\tLoss: 0.086855\n",
      "Train Epoch: 10 [2560/11862 (22%)]\tLoss: 0.123379\n",
      "Train Epoch: 10 [3200/11862 (27%)]\tLoss: 0.046388\n",
      "Train Epoch: 10 [3840/11862 (32%)]\tLoss: 0.030337\n",
      "Train Epoch: 10 [4480/11862 (38%)]\tLoss: 0.223243\n",
      "Train Epoch: 10 [5120/11862 (43%)]\tLoss: 0.068099\n",
      "Train Epoch: 10 [5760/11862 (48%)]\tLoss: 0.027414\n",
      "Train Epoch: 10 [6400/11862 (54%)]\tLoss: 0.001698\n",
      "Train Epoch: 10 [7040/11862 (59%)]\tLoss: 0.013520\n",
      "Train Epoch: 10 [7680/11862 (65%)]\tLoss: 0.056967\n",
      "Train Epoch: 10 [8320/11862 (70%)]\tLoss: 0.018370\n",
      "Train Epoch: 10 [8960/11862 (75%)]\tLoss: 0.011770\n",
      "Train Epoch: 10 [9600/11862 (81%)]\tLoss: 0.046703\n",
      "Train Epoch: 10 [10240/11862 (86%)]\tLoss: 0.069671\n",
      "Train Epoch: 10 [10880/11862 (91%)]\tLoss: 0.049145\n",
      "Train Epoch: 10 [11520/11862 (97%)]\tLoss: 0.028883\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 0.042089\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 0.055890\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 0.056107\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 0.027317\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 0.148077\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 0.056370\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 0.091026\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 0.170564\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 0.097975\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 0.099703\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 0.136833\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 0.058278\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 0.025428\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 0.104067\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 0.126352\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 0.047657\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 0.031520\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.026992\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.024229\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.146286\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.025995\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.030693\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.101710\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.038267\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.104045\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.096485\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.038756\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.110732\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.011819\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.221106\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.332087\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.031338\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.018533\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.050687\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.073080\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.031666\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.101926\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.145235\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.015872\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.048250\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.102469\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.007791\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.029940\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.138267\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.073715\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.083878\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.090039\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.087067\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.016922\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.009881\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.121192\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.074678\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.004530\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.026519\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.184207\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.034691\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.053325\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.059407\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.069971\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.070746\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.036508\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.025993\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.049129\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.034062\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.072284\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.055476\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.088337\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.017241\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.075344\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.051328\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.039093\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.046464\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.056966\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.029566\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.040121\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.029499\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.101552\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.012742\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.084298\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.035087\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.013248\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.035468\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.140153\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.038840\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.016691\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.141082\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.021846\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.006487\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.015336\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.061561\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.004933\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.094860\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.048734\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.227893\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.057799\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.110646\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.019615\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.028167\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.038273\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.005750\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.072452\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.016972\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.039887\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.011977\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.053009\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.031906\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.020632\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.066798\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.041247\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.083583\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.050976\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.111869\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.041791\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.018567\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.052533\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.012586\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.056728\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.091495\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.020008\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.044888\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.023446\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.197981\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.050766\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.052573\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.085118\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.004250\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.118869\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.047065\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.045237\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.078616\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.084976\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.101309\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.051444\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.042924\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.002516\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.075098\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.119619\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.003294\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.017397\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.036378\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.051598\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.046642\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.075136\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.014547\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.019051\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.024908\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.029717\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.095044\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.021022\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.032287\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.048261\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.036486\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.051779\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.094493\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.089178\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.040760\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.033048\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.036331\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.042399\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.020823\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5509 (0%)]\tLoss: 0.223058\n",
      "Train Epoch: 1 [640/5509 (11%)]\tLoss: 0.081001\n",
      "Train Epoch: 1 [1280/5509 (23%)]\tLoss: 0.048878\n",
      "Train Epoch: 1 [1920/5509 (34%)]\tLoss: 0.102547\n",
      "Train Epoch: 1 [2560/5509 (46%)]\tLoss: 0.055761\n",
      "Train Epoch: 1 [3200/5509 (57%)]\tLoss: 0.060056\n",
      "Train Epoch: 1 [3840/5509 (69%)]\tLoss: 0.124009\n",
      "Train Epoch: 1 [4480/5509 (80%)]\tLoss: 0.091931\n",
      "Train Epoch: 1 [5120/5509 (92%)]\tLoss: 0.161463\n",
      "Train Epoch: 2 [0/5509 (0%)]\tLoss: 0.037912\n",
      "Train Epoch: 2 [640/5509 (11%)]\tLoss: 0.035591\n",
      "Train Epoch: 2 [1280/5509 (23%)]\tLoss: 0.016300\n",
      "Train Epoch: 2 [1920/5509 (34%)]\tLoss: 0.065045\n",
      "Train Epoch: 2 [2560/5509 (46%)]\tLoss: 0.022303\n",
      "Train Epoch: 2 [3200/5509 (57%)]\tLoss: 0.258765\n",
      "Train Epoch: 2 [3840/5509 (69%)]\tLoss: 0.214844\n",
      "Train Epoch: 2 [4480/5509 (80%)]\tLoss: 0.019549\n",
      "Train Epoch: 2 [5120/5509 (92%)]\tLoss: 0.057293\n",
      "Train Epoch: 3 [0/5509 (0%)]\tLoss: 0.014648\n",
      "Train Epoch: 3 [640/5509 (11%)]\tLoss: 0.065766\n",
      "Train Epoch: 3 [1280/5509 (23%)]\tLoss: 0.092115\n",
      "Train Epoch: 3 [1920/5509 (34%)]\tLoss: 0.063110\n",
      "Train Epoch: 3 [2560/5509 (46%)]\tLoss: 0.022399\n",
      "Train Epoch: 3 [3200/5509 (57%)]\tLoss: 0.021712\n",
      "Train Epoch: 3 [3840/5509 (69%)]\tLoss: 0.040743\n",
      "Train Epoch: 3 [4480/5509 (80%)]\tLoss: 0.096919\n",
      "Train Epoch: 3 [5120/5509 (92%)]\tLoss: 0.101279\n",
      "Train Epoch: 4 [0/5509 (0%)]\tLoss: 0.035751\n",
      "Train Epoch: 4 [640/5509 (11%)]\tLoss: 0.098248\n",
      "Train Epoch: 4 [1280/5509 (23%)]\tLoss: 0.031841\n",
      "Train Epoch: 4 [1920/5509 (34%)]\tLoss: 0.240066\n",
      "Train Epoch: 4 [2560/5509 (46%)]\tLoss: 0.065084\n",
      "Train Epoch: 4 [3200/5509 (57%)]\tLoss: 0.106091\n",
      "Train Epoch: 4 [3840/5509 (69%)]\tLoss: 0.041313\n",
      "Train Epoch: 4 [4480/5509 (80%)]\tLoss: 0.447507\n",
      "Train Epoch: 4 [5120/5509 (92%)]\tLoss: 0.022688\n",
      "Train Epoch: 5 [0/5509 (0%)]\tLoss: 0.041874\n",
      "Train Epoch: 5 [640/5509 (11%)]\tLoss: 0.032144\n",
      "Train Epoch: 5 [1280/5509 (23%)]\tLoss: 0.026674\n",
      "Train Epoch: 5 [1920/5509 (34%)]\tLoss: 0.057108\n",
      "Train Epoch: 5 [2560/5509 (46%)]\tLoss: 0.070689\n",
      "Train Epoch: 5 [3200/5509 (57%)]\tLoss: 0.074172\n",
      "Train Epoch: 5 [3840/5509 (69%)]\tLoss: 0.036395\n",
      "Train Epoch: 5 [4480/5509 (80%)]\tLoss: 0.091809\n",
      "Train Epoch: 5 [5120/5509 (92%)]\tLoss: 0.059275\n",
      "Train Epoch: 6 [0/5509 (0%)]\tLoss: 0.031964\n",
      "Train Epoch: 6 [640/5509 (11%)]\tLoss: 0.146518\n",
      "Train Epoch: 6 [1280/5509 (23%)]\tLoss: 0.166965\n",
      "Train Epoch: 6 [1920/5509 (34%)]\tLoss: 0.035235\n",
      "Train Epoch: 6 [2560/5509 (46%)]\tLoss: 0.028792\n",
      "Train Epoch: 6 [3200/5509 (57%)]\tLoss: 0.066758\n",
      "Train Epoch: 6 [3840/5509 (69%)]\tLoss: 0.155129\n",
      "Train Epoch: 6 [4480/5509 (80%)]\tLoss: 0.012641\n",
      "Train Epoch: 6 [5120/5509 (92%)]\tLoss: 0.018513\n",
      "Train Epoch: 7 [0/5509 (0%)]\tLoss: 0.026355\n",
      "Train Epoch: 7 [640/5509 (11%)]\tLoss: 0.349896\n",
      "Train Epoch: 7 [1280/5509 (23%)]\tLoss: 0.020358\n",
      "Train Epoch: 7 [1920/5509 (34%)]\tLoss: 0.042663\n",
      "Train Epoch: 7 [2560/5509 (46%)]\tLoss: 0.053036\n",
      "Train Epoch: 7 [3200/5509 (57%)]\tLoss: 0.068340\n",
      "Train Epoch: 7 [3840/5509 (69%)]\tLoss: 0.071662\n",
      "Train Epoch: 7 [4480/5509 (80%)]\tLoss: 0.029801\n",
      "Train Epoch: 7 [5120/5509 (92%)]\tLoss: 0.017364\n",
      "Train Epoch: 8 [0/5509 (0%)]\tLoss: 0.112041\n",
      "Train Epoch: 8 [640/5509 (11%)]\tLoss: 0.087227\n",
      "Train Epoch: 8 [1280/5509 (23%)]\tLoss: 0.106437\n",
      "Train Epoch: 8 [1920/5509 (34%)]\tLoss: 0.072207\n",
      "Train Epoch: 8 [2560/5509 (46%)]\tLoss: 0.079876\n",
      "Train Epoch: 8 [3200/5509 (57%)]\tLoss: 0.100613\n",
      "Train Epoch: 8 [3840/5509 (69%)]\tLoss: 0.085141\n",
      "Train Epoch: 8 [4480/5509 (80%)]\tLoss: 0.110662\n",
      "Train Epoch: 8 [5120/5509 (92%)]\tLoss: 0.080681\n",
      "Train Epoch: 9 [0/5509 (0%)]\tLoss: 0.030080\n",
      "Train Epoch: 9 [640/5509 (11%)]\tLoss: 0.071691\n",
      "Train Epoch: 9 [1280/5509 (23%)]\tLoss: 0.141778\n",
      "Train Epoch: 9 [1920/5509 (34%)]\tLoss: 0.083927\n",
      "Train Epoch: 9 [2560/5509 (46%)]\tLoss: 0.066865\n",
      "Train Epoch: 9 [3200/5509 (57%)]\tLoss: 0.024357\n",
      "Train Epoch: 9 [3840/5509 (69%)]\tLoss: 0.071623\n",
      "Train Epoch: 9 [4480/5509 (80%)]\tLoss: 0.115076\n",
      "Train Epoch: 9 [5120/5509 (92%)]\tLoss: 0.150974\n",
      "Train Epoch: 10 [0/5509 (0%)]\tLoss: 0.131668\n",
      "Train Epoch: 10 [640/5509 (11%)]\tLoss: 0.041784\n",
      "Train Epoch: 10 [1280/5509 (23%)]\tLoss: 0.080876\n",
      "Train Epoch: 10 [1920/5509 (34%)]\tLoss: 0.018900\n",
      "Train Epoch: 10 [2560/5509 (46%)]\tLoss: 0.039777\n",
      "Train Epoch: 10 [3200/5509 (57%)]\tLoss: 0.081775\n",
      "Train Epoch: 10 [3840/5509 (69%)]\tLoss: 0.030285\n",
      "Train Epoch: 10 [4480/5509 (80%)]\tLoss: 0.130809\n",
      "Train Epoch: 10 [5120/5509 (92%)]\tLoss: 0.142363\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 0.164145\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 0.108191\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 0.107793\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 0.061207\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 0.080035\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 0.006703\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 0.022714\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 0.015395\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 0.026984\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 0.014446\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.032570\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.083101\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 0.129835\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 0.090578\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 0.118810\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.128058\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.157387\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.233328\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.051253\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.019783\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.004023\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.028444\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.092356\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.044859\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.005038\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.047418\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.053849\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.040607\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.019618\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.040831\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.029665\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.042654\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.095588\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.009187\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.018860\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.059859\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.015990\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.040147\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.015229\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.104705\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.048341\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.028762\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.071122\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.013997\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.025297\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.010725\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.023283\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.004317\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.050727\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.007930\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.011572\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.079850\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.063211\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.057136\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.064198\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.014727\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.065871\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.033123\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.115421\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.006183\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.040397\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.040912\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.032367\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.056599\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.009880\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.058014\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.009212\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.018555\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.063176\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.045707\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.036364\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.025412\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.030784\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.044353\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.058673\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.044942\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.004501\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.051641\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.118375\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.045637\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.007285\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.048926\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.003962\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.156431\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.045127\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.003336\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.108111\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.029775\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.046611\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.006346\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.018460\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.018976\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.007458\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.058452\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.098662\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.135048\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.013352\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.003074\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.012250\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.029837\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.113191\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.036970\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.079239\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.031278\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.011735\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.005741\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.007978\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.014901\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.048333\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.016760\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.005826\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.108962\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.018325\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.011464\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.132777\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.052444\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.002163\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.011285\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.008582\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.007232\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0507, Accuracy: 9829/10000 (98%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 0.064220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 0.080172\n",
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 0.080411\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 0.093185\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 0.169064\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 0.032007\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 0.063327\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 0.106697\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 0.027452\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 0.073569\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 0.037638\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 0.084929\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 0.164901\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 0.108085\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 0.301310\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 0.166458\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 0.083375\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 0.048274\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 0.118148\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 0.090944\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.043337\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 0.026096\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 0.153331\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.040723\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.030521\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 0.052776\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.014432\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 0.103136\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.115836\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.026153\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.041065\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.031375\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.028946\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.038207\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.026734\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.037914\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.115544\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.257121\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.020537\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.092270\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.139167\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.054208\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.028988\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.063132\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.028030\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.099569\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.077599\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.055051\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.074735\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.040816\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.152024\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.030616\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.021714\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.077946\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.061666\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.073766\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.057800\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.096711\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.018293\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.050765\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.057830\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.142108\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.154143\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.014761\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.012649\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.091050\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.085163\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.201162\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.021866\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.254287\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.063675\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.095845\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.038552\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.019272\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.092182\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.022969\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.125172\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.062983\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.151758\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.136796\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.080091\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.089836\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.053934\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.067246\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.032527\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.064272\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.037384\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.271572\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.216624\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.057183\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.026696\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.043038\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.043562\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.268794\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.101628\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.074430\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.095388\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.055004\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.075666\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.056948\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.139541\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.091507\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.079208\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.069071\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.026716\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.141527\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.098359\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.007460\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 0.032384\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.031334\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.072706\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.043018\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.088550\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.122624\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.030351\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.075210\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.099382\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.138157\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.055696\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.072025\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.048280\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.114507\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.033468\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.023202\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.052202\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.039844\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.027034\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.088937\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.027236\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.064225\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.054296\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.236939\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.056193\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.021923\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.091909\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.098225\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.110851\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.164780\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.087744\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.063759\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.016824\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.016557\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.045715\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.215615\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.048500\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.096729\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.087741\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.104772\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.081745\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.011286\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.019627\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.016632\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.217388\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.008307\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.026153\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.055612\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.039687\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.053682\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.155789\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.013554\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.038094\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.055724\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.014260\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.036537\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.126944\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.054107\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.050075\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.011302\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.045677\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.016818\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.029737\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.020815\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.031423\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.076876\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.002832\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.068989\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.125944\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.157126\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.015956\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.053509\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/13906 (0%)]\tLoss: 0.244644\n",
      "Train Epoch: 1 [640/13906 (5%)]\tLoss: 0.064108\n",
      "Train Epoch: 1 [1280/13906 (9%)]\tLoss: 0.204991\n",
      "Train Epoch: 1 [1920/13906 (14%)]\tLoss: 0.136326\n",
      "Train Epoch: 1 [2560/13906 (18%)]\tLoss: 0.229362\n",
      "Train Epoch: 1 [3200/13906 (23%)]\tLoss: 0.123668\n",
      "Train Epoch: 1 [3840/13906 (28%)]\tLoss: 0.200289\n",
      "Train Epoch: 1 [4480/13906 (32%)]\tLoss: 0.124664\n",
      "Train Epoch: 1 [5120/13906 (37%)]\tLoss: 0.082973\n",
      "Train Epoch: 1 [5760/13906 (41%)]\tLoss: 0.111872\n",
      "Train Epoch: 1 [6400/13906 (46%)]\tLoss: 0.070058\n",
      "Train Epoch: 1 [7040/13906 (50%)]\tLoss: 0.133778\n",
      "Train Epoch: 1 [7680/13906 (55%)]\tLoss: 0.035974\n",
      "Train Epoch: 1 [8320/13906 (60%)]\tLoss: 0.100463\n",
      "Train Epoch: 1 [8960/13906 (64%)]\tLoss: 0.038940\n",
      "Train Epoch: 1 [9600/13906 (69%)]\tLoss: 0.111118\n",
      "Train Epoch: 1 [10240/13906 (73%)]\tLoss: 0.221848\n",
      "Train Epoch: 1 [10880/13906 (78%)]\tLoss: 0.108669\n",
      "Train Epoch: 1 [11520/13906 (83%)]\tLoss: 0.116494\n",
      "Train Epoch: 1 [12160/13906 (87%)]\tLoss: 0.078775\n",
      "Train Epoch: 1 [12800/13906 (92%)]\tLoss: 0.060054\n",
      "Train Epoch: 1 [13440/13906 (96%)]\tLoss: 0.112227\n",
      "Train Epoch: 2 [0/13906 (0%)]\tLoss: 0.048720\n",
      "Train Epoch: 2 [640/13906 (5%)]\tLoss: 0.246745\n",
      "Train Epoch: 2 [1280/13906 (9%)]\tLoss: 0.079741\n",
      "Train Epoch: 2 [1920/13906 (14%)]\tLoss: 0.136529\n",
      "Train Epoch: 2 [2560/13906 (18%)]\tLoss: 0.007467\n",
      "Train Epoch: 2 [3200/13906 (23%)]\tLoss: 0.116105\n",
      "Train Epoch: 2 [3840/13906 (28%)]\tLoss: 0.110337\n",
      "Train Epoch: 2 [4480/13906 (32%)]\tLoss: 0.032492\n",
      "Train Epoch: 2 [5120/13906 (37%)]\tLoss: 0.086693\n",
      "Train Epoch: 2 [5760/13906 (41%)]\tLoss: 0.058622\n",
      "Train Epoch: 2 [6400/13906 (46%)]\tLoss: 0.285188\n",
      "Train Epoch: 2 [7040/13906 (50%)]\tLoss: 0.061886\n",
      "Train Epoch: 2 [7680/13906 (55%)]\tLoss: 0.108707\n",
      "Train Epoch: 2 [8320/13906 (60%)]\tLoss: 0.056799\n",
      "Train Epoch: 2 [8960/13906 (64%)]\tLoss: 0.156157\n",
      "Train Epoch: 2 [9600/13906 (69%)]\tLoss: 0.083683\n",
      "Train Epoch: 2 [10240/13906 (73%)]\tLoss: 0.048369\n",
      "Train Epoch: 2 [10880/13906 (78%)]\tLoss: 0.116102\n",
      "Train Epoch: 2 [11520/13906 (83%)]\tLoss: 0.093908\n",
      "Train Epoch: 2 [12160/13906 (87%)]\tLoss: 0.051026\n",
      "Train Epoch: 2 [12800/13906 (92%)]\tLoss: 0.029995\n",
      "Train Epoch: 2 [13440/13906 (96%)]\tLoss: 0.031875\n",
      "Train Epoch: 3 [0/13906 (0%)]\tLoss: 0.054510\n",
      "Train Epoch: 3 [640/13906 (5%)]\tLoss: 0.084902\n",
      "Train Epoch: 3 [1280/13906 (9%)]\tLoss: 0.104397\n",
      "Train Epoch: 3 [1920/13906 (14%)]\tLoss: 0.066122\n",
      "Train Epoch: 3 [2560/13906 (18%)]\tLoss: 0.141522\n",
      "Train Epoch: 3 [3200/13906 (23%)]\tLoss: 0.032210\n",
      "Train Epoch: 3 [3840/13906 (28%)]\tLoss: 0.112074\n",
      "Train Epoch: 3 [4480/13906 (32%)]\tLoss: 0.029954\n",
      "Train Epoch: 3 [5120/13906 (37%)]\tLoss: 0.121813\n",
      "Train Epoch: 3 [5760/13906 (41%)]\tLoss: 0.058782\n",
      "Train Epoch: 3 [6400/13906 (46%)]\tLoss: 0.087975\n",
      "Train Epoch: 3 [7040/13906 (50%)]\tLoss: 0.023429\n",
      "Train Epoch: 3 [7680/13906 (55%)]\tLoss: 0.200593\n",
      "Train Epoch: 3 [8320/13906 (60%)]\tLoss: 0.103273\n",
      "Train Epoch: 3 [8960/13906 (64%)]\tLoss: 0.101491\n",
      "Train Epoch: 3 [9600/13906 (69%)]\tLoss: 0.066953\n",
      "Train Epoch: 3 [10240/13906 (73%)]\tLoss: 0.072288\n",
      "Train Epoch: 3 [10880/13906 (78%)]\tLoss: 0.037523\n",
      "Train Epoch: 3 [11520/13906 (83%)]\tLoss: 0.076414\n",
      "Train Epoch: 3 [12160/13906 (87%)]\tLoss: 0.113489\n",
      "Train Epoch: 3 [12800/13906 (92%)]\tLoss: 0.039040\n",
      "Train Epoch: 3 [13440/13906 (96%)]\tLoss: 0.056010\n",
      "Train Epoch: 4 [0/13906 (0%)]\tLoss: 0.040316\n",
      "Train Epoch: 4 [640/13906 (5%)]\tLoss: 0.013346\n",
      "Train Epoch: 4 [1280/13906 (9%)]\tLoss: 0.014570\n",
      "Train Epoch: 4 [1920/13906 (14%)]\tLoss: 0.040738\n",
      "Train Epoch: 4 [2560/13906 (18%)]\tLoss: 0.116347\n",
      "Train Epoch: 4 [3200/13906 (23%)]\tLoss: 0.018199\n",
      "Train Epoch: 4 [3840/13906 (28%)]\tLoss: 0.101284\n",
      "Train Epoch: 4 [4480/13906 (32%)]\tLoss: 0.040225\n",
      "Train Epoch: 4 [5120/13906 (37%)]\tLoss: 0.062539\n",
      "Train Epoch: 4 [5760/13906 (41%)]\tLoss: 0.094557\n",
      "Train Epoch: 4 [6400/13906 (46%)]\tLoss: 0.105910\n",
      "Train Epoch: 4 [7040/13906 (50%)]\tLoss: 0.112164\n",
      "Train Epoch: 4 [7680/13906 (55%)]\tLoss: 0.017086\n",
      "Train Epoch: 4 [8320/13906 (60%)]\tLoss: 0.072558\n",
      "Train Epoch: 4 [8960/13906 (64%)]\tLoss: 0.036776\n",
      "Train Epoch: 4 [9600/13906 (69%)]\tLoss: 0.130788\n",
      "Train Epoch: 4 [10240/13906 (73%)]\tLoss: 0.079269\n",
      "Train Epoch: 4 [10880/13906 (78%)]\tLoss: 0.071927\n",
      "Train Epoch: 4 [11520/13906 (83%)]\tLoss: 0.053255\n",
      "Train Epoch: 4 [12160/13906 (87%)]\tLoss: 0.078884\n",
      "Train Epoch: 4 [12800/13906 (92%)]\tLoss: 0.311397\n",
      "Train Epoch: 4 [13440/13906 (96%)]\tLoss: 0.030822\n",
      "Train Epoch: 5 [0/13906 (0%)]\tLoss: 0.043594\n",
      "Train Epoch: 5 [640/13906 (5%)]\tLoss: 0.058299\n",
      "Train Epoch: 5 [1280/13906 (9%)]\tLoss: 0.057163\n",
      "Train Epoch: 5 [1920/13906 (14%)]\tLoss: 0.165158\n",
      "Train Epoch: 5 [2560/13906 (18%)]\tLoss: 0.007769\n",
      "Train Epoch: 5 [3200/13906 (23%)]\tLoss: 0.095213\n",
      "Train Epoch: 5 [3840/13906 (28%)]\tLoss: 0.056499\n",
      "Train Epoch: 5 [4480/13906 (32%)]\tLoss: 0.051687\n",
      "Train Epoch: 5 [5120/13906 (37%)]\tLoss: 0.056444\n",
      "Train Epoch: 5 [5760/13906 (41%)]\tLoss: 0.179286\n",
      "Train Epoch: 5 [6400/13906 (46%)]\tLoss: 0.073521\n",
      "Train Epoch: 5 [7040/13906 (50%)]\tLoss: 0.150462\n",
      "Train Epoch: 5 [7680/13906 (55%)]\tLoss: 0.028694\n",
      "Train Epoch: 5 [8320/13906 (60%)]\tLoss: 0.036601\n",
      "Train Epoch: 5 [8960/13906 (64%)]\tLoss: 0.205769\n",
      "Train Epoch: 5 [9600/13906 (69%)]\tLoss: 0.035401\n",
      "Train Epoch: 5 [10240/13906 (73%)]\tLoss: 0.023298\n",
      "Train Epoch: 5 [10880/13906 (78%)]\tLoss: 0.062035\n",
      "Train Epoch: 5 [11520/13906 (83%)]\tLoss: 0.037362\n",
      "Train Epoch: 5 [12160/13906 (87%)]\tLoss: 0.021642\n",
      "Train Epoch: 5 [12800/13906 (92%)]\tLoss: 0.126110\n",
      "Train Epoch: 5 [13440/13906 (96%)]\tLoss: 0.235894\n",
      "Train Epoch: 6 [0/13906 (0%)]\tLoss: 0.031236\n",
      "Train Epoch: 6 [640/13906 (5%)]\tLoss: 0.082807\n",
      "Train Epoch: 6 [1280/13906 (9%)]\tLoss: 0.034068\n",
      "Train Epoch: 6 [1920/13906 (14%)]\tLoss: 0.068494\n",
      "Train Epoch: 6 [2560/13906 (18%)]\tLoss: 0.082348\n",
      "Train Epoch: 6 [3200/13906 (23%)]\tLoss: 0.074208\n",
      "Train Epoch: 6 [3840/13906 (28%)]\tLoss: 0.130358\n",
      "Train Epoch: 6 [4480/13906 (32%)]\tLoss: 0.052108\n",
      "Train Epoch: 6 [5120/13906 (37%)]\tLoss: 0.144288\n",
      "Train Epoch: 6 [5760/13906 (41%)]\tLoss: 0.113983\n",
      "Train Epoch: 6 [6400/13906 (46%)]\tLoss: 0.065119\n",
      "Train Epoch: 6 [7040/13906 (50%)]\tLoss: 0.037809\n",
      "Train Epoch: 6 [7680/13906 (55%)]\tLoss: 0.201802\n",
      "Train Epoch: 6 [8320/13906 (60%)]\tLoss: 0.048286\n",
      "Train Epoch: 6 [8960/13906 (64%)]\tLoss: 0.038335\n",
      "Train Epoch: 6 [9600/13906 (69%)]\tLoss: 0.065302\n",
      "Train Epoch: 6 [10240/13906 (73%)]\tLoss: 0.090411\n",
      "Train Epoch: 6 [10880/13906 (78%)]\tLoss: 0.062596\n",
      "Train Epoch: 6 [11520/13906 (83%)]\tLoss: 0.239348\n",
      "Train Epoch: 6 [12160/13906 (87%)]\tLoss: 0.115257\n",
      "Train Epoch: 6 [12800/13906 (92%)]\tLoss: 0.089673\n",
      "Train Epoch: 6 [13440/13906 (96%)]\tLoss: 0.161275\n",
      "Train Epoch: 7 [0/13906 (0%)]\tLoss: 0.213295\n",
      "Train Epoch: 7 [640/13906 (5%)]\tLoss: 0.106604\n",
      "Train Epoch: 7 [1280/13906 (9%)]\tLoss: 0.142875\n",
      "Train Epoch: 7 [1920/13906 (14%)]\tLoss: 0.147465\n",
      "Train Epoch: 7 [2560/13906 (18%)]\tLoss: 0.062632\n",
      "Train Epoch: 7 [3200/13906 (23%)]\tLoss: 0.127533\n",
      "Train Epoch: 7 [3840/13906 (28%)]\tLoss: 0.218550\n",
      "Train Epoch: 7 [4480/13906 (32%)]\tLoss: 0.099792\n",
      "Train Epoch: 7 [5120/13906 (37%)]\tLoss: 0.076740\n",
      "Train Epoch: 7 [5760/13906 (41%)]\tLoss: 0.077191\n",
      "Train Epoch: 7 [6400/13906 (46%)]\tLoss: 0.060531\n",
      "Train Epoch: 7 [7040/13906 (50%)]\tLoss: 0.165476\n",
      "Train Epoch: 7 [7680/13906 (55%)]\tLoss: 0.034735\n",
      "Train Epoch: 7 [8320/13906 (60%)]\tLoss: 0.067871\n",
      "Train Epoch: 7 [8960/13906 (64%)]\tLoss: 0.151795\n",
      "Train Epoch: 7 [9600/13906 (69%)]\tLoss: 0.061668\n",
      "Train Epoch: 7 [10240/13906 (73%)]\tLoss: 0.096535\n",
      "Train Epoch: 7 [10880/13906 (78%)]\tLoss: 0.084896\n",
      "Train Epoch: 7 [11520/13906 (83%)]\tLoss: 0.026549\n",
      "Train Epoch: 7 [12160/13906 (87%)]\tLoss: 0.227794\n",
      "Train Epoch: 7 [12800/13906 (92%)]\tLoss: 0.131490\n",
      "Train Epoch: 7 [13440/13906 (96%)]\tLoss: 0.063417\n",
      "Train Epoch: 8 [0/13906 (0%)]\tLoss: 0.107165\n",
      "Train Epoch: 8 [640/13906 (5%)]\tLoss: 0.114385\n",
      "Train Epoch: 8 [1280/13906 (9%)]\tLoss: 0.027026\n",
      "Train Epoch: 8 [1920/13906 (14%)]\tLoss: 0.130421\n",
      "Train Epoch: 8 [2560/13906 (18%)]\tLoss: 0.050216\n",
      "Train Epoch: 8 [3200/13906 (23%)]\tLoss: 0.054399\n",
      "Train Epoch: 8 [3840/13906 (28%)]\tLoss: 0.042655\n",
      "Train Epoch: 8 [4480/13906 (32%)]\tLoss: 0.152277\n",
      "Train Epoch: 8 [5120/13906 (37%)]\tLoss: 0.011686\n",
      "Train Epoch: 8 [5760/13906 (41%)]\tLoss: 0.117097\n",
      "Train Epoch: 8 [6400/13906 (46%)]\tLoss: 0.080391\n",
      "Train Epoch: 8 [7040/13906 (50%)]\tLoss: 0.030666\n",
      "Train Epoch: 8 [7680/13906 (55%)]\tLoss: 0.095962\n",
      "Train Epoch: 8 [8320/13906 (60%)]\tLoss: 0.071154\n",
      "Train Epoch: 8 [8960/13906 (64%)]\tLoss: 0.087581\n",
      "Train Epoch: 8 [9600/13906 (69%)]\tLoss: 0.061768\n",
      "Train Epoch: 8 [10240/13906 (73%)]\tLoss: 0.241785\n",
      "Train Epoch: 8 [10880/13906 (78%)]\tLoss: 0.229699\n",
      "Train Epoch: 8 [11520/13906 (83%)]\tLoss: 0.026042\n",
      "Train Epoch: 8 [12160/13906 (87%)]\tLoss: 0.237285\n",
      "Train Epoch: 8 [12800/13906 (92%)]\tLoss: 0.055679\n",
      "Train Epoch: 8 [13440/13906 (96%)]\tLoss: 0.039962\n",
      "Train Epoch: 9 [0/13906 (0%)]\tLoss: 0.080093\n",
      "Train Epoch: 9 [640/13906 (5%)]\tLoss: 0.022585\n",
      "Train Epoch: 9 [1280/13906 (9%)]\tLoss: 0.054803\n",
      "Train Epoch: 9 [1920/13906 (14%)]\tLoss: 0.071857\n",
      "Train Epoch: 9 [2560/13906 (18%)]\tLoss: 0.164540\n",
      "Train Epoch: 9 [3200/13906 (23%)]\tLoss: 0.096356\n",
      "Train Epoch: 9 [3840/13906 (28%)]\tLoss: 0.082282\n",
      "Train Epoch: 9 [4480/13906 (32%)]\tLoss: 0.161638\n",
      "Train Epoch: 9 [5120/13906 (37%)]\tLoss: 0.129873\n",
      "Train Epoch: 9 [5760/13906 (41%)]\tLoss: 0.033973\n",
      "Train Epoch: 9 [6400/13906 (46%)]\tLoss: 0.055843\n",
      "Train Epoch: 9 [7040/13906 (50%)]\tLoss: 0.046435\n",
      "Train Epoch: 9 [7680/13906 (55%)]\tLoss: 0.053288\n",
      "Train Epoch: 9 [8320/13906 (60%)]\tLoss: 0.040676\n",
      "Train Epoch: 9 [8960/13906 (64%)]\tLoss: 0.223496\n",
      "Train Epoch: 9 [9600/13906 (69%)]\tLoss: 0.161425\n",
      "Train Epoch: 9 [10240/13906 (73%)]\tLoss: 0.075331\n",
      "Train Epoch: 9 [10880/13906 (78%)]\tLoss: 0.026741\n",
      "Train Epoch: 9 [11520/13906 (83%)]\tLoss: 0.116229\n",
      "Train Epoch: 9 [12160/13906 (87%)]\tLoss: 0.085431\n",
      "Train Epoch: 9 [12800/13906 (92%)]\tLoss: 0.066475\n",
      "Train Epoch: 9 [13440/13906 (96%)]\tLoss: 0.028519\n",
      "Train Epoch: 10 [0/13906 (0%)]\tLoss: 0.088985\n",
      "Train Epoch: 10 [640/13906 (5%)]\tLoss: 0.110092\n",
      "Train Epoch: 10 [1280/13906 (9%)]\tLoss: 0.019268\n",
      "Train Epoch: 10 [1920/13906 (14%)]\tLoss: 0.134078\n",
      "Train Epoch: 10 [2560/13906 (18%)]\tLoss: 0.064039\n",
      "Train Epoch: 10 [3200/13906 (23%)]\tLoss: 0.141791\n",
      "Train Epoch: 10 [3840/13906 (28%)]\tLoss: 0.029287\n",
      "Train Epoch: 10 [4480/13906 (32%)]\tLoss: 0.249337\n",
      "Train Epoch: 10 [5120/13906 (37%)]\tLoss: 0.051702\n",
      "Train Epoch: 10 [5760/13906 (41%)]\tLoss: 0.109389\n",
      "Train Epoch: 10 [6400/13906 (46%)]\tLoss: 0.110111\n",
      "Train Epoch: 10 [7040/13906 (50%)]\tLoss: 0.009672\n",
      "Train Epoch: 10 [7680/13906 (55%)]\tLoss: 0.032037\n",
      "Train Epoch: 10 [8320/13906 (60%)]\tLoss: 0.037544\n",
      "Train Epoch: 10 [8960/13906 (64%)]\tLoss: 0.080493\n",
      "Train Epoch: 10 [9600/13906 (69%)]\tLoss: 0.047917\n",
      "Train Epoch: 10 [10240/13906 (73%)]\tLoss: 0.080532\n",
      "Train Epoch: 10 [10880/13906 (78%)]\tLoss: 0.075421\n",
      "Train Epoch: 10 [11520/13906 (83%)]\tLoss: 0.086686\n",
      "Train Epoch: 10 [12160/13906 (87%)]\tLoss: 0.112956\n",
      "Train Epoch: 10 [12800/13906 (92%)]\tLoss: 0.186553\n",
      "Train Epoch: 10 [13440/13906 (96%)]\tLoss: 0.086416\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/11862 (0%)]\tLoss: 0.169793\n",
      "Train Epoch: 1 [640/11862 (5%)]\tLoss: 0.085115\n",
      "Train Epoch: 1 [1280/11862 (11%)]\tLoss: 0.076405\n",
      "Train Epoch: 1 [1920/11862 (16%)]\tLoss: 0.060519\n",
      "Train Epoch: 1 [2560/11862 (22%)]\tLoss: 0.095930\n",
      "Train Epoch: 1 [3200/11862 (27%)]\tLoss: 0.068761\n",
      "Train Epoch: 1 [3840/11862 (32%)]\tLoss: 0.062956\n",
      "Train Epoch: 1 [4480/11862 (38%)]\tLoss: 0.028790\n",
      "Train Epoch: 1 [5120/11862 (43%)]\tLoss: 0.188562\n",
      "Train Epoch: 1 [5760/11862 (48%)]\tLoss: 0.048085\n",
      "Train Epoch: 1 [6400/11862 (54%)]\tLoss: 0.092062\n",
      "Train Epoch: 1 [7040/11862 (59%)]\tLoss: 0.128833\n",
      "Train Epoch: 1 [7680/11862 (65%)]\tLoss: 0.153831\n",
      "Train Epoch: 1 [8320/11862 (70%)]\tLoss: 0.040445\n",
      "Train Epoch: 1 [8960/11862 (75%)]\tLoss: 0.023553\n",
      "Train Epoch: 1 [9600/11862 (81%)]\tLoss: 0.032981\n",
      "Train Epoch: 1 [10240/11862 (86%)]\tLoss: 0.076272\n",
      "Train Epoch: 1 [10880/11862 (91%)]\tLoss: 0.035252\n",
      "Train Epoch: 1 [11520/11862 (97%)]\tLoss: 0.023598\n",
      "Train Epoch: 2 [0/11862 (0%)]\tLoss: 0.071695\n",
      "Train Epoch: 2 [640/11862 (5%)]\tLoss: 0.010556\n",
      "Train Epoch: 2 [1280/11862 (11%)]\tLoss: 0.085722\n",
      "Train Epoch: 2 [1920/11862 (16%)]\tLoss: 0.105282\n",
      "Train Epoch: 2 [2560/11862 (22%)]\tLoss: 0.008261\n",
      "Train Epoch: 2 [3200/11862 (27%)]\tLoss: 0.073297\n",
      "Train Epoch: 2 [3840/11862 (32%)]\tLoss: 0.037845\n",
      "Train Epoch: 2 [4480/11862 (38%)]\tLoss: 0.072499\n",
      "Train Epoch: 2 [5120/11862 (43%)]\tLoss: 0.040135\n",
      "Train Epoch: 2 [5760/11862 (48%)]\tLoss: 0.039952\n",
      "Train Epoch: 2 [6400/11862 (54%)]\tLoss: 0.104899\n",
      "Train Epoch: 2 [7040/11862 (59%)]\tLoss: 0.101977\n",
      "Train Epoch: 2 [7680/11862 (65%)]\tLoss: 0.204137\n",
      "Train Epoch: 2 [8320/11862 (70%)]\tLoss: 0.023716\n",
      "Train Epoch: 2 [8960/11862 (75%)]\tLoss: 0.065619\n",
      "Train Epoch: 2 [9600/11862 (81%)]\tLoss: 0.109335\n",
      "Train Epoch: 2 [10240/11862 (86%)]\tLoss: 0.290165\n",
      "Train Epoch: 2 [10880/11862 (91%)]\tLoss: 0.020361\n",
      "Train Epoch: 2 [11520/11862 (97%)]\tLoss: 0.069084\n",
      "Train Epoch: 3 [0/11862 (0%)]\tLoss: 0.066344\n",
      "Train Epoch: 3 [640/11862 (5%)]\tLoss: 0.025651\n",
      "Train Epoch: 3 [1280/11862 (11%)]\tLoss: 0.163744\n",
      "Train Epoch: 3 [1920/11862 (16%)]\tLoss: 0.007908\n",
      "Train Epoch: 3 [2560/11862 (22%)]\tLoss: 0.024874\n",
      "Train Epoch: 3 [3200/11862 (27%)]\tLoss: 0.055058\n",
      "Train Epoch: 3 [3840/11862 (32%)]\tLoss: 0.073708\n",
      "Train Epoch: 3 [4480/11862 (38%)]\tLoss: 0.064626\n",
      "Train Epoch: 3 [5120/11862 (43%)]\tLoss: 0.025427\n",
      "Train Epoch: 3 [5760/11862 (48%)]\tLoss: 0.080127\n",
      "Train Epoch: 3 [6400/11862 (54%)]\tLoss: 0.007592\n",
      "Train Epoch: 3 [7040/11862 (59%)]\tLoss: 0.432689\n",
      "Train Epoch: 3 [7680/11862 (65%)]\tLoss: 0.070528\n",
      "Train Epoch: 3 [8320/11862 (70%)]\tLoss: 0.067617\n",
      "Train Epoch: 3 [8960/11862 (75%)]\tLoss: 0.017296\n",
      "Train Epoch: 3 [9600/11862 (81%)]\tLoss: 0.207888\n",
      "Train Epoch: 3 [10240/11862 (86%)]\tLoss: 0.141292\n",
      "Train Epoch: 3 [10880/11862 (91%)]\tLoss: 0.035106\n",
      "Train Epoch: 3 [11520/11862 (97%)]\tLoss: 0.100070\n",
      "Train Epoch: 4 [0/11862 (0%)]\tLoss: 0.035251\n",
      "Train Epoch: 4 [640/11862 (5%)]\tLoss: 0.027909\n",
      "Train Epoch: 4 [1280/11862 (11%)]\tLoss: 0.061607\n",
      "Train Epoch: 4 [1920/11862 (16%)]\tLoss: 0.062807\n",
      "Train Epoch: 4 [2560/11862 (22%)]\tLoss: 0.130110\n",
      "Train Epoch: 4 [3200/11862 (27%)]\tLoss: 0.044385\n",
      "Train Epoch: 4 [3840/11862 (32%)]\tLoss: 0.082982\n",
      "Train Epoch: 4 [4480/11862 (38%)]\tLoss: 0.078222\n",
      "Train Epoch: 4 [5120/11862 (43%)]\tLoss: 0.003511\n",
      "Train Epoch: 4 [5760/11862 (48%)]\tLoss: 0.024630\n",
      "Train Epoch: 4 [6400/11862 (54%)]\tLoss: 0.073072\n",
      "Train Epoch: 4 [7040/11862 (59%)]\tLoss: 0.058058\n",
      "Train Epoch: 4 [7680/11862 (65%)]\tLoss: 0.032461\n",
      "Train Epoch: 4 [8320/11862 (70%)]\tLoss: 0.134416\n",
      "Train Epoch: 4 [8960/11862 (75%)]\tLoss: 0.038808\n",
      "Train Epoch: 4 [9600/11862 (81%)]\tLoss: 0.061498\n",
      "Train Epoch: 4 [10240/11862 (86%)]\tLoss: 0.033656\n",
      "Train Epoch: 4 [10880/11862 (91%)]\tLoss: 0.040165\n",
      "Train Epoch: 4 [11520/11862 (97%)]\tLoss: 0.075120\n",
      "Train Epoch: 5 [0/11862 (0%)]\tLoss: 0.027004\n",
      "Train Epoch: 5 [640/11862 (5%)]\tLoss: 0.071477\n",
      "Train Epoch: 5 [1280/11862 (11%)]\tLoss: 0.067243\n",
      "Train Epoch: 5 [1920/11862 (16%)]\tLoss: 0.060416\n",
      "Train Epoch: 5 [2560/11862 (22%)]\tLoss: 0.049776\n",
      "Train Epoch: 5 [3200/11862 (27%)]\tLoss: 0.016919\n",
      "Train Epoch: 5 [3840/11862 (32%)]\tLoss: 0.031240\n",
      "Train Epoch: 5 [4480/11862 (38%)]\tLoss: 0.048380\n",
      "Train Epoch: 5 [5120/11862 (43%)]\tLoss: 0.033974\n",
      "Train Epoch: 5 [5760/11862 (48%)]\tLoss: 0.108364\n",
      "Train Epoch: 5 [6400/11862 (54%)]\tLoss: 0.126763\n",
      "Train Epoch: 5 [7040/11862 (59%)]\tLoss: 0.028558\n",
      "Train Epoch: 5 [7680/11862 (65%)]\tLoss: 0.049723\n",
      "Train Epoch: 5 [8320/11862 (70%)]\tLoss: 0.082616\n",
      "Train Epoch: 5 [8960/11862 (75%)]\tLoss: 0.051664\n",
      "Train Epoch: 5 [9600/11862 (81%)]\tLoss: 0.034697\n",
      "Train Epoch: 5 [10240/11862 (86%)]\tLoss: 0.045260\n",
      "Train Epoch: 5 [10880/11862 (91%)]\tLoss: 0.030659\n",
      "Train Epoch: 5 [11520/11862 (97%)]\tLoss: 0.111929\n",
      "Train Epoch: 6 [0/11862 (0%)]\tLoss: 0.018189\n",
      "Train Epoch: 6 [640/11862 (5%)]\tLoss: 0.106191\n",
      "Train Epoch: 6 [1280/11862 (11%)]\tLoss: 0.070604\n",
      "Train Epoch: 6 [1920/11862 (16%)]\tLoss: 0.055531\n",
      "Train Epoch: 6 [2560/11862 (22%)]\tLoss: 0.008890\n",
      "Train Epoch: 6 [3200/11862 (27%)]\tLoss: 0.058948\n",
      "Train Epoch: 6 [3840/11862 (32%)]\tLoss: 0.020586\n",
      "Train Epoch: 6 [4480/11862 (38%)]\tLoss: 0.098422\n",
      "Train Epoch: 6 [5120/11862 (43%)]\tLoss: 0.050667\n",
      "Train Epoch: 6 [5760/11862 (48%)]\tLoss: 0.028539\n",
      "Train Epoch: 6 [6400/11862 (54%)]\tLoss: 0.035666\n",
      "Train Epoch: 6 [7040/11862 (59%)]\tLoss: 0.061321\n",
      "Train Epoch: 6 [7680/11862 (65%)]\tLoss: 0.019662\n",
      "Train Epoch: 6 [8320/11862 (70%)]\tLoss: 0.046237\n",
      "Train Epoch: 6 [8960/11862 (75%)]\tLoss: 0.118026\n",
      "Train Epoch: 6 [9600/11862 (81%)]\tLoss: 0.088213\n",
      "Train Epoch: 6 [10240/11862 (86%)]\tLoss: 0.046247\n",
      "Train Epoch: 6 [10880/11862 (91%)]\tLoss: 0.087394\n",
      "Train Epoch: 6 [11520/11862 (97%)]\tLoss: 0.065487\n",
      "Train Epoch: 7 [0/11862 (0%)]\tLoss: 0.211766\n",
      "Train Epoch: 7 [640/11862 (5%)]\tLoss: 0.018858\n",
      "Train Epoch: 7 [1280/11862 (11%)]\tLoss: 0.015627\n",
      "Train Epoch: 7 [1920/11862 (16%)]\tLoss: 0.040303\n",
      "Train Epoch: 7 [2560/11862 (22%)]\tLoss: 0.049304\n",
      "Train Epoch: 7 [3200/11862 (27%)]\tLoss: 0.028169\n",
      "Train Epoch: 7 [3840/11862 (32%)]\tLoss: 0.051278\n",
      "Train Epoch: 7 [4480/11862 (38%)]\tLoss: 0.036977\n",
      "Train Epoch: 7 [5120/11862 (43%)]\tLoss: 0.025623\n",
      "Train Epoch: 7 [5760/11862 (48%)]\tLoss: 0.003725\n",
      "Train Epoch: 7 [6400/11862 (54%)]\tLoss: 0.017739\n",
      "Train Epoch: 7 [7040/11862 (59%)]\tLoss: 0.009889\n",
      "Train Epoch: 7 [7680/11862 (65%)]\tLoss: 0.100562\n",
      "Train Epoch: 7 [8320/11862 (70%)]\tLoss: 0.048602\n",
      "Train Epoch: 7 [8960/11862 (75%)]\tLoss: 0.023267\n",
      "Train Epoch: 7 [9600/11862 (81%)]\tLoss: 0.006152\n",
      "Train Epoch: 7 [10240/11862 (86%)]\tLoss: 0.078454\n",
      "Train Epoch: 7 [10880/11862 (91%)]\tLoss: 0.071024\n",
      "Train Epoch: 7 [11520/11862 (97%)]\tLoss: 0.031133\n",
      "Train Epoch: 8 [0/11862 (0%)]\tLoss: 0.114511\n",
      "Train Epoch: 8 [640/11862 (5%)]\tLoss: 0.094399\n",
      "Train Epoch: 8 [1280/11862 (11%)]\tLoss: 0.128984\n",
      "Train Epoch: 8 [1920/11862 (16%)]\tLoss: 0.065408\n",
      "Train Epoch: 8 [2560/11862 (22%)]\tLoss: 0.071458\n",
      "Train Epoch: 8 [3200/11862 (27%)]\tLoss: 0.039169\n",
      "Train Epoch: 8 [3840/11862 (32%)]\tLoss: 0.088711\n",
      "Train Epoch: 8 [4480/11862 (38%)]\tLoss: 0.060514\n",
      "Train Epoch: 8 [5120/11862 (43%)]\tLoss: 0.054554\n",
      "Train Epoch: 8 [5760/11862 (48%)]\tLoss: 0.095403\n",
      "Train Epoch: 8 [6400/11862 (54%)]\tLoss: 0.033047\n",
      "Train Epoch: 8 [7040/11862 (59%)]\tLoss: 0.013382\n",
      "Train Epoch: 8 [7680/11862 (65%)]\tLoss: 0.053215\n",
      "Train Epoch: 8 [8320/11862 (70%)]\tLoss: 0.069496\n",
      "Train Epoch: 8 [8960/11862 (75%)]\tLoss: 0.064560\n",
      "Train Epoch: 8 [9600/11862 (81%)]\tLoss: 0.003711\n",
      "Train Epoch: 8 [10240/11862 (86%)]\tLoss: 0.029927\n",
      "Train Epoch: 8 [10880/11862 (91%)]\tLoss: 0.074946\n",
      "Train Epoch: 8 [11520/11862 (97%)]\tLoss: 0.057885\n",
      "Train Epoch: 9 [0/11862 (0%)]\tLoss: 0.030267\n",
      "Train Epoch: 9 [640/11862 (5%)]\tLoss: 0.075117\n",
      "Train Epoch: 9 [1280/11862 (11%)]\tLoss: 0.008546\n",
      "Train Epoch: 9 [1920/11862 (16%)]\tLoss: 0.043172\n",
      "Train Epoch: 9 [2560/11862 (22%)]\tLoss: 0.051215\n",
      "Train Epoch: 9 [3200/11862 (27%)]\tLoss: 0.058233\n",
      "Train Epoch: 9 [3840/11862 (32%)]\tLoss: 0.028757\n",
      "Train Epoch: 9 [4480/11862 (38%)]\tLoss: 0.033692\n",
      "Train Epoch: 9 [5120/11862 (43%)]\tLoss: 0.075337\n",
      "Train Epoch: 9 [5760/11862 (48%)]\tLoss: 0.064360\n",
      "Train Epoch: 9 [6400/11862 (54%)]\tLoss: 0.043933\n",
      "Train Epoch: 9 [7040/11862 (59%)]\tLoss: 0.022367\n",
      "Train Epoch: 9 [7680/11862 (65%)]\tLoss: 0.048021\n",
      "Train Epoch: 9 [8320/11862 (70%)]\tLoss: 0.010199\n",
      "Train Epoch: 9 [8960/11862 (75%)]\tLoss: 0.024399\n",
      "Train Epoch: 9 [9600/11862 (81%)]\tLoss: 0.027321\n",
      "Train Epoch: 9 [10240/11862 (86%)]\tLoss: 0.086096\n",
      "Train Epoch: 9 [10880/11862 (91%)]\tLoss: 0.032207\n",
      "Train Epoch: 9 [11520/11862 (97%)]\tLoss: 0.015266\n",
      "Train Epoch: 10 [0/11862 (0%)]\tLoss: 0.009292\n",
      "Train Epoch: 10 [640/11862 (5%)]\tLoss: 0.040784\n",
      "Train Epoch: 10 [1280/11862 (11%)]\tLoss: 0.104408\n",
      "Train Epoch: 10 [1920/11862 (16%)]\tLoss: 0.051055\n",
      "Train Epoch: 10 [2560/11862 (22%)]\tLoss: 0.012828\n",
      "Train Epoch: 10 [3200/11862 (27%)]\tLoss: 0.017285\n",
      "Train Epoch: 10 [3840/11862 (32%)]\tLoss: 0.198808\n",
      "Train Epoch: 10 [4480/11862 (38%)]\tLoss: 0.082482\n",
      "Train Epoch: 10 [5120/11862 (43%)]\tLoss: 0.182549\n",
      "Train Epoch: 10 [5760/11862 (48%)]\tLoss: 0.035724\n",
      "Train Epoch: 10 [6400/11862 (54%)]\tLoss: 0.039301\n",
      "Train Epoch: 10 [7040/11862 (59%)]\tLoss: 0.029574\n",
      "Train Epoch: 10 [7680/11862 (65%)]\tLoss: 0.125495\n",
      "Train Epoch: 10 [8320/11862 (70%)]\tLoss: 0.014952\n",
      "Train Epoch: 10 [8960/11862 (75%)]\tLoss: 0.121297\n",
      "Train Epoch: 10 [9600/11862 (81%)]\tLoss: 0.067145\n",
      "Train Epoch: 10 [10240/11862 (86%)]\tLoss: 0.008557\n",
      "Train Epoch: 10 [10880/11862 (91%)]\tLoss: 0.088723\n",
      "Train Epoch: 10 [11520/11862 (97%)]\tLoss: 0.080147\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 0.170492\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 0.082355\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 0.051576\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 0.051180\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 0.042104\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 0.099943\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 0.097333\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 0.079727\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 0.176091\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 0.079234\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 0.177890\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 0.050309\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 0.007179\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 0.029681\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 0.152176\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 0.029952\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 0.100407\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.102613\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.079917\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.045254\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.032943\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.057778\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.022080\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.016440\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.018754\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.044406\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.063388\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.019258\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.007676\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.017600\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.090565\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.013947\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.088068\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.111631\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.134381\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.019224\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.021191\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.028341\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.181910\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.017578\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.021493\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.024415\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.075527\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.014173\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.049675\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.054186\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.184570\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.032653\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.039331\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.045052\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.028490\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.137072\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.044409\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.026632\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.030002\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.034256\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.100937\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.161516\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.031226\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.015647\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.095550\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.020334\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.105180\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.126588\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.090670\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.022156\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.057550\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.121474\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.048834\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.066418\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.036961\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.145200\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.035224\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.035282\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.089346\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.076117\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.066689\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.099617\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.062198\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.054509\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.022539\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.128874\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.067603\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.028751\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.024932\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.027682\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.055501\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.071948\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.055393\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.029335\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.016873\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.023297\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.029980\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.016186\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.098774\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.008899\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.107779\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.016276\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.105912\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.020083\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.187863\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.004952\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.275810\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.023457\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.082675\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.061240\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.078477\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.067981\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.120517\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.014016\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.028933\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.054012\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.069919\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.016293\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.158552\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.021166\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.010834\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.053659\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.056736\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.022215\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.031861\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.026654\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.114948\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.008949\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.035438\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.016540\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.038786\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.048701\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.040534\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.036884\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.102581\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.046013\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.015385\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.094134\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.060793\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.161662\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.053656\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.018638\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.042469\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.009950\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.032440\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.045468\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.025534\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.014197\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.104971\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.040489\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.023845\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.028858\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.066236\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.019467\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.020059\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.025405\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.017454\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.015954\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.102516\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.128614\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.077809\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.076905\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.019412\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.027392\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5509 (0%)]\tLoss: 0.181728\n",
      "Train Epoch: 1 [640/5509 (11%)]\tLoss: 0.296957\n",
      "Train Epoch: 1 [1280/5509 (23%)]\tLoss: 0.123865\n",
      "Train Epoch: 1 [1920/5509 (34%)]\tLoss: 0.038690\n",
      "Train Epoch: 1 [2560/5509 (46%)]\tLoss: 0.066098\n",
      "Train Epoch: 1 [3200/5509 (57%)]\tLoss: 0.164076\n",
      "Train Epoch: 1 [3840/5509 (69%)]\tLoss: 0.172348\n",
      "Train Epoch: 1 [4480/5509 (80%)]\tLoss: 0.079703\n",
      "Train Epoch: 1 [5120/5509 (92%)]\tLoss: 0.013432\n",
      "Train Epoch: 2 [0/5509 (0%)]\tLoss: 0.103172\n",
      "Train Epoch: 2 [640/5509 (11%)]\tLoss: 0.134344\n",
      "Train Epoch: 2 [1280/5509 (23%)]\tLoss: 0.032645\n",
      "Train Epoch: 2 [1920/5509 (34%)]\tLoss: 0.044157\n",
      "Train Epoch: 2 [2560/5509 (46%)]\tLoss: 0.089474\n",
      "Train Epoch: 2 [3200/5509 (57%)]\tLoss: 0.067301\n",
      "Train Epoch: 2 [3840/5509 (69%)]\tLoss: 0.036529\n",
      "Train Epoch: 2 [4480/5509 (80%)]\tLoss: 0.016489\n",
      "Train Epoch: 2 [5120/5509 (92%)]\tLoss: 0.126699\n",
      "Train Epoch: 3 [0/5509 (0%)]\tLoss: 0.038698\n",
      "Train Epoch: 3 [640/5509 (11%)]\tLoss: 0.053184\n",
      "Train Epoch: 3 [1280/5509 (23%)]\tLoss: 0.299981\n",
      "Train Epoch: 3 [1920/5509 (34%)]\tLoss: 0.087182\n",
      "Train Epoch: 3 [2560/5509 (46%)]\tLoss: 0.027151\n",
      "Train Epoch: 3 [3200/5509 (57%)]\tLoss: 0.036156\n",
      "Train Epoch: 3 [3840/5509 (69%)]\tLoss: 0.126737\n",
      "Train Epoch: 3 [4480/5509 (80%)]\tLoss: 0.061066\n",
      "Train Epoch: 3 [5120/5509 (92%)]\tLoss: 0.206951\n",
      "Train Epoch: 4 [0/5509 (0%)]\tLoss: 0.095775\n",
      "Train Epoch: 4 [640/5509 (11%)]\tLoss: 0.055619\n",
      "Train Epoch: 4 [1280/5509 (23%)]\tLoss: 0.055132\n",
      "Train Epoch: 4 [1920/5509 (34%)]\tLoss: 0.156094\n",
      "Train Epoch: 4 [2560/5509 (46%)]\tLoss: 0.018687\n",
      "Train Epoch: 4 [3200/5509 (57%)]\tLoss: 0.032415\n",
      "Train Epoch: 4 [3840/5509 (69%)]\tLoss: 0.041781\n",
      "Train Epoch: 4 [4480/5509 (80%)]\tLoss: 0.072238\n",
      "Train Epoch: 4 [5120/5509 (92%)]\tLoss: 0.063367\n",
      "Train Epoch: 5 [0/5509 (0%)]\tLoss: 0.146173\n",
      "Train Epoch: 5 [640/5509 (11%)]\tLoss: 0.031844\n",
      "Train Epoch: 5 [1280/5509 (23%)]\tLoss: 0.022430\n",
      "Train Epoch: 5 [1920/5509 (34%)]\tLoss: 0.078825\n",
      "Train Epoch: 5 [2560/5509 (46%)]\tLoss: 0.177712\n",
      "Train Epoch: 5 [3200/5509 (57%)]\tLoss: 0.049275\n",
      "Train Epoch: 5 [3840/5509 (69%)]\tLoss: 0.154491\n",
      "Train Epoch: 5 [4480/5509 (80%)]\tLoss: 0.013865\n",
      "Train Epoch: 5 [5120/5509 (92%)]\tLoss: 0.095400\n",
      "Train Epoch: 6 [0/5509 (0%)]\tLoss: 0.032659\n",
      "Train Epoch: 6 [640/5509 (11%)]\tLoss: 0.045738\n",
      "Train Epoch: 6 [1280/5509 (23%)]\tLoss: 0.025473\n",
      "Train Epoch: 6 [1920/5509 (34%)]\tLoss: 0.103700\n",
      "Train Epoch: 6 [2560/5509 (46%)]\tLoss: 0.059001\n",
      "Train Epoch: 6 [3200/5509 (57%)]\tLoss: 0.229181\n",
      "Train Epoch: 6 [3840/5509 (69%)]\tLoss: 0.044463\n",
      "Train Epoch: 6 [4480/5509 (80%)]\tLoss: 0.071845\n",
      "Train Epoch: 6 [5120/5509 (92%)]\tLoss: 0.085339\n",
      "Train Epoch: 7 [0/5509 (0%)]\tLoss: 0.064793\n",
      "Train Epoch: 7 [640/5509 (11%)]\tLoss: 0.028005\n",
      "Train Epoch: 7 [1280/5509 (23%)]\tLoss: 0.031008\n",
      "Train Epoch: 7 [1920/5509 (34%)]\tLoss: 0.048647\n",
      "Train Epoch: 7 [2560/5509 (46%)]\tLoss: 0.086914\n",
      "Train Epoch: 7 [3200/5509 (57%)]\tLoss: 0.036188\n",
      "Train Epoch: 7 [3840/5509 (69%)]\tLoss: 0.076647\n",
      "Train Epoch: 7 [4480/5509 (80%)]\tLoss: 0.030193\n",
      "Train Epoch: 7 [5120/5509 (92%)]\tLoss: 0.106648\n",
      "Train Epoch: 8 [0/5509 (0%)]\tLoss: 0.033525\n",
      "Train Epoch: 8 [640/5509 (11%)]\tLoss: 0.078359\n",
      "Train Epoch: 8 [1280/5509 (23%)]\tLoss: 0.060318\n",
      "Train Epoch: 8 [1920/5509 (34%)]\tLoss: 0.011067\n",
      "Train Epoch: 8 [2560/5509 (46%)]\tLoss: 0.065089\n",
      "Train Epoch: 8 [3200/5509 (57%)]\tLoss: 0.102095\n",
      "Train Epoch: 8 [3840/5509 (69%)]\tLoss: 0.022956\n",
      "Train Epoch: 8 [4480/5509 (80%)]\tLoss: 0.108394\n",
      "Train Epoch: 8 [5120/5509 (92%)]\tLoss: 0.086922\n",
      "Train Epoch: 9 [0/5509 (0%)]\tLoss: 0.024716\n",
      "Train Epoch: 9 [640/5509 (11%)]\tLoss: 0.064643\n",
      "Train Epoch: 9 [1280/5509 (23%)]\tLoss: 0.023629\n",
      "Train Epoch: 9 [1920/5509 (34%)]\tLoss: 0.174841\n",
      "Train Epoch: 9 [2560/5509 (46%)]\tLoss: 0.095831\n",
      "Train Epoch: 9 [3200/5509 (57%)]\tLoss: 0.070172\n",
      "Train Epoch: 9 [3840/5509 (69%)]\tLoss: 0.122178\n",
      "Train Epoch: 9 [4480/5509 (80%)]\tLoss: 0.049419\n",
      "Train Epoch: 9 [5120/5509 (92%)]\tLoss: 0.065170\n",
      "Train Epoch: 10 [0/5509 (0%)]\tLoss: 0.092678\n",
      "Train Epoch: 10 [640/5509 (11%)]\tLoss: 0.094634\n",
      "Train Epoch: 10 [1280/5509 (23%)]\tLoss: 0.125249\n",
      "Train Epoch: 10 [1920/5509 (34%)]\tLoss: 0.027573\n",
      "Train Epoch: 10 [2560/5509 (46%)]\tLoss: 0.078275\n",
      "Train Epoch: 10 [3200/5509 (57%)]\tLoss: 0.125058\n",
      "Train Epoch: 10 [3840/5509 (69%)]\tLoss: 0.025580\n",
      "Train Epoch: 10 [4480/5509 (80%)]\tLoss: 0.078045\n",
      "Train Epoch: 10 [5120/5509 (92%)]\tLoss: 0.090662\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 0.200618\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 0.092644\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 0.135719\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 0.038229\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 0.089274\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 0.085433\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 0.036133\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 0.040858\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 0.092720\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 0.194773\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.026222\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.044209\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 0.010028\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 0.057443\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 0.147384\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.036569\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.016234\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.009971\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.012378\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.034712\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.038944\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.031926\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.055715\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.020011\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.031471\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.024453\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.176033\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.025789\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.063795\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.047986\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.043753\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.068122\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.073379\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.100328\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.008207\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.097841\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.072158\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.070718\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.031277\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.034659\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.068944\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.181830\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.036074\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.006698\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.045986\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.086315\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.019919\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.165039\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.023973\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.008610\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.055344\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.034479\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.022444\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.010055\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.064011\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.027985\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.008074\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.068048\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.114110\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.119279\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.025262\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.013977\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.023471\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.010567\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.049156\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.058700\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.018706\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.011295\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.059935\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.049185\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.015523\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.004459\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.004069\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.041928\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.044952\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.088289\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.048393\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.047187\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.062607\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.008061\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.038207\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.009765\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.051909\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.007328\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.059915\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.003688\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.002261\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.014562\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.108410\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.051257\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.042632\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.024622\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.016941\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.147261\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.010726\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.014505\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.016290\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.016368\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.054607\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.087248\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.049189\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.022933\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.015425\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.086802\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.041609\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.013717\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.110383\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.007104\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.104063\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.039685\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.023617\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.034957\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.017431\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.036885\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.003207\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.009475\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.011046\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.008293\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.068716\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.021858\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0497, Accuracy: 9836/10000 (98%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 0.054686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 0.132831\n",
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 0.158615\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 0.092034\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 0.061135\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 0.145744\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 0.044193\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 0.048062\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 0.047128\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 0.036056\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 0.114334\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 0.122531\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 0.076034\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 0.154468\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 0.106877\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 0.110798\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 0.096385\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 0.135421\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 0.080741\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 0.184560\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.022290\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 0.171898\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 0.050420\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.065518\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.053993\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 0.067802\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.025017\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 0.065686\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.042483\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.070407\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.350544\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.120005\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.091931\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.022777\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.022045\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.020860\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.113698\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.087141\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.068395\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.098274\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.098906\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.052839\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.008966\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.053468\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.030882\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.071434\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.053216\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.153549\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.102928\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.138358\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.023998\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.136062\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.051938\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.036749\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.023103\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.277758\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.070376\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.084011\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.165135\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.177194\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.068036\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.116382\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.057893\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.123434\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.161803\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.044092\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.073405\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.117021\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.172358\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.057541\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.117365\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.158843\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.027546\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.031790\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.021697\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.048214\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.049931\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.038033\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.039115\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.052311\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.012282\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.148159\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.062895\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.115422\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.086165\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.013672\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.138882\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.072810\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.137147\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.052809\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.135507\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.065941\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.103370\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.034999\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.093457\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.063955\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.142229\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.126719\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.022472\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.138428\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.057544\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.087917\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.107643\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.125026\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.064641\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.037293\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.007808\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.075865\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 4.093524\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.043276\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.063448\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.285911\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.036692\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.025730\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.152576\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.180202\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.123229\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.115786\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.241075\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.069553\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.078664\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.042521\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.099551\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.091395\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.077887\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.066245\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.124389\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.092912\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.165234\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.072151\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.089892\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.084497\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.054247\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.044186\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.220153\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.455516\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.194418\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.100430\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.205791\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.072757\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.051049\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.083859\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.063790\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.091405\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.115842\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.107235\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.053621\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.022665\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.097109\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.313539\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.083400\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.134513\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.026133\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.073420\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.060657\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.073230\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.068725\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.109630\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.061951\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.051679\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.087021\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.091816\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.098660\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.032887\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.017121\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.025823\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.126263\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.114258\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.115666\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.096307\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.182165\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.150565\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.037692\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.091859\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.241373\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.105752\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.054438\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.062928\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.064856\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.145886\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/13906 (0%)]\tLoss: 0.220193\n",
      "Train Epoch: 1 [640/13906 (5%)]\tLoss: 0.052527\n",
      "Train Epoch: 1 [1280/13906 (9%)]\tLoss: 0.082204\n",
      "Train Epoch: 1 [1920/13906 (14%)]\tLoss: 0.175992\n",
      "Train Epoch: 1 [2560/13906 (18%)]\tLoss: 0.072240\n",
      "Train Epoch: 1 [3200/13906 (23%)]\tLoss: 0.189799\n",
      "Train Epoch: 1 [3840/13906 (28%)]\tLoss: 0.110580\n",
      "Train Epoch: 1 [4480/13906 (32%)]\tLoss: 0.185307\n",
      "Train Epoch: 1 [5120/13906 (37%)]\tLoss: 0.176836\n",
      "Train Epoch: 1 [5760/13906 (41%)]\tLoss: 0.150188\n",
      "Train Epoch: 1 [6400/13906 (46%)]\tLoss: 0.016251\n",
      "Train Epoch: 1 [7040/13906 (50%)]\tLoss: 0.196719\n",
      "Train Epoch: 1 [7680/13906 (55%)]\tLoss: 0.040988\n",
      "Train Epoch: 1 [8320/13906 (60%)]\tLoss: 0.040025\n",
      "Train Epoch: 1 [8960/13906 (64%)]\tLoss: 0.107788\n",
      "Train Epoch: 1 [9600/13906 (69%)]\tLoss: 0.054054\n",
      "Train Epoch: 1 [10240/13906 (73%)]\tLoss: 0.014319\n",
      "Train Epoch: 1 [10880/13906 (78%)]\tLoss: 0.171325\n",
      "Train Epoch: 1 [11520/13906 (83%)]\tLoss: 0.103241\n",
      "Train Epoch: 1 [12160/13906 (87%)]\tLoss: 0.092806\n",
      "Train Epoch: 1 [12800/13906 (92%)]\tLoss: 0.042648\n",
      "Train Epoch: 1 [13440/13906 (96%)]\tLoss: 0.068662\n",
      "Train Epoch: 2 [0/13906 (0%)]\tLoss: 0.075429\n",
      "Train Epoch: 2 [640/13906 (5%)]\tLoss: 0.063662\n",
      "Train Epoch: 2 [1280/13906 (9%)]\tLoss: 0.074453\n",
      "Train Epoch: 2 [1920/13906 (14%)]\tLoss: 0.063946\n",
      "Train Epoch: 2 [2560/13906 (18%)]\tLoss: 0.022107\n",
      "Train Epoch: 2 [3200/13906 (23%)]\tLoss: 0.055967\n",
      "Train Epoch: 2 [3840/13906 (28%)]\tLoss: 0.213863\n",
      "Train Epoch: 2 [4480/13906 (32%)]\tLoss: 0.139569\n",
      "Train Epoch: 2 [5120/13906 (37%)]\tLoss: 0.070496\n",
      "Train Epoch: 2 [5760/13906 (41%)]\tLoss: 0.033937\n",
      "Train Epoch: 2 [6400/13906 (46%)]\tLoss: 0.097213\n",
      "Train Epoch: 2 [7040/13906 (50%)]\tLoss: 0.035761\n",
      "Train Epoch: 2 [7680/13906 (55%)]\tLoss: 0.133312\n",
      "Train Epoch: 2 [8320/13906 (60%)]\tLoss: 0.099396\n",
      "Train Epoch: 2 [8960/13906 (64%)]\tLoss: 0.069181\n",
      "Train Epoch: 2 [9600/13906 (69%)]\tLoss: 0.079256\n",
      "Train Epoch: 2 [10240/13906 (73%)]\tLoss: 0.040319\n",
      "Train Epoch: 2 [10880/13906 (78%)]\tLoss: 0.035904\n",
      "Train Epoch: 2 [11520/13906 (83%)]\tLoss: 0.034123\n",
      "Train Epoch: 2 [12160/13906 (87%)]\tLoss: 0.017156\n",
      "Train Epoch: 2 [12800/13906 (92%)]\tLoss: 0.049200\n",
      "Train Epoch: 2 [13440/13906 (96%)]\tLoss: 0.095260\n",
      "Train Epoch: 3 [0/13906 (0%)]\tLoss: 0.007279\n",
      "Train Epoch: 3 [640/13906 (5%)]\tLoss: 0.067763\n",
      "Train Epoch: 3 [1280/13906 (9%)]\tLoss: 0.020731\n",
      "Train Epoch: 3 [1920/13906 (14%)]\tLoss: 0.030213\n",
      "Train Epoch: 3 [2560/13906 (18%)]\tLoss: 0.230505\n",
      "Train Epoch: 3 [3200/13906 (23%)]\tLoss: 0.174038\n",
      "Train Epoch: 3 [3840/13906 (28%)]\tLoss: 0.109720\n",
      "Train Epoch: 3 [4480/13906 (32%)]\tLoss: 0.241005\n",
      "Train Epoch: 3 [5120/13906 (37%)]\tLoss: 0.068095\n",
      "Train Epoch: 3 [5760/13906 (41%)]\tLoss: 0.016425\n",
      "Train Epoch: 3 [6400/13906 (46%)]\tLoss: 0.048748\n",
      "Train Epoch: 3 [7040/13906 (50%)]\tLoss: 0.025255\n",
      "Train Epoch: 3 [7680/13906 (55%)]\tLoss: 0.026880\n",
      "Train Epoch: 3 [8320/13906 (60%)]\tLoss: 0.208484\n",
      "Train Epoch: 3 [8960/13906 (64%)]\tLoss: 0.042060\n",
      "Train Epoch: 3 [9600/13906 (69%)]\tLoss: 0.111767\n",
      "Train Epoch: 3 [10240/13906 (73%)]\tLoss: 0.114082\n",
      "Train Epoch: 3 [10880/13906 (78%)]\tLoss: 0.065721\n",
      "Train Epoch: 3 [11520/13906 (83%)]\tLoss: 0.093247\n",
      "Train Epoch: 3 [12160/13906 (87%)]\tLoss: 0.096854\n",
      "Train Epoch: 3 [12800/13906 (92%)]\tLoss: 0.063688\n",
      "Train Epoch: 3 [13440/13906 (96%)]\tLoss: 0.060595\n",
      "Train Epoch: 4 [0/13906 (0%)]\tLoss: 0.037295\n",
      "Train Epoch: 4 [640/13906 (5%)]\tLoss: 0.399879\n",
      "Train Epoch: 4 [1280/13906 (9%)]\tLoss: 0.213127\n",
      "Train Epoch: 4 [1920/13906 (14%)]\tLoss: 0.026869\n",
      "Train Epoch: 4 [2560/13906 (18%)]\tLoss: 0.008737\n",
      "Train Epoch: 4 [3200/13906 (23%)]\tLoss: 0.055304\n",
      "Train Epoch: 4 [3840/13906 (28%)]\tLoss: 0.070196\n",
      "Train Epoch: 4 [4480/13906 (32%)]\tLoss: 0.168502\n",
      "Train Epoch: 4 [5120/13906 (37%)]\tLoss: 0.119172\n",
      "Train Epoch: 4 [5760/13906 (41%)]\tLoss: 0.078149\n",
      "Train Epoch: 4 [6400/13906 (46%)]\tLoss: 0.066831\n",
      "Train Epoch: 4 [7040/13906 (50%)]\tLoss: 0.046374\n",
      "Train Epoch: 4 [7680/13906 (55%)]\tLoss: 0.015584\n",
      "Train Epoch: 4 [8320/13906 (60%)]\tLoss: 0.123895\n",
      "Train Epoch: 4 [8960/13906 (64%)]\tLoss: 0.041018\n",
      "Train Epoch: 4 [9600/13906 (69%)]\tLoss: 0.079008\n",
      "Train Epoch: 4 [10240/13906 (73%)]\tLoss: 0.107587\n",
      "Train Epoch: 4 [10880/13906 (78%)]\tLoss: 0.118028\n",
      "Train Epoch: 4 [11520/13906 (83%)]\tLoss: 0.088612\n",
      "Train Epoch: 4 [12160/13906 (87%)]\tLoss: 0.038175\n",
      "Train Epoch: 4 [12800/13906 (92%)]\tLoss: 0.076932\n",
      "Train Epoch: 4 [13440/13906 (96%)]\tLoss: 0.274525\n",
      "Train Epoch: 5 [0/13906 (0%)]\tLoss: 0.064420\n",
      "Train Epoch: 5 [640/13906 (5%)]\tLoss: 0.345654\n",
      "Train Epoch: 5 [1280/13906 (9%)]\tLoss: 0.161218\n",
      "Train Epoch: 5 [1920/13906 (14%)]\tLoss: 0.087179\n",
      "Train Epoch: 5 [2560/13906 (18%)]\tLoss: 0.070391\n",
      "Train Epoch: 5 [3200/13906 (23%)]\tLoss: 0.053020\n",
      "Train Epoch: 5 [3840/13906 (28%)]\tLoss: 0.041687\n",
      "Train Epoch: 5 [4480/13906 (32%)]\tLoss: 0.001916\n",
      "Train Epoch: 5 [5120/13906 (37%)]\tLoss: 0.074252\n",
      "Train Epoch: 5 [5760/13906 (41%)]\tLoss: 0.152796\n",
      "Train Epoch: 5 [6400/13906 (46%)]\tLoss: 0.005075\n",
      "Train Epoch: 5 [7040/13906 (50%)]\tLoss: 0.048021\n",
      "Train Epoch: 5 [7680/13906 (55%)]\tLoss: 0.103484\n",
      "Train Epoch: 5 [8320/13906 (60%)]\tLoss: 0.024155\n",
      "Train Epoch: 5 [8960/13906 (64%)]\tLoss: 0.165454\n",
      "Train Epoch: 5 [9600/13906 (69%)]\tLoss: 0.208402\n",
      "Train Epoch: 5 [10240/13906 (73%)]\tLoss: 0.094153\n",
      "Train Epoch: 5 [10880/13906 (78%)]\tLoss: 0.119487\n",
      "Train Epoch: 5 [11520/13906 (83%)]\tLoss: 0.031782\n",
      "Train Epoch: 5 [12160/13906 (87%)]\tLoss: 0.038514\n",
      "Train Epoch: 5 [12800/13906 (92%)]\tLoss: 0.007037\n",
      "Train Epoch: 5 [13440/13906 (96%)]\tLoss: 0.065739\n",
      "Train Epoch: 6 [0/13906 (0%)]\tLoss: 0.081106\n",
      "Train Epoch: 6 [640/13906 (5%)]\tLoss: 0.068603\n",
      "Train Epoch: 6 [1280/13906 (9%)]\tLoss: 0.057900\n",
      "Train Epoch: 6 [1920/13906 (14%)]\tLoss: 0.039684\n",
      "Train Epoch: 6 [2560/13906 (18%)]\tLoss: 0.040007\n",
      "Train Epoch: 6 [3200/13906 (23%)]\tLoss: 0.059233\n",
      "Train Epoch: 6 [3840/13906 (28%)]\tLoss: 0.053050\n",
      "Train Epoch: 6 [4480/13906 (32%)]\tLoss: 0.022895\n",
      "Train Epoch: 6 [5120/13906 (37%)]\tLoss: 0.055061\n",
      "Train Epoch: 6 [5760/13906 (41%)]\tLoss: 0.194821\n",
      "Train Epoch: 6 [6400/13906 (46%)]\tLoss: 0.105480\n",
      "Train Epoch: 6 [7040/13906 (50%)]\tLoss: 0.080400\n",
      "Train Epoch: 6 [7680/13906 (55%)]\tLoss: 0.078848\n",
      "Train Epoch: 6 [8320/13906 (60%)]\tLoss: 0.049581\n",
      "Train Epoch: 6 [8960/13906 (64%)]\tLoss: 0.007433\n",
      "Train Epoch: 6 [9600/13906 (69%)]\tLoss: 0.112417\n",
      "Train Epoch: 6 [10240/13906 (73%)]\tLoss: 0.053826\n",
      "Train Epoch: 6 [10880/13906 (78%)]\tLoss: 0.078483\n",
      "Train Epoch: 6 [11520/13906 (83%)]\tLoss: 0.021273\n",
      "Train Epoch: 6 [12160/13906 (87%)]\tLoss: 0.062078\n",
      "Train Epoch: 6 [12800/13906 (92%)]\tLoss: 0.066937\n",
      "Train Epoch: 6 [13440/13906 (96%)]\tLoss: 0.072503\n",
      "Train Epoch: 7 [0/13906 (0%)]\tLoss: 0.095369\n",
      "Train Epoch: 7 [640/13906 (5%)]\tLoss: 0.052808\n",
      "Train Epoch: 7 [1280/13906 (9%)]\tLoss: 0.120884\n",
      "Train Epoch: 7 [1920/13906 (14%)]\tLoss: 0.075704\n",
      "Train Epoch: 7 [2560/13906 (18%)]\tLoss: 0.195764\n",
      "Train Epoch: 7 [3200/13906 (23%)]\tLoss: 0.044147\n",
      "Train Epoch: 7 [3840/13906 (28%)]\tLoss: 0.099353\n",
      "Train Epoch: 7 [4480/13906 (32%)]\tLoss: 0.050665\n",
      "Train Epoch: 7 [5120/13906 (37%)]\tLoss: 0.176160\n",
      "Train Epoch: 7 [5760/13906 (41%)]\tLoss: 0.031184\n",
      "Train Epoch: 7 [6400/13906 (46%)]\tLoss: 0.059478\n",
      "Train Epoch: 7 [7040/13906 (50%)]\tLoss: 0.030390\n",
      "Train Epoch: 7 [7680/13906 (55%)]\tLoss: 0.027426\n",
      "Train Epoch: 7 [8320/13906 (60%)]\tLoss: 0.041063\n",
      "Train Epoch: 7 [8960/13906 (64%)]\tLoss: 0.088472\n",
      "Train Epoch: 7 [9600/13906 (69%)]\tLoss: 0.014957\n",
      "Train Epoch: 7 [10240/13906 (73%)]\tLoss: 0.135296\n",
      "Train Epoch: 7 [10880/13906 (78%)]\tLoss: 0.099779\n",
      "Train Epoch: 7 [11520/13906 (83%)]\tLoss: 0.156459\n",
      "Train Epoch: 7 [12160/13906 (87%)]\tLoss: 0.009769\n",
      "Train Epoch: 7 [12800/13906 (92%)]\tLoss: 0.045102\n",
      "Train Epoch: 7 [13440/13906 (96%)]\tLoss: 0.043846\n",
      "Train Epoch: 8 [0/13906 (0%)]\tLoss: 0.029302\n",
      "Train Epoch: 8 [640/13906 (5%)]\tLoss: 0.027473\n",
      "Train Epoch: 8 [1280/13906 (9%)]\tLoss: 0.015485\n",
      "Train Epoch: 8 [1920/13906 (14%)]\tLoss: 0.053820\n",
      "Train Epoch: 8 [2560/13906 (18%)]\tLoss: 0.163382\n",
      "Train Epoch: 8 [3200/13906 (23%)]\tLoss: 0.083405\n",
      "Train Epoch: 8 [3840/13906 (28%)]\tLoss: 0.015080\n",
      "Train Epoch: 8 [4480/13906 (32%)]\tLoss: 0.057454\n",
      "Train Epoch: 8 [5120/13906 (37%)]\tLoss: 0.021354\n",
      "Train Epoch: 8 [5760/13906 (41%)]\tLoss: 0.018714\n",
      "Train Epoch: 8 [6400/13906 (46%)]\tLoss: 0.096008\n",
      "Train Epoch: 8 [7040/13906 (50%)]\tLoss: 0.094924\n",
      "Train Epoch: 8 [7680/13906 (55%)]\tLoss: 0.026756\n",
      "Train Epoch: 8 [8320/13906 (60%)]\tLoss: 0.164794\n",
      "Train Epoch: 8 [8960/13906 (64%)]\tLoss: 0.013946\n",
      "Train Epoch: 8 [9600/13906 (69%)]\tLoss: 0.023035\n",
      "Train Epoch: 8 [10240/13906 (73%)]\tLoss: 0.044089\n",
      "Train Epoch: 8 [10880/13906 (78%)]\tLoss: 0.191063\n",
      "Train Epoch: 8 [11520/13906 (83%)]\tLoss: 0.150694\n",
      "Train Epoch: 8 [12160/13906 (87%)]\tLoss: 0.072129\n",
      "Train Epoch: 8 [12800/13906 (92%)]\tLoss: 0.124427\n",
      "Train Epoch: 8 [13440/13906 (96%)]\tLoss: 0.054664\n",
      "Train Epoch: 9 [0/13906 (0%)]\tLoss: 0.026160\n",
      "Train Epoch: 9 [640/13906 (5%)]\tLoss: 0.231923\n",
      "Train Epoch: 9 [1280/13906 (9%)]\tLoss: 0.023648\n",
      "Train Epoch: 9 [1920/13906 (14%)]\tLoss: 0.051734\n",
      "Train Epoch: 9 [2560/13906 (18%)]\tLoss: 0.188658\n",
      "Train Epoch: 9 [3200/13906 (23%)]\tLoss: 0.026285\n",
      "Train Epoch: 9 [3840/13906 (28%)]\tLoss: 0.033405\n",
      "Train Epoch: 9 [4480/13906 (32%)]\tLoss: 0.074221\n",
      "Train Epoch: 9 [5120/13906 (37%)]\tLoss: 0.028194\n",
      "Train Epoch: 9 [5760/13906 (41%)]\tLoss: 0.028595\n",
      "Train Epoch: 9 [6400/13906 (46%)]\tLoss: 0.035641\n",
      "Train Epoch: 9 [7040/13906 (50%)]\tLoss: 0.066368\n",
      "Train Epoch: 9 [7680/13906 (55%)]\tLoss: 0.068827\n",
      "Train Epoch: 9 [8320/13906 (60%)]\tLoss: 0.049534\n",
      "Train Epoch: 9 [8960/13906 (64%)]\tLoss: 0.034535\n",
      "Train Epoch: 9 [9600/13906 (69%)]\tLoss: 0.091569\n",
      "Train Epoch: 9 [10240/13906 (73%)]\tLoss: 0.148956\n",
      "Train Epoch: 9 [10880/13906 (78%)]\tLoss: 0.143878\n",
      "Train Epoch: 9 [11520/13906 (83%)]\tLoss: 0.017621\n",
      "Train Epoch: 9 [12160/13906 (87%)]\tLoss: 0.014464\n",
      "Train Epoch: 9 [12800/13906 (92%)]\tLoss: 0.011554\n",
      "Train Epoch: 9 [13440/13906 (96%)]\tLoss: 0.119163\n",
      "Train Epoch: 10 [0/13906 (0%)]\tLoss: 0.052152\n",
      "Train Epoch: 10 [640/13906 (5%)]\tLoss: 0.115636\n",
      "Train Epoch: 10 [1280/13906 (9%)]\tLoss: 0.050142\n",
      "Train Epoch: 10 [1920/13906 (14%)]\tLoss: 0.070339\n",
      "Train Epoch: 10 [2560/13906 (18%)]\tLoss: 0.077253\n",
      "Train Epoch: 10 [3200/13906 (23%)]\tLoss: 0.344180\n",
      "Train Epoch: 10 [3840/13906 (28%)]\tLoss: 0.071646\n",
      "Train Epoch: 10 [4480/13906 (32%)]\tLoss: 0.075570\n",
      "Train Epoch: 10 [5120/13906 (37%)]\tLoss: 0.011059\n",
      "Train Epoch: 10 [5760/13906 (41%)]\tLoss: 0.089684\n",
      "Train Epoch: 10 [6400/13906 (46%)]\tLoss: 0.052661\n",
      "Train Epoch: 10 [7040/13906 (50%)]\tLoss: 0.029319\n",
      "Train Epoch: 10 [7680/13906 (55%)]\tLoss: 0.084062\n",
      "Train Epoch: 10 [8320/13906 (60%)]\tLoss: 0.031950\n",
      "Train Epoch: 10 [8960/13906 (64%)]\tLoss: 0.062080\n",
      "Train Epoch: 10 [9600/13906 (69%)]\tLoss: 0.043968\n",
      "Train Epoch: 10 [10240/13906 (73%)]\tLoss: 0.035813\n",
      "Train Epoch: 10 [10880/13906 (78%)]\tLoss: 0.015833\n",
      "Train Epoch: 10 [11520/13906 (83%)]\tLoss: 0.110049\n",
      "Train Epoch: 10 [12160/13906 (87%)]\tLoss: 0.039664\n",
      "Train Epoch: 10 [12800/13906 (92%)]\tLoss: 0.111790\n",
      "Train Epoch: 10 [13440/13906 (96%)]\tLoss: 0.108933\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/11862 (0%)]\tLoss: 0.106309\n",
      "Train Epoch: 1 [640/11862 (5%)]\tLoss: 0.118796\n",
      "Train Epoch: 1 [1280/11862 (11%)]\tLoss: 0.015120\n",
      "Train Epoch: 1 [1920/11862 (16%)]\tLoss: 0.103604\n",
      "Train Epoch: 1 [2560/11862 (22%)]\tLoss: 0.074860\n",
      "Train Epoch: 1 [3200/11862 (27%)]\tLoss: 0.116932\n",
      "Train Epoch: 1 [3840/11862 (32%)]\tLoss: 0.043846\n",
      "Train Epoch: 1 [4480/11862 (38%)]\tLoss: 0.063385\n",
      "Train Epoch: 1 [5120/11862 (43%)]\tLoss: 0.030802\n",
      "Train Epoch: 1 [5760/11862 (48%)]\tLoss: 0.057687\n",
      "Train Epoch: 1 [6400/11862 (54%)]\tLoss: 0.038869\n",
      "Train Epoch: 1 [7040/11862 (59%)]\tLoss: 0.068003\n",
      "Train Epoch: 1 [7680/11862 (65%)]\tLoss: 0.013860\n",
      "Train Epoch: 1 [8320/11862 (70%)]\tLoss: 0.031420\n",
      "Train Epoch: 1 [8960/11862 (75%)]\tLoss: 0.095413\n",
      "Train Epoch: 1 [9600/11862 (81%)]\tLoss: 0.067493\n",
      "Train Epoch: 1 [10240/11862 (86%)]\tLoss: 0.143752\n",
      "Train Epoch: 1 [10880/11862 (91%)]\tLoss: 0.078992\n",
      "Train Epoch: 1 [11520/11862 (97%)]\tLoss: 0.172449\n",
      "Train Epoch: 2 [0/11862 (0%)]\tLoss: 0.012075\n",
      "Train Epoch: 2 [640/11862 (5%)]\tLoss: 0.226629\n",
      "Train Epoch: 2 [1280/11862 (11%)]\tLoss: 0.075320\n",
      "Train Epoch: 2 [1920/11862 (16%)]\tLoss: 0.010258\n",
      "Train Epoch: 2 [2560/11862 (22%)]\tLoss: 0.055431\n",
      "Train Epoch: 2 [3200/11862 (27%)]\tLoss: 0.058460\n",
      "Train Epoch: 2 [3840/11862 (32%)]\tLoss: 0.064574\n",
      "Train Epoch: 2 [4480/11862 (38%)]\tLoss: 0.097661\n",
      "Train Epoch: 2 [5120/11862 (43%)]\tLoss: 0.167071\n",
      "Train Epoch: 2 [5760/11862 (48%)]\tLoss: 0.017863\n",
      "Train Epoch: 2 [6400/11862 (54%)]\tLoss: 0.068690\n",
      "Train Epoch: 2 [7040/11862 (59%)]\tLoss: 0.051749\n",
      "Train Epoch: 2 [7680/11862 (65%)]\tLoss: 0.034202\n",
      "Train Epoch: 2 [8320/11862 (70%)]\tLoss: 0.016777\n",
      "Train Epoch: 2 [8960/11862 (75%)]\tLoss: 0.038654\n",
      "Train Epoch: 2 [9600/11862 (81%)]\tLoss: 0.036857\n",
      "Train Epoch: 2 [10240/11862 (86%)]\tLoss: 0.017293\n",
      "Train Epoch: 2 [10880/11862 (91%)]\tLoss: 0.008052\n",
      "Train Epoch: 2 [11520/11862 (97%)]\tLoss: 0.282495\n",
      "Train Epoch: 3 [0/11862 (0%)]\tLoss: 0.065699\n",
      "Train Epoch: 3 [640/11862 (5%)]\tLoss: 0.026792\n",
      "Train Epoch: 3 [1280/11862 (11%)]\tLoss: 0.047757\n",
      "Train Epoch: 3 [1920/11862 (16%)]\tLoss: 0.021530\n",
      "Train Epoch: 3 [2560/11862 (22%)]\tLoss: 0.005305\n",
      "Train Epoch: 3 [3200/11862 (27%)]\tLoss: 0.037369\n",
      "Train Epoch: 3 [3840/11862 (32%)]\tLoss: 0.135067\n",
      "Train Epoch: 3 [4480/11862 (38%)]\tLoss: 0.034431\n",
      "Train Epoch: 3 [5120/11862 (43%)]\tLoss: 0.352246\n",
      "Train Epoch: 3 [5760/11862 (48%)]\tLoss: 0.066021\n",
      "Train Epoch: 3 [6400/11862 (54%)]\tLoss: 0.020905\n",
      "Train Epoch: 3 [7040/11862 (59%)]\tLoss: 0.034412\n",
      "Train Epoch: 3 [7680/11862 (65%)]\tLoss: 0.020726\n",
      "Train Epoch: 3 [8320/11862 (70%)]\tLoss: 0.013434\n",
      "Train Epoch: 3 [8960/11862 (75%)]\tLoss: 0.024479\n",
      "Train Epoch: 3 [9600/11862 (81%)]\tLoss: 0.109700\n",
      "Train Epoch: 3 [10240/11862 (86%)]\tLoss: 0.008988\n",
      "Train Epoch: 3 [10880/11862 (91%)]\tLoss: 0.046561\n",
      "Train Epoch: 3 [11520/11862 (97%)]\tLoss: 0.066730\n",
      "Train Epoch: 4 [0/11862 (0%)]\tLoss: 0.015644\n",
      "Train Epoch: 4 [640/11862 (5%)]\tLoss: 0.018642\n",
      "Train Epoch: 4 [1280/11862 (11%)]\tLoss: 0.022423\n",
      "Train Epoch: 4 [1920/11862 (16%)]\tLoss: 0.037615\n",
      "Train Epoch: 4 [2560/11862 (22%)]\tLoss: 0.016289\n",
      "Train Epoch: 4 [3200/11862 (27%)]\tLoss: 0.042208\n",
      "Train Epoch: 4 [3840/11862 (32%)]\tLoss: 0.037993\n",
      "Train Epoch: 4 [4480/11862 (38%)]\tLoss: 0.025801\n",
      "Train Epoch: 4 [5120/11862 (43%)]\tLoss: 0.029017\n",
      "Train Epoch: 4 [5760/11862 (48%)]\tLoss: 0.018626\n",
      "Train Epoch: 4 [6400/11862 (54%)]\tLoss: 0.082778\n",
      "Train Epoch: 4 [7040/11862 (59%)]\tLoss: 0.034355\n",
      "Train Epoch: 4 [7680/11862 (65%)]\tLoss: 0.009484\n",
      "Train Epoch: 4 [8320/11862 (70%)]\tLoss: 0.043395\n",
      "Train Epoch: 4 [8960/11862 (75%)]\tLoss: 0.084506\n",
      "Train Epoch: 4 [9600/11862 (81%)]\tLoss: 0.085247\n",
      "Train Epoch: 4 [10240/11862 (86%)]\tLoss: 0.006513\n",
      "Train Epoch: 4 [10880/11862 (91%)]\tLoss: 0.057970\n",
      "Train Epoch: 4 [11520/11862 (97%)]\tLoss: 0.103495\n",
      "Train Epoch: 5 [0/11862 (0%)]\tLoss: 0.095223\n",
      "Train Epoch: 5 [640/11862 (5%)]\tLoss: 0.027525\n",
      "Train Epoch: 5 [1280/11862 (11%)]\tLoss: 0.099343\n",
      "Train Epoch: 5 [1920/11862 (16%)]\tLoss: 0.043926\n",
      "Train Epoch: 5 [2560/11862 (22%)]\tLoss: 0.142142\n",
      "Train Epoch: 5 [3200/11862 (27%)]\tLoss: 0.047051\n",
      "Train Epoch: 5 [3840/11862 (32%)]\tLoss: 0.067479\n",
      "Train Epoch: 5 [4480/11862 (38%)]\tLoss: 0.029777\n",
      "Train Epoch: 5 [5120/11862 (43%)]\tLoss: 0.060126\n",
      "Train Epoch: 5 [5760/11862 (48%)]\tLoss: 0.110544\n",
      "Train Epoch: 5 [6400/11862 (54%)]\tLoss: 0.118462\n",
      "Train Epoch: 5 [7040/11862 (59%)]\tLoss: 0.164317\n",
      "Train Epoch: 5 [7680/11862 (65%)]\tLoss: 0.045759\n",
      "Train Epoch: 5 [8320/11862 (70%)]\tLoss: 0.058975\n",
      "Train Epoch: 5 [8960/11862 (75%)]\tLoss: 0.089629\n",
      "Train Epoch: 5 [9600/11862 (81%)]\tLoss: 0.051537\n",
      "Train Epoch: 5 [10240/11862 (86%)]\tLoss: 0.010120\n",
      "Train Epoch: 5 [10880/11862 (91%)]\tLoss: 0.023625\n",
      "Train Epoch: 5 [11520/11862 (97%)]\tLoss: 0.134661\n",
      "Train Epoch: 6 [0/11862 (0%)]\tLoss: 0.100817\n",
      "Train Epoch: 6 [640/11862 (5%)]\tLoss: 0.040347\n",
      "Train Epoch: 6 [1280/11862 (11%)]\tLoss: 0.049358\n",
      "Train Epoch: 6 [1920/11862 (16%)]\tLoss: 0.260464\n",
      "Train Epoch: 6 [2560/11862 (22%)]\tLoss: 0.024519\n",
      "Train Epoch: 6 [3200/11862 (27%)]\tLoss: 0.021266\n",
      "Train Epoch: 6 [3840/11862 (32%)]\tLoss: 0.176690\n",
      "Train Epoch: 6 [4480/11862 (38%)]\tLoss: 0.024123\n",
      "Train Epoch: 6 [5120/11862 (43%)]\tLoss: 0.048778\n",
      "Train Epoch: 6 [5760/11862 (48%)]\tLoss: 0.123053\n",
      "Train Epoch: 6 [6400/11862 (54%)]\tLoss: 0.009866\n",
      "Train Epoch: 6 [7040/11862 (59%)]\tLoss: 0.107979\n",
      "Train Epoch: 6 [7680/11862 (65%)]\tLoss: 0.025376\n",
      "Train Epoch: 6 [8320/11862 (70%)]\tLoss: 0.037145\n",
      "Train Epoch: 6 [8960/11862 (75%)]\tLoss: 0.041123\n",
      "Train Epoch: 6 [9600/11862 (81%)]\tLoss: 0.042587\n",
      "Train Epoch: 6 [10240/11862 (86%)]\tLoss: 0.038324\n",
      "Train Epoch: 6 [10880/11862 (91%)]\tLoss: 0.167206\n",
      "Train Epoch: 6 [11520/11862 (97%)]\tLoss: 0.027964\n",
      "Train Epoch: 7 [0/11862 (0%)]\tLoss: 0.025222\n",
      "Train Epoch: 7 [640/11862 (5%)]\tLoss: 0.051016\n",
      "Train Epoch: 7 [1280/11862 (11%)]\tLoss: 0.024165\n",
      "Train Epoch: 7 [1920/11862 (16%)]\tLoss: 0.079692\n",
      "Train Epoch: 7 [2560/11862 (22%)]\tLoss: 0.022064\n",
      "Train Epoch: 7 [3200/11862 (27%)]\tLoss: 0.025687\n",
      "Train Epoch: 7 [3840/11862 (32%)]\tLoss: 0.046779\n",
      "Train Epoch: 7 [4480/11862 (38%)]\tLoss: 0.093746\n",
      "Train Epoch: 7 [5120/11862 (43%)]\tLoss: 0.123477\n",
      "Train Epoch: 7 [5760/11862 (48%)]\tLoss: 0.031531\n",
      "Train Epoch: 7 [6400/11862 (54%)]\tLoss: 0.041754\n",
      "Train Epoch: 7 [7040/11862 (59%)]\tLoss: 0.050287\n",
      "Train Epoch: 7 [7680/11862 (65%)]\tLoss: 0.059321\n",
      "Train Epoch: 7 [8320/11862 (70%)]\tLoss: 0.081125\n",
      "Train Epoch: 7 [8960/11862 (75%)]\tLoss: 0.033589\n",
      "Train Epoch: 7 [9600/11862 (81%)]\tLoss: 0.006968\n",
      "Train Epoch: 7 [10240/11862 (86%)]\tLoss: 0.016289\n",
      "Train Epoch: 7 [10880/11862 (91%)]\tLoss: 0.016800\n",
      "Train Epoch: 7 [11520/11862 (97%)]\tLoss: 0.033718\n",
      "Train Epoch: 8 [0/11862 (0%)]\tLoss: 0.031980\n",
      "Train Epoch: 8 [640/11862 (5%)]\tLoss: 0.295126\n",
      "Train Epoch: 8 [1280/11862 (11%)]\tLoss: 0.038576\n",
      "Train Epoch: 8 [1920/11862 (16%)]\tLoss: 0.020461\n",
      "Train Epoch: 8 [2560/11862 (22%)]\tLoss: 0.040388\n",
      "Train Epoch: 8 [3200/11862 (27%)]\tLoss: 0.057291\n",
      "Train Epoch: 8 [3840/11862 (32%)]\tLoss: 0.122797\n",
      "Train Epoch: 8 [4480/11862 (38%)]\tLoss: 0.116907\n",
      "Train Epoch: 8 [5120/11862 (43%)]\tLoss: 0.016034\n",
      "Train Epoch: 8 [5760/11862 (48%)]\tLoss: 0.022056\n",
      "Train Epoch: 8 [6400/11862 (54%)]\tLoss: 0.029637\n",
      "Train Epoch: 8 [7040/11862 (59%)]\tLoss: 0.058060\n",
      "Train Epoch: 8 [7680/11862 (65%)]\tLoss: 0.039907\n",
      "Train Epoch: 8 [8320/11862 (70%)]\tLoss: 0.007642\n",
      "Train Epoch: 8 [8960/11862 (75%)]\tLoss: 0.072886\n",
      "Train Epoch: 8 [9600/11862 (81%)]\tLoss: 0.121351\n",
      "Train Epoch: 8 [10240/11862 (86%)]\tLoss: 0.022681\n",
      "Train Epoch: 8 [10880/11862 (91%)]\tLoss: 0.051061\n",
      "Train Epoch: 8 [11520/11862 (97%)]\tLoss: 0.047650\n",
      "Train Epoch: 9 [0/11862 (0%)]\tLoss: 0.017483\n",
      "Train Epoch: 9 [640/11862 (5%)]\tLoss: 0.025051\n",
      "Train Epoch: 9 [1280/11862 (11%)]\tLoss: 0.017141\n",
      "Train Epoch: 9 [1920/11862 (16%)]\tLoss: 0.095463\n",
      "Train Epoch: 9 [2560/11862 (22%)]\tLoss: 0.064393\n",
      "Train Epoch: 9 [3200/11862 (27%)]\tLoss: 0.133800\n",
      "Train Epoch: 9 [3840/11862 (32%)]\tLoss: 0.046754\n",
      "Train Epoch: 9 [4480/11862 (38%)]\tLoss: 0.051718\n",
      "Train Epoch: 9 [5120/11862 (43%)]\tLoss: 0.043203\n",
      "Train Epoch: 9 [5760/11862 (48%)]\tLoss: 0.003964\n",
      "Train Epoch: 9 [6400/11862 (54%)]\tLoss: 0.019150\n",
      "Train Epoch: 9 [7040/11862 (59%)]\tLoss: 0.082516\n",
      "Train Epoch: 9 [7680/11862 (65%)]\tLoss: 0.033012\n",
      "Train Epoch: 9 [8320/11862 (70%)]\tLoss: 0.125151\n",
      "Train Epoch: 9 [8960/11862 (75%)]\tLoss: 0.115442\n",
      "Train Epoch: 9 [9600/11862 (81%)]\tLoss: 0.035073\n",
      "Train Epoch: 9 [10240/11862 (86%)]\tLoss: 0.170867\n",
      "Train Epoch: 9 [10880/11862 (91%)]\tLoss: 0.095504\n",
      "Train Epoch: 9 [11520/11862 (97%)]\tLoss: 0.024274\n",
      "Train Epoch: 10 [0/11862 (0%)]\tLoss: 0.004387\n",
      "Train Epoch: 10 [640/11862 (5%)]\tLoss: 0.024604\n",
      "Train Epoch: 10 [1280/11862 (11%)]\tLoss: 0.022498\n",
      "Train Epoch: 10 [1920/11862 (16%)]\tLoss: 0.074391\n",
      "Train Epoch: 10 [2560/11862 (22%)]\tLoss: 0.022739\n",
      "Train Epoch: 10 [3200/11862 (27%)]\tLoss: 0.045049\n",
      "Train Epoch: 10 [3840/11862 (32%)]\tLoss: 0.043817\n",
      "Train Epoch: 10 [4480/11862 (38%)]\tLoss: 0.263069\n",
      "Train Epoch: 10 [5120/11862 (43%)]\tLoss: 0.040029\n",
      "Train Epoch: 10 [5760/11862 (48%)]\tLoss: 0.025079\n",
      "Train Epoch: 10 [6400/11862 (54%)]\tLoss: 0.058730\n",
      "Train Epoch: 10 [7040/11862 (59%)]\tLoss: 0.042168\n",
      "Train Epoch: 10 [7680/11862 (65%)]\tLoss: 0.062988\n",
      "Train Epoch: 10 [8320/11862 (70%)]\tLoss: 0.085744\n",
      "Train Epoch: 10 [8960/11862 (75%)]\tLoss: 0.122714\n",
      "Train Epoch: 10 [9600/11862 (81%)]\tLoss: 0.019021\n",
      "Train Epoch: 10 [10240/11862 (86%)]\tLoss: 0.038439\n",
      "Train Epoch: 10 [10880/11862 (91%)]\tLoss: 0.103261\n",
      "Train Epoch: 10 [11520/11862 (97%)]\tLoss: 0.019468\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 0.046568\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 0.046759\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 0.074344\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 0.239497\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 0.096306\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 0.087804\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 0.080837\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 0.096468\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 0.041071\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 0.048943\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 0.015924\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 0.082186\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 0.147807\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 0.061489\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 0.051957\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 0.026756\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 0.025339\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.069985\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.148472\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.033160\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.055366\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.137704\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.064494\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.086726\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.013471\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.011874\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.003617\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.042070\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.020987\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.029299\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.064468\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.092178\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.129962\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.145220\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.082855\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.079940\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.092749\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.078466\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.102968\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.039092\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.062680\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.048164\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.095081\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.047138\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.086327\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.079534\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.063240\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.106004\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.105049\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.110554\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.017330\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.142064\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.007473\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.065488\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.078226\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.070553\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.049949\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.114413\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.023975\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.042274\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.156041\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.031644\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.057201\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.045422\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.130851\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.026490\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.025101\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.170236\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.080635\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.017520\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.025482\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.011292\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.194989\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.094108\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.036037\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.013539\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.011818\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.086277\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.131231\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.035929\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.131874\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.076015\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.070125\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.078753\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.021438\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.035056\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.075190\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.072012\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.012291\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.200814\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.031394\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.055922\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.139216\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.022627\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.008131\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.021269\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.121439\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.023394\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.037905\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.027477\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.050872\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.017957\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.128455\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.020957\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.054441\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.036218\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.012422\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.131609\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.091310\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.052791\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.054381\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.052773\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.032021\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.023453\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.036322\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.021594\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.072711\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.023323\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.014481\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.057429\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.016554\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.213930\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.156944\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.029195\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.019672\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.014788\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.048935\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.019407\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.098106\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.013783\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.072079\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.005702\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.025950\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.017537\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.031224\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.259588\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.018811\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.011280\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.096070\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.176329\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.024373\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.012039\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.008838\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.081079\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.115777\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.062742\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.012294\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.018311\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.038885\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.018496\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.048105\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.041242\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.009285\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.028717\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.094257\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.055554\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.045792\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.056667\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.066659\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.068674\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5509 (0%)]\tLoss: 0.176745\n",
      "Train Epoch: 1 [640/5509 (11%)]\tLoss: 0.150526\n",
      "Train Epoch: 1 [1280/5509 (23%)]\tLoss: 0.161119\n",
      "Train Epoch: 1 [1920/5509 (34%)]\tLoss: 0.075471\n",
      "Train Epoch: 1 [2560/5509 (46%)]\tLoss: 0.123356\n",
      "Train Epoch: 1 [3200/5509 (57%)]\tLoss: 0.201071\n",
      "Train Epoch: 1 [3840/5509 (69%)]\tLoss: 0.104487\n",
      "Train Epoch: 1 [4480/5509 (80%)]\tLoss: 0.048957\n",
      "Train Epoch: 1 [5120/5509 (92%)]\tLoss: 0.064743\n",
      "Train Epoch: 2 [0/5509 (0%)]\tLoss: 0.056060\n",
      "Train Epoch: 2 [640/5509 (11%)]\tLoss: 0.057977\n",
      "Train Epoch: 2 [1280/5509 (23%)]\tLoss: 0.019715\n",
      "Train Epoch: 2 [1920/5509 (34%)]\tLoss: 0.091351\n",
      "Train Epoch: 2 [2560/5509 (46%)]\tLoss: 0.153585\n",
      "Train Epoch: 2 [3200/5509 (57%)]\tLoss: 0.061513\n",
      "Train Epoch: 2 [3840/5509 (69%)]\tLoss: 0.125564\n",
      "Train Epoch: 2 [4480/5509 (80%)]\tLoss: 0.079618\n",
      "Train Epoch: 2 [5120/5509 (92%)]\tLoss: 0.127936\n",
      "Train Epoch: 3 [0/5509 (0%)]\tLoss: 0.040611\n",
      "Train Epoch: 3 [640/5509 (11%)]\tLoss: 0.056301\n",
      "Train Epoch: 3 [1280/5509 (23%)]\tLoss: 0.011391\n",
      "Train Epoch: 3 [1920/5509 (34%)]\tLoss: 0.019105\n",
      "Train Epoch: 3 [2560/5509 (46%)]\tLoss: 0.102151\n",
      "Train Epoch: 3 [3200/5509 (57%)]\tLoss: 0.252437\n",
      "Train Epoch: 3 [3840/5509 (69%)]\tLoss: 0.161826\n",
      "Train Epoch: 3 [4480/5509 (80%)]\tLoss: 0.038276\n",
      "Train Epoch: 3 [5120/5509 (92%)]\tLoss: 0.018915\n",
      "Train Epoch: 4 [0/5509 (0%)]\tLoss: 0.028041\n",
      "Train Epoch: 4 [640/5509 (11%)]\tLoss: 0.092210\n",
      "Train Epoch: 4 [1280/5509 (23%)]\tLoss: 0.022159\n",
      "Train Epoch: 4 [1920/5509 (34%)]\tLoss: 0.058828\n",
      "Train Epoch: 4 [2560/5509 (46%)]\tLoss: 0.027051\n",
      "Train Epoch: 4 [3200/5509 (57%)]\tLoss: 0.042087\n",
      "Train Epoch: 4 [3840/5509 (69%)]\tLoss: 0.207410\n",
      "Train Epoch: 4 [4480/5509 (80%)]\tLoss: 0.076808\n",
      "Train Epoch: 4 [5120/5509 (92%)]\tLoss: 0.119761\n",
      "Train Epoch: 5 [0/5509 (0%)]\tLoss: 0.042148\n",
      "Train Epoch: 5 [640/5509 (11%)]\tLoss: 0.022357\n",
      "Train Epoch: 5 [1280/5509 (23%)]\tLoss: 0.025481\n",
      "Train Epoch: 5 [1920/5509 (34%)]\tLoss: 0.079941\n",
      "Train Epoch: 5 [2560/5509 (46%)]\tLoss: 0.141764\n",
      "Train Epoch: 5 [3200/5509 (57%)]\tLoss: 0.195075\n",
      "Train Epoch: 5 [3840/5509 (69%)]\tLoss: 0.028060\n",
      "Train Epoch: 5 [4480/5509 (80%)]\tLoss: 0.120197\n",
      "Train Epoch: 5 [5120/5509 (92%)]\tLoss: 0.241774\n",
      "Train Epoch: 6 [0/5509 (0%)]\tLoss: 0.028763\n",
      "Train Epoch: 6 [640/5509 (11%)]\tLoss: 0.127210\n",
      "Train Epoch: 6 [1280/5509 (23%)]\tLoss: 0.031588\n",
      "Train Epoch: 6 [1920/5509 (34%)]\tLoss: 0.060859\n",
      "Train Epoch: 6 [2560/5509 (46%)]\tLoss: 0.015988\n",
      "Train Epoch: 6 [3200/5509 (57%)]\tLoss: 0.037093\n",
      "Train Epoch: 6 [3840/5509 (69%)]\tLoss: 0.103138\n",
      "Train Epoch: 6 [4480/5509 (80%)]\tLoss: 0.101329\n",
      "Train Epoch: 6 [5120/5509 (92%)]\tLoss: 0.079141\n",
      "Train Epoch: 7 [0/5509 (0%)]\tLoss: 0.203382\n",
      "Train Epoch: 7 [640/5509 (11%)]\tLoss: 0.235227\n",
      "Train Epoch: 7 [1280/5509 (23%)]\tLoss: 0.042206\n",
      "Train Epoch: 7 [1920/5509 (34%)]\tLoss: 0.028210\n",
      "Train Epoch: 7 [2560/5509 (46%)]\tLoss: 0.024512\n",
      "Train Epoch: 7 [3200/5509 (57%)]\tLoss: 0.202614\n",
      "Train Epoch: 7 [3840/5509 (69%)]\tLoss: 0.120442\n",
      "Train Epoch: 7 [4480/5509 (80%)]\tLoss: 0.084819\n",
      "Train Epoch: 7 [5120/5509 (92%)]\tLoss: 0.019448\n",
      "Train Epoch: 8 [0/5509 (0%)]\tLoss: 0.043937\n",
      "Train Epoch: 8 [640/5509 (11%)]\tLoss: 0.125971\n",
      "Train Epoch: 8 [1280/5509 (23%)]\tLoss: 0.080177\n",
      "Train Epoch: 8 [1920/5509 (34%)]\tLoss: 0.035202\n",
      "Train Epoch: 8 [2560/5509 (46%)]\tLoss: 0.062861\n",
      "Train Epoch: 8 [3200/5509 (57%)]\tLoss: 0.157753\n",
      "Train Epoch: 8 [3840/5509 (69%)]\tLoss: 0.091291\n",
      "Train Epoch: 8 [4480/5509 (80%)]\tLoss: 0.039529\n",
      "Train Epoch: 8 [5120/5509 (92%)]\tLoss: 0.008666\n",
      "Train Epoch: 9 [0/5509 (0%)]\tLoss: 0.044466\n",
      "Train Epoch: 9 [640/5509 (11%)]\tLoss: 0.031729\n",
      "Train Epoch: 9 [1280/5509 (23%)]\tLoss: 0.024146\n",
      "Train Epoch: 9 [1920/5509 (34%)]\tLoss: 0.042619\n",
      "Train Epoch: 9 [2560/5509 (46%)]\tLoss: 0.028981\n",
      "Train Epoch: 9 [3200/5509 (57%)]\tLoss: 0.086514\n",
      "Train Epoch: 9 [3840/5509 (69%)]\tLoss: 0.141701\n",
      "Train Epoch: 9 [4480/5509 (80%)]\tLoss: 0.037983\n",
      "Train Epoch: 9 [5120/5509 (92%)]\tLoss: 0.131292\n",
      "Train Epoch: 10 [0/5509 (0%)]\tLoss: 0.057775\n",
      "Train Epoch: 10 [640/5509 (11%)]\tLoss: 0.098531\n",
      "Train Epoch: 10 [1280/5509 (23%)]\tLoss: 0.049166\n",
      "Train Epoch: 10 [1920/5509 (34%)]\tLoss: 0.023882\n",
      "Train Epoch: 10 [2560/5509 (46%)]\tLoss: 0.045633\n",
      "Train Epoch: 10 [3200/5509 (57%)]\tLoss: 0.096418\n",
      "Train Epoch: 10 [3840/5509 (69%)]\tLoss: 0.092402\n",
      "Train Epoch: 10 [4480/5509 (80%)]\tLoss: 0.029418\n",
      "Train Epoch: 10 [5120/5509 (92%)]\tLoss: 0.011132\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 0.233446\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 0.019111\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 0.129027\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 0.048019\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 0.062443\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 0.034976\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 0.037325\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 0.015887\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 0.051100\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 0.166091\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.100491\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.016305\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 0.047408\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 0.030909\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 0.027202\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.014318\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.177297\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.156706\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.119701\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.105916\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.045412\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.074423\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.032707\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.044280\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.070550\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.026477\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.030796\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.023089\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.022567\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.035944\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.014704\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.191328\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.009756\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.182689\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.004047\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.192623\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.073962\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.035715\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.006153\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.015687\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.010297\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.027964\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.048732\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.117528\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.144202\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.043761\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.026596\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.022785\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.031445\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.103220\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.178609\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.034834\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.044350\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.010116\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.045246\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.099512\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.073732\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.023489\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.010041\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.161764\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.018218\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.096290\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.018826\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.039201\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.032106\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.007235\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.021038\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.020547\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.053108\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.113619\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.040518\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.022710\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.095294\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.063027\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.064206\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.005857\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.012775\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.065279\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.013716\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.009857\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.017214\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.121778\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.166981\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.036710\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.077488\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.002308\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.079428\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.039020\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.011851\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.003314\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.012434\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.134602\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.055823\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.022305\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.018461\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.036436\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.025199\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.025783\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.052052\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.073167\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.034185\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.072835\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.030741\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.030328\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.024220\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.025951\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.017587\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.019980\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.068377\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.061891\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.051257\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.026827\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.066289\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.067673\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.019923\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.015695\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.049355\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.000899\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.028803\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.049468\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0530, Accuracy: 9824/10000 (98%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 0.093645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 0.104687\n",
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 0.122727\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 0.046322\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 0.055008\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 0.137863\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 0.078501\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 0.044918\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 0.109033\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 0.165140\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 0.063895\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 0.050198\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 0.099931\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 0.023959\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 0.128812\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 0.009380\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 0.036356\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 0.051907\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 0.045979\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 0.152569\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.062294\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 0.043446\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 0.165382\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.088757\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.026976\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 0.060520\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.015901\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 0.061555\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.074738\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.041774\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.059750\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.095192\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.086453\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.035396\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.038278\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.057649\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.244402\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.091302\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.017902\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.059403\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.044472\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.035185\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.088780\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.077805\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.207875\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.029698\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.080348\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.133851\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.050892\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.081904\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.125138\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.125213\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.126715\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.061228\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.009445\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.043606\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.225635\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.185828\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.061870\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.024467\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.016009\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.056067\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.057463\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.285939\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.096731\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.064342\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.075401\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.119299\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.131027\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.028805\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.015576\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.056187\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.107287\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.063730\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.078155\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.151937\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.004431\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.156615\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.122493\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.023241\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.035843\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.021615\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.053997\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.079532\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.143392\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.116309\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.087052\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.093599\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.045959\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.150758\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.114537\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.041515\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.032349\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.031535\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.120249\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.021477\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.015020\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.073123\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.109933\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.021508\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.060308\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.019325\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.133055\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.129628\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.014770\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.064520\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.041166\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.035506\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 0.066627\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.021216\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.022957\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.048339\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.009262\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.063645\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.072551\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.037772\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.073130\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.136087\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.160293\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.045756\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.075311\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.034664\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.047779\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.058167\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.042109\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.037998\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.035439\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.058519\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.139800\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.051767\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.045179\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.030642\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.017218\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.074988\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.074328\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.081672\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.067822\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.010229\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.045915\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.033741\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.194056\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.048331\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.028282\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.049257\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.138537\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.028004\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.034767\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.111681\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.026227\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.006098\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.097616\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.075491\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.019340\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.042012\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.016374\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.239571\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.056318\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.009876\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.051230\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.046476\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.112804\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.015560\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.029933\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.012496\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.173105\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.019151\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.049222\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.021465\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.061476\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.031615\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.023194\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.112413\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.123496\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.204134\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.016602\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.061814\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.035982\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.017416\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.038245\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.032121\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/13906 (0%)]\tLoss: 0.131309\n",
      "Train Epoch: 1 [640/13906 (5%)]\tLoss: 0.100101\n",
      "Train Epoch: 1 [1280/13906 (9%)]\tLoss: 0.134461\n",
      "Train Epoch: 1 [1920/13906 (14%)]\tLoss: 0.194282\n",
      "Train Epoch: 1 [2560/13906 (18%)]\tLoss: 0.327072\n",
      "Train Epoch: 1 [3200/13906 (23%)]\tLoss: 0.111334\n",
      "Train Epoch: 1 [3840/13906 (28%)]\tLoss: 0.074242\n",
      "Train Epoch: 1 [4480/13906 (32%)]\tLoss: 0.247856\n",
      "Train Epoch: 1 [5120/13906 (37%)]\tLoss: 0.064455\n",
      "Train Epoch: 1 [5760/13906 (41%)]\tLoss: 0.083144\n",
      "Train Epoch: 1 [6400/13906 (46%)]\tLoss: 0.160881\n",
      "Train Epoch: 1 [7040/13906 (50%)]\tLoss: 0.029084\n",
      "Train Epoch: 1 [7680/13906 (55%)]\tLoss: 0.076596\n",
      "Train Epoch: 1 [8320/13906 (60%)]\tLoss: 0.040870\n",
      "Train Epoch: 1 [8960/13906 (64%)]\tLoss: 0.030155\n",
      "Train Epoch: 1 [9600/13906 (69%)]\tLoss: 0.042844\n",
      "Train Epoch: 1 [10240/13906 (73%)]\tLoss: 0.253009\n",
      "Train Epoch: 1 [10880/13906 (78%)]\tLoss: 0.127053\n",
      "Train Epoch: 1 [11520/13906 (83%)]\tLoss: 0.092516\n",
      "Train Epoch: 1 [12160/13906 (87%)]\tLoss: 0.035520\n",
      "Train Epoch: 1 [12800/13906 (92%)]\tLoss: 0.048972\n",
      "Train Epoch: 1 [13440/13906 (96%)]\tLoss: 0.074177\n",
      "Train Epoch: 2 [0/13906 (0%)]\tLoss: 0.094014\n",
      "Train Epoch: 2 [640/13906 (5%)]\tLoss: 0.020680\n",
      "Train Epoch: 2 [1280/13906 (9%)]\tLoss: 0.160841\n",
      "Train Epoch: 2 [1920/13906 (14%)]\tLoss: 0.391364\n",
      "Train Epoch: 2 [2560/13906 (18%)]\tLoss: 0.099975\n",
      "Train Epoch: 2 [3200/13906 (23%)]\tLoss: 0.112887\n",
      "Train Epoch: 2 [3840/13906 (28%)]\tLoss: 0.061741\n",
      "Train Epoch: 2 [4480/13906 (32%)]\tLoss: 0.025919\n",
      "Train Epoch: 2 [5120/13906 (37%)]\tLoss: 0.020113\n",
      "Train Epoch: 2 [5760/13906 (41%)]\tLoss: 0.167078\n",
      "Train Epoch: 2 [6400/13906 (46%)]\tLoss: 0.039741\n",
      "Train Epoch: 2 [7040/13906 (50%)]\tLoss: 0.129841\n",
      "Train Epoch: 2 [7680/13906 (55%)]\tLoss: 0.161601\n",
      "Train Epoch: 2 [8320/13906 (60%)]\tLoss: 0.027312\n",
      "Train Epoch: 2 [8960/13906 (64%)]\tLoss: 0.026381\n",
      "Train Epoch: 2 [9600/13906 (69%)]\tLoss: 0.080761\n",
      "Train Epoch: 2 [10240/13906 (73%)]\tLoss: 0.103637\n",
      "Train Epoch: 2 [10880/13906 (78%)]\tLoss: 0.019972\n",
      "Train Epoch: 2 [11520/13906 (83%)]\tLoss: 0.206105\n",
      "Train Epoch: 2 [12160/13906 (87%)]\tLoss: 0.022772\n",
      "Train Epoch: 2 [12800/13906 (92%)]\tLoss: 0.054539\n",
      "Train Epoch: 2 [13440/13906 (96%)]\tLoss: 0.067051\n",
      "Train Epoch: 3 [0/13906 (0%)]\tLoss: 0.065693\n",
      "Train Epoch: 3 [640/13906 (5%)]\tLoss: 0.045436\n",
      "Train Epoch: 3 [1280/13906 (9%)]\tLoss: 0.074397\n",
      "Train Epoch: 3 [1920/13906 (14%)]\tLoss: 0.022147\n",
      "Train Epoch: 3 [2560/13906 (18%)]\tLoss: 0.043837\n",
      "Train Epoch: 3 [3200/13906 (23%)]\tLoss: 0.025277\n",
      "Train Epoch: 3 [3840/13906 (28%)]\tLoss: 0.075535\n",
      "Train Epoch: 3 [4480/13906 (32%)]\tLoss: 0.077835\n",
      "Train Epoch: 3 [5120/13906 (37%)]\tLoss: 0.045238\n",
      "Train Epoch: 3 [5760/13906 (41%)]\tLoss: 0.052849\n",
      "Train Epoch: 3 [6400/13906 (46%)]\tLoss: 0.019815\n",
      "Train Epoch: 3 [7040/13906 (50%)]\tLoss: 0.068243\n",
      "Train Epoch: 3 [7680/13906 (55%)]\tLoss: 0.093974\n",
      "Train Epoch: 3 [8320/13906 (60%)]\tLoss: 0.094819\n",
      "Train Epoch: 3 [8960/13906 (64%)]\tLoss: 0.060762\n",
      "Train Epoch: 3 [9600/13906 (69%)]\tLoss: 0.117297\n",
      "Train Epoch: 3 [10240/13906 (73%)]\tLoss: 0.171084\n",
      "Train Epoch: 3 [10880/13906 (78%)]\tLoss: 0.113961\n",
      "Train Epoch: 3 [11520/13906 (83%)]\tLoss: 0.019032\n",
      "Train Epoch: 3 [12160/13906 (87%)]\tLoss: 0.084420\n",
      "Train Epoch: 3 [12800/13906 (92%)]\tLoss: 0.152428\n",
      "Train Epoch: 3 [13440/13906 (96%)]\tLoss: 0.063400\n",
      "Train Epoch: 4 [0/13906 (0%)]\tLoss: 0.105238\n",
      "Train Epoch: 4 [640/13906 (5%)]\tLoss: 0.095714\n",
      "Train Epoch: 4 [1280/13906 (9%)]\tLoss: 0.082752\n",
      "Train Epoch: 4 [1920/13906 (14%)]\tLoss: 0.074399\n",
      "Train Epoch: 4 [2560/13906 (18%)]\tLoss: 0.072019\n",
      "Train Epoch: 4 [3200/13906 (23%)]\tLoss: 0.086442\n",
      "Train Epoch: 4 [3840/13906 (28%)]\tLoss: 0.056638\n",
      "Train Epoch: 4 [4480/13906 (32%)]\tLoss: 0.056160\n",
      "Train Epoch: 4 [5120/13906 (37%)]\tLoss: 0.017671\n",
      "Train Epoch: 4 [5760/13906 (41%)]\tLoss: 0.229697\n",
      "Train Epoch: 4 [6400/13906 (46%)]\tLoss: 0.074434\n",
      "Train Epoch: 4 [7040/13906 (50%)]\tLoss: 0.111121\n",
      "Train Epoch: 4 [7680/13906 (55%)]\tLoss: 0.117122\n",
      "Train Epoch: 4 [8320/13906 (60%)]\tLoss: 0.052837\n",
      "Train Epoch: 4 [8960/13906 (64%)]\tLoss: 0.058973\n",
      "Train Epoch: 4 [9600/13906 (69%)]\tLoss: 0.019339\n",
      "Train Epoch: 4 [10240/13906 (73%)]\tLoss: 0.041052\n",
      "Train Epoch: 4 [10880/13906 (78%)]\tLoss: 0.050093\n",
      "Train Epoch: 4 [11520/13906 (83%)]\tLoss: 0.013412\n",
      "Train Epoch: 4 [12160/13906 (87%)]\tLoss: 0.030950\n",
      "Train Epoch: 4 [12800/13906 (92%)]\tLoss: 0.016747\n",
      "Train Epoch: 4 [13440/13906 (96%)]\tLoss: 0.018242\n",
      "Train Epoch: 5 [0/13906 (0%)]\tLoss: 0.028481\n",
      "Train Epoch: 5 [640/13906 (5%)]\tLoss: 0.040583\n",
      "Train Epoch: 5 [1280/13906 (9%)]\tLoss: 0.086597\n",
      "Train Epoch: 5 [1920/13906 (14%)]\tLoss: 0.037667\n",
      "Train Epoch: 5 [2560/13906 (18%)]\tLoss: 0.062057\n",
      "Train Epoch: 5 [3200/13906 (23%)]\tLoss: 0.111992\n",
      "Train Epoch: 5 [3840/13906 (28%)]\tLoss: 0.051423\n",
      "Train Epoch: 5 [4480/13906 (32%)]\tLoss: 0.082637\n",
      "Train Epoch: 5 [5120/13906 (37%)]\tLoss: 0.034795\n",
      "Train Epoch: 5 [5760/13906 (41%)]\tLoss: 0.045326\n",
      "Train Epoch: 5 [6400/13906 (46%)]\tLoss: 0.035320\n",
      "Train Epoch: 5 [7040/13906 (50%)]\tLoss: 0.043899\n",
      "Train Epoch: 5 [7680/13906 (55%)]\tLoss: 0.152630\n",
      "Train Epoch: 5 [8320/13906 (60%)]\tLoss: 0.047981\n",
      "Train Epoch: 5 [8960/13906 (64%)]\tLoss: 0.071387\n",
      "Train Epoch: 5 [9600/13906 (69%)]\tLoss: 0.050224\n",
      "Train Epoch: 5 [10240/13906 (73%)]\tLoss: 0.027394\n",
      "Train Epoch: 5 [10880/13906 (78%)]\tLoss: 0.096944\n",
      "Train Epoch: 5 [11520/13906 (83%)]\tLoss: 0.102608\n",
      "Train Epoch: 5 [12160/13906 (87%)]\tLoss: 0.075575\n",
      "Train Epoch: 5 [12800/13906 (92%)]\tLoss: 0.068165\n",
      "Train Epoch: 5 [13440/13906 (96%)]\tLoss: 0.159612\n",
      "Train Epoch: 6 [0/13906 (0%)]\tLoss: 0.013530\n",
      "Train Epoch: 6 [640/13906 (5%)]\tLoss: 0.292211\n",
      "Train Epoch: 6 [1280/13906 (9%)]\tLoss: 0.050724\n",
      "Train Epoch: 6 [1920/13906 (14%)]\tLoss: 0.046633\n",
      "Train Epoch: 6 [2560/13906 (18%)]\tLoss: 0.053207\n",
      "Train Epoch: 6 [3200/13906 (23%)]\tLoss: 0.134728\n",
      "Train Epoch: 6 [3840/13906 (28%)]\tLoss: 0.024930\n",
      "Train Epoch: 6 [4480/13906 (32%)]\tLoss: 0.115819\n",
      "Train Epoch: 6 [5120/13906 (37%)]\tLoss: 0.133281\n",
      "Train Epoch: 6 [5760/13906 (41%)]\tLoss: 0.005064\n",
      "Train Epoch: 6 [6400/13906 (46%)]\tLoss: 0.014904\n",
      "Train Epoch: 6 [7040/13906 (50%)]\tLoss: 0.069194\n",
      "Train Epoch: 6 [7680/13906 (55%)]\tLoss: 0.044282\n",
      "Train Epoch: 6 [8320/13906 (60%)]\tLoss: 0.014699\n",
      "Train Epoch: 6 [8960/13906 (64%)]\tLoss: 0.058150\n",
      "Train Epoch: 6 [9600/13906 (69%)]\tLoss: 0.284544\n",
      "Train Epoch: 6 [10240/13906 (73%)]\tLoss: 0.037340\n",
      "Train Epoch: 6 [10880/13906 (78%)]\tLoss: 0.102202\n",
      "Train Epoch: 6 [11520/13906 (83%)]\tLoss: 0.090802\n",
      "Train Epoch: 6 [12160/13906 (87%)]\tLoss: 0.054952\n",
      "Train Epoch: 6 [12800/13906 (92%)]\tLoss: 0.038204\n",
      "Train Epoch: 6 [13440/13906 (96%)]\tLoss: 0.032293\n",
      "Train Epoch: 7 [0/13906 (0%)]\tLoss: 0.033500\n",
      "Train Epoch: 7 [640/13906 (5%)]\tLoss: 0.104151\n",
      "Train Epoch: 7 [1280/13906 (9%)]\tLoss: 0.009209\n",
      "Train Epoch: 7 [1920/13906 (14%)]\tLoss: 0.016955\n",
      "Train Epoch: 7 [2560/13906 (18%)]\tLoss: 0.062335\n",
      "Train Epoch: 7 [3200/13906 (23%)]\tLoss: 0.036361\n",
      "Train Epoch: 7 [3840/13906 (28%)]\tLoss: 0.026167\n",
      "Train Epoch: 7 [4480/13906 (32%)]\tLoss: 0.038956\n",
      "Train Epoch: 7 [5120/13906 (37%)]\tLoss: 0.045952\n",
      "Train Epoch: 7 [5760/13906 (41%)]\tLoss: 0.042636\n",
      "Train Epoch: 7 [6400/13906 (46%)]\tLoss: 0.120356\n",
      "Train Epoch: 7 [7040/13906 (50%)]\tLoss: 0.075262\n",
      "Train Epoch: 7 [7680/13906 (55%)]\tLoss: 0.078224\n",
      "Train Epoch: 7 [8320/13906 (60%)]\tLoss: 0.114516\n",
      "Train Epoch: 7 [8960/13906 (64%)]\tLoss: 0.021510\n",
      "Train Epoch: 7 [9600/13906 (69%)]\tLoss: 0.025060\n",
      "Train Epoch: 7 [10240/13906 (73%)]\tLoss: 0.172007\n",
      "Train Epoch: 7 [10880/13906 (78%)]\tLoss: 0.063535\n",
      "Train Epoch: 7 [11520/13906 (83%)]\tLoss: 0.100807\n",
      "Train Epoch: 7 [12160/13906 (87%)]\tLoss: 0.037811\n",
      "Train Epoch: 7 [12800/13906 (92%)]\tLoss: 0.064404\n",
      "Train Epoch: 7 [13440/13906 (96%)]\tLoss: 0.060105\n",
      "Train Epoch: 8 [0/13906 (0%)]\tLoss: 0.171488\n",
      "Train Epoch: 8 [640/13906 (5%)]\tLoss: 0.041598\n",
      "Train Epoch: 8 [1280/13906 (9%)]\tLoss: 0.143429\n",
      "Train Epoch: 8 [1920/13906 (14%)]\tLoss: 0.046380\n",
      "Train Epoch: 8 [2560/13906 (18%)]\tLoss: 0.021351\n",
      "Train Epoch: 8 [3200/13906 (23%)]\tLoss: 0.072865\n",
      "Train Epoch: 8 [3840/13906 (28%)]\tLoss: 0.046163\n",
      "Train Epoch: 8 [4480/13906 (32%)]\tLoss: 0.024301\n",
      "Train Epoch: 8 [5120/13906 (37%)]\tLoss: 0.055980\n",
      "Train Epoch: 8 [5760/13906 (41%)]\tLoss: 0.080328\n",
      "Train Epoch: 8 [6400/13906 (46%)]\tLoss: 0.010749\n",
      "Train Epoch: 8 [7040/13906 (50%)]\tLoss: 0.053050\n",
      "Train Epoch: 8 [7680/13906 (55%)]\tLoss: 0.032983\n",
      "Train Epoch: 8 [8320/13906 (60%)]\tLoss: 0.181463\n",
      "Train Epoch: 8 [8960/13906 (64%)]\tLoss: 0.031285\n",
      "Train Epoch: 8 [9600/13906 (69%)]\tLoss: 0.114793\n",
      "Train Epoch: 8 [10240/13906 (73%)]\tLoss: 0.077132\n",
      "Train Epoch: 8 [10880/13906 (78%)]\tLoss: 0.127911\n",
      "Train Epoch: 8 [11520/13906 (83%)]\tLoss: 0.072189\n",
      "Train Epoch: 8 [12160/13906 (87%)]\tLoss: 0.072866\n",
      "Train Epoch: 8 [12800/13906 (92%)]\tLoss: 0.008238\n",
      "Train Epoch: 8 [13440/13906 (96%)]\tLoss: 0.071225\n",
      "Train Epoch: 9 [0/13906 (0%)]\tLoss: 0.105728\n",
      "Train Epoch: 9 [640/13906 (5%)]\tLoss: 0.148189\n",
      "Train Epoch: 9 [1280/13906 (9%)]\tLoss: 0.030192\n",
      "Train Epoch: 9 [1920/13906 (14%)]\tLoss: 0.172877\n",
      "Train Epoch: 9 [2560/13906 (18%)]\tLoss: 0.101603\n",
      "Train Epoch: 9 [3200/13906 (23%)]\tLoss: 0.057069\n",
      "Train Epoch: 9 [3840/13906 (28%)]\tLoss: 0.086978\n",
      "Train Epoch: 9 [4480/13906 (32%)]\tLoss: 0.042354\n",
      "Train Epoch: 9 [5120/13906 (37%)]\tLoss: 0.017797\n",
      "Train Epoch: 9 [5760/13906 (41%)]\tLoss: 0.070250\n",
      "Train Epoch: 9 [6400/13906 (46%)]\tLoss: 0.023275\n",
      "Train Epoch: 9 [7040/13906 (50%)]\tLoss: 0.107921\n",
      "Train Epoch: 9 [7680/13906 (55%)]\tLoss: 0.030798\n",
      "Train Epoch: 9 [8320/13906 (60%)]\tLoss: 0.009473\n",
      "Train Epoch: 9 [8960/13906 (64%)]\tLoss: 0.075018\n",
      "Train Epoch: 9 [9600/13906 (69%)]\tLoss: 0.038062\n",
      "Train Epoch: 9 [10240/13906 (73%)]\tLoss: 0.189762\n",
      "Train Epoch: 9 [10880/13906 (78%)]\tLoss: 0.053391\n",
      "Train Epoch: 9 [11520/13906 (83%)]\tLoss: 0.030679\n",
      "Train Epoch: 9 [12160/13906 (87%)]\tLoss: 0.081432\n",
      "Train Epoch: 9 [12800/13906 (92%)]\tLoss: 0.036434\n",
      "Train Epoch: 9 [13440/13906 (96%)]\tLoss: 0.090728\n",
      "Train Epoch: 10 [0/13906 (0%)]\tLoss: 0.092200\n",
      "Train Epoch: 10 [640/13906 (5%)]\tLoss: 0.019939\n",
      "Train Epoch: 10 [1280/13906 (9%)]\tLoss: 0.122884\n",
      "Train Epoch: 10 [1920/13906 (14%)]\tLoss: 0.065655\n",
      "Train Epoch: 10 [2560/13906 (18%)]\tLoss: 0.088757\n",
      "Train Epoch: 10 [3200/13906 (23%)]\tLoss: 0.049790\n",
      "Train Epoch: 10 [3840/13906 (28%)]\tLoss: 0.041113\n",
      "Train Epoch: 10 [4480/13906 (32%)]\tLoss: 0.078285\n",
      "Train Epoch: 10 [5120/13906 (37%)]\tLoss: 0.034099\n",
      "Train Epoch: 10 [5760/13906 (41%)]\tLoss: 0.058495\n",
      "Train Epoch: 10 [6400/13906 (46%)]\tLoss: 0.084179\n",
      "Train Epoch: 10 [7040/13906 (50%)]\tLoss: 0.038656\n",
      "Train Epoch: 10 [7680/13906 (55%)]\tLoss: 0.070311\n",
      "Train Epoch: 10 [8320/13906 (60%)]\tLoss: 0.013880\n",
      "Train Epoch: 10 [8960/13906 (64%)]\tLoss: 0.045385\n",
      "Train Epoch: 10 [9600/13906 (69%)]\tLoss: 0.011303\n",
      "Train Epoch: 10 [10240/13906 (73%)]\tLoss: 0.011123\n",
      "Train Epoch: 10 [10880/13906 (78%)]\tLoss: 0.052326\n",
      "Train Epoch: 10 [11520/13906 (83%)]\tLoss: 0.046106\n",
      "Train Epoch: 10 [12160/13906 (87%)]\tLoss: 0.544743\n",
      "Train Epoch: 10 [12800/13906 (92%)]\tLoss: 0.102735\n",
      "Train Epoch: 10 [13440/13906 (96%)]\tLoss: 0.077425\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/11862 (0%)]\tLoss: 0.136588\n",
      "Train Epoch: 1 [640/11862 (5%)]\tLoss: 0.180076\n",
      "Train Epoch: 1 [1280/11862 (11%)]\tLoss: 0.022160\n",
      "Train Epoch: 1 [1920/11862 (16%)]\tLoss: 0.101565\n",
      "Train Epoch: 1 [2560/11862 (22%)]\tLoss: 0.087282\n",
      "Train Epoch: 1 [3200/11862 (27%)]\tLoss: 0.053610\n",
      "Train Epoch: 1 [3840/11862 (32%)]\tLoss: 0.066841\n",
      "Train Epoch: 1 [4480/11862 (38%)]\tLoss: 0.068186\n",
      "Train Epoch: 1 [5120/11862 (43%)]\tLoss: 0.051282\n",
      "Train Epoch: 1 [5760/11862 (48%)]\tLoss: 0.007347\n",
      "Train Epoch: 1 [6400/11862 (54%)]\tLoss: 0.020810\n",
      "Train Epoch: 1 [7040/11862 (59%)]\tLoss: 0.070862\n",
      "Train Epoch: 1 [7680/11862 (65%)]\tLoss: 0.086759\n",
      "Train Epoch: 1 [8320/11862 (70%)]\tLoss: 0.047795\n",
      "Train Epoch: 1 [8960/11862 (75%)]\tLoss: 0.209803\n",
      "Train Epoch: 1 [9600/11862 (81%)]\tLoss: 0.006167\n",
      "Train Epoch: 1 [10240/11862 (86%)]\tLoss: 0.010833\n",
      "Train Epoch: 1 [10880/11862 (91%)]\tLoss: 0.013156\n",
      "Train Epoch: 1 [11520/11862 (97%)]\tLoss: 0.013112\n",
      "Train Epoch: 2 [0/11862 (0%)]\tLoss: 0.096809\n",
      "Train Epoch: 2 [640/11862 (5%)]\tLoss: 0.115561\n",
      "Train Epoch: 2 [1280/11862 (11%)]\tLoss: 0.073823\n",
      "Train Epoch: 2 [1920/11862 (16%)]\tLoss: 0.105430\n",
      "Train Epoch: 2 [2560/11862 (22%)]\tLoss: 0.108717\n",
      "Train Epoch: 2 [3200/11862 (27%)]\tLoss: 0.170511\n",
      "Train Epoch: 2 [3840/11862 (32%)]\tLoss: 0.055246\n",
      "Train Epoch: 2 [4480/11862 (38%)]\tLoss: 0.067525\n",
      "Train Epoch: 2 [5120/11862 (43%)]\tLoss: 0.020918\n",
      "Train Epoch: 2 [5760/11862 (48%)]\tLoss: 0.026732\n",
      "Train Epoch: 2 [6400/11862 (54%)]\tLoss: 0.027340\n",
      "Train Epoch: 2 [7040/11862 (59%)]\tLoss: 0.022815\n",
      "Train Epoch: 2 [7680/11862 (65%)]\tLoss: 0.005295\n",
      "Train Epoch: 2 [8320/11862 (70%)]\tLoss: 0.164474\n",
      "Train Epoch: 2 [8960/11862 (75%)]\tLoss: 0.012599\n",
      "Train Epoch: 2 [9600/11862 (81%)]\tLoss: 0.020794\n",
      "Train Epoch: 2 [10240/11862 (86%)]\tLoss: 0.084066\n",
      "Train Epoch: 2 [10880/11862 (91%)]\tLoss: 0.052710\n",
      "Train Epoch: 2 [11520/11862 (97%)]\tLoss: 0.110597\n",
      "Train Epoch: 3 [0/11862 (0%)]\tLoss: 0.115260\n",
      "Train Epoch: 3 [640/11862 (5%)]\tLoss: 0.015248\n",
      "Train Epoch: 3 [1280/11862 (11%)]\tLoss: 0.143850\n",
      "Train Epoch: 3 [1920/11862 (16%)]\tLoss: 0.085368\n",
      "Train Epoch: 3 [2560/11862 (22%)]\tLoss: 0.016466\n",
      "Train Epoch: 3 [3200/11862 (27%)]\tLoss: 0.076630\n",
      "Train Epoch: 3 [3840/11862 (32%)]\tLoss: 0.089240\n",
      "Train Epoch: 3 [4480/11862 (38%)]\tLoss: 0.045154\n",
      "Train Epoch: 3 [5120/11862 (43%)]\tLoss: 0.042661\n",
      "Train Epoch: 3 [5760/11862 (48%)]\tLoss: 0.227681\n",
      "Train Epoch: 3 [6400/11862 (54%)]\tLoss: 0.027972\n",
      "Train Epoch: 3 [7040/11862 (59%)]\tLoss: 0.078815\n",
      "Train Epoch: 3 [7680/11862 (65%)]\tLoss: 0.033740\n",
      "Train Epoch: 3 [8320/11862 (70%)]\tLoss: 0.156121\n",
      "Train Epoch: 3 [8960/11862 (75%)]\tLoss: 0.104153\n",
      "Train Epoch: 3 [9600/11862 (81%)]\tLoss: 0.025015\n",
      "Train Epoch: 3 [10240/11862 (86%)]\tLoss: 0.092230\n",
      "Train Epoch: 3 [10880/11862 (91%)]\tLoss: 0.017163\n",
      "Train Epoch: 3 [11520/11862 (97%)]\tLoss: 0.105605\n",
      "Train Epoch: 4 [0/11862 (0%)]\tLoss: 0.005746\n",
      "Train Epoch: 4 [640/11862 (5%)]\tLoss: 0.035166\n",
      "Train Epoch: 4 [1280/11862 (11%)]\tLoss: 0.060431\n",
      "Train Epoch: 4 [1920/11862 (16%)]\tLoss: 0.165418\n",
      "Train Epoch: 4 [2560/11862 (22%)]\tLoss: 0.099236\n",
      "Train Epoch: 4 [3200/11862 (27%)]\tLoss: 0.044752\n",
      "Train Epoch: 4 [3840/11862 (32%)]\tLoss: 0.064104\n",
      "Train Epoch: 4 [4480/11862 (38%)]\tLoss: 0.164325\n",
      "Train Epoch: 4 [5120/11862 (43%)]\tLoss: 0.099555\n",
      "Train Epoch: 4 [5760/11862 (48%)]\tLoss: 0.120622\n",
      "Train Epoch: 4 [6400/11862 (54%)]\tLoss: 0.146195\n",
      "Train Epoch: 4 [7040/11862 (59%)]\tLoss: 0.023826\n",
      "Train Epoch: 4 [7680/11862 (65%)]\tLoss: 0.071560\n",
      "Train Epoch: 4 [8320/11862 (70%)]\tLoss: 0.019199\n",
      "Train Epoch: 4 [8960/11862 (75%)]\tLoss: 0.090913\n",
      "Train Epoch: 4 [9600/11862 (81%)]\tLoss: 0.015483\n",
      "Train Epoch: 4 [10240/11862 (86%)]\tLoss: 0.083032\n",
      "Train Epoch: 4 [10880/11862 (91%)]\tLoss: 0.018692\n",
      "Train Epoch: 4 [11520/11862 (97%)]\tLoss: 0.110329\n",
      "Train Epoch: 5 [0/11862 (0%)]\tLoss: 0.024689\n",
      "Train Epoch: 5 [640/11862 (5%)]\tLoss: 0.054104\n",
      "Train Epoch: 5 [1280/11862 (11%)]\tLoss: 0.094961\n",
      "Train Epoch: 5 [1920/11862 (16%)]\tLoss: 0.161787\n",
      "Train Epoch: 5 [2560/11862 (22%)]\tLoss: 0.048114\n",
      "Train Epoch: 5 [3200/11862 (27%)]\tLoss: 0.068844\n",
      "Train Epoch: 5 [3840/11862 (32%)]\tLoss: 0.090772\n",
      "Train Epoch: 5 [4480/11862 (38%)]\tLoss: 0.031386\n",
      "Train Epoch: 5 [5120/11862 (43%)]\tLoss: 0.031421\n",
      "Train Epoch: 5 [5760/11862 (48%)]\tLoss: 0.102903\n",
      "Train Epoch: 5 [6400/11862 (54%)]\tLoss: 0.072513\n",
      "Train Epoch: 5 [7040/11862 (59%)]\tLoss: 0.018378\n",
      "Train Epoch: 5 [7680/11862 (65%)]\tLoss: 0.111257\n",
      "Train Epoch: 5 [8320/11862 (70%)]\tLoss: 0.068256\n",
      "Train Epoch: 5 [8960/11862 (75%)]\tLoss: 0.073044\n",
      "Train Epoch: 5 [9600/11862 (81%)]\tLoss: 0.010434\n",
      "Train Epoch: 5 [10240/11862 (86%)]\tLoss: 0.032162\n",
      "Train Epoch: 5 [10880/11862 (91%)]\tLoss: 0.020352\n",
      "Train Epoch: 5 [11520/11862 (97%)]\tLoss: 0.123495\n",
      "Train Epoch: 6 [0/11862 (0%)]\tLoss: 0.103526\n",
      "Train Epoch: 6 [640/11862 (5%)]\tLoss: 0.080233\n",
      "Train Epoch: 6 [1280/11862 (11%)]\tLoss: 0.150947\n",
      "Train Epoch: 6 [1920/11862 (16%)]\tLoss: 0.026393\n",
      "Train Epoch: 6 [2560/11862 (22%)]\tLoss: 0.031083\n",
      "Train Epoch: 6 [3200/11862 (27%)]\tLoss: 0.051164\n",
      "Train Epoch: 6 [3840/11862 (32%)]\tLoss: 0.037146\n",
      "Train Epoch: 6 [4480/11862 (38%)]\tLoss: 0.027347\n",
      "Train Epoch: 6 [5120/11862 (43%)]\tLoss: 0.085170\n",
      "Train Epoch: 6 [5760/11862 (48%)]\tLoss: 0.039341\n",
      "Train Epoch: 6 [6400/11862 (54%)]\tLoss: 0.092778\n",
      "Train Epoch: 6 [7040/11862 (59%)]\tLoss: 0.024828\n",
      "Train Epoch: 6 [7680/11862 (65%)]\tLoss: 0.013665\n",
      "Train Epoch: 6 [8320/11862 (70%)]\tLoss: 0.065151\n",
      "Train Epoch: 6 [8960/11862 (75%)]\tLoss: 0.067587\n",
      "Train Epoch: 6 [9600/11862 (81%)]\tLoss: 0.076356\n",
      "Train Epoch: 6 [10240/11862 (86%)]\tLoss: 0.061508\n",
      "Train Epoch: 6 [10880/11862 (91%)]\tLoss: 0.105373\n",
      "Train Epoch: 6 [11520/11862 (97%)]\tLoss: 0.022317\n",
      "Train Epoch: 7 [0/11862 (0%)]\tLoss: 0.050820\n",
      "Train Epoch: 7 [640/11862 (5%)]\tLoss: 0.053391\n",
      "Train Epoch: 7 [1280/11862 (11%)]\tLoss: 0.102803\n",
      "Train Epoch: 7 [1920/11862 (16%)]\tLoss: 0.047158\n",
      "Train Epoch: 7 [2560/11862 (22%)]\tLoss: 0.027197\n",
      "Train Epoch: 7 [3200/11862 (27%)]\tLoss: 0.018260\n",
      "Train Epoch: 7 [3840/11862 (32%)]\tLoss: 0.050502\n",
      "Train Epoch: 7 [4480/11862 (38%)]\tLoss: 0.045290\n",
      "Train Epoch: 7 [5120/11862 (43%)]\tLoss: 0.055816\n",
      "Train Epoch: 7 [5760/11862 (48%)]\tLoss: 0.037354\n",
      "Train Epoch: 7 [6400/11862 (54%)]\tLoss: 0.048497\n",
      "Train Epoch: 7 [7040/11862 (59%)]\tLoss: 0.134555\n",
      "Train Epoch: 7 [7680/11862 (65%)]\tLoss: 0.048907\n",
      "Train Epoch: 7 [8320/11862 (70%)]\tLoss: 0.042402\n",
      "Train Epoch: 7 [8960/11862 (75%)]\tLoss: 0.008227\n",
      "Train Epoch: 7 [9600/11862 (81%)]\tLoss: 0.012716\n",
      "Train Epoch: 7 [10240/11862 (86%)]\tLoss: 0.043699\n",
      "Train Epoch: 7 [10880/11862 (91%)]\tLoss: 0.001890\n",
      "Train Epoch: 7 [11520/11862 (97%)]\tLoss: 0.062403\n",
      "Train Epoch: 8 [0/11862 (0%)]\tLoss: 0.068290\n",
      "Train Epoch: 8 [640/11862 (5%)]\tLoss: 0.032301\n",
      "Train Epoch: 8 [1280/11862 (11%)]\tLoss: 0.039725\n",
      "Train Epoch: 8 [1920/11862 (16%)]\tLoss: 0.030581\n",
      "Train Epoch: 8 [2560/11862 (22%)]\tLoss: 0.041772\n",
      "Train Epoch: 8 [3200/11862 (27%)]\tLoss: 0.065820\n",
      "Train Epoch: 8 [3840/11862 (32%)]\tLoss: 0.031763\n",
      "Train Epoch: 8 [4480/11862 (38%)]\tLoss: 0.010644\n",
      "Train Epoch: 8 [5120/11862 (43%)]\tLoss: 0.058108\n",
      "Train Epoch: 8 [5760/11862 (48%)]\tLoss: 0.047229\n",
      "Train Epoch: 8 [6400/11862 (54%)]\tLoss: 0.021582\n",
      "Train Epoch: 8 [7040/11862 (59%)]\tLoss: 0.020794\n",
      "Train Epoch: 8 [7680/11862 (65%)]\tLoss: 0.046063\n",
      "Train Epoch: 8 [8320/11862 (70%)]\tLoss: 0.103364\n",
      "Train Epoch: 8 [8960/11862 (75%)]\tLoss: 0.135532\n",
      "Train Epoch: 8 [9600/11862 (81%)]\tLoss: 0.041423\n",
      "Train Epoch: 8 [10240/11862 (86%)]\tLoss: 0.035289\n",
      "Train Epoch: 8 [10880/11862 (91%)]\tLoss: 0.069912\n",
      "Train Epoch: 8 [11520/11862 (97%)]\tLoss: 0.008960\n",
      "Train Epoch: 9 [0/11862 (0%)]\tLoss: 0.010783\n",
      "Train Epoch: 9 [640/11862 (5%)]\tLoss: 0.011420\n",
      "Train Epoch: 9 [1280/11862 (11%)]\tLoss: 0.180770\n",
      "Train Epoch: 9 [1920/11862 (16%)]\tLoss: 0.056629\n",
      "Train Epoch: 9 [2560/11862 (22%)]\tLoss: 0.061366\n",
      "Train Epoch: 9 [3200/11862 (27%)]\tLoss: 0.066242\n",
      "Train Epoch: 9 [3840/11862 (32%)]\tLoss: 0.118549\n",
      "Train Epoch: 9 [4480/11862 (38%)]\tLoss: 0.088428\n",
      "Train Epoch: 9 [5120/11862 (43%)]\tLoss: 0.038395\n",
      "Train Epoch: 9 [5760/11862 (48%)]\tLoss: 0.016718\n",
      "Train Epoch: 9 [6400/11862 (54%)]\tLoss: 0.047663\n",
      "Train Epoch: 9 [7040/11862 (59%)]\tLoss: 0.010093\n",
      "Train Epoch: 9 [7680/11862 (65%)]\tLoss: 0.077816\n",
      "Train Epoch: 9 [8320/11862 (70%)]\tLoss: 0.111505\n",
      "Train Epoch: 9 [8960/11862 (75%)]\tLoss: 0.094277\n",
      "Train Epoch: 9 [9600/11862 (81%)]\tLoss: 0.014214\n",
      "Train Epoch: 9 [10240/11862 (86%)]\tLoss: 0.067700\n",
      "Train Epoch: 9 [10880/11862 (91%)]\tLoss: 0.158798\n",
      "Train Epoch: 9 [11520/11862 (97%)]\tLoss: 0.167239\n",
      "Train Epoch: 10 [0/11862 (0%)]\tLoss: 0.029167\n",
      "Train Epoch: 10 [640/11862 (5%)]\tLoss: 0.060006\n",
      "Train Epoch: 10 [1280/11862 (11%)]\tLoss: 0.070252\n",
      "Train Epoch: 10 [1920/11862 (16%)]\tLoss: 0.022201\n",
      "Train Epoch: 10 [2560/11862 (22%)]\tLoss: 0.137342\n",
      "Train Epoch: 10 [3200/11862 (27%)]\tLoss: 0.064260\n",
      "Train Epoch: 10 [3840/11862 (32%)]\tLoss: 0.066883\n",
      "Train Epoch: 10 [4480/11862 (38%)]\tLoss: 0.010340\n",
      "Train Epoch: 10 [5120/11862 (43%)]\tLoss: 0.020781\n",
      "Train Epoch: 10 [5760/11862 (48%)]\tLoss: 0.043641\n",
      "Train Epoch: 10 [6400/11862 (54%)]\tLoss: 0.071924\n",
      "Train Epoch: 10 [7040/11862 (59%)]\tLoss: 0.060154\n",
      "Train Epoch: 10 [7680/11862 (65%)]\tLoss: 0.037991\n",
      "Train Epoch: 10 [8320/11862 (70%)]\tLoss: 0.062532\n",
      "Train Epoch: 10 [8960/11862 (75%)]\tLoss: 0.018890\n",
      "Train Epoch: 10 [9600/11862 (81%)]\tLoss: 0.088516\n",
      "Train Epoch: 10 [10240/11862 (86%)]\tLoss: 0.039962\n",
      "Train Epoch: 10 [10880/11862 (91%)]\tLoss: 0.034816\n",
      "Train Epoch: 10 [11520/11862 (97%)]\tLoss: 0.035361\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 0.053309\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 0.042492\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 0.087563\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 0.150068\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 0.098605\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 0.143492\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 0.043968\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 0.035749\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 0.014719\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 0.048131\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 0.105633\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 0.111974\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 0.051398\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 0.059657\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 0.033068\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 0.018525\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 0.115288\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.014649\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.009382\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.230711\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.066805\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.018961\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.073294\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.029677\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.121218\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.051452\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.035293\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.047823\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.088782\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.034018\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.096396\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.014067\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.071666\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.031042\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.084150\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.029009\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.015367\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.010709\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.019263\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.013179\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.125914\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.001809\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.037298\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.038944\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.132007\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.183980\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.044226\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.084473\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.029533\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.054541\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.025936\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.105096\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.133114\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.020377\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.031205\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.025055\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.039998\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.028275\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.141804\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.039079\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.093569\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.009025\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.073134\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.033296\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.033026\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.043774\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.017047\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.047428\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.101457\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.089479\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.029182\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.027293\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.062279\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.040611\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.043807\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.041133\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.082365\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.102125\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.011628\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.029885\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.027190\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.019435\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.104121\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.070283\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.039870\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.047210\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.044278\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.046991\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.059850\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.116270\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.013156\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.009774\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.022751\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.061667\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.010085\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.075602\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.088831\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.084281\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.058056\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.103857\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.070469\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.100603\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.065423\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.040878\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.045034\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.008542\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.036486\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.007135\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.026986\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.142524\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.082177\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.038303\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.046529\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.064704\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.209525\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.014262\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.039938\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.014859\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.027086\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.064569\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.059754\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.030285\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.044473\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.023626\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.061774\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.068390\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.007277\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.005392\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.030308\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.014651\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.016217\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.035702\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.130407\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.044279\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.010136\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.059215\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.037571\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.038188\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.025556\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.008962\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.044606\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.025605\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.097334\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.042695\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.055639\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.013983\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.053324\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.065658\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.016763\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.036356\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.022067\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.017585\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.043640\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.032484\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.006728\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.139036\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.079205\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.044186\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.069886\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.034048\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5509 (0%)]\tLoss: 0.110988\n",
      "Train Epoch: 1 [640/5509 (11%)]\tLoss: 0.064819\n",
      "Train Epoch: 1 [1280/5509 (23%)]\tLoss: 0.147939\n",
      "Train Epoch: 1 [1920/5509 (34%)]\tLoss: 0.078132\n",
      "Train Epoch: 1 [2560/5509 (46%)]\tLoss: 0.059588\n",
      "Train Epoch: 1 [3200/5509 (57%)]\tLoss: 0.078999\n",
      "Train Epoch: 1 [3840/5509 (69%)]\tLoss: 0.126275\n",
      "Train Epoch: 1 [4480/5509 (80%)]\tLoss: 0.079823\n",
      "Train Epoch: 1 [5120/5509 (92%)]\tLoss: 0.073527\n",
      "Train Epoch: 2 [0/5509 (0%)]\tLoss: 0.087153\n",
      "Train Epoch: 2 [640/5509 (11%)]\tLoss: 0.088050\n",
      "Train Epoch: 2 [1280/5509 (23%)]\tLoss: 0.016059\n",
      "Train Epoch: 2 [1920/5509 (34%)]\tLoss: 0.023407\n",
      "Train Epoch: 2 [2560/5509 (46%)]\tLoss: 0.063898\n",
      "Train Epoch: 2 [3200/5509 (57%)]\tLoss: 0.024406\n",
      "Train Epoch: 2 [3840/5509 (69%)]\tLoss: 0.052244\n",
      "Train Epoch: 2 [4480/5509 (80%)]\tLoss: 0.071620\n",
      "Train Epoch: 2 [5120/5509 (92%)]\tLoss: 0.091966\n",
      "Train Epoch: 3 [0/5509 (0%)]\tLoss: 0.047248\n",
      "Train Epoch: 3 [640/5509 (11%)]\tLoss: 0.120297\n",
      "Train Epoch: 3 [1280/5509 (23%)]\tLoss: 0.098842\n",
      "Train Epoch: 3 [1920/5509 (34%)]\tLoss: 0.096911\n",
      "Train Epoch: 3 [2560/5509 (46%)]\tLoss: 0.092851\n",
      "Train Epoch: 3 [3200/5509 (57%)]\tLoss: 0.049863\n",
      "Train Epoch: 3 [3840/5509 (69%)]\tLoss: 0.055924\n",
      "Train Epoch: 3 [4480/5509 (80%)]\tLoss: 0.037963\n",
      "Train Epoch: 3 [5120/5509 (92%)]\tLoss: 0.067771\n",
      "Train Epoch: 4 [0/5509 (0%)]\tLoss: 0.015958\n",
      "Train Epoch: 4 [640/5509 (11%)]\tLoss: 0.067308\n",
      "Train Epoch: 4 [1280/5509 (23%)]\tLoss: 0.036404\n",
      "Train Epoch: 4 [1920/5509 (34%)]\tLoss: 0.009047\n",
      "Train Epoch: 4 [2560/5509 (46%)]\tLoss: 0.118102\n",
      "Train Epoch: 4 [3200/5509 (57%)]\tLoss: 0.078607\n",
      "Train Epoch: 4 [3840/5509 (69%)]\tLoss: 0.013381\n",
      "Train Epoch: 4 [4480/5509 (80%)]\tLoss: 0.073210\n",
      "Train Epoch: 4 [5120/5509 (92%)]\tLoss: 0.033208\n",
      "Train Epoch: 5 [0/5509 (0%)]\tLoss: 0.045825\n",
      "Train Epoch: 5 [640/5509 (11%)]\tLoss: 0.142699\n",
      "Train Epoch: 5 [1280/5509 (23%)]\tLoss: 0.003377\n",
      "Train Epoch: 5 [1920/5509 (34%)]\tLoss: 0.097535\n",
      "Train Epoch: 5 [2560/5509 (46%)]\tLoss: 0.118956\n",
      "Train Epoch: 5 [3200/5509 (57%)]\tLoss: 0.105402\n",
      "Train Epoch: 5 [3840/5509 (69%)]\tLoss: 0.015403\n",
      "Train Epoch: 5 [4480/5509 (80%)]\tLoss: 0.050253\n",
      "Train Epoch: 5 [5120/5509 (92%)]\tLoss: 0.058374\n",
      "Train Epoch: 6 [0/5509 (0%)]\tLoss: 0.017680\n",
      "Train Epoch: 6 [640/5509 (11%)]\tLoss: 0.095939\n",
      "Train Epoch: 6 [1280/5509 (23%)]\tLoss: 0.036603\n",
      "Train Epoch: 6 [1920/5509 (34%)]\tLoss: 0.026457\n",
      "Train Epoch: 6 [2560/5509 (46%)]\tLoss: 0.067977\n",
      "Train Epoch: 6 [3200/5509 (57%)]\tLoss: 0.062651\n",
      "Train Epoch: 6 [3840/5509 (69%)]\tLoss: 0.055824\n",
      "Train Epoch: 6 [4480/5509 (80%)]\tLoss: 0.039748\n",
      "Train Epoch: 6 [5120/5509 (92%)]\tLoss: 0.053863\n",
      "Train Epoch: 7 [0/5509 (0%)]\tLoss: 0.020640\n",
      "Train Epoch: 7 [640/5509 (11%)]\tLoss: 0.088124\n",
      "Train Epoch: 7 [1280/5509 (23%)]\tLoss: 0.083255\n",
      "Train Epoch: 7 [1920/5509 (34%)]\tLoss: 0.197042\n",
      "Train Epoch: 7 [2560/5509 (46%)]\tLoss: 0.093108\n",
      "Train Epoch: 7 [3200/5509 (57%)]\tLoss: 0.054058\n",
      "Train Epoch: 7 [3840/5509 (69%)]\tLoss: 0.051072\n",
      "Train Epoch: 7 [4480/5509 (80%)]\tLoss: 0.062101\n",
      "Train Epoch: 7 [5120/5509 (92%)]\tLoss: 0.062721\n",
      "Train Epoch: 8 [0/5509 (0%)]\tLoss: 0.111522\n",
      "Train Epoch: 8 [640/5509 (11%)]\tLoss: 0.077169\n",
      "Train Epoch: 8 [1280/5509 (23%)]\tLoss: 0.030478\n",
      "Train Epoch: 8 [1920/5509 (34%)]\tLoss: 0.063291\n",
      "Train Epoch: 8 [2560/5509 (46%)]\tLoss: 0.009019\n",
      "Train Epoch: 8 [3200/5509 (57%)]\tLoss: 0.210886\n",
      "Train Epoch: 8 [3840/5509 (69%)]\tLoss: 0.123993\n",
      "Train Epoch: 8 [4480/5509 (80%)]\tLoss: 0.196962\n",
      "Train Epoch: 8 [5120/5509 (92%)]\tLoss: 0.114278\n",
      "Train Epoch: 9 [0/5509 (0%)]\tLoss: 0.052255\n",
      "Train Epoch: 9 [640/5509 (11%)]\tLoss: 0.109415\n",
      "Train Epoch: 9 [1280/5509 (23%)]\tLoss: 0.037137\n",
      "Train Epoch: 9 [1920/5509 (34%)]\tLoss: 0.103166\n",
      "Train Epoch: 9 [2560/5509 (46%)]\tLoss: 0.048335\n",
      "Train Epoch: 9 [3200/5509 (57%)]\tLoss: 0.055968\n",
      "Train Epoch: 9 [3840/5509 (69%)]\tLoss: 0.092883\n",
      "Train Epoch: 9 [4480/5509 (80%)]\tLoss: 0.046370\n",
      "Train Epoch: 9 [5120/5509 (92%)]\tLoss: 0.044904\n",
      "Train Epoch: 10 [0/5509 (0%)]\tLoss: 0.060416\n",
      "Train Epoch: 10 [640/5509 (11%)]\tLoss: 0.095911\n",
      "Train Epoch: 10 [1280/5509 (23%)]\tLoss: 0.056187\n",
      "Train Epoch: 10 [1920/5509 (34%)]\tLoss: 0.053705\n",
      "Train Epoch: 10 [2560/5509 (46%)]\tLoss: 0.012389\n",
      "Train Epoch: 10 [3200/5509 (57%)]\tLoss: 0.010919\n",
      "Train Epoch: 10 [3840/5509 (69%)]\tLoss: 0.033310\n",
      "Train Epoch: 10 [4480/5509 (80%)]\tLoss: 0.160131\n",
      "Train Epoch: 10 [5120/5509 (92%)]\tLoss: 0.029707\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 0.142648\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 0.077625\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 0.081013\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 0.031591\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 0.022430\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 0.075812\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 0.028195\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 0.123688\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 0.006622\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 0.079962\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.040739\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.017315\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 0.066894\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 0.030726\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 0.032143\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.070211\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.045312\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.014368\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.071899\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.143891\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.023504\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.036792\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.020590\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.009423\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.035738\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.016955\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.010314\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.089896\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.057741\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.036814\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.015263\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.042951\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.020564\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.111623\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.025685\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.018289\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.040148\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.029221\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.043866\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.079651\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.033575\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.045800\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.068322\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.060281\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.047875\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.033109\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.039495\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.020944\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.113950\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.060038\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.035525\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.024080\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.037533\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.018237\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.008646\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.028233\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.030820\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.033192\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.050194\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.041065\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.021995\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.060336\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.057413\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.044474\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.050941\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.012695\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.044454\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.031417\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.051195\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.037354\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.188216\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.029933\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.028378\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.065817\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.004757\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.048745\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.007382\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.055291\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.012388\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.038081\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.056122\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.128997\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.021518\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.016472\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.092871\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.009630\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.034523\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.012763\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.013385\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.026553\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.108116\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.053690\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.008054\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.014616\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.020449\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.037323\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.009373\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.026591\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.078777\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.025227\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.178296\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.102980\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.034942\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.007592\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.014521\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.013011\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.021511\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.121923\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.015403\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.019797\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.021340\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.030119\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.072522\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.009538\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.147333\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.020380\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.091523\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.056428\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.061726\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.002532\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0488, Accuracy: 9835/10000 (98%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 0.101219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 0.028153\n",
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 0.094085\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 0.029394\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 0.024223\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 0.018119\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 0.060637\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 0.266606\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 0.061310\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 0.033314\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 0.068547\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 0.127617\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 0.067547\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 0.050878\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 0.070583\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 0.029494\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 0.215069\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 0.083442\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 0.083135\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 0.099604\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.040353\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 0.152244\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 0.016852\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.082653\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.037090\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 0.056191\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.103990\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 0.059979\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.029099\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.119748\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.031992\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.019734\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.111915\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.056366\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.215950\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.034002\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.036296\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.045142\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.147940\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.088172\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.010919\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.107170\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.007642\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.079435\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.019072\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.019314\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.085967\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.155207\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.014595\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.011326\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.070226\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.045148\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.040415\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.046823\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.083668\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.014446\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.124046\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.077898\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.181489\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.012439\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.131093\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.065084\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.037769\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.088009\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.017708\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.153767\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.139085\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.085793\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.076302\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.095552\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.046984\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.016269\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.030339\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.015268\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.330914\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.134866\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.082966\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.010015\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.054311\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.014834\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.038977\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.009810\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.070587\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.075014\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.079924\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.074490\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.018576\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.234958\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.051864\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.022822\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.039869\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.022250\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.029585\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.039952\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.029967\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.044971\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.055510\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.017067\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.015740\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.042729\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.027519\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.076489\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.056249\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.143585\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.036135\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.092554\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.078949\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.064126\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 0.007084\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.020997\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.039967\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.015716\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.072373\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.105222\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.048494\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.059932\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.028690\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.080703\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.171967\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.046452\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.062629\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.113161\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.035664\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.056245\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.054772\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.054848\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.138183\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.023474\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.006641\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.044508\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.058747\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.100815\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.010328\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.029466\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.010123\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.031882\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.019974\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.017739\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.191873\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.053806\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.084682\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.073224\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.054960\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.113834\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.056493\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.054539\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.056025\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.186137\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.030084\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.048143\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.086063\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.009468\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.015742\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.034440\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.035452\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.032409\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.071274\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.003544\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.020523\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.144664\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.032813\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.126583\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.042283\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.096724\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.033248\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.074154\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.132512\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.029187\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.026885\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.173792\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.050562\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.103945\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.056775\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.036870\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.125533\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.138315\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.004740\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.013605\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.073340\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.086685\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/5110 (0%)]\tLoss: 0.010150\n",
      "Train Epoch: 1 [640/5110 (12%)]\tLoss: 0.093611\n",
      "Train Epoch: 1 [1280/5110 (25%)]\tLoss: 0.114636\n",
      "Train Epoch: 1 [1920/5110 (38%)]\tLoss: 0.025741\n",
      "Train Epoch: 1 [2560/5110 (50%)]\tLoss: 0.039810\n",
      "Train Epoch: 1 [3200/5110 (62%)]\tLoss: 0.037365\n",
      "Train Epoch: 1 [3840/5110 (75%)]\tLoss: 0.033132\n",
      "Train Epoch: 1 [4480/5110 (88%)]\tLoss: 0.174371\n",
      "Train Epoch: 2 [0/5110 (0%)]\tLoss: 0.092361\n",
      "Train Epoch: 2 [640/5110 (12%)]\tLoss: 0.090010\n",
      "Train Epoch: 2 [1280/5110 (25%)]\tLoss: 0.019149\n",
      "Train Epoch: 2 [1920/5110 (38%)]\tLoss: 0.098906\n",
      "Train Epoch: 2 [2560/5110 (50%)]\tLoss: 0.021750\n",
      "Train Epoch: 2 [3200/5110 (62%)]\tLoss: 0.070793\n",
      "Train Epoch: 2 [3840/5110 (75%)]\tLoss: 0.054438\n",
      "Train Epoch: 2 [4480/5110 (88%)]\tLoss: 0.049476\n",
      "Train Epoch: 3 [0/5110 (0%)]\tLoss: 0.010800\n",
      "Train Epoch: 3 [640/5110 (12%)]\tLoss: 0.139771\n",
      "Train Epoch: 3 [1280/5110 (25%)]\tLoss: 0.023052\n",
      "Train Epoch: 3 [1920/5110 (38%)]\tLoss: 0.124800\n",
      "Train Epoch: 3 [2560/5110 (50%)]\tLoss: 0.036060\n",
      "Train Epoch: 3 [3200/5110 (62%)]\tLoss: 0.045703\n",
      "Train Epoch: 3 [3840/5110 (75%)]\tLoss: 0.005762\n",
      "Train Epoch: 3 [4480/5110 (88%)]\tLoss: 0.027335\n",
      "Train Epoch: 4 [0/5110 (0%)]\tLoss: 0.038944\n",
      "Train Epoch: 4 [640/5110 (12%)]\tLoss: 0.026776\n",
      "Train Epoch: 4 [1280/5110 (25%)]\tLoss: 0.045492\n",
      "Train Epoch: 4 [1920/5110 (38%)]\tLoss: 0.036775\n",
      "Train Epoch: 4 [2560/5110 (50%)]\tLoss: 0.066954\n",
      "Train Epoch: 4 [3200/5110 (62%)]\tLoss: 0.090800\n",
      "Train Epoch: 4 [3840/5110 (75%)]\tLoss: 0.077184\n",
      "Train Epoch: 4 [4480/5110 (88%)]\tLoss: 0.005706\n",
      "Train Epoch: 5 [0/5110 (0%)]\tLoss: 0.068986\n",
      "Train Epoch: 5 [640/5110 (12%)]\tLoss: 0.013026\n",
      "Train Epoch: 5 [1280/5110 (25%)]\tLoss: 0.216040\n",
      "Train Epoch: 5 [1920/5110 (38%)]\tLoss: 0.052735\n",
      "Train Epoch: 5 [2560/5110 (50%)]\tLoss: 0.045508\n",
      "Train Epoch: 5 [3200/5110 (62%)]\tLoss: 0.034003\n",
      "Train Epoch: 5 [3840/5110 (75%)]\tLoss: 0.012177\n",
      "Train Epoch: 5 [4480/5110 (88%)]\tLoss: 0.118551\n",
      "Train Epoch: 6 [0/5110 (0%)]\tLoss: 0.038204\n",
      "Train Epoch: 6 [640/5110 (12%)]\tLoss: 0.084225\n",
      "Train Epoch: 6 [1280/5110 (25%)]\tLoss: 0.017456\n",
      "Train Epoch: 6 [1920/5110 (38%)]\tLoss: 0.014805\n",
      "Train Epoch: 6 [2560/5110 (50%)]\tLoss: 0.127906\n",
      "Train Epoch: 6 [3200/5110 (62%)]\tLoss: 0.023378\n",
      "Train Epoch: 6 [3840/5110 (75%)]\tLoss: 0.018864\n",
      "Train Epoch: 6 [4480/5110 (88%)]\tLoss: 0.034423\n",
      "Train Epoch: 7 [0/5110 (0%)]\tLoss: 0.011000\n",
      "Train Epoch: 7 [640/5110 (12%)]\tLoss: 0.006329\n",
      "Train Epoch: 7 [1280/5110 (25%)]\tLoss: 0.030600\n",
      "Train Epoch: 7 [1920/5110 (38%)]\tLoss: 0.053159\n",
      "Train Epoch: 7 [2560/5110 (50%)]\tLoss: 0.160420\n",
      "Train Epoch: 7 [3200/5110 (62%)]\tLoss: 0.022038\n",
      "Train Epoch: 7 [3840/5110 (75%)]\tLoss: 0.041100\n",
      "Train Epoch: 7 [4480/5110 (88%)]\tLoss: 0.024946\n",
      "Train Epoch: 8 [0/5110 (0%)]\tLoss: 0.049113\n",
      "Train Epoch: 8 [640/5110 (12%)]\tLoss: 0.074854\n",
      "Train Epoch: 8 [1280/5110 (25%)]\tLoss: 0.033197\n",
      "Train Epoch: 8 [1920/5110 (38%)]\tLoss: 0.005426\n",
      "Train Epoch: 8 [2560/5110 (50%)]\tLoss: 0.076015\n",
      "Train Epoch: 8 [3200/5110 (62%)]\tLoss: 0.061822\n",
      "Train Epoch: 8 [3840/5110 (75%)]\tLoss: 0.028361\n",
      "Train Epoch: 8 [4480/5110 (88%)]\tLoss: 0.059755\n",
      "Train Epoch: 9 [0/5110 (0%)]\tLoss: 0.032070\n",
      "Train Epoch: 9 [640/5110 (12%)]\tLoss: 0.023912\n",
      "Train Epoch: 9 [1280/5110 (25%)]\tLoss: 0.025223\n",
      "Train Epoch: 9 [1920/5110 (38%)]\tLoss: 0.162101\n",
      "Train Epoch: 9 [2560/5110 (50%)]\tLoss: 0.079780\n",
      "Train Epoch: 9 [3200/5110 (62%)]\tLoss: 0.083202\n",
      "Train Epoch: 9 [3840/5110 (75%)]\tLoss: 0.013758\n",
      "Train Epoch: 9 [4480/5110 (88%)]\tLoss: 0.030407\n",
      "Train Epoch: 10 [0/5110 (0%)]\tLoss: 0.053759\n",
      "Train Epoch: 10 [640/5110 (12%)]\tLoss: 0.039506\n",
      "Train Epoch: 10 [1280/5110 (25%)]\tLoss: 0.014792\n",
      "Train Epoch: 10 [1920/5110 (38%)]\tLoss: 0.021364\n",
      "Train Epoch: 10 [2560/5110 (50%)]\tLoss: 0.003906\n",
      "Train Epoch: 10 [3200/5110 (62%)]\tLoss: 0.041987\n",
      "Train Epoch: 10 [3840/5110 (75%)]\tLoss: 0.051716\n",
      "Train Epoch: 10 [4480/5110 (88%)]\tLoss: 0.089092\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/10296 (0%)]\tLoss: 0.085360\n",
      "Train Epoch: 1 [640/10296 (6%)]\tLoss: 0.162570\n",
      "Train Epoch: 1 [1280/10296 (12%)]\tLoss: 0.111064\n",
      "Train Epoch: 1 [1920/10296 (19%)]\tLoss: 0.051110\n",
      "Train Epoch: 1 [2560/10296 (25%)]\tLoss: 0.068508\n",
      "Train Epoch: 1 [3200/10296 (31%)]\tLoss: 0.123216\n",
      "Train Epoch: 1 [3840/10296 (37%)]\tLoss: 0.121704\n",
      "Train Epoch: 1 [4480/10296 (43%)]\tLoss: 0.065888\n",
      "Train Epoch: 1 [5120/10296 (50%)]\tLoss: 0.056432\n",
      "Train Epoch: 1 [5760/10296 (56%)]\tLoss: 0.080192\n",
      "Train Epoch: 1 [6400/10296 (62%)]\tLoss: 0.030595\n",
      "Train Epoch: 1 [7040/10296 (68%)]\tLoss: 0.072384\n",
      "Train Epoch: 1 [7680/10296 (75%)]\tLoss: 0.099675\n",
      "Train Epoch: 1 [8320/10296 (81%)]\tLoss: 0.060333\n",
      "Train Epoch: 1 [8960/10296 (87%)]\tLoss: 0.017713\n",
      "Train Epoch: 1 [9600/10296 (93%)]\tLoss: 0.171582\n",
      "Train Epoch: 1 [8960/10296 (99%)]\tLoss: 0.024825\n",
      "Train Epoch: 2 [0/10296 (0%)]\tLoss: 0.109901\n",
      "Train Epoch: 2 [640/10296 (6%)]\tLoss: 0.123170\n",
      "Train Epoch: 2 [1280/10296 (12%)]\tLoss: 0.257041\n",
      "Train Epoch: 2 [1920/10296 (19%)]\tLoss: 0.110218\n",
      "Train Epoch: 2 [2560/10296 (25%)]\tLoss: 0.129144\n",
      "Train Epoch: 2 [3200/10296 (31%)]\tLoss: 0.220098\n",
      "Train Epoch: 2 [3840/10296 (37%)]\tLoss: 0.111250\n",
      "Train Epoch: 2 [4480/10296 (43%)]\tLoss: 0.047456\n",
      "Train Epoch: 2 [5120/10296 (50%)]\tLoss: 0.090486\n",
      "Train Epoch: 2 [5760/10296 (56%)]\tLoss: 0.031943\n",
      "Train Epoch: 2 [6400/10296 (62%)]\tLoss: 0.023494\n",
      "Train Epoch: 2 [7040/10296 (68%)]\tLoss: 0.181261\n",
      "Train Epoch: 2 [7680/10296 (75%)]\tLoss: 0.080333\n",
      "Train Epoch: 2 [8320/10296 (81%)]\tLoss: 0.011389\n",
      "Train Epoch: 2 [8960/10296 (87%)]\tLoss: 0.015989\n",
      "Train Epoch: 2 [9600/10296 (93%)]\tLoss: 0.020228\n",
      "Train Epoch: 2 [8960/10296 (99%)]\tLoss: 0.040489\n",
      "Train Epoch: 3 [0/10296 (0%)]\tLoss: 0.055561\n",
      "Train Epoch: 3 [640/10296 (6%)]\tLoss: 0.080034\n",
      "Train Epoch: 3 [1280/10296 (12%)]\tLoss: 0.029969\n",
      "Train Epoch: 3 [1920/10296 (19%)]\tLoss: 0.040394\n",
      "Train Epoch: 3 [2560/10296 (25%)]\tLoss: 0.031032\n",
      "Train Epoch: 3 [3200/10296 (31%)]\tLoss: 0.070095\n",
      "Train Epoch: 3 [3840/10296 (37%)]\tLoss: 0.028847\n",
      "Train Epoch: 3 [4480/10296 (43%)]\tLoss: 0.180424\n",
      "Train Epoch: 3 [5120/10296 (50%)]\tLoss: 0.036062\n",
      "Train Epoch: 3 [5760/10296 (56%)]\tLoss: 0.049342\n",
      "Train Epoch: 3 [6400/10296 (62%)]\tLoss: 0.045607\n",
      "Train Epoch: 3 [7040/10296 (68%)]\tLoss: 0.055241\n",
      "Train Epoch: 3 [7680/10296 (75%)]\tLoss: 0.021623\n",
      "Train Epoch: 3 [8320/10296 (81%)]\tLoss: 0.080100\n",
      "Train Epoch: 3 [8960/10296 (87%)]\tLoss: 0.050691\n",
      "Train Epoch: 3 [9600/10296 (93%)]\tLoss: 0.025235\n",
      "Train Epoch: 3 [8960/10296 (99%)]\tLoss: 0.205247\n",
      "Train Epoch: 4 [0/10296 (0%)]\tLoss: 0.145254\n",
      "Train Epoch: 4 [640/10296 (6%)]\tLoss: 0.145251\n",
      "Train Epoch: 4 [1280/10296 (12%)]\tLoss: 0.194440\n",
      "Train Epoch: 4 [1920/10296 (19%)]\tLoss: 0.066005\n",
      "Train Epoch: 4 [2560/10296 (25%)]\tLoss: 0.069314\n",
      "Train Epoch: 4 [3200/10296 (31%)]\tLoss: 0.016866\n",
      "Train Epoch: 4 [3840/10296 (37%)]\tLoss: 0.050342\n",
      "Train Epoch: 4 [4480/10296 (43%)]\tLoss: 0.031915\n",
      "Train Epoch: 4 [5120/10296 (50%)]\tLoss: 0.063016\n",
      "Train Epoch: 4 [5760/10296 (56%)]\tLoss: 0.135173\n",
      "Train Epoch: 4 [6400/10296 (62%)]\tLoss: 0.063270\n",
      "Train Epoch: 4 [7040/10296 (68%)]\tLoss: 0.036825\n",
      "Train Epoch: 4 [7680/10296 (75%)]\tLoss: 0.133123\n",
      "Train Epoch: 4 [8320/10296 (81%)]\tLoss: 0.086058\n",
      "Train Epoch: 4 [8960/10296 (87%)]\tLoss: 0.044685\n",
      "Train Epoch: 4 [9600/10296 (93%)]\tLoss: 0.077942\n",
      "Train Epoch: 4 [8960/10296 (99%)]\tLoss: 0.103346\n",
      "Train Epoch: 5 [0/10296 (0%)]\tLoss: 0.067034\n",
      "Train Epoch: 5 [640/10296 (6%)]\tLoss: 0.080996\n",
      "Train Epoch: 5 [1280/10296 (12%)]\tLoss: 0.007294\n",
      "Train Epoch: 5 [1920/10296 (19%)]\tLoss: 0.126620\n",
      "Train Epoch: 5 [2560/10296 (25%)]\tLoss: 0.083517\n",
      "Train Epoch: 5 [3200/10296 (31%)]\tLoss: 0.022271\n",
      "Train Epoch: 5 [3840/10296 (37%)]\tLoss: 0.032778\n",
      "Train Epoch: 5 [4480/10296 (43%)]\tLoss: 0.108147\n",
      "Train Epoch: 5 [5120/10296 (50%)]\tLoss: 0.113701\n",
      "Train Epoch: 5 [5760/10296 (56%)]\tLoss: 0.012648\n",
      "Train Epoch: 5 [6400/10296 (62%)]\tLoss: 0.035497\n",
      "Train Epoch: 5 [7040/10296 (68%)]\tLoss: 0.020240\n",
      "Train Epoch: 5 [7680/10296 (75%)]\tLoss: 0.254100\n",
      "Train Epoch: 5 [8320/10296 (81%)]\tLoss: 0.111736\n",
      "Train Epoch: 5 [8960/10296 (87%)]\tLoss: 0.158470\n",
      "Train Epoch: 5 [9600/10296 (93%)]\tLoss: 0.103167\n",
      "Train Epoch: 5 [8960/10296 (99%)]\tLoss: 0.078326\n",
      "Train Epoch: 6 [0/10296 (0%)]\tLoss: 0.118971\n",
      "Train Epoch: 6 [640/10296 (6%)]\tLoss: 0.036523\n",
      "Train Epoch: 6 [1280/10296 (12%)]\tLoss: 0.159616\n",
      "Train Epoch: 6 [1920/10296 (19%)]\tLoss: 0.056495\n",
      "Train Epoch: 6 [2560/10296 (25%)]\tLoss: 0.056328\n",
      "Train Epoch: 6 [3200/10296 (31%)]\tLoss: 0.055113\n",
      "Train Epoch: 6 [3840/10296 (37%)]\tLoss: 0.017536\n",
      "Train Epoch: 6 [4480/10296 (43%)]\tLoss: 0.100009\n",
      "Train Epoch: 6 [5120/10296 (50%)]\tLoss: 0.239551\n",
      "Train Epoch: 6 [5760/10296 (56%)]\tLoss: 0.076638\n",
      "Train Epoch: 6 [6400/10296 (62%)]\tLoss: 0.077053\n",
      "Train Epoch: 6 [7040/10296 (68%)]\tLoss: 0.029596\n",
      "Train Epoch: 6 [7680/10296 (75%)]\tLoss: 0.025899\n",
      "Train Epoch: 6 [8320/10296 (81%)]\tLoss: 0.165053\n",
      "Train Epoch: 6 [8960/10296 (87%)]\tLoss: 0.115111\n",
      "Train Epoch: 6 [9600/10296 (93%)]\tLoss: 0.070335\n",
      "Train Epoch: 6 [8960/10296 (99%)]\tLoss: 0.031935\n",
      "Train Epoch: 7 [0/10296 (0%)]\tLoss: 0.025041\n",
      "Train Epoch: 7 [640/10296 (6%)]\tLoss: 0.056399\n",
      "Train Epoch: 7 [1280/10296 (12%)]\tLoss: 0.034555\n",
      "Train Epoch: 7 [1920/10296 (19%)]\tLoss: 0.129989\n",
      "Train Epoch: 7 [2560/10296 (25%)]\tLoss: 0.070609\n",
      "Train Epoch: 7 [3200/10296 (31%)]\tLoss: 0.094065\n",
      "Train Epoch: 7 [3840/10296 (37%)]\tLoss: 0.031576\n",
      "Train Epoch: 7 [4480/10296 (43%)]\tLoss: 0.026522\n",
      "Train Epoch: 7 [5120/10296 (50%)]\tLoss: 0.084132\n",
      "Train Epoch: 7 [5760/10296 (56%)]\tLoss: 0.076114\n",
      "Train Epoch: 7 [6400/10296 (62%)]\tLoss: 0.017235\n",
      "Train Epoch: 7 [7040/10296 (68%)]\tLoss: 0.020128\n",
      "Train Epoch: 7 [7680/10296 (75%)]\tLoss: 0.042048\n",
      "Train Epoch: 7 [8320/10296 (81%)]\tLoss: 0.077108\n",
      "Train Epoch: 7 [8960/10296 (87%)]\tLoss: 0.010905\n",
      "Train Epoch: 7 [9600/10296 (93%)]\tLoss: 0.056256\n",
      "Train Epoch: 7 [8960/10296 (99%)]\tLoss: 0.063171\n",
      "Train Epoch: 8 [0/10296 (0%)]\tLoss: 0.109673\n",
      "Train Epoch: 8 [640/10296 (6%)]\tLoss: 0.035094\n",
      "Train Epoch: 8 [1280/10296 (12%)]\tLoss: 0.089859\n",
      "Train Epoch: 8 [1920/10296 (19%)]\tLoss: 0.025211\n",
      "Train Epoch: 8 [2560/10296 (25%)]\tLoss: 0.179312\n",
      "Train Epoch: 8 [3200/10296 (31%)]\tLoss: 0.066285\n",
      "Train Epoch: 8 [3840/10296 (37%)]\tLoss: 0.137716\n",
      "Train Epoch: 8 [4480/10296 (43%)]\tLoss: 0.045274\n",
      "Train Epoch: 8 [5120/10296 (50%)]\tLoss: 0.056329\n",
      "Train Epoch: 8 [5760/10296 (56%)]\tLoss: 0.069404\n",
      "Train Epoch: 8 [6400/10296 (62%)]\tLoss: 0.057728\n",
      "Train Epoch: 8 [7040/10296 (68%)]\tLoss: 0.025704\n",
      "Train Epoch: 8 [7680/10296 (75%)]\tLoss: 0.066075\n",
      "Train Epoch: 8 [8320/10296 (81%)]\tLoss: 0.097324\n",
      "Train Epoch: 8 [8960/10296 (87%)]\tLoss: 0.076775\n",
      "Train Epoch: 8 [9600/10296 (93%)]\tLoss: 0.301610\n",
      "Train Epoch: 8 [8960/10296 (99%)]\tLoss: 0.091492\n",
      "Train Epoch: 9 [0/10296 (0%)]\tLoss: 0.028381\n",
      "Train Epoch: 9 [640/10296 (6%)]\tLoss: 0.018177\n",
      "Train Epoch: 9 [1280/10296 (12%)]\tLoss: 0.110370\n",
      "Train Epoch: 9 [1920/10296 (19%)]\tLoss: 0.131788\n",
      "Train Epoch: 9 [2560/10296 (25%)]\tLoss: 0.027314\n",
      "Train Epoch: 9 [3200/10296 (31%)]\tLoss: 0.129385\n",
      "Train Epoch: 9 [3840/10296 (37%)]\tLoss: 0.109030\n",
      "Train Epoch: 9 [4480/10296 (43%)]\tLoss: 0.057432\n",
      "Train Epoch: 9 [5120/10296 (50%)]\tLoss: 0.100571\n",
      "Train Epoch: 9 [5760/10296 (56%)]\tLoss: 0.057690\n",
      "Train Epoch: 9 [6400/10296 (62%)]\tLoss: 0.056794\n",
      "Train Epoch: 9 [7040/10296 (68%)]\tLoss: 0.062893\n",
      "Train Epoch: 9 [7680/10296 (75%)]\tLoss: 0.090558\n",
      "Train Epoch: 9 [8320/10296 (81%)]\tLoss: 0.034790\n",
      "Train Epoch: 9 [8960/10296 (87%)]\tLoss: 0.052090\n",
      "Train Epoch: 9 [9600/10296 (93%)]\tLoss: 0.031048\n",
      "Train Epoch: 9 [8960/10296 (99%)]\tLoss: 0.093434\n",
      "Train Epoch: 10 [0/10296 (0%)]\tLoss: 0.062171\n",
      "Train Epoch: 10 [640/10296 (6%)]\tLoss: 0.226261\n",
      "Train Epoch: 10 [1280/10296 (12%)]\tLoss: 0.059391\n",
      "Train Epoch: 10 [1920/10296 (19%)]\tLoss: 0.031367\n",
      "Train Epoch: 10 [2560/10296 (25%)]\tLoss: 0.015644\n",
      "Train Epoch: 10 [3200/10296 (31%)]\tLoss: 0.000792\n",
      "Train Epoch: 10 [3840/10296 (37%)]\tLoss: 0.012617\n",
      "Train Epoch: 10 [4480/10296 (43%)]\tLoss: 0.039347\n",
      "Train Epoch: 10 [5120/10296 (50%)]\tLoss: 0.190105\n",
      "Train Epoch: 10 [5760/10296 (56%)]\tLoss: 0.058501\n",
      "Train Epoch: 10 [6400/10296 (62%)]\tLoss: 0.011964\n",
      "Train Epoch: 10 [7040/10296 (68%)]\tLoss: 0.010923\n",
      "Train Epoch: 10 [7680/10296 (75%)]\tLoss: 0.032710\n",
      "Train Epoch: 10 [8320/10296 (81%)]\tLoss: 0.062106\n",
      "Train Epoch: 10 [8960/10296 (87%)]\tLoss: 0.030658\n",
      "Train Epoch: 10 [9600/10296 (93%)]\tLoss: 0.137526\n",
      "Train Epoch: 10 [8960/10296 (99%)]\tLoss: 0.060602\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 0.055607\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 0.065517\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 0.052834\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 0.017002\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 0.105692\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 0.015055\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 0.048783\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 0.018697\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 0.031968\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 0.020528\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 0.061972\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 0.034028\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 0.110510\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 0.118649\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 0.171128\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 0.128158\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 0.044961\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.045534\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.013316\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.028622\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.035383\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.079756\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.137296\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.029898\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.047357\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.097050\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.438684\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.133521\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.008967\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.008009\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.013669\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.040063\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.043434\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.044385\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.108951\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.022735\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.054692\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.127996\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.017239\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.034530\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.039132\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.085175\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.076539\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.014731\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.378998\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.232893\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.048460\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.187786\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.053352\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.153908\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.011157\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.063045\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.065151\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.037930\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.017052\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.012306\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.084452\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.054873\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.058100\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.090936\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.066663\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.081118\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.040205\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.101491\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.082823\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.115872\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.014010\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.005820\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.048489\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.039482\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.183133\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.196031\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.022504\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.067945\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.088071\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.010077\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.121607\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.087011\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.024040\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.031379\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.053202\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.098408\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.047339\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.055977\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.042338\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.030070\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.070324\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.050782\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.009748\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.049148\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.048935\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.012224\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.038122\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.008538\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.030041\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.009624\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.055399\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.087163\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.017140\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.092058\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.043597\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.020813\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.005106\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.023123\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.052283\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.051474\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.037274\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.059807\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.156829\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.018075\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.211413\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.106778\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.031324\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.026937\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.023022\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.001318\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.117981\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.063840\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.039357\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.024333\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.045303\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.063101\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.056168\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.086538\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.060505\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.020269\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.004728\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.072867\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.017816\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.038441\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.109019\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.028084\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.018361\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.010649\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.038847\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.015916\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.147598\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.106325\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.065553\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.020083\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.055531\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.040554\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.077596\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.112147\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.134767\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.012723\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.022381\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.085773\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.120055\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.042775\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.018649\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.026649\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.012525\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.015667\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.028143\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.107349\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.008408\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.080061\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.028470\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.048805\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/3910 (0%)]\tLoss: 0.174236\n",
      "Train Epoch: 1 [640/3910 (16%)]\tLoss: 0.160982\n",
      "Train Epoch: 1 [1280/3910 (32%)]\tLoss: 0.079112\n",
      "Train Epoch: 1 [1920/3910 (48%)]\tLoss: 0.065033\n",
      "Train Epoch: 1 [2560/3910 (65%)]\tLoss: 0.121179\n",
      "Train Epoch: 1 [3200/3910 (81%)]\tLoss: 0.092303\n",
      "Train Epoch: 1 [3840/3910 (97%)]\tLoss: 0.037512\n",
      "Train Epoch: 2 [0/3910 (0%)]\tLoss: 0.310843\n",
      "Train Epoch: 2 [640/3910 (16%)]\tLoss: 0.035192\n",
      "Train Epoch: 2 [1280/3910 (32%)]\tLoss: 0.045625\n",
      "Train Epoch: 2 [1920/3910 (48%)]\tLoss: 0.095822\n",
      "Train Epoch: 2 [2560/3910 (65%)]\tLoss: 0.062435\n",
      "Train Epoch: 2 [3200/3910 (81%)]\tLoss: 0.036249\n",
      "Train Epoch: 2 [3840/3910 (97%)]\tLoss: 0.198581\n",
      "Train Epoch: 3 [0/3910 (0%)]\tLoss: 0.065227\n",
      "Train Epoch: 3 [640/3910 (16%)]\tLoss: 0.064006\n",
      "Train Epoch: 3 [1280/3910 (32%)]\tLoss: 0.077514\n",
      "Train Epoch: 3 [1920/3910 (48%)]\tLoss: 0.089663\n",
      "Train Epoch: 3 [2560/3910 (65%)]\tLoss: 0.015178\n",
      "Train Epoch: 3 [3200/3910 (81%)]\tLoss: 0.061546\n",
      "Train Epoch: 3 [3840/3910 (97%)]\tLoss: 0.035211\n",
      "Train Epoch: 4 [0/3910 (0%)]\tLoss: 0.080817\n",
      "Train Epoch: 4 [640/3910 (16%)]\tLoss: 0.011121\n",
      "Train Epoch: 4 [1280/3910 (32%)]\tLoss: 0.068423\n",
      "Train Epoch: 4 [1920/3910 (48%)]\tLoss: 0.021738\n",
      "Train Epoch: 4 [2560/3910 (65%)]\tLoss: 0.048237\n",
      "Train Epoch: 4 [3200/3910 (81%)]\tLoss: 0.005554\n",
      "Train Epoch: 4 [3840/3910 (97%)]\tLoss: 0.029110\n",
      "Train Epoch: 5 [0/3910 (0%)]\tLoss: 0.018265\n",
      "Train Epoch: 5 [640/3910 (16%)]\tLoss: 0.062851\n",
      "Train Epoch: 5 [1280/3910 (32%)]\tLoss: 0.015427\n",
      "Train Epoch: 5 [1920/3910 (48%)]\tLoss: 0.121227\n",
      "Train Epoch: 5 [2560/3910 (65%)]\tLoss: 0.115076\n",
      "Train Epoch: 5 [3200/3910 (81%)]\tLoss: 0.079362\n",
      "Train Epoch: 5 [3840/3910 (97%)]\tLoss: 0.080979\n",
      "Train Epoch: 6 [0/3910 (0%)]\tLoss: 0.012049\n",
      "Train Epoch: 6 [640/3910 (16%)]\tLoss: 0.008145\n",
      "Train Epoch: 6 [1280/3910 (32%)]\tLoss: 0.055119\n",
      "Train Epoch: 6 [1920/3910 (48%)]\tLoss: 0.062403\n",
      "Train Epoch: 6 [2560/3910 (65%)]\tLoss: 0.068663\n",
      "Train Epoch: 6 [3200/3910 (81%)]\tLoss: 0.078124\n",
      "Train Epoch: 6 [3840/3910 (97%)]\tLoss: 0.080250\n",
      "Train Epoch: 7 [0/3910 (0%)]\tLoss: 0.054597\n",
      "Train Epoch: 7 [640/3910 (16%)]\tLoss: 0.008386\n",
      "Train Epoch: 7 [1280/3910 (32%)]\tLoss: 0.042009\n",
      "Train Epoch: 7 [1920/3910 (48%)]\tLoss: 0.061812\n",
      "Train Epoch: 7 [2560/3910 (65%)]\tLoss: 0.127565\n",
      "Train Epoch: 7 [3200/3910 (81%)]\tLoss: 0.079484\n",
      "Train Epoch: 7 [3840/3910 (97%)]\tLoss: 0.020239\n",
      "Train Epoch: 8 [0/3910 (0%)]\tLoss: 0.036094\n",
      "Train Epoch: 8 [640/3910 (16%)]\tLoss: 0.006390\n",
      "Train Epoch: 8 [1280/3910 (32%)]\tLoss: 0.068071\n",
      "Train Epoch: 8 [1920/3910 (48%)]\tLoss: 0.061448\n",
      "Train Epoch: 8 [2560/3910 (65%)]\tLoss: 0.072754\n",
      "Train Epoch: 8 [3200/3910 (81%)]\tLoss: 0.161314\n",
      "Train Epoch: 8 [3840/3910 (97%)]\tLoss: 0.007109\n",
      "Train Epoch: 9 [0/3910 (0%)]\tLoss: 0.014052\n",
      "Train Epoch: 9 [640/3910 (16%)]\tLoss: 0.037562\n",
      "Train Epoch: 9 [1280/3910 (32%)]\tLoss: 0.025623\n",
      "Train Epoch: 9 [1920/3910 (48%)]\tLoss: 0.099864\n",
      "Train Epoch: 9 [2560/3910 (65%)]\tLoss: 0.103901\n",
      "Train Epoch: 9 [3200/3910 (81%)]\tLoss: 0.021000\n",
      "Train Epoch: 9 [3840/3910 (97%)]\tLoss: 0.012558\n",
      "Train Epoch: 10 [0/3910 (0%)]\tLoss: 0.051279\n",
      "Train Epoch: 10 [640/3910 (16%)]\tLoss: 0.103136\n",
      "Train Epoch: 10 [1280/3910 (32%)]\tLoss: 0.011310\n",
      "Train Epoch: 10 [1920/3910 (48%)]\tLoss: 0.011710\n",
      "Train Epoch: 10 [2560/3910 (65%)]\tLoss: 0.180045\n",
      "Train Epoch: 10 [3200/3910 (81%)]\tLoss: 0.068769\n",
      "Train Epoch: 10 [3840/3910 (97%)]\tLoss: 0.024594\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 0.241241\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 0.039479\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 0.018301\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 0.057939\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 0.045711\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 0.008942\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 0.129927\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 0.014844\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 0.064800\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 0.050072\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.037525\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.042620\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 0.039643\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 0.077807\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 0.039300\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.096697\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.021448\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.051857\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.060665\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.028453\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.071534\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.029495\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.004681\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.068181\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.095655\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.053702\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.170450\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.018179\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.048675\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.015973\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.051880\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.145163\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.021391\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.120098\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.109873\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.024858\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.031936\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.035398\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.026268\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.078119\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.074688\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.016446\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.048076\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.053926\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.032244\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.024488\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.014085\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.006074\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.053257\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.033017\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.014575\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.031346\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.089133\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.098483\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.082857\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.046516\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.007497\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.109725\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.022665\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.015711\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.005457\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.007329\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.094940\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.044762\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.019099\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.007595\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.047924\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.072680\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.036549\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.117570\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.037726\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.065699\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.030363\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.056694\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.063735\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.033218\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.088456\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.018154\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.007669\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.014577\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.073724\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.053100\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.021352\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.035390\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.049968\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.076188\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.017032\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.030576\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.132948\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.032236\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.040443\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.041327\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.078900\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.021645\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.009948\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.076847\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.068282\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.019254\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.033343\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.042096\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.021652\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.007907\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.062589\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.028186\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.003207\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.002920\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.021333\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.038903\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.004884\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.082425\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.113919\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.091600\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.011073\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.060389\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.057727\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.003375\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.019277\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.165673\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.011743\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.005144\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/5096 (0%)]\tLoss: 0.168189\n",
      "Train Epoch: 1 [640/5096 (12%)]\tLoss: 0.104380\n",
      "Train Epoch: 1 [1280/5096 (25%)]\tLoss: 0.064286\n",
      "Train Epoch: 1 [1920/5096 (38%)]\tLoss: 0.129564\n",
      "Train Epoch: 1 [2560/5096 (50%)]\tLoss: 0.054645\n",
      "Train Epoch: 1 [3200/5096 (62%)]\tLoss: 0.005425\n",
      "Train Epoch: 1 [3840/5096 (75%)]\tLoss: 0.046719\n",
      "Train Epoch: 1 [4480/5096 (88%)]\tLoss: 0.023662\n",
      "Train Epoch: 2 [0/5096 (0%)]\tLoss: 0.076367\n",
      "Train Epoch: 2 [640/5096 (12%)]\tLoss: 0.008908\n",
      "Train Epoch: 2 [1280/5096 (25%)]\tLoss: 0.011858\n",
      "Train Epoch: 2 [1920/5096 (38%)]\tLoss: 0.051814\n",
      "Train Epoch: 2 [2560/5096 (50%)]\tLoss: 0.016191\n",
      "Train Epoch: 2 [3200/5096 (62%)]\tLoss: 0.069286\n",
      "Train Epoch: 2 [3840/5096 (75%)]\tLoss: 0.028061\n",
      "Train Epoch: 2 [4480/5096 (88%)]\tLoss: 0.019788\n",
      "Train Epoch: 3 [0/5096 (0%)]\tLoss: 0.002006\n",
      "Train Epoch: 3 [640/5096 (12%)]\tLoss: 0.041071\n",
      "Train Epoch: 3 [1280/5096 (25%)]\tLoss: 0.132942\n",
      "Train Epoch: 3 [1920/5096 (38%)]\tLoss: 0.013188\n",
      "Train Epoch: 3 [2560/5096 (50%)]\tLoss: 0.062081\n",
      "Train Epoch: 3 [3200/5096 (62%)]\tLoss: 0.013796\n",
      "Train Epoch: 3 [3840/5096 (75%)]\tLoss: 0.028247\n",
      "Train Epoch: 3 [4480/5096 (88%)]\tLoss: 0.008994\n",
      "Train Epoch: 4 [0/5096 (0%)]\tLoss: 0.018022\n",
      "Train Epoch: 4 [640/5096 (12%)]\tLoss: 0.003290\n",
      "Train Epoch: 4 [1280/5096 (25%)]\tLoss: 0.207171\n",
      "Train Epoch: 4 [1920/5096 (38%)]\tLoss: 0.018991\n",
      "Train Epoch: 4 [2560/5096 (50%)]\tLoss: 0.011427\n",
      "Train Epoch: 4 [3200/5096 (62%)]\tLoss: 0.017010\n",
      "Train Epoch: 4 [3840/5096 (75%)]\tLoss: 0.006958\n",
      "Train Epoch: 4 [4480/5096 (88%)]\tLoss: 0.062609\n",
      "Train Epoch: 5 [0/5096 (0%)]\tLoss: 0.088342\n",
      "Train Epoch: 5 [640/5096 (12%)]\tLoss: 0.025889\n",
      "Train Epoch: 5 [1280/5096 (25%)]\tLoss: 0.002602\n",
      "Train Epoch: 5 [1920/5096 (38%)]\tLoss: 0.009182\n",
      "Train Epoch: 5 [2560/5096 (50%)]\tLoss: 0.006545\n",
      "Train Epoch: 5 [3200/5096 (62%)]\tLoss: 0.007544\n",
      "Train Epoch: 5 [3840/5096 (75%)]\tLoss: 0.008703\n",
      "Train Epoch: 5 [4480/5096 (88%)]\tLoss: 0.140176\n",
      "Train Epoch: 6 [0/5096 (0%)]\tLoss: 0.001448\n",
      "Train Epoch: 6 [640/5096 (12%)]\tLoss: 0.016929\n",
      "Train Epoch: 6 [1280/5096 (25%)]\tLoss: 0.001621\n",
      "Train Epoch: 6 [1920/5096 (38%)]\tLoss: 0.014306\n",
      "Train Epoch: 6 [2560/5096 (50%)]\tLoss: 0.014051\n",
      "Train Epoch: 6 [3200/5096 (62%)]\tLoss: 0.090610\n",
      "Train Epoch: 6 [3840/5096 (75%)]\tLoss: 0.018136\n",
      "Train Epoch: 6 [4480/5096 (88%)]\tLoss: 0.054049\n",
      "Train Epoch: 7 [0/5096 (0%)]\tLoss: 0.036517\n",
      "Train Epoch: 7 [640/5096 (12%)]\tLoss: 0.007363\n",
      "Train Epoch: 7 [1280/5096 (25%)]\tLoss: 0.011437\n",
      "Train Epoch: 7 [1920/5096 (38%)]\tLoss: 0.004736\n",
      "Train Epoch: 7 [2560/5096 (50%)]\tLoss: 0.012790\n",
      "Train Epoch: 7 [3200/5096 (62%)]\tLoss: 0.059518\n",
      "Train Epoch: 7 [3840/5096 (75%)]\tLoss: 0.007571\n",
      "Train Epoch: 7 [4480/5096 (88%)]\tLoss: 0.104894\n",
      "Train Epoch: 8 [0/5096 (0%)]\tLoss: 0.031235\n",
      "Train Epoch: 8 [640/5096 (12%)]\tLoss: 0.019221\n",
      "Train Epoch: 8 [1280/5096 (25%)]\tLoss: 0.026997\n",
      "Train Epoch: 8 [1920/5096 (38%)]\tLoss: 0.011825\n",
      "Train Epoch: 8 [2560/5096 (50%)]\tLoss: 0.007186\n",
      "Train Epoch: 8 [3200/5096 (62%)]\tLoss: 0.014937\n",
      "Train Epoch: 8 [3840/5096 (75%)]\tLoss: 0.031752\n",
      "Train Epoch: 8 [4480/5096 (88%)]\tLoss: 0.068139\n",
      "Train Epoch: 9 [0/5096 (0%)]\tLoss: 0.048385\n",
      "Train Epoch: 9 [640/5096 (12%)]\tLoss: 0.002923\n",
      "Train Epoch: 9 [1280/5096 (25%)]\tLoss: 0.051605\n",
      "Train Epoch: 9 [1920/5096 (38%)]\tLoss: 0.021804\n",
      "Train Epoch: 9 [2560/5096 (50%)]\tLoss: 0.036905\n",
      "Train Epoch: 9 [3200/5096 (62%)]\tLoss: 0.025220\n",
      "Train Epoch: 9 [3840/5096 (75%)]\tLoss: 0.043696\n",
      "Train Epoch: 9 [4480/5096 (88%)]\tLoss: 0.016566\n",
      "Train Epoch: 10 [0/5096 (0%)]\tLoss: 0.032751\n",
      "Train Epoch: 10 [640/5096 (12%)]\tLoss: 0.002544\n",
      "Train Epoch: 10 [1280/5096 (25%)]\tLoss: 0.018805\n",
      "Train Epoch: 10 [1920/5096 (38%)]\tLoss: 0.012901\n",
      "Train Epoch: 10 [2560/5096 (50%)]\tLoss: 0.012960\n",
      "Train Epoch: 10 [3200/5096 (62%)]\tLoss: 0.042398\n",
      "Train Epoch: 10 [3840/5096 (75%)]\tLoss: 0.011197\n",
      "Train Epoch: 10 [4480/5096 (88%)]\tLoss: 0.016630\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6865 (0%)]\tLoss: 0.289683\n",
      "Train Epoch: 1 [640/6865 (9%)]\tLoss: 0.067421\n",
      "Train Epoch: 1 [1280/6865 (19%)]\tLoss: 0.038301\n",
      "Train Epoch: 1 [1920/6865 (28%)]\tLoss: 0.058352\n",
      "Train Epoch: 1 [2560/6865 (37%)]\tLoss: 0.020543\n",
      "Train Epoch: 1 [3200/6865 (46%)]\tLoss: 0.038232\n",
      "Train Epoch: 1 [3840/6865 (56%)]\tLoss: 0.080251\n",
      "Train Epoch: 1 [4480/6865 (65%)]\tLoss: 0.019731\n",
      "Train Epoch: 1 [5120/6865 (74%)]\tLoss: 0.099866\n",
      "Train Epoch: 1 [5760/6865 (83%)]\tLoss: 0.042366\n",
      "Train Epoch: 1 [6400/6865 (93%)]\tLoss: 0.013650\n",
      "Train Epoch: 2 [0/6865 (0%)]\tLoss: 0.042348\n",
      "Train Epoch: 2 [640/6865 (9%)]\tLoss: 0.059229\n",
      "Train Epoch: 2 [1280/6865 (19%)]\tLoss: 0.044789\n",
      "Train Epoch: 2 [1920/6865 (28%)]\tLoss: 0.154740\n",
      "Train Epoch: 2 [2560/6865 (37%)]\tLoss: 0.018009\n",
      "Train Epoch: 2 [3200/6865 (46%)]\tLoss: 0.043409\n",
      "Train Epoch: 2 [3840/6865 (56%)]\tLoss: 0.009645\n",
      "Train Epoch: 2 [4480/6865 (65%)]\tLoss: 0.007980\n",
      "Train Epoch: 2 [5120/6865 (74%)]\tLoss: 0.033255\n",
      "Train Epoch: 2 [5760/6865 (83%)]\tLoss: 0.019300\n",
      "Train Epoch: 2 [6400/6865 (93%)]\tLoss: 0.041491\n",
      "Train Epoch: 3 [0/6865 (0%)]\tLoss: 0.020250\n",
      "Train Epoch: 3 [640/6865 (9%)]\tLoss: 0.030781\n",
      "Train Epoch: 3 [1280/6865 (19%)]\tLoss: 0.041122\n",
      "Train Epoch: 3 [1920/6865 (28%)]\tLoss: 0.035734\n",
      "Train Epoch: 3 [2560/6865 (37%)]\tLoss: 0.029771\n",
      "Train Epoch: 3 [3200/6865 (46%)]\tLoss: 0.015782\n",
      "Train Epoch: 3 [3840/6865 (56%)]\tLoss: 0.006147\n",
      "Train Epoch: 3 [4480/6865 (65%)]\tLoss: 0.086573\n",
      "Train Epoch: 3 [5120/6865 (74%)]\tLoss: 0.041831\n",
      "Train Epoch: 3 [5760/6865 (83%)]\tLoss: 0.081616\n",
      "Train Epoch: 3 [6400/6865 (93%)]\tLoss: 0.049660\n",
      "Train Epoch: 4 [0/6865 (0%)]\tLoss: 0.010712\n",
      "Train Epoch: 4 [640/6865 (9%)]\tLoss: 0.037107\n",
      "Train Epoch: 4 [1280/6865 (19%)]\tLoss: 0.096390\n",
      "Train Epoch: 4 [1920/6865 (28%)]\tLoss: 0.004894\n",
      "Train Epoch: 4 [2560/6865 (37%)]\tLoss: 0.029267\n",
      "Train Epoch: 4 [3200/6865 (46%)]\tLoss: 0.028360\n",
      "Train Epoch: 4 [3840/6865 (56%)]\tLoss: 0.029858\n",
      "Train Epoch: 4 [4480/6865 (65%)]\tLoss: 0.116147\n",
      "Train Epoch: 4 [5120/6865 (74%)]\tLoss: 0.059506\n",
      "Train Epoch: 4 [5760/6865 (83%)]\tLoss: 0.094127\n",
      "Train Epoch: 4 [6400/6865 (93%)]\tLoss: 0.030686\n",
      "Train Epoch: 5 [0/6865 (0%)]\tLoss: 0.029818\n",
      "Train Epoch: 5 [640/6865 (9%)]\tLoss: 0.020001\n",
      "Train Epoch: 5 [1280/6865 (19%)]\tLoss: 0.023869\n",
      "Train Epoch: 5 [1920/6865 (28%)]\tLoss: 0.037972\n",
      "Train Epoch: 5 [2560/6865 (37%)]\tLoss: 0.084632\n",
      "Train Epoch: 5 [3200/6865 (46%)]\tLoss: 0.065282\n",
      "Train Epoch: 5 [3840/6865 (56%)]\tLoss: 0.009050\n",
      "Train Epoch: 5 [4480/6865 (65%)]\tLoss: 0.183253\n",
      "Train Epoch: 5 [5120/6865 (74%)]\tLoss: 0.013102\n",
      "Train Epoch: 5 [5760/6865 (83%)]\tLoss: 0.005560\n",
      "Train Epoch: 5 [6400/6865 (93%)]\tLoss: 0.052680\n",
      "Train Epoch: 6 [0/6865 (0%)]\tLoss: 0.045854\n",
      "Train Epoch: 6 [640/6865 (9%)]\tLoss: 0.018492\n",
      "Train Epoch: 6 [1280/6865 (19%)]\tLoss: 0.020585\n",
      "Train Epoch: 6 [1920/6865 (28%)]\tLoss: 0.026446\n",
      "Train Epoch: 6 [2560/6865 (37%)]\tLoss: 0.017164\n",
      "Train Epoch: 6 [3200/6865 (46%)]\tLoss: 0.004576\n",
      "Train Epoch: 6 [3840/6865 (56%)]\tLoss: 0.050739\n",
      "Train Epoch: 6 [4480/6865 (65%)]\tLoss: 0.006974\n",
      "Train Epoch: 6 [5120/6865 (74%)]\tLoss: 0.027367\n",
      "Train Epoch: 6 [5760/6865 (83%)]\tLoss: 0.035977\n",
      "Train Epoch: 6 [6400/6865 (93%)]\tLoss: 0.003962\n",
      "Train Epoch: 7 [0/6865 (0%)]\tLoss: 0.067837\n",
      "Train Epoch: 7 [640/6865 (9%)]\tLoss: 0.021062\n",
      "Train Epoch: 7 [1280/6865 (19%)]\tLoss: 0.137976\n",
      "Train Epoch: 7 [1920/6865 (28%)]\tLoss: 0.039429\n",
      "Train Epoch: 7 [2560/6865 (37%)]\tLoss: 0.026246\n",
      "Train Epoch: 7 [3200/6865 (46%)]\tLoss: 0.011378\n",
      "Train Epoch: 7 [3840/6865 (56%)]\tLoss: 0.031150\n",
      "Train Epoch: 7 [4480/6865 (65%)]\tLoss: 0.034405\n",
      "Train Epoch: 7 [5120/6865 (74%)]\tLoss: 0.001688\n",
      "Train Epoch: 7 [5760/6865 (83%)]\tLoss: 0.006120\n",
      "Train Epoch: 7 [6400/6865 (93%)]\tLoss: 0.050533\n",
      "Train Epoch: 8 [0/6865 (0%)]\tLoss: 0.015703\n",
      "Train Epoch: 8 [640/6865 (9%)]\tLoss: 0.011732\n",
      "Train Epoch: 8 [1280/6865 (19%)]\tLoss: 0.017452\n",
      "Train Epoch: 8 [1920/6865 (28%)]\tLoss: 0.025804\n",
      "Train Epoch: 8 [2560/6865 (37%)]\tLoss: 0.026161\n",
      "Train Epoch: 8 [3200/6865 (46%)]\tLoss: 0.051505\n",
      "Train Epoch: 8 [3840/6865 (56%)]\tLoss: 0.009100\n",
      "Train Epoch: 8 [4480/6865 (65%)]\tLoss: 0.013041\n",
      "Train Epoch: 8 [5120/6865 (74%)]\tLoss: 0.005236\n",
      "Train Epoch: 8 [5760/6865 (83%)]\tLoss: 0.026789\n",
      "Train Epoch: 8 [6400/6865 (93%)]\tLoss: 0.024225\n",
      "Train Epoch: 9 [0/6865 (0%)]\tLoss: 0.019827\n",
      "Train Epoch: 9 [640/6865 (9%)]\tLoss: 0.005928\n",
      "Train Epoch: 9 [1280/6865 (19%)]\tLoss: 0.009037\n",
      "Train Epoch: 9 [1920/6865 (28%)]\tLoss: 0.029891\n",
      "Train Epoch: 9 [2560/6865 (37%)]\tLoss: 0.023243\n",
      "Train Epoch: 9 [3200/6865 (46%)]\tLoss: 0.010767\n",
      "Train Epoch: 9 [3840/6865 (56%)]\tLoss: 0.013383\n",
      "Train Epoch: 9 [4480/6865 (65%)]\tLoss: 0.056223\n",
      "Train Epoch: 9 [5120/6865 (74%)]\tLoss: 0.079408\n",
      "Train Epoch: 9 [5760/6865 (83%)]\tLoss: 0.011044\n",
      "Train Epoch: 9 [6400/6865 (93%)]\tLoss: 0.131862\n",
      "Train Epoch: 10 [0/6865 (0%)]\tLoss: 0.009290\n",
      "Train Epoch: 10 [640/6865 (9%)]\tLoss: 0.009237\n",
      "Train Epoch: 10 [1280/6865 (19%)]\tLoss: 0.025534\n",
      "Train Epoch: 10 [1920/6865 (28%)]\tLoss: 0.028944\n",
      "Train Epoch: 10 [2560/6865 (37%)]\tLoss: 0.021558\n",
      "Train Epoch: 10 [3200/6865 (46%)]\tLoss: 0.116706\n",
      "Train Epoch: 10 [3840/6865 (56%)]\tLoss: 0.027070\n",
      "Train Epoch: 10 [4480/6865 (65%)]\tLoss: 0.134309\n",
      "Train Epoch: 10 [5120/6865 (74%)]\tLoss: 0.005162\n",
      "Train Epoch: 10 [5760/6865 (83%)]\tLoss: 0.043323\n",
      "Train Epoch: 10 [6400/6865 (93%)]\tLoss: 0.005227\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0437, Accuracy: 9851/10000 (99%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 0.106371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 0.611295\n",
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 0.219449\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 0.086892\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 0.098397\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 0.101174\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 0.093532\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 0.084382\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 0.124365\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 0.065343\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 0.101068\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 0.127019\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 0.021051\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 0.041483\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 0.055789\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 0.116171\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 0.049026\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 0.028517\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 0.055166\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 0.096119\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.072584\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 0.106309\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 0.112168\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.029345\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.060594\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 0.033185\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.046952\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 0.037342\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.084164\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.185130\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.075271\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.139685\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.007162\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.057918\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.156943\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.024911\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.036223\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.021409\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.010654\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.087159\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.032225\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.102330\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.081882\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.089858\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.084785\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.099990\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.060414\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.079343\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.036871\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.086026\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.094962\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.026602\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.041605\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.047302\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.067171\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.074280\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.037761\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.106392\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.133000\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.009172\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.059969\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.071501\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.098427\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.026903\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.137688\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.131183\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.136240\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.023354\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.132305\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.044721\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.004117\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.060246\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.024944\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.018060\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.041359\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.022321\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.044765\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.164070\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.051088\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.028285\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.124090\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.046403\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.101571\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.130398\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.049281\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.127809\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.026472\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.025455\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.074910\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.188172\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.052769\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.069029\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.074544\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.116319\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.067603\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.050225\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.020973\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.110895\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.039186\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.054962\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.064762\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.023044\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.078401\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.139997\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.044763\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.121010\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.057792\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.139299\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 0.031027\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.135812\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.029831\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.088194\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.044739\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.009210\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.031267\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.067469\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.029717\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.026853\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.070595\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.046867\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.251081\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.032025\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.013560\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.044891\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.009850\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.035451\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.057018\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.093834\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.046805\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.071076\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.025494\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.054329\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.160253\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.042733\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.049298\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.106593\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.059205\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.030854\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.182215\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.094865\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.023505\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.042946\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.066851\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.040386\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.012242\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.019465\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.093588\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.019528\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.076629\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.040468\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.028179\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.253523\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.043668\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.027579\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.049511\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.035942\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.009273\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.036866\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.072744\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.055154\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.097930\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.211255\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.067095\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.106730\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.052609\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.026338\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.080039\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.029653\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.048327\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.018211\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.044396\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.018020\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.028929\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.038883\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.124925\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.034956\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.057361\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.230071\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.008310\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.102925\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/5110 (0%)]\tLoss: 0.152026\n",
      "Train Epoch: 1 [640/5110 (12%)]\tLoss: 0.066370\n",
      "Train Epoch: 1 [1280/5110 (25%)]\tLoss: 0.076874\n",
      "Train Epoch: 1 [1920/5110 (38%)]\tLoss: 0.086491\n",
      "Train Epoch: 1 [2560/5110 (50%)]\tLoss: 0.047688\n",
      "Train Epoch: 1 [3200/5110 (62%)]\tLoss: 0.324817\n",
      "Train Epoch: 1 [3840/5110 (75%)]\tLoss: 0.034048\n",
      "Train Epoch: 1 [4480/5110 (88%)]\tLoss: 0.032729\n",
      "Train Epoch: 2 [0/5110 (0%)]\tLoss: 0.059946\n",
      "Train Epoch: 2 [640/5110 (12%)]\tLoss: 0.064485\n",
      "Train Epoch: 2 [1280/5110 (25%)]\tLoss: 0.451848\n",
      "Train Epoch: 2 [1920/5110 (38%)]\tLoss: 0.010715\n",
      "Train Epoch: 2 [2560/5110 (50%)]\tLoss: 0.095873\n",
      "Train Epoch: 2 [3200/5110 (62%)]\tLoss: 0.019615\n",
      "Train Epoch: 2 [3840/5110 (75%)]\tLoss: 0.040165\n",
      "Train Epoch: 2 [4480/5110 (88%)]\tLoss: 0.085330\n",
      "Train Epoch: 3 [0/5110 (0%)]\tLoss: 0.050918\n",
      "Train Epoch: 3 [640/5110 (12%)]\tLoss: 0.133866\n",
      "Train Epoch: 3 [1280/5110 (25%)]\tLoss: 0.033474\n",
      "Train Epoch: 3 [1920/5110 (38%)]\tLoss: 0.044656\n",
      "Train Epoch: 3 [2560/5110 (50%)]\tLoss: 0.118740\n",
      "Train Epoch: 3 [3200/5110 (62%)]\tLoss: 0.115818\n",
      "Train Epoch: 3 [3840/5110 (75%)]\tLoss: 0.089307\n",
      "Train Epoch: 3 [4480/5110 (88%)]\tLoss: 0.017134\n",
      "Train Epoch: 4 [0/5110 (0%)]\tLoss: 0.091261\n",
      "Train Epoch: 4 [640/5110 (12%)]\tLoss: 0.064417\n",
      "Train Epoch: 4 [1280/5110 (25%)]\tLoss: 0.045689\n",
      "Train Epoch: 4 [1920/5110 (38%)]\tLoss: 0.043389\n",
      "Train Epoch: 4 [2560/5110 (50%)]\tLoss: 0.219051\n",
      "Train Epoch: 4 [3200/5110 (62%)]\tLoss: 0.118125\n",
      "Train Epoch: 4 [3840/5110 (75%)]\tLoss: 0.045315\n",
      "Train Epoch: 4 [4480/5110 (88%)]\tLoss: 0.074313\n",
      "Train Epoch: 5 [0/5110 (0%)]\tLoss: 0.116625\n",
      "Train Epoch: 5 [640/5110 (12%)]\tLoss: 0.044716\n",
      "Train Epoch: 5 [1280/5110 (25%)]\tLoss: 0.040406\n",
      "Train Epoch: 5 [1920/5110 (38%)]\tLoss: 0.037004\n",
      "Train Epoch: 5 [2560/5110 (50%)]\tLoss: 0.063212\n",
      "Train Epoch: 5 [3200/5110 (62%)]\tLoss: 0.068491\n",
      "Train Epoch: 5 [3840/5110 (75%)]\tLoss: 0.006311\n",
      "Train Epoch: 5 [4480/5110 (88%)]\tLoss: 0.061843\n",
      "Train Epoch: 6 [0/5110 (0%)]\tLoss: 0.005384\n",
      "Train Epoch: 6 [640/5110 (12%)]\tLoss: 0.019690\n",
      "Train Epoch: 6 [1280/5110 (25%)]\tLoss: 0.158174\n",
      "Train Epoch: 6 [1920/5110 (38%)]\tLoss: 0.040518\n",
      "Train Epoch: 6 [2560/5110 (50%)]\tLoss: 0.025977\n",
      "Train Epoch: 6 [3200/5110 (62%)]\tLoss: 0.106947\n",
      "Train Epoch: 6 [3840/5110 (75%)]\tLoss: 0.179403\n",
      "Train Epoch: 6 [4480/5110 (88%)]\tLoss: 0.047009\n",
      "Train Epoch: 7 [0/5110 (0%)]\tLoss: 0.005704\n",
      "Train Epoch: 7 [640/5110 (12%)]\tLoss: 0.097315\n",
      "Train Epoch: 7 [1280/5110 (25%)]\tLoss: 0.097911\n",
      "Train Epoch: 7 [1920/5110 (38%)]\tLoss: 0.104685\n",
      "Train Epoch: 7 [2560/5110 (50%)]\tLoss: 0.144261\n",
      "Train Epoch: 7 [3200/5110 (62%)]\tLoss: 0.021507\n",
      "Train Epoch: 7 [3840/5110 (75%)]\tLoss: 0.172057\n",
      "Train Epoch: 7 [4480/5110 (88%)]\tLoss: 0.003878\n",
      "Train Epoch: 8 [0/5110 (0%)]\tLoss: 0.029906\n",
      "Train Epoch: 8 [640/5110 (12%)]\tLoss: 0.019641\n",
      "Train Epoch: 8 [1280/5110 (25%)]\tLoss: 0.047658\n",
      "Train Epoch: 8 [1920/5110 (38%)]\tLoss: 0.020689\n",
      "Train Epoch: 8 [2560/5110 (50%)]\tLoss: 0.123590\n",
      "Train Epoch: 8 [3200/5110 (62%)]\tLoss: 0.030807\n",
      "Train Epoch: 8 [3840/5110 (75%)]\tLoss: 0.089623\n",
      "Train Epoch: 8 [4480/5110 (88%)]\tLoss: 0.081057\n",
      "Train Epoch: 9 [0/5110 (0%)]\tLoss: 0.044019\n",
      "Train Epoch: 9 [640/5110 (12%)]\tLoss: 0.005712\n",
      "Train Epoch: 9 [1280/5110 (25%)]\tLoss: 0.005381\n",
      "Train Epoch: 9 [1920/5110 (38%)]\tLoss: 0.018007\n",
      "Train Epoch: 9 [2560/5110 (50%)]\tLoss: 0.033216\n",
      "Train Epoch: 9 [3200/5110 (62%)]\tLoss: 0.025235\n",
      "Train Epoch: 9 [3840/5110 (75%)]\tLoss: 0.076788\n",
      "Train Epoch: 9 [4480/5110 (88%)]\tLoss: 0.027921\n",
      "Train Epoch: 10 [0/5110 (0%)]\tLoss: 0.230129\n",
      "Train Epoch: 10 [640/5110 (12%)]\tLoss: 0.023836\n",
      "Train Epoch: 10 [1280/5110 (25%)]\tLoss: 0.089424\n",
      "Train Epoch: 10 [1920/5110 (38%)]\tLoss: 0.096632\n",
      "Train Epoch: 10 [2560/5110 (50%)]\tLoss: 0.008679\n",
      "Train Epoch: 10 [3200/5110 (62%)]\tLoss: 0.101229\n",
      "Train Epoch: 10 [3840/5110 (75%)]\tLoss: 0.050680\n",
      "Train Epoch: 10 [4480/5110 (88%)]\tLoss: 0.046287\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/10296 (0%)]\tLoss: 0.319162\n",
      "Train Epoch: 1 [640/10296 (6%)]\tLoss: 0.132748\n",
      "Train Epoch: 1 [1280/10296 (12%)]\tLoss: 0.027093\n",
      "Train Epoch: 1 [1920/10296 (19%)]\tLoss: 0.179091\n",
      "Train Epoch: 1 [2560/10296 (25%)]\tLoss: 0.039590\n",
      "Train Epoch: 1 [3200/10296 (31%)]\tLoss: 0.036127\n",
      "Train Epoch: 1 [3840/10296 (37%)]\tLoss: 0.074240\n",
      "Train Epoch: 1 [4480/10296 (43%)]\tLoss: 0.124281\n",
      "Train Epoch: 1 [5120/10296 (50%)]\tLoss: 0.101437\n",
      "Train Epoch: 1 [5760/10296 (56%)]\tLoss: 0.109022\n",
      "Train Epoch: 1 [6400/10296 (62%)]\tLoss: 0.108806\n",
      "Train Epoch: 1 [7040/10296 (68%)]\tLoss: 0.020887\n",
      "Train Epoch: 1 [7680/10296 (75%)]\tLoss: 0.052836\n",
      "Train Epoch: 1 [8320/10296 (81%)]\tLoss: 0.030020\n",
      "Train Epoch: 1 [8960/10296 (87%)]\tLoss: 0.055226\n",
      "Train Epoch: 1 [9600/10296 (93%)]\tLoss: 0.038449\n",
      "Train Epoch: 1 [8960/10296 (99%)]\tLoss: 0.063086\n",
      "Train Epoch: 2 [0/10296 (0%)]\tLoss: 0.102396\n",
      "Train Epoch: 2 [640/10296 (6%)]\tLoss: 0.098695\n",
      "Train Epoch: 2 [1280/10296 (12%)]\tLoss: 0.053464\n",
      "Train Epoch: 2 [1920/10296 (19%)]\tLoss: 0.151768\n",
      "Train Epoch: 2 [2560/10296 (25%)]\tLoss: 0.113829\n",
      "Train Epoch: 2 [3200/10296 (31%)]\tLoss: 0.118307\n",
      "Train Epoch: 2 [3840/10296 (37%)]\tLoss: 0.025816\n",
      "Train Epoch: 2 [4480/10296 (43%)]\tLoss: 0.091329\n",
      "Train Epoch: 2 [5120/10296 (50%)]\tLoss: 0.017771\n",
      "Train Epoch: 2 [5760/10296 (56%)]\tLoss: 0.117191\n",
      "Train Epoch: 2 [6400/10296 (62%)]\tLoss: 0.091837\n",
      "Train Epoch: 2 [7040/10296 (68%)]\tLoss: 0.038480\n",
      "Train Epoch: 2 [7680/10296 (75%)]\tLoss: 0.296552\n",
      "Train Epoch: 2 [8320/10296 (81%)]\tLoss: 0.078209\n",
      "Train Epoch: 2 [8960/10296 (87%)]\tLoss: 0.058362\n",
      "Train Epoch: 2 [9600/10296 (93%)]\tLoss: 0.072212\n",
      "Train Epoch: 2 [8960/10296 (99%)]\tLoss: 0.055173\n",
      "Train Epoch: 3 [0/10296 (0%)]\tLoss: 0.095533\n",
      "Train Epoch: 3 [640/10296 (6%)]\tLoss: 0.118345\n",
      "Train Epoch: 3 [1280/10296 (12%)]\tLoss: 0.025064\n",
      "Train Epoch: 3 [1920/10296 (19%)]\tLoss: 0.150874\n",
      "Train Epoch: 3 [2560/10296 (25%)]\tLoss: 0.004726\n",
      "Train Epoch: 3 [3200/10296 (31%)]\tLoss: 0.062364\n",
      "Train Epoch: 3 [3840/10296 (37%)]\tLoss: 0.151260\n",
      "Train Epoch: 3 [4480/10296 (43%)]\tLoss: 0.075678\n",
      "Train Epoch: 3 [5120/10296 (50%)]\tLoss: 0.039578\n",
      "Train Epoch: 3 [5760/10296 (56%)]\tLoss: 0.111371\n",
      "Train Epoch: 3 [6400/10296 (62%)]\tLoss: 0.103280\n",
      "Train Epoch: 3 [7040/10296 (68%)]\tLoss: 0.070495\n",
      "Train Epoch: 3 [7680/10296 (75%)]\tLoss: 0.104895\n",
      "Train Epoch: 3 [8320/10296 (81%)]\tLoss: 0.045979\n",
      "Train Epoch: 3 [8960/10296 (87%)]\tLoss: 0.051382\n",
      "Train Epoch: 3 [9600/10296 (93%)]\tLoss: 0.227205\n",
      "Train Epoch: 3 [8960/10296 (99%)]\tLoss: 0.060582\n",
      "Train Epoch: 4 [0/10296 (0%)]\tLoss: 0.023738\n",
      "Train Epoch: 4 [640/10296 (6%)]\tLoss: 0.020041\n",
      "Train Epoch: 4 [1280/10296 (12%)]\tLoss: 0.036804\n",
      "Train Epoch: 4 [1920/10296 (19%)]\tLoss: 0.155627\n",
      "Train Epoch: 4 [2560/10296 (25%)]\tLoss: 0.158554\n",
      "Train Epoch: 4 [3200/10296 (31%)]\tLoss: 0.119074\n",
      "Train Epoch: 4 [3840/10296 (37%)]\tLoss: 0.010123\n",
      "Train Epoch: 4 [4480/10296 (43%)]\tLoss: 0.225846\n",
      "Train Epoch: 4 [5120/10296 (50%)]\tLoss: 0.024536\n",
      "Train Epoch: 4 [5760/10296 (56%)]\tLoss: 0.079484\n",
      "Train Epoch: 4 [6400/10296 (62%)]\tLoss: 0.012763\n",
      "Train Epoch: 4 [7040/10296 (68%)]\tLoss: 0.102594\n",
      "Train Epoch: 4 [7680/10296 (75%)]\tLoss: 0.080565\n",
      "Train Epoch: 4 [8320/10296 (81%)]\tLoss: 0.029862\n",
      "Train Epoch: 4 [8960/10296 (87%)]\tLoss: 0.066736\n",
      "Train Epoch: 4 [9600/10296 (93%)]\tLoss: 0.011360\n",
      "Train Epoch: 4 [8960/10296 (99%)]\tLoss: 0.016253\n",
      "Train Epoch: 5 [0/10296 (0%)]\tLoss: 0.245060\n",
      "Train Epoch: 5 [640/10296 (6%)]\tLoss: 0.056378\n",
      "Train Epoch: 5 [1280/10296 (12%)]\tLoss: 0.102268\n",
      "Train Epoch: 5 [1920/10296 (19%)]\tLoss: 0.113459\n",
      "Train Epoch: 5 [2560/10296 (25%)]\tLoss: 0.020667\n",
      "Train Epoch: 5 [3200/10296 (31%)]\tLoss: 0.012965\n",
      "Train Epoch: 5 [3840/10296 (37%)]\tLoss: 0.081377\n",
      "Train Epoch: 5 [4480/10296 (43%)]\tLoss: 0.035295\n",
      "Train Epoch: 5 [5120/10296 (50%)]\tLoss: 0.047416\n",
      "Train Epoch: 5 [5760/10296 (56%)]\tLoss: 0.024507\n",
      "Train Epoch: 5 [6400/10296 (62%)]\tLoss: 0.030754\n",
      "Train Epoch: 5 [7040/10296 (68%)]\tLoss: 0.086305\n",
      "Train Epoch: 5 [7680/10296 (75%)]\tLoss: 0.083496\n",
      "Train Epoch: 5 [8320/10296 (81%)]\tLoss: 0.004345\n",
      "Train Epoch: 5 [8960/10296 (87%)]\tLoss: 0.036284\n",
      "Train Epoch: 5 [9600/10296 (93%)]\tLoss: 0.100283\n",
      "Train Epoch: 5 [8960/10296 (99%)]\tLoss: 0.047575\n",
      "Train Epoch: 6 [0/10296 (0%)]\tLoss: 0.020415\n",
      "Train Epoch: 6 [640/10296 (6%)]\tLoss: 0.098531\n",
      "Train Epoch: 6 [1280/10296 (12%)]\tLoss: 0.012234\n",
      "Train Epoch: 6 [1920/10296 (19%)]\tLoss: 0.014920\n",
      "Train Epoch: 6 [2560/10296 (25%)]\tLoss: 0.114242\n",
      "Train Epoch: 6 [3200/10296 (31%)]\tLoss: 0.043616\n",
      "Train Epoch: 6 [3840/10296 (37%)]\tLoss: 0.032477\n",
      "Train Epoch: 6 [4480/10296 (43%)]\tLoss: 0.182978\n",
      "Train Epoch: 6 [5120/10296 (50%)]\tLoss: 0.024425\n",
      "Train Epoch: 6 [5760/10296 (56%)]\tLoss: 0.046392\n",
      "Train Epoch: 6 [6400/10296 (62%)]\tLoss: 0.180494\n",
      "Train Epoch: 6 [7040/10296 (68%)]\tLoss: 0.062175\n",
      "Train Epoch: 6 [7680/10296 (75%)]\tLoss: 0.068086\n",
      "Train Epoch: 6 [8320/10296 (81%)]\tLoss: 0.059577\n",
      "Train Epoch: 6 [8960/10296 (87%)]\tLoss: 0.251457\n",
      "Train Epoch: 6 [9600/10296 (93%)]\tLoss: 0.056843\n",
      "Train Epoch: 6 [8960/10296 (99%)]\tLoss: 0.027349\n",
      "Train Epoch: 7 [0/10296 (0%)]\tLoss: 0.146431\n",
      "Train Epoch: 7 [640/10296 (6%)]\tLoss: 0.062509\n",
      "Train Epoch: 7 [1280/10296 (12%)]\tLoss: 0.110047\n",
      "Train Epoch: 7 [1920/10296 (19%)]\tLoss: 0.066442\n",
      "Train Epoch: 7 [2560/10296 (25%)]\tLoss: 0.042907\n",
      "Train Epoch: 7 [3200/10296 (31%)]\tLoss: 0.066648\n",
      "Train Epoch: 7 [3840/10296 (37%)]\tLoss: 0.084273\n",
      "Train Epoch: 7 [4480/10296 (43%)]\tLoss: 0.020565\n",
      "Train Epoch: 7 [5120/10296 (50%)]\tLoss: 0.029679\n",
      "Train Epoch: 7 [5760/10296 (56%)]\tLoss: 0.022927\n",
      "Train Epoch: 7 [6400/10296 (62%)]\tLoss: 0.016498\n",
      "Train Epoch: 7 [7040/10296 (68%)]\tLoss: 0.034481\n",
      "Train Epoch: 7 [7680/10296 (75%)]\tLoss: 0.059535\n",
      "Train Epoch: 7 [8320/10296 (81%)]\tLoss: 0.062394\n",
      "Train Epoch: 7 [8960/10296 (87%)]\tLoss: 0.048734\n",
      "Train Epoch: 7 [9600/10296 (93%)]\tLoss: 0.114772\n",
      "Train Epoch: 7 [8960/10296 (99%)]\tLoss: 0.022997\n",
      "Train Epoch: 8 [0/10296 (0%)]\tLoss: 0.072751\n",
      "Train Epoch: 8 [640/10296 (6%)]\tLoss: 0.036774\n",
      "Train Epoch: 8 [1280/10296 (12%)]\tLoss: 0.017757\n",
      "Train Epoch: 8 [1920/10296 (19%)]\tLoss: 0.044236\n",
      "Train Epoch: 8 [2560/10296 (25%)]\tLoss: 0.078999\n",
      "Train Epoch: 8 [3200/10296 (31%)]\tLoss: 0.073788\n",
      "Train Epoch: 8 [3840/10296 (37%)]\tLoss: 0.065314\n",
      "Train Epoch: 8 [4480/10296 (43%)]\tLoss: 0.085749\n",
      "Train Epoch: 8 [5120/10296 (50%)]\tLoss: 0.017907\n",
      "Train Epoch: 8 [5760/10296 (56%)]\tLoss: 0.082937\n",
      "Train Epoch: 8 [6400/10296 (62%)]\tLoss: 0.055103\n",
      "Train Epoch: 8 [7040/10296 (68%)]\tLoss: 0.003702\n",
      "Train Epoch: 8 [7680/10296 (75%)]\tLoss: 0.112191\n",
      "Train Epoch: 8 [8320/10296 (81%)]\tLoss: 0.065539\n",
      "Train Epoch: 8 [8960/10296 (87%)]\tLoss: 0.043388\n",
      "Train Epoch: 8 [9600/10296 (93%)]\tLoss: 0.073494\n",
      "Train Epoch: 8 [8960/10296 (99%)]\tLoss: 0.197914\n",
      "Train Epoch: 9 [0/10296 (0%)]\tLoss: 0.075264\n",
      "Train Epoch: 9 [640/10296 (6%)]\tLoss: 0.040651\n",
      "Train Epoch: 9 [1280/10296 (12%)]\tLoss: 0.063740\n",
      "Train Epoch: 9 [1920/10296 (19%)]\tLoss: 0.005149\n",
      "Train Epoch: 9 [2560/10296 (25%)]\tLoss: 0.083426\n",
      "Train Epoch: 9 [3200/10296 (31%)]\tLoss: 0.040030\n",
      "Train Epoch: 9 [3840/10296 (37%)]\tLoss: 0.038833\n",
      "Train Epoch: 9 [4480/10296 (43%)]\tLoss: 0.030791\n",
      "Train Epoch: 9 [5120/10296 (50%)]\tLoss: 0.075329\n",
      "Train Epoch: 9 [5760/10296 (56%)]\tLoss: 0.069900\n",
      "Train Epoch: 9 [6400/10296 (62%)]\tLoss: 0.054092\n",
      "Train Epoch: 9 [7040/10296 (68%)]\tLoss: 0.006995\n",
      "Train Epoch: 9 [7680/10296 (75%)]\tLoss: 0.069843\n",
      "Train Epoch: 9 [8320/10296 (81%)]\tLoss: 0.081359\n",
      "Train Epoch: 9 [8960/10296 (87%)]\tLoss: 0.041362\n",
      "Train Epoch: 9 [9600/10296 (93%)]\tLoss: 0.016959\n",
      "Train Epoch: 9 [8960/10296 (99%)]\tLoss: 0.288778\n",
      "Train Epoch: 10 [0/10296 (0%)]\tLoss: 0.187669\n",
      "Train Epoch: 10 [640/10296 (6%)]\tLoss: 0.117714\n",
      "Train Epoch: 10 [1280/10296 (12%)]\tLoss: 0.077563\n",
      "Train Epoch: 10 [1920/10296 (19%)]\tLoss: 0.164341\n",
      "Train Epoch: 10 [2560/10296 (25%)]\tLoss: 0.021058\n",
      "Train Epoch: 10 [3200/10296 (31%)]\tLoss: 0.008539\n",
      "Train Epoch: 10 [3840/10296 (37%)]\tLoss: 0.015984\n",
      "Train Epoch: 10 [4480/10296 (43%)]\tLoss: 0.019181\n",
      "Train Epoch: 10 [5120/10296 (50%)]\tLoss: 0.116436\n",
      "Train Epoch: 10 [5760/10296 (56%)]\tLoss: 0.028397\n",
      "Train Epoch: 10 [6400/10296 (62%)]\tLoss: 0.034567\n",
      "Train Epoch: 10 [7040/10296 (68%)]\tLoss: 0.021992\n",
      "Train Epoch: 10 [7680/10296 (75%)]\tLoss: 0.032371\n",
      "Train Epoch: 10 [8320/10296 (81%)]\tLoss: 0.027135\n",
      "Train Epoch: 10 [8960/10296 (87%)]\tLoss: 0.021075\n",
      "Train Epoch: 10 [9600/10296 (93%)]\tLoss: 0.008559\n",
      "Train Epoch: 10 [8960/10296 (99%)]\tLoss: 0.058719\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 0.207658\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 0.049113\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 0.066362\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 0.051526\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 0.045190\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 0.068221\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 0.072268\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 0.047267\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 0.046581\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 0.072969\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 0.045184\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 0.048304\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 0.008932\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 0.023236\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 0.031196\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 0.184836\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 0.076253\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.069215\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.044357\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.053291\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.014858\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.043127\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.068161\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.105505\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.070707\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.025332\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.104156\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.033318\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.090207\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.020978\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.021129\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.059880\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.014438\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.080466\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.035795\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.168788\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.214573\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.090599\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.025547\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.063487\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.255681\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.036809\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.038901\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.010550\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.025687\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.052525\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.065756\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.062383\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.048417\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.021421\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.039491\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.084067\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.150564\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.037260\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.006262\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.016301\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.203102\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.095465\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.083889\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.089398\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.055904\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.058391\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.038924\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.067163\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.014533\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.037439\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.009502\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.019063\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.075224\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.091683\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.012330\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.046545\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.278869\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.030021\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.072449\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.065886\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.116344\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.047342\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.022599\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.086674\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.040378\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.029368\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.005778\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.015035\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.020174\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.083543\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.063741\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.045671\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.016965\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.048981\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.063688\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.073414\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.042748\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.032412\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.039348\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.037915\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.079001\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.034675\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.029806\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.018936\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.032865\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.070178\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.004146\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.171073\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.008627\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.058654\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.154506\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.007481\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.018383\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.090681\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.093610\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.041155\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.022613\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.046911\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.072909\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.050182\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.025325\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.073267\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.022717\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.031658\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.033712\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.023911\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.016951\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.025405\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.036169\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.127931\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.051429\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.031911\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.053277\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.035449\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.032693\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.025838\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.038766\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.067610\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.078460\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.189627\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.018704\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.019066\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.049398\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.037157\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.033929\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.058037\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.074001\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.029571\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.024532\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.064085\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.055136\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.141121\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.142958\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.026515\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.272111\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.042551\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.046064\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.019977\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.045934\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.094256\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.033963\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.108418\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.073732\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.015862\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/3910 (0%)]\tLoss: 0.072250\n",
      "Train Epoch: 1 [640/3910 (16%)]\tLoss: 0.151584\n",
      "Train Epoch: 1 [1280/3910 (32%)]\tLoss: 0.120561\n",
      "Train Epoch: 1 [1920/3910 (48%)]\tLoss: 0.027716\n",
      "Train Epoch: 1 [2560/3910 (65%)]\tLoss: 0.084300\n",
      "Train Epoch: 1 [3200/3910 (81%)]\tLoss: 0.085005\n",
      "Train Epoch: 1 [3840/3910 (97%)]\tLoss: 0.054012\n",
      "Train Epoch: 2 [0/3910 (0%)]\tLoss: 0.097100\n",
      "Train Epoch: 2 [640/3910 (16%)]\tLoss: 0.115863\n",
      "Train Epoch: 2 [1280/3910 (32%)]\tLoss: 0.005842\n",
      "Train Epoch: 2 [1920/3910 (48%)]\tLoss: 0.060038\n",
      "Train Epoch: 2 [2560/3910 (65%)]\tLoss: 0.194764\n",
      "Train Epoch: 2 [3200/3910 (81%)]\tLoss: 0.127002\n",
      "Train Epoch: 2 [3840/3910 (97%)]\tLoss: 0.151715\n",
      "Train Epoch: 3 [0/3910 (0%)]\tLoss: 0.025177\n",
      "Train Epoch: 3 [640/3910 (16%)]\tLoss: 0.123023\n",
      "Train Epoch: 3 [1280/3910 (32%)]\tLoss: 0.101739\n",
      "Train Epoch: 3 [1920/3910 (48%)]\tLoss: 0.040905\n",
      "Train Epoch: 3 [2560/3910 (65%)]\tLoss: 0.060638\n",
      "Train Epoch: 3 [3200/3910 (81%)]\tLoss: 0.074111\n",
      "Train Epoch: 3 [3840/3910 (97%)]\tLoss: 0.057072\n",
      "Train Epoch: 4 [0/3910 (0%)]\tLoss: 0.041359\n",
      "Train Epoch: 4 [640/3910 (16%)]\tLoss: 0.005099\n",
      "Train Epoch: 4 [1280/3910 (32%)]\tLoss: 0.177138\n",
      "Train Epoch: 4 [1920/3910 (48%)]\tLoss: 0.082712\n",
      "Train Epoch: 4 [2560/3910 (65%)]\tLoss: 0.070786\n",
      "Train Epoch: 4 [3200/3910 (81%)]\tLoss: 0.014221\n",
      "Train Epoch: 4 [3840/3910 (97%)]\tLoss: 0.177449\n",
      "Train Epoch: 5 [0/3910 (0%)]\tLoss: 0.016017\n",
      "Train Epoch: 5 [640/3910 (16%)]\tLoss: 0.019849\n",
      "Train Epoch: 5 [1280/3910 (32%)]\tLoss: 0.006331\n",
      "Train Epoch: 5 [1920/3910 (48%)]\tLoss: 0.040669\n",
      "Train Epoch: 5 [2560/3910 (65%)]\tLoss: 0.162439\n",
      "Train Epoch: 5 [3200/3910 (81%)]\tLoss: 0.093702\n",
      "Train Epoch: 5 [3840/3910 (97%)]\tLoss: 0.046177\n",
      "Train Epoch: 6 [0/3910 (0%)]\tLoss: 0.004986\n",
      "Train Epoch: 6 [640/3910 (16%)]\tLoss: 0.032299\n",
      "Train Epoch: 6 [1280/3910 (32%)]\tLoss: 0.015288\n",
      "Train Epoch: 6 [1920/3910 (48%)]\tLoss: 0.035267\n",
      "Train Epoch: 6 [2560/3910 (65%)]\tLoss: 0.100470\n",
      "Train Epoch: 6 [3200/3910 (81%)]\tLoss: 0.104023\n",
      "Train Epoch: 6 [3840/3910 (97%)]\tLoss: 0.101335\n",
      "Train Epoch: 7 [0/3910 (0%)]\tLoss: 0.016194\n",
      "Train Epoch: 7 [640/3910 (16%)]\tLoss: 0.066465\n",
      "Train Epoch: 7 [1280/3910 (32%)]\tLoss: 0.053471\n",
      "Train Epoch: 7 [1920/3910 (48%)]\tLoss: 0.061614\n",
      "Train Epoch: 7 [2560/3910 (65%)]\tLoss: 0.024406\n",
      "Train Epoch: 7 [3200/3910 (81%)]\tLoss: 0.044776\n",
      "Train Epoch: 7 [3840/3910 (97%)]\tLoss: 0.098553\n",
      "Train Epoch: 8 [0/3910 (0%)]\tLoss: 0.064666\n",
      "Train Epoch: 8 [640/3910 (16%)]\tLoss: 0.016978\n",
      "Train Epoch: 8 [1280/3910 (32%)]\tLoss: 0.167967\n",
      "Train Epoch: 8 [1920/3910 (48%)]\tLoss: 0.061128\n",
      "Train Epoch: 8 [2560/3910 (65%)]\tLoss: 0.108612\n",
      "Train Epoch: 8 [3200/3910 (81%)]\tLoss: 0.017775\n",
      "Train Epoch: 8 [3840/3910 (97%)]\tLoss: 0.024134\n",
      "Train Epoch: 9 [0/3910 (0%)]\tLoss: 0.139779\n",
      "Train Epoch: 9 [640/3910 (16%)]\tLoss: 0.044474\n",
      "Train Epoch: 9 [1280/3910 (32%)]\tLoss: 0.018950\n",
      "Train Epoch: 9 [1920/3910 (48%)]\tLoss: 0.024529\n",
      "Train Epoch: 9 [2560/3910 (65%)]\tLoss: 0.063209\n",
      "Train Epoch: 9 [3200/3910 (81%)]\tLoss: 0.041268\n",
      "Train Epoch: 9 [3840/3910 (97%)]\tLoss: 0.059502\n",
      "Train Epoch: 10 [0/3910 (0%)]\tLoss: 0.008019\n",
      "Train Epoch: 10 [640/3910 (16%)]\tLoss: 0.105682\n",
      "Train Epoch: 10 [1280/3910 (32%)]\tLoss: 0.088848\n",
      "Train Epoch: 10 [1920/3910 (48%)]\tLoss: 0.065780\n",
      "Train Epoch: 10 [2560/3910 (65%)]\tLoss: 0.101836\n",
      "Train Epoch: 10 [3200/3910 (81%)]\tLoss: 0.061827\n",
      "Train Epoch: 10 [3840/3910 (97%)]\tLoss: 0.261190\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 0.202920\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 0.083879\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 0.102690\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 0.037565\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 0.046433\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 0.142072\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 0.075722\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 0.022990\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 0.085424\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 0.042836\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.012929\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.029121\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 0.067497\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 0.008060\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 0.095692\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.043698\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.125033\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.031614\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.066125\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.041002\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.099946\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.051913\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.004878\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.007994\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.007071\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.037311\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.062636\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.074249\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.102732\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.034498\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.048278\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.124581\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.018925\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.036862\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.037961\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.013165\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.046627\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.004413\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.011942\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.011022\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.012886\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.066948\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.058205\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.004950\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.010215\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.033095\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.107040\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.117956\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.014006\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.013885\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.225736\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.016452\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.070884\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.021338\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.052883\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.004383\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.027630\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.010393\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.036782\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.004585\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.156279\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.027279\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.274403\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.009986\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.011735\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.039307\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.012855\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.002428\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.002848\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.008735\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.053688\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.077171\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.023969\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.022117\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.034555\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.119668\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.074635\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.062185\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.024739\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.019076\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.012484\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.024607\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.015359\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.009593\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.032781\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.035801\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.062029\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.023946\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.007216\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.015512\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.067003\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.092438\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.091017\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.007504\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.010684\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.014099\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.018556\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.021491\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.034690\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.019368\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.007433\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.029823\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.019103\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.070256\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.005656\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.044290\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.016218\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.012962\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.128231\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.015187\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.010739\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.031419\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.143181\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.003607\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.008154\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.029532\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.031301\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.031073\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.007207\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.021891\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/5096 (0%)]\tLoss: 0.140496\n",
      "Train Epoch: 1 [640/5096 (12%)]\tLoss: 0.025012\n",
      "Train Epoch: 1 [1280/5096 (25%)]\tLoss: 0.023736\n",
      "Train Epoch: 1 [1920/5096 (38%)]\tLoss: 0.056454\n",
      "Train Epoch: 1 [2560/5096 (50%)]\tLoss: 0.004753\n",
      "Train Epoch: 1 [3200/5096 (62%)]\tLoss: 0.045719\n",
      "Train Epoch: 1 [3840/5096 (75%)]\tLoss: 0.004644\n",
      "Train Epoch: 1 [4480/5096 (88%)]\tLoss: 0.078902\n",
      "Train Epoch: 2 [0/5096 (0%)]\tLoss: 0.082390\n",
      "Train Epoch: 2 [640/5096 (12%)]\tLoss: 0.011694\n",
      "Train Epoch: 2 [1280/5096 (25%)]\tLoss: 0.005503\n",
      "Train Epoch: 2 [1920/5096 (38%)]\tLoss: 0.131014\n",
      "Train Epoch: 2 [2560/5096 (50%)]\tLoss: 0.071636\n",
      "Train Epoch: 2 [3200/5096 (62%)]\tLoss: 0.014297\n",
      "Train Epoch: 2 [3840/5096 (75%)]\tLoss: 0.044453\n",
      "Train Epoch: 2 [4480/5096 (88%)]\tLoss: 0.029584\n",
      "Train Epoch: 3 [0/5096 (0%)]\tLoss: 0.159278\n",
      "Train Epoch: 3 [640/5096 (12%)]\tLoss: 0.005734\n",
      "Train Epoch: 3 [1280/5096 (25%)]\tLoss: 0.025020\n",
      "Train Epoch: 3 [1920/5096 (38%)]\tLoss: 0.009603\n",
      "Train Epoch: 3 [2560/5096 (50%)]\tLoss: 0.019401\n",
      "Train Epoch: 3 [3200/5096 (62%)]\tLoss: 0.008037\n",
      "Train Epoch: 3 [3840/5096 (75%)]\tLoss: 0.078355\n",
      "Train Epoch: 3 [4480/5096 (88%)]\tLoss: 0.037618\n",
      "Train Epoch: 4 [0/5096 (0%)]\tLoss: 0.022402\n",
      "Train Epoch: 4 [640/5096 (12%)]\tLoss: 0.008839\n",
      "Train Epoch: 4 [1280/5096 (25%)]\tLoss: 0.010066\n",
      "Train Epoch: 4 [1920/5096 (38%)]\tLoss: 0.044295\n",
      "Train Epoch: 4 [2560/5096 (50%)]\tLoss: 0.024030\n",
      "Train Epoch: 4 [3200/5096 (62%)]\tLoss: 0.023399\n",
      "Train Epoch: 4 [3840/5096 (75%)]\tLoss: 0.024396\n",
      "Train Epoch: 4 [4480/5096 (88%)]\tLoss: 0.035895\n",
      "Train Epoch: 5 [0/5096 (0%)]\tLoss: 0.029900\n",
      "Train Epoch: 5 [640/5096 (12%)]\tLoss: 0.006329\n",
      "Train Epoch: 5 [1280/5096 (25%)]\tLoss: 0.006544\n",
      "Train Epoch: 5 [1920/5096 (38%)]\tLoss: 0.016566\n",
      "Train Epoch: 5 [2560/5096 (50%)]\tLoss: 0.029496\n",
      "Train Epoch: 5 [3200/5096 (62%)]\tLoss: 0.012305\n",
      "Train Epoch: 5 [3840/5096 (75%)]\tLoss: 0.025290\n",
      "Train Epoch: 5 [4480/5096 (88%)]\tLoss: 0.003382\n",
      "Train Epoch: 6 [0/5096 (0%)]\tLoss: 0.025822\n",
      "Train Epoch: 6 [640/5096 (12%)]\tLoss: 0.061217\n",
      "Train Epoch: 6 [1280/5096 (25%)]\tLoss: 0.009813\n",
      "Train Epoch: 6 [1920/5096 (38%)]\tLoss: 0.010885\n",
      "Train Epoch: 6 [2560/5096 (50%)]\tLoss: 0.053462\n",
      "Train Epoch: 6 [3200/5096 (62%)]\tLoss: 0.001071\n",
      "Train Epoch: 6 [3840/5096 (75%)]\tLoss: 0.038817\n",
      "Train Epoch: 6 [4480/5096 (88%)]\tLoss: 0.008210\n",
      "Train Epoch: 7 [0/5096 (0%)]\tLoss: 0.047456\n",
      "Train Epoch: 7 [640/5096 (12%)]\tLoss: 0.056787\n",
      "Train Epoch: 7 [1280/5096 (25%)]\tLoss: 0.005299\n",
      "Train Epoch: 7 [1920/5096 (38%)]\tLoss: 0.013639\n",
      "Train Epoch: 7 [2560/5096 (50%)]\tLoss: 0.002756\n",
      "Train Epoch: 7 [3200/5096 (62%)]\tLoss: 0.020286\n",
      "Train Epoch: 7 [3840/5096 (75%)]\tLoss: 0.147653\n",
      "Train Epoch: 7 [4480/5096 (88%)]\tLoss: 0.009576\n",
      "Train Epoch: 8 [0/5096 (0%)]\tLoss: 0.041283\n",
      "Train Epoch: 8 [640/5096 (12%)]\tLoss: 0.027844\n",
      "Train Epoch: 8 [1280/5096 (25%)]\tLoss: 0.025285\n",
      "Train Epoch: 8 [1920/5096 (38%)]\tLoss: 0.049514\n",
      "Train Epoch: 8 [2560/5096 (50%)]\tLoss: 0.011375\n",
      "Train Epoch: 8 [3200/5096 (62%)]\tLoss: 0.006661\n",
      "Train Epoch: 8 [3840/5096 (75%)]\tLoss: 0.114951\n",
      "Train Epoch: 8 [4480/5096 (88%)]\tLoss: 0.109186\n",
      "Train Epoch: 9 [0/5096 (0%)]\tLoss: 0.024066\n",
      "Train Epoch: 9 [640/5096 (12%)]\tLoss: 0.003209\n",
      "Train Epoch: 9 [1280/5096 (25%)]\tLoss: 0.012969\n",
      "Train Epoch: 9 [1920/5096 (38%)]\tLoss: 0.015195\n",
      "Train Epoch: 9 [2560/5096 (50%)]\tLoss: 0.009409\n",
      "Train Epoch: 9 [3200/5096 (62%)]\tLoss: 0.016645\n",
      "Train Epoch: 9 [3840/5096 (75%)]\tLoss: 0.029114\n",
      "Train Epoch: 9 [4480/5096 (88%)]\tLoss: 0.024193\n",
      "Train Epoch: 10 [0/5096 (0%)]\tLoss: 0.009274\n",
      "Train Epoch: 10 [640/5096 (12%)]\tLoss: 0.012035\n",
      "Train Epoch: 10 [1280/5096 (25%)]\tLoss: 0.034906\n",
      "Train Epoch: 10 [1920/5096 (38%)]\tLoss: 0.049147\n",
      "Train Epoch: 10 [2560/5096 (50%)]\tLoss: 0.008553\n",
      "Train Epoch: 10 [3200/5096 (62%)]\tLoss: 0.011694\n",
      "Train Epoch: 10 [3840/5096 (75%)]\tLoss: 0.035625\n",
      "Train Epoch: 10 [4480/5096 (88%)]\tLoss: 0.006671\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6865 (0%)]\tLoss: 0.305328\n",
      "Train Epoch: 1 [640/6865 (9%)]\tLoss: 0.049707\n",
      "Train Epoch: 1 [1280/6865 (19%)]\tLoss: 0.067272\n",
      "Train Epoch: 1 [1920/6865 (28%)]\tLoss: 0.137425\n",
      "Train Epoch: 1 [2560/6865 (37%)]\tLoss: 0.111657\n",
      "Train Epoch: 1 [3200/6865 (46%)]\tLoss: 0.027102\n",
      "Train Epoch: 1 [3840/6865 (56%)]\tLoss: 0.014543\n",
      "Train Epoch: 1 [4480/6865 (65%)]\tLoss: 0.038212\n",
      "Train Epoch: 1 [5120/6865 (74%)]\tLoss: 0.009876\n",
      "Train Epoch: 1 [5760/6865 (83%)]\tLoss: 0.045520\n",
      "Train Epoch: 1 [6400/6865 (93%)]\tLoss: 0.045070\n",
      "Train Epoch: 2 [0/6865 (0%)]\tLoss: 0.019276\n",
      "Train Epoch: 2 [640/6865 (9%)]\tLoss: 0.081576\n",
      "Train Epoch: 2 [1280/6865 (19%)]\tLoss: 0.005364\n",
      "Train Epoch: 2 [1920/6865 (28%)]\tLoss: 0.025344\n",
      "Train Epoch: 2 [2560/6865 (37%)]\tLoss: 0.025892\n",
      "Train Epoch: 2 [3200/6865 (46%)]\tLoss: 0.006648\n",
      "Train Epoch: 2 [3840/6865 (56%)]\tLoss: 0.024588\n",
      "Train Epoch: 2 [4480/6865 (65%)]\tLoss: 0.059048\n",
      "Train Epoch: 2 [5120/6865 (74%)]\tLoss: 0.143877\n",
      "Train Epoch: 2 [5760/6865 (83%)]\tLoss: 0.006456\n",
      "Train Epoch: 2 [6400/6865 (93%)]\tLoss: 0.009470\n",
      "Train Epoch: 3 [0/6865 (0%)]\tLoss: 0.063343\n",
      "Train Epoch: 3 [640/6865 (9%)]\tLoss: 0.023187\n",
      "Train Epoch: 3 [1280/6865 (19%)]\tLoss: 0.109218\n",
      "Train Epoch: 3 [1920/6865 (28%)]\tLoss: 0.019574\n",
      "Train Epoch: 3 [2560/6865 (37%)]\tLoss: 0.048314\n",
      "Train Epoch: 3 [3200/6865 (46%)]\tLoss: 0.112472\n",
      "Train Epoch: 3 [3840/6865 (56%)]\tLoss: 0.011050\n",
      "Train Epoch: 3 [4480/6865 (65%)]\tLoss: 0.059988\n",
      "Train Epoch: 3 [5120/6865 (74%)]\tLoss: 0.040638\n",
      "Train Epoch: 3 [5760/6865 (83%)]\tLoss: 0.005233\n",
      "Train Epoch: 3 [6400/6865 (93%)]\tLoss: 0.075812\n",
      "Train Epoch: 4 [0/6865 (0%)]\tLoss: 0.033616\n",
      "Train Epoch: 4 [640/6865 (9%)]\tLoss: 0.020249\n",
      "Train Epoch: 4 [1280/6865 (19%)]\tLoss: 0.203069\n",
      "Train Epoch: 4 [1920/6865 (28%)]\tLoss: 0.020907\n",
      "Train Epoch: 4 [2560/6865 (37%)]\tLoss: 0.075559\n",
      "Train Epoch: 4 [3200/6865 (46%)]\tLoss: 0.017620\n",
      "Train Epoch: 4 [3840/6865 (56%)]\tLoss: 0.052700\n",
      "Train Epoch: 4 [4480/6865 (65%)]\tLoss: 0.165668\n",
      "Train Epoch: 4 [5120/6865 (74%)]\tLoss: 0.022538\n",
      "Train Epoch: 4 [5760/6865 (83%)]\tLoss: 0.022957\n",
      "Train Epoch: 4 [6400/6865 (93%)]\tLoss: 0.005042\n",
      "Train Epoch: 5 [0/6865 (0%)]\tLoss: 0.056537\n",
      "Train Epoch: 5 [640/6865 (9%)]\tLoss: 0.004549\n",
      "Train Epoch: 5 [1280/6865 (19%)]\tLoss: 0.006286\n",
      "Train Epoch: 5 [1920/6865 (28%)]\tLoss: 0.058213\n",
      "Train Epoch: 5 [2560/6865 (37%)]\tLoss: 0.004473\n",
      "Train Epoch: 5 [3200/6865 (46%)]\tLoss: 0.023333\n",
      "Train Epoch: 5 [3840/6865 (56%)]\tLoss: 0.016076\n",
      "Train Epoch: 5 [4480/6865 (65%)]\tLoss: 0.033544\n",
      "Train Epoch: 5 [5120/6865 (74%)]\tLoss: 0.012716\n",
      "Train Epoch: 5 [5760/6865 (83%)]\tLoss: 0.028748\n",
      "Train Epoch: 5 [6400/6865 (93%)]\tLoss: 0.043082\n",
      "Train Epoch: 6 [0/6865 (0%)]\tLoss: 0.202432\n",
      "Train Epoch: 6 [640/6865 (9%)]\tLoss: 0.144932\n",
      "Train Epoch: 6 [1280/6865 (19%)]\tLoss: 0.026228\n",
      "Train Epoch: 6 [1920/6865 (28%)]\tLoss: 0.118250\n",
      "Train Epoch: 6 [2560/6865 (37%)]\tLoss: 0.013602\n",
      "Train Epoch: 6 [3200/6865 (46%)]\tLoss: 0.056796\n",
      "Train Epoch: 6 [3840/6865 (56%)]\tLoss: 0.008928\n",
      "Train Epoch: 6 [4480/6865 (65%)]\tLoss: 0.012130\n",
      "Train Epoch: 6 [5120/6865 (74%)]\tLoss: 0.012595\n",
      "Train Epoch: 6 [5760/6865 (83%)]\tLoss: 0.035222\n",
      "Train Epoch: 6 [6400/6865 (93%)]\tLoss: 0.057594\n",
      "Train Epoch: 7 [0/6865 (0%)]\tLoss: 0.003282\n",
      "Train Epoch: 7 [640/6865 (9%)]\tLoss: 0.067598\n",
      "Train Epoch: 7 [1280/6865 (19%)]\tLoss: 0.014895\n",
      "Train Epoch: 7 [1920/6865 (28%)]\tLoss: 0.017633\n",
      "Train Epoch: 7 [2560/6865 (37%)]\tLoss: 0.013782\n",
      "Train Epoch: 7 [3200/6865 (46%)]\tLoss: 0.010497\n",
      "Train Epoch: 7 [3840/6865 (56%)]\tLoss: 0.008185\n",
      "Train Epoch: 7 [4480/6865 (65%)]\tLoss: 0.064868\n",
      "Train Epoch: 7 [5120/6865 (74%)]\tLoss: 0.012616\n",
      "Train Epoch: 7 [5760/6865 (83%)]\tLoss: 0.029640\n",
      "Train Epoch: 7 [6400/6865 (93%)]\tLoss: 0.010877\n",
      "Train Epoch: 8 [0/6865 (0%)]\tLoss: 0.020599\n",
      "Train Epoch: 8 [640/6865 (9%)]\tLoss: 0.088575\n",
      "Train Epoch: 8 [1280/6865 (19%)]\tLoss: 0.019014\n",
      "Train Epoch: 8 [1920/6865 (28%)]\tLoss: 0.002921\n",
      "Train Epoch: 8 [2560/6865 (37%)]\tLoss: 0.403586\n",
      "Train Epoch: 8 [3200/6865 (46%)]\tLoss: 0.023230\n",
      "Train Epoch: 8 [3840/6865 (56%)]\tLoss: 0.118315\n",
      "Train Epoch: 8 [4480/6865 (65%)]\tLoss: 0.011827\n",
      "Train Epoch: 8 [5120/6865 (74%)]\tLoss: 0.011163\n",
      "Train Epoch: 8 [5760/6865 (83%)]\tLoss: 0.017378\n",
      "Train Epoch: 8 [6400/6865 (93%)]\tLoss: 0.011377\n",
      "Train Epoch: 9 [0/6865 (0%)]\tLoss: 0.007426\n",
      "Train Epoch: 9 [640/6865 (9%)]\tLoss: 0.055390\n",
      "Train Epoch: 9 [1280/6865 (19%)]\tLoss: 0.016238\n",
      "Train Epoch: 9 [1920/6865 (28%)]\tLoss: 0.086960\n",
      "Train Epoch: 9 [2560/6865 (37%)]\tLoss: 0.104992\n",
      "Train Epoch: 9 [3200/6865 (46%)]\tLoss: 0.083869\n",
      "Train Epoch: 9 [3840/6865 (56%)]\tLoss: 0.031419\n",
      "Train Epoch: 9 [4480/6865 (65%)]\tLoss: 0.002887\n",
      "Train Epoch: 9 [5120/6865 (74%)]\tLoss: 0.013557\n",
      "Train Epoch: 9 [5760/6865 (83%)]\tLoss: 0.003209\n",
      "Train Epoch: 9 [6400/6865 (93%)]\tLoss: 0.030182\n",
      "Train Epoch: 10 [0/6865 (0%)]\tLoss: 0.012706\n",
      "Train Epoch: 10 [640/6865 (9%)]\tLoss: 0.014421\n",
      "Train Epoch: 10 [1280/6865 (19%)]\tLoss: 0.084220\n",
      "Train Epoch: 10 [1920/6865 (28%)]\tLoss: 0.160681\n",
      "Train Epoch: 10 [2560/6865 (37%)]\tLoss: 0.001689\n",
      "Train Epoch: 10 [3200/6865 (46%)]\tLoss: 0.003791\n",
      "Train Epoch: 10 [3840/6865 (56%)]\tLoss: 0.036616\n",
      "Train Epoch: 10 [4480/6865 (65%)]\tLoss: 0.021629\n",
      "Train Epoch: 10 [5120/6865 (74%)]\tLoss: 0.068833\n",
      "Train Epoch: 10 [5760/6865 (83%)]\tLoss: 0.078267\n",
      "Train Epoch: 10 [6400/6865 (93%)]\tLoss: 0.031191\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0432, Accuracy: 9848/10000 (98%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 0.065423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 0.058666\n",
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 0.074719\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 0.097163\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 0.151470\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 0.102882\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 0.039011\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 0.055032\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 0.021643\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 0.129004\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 0.069806\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 0.036718\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 0.042264\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 0.030582\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 0.064626\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 0.116058\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 0.083707\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 0.073416\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 0.197532\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 0.054585\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.052257\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 0.153841\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 0.058873\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.050746\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.024968\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 0.155103\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.178916\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 0.062127\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.173370\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.087477\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.023242\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.011303\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.089666\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.108323\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.050689\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.021788\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.021175\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.072117\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.040771\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.126104\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.084037\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.062232\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.023093\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.084334\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.142482\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.029124\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.082463\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.246252\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.054956\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.157366\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.114844\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.010543\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.108121\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.089646\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.187550\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.012126\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.019826\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.078554\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.113546\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.073180\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.046928\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.206115\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.030671\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.064472\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.135247\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.123974\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.012093\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.071849\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.065511\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.011599\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.018805\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.124031\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.088690\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.088831\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.053294\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.097001\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.039651\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.153558\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.078503\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.134565\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.038483\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.021990\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.031756\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.142214\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.095213\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.020621\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.054671\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.021699\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.215173\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.023815\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.036690\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.029736\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.057935\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.005290\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.023853\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.119513\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.007903\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.051511\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.032284\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.069094\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.229462\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.024144\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.028991\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.038742\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.014158\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.024325\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.218285\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.139101\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 0.047754\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.022854\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.068603\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.034231\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.038392\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.065296\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.052019\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.042940\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.020547\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.150409\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.107733\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.117651\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.017810\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.015189\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.089420\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.005140\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.097176\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.043579\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.036514\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.044177\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.034170\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.025784\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.078509\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.037235\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.078106\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.034247\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.169428\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.052775\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.029496\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.050876\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.085817\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.022383\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.110704\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.054838\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.029953\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.004500\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.062510\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.002834\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.013275\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.105783\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.034894\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.031412\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.027687\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.100095\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.020446\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.027093\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.004402\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.089793\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.093164\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.094264\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.112278\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.036237\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.017182\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.026529\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.093606\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.048940\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.015785\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.019592\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.022927\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.177583\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.105782\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.035984\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.032625\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.049351\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.059520\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.033809\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.005448\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.236106\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.037318\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.153764\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.040086\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.096418\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/5110 (0%)]\tLoss: 0.258793\n",
      "Train Epoch: 1 [640/5110 (12%)]\tLoss: 0.149756\n",
      "Train Epoch: 1 [1280/5110 (25%)]\tLoss: 0.106073\n",
      "Train Epoch: 1 [1920/5110 (38%)]\tLoss: 0.064931\n",
      "Train Epoch: 1 [2560/5110 (50%)]\tLoss: 0.192574\n",
      "Train Epoch: 1 [3200/5110 (62%)]\tLoss: 0.015918\n",
      "Train Epoch: 1 [3840/5110 (75%)]\tLoss: 0.084296\n",
      "Train Epoch: 1 [4480/5110 (88%)]\tLoss: 0.172433\n",
      "Train Epoch: 2 [0/5110 (0%)]\tLoss: 0.092669\n",
      "Train Epoch: 2 [640/5110 (12%)]\tLoss: 0.038142\n",
      "Train Epoch: 2 [1280/5110 (25%)]\tLoss: 0.005880\n",
      "Train Epoch: 2 [1920/5110 (38%)]\tLoss: 0.102007\n",
      "Train Epoch: 2 [2560/5110 (50%)]\tLoss: 0.007332\n",
      "Train Epoch: 2 [3200/5110 (62%)]\tLoss: 0.141302\n",
      "Train Epoch: 2 [3840/5110 (75%)]\tLoss: 0.088953\n",
      "Train Epoch: 2 [4480/5110 (88%)]\tLoss: 0.020605\n",
      "Train Epoch: 3 [0/5110 (0%)]\tLoss: 0.069421\n",
      "Train Epoch: 3 [640/5110 (12%)]\tLoss: 0.015132\n",
      "Train Epoch: 3 [1280/5110 (25%)]\tLoss: 0.073837\n",
      "Train Epoch: 3 [1920/5110 (38%)]\tLoss: 0.018021\n",
      "Train Epoch: 3 [2560/5110 (50%)]\tLoss: 0.058900\n",
      "Train Epoch: 3 [3200/5110 (62%)]\tLoss: 0.066133\n",
      "Train Epoch: 3 [3840/5110 (75%)]\tLoss: 0.160493\n",
      "Train Epoch: 3 [4480/5110 (88%)]\tLoss: 0.057397\n",
      "Train Epoch: 4 [0/5110 (0%)]\tLoss: 0.074848\n",
      "Train Epoch: 4 [640/5110 (12%)]\tLoss: 0.121413\n",
      "Train Epoch: 4 [1280/5110 (25%)]\tLoss: 0.057296\n",
      "Train Epoch: 4 [1920/5110 (38%)]\tLoss: 0.022392\n",
      "Train Epoch: 4 [2560/5110 (50%)]\tLoss: 0.119485\n",
      "Train Epoch: 4 [3200/5110 (62%)]\tLoss: 0.004548\n",
      "Train Epoch: 4 [3840/5110 (75%)]\tLoss: 0.181094\n",
      "Train Epoch: 4 [4480/5110 (88%)]\tLoss: 0.054409\n",
      "Train Epoch: 5 [0/5110 (0%)]\tLoss: 0.210809\n",
      "Train Epoch: 5 [640/5110 (12%)]\tLoss: 0.027685\n",
      "Train Epoch: 5 [1280/5110 (25%)]\tLoss: 0.049447\n",
      "Train Epoch: 5 [1920/5110 (38%)]\tLoss: 0.035908\n",
      "Train Epoch: 5 [2560/5110 (50%)]\tLoss: 0.053091\n",
      "Train Epoch: 5 [3200/5110 (62%)]\tLoss: 0.105586\n",
      "Train Epoch: 5 [3840/5110 (75%)]\tLoss: 0.028120\n",
      "Train Epoch: 5 [4480/5110 (88%)]\tLoss: 0.037963\n",
      "Train Epoch: 6 [0/5110 (0%)]\tLoss: 0.096459\n",
      "Train Epoch: 6 [640/5110 (12%)]\tLoss: 0.054785\n",
      "Train Epoch: 6 [1280/5110 (25%)]\tLoss: 0.009561\n",
      "Train Epoch: 6 [1920/5110 (38%)]\tLoss: 0.081446\n",
      "Train Epoch: 6 [2560/5110 (50%)]\tLoss: 0.063075\n",
      "Train Epoch: 6 [3200/5110 (62%)]\tLoss: 0.029545\n",
      "Train Epoch: 6 [3840/5110 (75%)]\tLoss: 0.072747\n",
      "Train Epoch: 6 [4480/5110 (88%)]\tLoss: 0.010341\n",
      "Train Epoch: 7 [0/5110 (0%)]\tLoss: 0.028628\n",
      "Train Epoch: 7 [640/5110 (12%)]\tLoss: 0.014944\n",
      "Train Epoch: 7 [1280/5110 (25%)]\tLoss: 0.088470\n",
      "Train Epoch: 7 [1920/5110 (38%)]\tLoss: 0.060373\n",
      "Train Epoch: 7 [2560/5110 (50%)]\tLoss: 0.016617\n",
      "Train Epoch: 7 [3200/5110 (62%)]\tLoss: 0.098807\n",
      "Train Epoch: 7 [3840/5110 (75%)]\tLoss: 0.039910\n",
      "Train Epoch: 7 [4480/5110 (88%)]\tLoss: 0.018721\n",
      "Train Epoch: 8 [0/5110 (0%)]\tLoss: 0.011576\n",
      "Train Epoch: 8 [640/5110 (12%)]\tLoss: 0.022386\n",
      "Train Epoch: 8 [1280/5110 (25%)]\tLoss: 0.019380\n",
      "Train Epoch: 8 [1920/5110 (38%)]\tLoss: 0.041210\n",
      "Train Epoch: 8 [2560/5110 (50%)]\tLoss: 0.106690\n",
      "Train Epoch: 8 [3200/5110 (62%)]\tLoss: 0.085220\n",
      "Train Epoch: 8 [3840/5110 (75%)]\tLoss: 0.038775\n",
      "Train Epoch: 8 [4480/5110 (88%)]\tLoss: 0.002142\n",
      "Train Epoch: 9 [0/5110 (0%)]\tLoss: 0.011669\n",
      "Train Epoch: 9 [640/5110 (12%)]\tLoss: 0.063428\n",
      "Train Epoch: 9 [1280/5110 (25%)]\tLoss: 0.023059\n",
      "Train Epoch: 9 [1920/5110 (38%)]\tLoss: 0.079222\n",
      "Train Epoch: 9 [2560/5110 (50%)]\tLoss: 0.069216\n",
      "Train Epoch: 9 [3200/5110 (62%)]\tLoss: 0.016769\n",
      "Train Epoch: 9 [3840/5110 (75%)]\tLoss: 0.016335\n",
      "Train Epoch: 9 [4480/5110 (88%)]\tLoss: 0.024977\n",
      "Train Epoch: 10 [0/5110 (0%)]\tLoss: 0.017626\n",
      "Train Epoch: 10 [640/5110 (12%)]\tLoss: 0.036449\n",
      "Train Epoch: 10 [1280/5110 (25%)]\tLoss: 0.115098\n",
      "Train Epoch: 10 [1920/5110 (38%)]\tLoss: 0.044777\n",
      "Train Epoch: 10 [2560/5110 (50%)]\tLoss: 0.086639\n",
      "Train Epoch: 10 [3200/5110 (62%)]\tLoss: 0.034448\n",
      "Train Epoch: 10 [3840/5110 (75%)]\tLoss: 0.016951\n",
      "Train Epoch: 10 [4480/5110 (88%)]\tLoss: 0.031324\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/10296 (0%)]\tLoss: 0.143863\n",
      "Train Epoch: 1 [640/10296 (6%)]\tLoss: 0.059497\n",
      "Train Epoch: 1 [1280/10296 (12%)]\tLoss: 0.175326\n",
      "Train Epoch: 1 [1920/10296 (19%)]\tLoss: 0.038022\n",
      "Train Epoch: 1 [2560/10296 (25%)]\tLoss: 0.056900\n",
      "Train Epoch: 1 [3200/10296 (31%)]\tLoss: 0.066539\n",
      "Train Epoch: 1 [3840/10296 (37%)]\tLoss: 0.028427\n",
      "Train Epoch: 1 [4480/10296 (43%)]\tLoss: 0.102001\n",
      "Train Epoch: 1 [5120/10296 (50%)]\tLoss: 0.144271\n",
      "Train Epoch: 1 [5760/10296 (56%)]\tLoss: 0.252958\n",
      "Train Epoch: 1 [6400/10296 (62%)]\tLoss: 0.092739\n",
      "Train Epoch: 1 [7040/10296 (68%)]\tLoss: 0.036791\n",
      "Train Epoch: 1 [7680/10296 (75%)]\tLoss: 0.145263\n",
      "Train Epoch: 1 [8320/10296 (81%)]\tLoss: 0.053544\n",
      "Train Epoch: 1 [8960/10296 (87%)]\tLoss: 0.033819\n",
      "Train Epoch: 1 [9600/10296 (93%)]\tLoss: 0.078464\n",
      "Train Epoch: 1 [8960/10296 (99%)]\tLoss: 0.055421\n",
      "Train Epoch: 2 [0/10296 (0%)]\tLoss: 0.090208\n",
      "Train Epoch: 2 [640/10296 (6%)]\tLoss: 0.050662\n",
      "Train Epoch: 2 [1280/10296 (12%)]\tLoss: 0.102846\n",
      "Train Epoch: 2 [1920/10296 (19%)]\tLoss: 0.038124\n",
      "Train Epoch: 2 [2560/10296 (25%)]\tLoss: 0.083950\n",
      "Train Epoch: 2 [3200/10296 (31%)]\tLoss: 0.086152\n",
      "Train Epoch: 2 [3840/10296 (37%)]\tLoss: 0.089216\n",
      "Train Epoch: 2 [4480/10296 (43%)]\tLoss: 0.040108\n",
      "Train Epoch: 2 [5120/10296 (50%)]\tLoss: 0.143331\n",
      "Train Epoch: 2 [5760/10296 (56%)]\tLoss: 0.119604\n",
      "Train Epoch: 2 [6400/10296 (62%)]\tLoss: 0.034799\n",
      "Train Epoch: 2 [7040/10296 (68%)]\tLoss: 0.083463\n",
      "Train Epoch: 2 [7680/10296 (75%)]\tLoss: 0.173492\n",
      "Train Epoch: 2 [8320/10296 (81%)]\tLoss: 0.133242\n",
      "Train Epoch: 2 [8960/10296 (87%)]\tLoss: 0.066020\n",
      "Train Epoch: 2 [9600/10296 (93%)]\tLoss: 0.044531\n",
      "Train Epoch: 2 [8960/10296 (99%)]\tLoss: 0.165093\n",
      "Train Epoch: 3 [0/10296 (0%)]\tLoss: 0.088520\n",
      "Train Epoch: 3 [640/10296 (6%)]\tLoss: 0.030402\n",
      "Train Epoch: 3 [1280/10296 (12%)]\tLoss: 0.087425\n",
      "Train Epoch: 3 [1920/10296 (19%)]\tLoss: 0.147634\n",
      "Train Epoch: 3 [2560/10296 (25%)]\tLoss: 0.046152\n",
      "Train Epoch: 3 [3200/10296 (31%)]\tLoss: 0.064909\n",
      "Train Epoch: 3 [3840/10296 (37%)]\tLoss: 0.008655\n",
      "Train Epoch: 3 [4480/10296 (43%)]\tLoss: 0.074593\n",
      "Train Epoch: 3 [5120/10296 (50%)]\tLoss: 0.039852\n",
      "Train Epoch: 3 [5760/10296 (56%)]\tLoss: 0.014845\n",
      "Train Epoch: 3 [6400/10296 (62%)]\tLoss: 0.065258\n",
      "Train Epoch: 3 [7040/10296 (68%)]\tLoss: 0.010311\n",
      "Train Epoch: 3 [7680/10296 (75%)]\tLoss: 0.030776\n",
      "Train Epoch: 3 [8320/10296 (81%)]\tLoss: 0.070617\n",
      "Train Epoch: 3 [8960/10296 (87%)]\tLoss: 0.066193\n",
      "Train Epoch: 3 [9600/10296 (93%)]\tLoss: 0.008283\n",
      "Train Epoch: 3 [8960/10296 (99%)]\tLoss: 0.051239\n",
      "Train Epoch: 4 [0/10296 (0%)]\tLoss: 0.104863\n",
      "Train Epoch: 4 [640/10296 (6%)]\tLoss: 0.080302\n",
      "Train Epoch: 4 [1280/10296 (12%)]\tLoss: 0.045025\n",
      "Train Epoch: 4 [1920/10296 (19%)]\tLoss: 0.079362\n",
      "Train Epoch: 4 [2560/10296 (25%)]\tLoss: 0.098384\n",
      "Train Epoch: 4 [3200/10296 (31%)]\tLoss: 0.051672\n",
      "Train Epoch: 4 [3840/10296 (37%)]\tLoss: 0.061051\n",
      "Train Epoch: 4 [4480/10296 (43%)]\tLoss: 0.019681\n",
      "Train Epoch: 4 [5120/10296 (50%)]\tLoss: 0.063788\n",
      "Train Epoch: 4 [5760/10296 (56%)]\tLoss: 0.015833\n",
      "Train Epoch: 4 [6400/10296 (62%)]\tLoss: 0.072862\n",
      "Train Epoch: 4 [7040/10296 (68%)]\tLoss: 0.049796\n",
      "Train Epoch: 4 [7680/10296 (75%)]\tLoss: 0.045834\n",
      "Train Epoch: 4 [8320/10296 (81%)]\tLoss: 0.087572\n",
      "Train Epoch: 4 [8960/10296 (87%)]\tLoss: 0.082678\n",
      "Train Epoch: 4 [9600/10296 (93%)]\tLoss: 0.026763\n",
      "Train Epoch: 4 [8960/10296 (99%)]\tLoss: 0.052035\n",
      "Train Epoch: 5 [0/10296 (0%)]\tLoss: 0.049809\n",
      "Train Epoch: 5 [640/10296 (6%)]\tLoss: 0.105271\n",
      "Train Epoch: 5 [1280/10296 (12%)]\tLoss: 0.068445\n",
      "Train Epoch: 5 [1920/10296 (19%)]\tLoss: 0.097270\n",
      "Train Epoch: 5 [2560/10296 (25%)]\tLoss: 0.018745\n",
      "Train Epoch: 5 [3200/10296 (31%)]\tLoss: 0.061979\n",
      "Train Epoch: 5 [3840/10296 (37%)]\tLoss: 0.146619\n",
      "Train Epoch: 5 [4480/10296 (43%)]\tLoss: 0.035942\n",
      "Train Epoch: 5 [5120/10296 (50%)]\tLoss: 0.040271\n",
      "Train Epoch: 5 [5760/10296 (56%)]\tLoss: 0.031541\n",
      "Train Epoch: 5 [6400/10296 (62%)]\tLoss: 0.077543\n",
      "Train Epoch: 5 [7040/10296 (68%)]\tLoss: 0.036346\n",
      "Train Epoch: 5 [7680/10296 (75%)]\tLoss: 0.067645\n",
      "Train Epoch: 5 [8320/10296 (81%)]\tLoss: 0.159920\n",
      "Train Epoch: 5 [8960/10296 (87%)]\tLoss: 0.022333\n",
      "Train Epoch: 5 [9600/10296 (93%)]\tLoss: 0.150988\n",
      "Train Epoch: 5 [8960/10296 (99%)]\tLoss: 0.080429\n",
      "Train Epoch: 6 [0/10296 (0%)]\tLoss: 0.075014\n",
      "Train Epoch: 6 [640/10296 (6%)]\tLoss: 0.091129\n",
      "Train Epoch: 6 [1280/10296 (12%)]\tLoss: 0.041888\n",
      "Train Epoch: 6 [1920/10296 (19%)]\tLoss: 0.041879\n",
      "Train Epoch: 6 [2560/10296 (25%)]\tLoss: 0.177539\n",
      "Train Epoch: 6 [3200/10296 (31%)]\tLoss: 0.078342\n",
      "Train Epoch: 6 [3840/10296 (37%)]\tLoss: 0.208951\n",
      "Train Epoch: 6 [4480/10296 (43%)]\tLoss: 0.069930\n",
      "Train Epoch: 6 [5120/10296 (50%)]\tLoss: 0.054734\n",
      "Train Epoch: 6 [5760/10296 (56%)]\tLoss: 0.048067\n",
      "Train Epoch: 6 [6400/10296 (62%)]\tLoss: 0.027761\n",
      "Train Epoch: 6 [7040/10296 (68%)]\tLoss: 0.106412\n",
      "Train Epoch: 6 [7680/10296 (75%)]\tLoss: 0.034509\n",
      "Train Epoch: 6 [8320/10296 (81%)]\tLoss: 0.095520\n",
      "Train Epoch: 6 [8960/10296 (87%)]\tLoss: 0.103857\n",
      "Train Epoch: 6 [9600/10296 (93%)]\tLoss: 0.025707\n",
      "Train Epoch: 6 [8960/10296 (99%)]\tLoss: 0.022276\n",
      "Train Epoch: 7 [0/10296 (0%)]\tLoss: 0.014484\n",
      "Train Epoch: 7 [640/10296 (6%)]\tLoss: 0.025231\n",
      "Train Epoch: 7 [1280/10296 (12%)]\tLoss: 0.033577\n",
      "Train Epoch: 7 [1920/10296 (19%)]\tLoss: 0.111168\n",
      "Train Epoch: 7 [2560/10296 (25%)]\tLoss: 0.127639\n",
      "Train Epoch: 7 [3200/10296 (31%)]\tLoss: 0.042772\n",
      "Train Epoch: 7 [3840/10296 (37%)]\tLoss: 0.054758\n",
      "Train Epoch: 7 [4480/10296 (43%)]\tLoss: 0.061661\n",
      "Train Epoch: 7 [5120/10296 (50%)]\tLoss: 0.026482\n",
      "Train Epoch: 7 [5760/10296 (56%)]\tLoss: 0.013951\n",
      "Train Epoch: 7 [6400/10296 (62%)]\tLoss: 0.051760\n",
      "Train Epoch: 7 [7040/10296 (68%)]\tLoss: 0.019706\n",
      "Train Epoch: 7 [7680/10296 (75%)]\tLoss: 0.100515\n",
      "Train Epoch: 7 [8320/10296 (81%)]\tLoss: 0.024439\n",
      "Train Epoch: 7 [8960/10296 (87%)]\tLoss: 0.026364\n",
      "Train Epoch: 7 [9600/10296 (93%)]\tLoss: 0.059989\n",
      "Train Epoch: 7 [8960/10296 (99%)]\tLoss: 0.070080\n",
      "Train Epoch: 8 [0/10296 (0%)]\tLoss: 0.032402\n",
      "Train Epoch: 8 [640/10296 (6%)]\tLoss: 0.013962\n",
      "Train Epoch: 8 [1280/10296 (12%)]\tLoss: 0.072382\n",
      "Train Epoch: 8 [1920/10296 (19%)]\tLoss: 0.013465\n",
      "Train Epoch: 8 [2560/10296 (25%)]\tLoss: 0.028702\n",
      "Train Epoch: 8 [3200/10296 (31%)]\tLoss: 0.018474\n",
      "Train Epoch: 8 [3840/10296 (37%)]\tLoss: 0.096599\n",
      "Train Epoch: 8 [4480/10296 (43%)]\tLoss: 0.010826\n",
      "Train Epoch: 8 [5120/10296 (50%)]\tLoss: 0.039893\n",
      "Train Epoch: 8 [5760/10296 (56%)]\tLoss: 0.071914\n",
      "Train Epoch: 8 [6400/10296 (62%)]\tLoss: 0.091209\n",
      "Train Epoch: 8 [7040/10296 (68%)]\tLoss: 0.101046\n",
      "Train Epoch: 8 [7680/10296 (75%)]\tLoss: 0.021617\n",
      "Train Epoch: 8 [8320/10296 (81%)]\tLoss: 0.028436\n",
      "Train Epoch: 8 [8960/10296 (87%)]\tLoss: 0.020855\n",
      "Train Epoch: 8 [9600/10296 (93%)]\tLoss: 0.055887\n",
      "Train Epoch: 8 [8960/10296 (99%)]\tLoss: 0.011176\n",
      "Train Epoch: 9 [0/10296 (0%)]\tLoss: 0.080687\n",
      "Train Epoch: 9 [640/10296 (6%)]\tLoss: 0.047400\n",
      "Train Epoch: 9 [1280/10296 (12%)]\tLoss: 0.026233\n",
      "Train Epoch: 9 [1920/10296 (19%)]\tLoss: 0.083071\n",
      "Train Epoch: 9 [2560/10296 (25%)]\tLoss: 0.066198\n",
      "Train Epoch: 9 [3200/10296 (31%)]\tLoss: 0.023902\n",
      "Train Epoch: 9 [3840/10296 (37%)]\tLoss: 0.085093\n",
      "Train Epoch: 9 [4480/10296 (43%)]\tLoss: 0.017684\n",
      "Train Epoch: 9 [5120/10296 (50%)]\tLoss: 0.048616\n",
      "Train Epoch: 9 [5760/10296 (56%)]\tLoss: 0.033591\n",
      "Train Epoch: 9 [6400/10296 (62%)]\tLoss: 0.028831\n",
      "Train Epoch: 9 [7040/10296 (68%)]\tLoss: 0.084057\n",
      "Train Epoch: 9 [7680/10296 (75%)]\tLoss: 0.127830\n",
      "Train Epoch: 9 [8320/10296 (81%)]\tLoss: 0.179802\n",
      "Train Epoch: 9 [8960/10296 (87%)]\tLoss: 0.083341\n",
      "Train Epoch: 9 [9600/10296 (93%)]\tLoss: 0.056942\n",
      "Train Epoch: 9 [8960/10296 (99%)]\tLoss: 0.032069\n",
      "Train Epoch: 10 [0/10296 (0%)]\tLoss: 0.253342\n",
      "Train Epoch: 10 [640/10296 (6%)]\tLoss: 0.022558\n",
      "Train Epoch: 10 [1280/10296 (12%)]\tLoss: 0.025362\n",
      "Train Epoch: 10 [1920/10296 (19%)]\tLoss: 0.018427\n",
      "Train Epoch: 10 [2560/10296 (25%)]\tLoss: 0.086775\n",
      "Train Epoch: 10 [3200/10296 (31%)]\tLoss: 0.131545\n",
      "Train Epoch: 10 [3840/10296 (37%)]\tLoss: 0.039913\n",
      "Train Epoch: 10 [4480/10296 (43%)]\tLoss: 0.080192\n",
      "Train Epoch: 10 [5120/10296 (50%)]\tLoss: 0.027895\n",
      "Train Epoch: 10 [5760/10296 (56%)]\tLoss: 0.038117\n",
      "Train Epoch: 10 [6400/10296 (62%)]\tLoss: 0.026604\n",
      "Train Epoch: 10 [7040/10296 (68%)]\tLoss: 0.026006\n",
      "Train Epoch: 10 [7680/10296 (75%)]\tLoss: 0.139754\n",
      "Train Epoch: 10 [8320/10296 (81%)]\tLoss: 0.037637\n",
      "Train Epoch: 10 [8960/10296 (87%)]\tLoss: 0.021806\n",
      "Train Epoch: 10 [9600/10296 (93%)]\tLoss: 0.107727\n",
      "Train Epoch: 10 [8960/10296 (99%)]\tLoss: 0.009886\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 0.094530\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 0.137335\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 0.049288\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 0.081253\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 0.052516\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 0.108559\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 0.069060\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 0.058253\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 0.024226\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 0.080704\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 0.065052\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 0.065620\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 0.019116\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 0.107750\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 0.043070\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 0.024023\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 0.007245\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.103155\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.078929\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.033467\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.215563\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.046112\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.075954\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.062526\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.041053\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.068678\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.009866\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.027301\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.057269\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.029865\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.017810\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.053699\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.044552\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.019542\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.028439\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.118198\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.030226\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.019578\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.035609\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.086105\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.047057\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.030190\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.115473\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.046802\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.032976\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.072571\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.026681\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.042685\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.085144\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.035276\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.116047\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.152702\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.131371\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.042802\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.046357\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.029244\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.015373\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.187210\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.022981\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.043549\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.104045\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.061713\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.091706\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.095138\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.068138\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.069387\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.024036\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.023529\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.046313\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.035225\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.038864\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.020614\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.068644\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.103057\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.082420\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.060840\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.016981\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.038483\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.037274\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.008807\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.048658\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.028442\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.134606\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.057321\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.037542\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.033812\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.069873\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.036280\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.097227\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.031472\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.016650\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.066368\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.095180\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.052759\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.065245\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.060631\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.007411\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.017482\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.036129\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.056986\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.021681\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.028685\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.096005\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.054911\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.053603\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.027424\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.081544\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.021170\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.032028\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.053045\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.042176\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.041766\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.076157\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.036069\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.050585\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.082463\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.021212\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.025061\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.025092\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.140359\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.158244\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.016691\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.087375\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.040906\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.171541\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.006685\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.032312\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.072647\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.034993\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.020288\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.055064\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.027076\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.021822\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.121976\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.022351\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.010845\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.052060\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.027293\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.019342\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.079463\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.076754\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.005178\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.021600\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.013284\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.059380\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.116337\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.028135\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.039534\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.063686\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.030754\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.107004\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.101928\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.051076\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.112395\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.058024\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.039545\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.042002\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.035955\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.018710\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.047034\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/3910 (0%)]\tLoss: 0.120905\n",
      "Train Epoch: 1 [640/3910 (16%)]\tLoss: 0.117373\n",
      "Train Epoch: 1 [1280/3910 (32%)]\tLoss: 0.038510\n",
      "Train Epoch: 1 [1920/3910 (48%)]\tLoss: 0.082699\n",
      "Train Epoch: 1 [2560/3910 (65%)]\tLoss: 0.014895\n",
      "Train Epoch: 1 [3200/3910 (81%)]\tLoss: 0.072625\n",
      "Train Epoch: 1 [3840/3910 (97%)]\tLoss: 0.111958\n",
      "Train Epoch: 2 [0/3910 (0%)]\tLoss: 0.290760\n",
      "Train Epoch: 2 [640/3910 (16%)]\tLoss: 0.071789\n",
      "Train Epoch: 2 [1280/3910 (32%)]\tLoss: 0.066505\n",
      "Train Epoch: 2 [1920/3910 (48%)]\tLoss: 0.022666\n",
      "Train Epoch: 2 [2560/3910 (65%)]\tLoss: 0.113552\n",
      "Train Epoch: 2 [3200/3910 (81%)]\tLoss: 0.027697\n",
      "Train Epoch: 2 [3840/3910 (97%)]\tLoss: 0.025033\n",
      "Train Epoch: 3 [0/3910 (0%)]\tLoss: 0.027376\n",
      "Train Epoch: 3 [640/3910 (16%)]\tLoss: 0.034704\n",
      "Train Epoch: 3 [1280/3910 (32%)]\tLoss: 0.056671\n",
      "Train Epoch: 3 [1920/3910 (48%)]\tLoss: 0.100752\n",
      "Train Epoch: 3 [2560/3910 (65%)]\tLoss: 0.022988\n",
      "Train Epoch: 3 [3200/3910 (81%)]\tLoss: 0.042537\n",
      "Train Epoch: 3 [3840/3910 (97%)]\tLoss: 0.120353\n",
      "Train Epoch: 4 [0/3910 (0%)]\tLoss: 0.116754\n",
      "Train Epoch: 4 [640/3910 (16%)]\tLoss: 0.040546\n",
      "Train Epoch: 4 [1280/3910 (32%)]\tLoss: 0.079325\n",
      "Train Epoch: 4 [1920/3910 (48%)]\tLoss: 0.094555\n",
      "Train Epoch: 4 [2560/3910 (65%)]\tLoss: 0.006557\n",
      "Train Epoch: 4 [3200/3910 (81%)]\tLoss: 0.038576\n",
      "Train Epoch: 4 [3840/3910 (97%)]\tLoss: 0.011393\n",
      "Train Epoch: 5 [0/3910 (0%)]\tLoss: 0.042673\n",
      "Train Epoch: 5 [640/3910 (16%)]\tLoss: 0.177685\n",
      "Train Epoch: 5 [1280/3910 (32%)]\tLoss: 0.017171\n",
      "Train Epoch: 5 [1920/3910 (48%)]\tLoss: 0.241732\n",
      "Train Epoch: 5 [2560/3910 (65%)]\tLoss: 0.082524\n",
      "Train Epoch: 5 [3200/3910 (81%)]\tLoss: 0.062191\n",
      "Train Epoch: 5 [3840/3910 (97%)]\tLoss: 0.081659\n",
      "Train Epoch: 6 [0/3910 (0%)]\tLoss: 0.218142\n",
      "Train Epoch: 6 [640/3910 (16%)]\tLoss: 0.039858\n",
      "Train Epoch: 6 [1280/3910 (32%)]\tLoss: 0.135672\n",
      "Train Epoch: 6 [1920/3910 (48%)]\tLoss: 0.024595\n",
      "Train Epoch: 6 [2560/3910 (65%)]\tLoss: 0.074093\n",
      "Train Epoch: 6 [3200/3910 (81%)]\tLoss: 0.012569\n",
      "Train Epoch: 6 [3840/3910 (97%)]\tLoss: 0.023914\n",
      "Train Epoch: 7 [0/3910 (0%)]\tLoss: 0.110754\n",
      "Train Epoch: 7 [640/3910 (16%)]\tLoss: 0.024163\n",
      "Train Epoch: 7 [1280/3910 (32%)]\tLoss: 0.083029\n",
      "Train Epoch: 7 [1920/3910 (48%)]\tLoss: 0.035897\n",
      "Train Epoch: 7 [2560/3910 (65%)]\tLoss: 0.031060\n",
      "Train Epoch: 7 [3200/3910 (81%)]\tLoss: 0.034522\n",
      "Train Epoch: 7 [3840/3910 (97%)]\tLoss: 0.009037\n",
      "Train Epoch: 8 [0/3910 (0%)]\tLoss: 0.073018\n",
      "Train Epoch: 8 [640/3910 (16%)]\tLoss: 0.179328\n",
      "Train Epoch: 8 [1280/3910 (32%)]\tLoss: 0.020876\n",
      "Train Epoch: 8 [1920/3910 (48%)]\tLoss: 0.069775\n",
      "Train Epoch: 8 [2560/3910 (65%)]\tLoss: 0.096779\n",
      "Train Epoch: 8 [3200/3910 (81%)]\tLoss: 0.015916\n",
      "Train Epoch: 8 [3840/3910 (97%)]\tLoss: 0.020708\n",
      "Train Epoch: 9 [0/3910 (0%)]\tLoss: 0.047661\n",
      "Train Epoch: 9 [640/3910 (16%)]\tLoss: 0.083256\n",
      "Train Epoch: 9 [1280/3910 (32%)]\tLoss: 0.065179\n",
      "Train Epoch: 9 [1920/3910 (48%)]\tLoss: 0.034567\n",
      "Train Epoch: 9 [2560/3910 (65%)]\tLoss: 0.058400\n",
      "Train Epoch: 9 [3200/3910 (81%)]\tLoss: 0.039607\n",
      "Train Epoch: 9 [3840/3910 (97%)]\tLoss: 0.036797\n",
      "Train Epoch: 10 [0/3910 (0%)]\tLoss: 0.109959\n",
      "Train Epoch: 10 [640/3910 (16%)]\tLoss: 0.030985\n",
      "Train Epoch: 10 [1280/3910 (32%)]\tLoss: 0.026809\n",
      "Train Epoch: 10 [1920/3910 (48%)]\tLoss: 0.023055\n",
      "Train Epoch: 10 [2560/3910 (65%)]\tLoss: 0.013655\n",
      "Train Epoch: 10 [3200/3910 (81%)]\tLoss: 0.105343\n",
      "Train Epoch: 10 [3840/3910 (97%)]\tLoss: 0.097511\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 0.145904\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 0.060335\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 0.062559\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 0.056776\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 0.051589\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 0.010518\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 0.007000\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 0.066222\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 0.021700\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 0.039985\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.108530\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.020171\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 0.022407\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 0.032623\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 0.037650\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.040652\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.038615\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.064708\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.059369\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.009627\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.079959\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.048896\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.028542\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.054592\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.024842\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.003206\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.012130\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.066467\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.140797\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.009328\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.035539\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.073035\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.009010\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.028005\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.005122\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.043536\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.034819\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.022662\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.080081\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.048169\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.005922\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.031454\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.061468\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.030641\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.011139\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.042781\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.032075\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.115491\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.020778\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.068036\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.070173\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.011487\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.082478\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.007910\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.145323\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.039918\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.015057\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.052496\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.033226\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.080066\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.051606\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.015135\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.150210\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.045100\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.014065\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.067589\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.008182\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.028227\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.010031\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.031146\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.018114\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.005995\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.049719\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.221139\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.041198\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.026848\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.038942\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.007672\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.009965\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.010474\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.054073\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.002432\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.011574\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.014519\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.059823\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.008430\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.035493\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.088329\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.014258\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.004481\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.080294\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.028879\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.012253\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.028340\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.059890\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.022138\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.022326\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.002973\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.041210\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.002580\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.020415\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.004365\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.080376\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.055325\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.036740\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.011173\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.006560\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.029028\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.057582\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.010166\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.043626\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.021722\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.046663\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.045941\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.040470\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.133705\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.046629\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.056902\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.011646\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.017513\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/5096 (0%)]\tLoss: 0.113815\n",
      "Train Epoch: 1 [640/5096 (12%)]\tLoss: 0.038615\n",
      "Train Epoch: 1 [1280/5096 (25%)]\tLoss: 0.136148\n",
      "Train Epoch: 1 [1920/5096 (38%)]\tLoss: 0.051039\n",
      "Train Epoch: 1 [2560/5096 (50%)]\tLoss: 0.040657\n",
      "Train Epoch: 1 [3200/5096 (62%)]\tLoss: 0.068677\n",
      "Train Epoch: 1 [3840/5096 (75%)]\tLoss: 0.192627\n",
      "Train Epoch: 1 [4480/5096 (88%)]\tLoss: 0.153364\n",
      "Train Epoch: 2 [0/5096 (0%)]\tLoss: 0.095963\n",
      "Train Epoch: 2 [640/5096 (12%)]\tLoss: 0.015100\n",
      "Train Epoch: 2 [1280/5096 (25%)]\tLoss: 0.043180\n",
      "Train Epoch: 2 [1920/5096 (38%)]\tLoss: 0.013797\n",
      "Train Epoch: 2 [2560/5096 (50%)]\tLoss: 0.025682\n",
      "Train Epoch: 2 [3200/5096 (62%)]\tLoss: 0.024059\n",
      "Train Epoch: 2 [3840/5096 (75%)]\tLoss: 0.098879\n",
      "Train Epoch: 2 [4480/5096 (88%)]\tLoss: 0.070829\n",
      "Train Epoch: 3 [0/5096 (0%)]\tLoss: 0.037120\n",
      "Train Epoch: 3 [640/5096 (12%)]\tLoss: 0.014193\n",
      "Train Epoch: 3 [1280/5096 (25%)]\tLoss: 0.059643\n",
      "Train Epoch: 3 [1920/5096 (38%)]\tLoss: 0.005261\n",
      "Train Epoch: 3 [2560/5096 (50%)]\tLoss: 0.033299\n",
      "Train Epoch: 3 [3200/5096 (62%)]\tLoss: 0.027093\n",
      "Train Epoch: 3 [3840/5096 (75%)]\tLoss: 0.021676\n",
      "Train Epoch: 3 [4480/5096 (88%)]\tLoss: 0.116876\n",
      "Train Epoch: 4 [0/5096 (0%)]\tLoss: 0.115563\n",
      "Train Epoch: 4 [640/5096 (12%)]\tLoss: 0.022204\n",
      "Train Epoch: 4 [1280/5096 (25%)]\tLoss: 0.007692\n",
      "Train Epoch: 4 [1920/5096 (38%)]\tLoss: 0.029506\n",
      "Train Epoch: 4 [2560/5096 (50%)]\tLoss: 0.046579\n",
      "Train Epoch: 4 [3200/5096 (62%)]\tLoss: 0.011301\n",
      "Train Epoch: 4 [3840/5096 (75%)]\tLoss: 0.003195\n",
      "Train Epoch: 4 [4480/5096 (88%)]\tLoss: 0.024421\n",
      "Train Epoch: 5 [0/5096 (0%)]\tLoss: 0.004331\n",
      "Train Epoch: 5 [640/5096 (12%)]\tLoss: 0.055503\n",
      "Train Epoch: 5 [1280/5096 (25%)]\tLoss: 0.005719\n",
      "Train Epoch: 5 [1920/5096 (38%)]\tLoss: 0.005529\n",
      "Train Epoch: 5 [2560/5096 (50%)]\tLoss: 0.076177\n",
      "Train Epoch: 5 [3200/5096 (62%)]\tLoss: 0.061603\n",
      "Train Epoch: 5 [3840/5096 (75%)]\tLoss: 0.014907\n",
      "Train Epoch: 5 [4480/5096 (88%)]\tLoss: 0.008643\n",
      "Train Epoch: 6 [0/5096 (0%)]\tLoss: 0.010111\n",
      "Train Epoch: 6 [640/5096 (12%)]\tLoss: 0.059692\n",
      "Train Epoch: 6 [1280/5096 (25%)]\tLoss: 0.087277\n",
      "Train Epoch: 6 [1920/5096 (38%)]\tLoss: 0.052616\n",
      "Train Epoch: 6 [2560/5096 (50%)]\tLoss: 0.000553\n",
      "Train Epoch: 6 [3200/5096 (62%)]\tLoss: 0.006469\n",
      "Train Epoch: 6 [3840/5096 (75%)]\tLoss: 0.037766\n",
      "Train Epoch: 6 [4480/5096 (88%)]\tLoss: 0.060634\n",
      "Train Epoch: 7 [0/5096 (0%)]\tLoss: 0.025009\n",
      "Train Epoch: 7 [640/5096 (12%)]\tLoss: 0.083030\n",
      "Train Epoch: 7 [1280/5096 (25%)]\tLoss: 0.002210\n",
      "Train Epoch: 7 [1920/5096 (38%)]\tLoss: 0.023968\n",
      "Train Epoch: 7 [2560/5096 (50%)]\tLoss: 0.022372\n",
      "Train Epoch: 7 [3200/5096 (62%)]\tLoss: 0.150718\n",
      "Train Epoch: 7 [3840/5096 (75%)]\tLoss: 0.111293\n",
      "Train Epoch: 7 [4480/5096 (88%)]\tLoss: 0.010736\n",
      "Train Epoch: 8 [0/5096 (0%)]\tLoss: 0.044051\n",
      "Train Epoch: 8 [640/5096 (12%)]\tLoss: 0.037431\n",
      "Train Epoch: 8 [1280/5096 (25%)]\tLoss: 0.043644\n",
      "Train Epoch: 8 [1920/5096 (38%)]\tLoss: 0.047641\n",
      "Train Epoch: 8 [2560/5096 (50%)]\tLoss: 0.018017\n",
      "Train Epoch: 8 [3200/5096 (62%)]\tLoss: 0.019732\n",
      "Train Epoch: 8 [3840/5096 (75%)]\tLoss: 0.003178\n",
      "Train Epoch: 8 [4480/5096 (88%)]\tLoss: 0.016394\n",
      "Train Epoch: 9 [0/5096 (0%)]\tLoss: 0.089458\n",
      "Train Epoch: 9 [640/5096 (12%)]\tLoss: 0.005415\n",
      "Train Epoch: 9 [1280/5096 (25%)]\tLoss: 0.002514\n",
      "Train Epoch: 9 [1920/5096 (38%)]\tLoss: 0.017644\n",
      "Train Epoch: 9 [2560/5096 (50%)]\tLoss: 0.005905\n",
      "Train Epoch: 9 [3200/5096 (62%)]\tLoss: 0.007265\n",
      "Train Epoch: 9 [3840/5096 (75%)]\tLoss: 0.090046\n",
      "Train Epoch: 9 [4480/5096 (88%)]\tLoss: 0.048571\n",
      "Train Epoch: 10 [0/5096 (0%)]\tLoss: 0.018946\n",
      "Train Epoch: 10 [640/5096 (12%)]\tLoss: 0.024832\n",
      "Train Epoch: 10 [1280/5096 (25%)]\tLoss: 0.035250\n",
      "Train Epoch: 10 [1920/5096 (38%)]\tLoss: 0.088468\n",
      "Train Epoch: 10 [2560/5096 (50%)]\tLoss: 0.007765\n",
      "Train Epoch: 10 [3200/5096 (62%)]\tLoss: 0.059337\n",
      "Train Epoch: 10 [3840/5096 (75%)]\tLoss: 0.004867\n",
      "Train Epoch: 10 [4480/5096 (88%)]\tLoss: 0.009909\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6865 (0%)]\tLoss: 0.094733\n",
      "Train Epoch: 1 [640/6865 (9%)]\tLoss: 0.101399\n",
      "Train Epoch: 1 [1280/6865 (19%)]\tLoss: 0.068266\n",
      "Train Epoch: 1 [1920/6865 (28%)]\tLoss: 0.034568\n",
      "Train Epoch: 1 [2560/6865 (37%)]\tLoss: 0.027714\n",
      "Train Epoch: 1 [3200/6865 (46%)]\tLoss: 0.060585\n",
      "Train Epoch: 1 [3840/6865 (56%)]\tLoss: 0.029027\n",
      "Train Epoch: 1 [4480/6865 (65%)]\tLoss: 0.093952\n",
      "Train Epoch: 1 [5120/6865 (74%)]\tLoss: 0.083212\n",
      "Train Epoch: 1 [5760/6865 (83%)]\tLoss: 0.051158\n",
      "Train Epoch: 1 [6400/6865 (93%)]\tLoss: 0.057050\n",
      "Train Epoch: 2 [0/6865 (0%)]\tLoss: 0.012214\n",
      "Train Epoch: 2 [640/6865 (9%)]\tLoss: 0.062119\n",
      "Train Epoch: 2 [1280/6865 (19%)]\tLoss: 0.030523\n",
      "Train Epoch: 2 [1920/6865 (28%)]\tLoss: 0.010696\n",
      "Train Epoch: 2 [2560/6865 (37%)]\tLoss: 0.022202\n",
      "Train Epoch: 2 [3200/6865 (46%)]\tLoss: 0.004863\n",
      "Train Epoch: 2 [3840/6865 (56%)]\tLoss: 0.045826\n",
      "Train Epoch: 2 [4480/6865 (65%)]\tLoss: 0.014507\n",
      "Train Epoch: 2 [5120/6865 (74%)]\tLoss: 0.042988\n",
      "Train Epoch: 2 [5760/6865 (83%)]\tLoss: 0.005633\n",
      "Train Epoch: 2 [6400/6865 (93%)]\tLoss: 0.019379\n",
      "Train Epoch: 3 [0/6865 (0%)]\tLoss: 0.060198\n",
      "Train Epoch: 3 [640/6865 (9%)]\tLoss: 0.019634\n",
      "Train Epoch: 3 [1280/6865 (19%)]\tLoss: 0.041935\n",
      "Train Epoch: 3 [1920/6865 (28%)]\tLoss: 0.037283\n",
      "Train Epoch: 3 [2560/6865 (37%)]\tLoss: 0.054731\n",
      "Train Epoch: 3 [3200/6865 (46%)]\tLoss: 0.076881\n",
      "Train Epoch: 3 [3840/6865 (56%)]\tLoss: 0.134331\n",
      "Train Epoch: 3 [4480/6865 (65%)]\tLoss: 0.011830\n",
      "Train Epoch: 3 [5120/6865 (74%)]\tLoss: 0.081476\n",
      "Train Epoch: 3 [5760/6865 (83%)]\tLoss: 0.030235\n",
      "Train Epoch: 3 [6400/6865 (93%)]\tLoss: 0.182097\n",
      "Train Epoch: 4 [0/6865 (0%)]\tLoss: 0.018000\n",
      "Train Epoch: 4 [640/6865 (9%)]\tLoss: 0.052289\n",
      "Train Epoch: 4 [1280/6865 (19%)]\tLoss: 0.176552\n",
      "Train Epoch: 4 [1920/6865 (28%)]\tLoss: 0.031461\n",
      "Train Epoch: 4 [2560/6865 (37%)]\tLoss: 0.025164\n",
      "Train Epoch: 4 [3200/6865 (46%)]\tLoss: 0.161596\n",
      "Train Epoch: 4 [3840/6865 (56%)]\tLoss: 0.033363\n",
      "Train Epoch: 4 [4480/6865 (65%)]\tLoss: 0.035363\n",
      "Train Epoch: 4 [5120/6865 (74%)]\tLoss: 0.005912\n",
      "Train Epoch: 4 [5760/6865 (83%)]\tLoss: 0.005216\n",
      "Train Epoch: 4 [6400/6865 (93%)]\tLoss: 0.021517\n",
      "Train Epoch: 5 [0/6865 (0%)]\tLoss: 0.019656\n",
      "Train Epoch: 5 [640/6865 (9%)]\tLoss: 0.041277\n",
      "Train Epoch: 5 [1280/6865 (19%)]\tLoss: 0.016118\n",
      "Train Epoch: 5 [1920/6865 (28%)]\tLoss: 0.014975\n",
      "Train Epoch: 5 [2560/6865 (37%)]\tLoss: 0.115894\n",
      "Train Epoch: 5 [3200/6865 (46%)]\tLoss: 0.204193\n",
      "Train Epoch: 5 [3840/6865 (56%)]\tLoss: 0.011020\n",
      "Train Epoch: 5 [4480/6865 (65%)]\tLoss: 0.108690\n",
      "Train Epoch: 5 [5120/6865 (74%)]\tLoss: 0.025257\n",
      "Train Epoch: 5 [5760/6865 (83%)]\tLoss: 0.035447\n",
      "Train Epoch: 5 [6400/6865 (93%)]\tLoss: 0.019902\n",
      "Train Epoch: 6 [0/6865 (0%)]\tLoss: 0.116977\n",
      "Train Epoch: 6 [640/6865 (9%)]\tLoss: 0.021103\n",
      "Train Epoch: 6 [1280/6865 (19%)]\tLoss: 0.088440\n",
      "Train Epoch: 6 [1920/6865 (28%)]\tLoss: 0.053472\n",
      "Train Epoch: 6 [2560/6865 (37%)]\tLoss: 0.028527\n",
      "Train Epoch: 6 [3200/6865 (46%)]\tLoss: 0.042671\n",
      "Train Epoch: 6 [3840/6865 (56%)]\tLoss: 0.014871\n",
      "Train Epoch: 6 [4480/6865 (65%)]\tLoss: 0.015435\n",
      "Train Epoch: 6 [5120/6865 (74%)]\tLoss: 0.239862\n",
      "Train Epoch: 6 [5760/6865 (83%)]\tLoss: 0.003116\n",
      "Train Epoch: 6 [6400/6865 (93%)]\tLoss: 0.042320\n",
      "Train Epoch: 7 [0/6865 (0%)]\tLoss: 0.008572\n",
      "Train Epoch: 7 [640/6865 (9%)]\tLoss: 0.110469\n",
      "Train Epoch: 7 [1280/6865 (19%)]\tLoss: 0.036459\n",
      "Train Epoch: 7 [1920/6865 (28%)]\tLoss: 0.004674\n",
      "Train Epoch: 7 [2560/6865 (37%)]\tLoss: 0.013213\n",
      "Train Epoch: 7 [3200/6865 (46%)]\tLoss: 0.031246\n",
      "Train Epoch: 7 [3840/6865 (56%)]\tLoss: 0.121864\n",
      "Train Epoch: 7 [4480/6865 (65%)]\tLoss: 0.105983\n",
      "Train Epoch: 7 [5120/6865 (74%)]\tLoss: 0.019127\n",
      "Train Epoch: 7 [5760/6865 (83%)]\tLoss: 0.110130\n",
      "Train Epoch: 7 [6400/6865 (93%)]\tLoss: 0.068764\n",
      "Train Epoch: 8 [0/6865 (0%)]\tLoss: 0.142625\n",
      "Train Epoch: 8 [640/6865 (9%)]\tLoss: 0.018049\n",
      "Train Epoch: 8 [1280/6865 (19%)]\tLoss: 0.010551\n",
      "Train Epoch: 8 [1920/6865 (28%)]\tLoss: 0.034524\n",
      "Train Epoch: 8 [2560/6865 (37%)]\tLoss: 0.008038\n",
      "Train Epoch: 8 [3200/6865 (46%)]\tLoss: 0.041528\n",
      "Train Epoch: 8 [3840/6865 (56%)]\tLoss: 0.035687\n",
      "Train Epoch: 8 [4480/6865 (65%)]\tLoss: 0.125663\n",
      "Train Epoch: 8 [5120/6865 (74%)]\tLoss: 0.162761\n",
      "Train Epoch: 8 [5760/6865 (83%)]\tLoss: 0.004816\n",
      "Train Epoch: 8 [6400/6865 (93%)]\tLoss: 0.048348\n",
      "Train Epoch: 9 [0/6865 (0%)]\tLoss: 0.056533\n",
      "Train Epoch: 9 [640/6865 (9%)]\tLoss: 0.119444\n",
      "Train Epoch: 9 [1280/6865 (19%)]\tLoss: 0.056859\n",
      "Train Epoch: 9 [1920/6865 (28%)]\tLoss: 0.024527\n",
      "Train Epoch: 9 [2560/6865 (37%)]\tLoss: 0.073666\n",
      "Train Epoch: 9 [3200/6865 (46%)]\tLoss: 0.009984\n",
      "Train Epoch: 9 [3840/6865 (56%)]\tLoss: 0.020423\n",
      "Train Epoch: 9 [4480/6865 (65%)]\tLoss: 0.060239\n",
      "Train Epoch: 9 [5120/6865 (74%)]\tLoss: 0.067985\n",
      "Train Epoch: 9 [5760/6865 (83%)]\tLoss: 0.004002\n",
      "Train Epoch: 9 [6400/6865 (93%)]\tLoss: 0.083966\n",
      "Train Epoch: 10 [0/6865 (0%)]\tLoss: 0.013556\n",
      "Train Epoch: 10 [640/6865 (9%)]\tLoss: 0.017730\n",
      "Train Epoch: 10 [1280/6865 (19%)]\tLoss: 0.032690\n",
      "Train Epoch: 10 [1920/6865 (28%)]\tLoss: 0.042752\n",
      "Train Epoch: 10 [2560/6865 (37%)]\tLoss: 0.014141\n",
      "Train Epoch: 10 [3200/6865 (46%)]\tLoss: 0.061210\n",
      "Train Epoch: 10 [3840/6865 (56%)]\tLoss: 0.033447\n",
      "Train Epoch: 10 [4480/6865 (65%)]\tLoss: 0.082320\n",
      "Train Epoch: 10 [5120/6865 (74%)]\tLoss: 0.016332\n",
      "Train Epoch: 10 [5760/6865 (83%)]\tLoss: 0.079378\n",
      "Train Epoch: 10 [6400/6865 (93%)]\tLoss: 0.040544\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0428, Accuracy: 9855/10000 (99%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 0.119200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 0.023813\n",
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 0.103287\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 0.093234\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 0.084019\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 0.042896\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 0.041447\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 0.064021\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 0.111832\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 0.048593\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 0.070229\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 0.050948\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 0.080818\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 0.067781\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 0.084422\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 0.029735\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 0.110257\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 0.037412\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 0.037024\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 0.065199\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.048941\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 0.072304\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 0.010367\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.151441\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.053518\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 0.049252\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.187296\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 0.048894\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.076359\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.118844\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.090300\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.209485\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.011995\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.128914\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.008020\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.043607\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.041687\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.260708\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.069215\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.035373\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.014125\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.126822\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.009610\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.016572\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.063708\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.066430\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.156377\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.134594\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.119552\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.018652\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.027294\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.017234\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.004048\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.091356\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.050556\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.257978\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.148124\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.170449\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.059605\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.085855\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.037439\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.019610\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.117122\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.057945\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.023060\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.042785\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.038909\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.022857\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.053913\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.022571\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.238345\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.030263\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.024639\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.029681\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.102720\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.189374\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.064567\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.115077\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.047879\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.050917\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.058788\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.063269\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.039718\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.038204\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.053704\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.013215\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.011782\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.004739\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.055662\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.080199\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.098499\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.058581\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.075513\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.040925\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.072969\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.014556\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.075944\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.023456\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.018927\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.112146\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.022897\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.066169\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.105344\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.007609\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.304642\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.020633\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.064837\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.083851\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 0.018408\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.069448\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.021826\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.034121\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.029172\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.017332\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.069834\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.026486\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.019132\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.030347\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.013373\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.205775\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.148295\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.062834\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.094836\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.037399\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.130996\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.088490\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.029714\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.038067\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.093422\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.035649\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.051838\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.175553\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.044687\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.027513\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.046562\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.020905\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.088588\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.033528\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.059813\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.014961\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.009115\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.052216\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.058929\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.040724\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.063229\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.038724\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.089993\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.087268\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.078277\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.064847\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.009781\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.010819\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.011386\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.062470\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.152927\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.089519\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.020604\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.082478\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.154515\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.089306\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.011797\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.194279\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.075938\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.046629\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.083833\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.061224\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.046679\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.021695\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.109386\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.018625\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.010738\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.074572\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.102550\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.086883\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.066531\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.045959\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.035848\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.062972\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.027447\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.104538\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/5110 (0%)]\tLoss: 0.269167\n",
      "Train Epoch: 1 [640/5110 (12%)]\tLoss: 0.023026\n",
      "Train Epoch: 1 [1280/5110 (25%)]\tLoss: 0.079610\n",
      "Train Epoch: 1 [1920/5110 (38%)]\tLoss: 0.188416\n",
      "Train Epoch: 1 [2560/5110 (50%)]\tLoss: 0.014351\n",
      "Train Epoch: 1 [3200/5110 (62%)]\tLoss: 0.063731\n",
      "Train Epoch: 1 [3840/5110 (75%)]\tLoss: 0.018044\n",
      "Train Epoch: 1 [4480/5110 (88%)]\tLoss: 0.045907\n",
      "Train Epoch: 2 [0/5110 (0%)]\tLoss: 0.013972\n",
      "Train Epoch: 2 [640/5110 (12%)]\tLoss: 0.058205\n",
      "Train Epoch: 2 [1280/5110 (25%)]\tLoss: 0.016147\n",
      "Train Epoch: 2 [1920/5110 (38%)]\tLoss: 0.168490\n",
      "Train Epoch: 2 [2560/5110 (50%)]\tLoss: 0.052032\n",
      "Train Epoch: 2 [3200/5110 (62%)]\tLoss: 0.043529\n",
      "Train Epoch: 2 [3840/5110 (75%)]\tLoss: 0.063870\n",
      "Train Epoch: 2 [4480/5110 (88%)]\tLoss: 0.085260\n",
      "Train Epoch: 3 [0/5110 (0%)]\tLoss: 0.070840\n",
      "Train Epoch: 3 [640/5110 (12%)]\tLoss: 0.024204\n",
      "Train Epoch: 3 [1280/5110 (25%)]\tLoss: 0.030270\n",
      "Train Epoch: 3 [1920/5110 (38%)]\tLoss: 0.124214\n",
      "Train Epoch: 3 [2560/5110 (50%)]\tLoss: 0.069847\n",
      "Train Epoch: 3 [3200/5110 (62%)]\tLoss: 0.043985\n",
      "Train Epoch: 3 [3840/5110 (75%)]\tLoss: 0.031145\n",
      "Train Epoch: 3 [4480/5110 (88%)]\tLoss: 0.082839\n",
      "Train Epoch: 4 [0/5110 (0%)]\tLoss: 0.072784\n",
      "Train Epoch: 4 [640/5110 (12%)]\tLoss: 0.120027\n",
      "Train Epoch: 4 [1280/5110 (25%)]\tLoss: 0.109611\n",
      "Train Epoch: 4 [1920/5110 (38%)]\tLoss: 0.044296\n",
      "Train Epoch: 4 [2560/5110 (50%)]\tLoss: 0.063623\n",
      "Train Epoch: 4 [3200/5110 (62%)]\tLoss: 0.095027\n",
      "Train Epoch: 4 [3840/5110 (75%)]\tLoss: 0.048612\n",
      "Train Epoch: 4 [4480/5110 (88%)]\tLoss: 0.034799\n",
      "Train Epoch: 5 [0/5110 (0%)]\tLoss: 0.082415\n",
      "Train Epoch: 5 [640/5110 (12%)]\tLoss: 0.069071\n",
      "Train Epoch: 5 [1280/5110 (25%)]\tLoss: 0.052408\n",
      "Train Epoch: 5 [1920/5110 (38%)]\tLoss: 0.020340\n",
      "Train Epoch: 5 [2560/5110 (50%)]\tLoss: 0.022619\n",
      "Train Epoch: 5 [3200/5110 (62%)]\tLoss: 0.180271\n",
      "Train Epoch: 5 [3840/5110 (75%)]\tLoss: 0.021320\n",
      "Train Epoch: 5 [4480/5110 (88%)]\tLoss: 0.131679\n",
      "Train Epoch: 6 [0/5110 (0%)]\tLoss: 0.024241\n",
      "Train Epoch: 6 [640/5110 (12%)]\tLoss: 0.034003\n",
      "Train Epoch: 6 [1280/5110 (25%)]\tLoss: 0.011585\n",
      "Train Epoch: 6 [1920/5110 (38%)]\tLoss: 0.008166\n",
      "Train Epoch: 6 [2560/5110 (50%)]\tLoss: 0.055764\n",
      "Train Epoch: 6 [3200/5110 (62%)]\tLoss: 0.004673\n",
      "Train Epoch: 6 [3840/5110 (75%)]\tLoss: 0.083120\n",
      "Train Epoch: 6 [4480/5110 (88%)]\tLoss: 0.038869\n",
      "Train Epoch: 7 [0/5110 (0%)]\tLoss: 0.050740\n",
      "Train Epoch: 7 [640/5110 (12%)]\tLoss: 0.144406\n",
      "Train Epoch: 7 [1280/5110 (25%)]\tLoss: 0.072526\n",
      "Train Epoch: 7 [1920/5110 (38%)]\tLoss: 0.044228\n",
      "Train Epoch: 7 [2560/5110 (50%)]\tLoss: 0.095513\n",
      "Train Epoch: 7 [3200/5110 (62%)]\tLoss: 0.076287\n",
      "Train Epoch: 7 [3840/5110 (75%)]\tLoss: 0.025617\n",
      "Train Epoch: 7 [4480/5110 (88%)]\tLoss: 0.091047\n",
      "Train Epoch: 8 [0/5110 (0%)]\tLoss: 0.022822\n",
      "Train Epoch: 8 [640/5110 (12%)]\tLoss: 0.078872\n",
      "Train Epoch: 8 [1280/5110 (25%)]\tLoss: 0.148654\n",
      "Train Epoch: 8 [1920/5110 (38%)]\tLoss: 0.008444\n",
      "Train Epoch: 8 [2560/5110 (50%)]\tLoss: 0.069911\n",
      "Train Epoch: 8 [3200/5110 (62%)]\tLoss: 0.045852\n",
      "Train Epoch: 8 [3840/5110 (75%)]\tLoss: 0.030423\n",
      "Train Epoch: 8 [4480/5110 (88%)]\tLoss: 0.055297\n",
      "Train Epoch: 9 [0/5110 (0%)]\tLoss: 0.056276\n",
      "Train Epoch: 9 [640/5110 (12%)]\tLoss: 0.040872\n",
      "Train Epoch: 9 [1280/5110 (25%)]\tLoss: 0.006068\n",
      "Train Epoch: 9 [1920/5110 (38%)]\tLoss: 0.030715\n",
      "Train Epoch: 9 [2560/5110 (50%)]\tLoss: 0.057658\n",
      "Train Epoch: 9 [3200/5110 (62%)]\tLoss: 0.058907\n",
      "Train Epoch: 9 [3840/5110 (75%)]\tLoss: 0.013977\n",
      "Train Epoch: 9 [4480/5110 (88%)]\tLoss: 0.067191\n",
      "Train Epoch: 10 [0/5110 (0%)]\tLoss: 0.048094\n",
      "Train Epoch: 10 [640/5110 (12%)]\tLoss: 0.085704\n",
      "Train Epoch: 10 [1280/5110 (25%)]\tLoss: 0.094287\n",
      "Train Epoch: 10 [1920/5110 (38%)]\tLoss: 0.014569\n",
      "Train Epoch: 10 [2560/5110 (50%)]\tLoss: 0.024710\n",
      "Train Epoch: 10 [3200/5110 (62%)]\tLoss: 0.044746\n",
      "Train Epoch: 10 [3840/5110 (75%)]\tLoss: 0.034461\n",
      "Train Epoch: 10 [4480/5110 (88%)]\tLoss: 0.024234\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/10296 (0%)]\tLoss: 0.142122\n",
      "Train Epoch: 1 [640/10296 (6%)]\tLoss: 0.385944\n",
      "Train Epoch: 1 [1280/10296 (12%)]\tLoss: 0.078947\n",
      "Train Epoch: 1 [1920/10296 (19%)]\tLoss: 0.096130\n",
      "Train Epoch: 1 [2560/10296 (25%)]\tLoss: 0.072334\n",
      "Train Epoch: 1 [3200/10296 (31%)]\tLoss: 0.251816\n",
      "Train Epoch: 1 [3840/10296 (37%)]\tLoss: 0.059128\n",
      "Train Epoch: 1 [4480/10296 (43%)]\tLoss: 0.118368\n",
      "Train Epoch: 1 [5120/10296 (50%)]\tLoss: 0.128290\n",
      "Train Epoch: 1 [5760/10296 (56%)]\tLoss: 0.034414\n",
      "Train Epoch: 1 [6400/10296 (62%)]\tLoss: 0.076050\n",
      "Train Epoch: 1 [7040/10296 (68%)]\tLoss: 0.123543\n",
      "Train Epoch: 1 [7680/10296 (75%)]\tLoss: 0.152126\n",
      "Train Epoch: 1 [8320/10296 (81%)]\tLoss: 0.241439\n",
      "Train Epoch: 1 [8960/10296 (87%)]\tLoss: 0.017291\n",
      "Train Epoch: 1 [9600/10296 (93%)]\tLoss: 0.089974\n",
      "Train Epoch: 1 [8960/10296 (99%)]\tLoss: 0.074525\n",
      "Train Epoch: 2 [0/10296 (0%)]\tLoss: 0.118674\n",
      "Train Epoch: 2 [640/10296 (6%)]\tLoss: 0.025466\n",
      "Train Epoch: 2 [1280/10296 (12%)]\tLoss: 0.039026\n",
      "Train Epoch: 2 [1920/10296 (19%)]\tLoss: 0.032931\n",
      "Train Epoch: 2 [2560/10296 (25%)]\tLoss: 0.015138\n",
      "Train Epoch: 2 [3200/10296 (31%)]\tLoss: 0.210454\n",
      "Train Epoch: 2 [3840/10296 (37%)]\tLoss: 0.041417\n",
      "Train Epoch: 2 [4480/10296 (43%)]\tLoss: 0.056155\n",
      "Train Epoch: 2 [5120/10296 (50%)]\tLoss: 0.016201\n",
      "Train Epoch: 2 [5760/10296 (56%)]\tLoss: 0.301351\n",
      "Train Epoch: 2 [6400/10296 (62%)]\tLoss: 0.140770\n",
      "Train Epoch: 2 [7040/10296 (68%)]\tLoss: 0.077665\n",
      "Train Epoch: 2 [7680/10296 (75%)]\tLoss: 0.011981\n",
      "Train Epoch: 2 [8320/10296 (81%)]\tLoss: 0.212053\n",
      "Train Epoch: 2 [8960/10296 (87%)]\tLoss: 0.057984\n",
      "Train Epoch: 2 [9600/10296 (93%)]\tLoss: 0.029125\n",
      "Train Epoch: 2 [8960/10296 (99%)]\tLoss: 0.142662\n",
      "Train Epoch: 3 [0/10296 (0%)]\tLoss: 0.141665\n",
      "Train Epoch: 3 [640/10296 (6%)]\tLoss: 0.049898\n",
      "Train Epoch: 3 [1280/10296 (12%)]\tLoss: 0.211172\n",
      "Train Epoch: 3 [1920/10296 (19%)]\tLoss: 0.081839\n",
      "Train Epoch: 3 [2560/10296 (25%)]\tLoss: 0.033746\n",
      "Train Epoch: 3 [3200/10296 (31%)]\tLoss: 0.035615\n",
      "Train Epoch: 3 [3840/10296 (37%)]\tLoss: 0.046054\n",
      "Train Epoch: 3 [4480/10296 (43%)]\tLoss: 0.248206\n",
      "Train Epoch: 3 [5120/10296 (50%)]\tLoss: 0.120163\n",
      "Train Epoch: 3 [5760/10296 (56%)]\tLoss: 0.179862\n",
      "Train Epoch: 3 [6400/10296 (62%)]\tLoss: 0.054965\n",
      "Train Epoch: 3 [7040/10296 (68%)]\tLoss: 0.074951\n",
      "Train Epoch: 3 [7680/10296 (75%)]\tLoss: 0.076334\n",
      "Train Epoch: 3 [8320/10296 (81%)]\tLoss: 0.042843\n",
      "Train Epoch: 3 [8960/10296 (87%)]\tLoss: 0.060123\n",
      "Train Epoch: 3 [9600/10296 (93%)]\tLoss: 0.069873\n",
      "Train Epoch: 3 [8960/10296 (99%)]\tLoss: 0.077335\n",
      "Train Epoch: 4 [0/10296 (0%)]\tLoss: 0.119834\n",
      "Train Epoch: 4 [640/10296 (6%)]\tLoss: 0.021476\n",
      "Train Epoch: 4 [1280/10296 (12%)]\tLoss: 0.016835\n",
      "Train Epoch: 4 [1920/10296 (19%)]\tLoss: 0.056168\n",
      "Train Epoch: 4 [2560/10296 (25%)]\tLoss: 0.038184\n",
      "Train Epoch: 4 [3200/10296 (31%)]\tLoss: 0.013897\n",
      "Train Epoch: 4 [3840/10296 (37%)]\tLoss: 0.084134\n",
      "Train Epoch: 4 [4480/10296 (43%)]\tLoss: 0.043491\n",
      "Train Epoch: 4 [5120/10296 (50%)]\tLoss: 0.055896\n",
      "Train Epoch: 4 [5760/10296 (56%)]\tLoss: 0.052056\n",
      "Train Epoch: 4 [6400/10296 (62%)]\tLoss: 0.099308\n",
      "Train Epoch: 4 [7040/10296 (68%)]\tLoss: 0.154772\n",
      "Train Epoch: 4 [7680/10296 (75%)]\tLoss: 0.065615\n",
      "Train Epoch: 4 [8320/10296 (81%)]\tLoss: 0.044773\n",
      "Train Epoch: 4 [8960/10296 (87%)]\tLoss: 0.166302\n",
      "Train Epoch: 4 [9600/10296 (93%)]\tLoss: 0.044449\n",
      "Train Epoch: 4 [8960/10296 (99%)]\tLoss: 0.014931\n",
      "Train Epoch: 5 [0/10296 (0%)]\tLoss: 0.048442\n",
      "Train Epoch: 5 [640/10296 (6%)]\tLoss: 0.054075\n",
      "Train Epoch: 5 [1280/10296 (12%)]\tLoss: 0.024302\n",
      "Train Epoch: 5 [1920/10296 (19%)]\tLoss: 0.163065\n",
      "Train Epoch: 5 [2560/10296 (25%)]\tLoss: 0.017963\n",
      "Train Epoch: 5 [3200/10296 (31%)]\tLoss: 0.080474\n",
      "Train Epoch: 5 [3840/10296 (37%)]\tLoss: 0.079080\n",
      "Train Epoch: 5 [4480/10296 (43%)]\tLoss: 0.041955\n",
      "Train Epoch: 5 [5120/10296 (50%)]\tLoss: 0.097688\n",
      "Train Epoch: 5 [5760/10296 (56%)]\tLoss: 0.109478\n",
      "Train Epoch: 5 [6400/10296 (62%)]\tLoss: 0.169608\n",
      "Train Epoch: 5 [7040/10296 (68%)]\tLoss: 0.044996\n",
      "Train Epoch: 5 [7680/10296 (75%)]\tLoss: 0.041392\n",
      "Train Epoch: 5 [8320/10296 (81%)]\tLoss: 0.008069\n",
      "Train Epoch: 5 [8960/10296 (87%)]\tLoss: 0.189955\n",
      "Train Epoch: 5 [9600/10296 (93%)]\tLoss: 0.087812\n",
      "Train Epoch: 5 [8960/10296 (99%)]\tLoss: 0.323918\n",
      "Train Epoch: 6 [0/10296 (0%)]\tLoss: 0.013343\n",
      "Train Epoch: 6 [640/10296 (6%)]\tLoss: 0.053145\n",
      "Train Epoch: 6 [1280/10296 (12%)]\tLoss: 0.024999\n",
      "Train Epoch: 6 [1920/10296 (19%)]\tLoss: 0.017661\n",
      "Train Epoch: 6 [2560/10296 (25%)]\tLoss: 0.045800\n",
      "Train Epoch: 6 [3200/10296 (31%)]\tLoss: 0.052848\n",
      "Train Epoch: 6 [3840/10296 (37%)]\tLoss: 0.047909\n",
      "Train Epoch: 6 [4480/10296 (43%)]\tLoss: 0.101112\n",
      "Train Epoch: 6 [5120/10296 (50%)]\tLoss: 0.040101\n",
      "Train Epoch: 6 [5760/10296 (56%)]\tLoss: 0.051533\n",
      "Train Epoch: 6 [6400/10296 (62%)]\tLoss: 0.084647\n",
      "Train Epoch: 6 [7040/10296 (68%)]\tLoss: 0.060085\n",
      "Train Epoch: 6 [7680/10296 (75%)]\tLoss: 0.078152\n",
      "Train Epoch: 6 [8320/10296 (81%)]\tLoss: 0.025031\n",
      "Train Epoch: 6 [8960/10296 (87%)]\tLoss: 0.169915\n",
      "Train Epoch: 6 [9600/10296 (93%)]\tLoss: 0.132221\n",
      "Train Epoch: 6 [8960/10296 (99%)]\tLoss: 0.107242\n",
      "Train Epoch: 7 [0/10296 (0%)]\tLoss: 0.061006\n",
      "Train Epoch: 7 [640/10296 (6%)]\tLoss: 0.008506\n",
      "Train Epoch: 7 [1280/10296 (12%)]\tLoss: 0.033535\n",
      "Train Epoch: 7 [1920/10296 (19%)]\tLoss: 0.006506\n",
      "Train Epoch: 7 [2560/10296 (25%)]\tLoss: 0.016694\n",
      "Train Epoch: 7 [3200/10296 (31%)]\tLoss: 0.077299\n",
      "Train Epoch: 7 [3840/10296 (37%)]\tLoss: 0.076274\n",
      "Train Epoch: 7 [4480/10296 (43%)]\tLoss: 0.032626\n",
      "Train Epoch: 7 [5120/10296 (50%)]\tLoss: 0.068982\n",
      "Train Epoch: 7 [5760/10296 (56%)]\tLoss: 0.097770\n",
      "Train Epoch: 7 [6400/10296 (62%)]\tLoss: 0.035144\n",
      "Train Epoch: 7 [7040/10296 (68%)]\tLoss: 0.036459\n",
      "Train Epoch: 7 [7680/10296 (75%)]\tLoss: 0.047845\n",
      "Train Epoch: 7 [8320/10296 (81%)]\tLoss: 0.015336\n",
      "Train Epoch: 7 [8960/10296 (87%)]\tLoss: 0.022146\n",
      "Train Epoch: 7 [9600/10296 (93%)]\tLoss: 0.014112\n",
      "Train Epoch: 7 [8960/10296 (99%)]\tLoss: 0.088523\n",
      "Train Epoch: 8 [0/10296 (0%)]\tLoss: 0.010563\n",
      "Train Epoch: 8 [640/10296 (6%)]\tLoss: 0.035830\n",
      "Train Epoch: 8 [1280/10296 (12%)]\tLoss: 0.130542\n",
      "Train Epoch: 8 [1920/10296 (19%)]\tLoss: 0.299821\n",
      "Train Epoch: 8 [2560/10296 (25%)]\tLoss: 0.078346\n",
      "Train Epoch: 8 [3200/10296 (31%)]\tLoss: 0.071242\n",
      "Train Epoch: 8 [3840/10296 (37%)]\tLoss: 0.021907\n",
      "Train Epoch: 8 [4480/10296 (43%)]\tLoss: 0.064310\n",
      "Train Epoch: 8 [5120/10296 (50%)]\tLoss: 0.022791\n",
      "Train Epoch: 8 [5760/10296 (56%)]\tLoss: 0.049437\n",
      "Train Epoch: 8 [6400/10296 (62%)]\tLoss: 0.032235\n",
      "Train Epoch: 8 [7040/10296 (68%)]\tLoss: 0.015654\n",
      "Train Epoch: 8 [7680/10296 (75%)]\tLoss: 0.025968\n",
      "Train Epoch: 8 [8320/10296 (81%)]\tLoss: 0.154332\n",
      "Train Epoch: 8 [8960/10296 (87%)]\tLoss: 0.045785\n",
      "Train Epoch: 8 [9600/10296 (93%)]\tLoss: 0.034340\n",
      "Train Epoch: 8 [8960/10296 (99%)]\tLoss: 0.062874\n",
      "Train Epoch: 9 [0/10296 (0%)]\tLoss: 0.011820\n",
      "Train Epoch: 9 [640/10296 (6%)]\tLoss: 0.067702\n",
      "Train Epoch: 9 [1280/10296 (12%)]\tLoss: 0.114429\n",
      "Train Epoch: 9 [1920/10296 (19%)]\tLoss: 0.048307\n",
      "Train Epoch: 9 [2560/10296 (25%)]\tLoss: 0.023180\n",
      "Train Epoch: 9 [3200/10296 (31%)]\tLoss: 0.086369\n",
      "Train Epoch: 9 [3840/10296 (37%)]\tLoss: 0.063405\n",
      "Train Epoch: 9 [4480/10296 (43%)]\tLoss: 0.064106\n",
      "Train Epoch: 9 [5120/10296 (50%)]\tLoss: 0.048980\n",
      "Train Epoch: 9 [5760/10296 (56%)]\tLoss: 0.059642\n",
      "Train Epoch: 9 [6400/10296 (62%)]\tLoss: 0.076960\n",
      "Train Epoch: 9 [7040/10296 (68%)]\tLoss: 0.164807\n",
      "Train Epoch: 9 [7680/10296 (75%)]\tLoss: 0.008432\n",
      "Train Epoch: 9 [8320/10296 (81%)]\tLoss: 0.097128\n",
      "Train Epoch: 9 [8960/10296 (87%)]\tLoss: 0.084339\n",
      "Train Epoch: 9 [9600/10296 (93%)]\tLoss: 0.025700\n",
      "Train Epoch: 9 [8960/10296 (99%)]\tLoss: 0.039437\n",
      "Train Epoch: 10 [0/10296 (0%)]\tLoss: 0.047977\n",
      "Train Epoch: 10 [640/10296 (6%)]\tLoss: 0.095798\n",
      "Train Epoch: 10 [1280/10296 (12%)]\tLoss: 0.140591\n",
      "Train Epoch: 10 [1920/10296 (19%)]\tLoss: 0.019726\n",
      "Train Epoch: 10 [2560/10296 (25%)]\tLoss: 0.001380\n",
      "Train Epoch: 10 [3200/10296 (31%)]\tLoss: 0.072092\n",
      "Train Epoch: 10 [3840/10296 (37%)]\tLoss: 0.060522\n",
      "Train Epoch: 10 [4480/10296 (43%)]\tLoss: 0.039878\n",
      "Train Epoch: 10 [5120/10296 (50%)]\tLoss: 0.117503\n",
      "Train Epoch: 10 [5760/10296 (56%)]\tLoss: 0.075089\n",
      "Train Epoch: 10 [6400/10296 (62%)]\tLoss: 0.085598\n",
      "Train Epoch: 10 [7040/10296 (68%)]\tLoss: 0.035454\n",
      "Train Epoch: 10 [7680/10296 (75%)]\tLoss: 0.054335\n",
      "Train Epoch: 10 [8320/10296 (81%)]\tLoss: 0.013265\n",
      "Train Epoch: 10 [8960/10296 (87%)]\tLoss: 0.023229\n",
      "Train Epoch: 10 [9600/10296 (93%)]\tLoss: 0.133814\n",
      "Train Epoch: 10 [8960/10296 (99%)]\tLoss: 0.018893\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 0.195946\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 0.035086\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 0.059420\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 0.049257\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 0.215286\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 0.064811\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 0.085254\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 0.158830\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 0.057853\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 0.049212\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 0.047449\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 0.039648\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 0.060145\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 0.050794\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 0.104467\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 0.120543\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 0.055315\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.110578\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.021654\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.055933\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.035213\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.019729\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.022571\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.008229\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.033583\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.061251\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.025803\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.121052\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.043217\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.086144\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.069893\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.063393\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.031339\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.028130\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.050819\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.025558\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.004772\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.019590\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.202998\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.011136\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.039742\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.032809\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.013044\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.104417\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.092115\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.096695\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.019859\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.083428\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.095549\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.086650\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.091206\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.045395\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.013558\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.012893\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.008651\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.013014\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.025373\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.006707\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.008907\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.008182\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.093051\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.013272\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.088094\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.023440\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.009062\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.099301\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.114259\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.060431\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.052638\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.026699\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.047627\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.005684\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.008743\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.037265\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.034705\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.039676\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.034918\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.040708\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.051451\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.080535\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.112824\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.021625\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.011586\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.004319\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.176190\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.035721\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.039053\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.033234\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.020025\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.012010\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.067627\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.081721\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.041443\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.018344\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.043899\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.015181\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.045205\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.075417\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.039931\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.104990\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.049131\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.032297\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.042079\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.023319\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.035134\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.031930\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.023044\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.012464\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.137896\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.014774\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.024606\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.163491\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.022279\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.051716\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.071455\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.136088\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.046557\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.038006\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.068274\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.053684\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.050120\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.101707\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.023943\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.014870\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.017502\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.031872\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.014501\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.229487\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.013514\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.024757\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.028147\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.003029\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.121040\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.043526\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.025783\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.080189\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.049305\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.045312\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.039775\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.030912\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.066230\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.110618\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.034663\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.019542\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.051286\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.021249\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.006913\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.014569\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.033718\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.242665\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.004155\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.125834\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.179808\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.023527\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.131089\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.059501\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.051536\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.069188\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.072444\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.037918\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/3910 (0%)]\tLoss: 0.163488\n",
      "Train Epoch: 1 [640/3910 (16%)]\tLoss: 0.032901\n",
      "Train Epoch: 1 [1280/3910 (32%)]\tLoss: 0.114928\n",
      "Train Epoch: 1 [1920/3910 (48%)]\tLoss: 0.086042\n",
      "Train Epoch: 1 [2560/3910 (65%)]\tLoss: 0.235019\n",
      "Train Epoch: 1 [3200/3910 (81%)]\tLoss: 0.053619\n",
      "Train Epoch: 1 [3840/3910 (97%)]\tLoss: 0.155193\n",
      "Train Epoch: 2 [0/3910 (0%)]\tLoss: 0.128002\n",
      "Train Epoch: 2 [640/3910 (16%)]\tLoss: 0.043066\n",
      "Train Epoch: 2 [1280/3910 (32%)]\tLoss: 0.048987\n",
      "Train Epoch: 2 [1920/3910 (48%)]\tLoss: 0.144869\n",
      "Train Epoch: 2 [2560/3910 (65%)]\tLoss: 0.144784\n",
      "Train Epoch: 2 [3200/3910 (81%)]\tLoss: 0.068286\n",
      "Train Epoch: 2 [3840/3910 (97%)]\tLoss: 0.113905\n",
      "Train Epoch: 3 [0/3910 (0%)]\tLoss: 0.088630\n",
      "Train Epoch: 3 [640/3910 (16%)]\tLoss: 0.086232\n",
      "Train Epoch: 3 [1280/3910 (32%)]\tLoss: 0.071306\n",
      "Train Epoch: 3 [1920/3910 (48%)]\tLoss: 0.160529\n",
      "Train Epoch: 3 [2560/3910 (65%)]\tLoss: 0.043533\n",
      "Train Epoch: 3 [3200/3910 (81%)]\tLoss: 0.026789\n",
      "Train Epoch: 3 [3840/3910 (97%)]\tLoss: 0.035173\n",
      "Train Epoch: 4 [0/3910 (0%)]\tLoss: 0.018452\n",
      "Train Epoch: 4 [640/3910 (16%)]\tLoss: 0.026021\n",
      "Train Epoch: 4 [1280/3910 (32%)]\tLoss: 0.060963\n",
      "Train Epoch: 4 [1920/3910 (48%)]\tLoss: 0.065999\n",
      "Train Epoch: 4 [2560/3910 (65%)]\tLoss: 0.052006\n",
      "Train Epoch: 4 [3200/3910 (81%)]\tLoss: 0.222240\n",
      "Train Epoch: 4 [3840/3910 (97%)]\tLoss: 0.013617\n",
      "Train Epoch: 5 [0/3910 (0%)]\tLoss: 0.073919\n",
      "Train Epoch: 5 [640/3910 (16%)]\tLoss: 0.019007\n",
      "Train Epoch: 5 [1280/3910 (32%)]\tLoss: 0.046369\n",
      "Train Epoch: 5 [1920/3910 (48%)]\tLoss: 0.035888\n",
      "Train Epoch: 5 [2560/3910 (65%)]\tLoss: 0.147428\n",
      "Train Epoch: 5 [3200/3910 (81%)]\tLoss: 0.007686\n",
      "Train Epoch: 5 [3840/3910 (97%)]\tLoss: 0.053491\n",
      "Train Epoch: 6 [0/3910 (0%)]\tLoss: 0.069337\n",
      "Train Epoch: 6 [640/3910 (16%)]\tLoss: 0.038432\n",
      "Train Epoch: 6 [1280/3910 (32%)]\tLoss: 0.078421\n",
      "Train Epoch: 6 [1920/3910 (48%)]\tLoss: 0.042943\n",
      "Train Epoch: 6 [2560/3910 (65%)]\tLoss: 0.166766\n",
      "Train Epoch: 6 [3200/3910 (81%)]\tLoss: 0.061303\n",
      "Train Epoch: 6 [3840/3910 (97%)]\tLoss: 0.029414\n",
      "Train Epoch: 7 [0/3910 (0%)]\tLoss: 0.030580\n",
      "Train Epoch: 7 [640/3910 (16%)]\tLoss: 0.042024\n",
      "Train Epoch: 7 [1280/3910 (32%)]\tLoss: 0.046556\n",
      "Train Epoch: 7 [1920/3910 (48%)]\tLoss: 0.059491\n",
      "Train Epoch: 7 [2560/3910 (65%)]\tLoss: 0.040083\n",
      "Train Epoch: 7 [3200/3910 (81%)]\tLoss: 0.062701\n",
      "Train Epoch: 7 [3840/3910 (97%)]\tLoss: 0.050187\n",
      "Train Epoch: 8 [0/3910 (0%)]\tLoss: 0.032063\n",
      "Train Epoch: 8 [640/3910 (16%)]\tLoss: 0.005178\n",
      "Train Epoch: 8 [1280/3910 (32%)]\tLoss: 0.060580\n",
      "Train Epoch: 8 [1920/3910 (48%)]\tLoss: 0.007072\n",
      "Train Epoch: 8 [2560/3910 (65%)]\tLoss: 0.086717\n",
      "Train Epoch: 8 [3200/3910 (81%)]\tLoss: 0.004582\n",
      "Train Epoch: 8 [3840/3910 (97%)]\tLoss: 0.037461\n",
      "Train Epoch: 9 [0/3910 (0%)]\tLoss: 0.136421\n",
      "Train Epoch: 9 [640/3910 (16%)]\tLoss: 0.029092\n",
      "Train Epoch: 9 [1280/3910 (32%)]\tLoss: 0.055703\n",
      "Train Epoch: 9 [1920/3910 (48%)]\tLoss: 0.012118\n",
      "Train Epoch: 9 [2560/3910 (65%)]\tLoss: 0.141274\n",
      "Train Epoch: 9 [3200/3910 (81%)]\tLoss: 0.083865\n",
      "Train Epoch: 9 [3840/3910 (97%)]\tLoss: 0.146522\n",
      "Train Epoch: 10 [0/3910 (0%)]\tLoss: 0.034118\n",
      "Train Epoch: 10 [640/3910 (16%)]\tLoss: 0.013296\n",
      "Train Epoch: 10 [1280/3910 (32%)]\tLoss: 0.030793\n",
      "Train Epoch: 10 [1920/3910 (48%)]\tLoss: 0.099096\n",
      "Train Epoch: 10 [2560/3910 (65%)]\tLoss: 0.077063\n",
      "Train Epoch: 10 [3200/3910 (81%)]\tLoss: 0.020057\n",
      "Train Epoch: 10 [3840/3910 (97%)]\tLoss: 0.019384\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 0.113119\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 0.058096\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 0.068131\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 0.073616\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 0.107659\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 0.022432\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 0.092025\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 0.059773\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 0.048464\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 0.065857\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.090915\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.042532\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 0.026447\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 0.035114\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 0.018155\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.088529\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.071762\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.030631\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.060815\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.097230\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.021471\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.031063\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.046652\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.017218\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.023359\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.133520\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.066785\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.127265\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.016773\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.102797\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.010365\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.012403\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.008700\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.007305\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.003020\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.051079\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.076388\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.023948\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.038234\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.013949\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.150044\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.053466\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.027284\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.066144\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.012628\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.112794\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.043568\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.014547\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.004192\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.025251\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.052390\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.084865\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.082928\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.015640\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.030050\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.012573\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.228794\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.003479\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.015911\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.062552\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.013679\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.027777\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.017280\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.006591\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.122765\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.007346\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.046786\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.078999\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.013460\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.023406\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.014323\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.050140\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.057473\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.039559\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.010232\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.011498\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.010001\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.022598\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.075667\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.009100\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.152497\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.051355\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.057710\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.044028\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.032766\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.001637\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.033302\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.019524\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.098598\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.011177\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.058519\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.029296\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.034469\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.024188\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.012289\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.043929\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.020365\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.022178\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.027284\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.060743\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.096346\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.064176\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.006119\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.015896\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.008565\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.005797\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.030002\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.052641\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.022885\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.017199\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.006364\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.067063\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.030744\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.005397\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.024880\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.019516\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.008607\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.022961\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.063710\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.021909\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/5096 (0%)]\tLoss: 0.248129\n",
      "Train Epoch: 1 [640/5096 (12%)]\tLoss: 0.066985\n",
      "Train Epoch: 1 [1280/5096 (25%)]\tLoss: 0.218334\n",
      "Train Epoch: 1 [1920/5096 (38%)]\tLoss: 0.018815\n",
      "Train Epoch: 1 [2560/5096 (50%)]\tLoss: 0.107565\n",
      "Train Epoch: 1 [3200/5096 (62%)]\tLoss: 0.029403\n",
      "Train Epoch: 1 [3840/5096 (75%)]\tLoss: 0.075883\n",
      "Train Epoch: 1 [4480/5096 (88%)]\tLoss: 0.030958\n",
      "Train Epoch: 2 [0/5096 (0%)]\tLoss: 0.034843\n",
      "Train Epoch: 2 [640/5096 (12%)]\tLoss: 0.032278\n",
      "Train Epoch: 2 [1280/5096 (25%)]\tLoss: 0.033271\n",
      "Train Epoch: 2 [1920/5096 (38%)]\tLoss: 0.044914\n",
      "Train Epoch: 2 [2560/5096 (50%)]\tLoss: 0.088934\n",
      "Train Epoch: 2 [3200/5096 (62%)]\tLoss: 0.095027\n",
      "Train Epoch: 2 [3840/5096 (75%)]\tLoss: 0.081172\n",
      "Train Epoch: 2 [4480/5096 (88%)]\tLoss: 0.010297\n",
      "Train Epoch: 3 [0/5096 (0%)]\tLoss: 0.034788\n",
      "Train Epoch: 3 [640/5096 (12%)]\tLoss: 0.032213\n",
      "Train Epoch: 3 [1280/5096 (25%)]\tLoss: 0.006029\n",
      "Train Epoch: 3 [1920/5096 (38%)]\tLoss: 0.019515\n",
      "Train Epoch: 3 [2560/5096 (50%)]\tLoss: 0.007256\n",
      "Train Epoch: 3 [3200/5096 (62%)]\tLoss: 0.031243\n",
      "Train Epoch: 3 [3840/5096 (75%)]\tLoss: 0.025053\n",
      "Train Epoch: 3 [4480/5096 (88%)]\tLoss: 0.015399\n",
      "Train Epoch: 4 [0/5096 (0%)]\tLoss: 0.093058\n",
      "Train Epoch: 4 [640/5096 (12%)]\tLoss: 0.083910\n",
      "Train Epoch: 4 [1280/5096 (25%)]\tLoss: 0.033210\n",
      "Train Epoch: 4 [1920/5096 (38%)]\tLoss: 0.019663\n",
      "Train Epoch: 4 [2560/5096 (50%)]\tLoss: 0.001640\n",
      "Train Epoch: 4 [3200/5096 (62%)]\tLoss: 0.017517\n",
      "Train Epoch: 4 [3840/5096 (75%)]\tLoss: 0.022892\n",
      "Train Epoch: 4 [4480/5096 (88%)]\tLoss: 0.010349\n",
      "Train Epoch: 5 [0/5096 (0%)]\tLoss: 0.018152\n",
      "Train Epoch: 5 [640/5096 (12%)]\tLoss: 0.039906\n",
      "Train Epoch: 5 [1280/5096 (25%)]\tLoss: 0.023787\n",
      "Train Epoch: 5 [1920/5096 (38%)]\tLoss: 0.003021\n",
      "Train Epoch: 5 [2560/5096 (50%)]\tLoss: 0.015445\n",
      "Train Epoch: 5 [3200/5096 (62%)]\tLoss: 0.000929\n",
      "Train Epoch: 5 [3840/5096 (75%)]\tLoss: 0.073427\n",
      "Train Epoch: 5 [4480/5096 (88%)]\tLoss: 0.008151\n",
      "Train Epoch: 6 [0/5096 (0%)]\tLoss: 0.025195\n",
      "Train Epoch: 6 [640/5096 (12%)]\tLoss: 0.009185\n",
      "Train Epoch: 6 [1280/5096 (25%)]\tLoss: 0.010654\n",
      "Train Epoch: 6 [1920/5096 (38%)]\tLoss: 0.031535\n",
      "Train Epoch: 6 [2560/5096 (50%)]\tLoss: 0.007012\n",
      "Train Epoch: 6 [3200/5096 (62%)]\tLoss: 0.012969\n",
      "Train Epoch: 6 [3840/5096 (75%)]\tLoss: 0.010789\n",
      "Train Epoch: 6 [4480/5096 (88%)]\tLoss: 0.004228\n",
      "Train Epoch: 7 [0/5096 (0%)]\tLoss: 0.029313\n",
      "Train Epoch: 7 [640/5096 (12%)]\tLoss: 0.020102\n",
      "Train Epoch: 7 [1280/5096 (25%)]\tLoss: 0.008657\n",
      "Train Epoch: 7 [1920/5096 (38%)]\tLoss: 0.046433\n",
      "Train Epoch: 7 [2560/5096 (50%)]\tLoss: 0.008444\n",
      "Train Epoch: 7 [3200/5096 (62%)]\tLoss: 0.155226\n",
      "Train Epoch: 7 [3840/5096 (75%)]\tLoss: 0.019375\n",
      "Train Epoch: 7 [4480/5096 (88%)]\tLoss: 0.025567\n",
      "Train Epoch: 8 [0/5096 (0%)]\tLoss: 0.093129\n",
      "Train Epoch: 8 [640/5096 (12%)]\tLoss: 0.004022\n",
      "Train Epoch: 8 [1280/5096 (25%)]\tLoss: 0.003420\n",
      "Train Epoch: 8 [1920/5096 (38%)]\tLoss: 0.050698\n",
      "Train Epoch: 8 [2560/5096 (50%)]\tLoss: 0.167340\n",
      "Train Epoch: 8 [3200/5096 (62%)]\tLoss: 0.013573\n",
      "Train Epoch: 8 [3840/5096 (75%)]\tLoss: 0.008064\n",
      "Train Epoch: 8 [4480/5096 (88%)]\tLoss: 0.016235\n",
      "Train Epoch: 9 [0/5096 (0%)]\tLoss: 0.019065\n",
      "Train Epoch: 9 [640/5096 (12%)]\tLoss: 0.018282\n",
      "Train Epoch: 9 [1280/5096 (25%)]\tLoss: 0.011288\n",
      "Train Epoch: 9 [1920/5096 (38%)]\tLoss: 0.005985\n",
      "Train Epoch: 9 [2560/5096 (50%)]\tLoss: 0.010645\n",
      "Train Epoch: 9 [3200/5096 (62%)]\tLoss: 0.002570\n",
      "Train Epoch: 9 [3840/5096 (75%)]\tLoss: 0.015150\n",
      "Train Epoch: 9 [4480/5096 (88%)]\tLoss: 0.025889\n",
      "Train Epoch: 10 [0/5096 (0%)]\tLoss: 0.020329\n",
      "Train Epoch: 10 [640/5096 (12%)]\tLoss: 0.004095\n",
      "Train Epoch: 10 [1280/5096 (25%)]\tLoss: 0.020904\n",
      "Train Epoch: 10 [1920/5096 (38%)]\tLoss: 0.030768\n",
      "Train Epoch: 10 [2560/5096 (50%)]\tLoss: 0.043344\n",
      "Train Epoch: 10 [3200/5096 (62%)]\tLoss: 0.005304\n",
      "Train Epoch: 10 [3840/5096 (75%)]\tLoss: 0.026389\n",
      "Train Epoch: 10 [4480/5096 (88%)]\tLoss: 0.022010\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6865 (0%)]\tLoss: 0.156209\n",
      "Train Epoch: 1 [640/6865 (9%)]\tLoss: 0.068744\n",
      "Train Epoch: 1 [1280/6865 (19%)]\tLoss: 0.046590\n",
      "Train Epoch: 1 [1920/6865 (28%)]\tLoss: 0.007335\n",
      "Train Epoch: 1 [2560/6865 (37%)]\tLoss: 0.086800\n",
      "Train Epoch: 1 [3200/6865 (46%)]\tLoss: 0.040241\n",
      "Train Epoch: 1 [3840/6865 (56%)]\tLoss: 0.030192\n",
      "Train Epoch: 1 [4480/6865 (65%)]\tLoss: 0.073623\n",
      "Train Epoch: 1 [5120/6865 (74%)]\tLoss: 0.086071\n",
      "Train Epoch: 1 [5760/6865 (83%)]\tLoss: 0.028289\n",
      "Train Epoch: 1 [6400/6865 (93%)]\tLoss: 0.051128\n",
      "Train Epoch: 2 [0/6865 (0%)]\tLoss: 0.100234\n",
      "Train Epoch: 2 [640/6865 (9%)]\tLoss: 0.060458\n",
      "Train Epoch: 2 [1280/6865 (19%)]\tLoss: 0.027869\n",
      "Train Epoch: 2 [1920/6865 (28%)]\tLoss: 0.213020\n",
      "Train Epoch: 2 [2560/6865 (37%)]\tLoss: 0.014800\n",
      "Train Epoch: 2 [3200/6865 (46%)]\tLoss: 0.043325\n",
      "Train Epoch: 2 [3840/6865 (56%)]\tLoss: 0.033281\n",
      "Train Epoch: 2 [4480/6865 (65%)]\tLoss: 0.074341\n",
      "Train Epoch: 2 [5120/6865 (74%)]\tLoss: 0.055261\n",
      "Train Epoch: 2 [5760/6865 (83%)]\tLoss: 0.118625\n",
      "Train Epoch: 2 [6400/6865 (93%)]\tLoss: 0.056442\n",
      "Train Epoch: 3 [0/6865 (0%)]\tLoss: 0.008908\n",
      "Train Epoch: 3 [640/6865 (9%)]\tLoss: 0.035008\n",
      "Train Epoch: 3 [1280/6865 (19%)]\tLoss: 0.024943\n",
      "Train Epoch: 3 [1920/6865 (28%)]\tLoss: 0.031194\n",
      "Train Epoch: 3 [2560/6865 (37%)]\tLoss: 0.020766\n",
      "Train Epoch: 3 [3200/6865 (46%)]\tLoss: 0.006463\n",
      "Train Epoch: 3 [3840/6865 (56%)]\tLoss: 0.002077\n",
      "Train Epoch: 3 [4480/6865 (65%)]\tLoss: 0.017943\n",
      "Train Epoch: 3 [5120/6865 (74%)]\tLoss: 0.081992\n",
      "Train Epoch: 3 [5760/6865 (83%)]\tLoss: 0.042690\n",
      "Train Epoch: 3 [6400/6865 (93%)]\tLoss: 0.002657\n",
      "Train Epoch: 4 [0/6865 (0%)]\tLoss: 0.013099\n",
      "Train Epoch: 4 [640/6865 (9%)]\tLoss: 0.031641\n",
      "Train Epoch: 4 [1280/6865 (19%)]\tLoss: 0.042082\n",
      "Train Epoch: 4 [1920/6865 (28%)]\tLoss: 0.079676\n",
      "Train Epoch: 4 [2560/6865 (37%)]\tLoss: 0.140550\n",
      "Train Epoch: 4 [3200/6865 (46%)]\tLoss: 0.004804\n",
      "Train Epoch: 4 [3840/6865 (56%)]\tLoss: 0.095219\n",
      "Train Epoch: 4 [4480/6865 (65%)]\tLoss: 0.007412\n",
      "Train Epoch: 4 [5120/6865 (74%)]\tLoss: 0.052258\n",
      "Train Epoch: 4 [5760/6865 (83%)]\tLoss: 0.168141\n",
      "Train Epoch: 4 [6400/6865 (93%)]\tLoss: 0.129498\n",
      "Train Epoch: 5 [0/6865 (0%)]\tLoss: 0.062437\n",
      "Train Epoch: 5 [640/6865 (9%)]\tLoss: 0.022053\n",
      "Train Epoch: 5 [1280/6865 (19%)]\tLoss: 0.076581\n",
      "Train Epoch: 5 [1920/6865 (28%)]\tLoss: 0.039899\n",
      "Train Epoch: 5 [2560/6865 (37%)]\tLoss: 0.127679\n",
      "Train Epoch: 5 [3200/6865 (46%)]\tLoss: 0.087931\n",
      "Train Epoch: 5 [3840/6865 (56%)]\tLoss: 0.009106\n",
      "Train Epoch: 5 [4480/6865 (65%)]\tLoss: 0.095011\n",
      "Train Epoch: 5 [5120/6865 (74%)]\tLoss: 0.002203\n",
      "Train Epoch: 5 [5760/6865 (83%)]\tLoss: 0.003626\n",
      "Train Epoch: 5 [6400/6865 (93%)]\tLoss: 0.045592\n",
      "Train Epoch: 6 [0/6865 (0%)]\tLoss: 0.010419\n",
      "Train Epoch: 6 [640/6865 (9%)]\tLoss: 0.039452\n",
      "Train Epoch: 6 [1280/6865 (19%)]\tLoss: 0.008357\n",
      "Train Epoch: 6 [1920/6865 (28%)]\tLoss: 0.109584\n",
      "Train Epoch: 6 [2560/6865 (37%)]\tLoss: 0.057972\n",
      "Train Epoch: 6 [3200/6865 (46%)]\tLoss: 0.150044\n",
      "Train Epoch: 6 [3840/6865 (56%)]\tLoss: 0.044966\n",
      "Train Epoch: 6 [4480/6865 (65%)]\tLoss: 0.021019\n",
      "Train Epoch: 6 [5120/6865 (74%)]\tLoss: 0.026102\n",
      "Train Epoch: 6 [5760/6865 (83%)]\tLoss: 0.103139\n",
      "Train Epoch: 6 [6400/6865 (93%)]\tLoss: 0.030770\n",
      "Train Epoch: 7 [0/6865 (0%)]\tLoss: 0.034625\n",
      "Train Epoch: 7 [640/6865 (9%)]\tLoss: 0.019807\n",
      "Train Epoch: 7 [1280/6865 (19%)]\tLoss: 0.009263\n",
      "Train Epoch: 7 [1920/6865 (28%)]\tLoss: 0.044567\n",
      "Train Epoch: 7 [2560/6865 (37%)]\tLoss: 0.019488\n",
      "Train Epoch: 7 [3200/6865 (46%)]\tLoss: 0.037485\n",
      "Train Epoch: 7 [3840/6865 (56%)]\tLoss: 0.015951\n",
      "Train Epoch: 7 [4480/6865 (65%)]\tLoss: 0.073350\n",
      "Train Epoch: 7 [5120/6865 (74%)]\tLoss: 0.236636\n",
      "Train Epoch: 7 [5760/6865 (83%)]\tLoss: 0.051784\n",
      "Train Epoch: 7 [6400/6865 (93%)]\tLoss: 0.135664\n",
      "Train Epoch: 8 [0/6865 (0%)]\tLoss: 0.052979\n",
      "Train Epoch: 8 [640/6865 (9%)]\tLoss: 0.009667\n",
      "Train Epoch: 8 [1280/6865 (19%)]\tLoss: 0.074395\n",
      "Train Epoch: 8 [1920/6865 (28%)]\tLoss: 0.012173\n",
      "Train Epoch: 8 [2560/6865 (37%)]\tLoss: 0.013812\n",
      "Train Epoch: 8 [3200/6865 (46%)]\tLoss: 0.069850\n",
      "Train Epoch: 8 [3840/6865 (56%)]\tLoss: 0.020620\n",
      "Train Epoch: 8 [4480/6865 (65%)]\tLoss: 0.021692\n",
      "Train Epoch: 8 [5120/6865 (74%)]\tLoss: 0.058679\n",
      "Train Epoch: 8 [5760/6865 (83%)]\tLoss: 0.016661\n",
      "Train Epoch: 8 [6400/6865 (93%)]\tLoss: 0.011075\n",
      "Train Epoch: 9 [0/6865 (0%)]\tLoss: 0.017602\n",
      "Train Epoch: 9 [640/6865 (9%)]\tLoss: 0.003876\n",
      "Train Epoch: 9 [1280/6865 (19%)]\tLoss: 0.023862\n",
      "Train Epoch: 9 [1920/6865 (28%)]\tLoss: 0.043835\n",
      "Train Epoch: 9 [2560/6865 (37%)]\tLoss: 0.064098\n",
      "Train Epoch: 9 [3200/6865 (46%)]\tLoss: 0.017433\n",
      "Train Epoch: 9 [3840/6865 (56%)]\tLoss: 0.003693\n",
      "Train Epoch: 9 [4480/6865 (65%)]\tLoss: 0.004272\n",
      "Train Epoch: 9 [5120/6865 (74%)]\tLoss: 0.042494\n",
      "Train Epoch: 9 [5760/6865 (83%)]\tLoss: 0.013853\n",
      "Train Epoch: 9 [6400/6865 (93%)]\tLoss: 0.063513\n",
      "Train Epoch: 10 [0/6865 (0%)]\tLoss: 0.053637\n",
      "Train Epoch: 10 [640/6865 (9%)]\tLoss: 0.050547\n",
      "Train Epoch: 10 [1280/6865 (19%)]\tLoss: 0.031908\n",
      "Train Epoch: 10 [1920/6865 (28%)]\tLoss: 0.119766\n",
      "Train Epoch: 10 [2560/6865 (37%)]\tLoss: 0.023294\n",
      "Train Epoch: 10 [3200/6865 (46%)]\tLoss: 0.018121\n",
      "Train Epoch: 10 [3840/6865 (56%)]\tLoss: 0.010817\n",
      "Train Epoch: 10 [4480/6865 (65%)]\tLoss: 0.036603\n",
      "Train Epoch: 10 [5120/6865 (74%)]\tLoss: 0.035500\n",
      "Train Epoch: 10 [5760/6865 (83%)]\tLoss: 0.061030\n",
      "Train Epoch: 10 [6400/6865 (93%)]\tLoss: 0.005014\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0425, Accuracy: 9856/10000 (99%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 0.102164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 0.154266\n",
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 0.048811\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 0.050801\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 0.116319\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 0.049751\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 0.072199\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 0.155834\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 0.123118\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 0.032407\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 0.063195\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 0.061443\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 0.079497\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 0.090529\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 0.030887\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 0.018470\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 0.097113\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 0.023375\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 0.130593\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 0.046834\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.051134\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 0.058704\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 0.027724\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.100722\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.080933\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 0.018185\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.042427\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 0.056052\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.026767\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.067621\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.075284\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.078677\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.028982\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.144470\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.060578\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.036322\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.017790\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.041046\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.214097\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.028435\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.310668\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.102336\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.076754\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.079964\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.043673\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.042835\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.011622\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.013836\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.002020\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.042535\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.044227\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.209013\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.045270\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.037195\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.034877\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.021197\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.169628\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.045859\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.028345\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.047931\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.171411\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.064652\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.008607\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.019807\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.100127\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.159517\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.043728\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.175445\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.035088\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.093938\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.061797\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.075233\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.033562\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.195500\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.073311\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.143335\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.093968\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.141199\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.007842\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.041739\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.021106\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.063869\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.095465\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.037713\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.032504\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.141133\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.127849\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.021676\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.101395\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.045808\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.041773\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.036423\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.041434\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.044503\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.123230\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.027795\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.029553\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.099360\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.109679\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.061061\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.043184\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.088403\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.105005\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.032251\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.004063\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.082518\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.062002\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.074046\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 0.027092\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.045514\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.018835\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.176511\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.065522\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.142795\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.135309\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.062315\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.047124\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.027180\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.039739\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.060702\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.055009\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.159011\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.025271\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.022846\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.035462\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.049440\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.065574\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.198857\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.039727\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.031078\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.019008\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.171889\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.018237\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.009025\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.047227\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.025542\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.109839\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.133376\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.039517\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.041949\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.013101\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.051028\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.018905\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.026795\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.077170\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.127871\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.030429\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.020310\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.043322\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.055975\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.074775\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.025443\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.145707\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.182529\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.064475\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.072631\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.064130\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.075165\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.044044\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.073931\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.105713\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.065214\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.325512\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.021465\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.009421\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.018042\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.028761\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.055350\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.039435\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.147254\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.058477\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.058821\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.024041\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.079729\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.036056\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.136182\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.031844\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.015244\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.046824\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.024248\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/5110 (0%)]\tLoss: 0.044680\n",
      "Train Epoch: 1 [640/5110 (12%)]\tLoss: 0.093711\n",
      "Train Epoch: 1 [1280/5110 (25%)]\tLoss: 0.105701\n",
      "Train Epoch: 1 [1920/5110 (38%)]\tLoss: 0.054634\n",
      "Train Epoch: 1 [2560/5110 (50%)]\tLoss: 0.056962\n",
      "Train Epoch: 1 [3200/5110 (62%)]\tLoss: 0.027783\n",
      "Train Epoch: 1 [3840/5110 (75%)]\tLoss: 0.060404\n",
      "Train Epoch: 1 [4480/5110 (88%)]\tLoss: 0.114995\n",
      "Train Epoch: 2 [0/5110 (0%)]\tLoss: 0.008193\n",
      "Train Epoch: 2 [640/5110 (12%)]\tLoss: 0.039381\n",
      "Train Epoch: 2 [1280/5110 (25%)]\tLoss: 0.035878\n",
      "Train Epoch: 2 [1920/5110 (38%)]\tLoss: 0.117626\n",
      "Train Epoch: 2 [2560/5110 (50%)]\tLoss: 0.077707\n",
      "Train Epoch: 2 [3200/5110 (62%)]\tLoss: 0.221969\n",
      "Train Epoch: 2 [3840/5110 (75%)]\tLoss: 0.017422\n",
      "Train Epoch: 2 [4480/5110 (88%)]\tLoss: 0.039739\n",
      "Train Epoch: 3 [0/5110 (0%)]\tLoss: 0.110195\n",
      "Train Epoch: 3 [640/5110 (12%)]\tLoss: 0.051908\n",
      "Train Epoch: 3 [1280/5110 (25%)]\tLoss: 0.024801\n",
      "Train Epoch: 3 [1920/5110 (38%)]\tLoss: 0.097299\n",
      "Train Epoch: 3 [2560/5110 (50%)]\tLoss: 0.050201\n",
      "Train Epoch: 3 [3200/5110 (62%)]\tLoss: 0.178313\n",
      "Train Epoch: 3 [3840/5110 (75%)]\tLoss: 0.014720\n",
      "Train Epoch: 3 [4480/5110 (88%)]\tLoss: 0.091821\n",
      "Train Epoch: 4 [0/5110 (0%)]\tLoss: 0.055741\n",
      "Train Epoch: 4 [640/5110 (12%)]\tLoss: 0.225142\n",
      "Train Epoch: 4 [1280/5110 (25%)]\tLoss: 0.089061\n",
      "Train Epoch: 4 [1920/5110 (38%)]\tLoss: 0.011388\n",
      "Train Epoch: 4 [2560/5110 (50%)]\tLoss: 0.045941\n",
      "Train Epoch: 4 [3200/5110 (62%)]\tLoss: 0.100842\n",
      "Train Epoch: 4 [3840/5110 (75%)]\tLoss: 0.041355\n",
      "Train Epoch: 4 [4480/5110 (88%)]\tLoss: 0.028715\n",
      "Train Epoch: 5 [0/5110 (0%)]\tLoss: 0.182303\n",
      "Train Epoch: 5 [640/5110 (12%)]\tLoss: 0.036285\n",
      "Train Epoch: 5 [1280/5110 (25%)]\tLoss: 0.053530\n",
      "Train Epoch: 5 [1920/5110 (38%)]\tLoss: 0.118693\n",
      "Train Epoch: 5 [2560/5110 (50%)]\tLoss: 0.072823\n",
      "Train Epoch: 5 [3200/5110 (62%)]\tLoss: 0.103053\n",
      "Train Epoch: 5 [3840/5110 (75%)]\tLoss: 0.053700\n",
      "Train Epoch: 5 [4480/5110 (88%)]\tLoss: 0.037363\n",
      "Train Epoch: 6 [0/5110 (0%)]\tLoss: 0.225046\n",
      "Train Epoch: 6 [640/5110 (12%)]\tLoss: 0.064529\n",
      "Train Epoch: 6 [1280/5110 (25%)]\tLoss: 0.028284\n",
      "Train Epoch: 6 [1920/5110 (38%)]\tLoss: 0.052745\n",
      "Train Epoch: 6 [2560/5110 (50%)]\tLoss: 0.020797\n",
      "Train Epoch: 6 [3200/5110 (62%)]\tLoss: 0.026300\n",
      "Train Epoch: 6 [3840/5110 (75%)]\tLoss: 0.072147\n",
      "Train Epoch: 6 [4480/5110 (88%)]\tLoss: 0.044215\n",
      "Train Epoch: 7 [0/5110 (0%)]\tLoss: 0.031901\n",
      "Train Epoch: 7 [640/5110 (12%)]\tLoss: 0.072571\n",
      "Train Epoch: 7 [1280/5110 (25%)]\tLoss: 0.050388\n",
      "Train Epoch: 7 [1920/5110 (38%)]\tLoss: 0.014479\n",
      "Train Epoch: 7 [2560/5110 (50%)]\tLoss: 0.082250\n",
      "Train Epoch: 7 [3200/5110 (62%)]\tLoss: 0.066871\n",
      "Train Epoch: 7 [3840/5110 (75%)]\tLoss: 0.008399\n",
      "Train Epoch: 7 [4480/5110 (88%)]\tLoss: 0.020055\n",
      "Train Epoch: 8 [0/5110 (0%)]\tLoss: 0.006096\n",
      "Train Epoch: 8 [640/5110 (12%)]\tLoss: 0.062803\n",
      "Train Epoch: 8 [1280/5110 (25%)]\tLoss: 0.049617\n",
      "Train Epoch: 8 [1920/5110 (38%)]\tLoss: 0.139978\n",
      "Train Epoch: 8 [2560/5110 (50%)]\tLoss: 0.058102\n",
      "Train Epoch: 8 [3200/5110 (62%)]\tLoss: 0.008247\n",
      "Train Epoch: 8 [3840/5110 (75%)]\tLoss: 0.039542\n",
      "Train Epoch: 8 [4480/5110 (88%)]\tLoss: 0.094746\n",
      "Train Epoch: 9 [0/5110 (0%)]\tLoss: 0.023301\n",
      "Train Epoch: 9 [640/5110 (12%)]\tLoss: 0.021553\n",
      "Train Epoch: 9 [1280/5110 (25%)]\tLoss: 0.026705\n",
      "Train Epoch: 9 [1920/5110 (38%)]\tLoss: 0.031188\n",
      "Train Epoch: 9 [2560/5110 (50%)]\tLoss: 0.027006\n",
      "Train Epoch: 9 [3200/5110 (62%)]\tLoss: 0.017254\n",
      "Train Epoch: 9 [3840/5110 (75%)]\tLoss: 0.048581\n",
      "Train Epoch: 9 [4480/5110 (88%)]\tLoss: 0.021792\n",
      "Train Epoch: 10 [0/5110 (0%)]\tLoss: 0.014915\n",
      "Train Epoch: 10 [640/5110 (12%)]\tLoss: 0.044770\n",
      "Train Epoch: 10 [1280/5110 (25%)]\tLoss: 0.077622\n",
      "Train Epoch: 10 [1920/5110 (38%)]\tLoss: 0.007701\n",
      "Train Epoch: 10 [2560/5110 (50%)]\tLoss: 0.085522\n",
      "Train Epoch: 10 [3200/5110 (62%)]\tLoss: 0.066110\n",
      "Train Epoch: 10 [3840/5110 (75%)]\tLoss: 0.065793\n",
      "Train Epoch: 10 [4480/5110 (88%)]\tLoss: 0.016987\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6766 (0%)]\tLoss: 0.103486\n",
      "Train Epoch: 1 [640/6766 (9%)]\tLoss: 0.035888\n",
      "Train Epoch: 1 [1280/6766 (19%)]\tLoss: 0.013899\n",
      "Train Epoch: 1 [1920/6766 (28%)]\tLoss: 0.099020\n",
      "Train Epoch: 1 [2560/6766 (38%)]\tLoss: 0.123390\n",
      "Train Epoch: 1 [3200/6766 (47%)]\tLoss: 0.069446\n",
      "Train Epoch: 1 [3840/6766 (57%)]\tLoss: 0.079792\n",
      "Train Epoch: 1 [4480/6766 (66%)]\tLoss: 0.219077\n",
      "Train Epoch: 1 [5120/6766 (75%)]\tLoss: 0.042103\n",
      "Train Epoch: 1 [5760/6766 (85%)]\tLoss: 0.062799\n",
      "Train Epoch: 1 [6400/6766 (94%)]\tLoss: 0.017795\n",
      "Train Epoch: 2 [0/6766 (0%)]\tLoss: 0.125983\n",
      "Train Epoch: 2 [640/6766 (9%)]\tLoss: 0.071650\n",
      "Train Epoch: 2 [1280/6766 (19%)]\tLoss: 0.123185\n",
      "Train Epoch: 2 [1920/6766 (28%)]\tLoss: 0.025412\n",
      "Train Epoch: 2 [2560/6766 (38%)]\tLoss: 0.150564\n",
      "Train Epoch: 2 [3200/6766 (47%)]\tLoss: 0.058311\n",
      "Train Epoch: 2 [3840/6766 (57%)]\tLoss: 0.030201\n",
      "Train Epoch: 2 [4480/6766 (66%)]\tLoss: 0.064739\n",
      "Train Epoch: 2 [5120/6766 (75%)]\tLoss: 0.045850\n",
      "Train Epoch: 2 [5760/6766 (85%)]\tLoss: 0.018101\n",
      "Train Epoch: 2 [6400/6766 (94%)]\tLoss: 0.071736\n",
      "Train Epoch: 3 [0/6766 (0%)]\tLoss: 0.025102\n",
      "Train Epoch: 3 [640/6766 (9%)]\tLoss: 0.044884\n",
      "Train Epoch: 3 [1280/6766 (19%)]\tLoss: 0.074404\n",
      "Train Epoch: 3 [1920/6766 (28%)]\tLoss: 0.013165\n",
      "Train Epoch: 3 [2560/6766 (38%)]\tLoss: 0.039409\n",
      "Train Epoch: 3 [3200/6766 (47%)]\tLoss: 0.025934\n",
      "Train Epoch: 3 [3840/6766 (57%)]\tLoss: 0.034011\n",
      "Train Epoch: 3 [4480/6766 (66%)]\tLoss: 0.042122\n",
      "Train Epoch: 3 [5120/6766 (75%)]\tLoss: 0.204338\n",
      "Train Epoch: 3 [5760/6766 (85%)]\tLoss: 0.019710\n",
      "Train Epoch: 3 [6400/6766 (94%)]\tLoss: 0.077607\n",
      "Train Epoch: 4 [0/6766 (0%)]\tLoss: 0.014982\n",
      "Train Epoch: 4 [640/6766 (9%)]\tLoss: 0.053925\n",
      "Train Epoch: 4 [1280/6766 (19%)]\tLoss: 0.021649\n",
      "Train Epoch: 4 [1920/6766 (28%)]\tLoss: 0.017469\n",
      "Train Epoch: 4 [2560/6766 (38%)]\tLoss: 0.040717\n",
      "Train Epoch: 4 [3200/6766 (47%)]\tLoss: 0.032406\n",
      "Train Epoch: 4 [3840/6766 (57%)]\tLoss: 0.052513\n",
      "Train Epoch: 4 [4480/6766 (66%)]\tLoss: 0.369003\n",
      "Train Epoch: 4 [5120/6766 (75%)]\tLoss: 0.122764\n",
      "Train Epoch: 4 [5760/6766 (85%)]\tLoss: 0.080834\n",
      "Train Epoch: 4 [6400/6766 (94%)]\tLoss: 0.060938\n",
      "Train Epoch: 5 [0/6766 (0%)]\tLoss: 0.020143\n",
      "Train Epoch: 5 [640/6766 (9%)]\tLoss: 0.022114\n",
      "Train Epoch: 5 [1280/6766 (19%)]\tLoss: 0.013402\n",
      "Train Epoch: 5 [1920/6766 (28%)]\tLoss: 0.036710\n",
      "Train Epoch: 5 [2560/6766 (38%)]\tLoss: 0.021036\n",
      "Train Epoch: 5 [3200/6766 (47%)]\tLoss: 0.016043\n",
      "Train Epoch: 5 [3840/6766 (57%)]\tLoss: 0.041108\n",
      "Train Epoch: 5 [4480/6766 (66%)]\tLoss: 0.004244\n",
      "Train Epoch: 5 [5120/6766 (75%)]\tLoss: 0.065778\n",
      "Train Epoch: 5 [5760/6766 (85%)]\tLoss: 0.087499\n",
      "Train Epoch: 5 [6400/6766 (94%)]\tLoss: 0.115250\n",
      "Train Epoch: 6 [0/6766 (0%)]\tLoss: 0.041267\n",
      "Train Epoch: 6 [640/6766 (9%)]\tLoss: 0.009199\n",
      "Train Epoch: 6 [1280/6766 (19%)]\tLoss: 0.043555\n",
      "Train Epoch: 6 [1920/6766 (28%)]\tLoss: 0.044304\n",
      "Train Epoch: 6 [2560/6766 (38%)]\tLoss: 0.139711\n",
      "Train Epoch: 6 [3200/6766 (47%)]\tLoss: 0.034024\n",
      "Train Epoch: 6 [3840/6766 (57%)]\tLoss: 0.013216\n",
      "Train Epoch: 6 [4480/6766 (66%)]\tLoss: 0.031617\n",
      "Train Epoch: 6 [5120/6766 (75%)]\tLoss: 0.021279\n",
      "Train Epoch: 6 [5760/6766 (85%)]\tLoss: 0.018752\n",
      "Train Epoch: 6 [6400/6766 (94%)]\tLoss: 0.046286\n",
      "Train Epoch: 7 [0/6766 (0%)]\tLoss: 0.015850\n",
      "Train Epoch: 7 [640/6766 (9%)]\tLoss: 0.187054\n",
      "Train Epoch: 7 [1280/6766 (19%)]\tLoss: 0.024257\n",
      "Train Epoch: 7 [1920/6766 (28%)]\tLoss: 0.064624\n",
      "Train Epoch: 7 [2560/6766 (38%)]\tLoss: 0.029390\n",
      "Train Epoch: 7 [3200/6766 (47%)]\tLoss: 0.222544\n",
      "Train Epoch: 7 [3840/6766 (57%)]\tLoss: 0.066298\n",
      "Train Epoch: 7 [4480/6766 (66%)]\tLoss: 0.004382\n",
      "Train Epoch: 7 [5120/6766 (75%)]\tLoss: 0.083855\n",
      "Train Epoch: 7 [5760/6766 (85%)]\tLoss: 0.083239\n",
      "Train Epoch: 7 [6400/6766 (94%)]\tLoss: 0.026523\n",
      "Train Epoch: 8 [0/6766 (0%)]\tLoss: 0.010508\n",
      "Train Epoch: 8 [640/6766 (9%)]\tLoss: 0.052822\n",
      "Train Epoch: 8 [1280/6766 (19%)]\tLoss: 0.066714\n",
      "Train Epoch: 8 [1920/6766 (28%)]\tLoss: 0.051233\n",
      "Train Epoch: 8 [2560/6766 (38%)]\tLoss: 0.007365\n",
      "Train Epoch: 8 [3200/6766 (47%)]\tLoss: 0.059205\n",
      "Train Epoch: 8 [3840/6766 (57%)]\tLoss: 0.018860\n",
      "Train Epoch: 8 [4480/6766 (66%)]\tLoss: 0.014163\n",
      "Train Epoch: 8 [5120/6766 (75%)]\tLoss: 0.022767\n",
      "Train Epoch: 8 [5760/6766 (85%)]\tLoss: 0.044201\n",
      "Train Epoch: 8 [6400/6766 (94%)]\tLoss: 0.035370\n",
      "Train Epoch: 9 [0/6766 (0%)]\tLoss: 0.032455\n",
      "Train Epoch: 9 [640/6766 (9%)]\tLoss: 0.022713\n",
      "Train Epoch: 9 [1280/6766 (19%)]\tLoss: 0.046878\n",
      "Train Epoch: 9 [1920/6766 (28%)]\tLoss: 0.005539\n",
      "Train Epoch: 9 [2560/6766 (38%)]\tLoss: 0.012291\n",
      "Train Epoch: 9 [3200/6766 (47%)]\tLoss: 0.132801\n",
      "Train Epoch: 9 [3840/6766 (57%)]\tLoss: 0.027440\n",
      "Train Epoch: 9 [4480/6766 (66%)]\tLoss: 0.027802\n",
      "Train Epoch: 9 [5120/6766 (75%)]\tLoss: 0.074169\n",
      "Train Epoch: 9 [5760/6766 (85%)]\tLoss: 0.014305\n",
      "Train Epoch: 9 [6400/6766 (94%)]\tLoss: 0.179158\n",
      "Train Epoch: 10 [0/6766 (0%)]\tLoss: 0.261402\n",
      "Train Epoch: 10 [640/6766 (9%)]\tLoss: 0.007958\n",
      "Train Epoch: 10 [1280/6766 (19%)]\tLoss: 0.040189\n",
      "Train Epoch: 10 [1920/6766 (28%)]\tLoss: 0.010452\n",
      "Train Epoch: 10 [2560/6766 (38%)]\tLoss: 0.054672\n",
      "Train Epoch: 10 [3200/6766 (47%)]\tLoss: 0.044100\n",
      "Train Epoch: 10 [3840/6766 (57%)]\tLoss: 0.093546\n",
      "Train Epoch: 10 [4480/6766 (66%)]\tLoss: 0.133822\n",
      "Train Epoch: 10 [5120/6766 (75%)]\tLoss: 0.008220\n",
      "Train Epoch: 10 [5760/6766 (85%)]\tLoss: 0.030352\n",
      "Train Epoch: 10 [6400/6766 (94%)]\tLoss: 0.017417\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 0.093054\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 0.205769\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 0.141002\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 0.053496\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 0.034841\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 0.222750\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 0.196028\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 0.008373\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 0.093377\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 0.069492\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 0.020538\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 0.073357\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 0.063697\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 0.103240\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 0.012314\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 0.083175\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 0.023310\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.191078\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.032720\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.021268\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.275422\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.119710\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.015973\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.054514\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.016180\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.032188\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.028298\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.039306\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.032373\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.012159\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.021708\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.050672\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.049294\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.064712\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.013754\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.010396\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.036990\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.032302\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.034582\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.095985\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.053389\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.043105\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.037098\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.235683\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.051792\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.023754\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.030695\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.031561\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.049253\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.118178\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.048269\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.044080\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.106961\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.020788\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.072683\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.079063\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.044507\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.046642\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.108077\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.079978\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.040559\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.041645\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.105511\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.041004\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.047016\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.032088\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.047930\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.026633\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.017311\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.070191\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.035824\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.133294\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.047985\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.009656\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.091724\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.029572\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.015570\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.031071\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.050099\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.154372\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.046957\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.130662\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.028402\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.085823\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.088497\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.124272\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.088476\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.109608\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.031167\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.022724\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.030390\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.026259\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.032307\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.061014\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.013067\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.115242\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.042918\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.133433\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.014463\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.045805\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.117116\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.085152\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.012973\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.051462\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.008510\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.035166\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.011265\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.074686\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.130721\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.036412\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.026524\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.003873\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.013555\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.068488\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.011655\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.014704\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.045365\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.027638\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.004640\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.044487\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.008895\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.142201\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.033386\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.101229\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.033430\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.033126\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.056421\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.025948\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.009331\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.112142\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.089390\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.014090\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.014059\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.061266\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.020746\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.037332\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.005066\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.051985\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.062893\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.044373\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.041018\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.031765\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.019539\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.122765\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.029285\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.020418\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.012662\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.081273\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.007295\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.063823\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.029825\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.047895\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.225252\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.026738\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.072820\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.075058\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.059378\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.018537\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.017823\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.101331\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/3910 (0%)]\tLoss: 0.134325\n",
      "Train Epoch: 1 [640/3910 (16%)]\tLoss: 0.064096\n",
      "Train Epoch: 1 [1280/3910 (32%)]\tLoss: 0.050521\n",
      "Train Epoch: 1 [1920/3910 (48%)]\tLoss: 0.294078\n",
      "Train Epoch: 1 [2560/3910 (65%)]\tLoss: 0.038613\n",
      "Train Epoch: 1 [3200/3910 (81%)]\tLoss: 0.116260\n",
      "Train Epoch: 1 [3840/3910 (97%)]\tLoss: 0.062665\n",
      "Train Epoch: 2 [0/3910 (0%)]\tLoss: 0.089393\n",
      "Train Epoch: 2 [640/3910 (16%)]\tLoss: 0.042300\n",
      "Train Epoch: 2 [1280/3910 (32%)]\tLoss: 0.147652\n",
      "Train Epoch: 2 [1920/3910 (48%)]\tLoss: 0.130257\n",
      "Train Epoch: 2 [2560/3910 (65%)]\tLoss: 0.056587\n",
      "Train Epoch: 2 [3200/3910 (81%)]\tLoss: 0.124606\n",
      "Train Epoch: 2 [3840/3910 (97%)]\tLoss: 0.057400\n",
      "Train Epoch: 3 [0/3910 (0%)]\tLoss: 0.035086\n",
      "Train Epoch: 3 [640/3910 (16%)]\tLoss: 0.005534\n",
      "Train Epoch: 3 [1280/3910 (32%)]\tLoss: 0.093232\n",
      "Train Epoch: 3 [1920/3910 (48%)]\tLoss: 0.083047\n",
      "Train Epoch: 3 [2560/3910 (65%)]\tLoss: 0.057225\n",
      "Train Epoch: 3 [3200/3910 (81%)]\tLoss: 0.017216\n",
      "Train Epoch: 3 [3840/3910 (97%)]\tLoss: 0.083281\n",
      "Train Epoch: 4 [0/3910 (0%)]\tLoss: 0.052163\n",
      "Train Epoch: 4 [640/3910 (16%)]\tLoss: 0.018131\n",
      "Train Epoch: 4 [1280/3910 (32%)]\tLoss: 0.111892\n",
      "Train Epoch: 4 [1920/3910 (48%)]\tLoss: 0.092192\n",
      "Train Epoch: 4 [2560/3910 (65%)]\tLoss: 0.053843\n",
      "Train Epoch: 4 [3200/3910 (81%)]\tLoss: 0.036805\n",
      "Train Epoch: 4 [3840/3910 (97%)]\tLoss: 0.027362\n",
      "Train Epoch: 5 [0/3910 (0%)]\tLoss: 0.110012\n",
      "Train Epoch: 5 [640/3910 (16%)]\tLoss: 0.145804\n",
      "Train Epoch: 5 [1280/3910 (32%)]\tLoss: 0.079583\n",
      "Train Epoch: 5 [1920/3910 (48%)]\tLoss: 0.033999\n",
      "Train Epoch: 5 [2560/3910 (65%)]\tLoss: 0.037085\n",
      "Train Epoch: 5 [3200/3910 (81%)]\tLoss: 0.008534\n",
      "Train Epoch: 5 [3840/3910 (97%)]\tLoss: 0.018957\n",
      "Train Epoch: 6 [0/3910 (0%)]\tLoss: 0.039423\n",
      "Train Epoch: 6 [640/3910 (16%)]\tLoss: 0.008293\n",
      "Train Epoch: 6 [1280/3910 (32%)]\tLoss: 0.081248\n",
      "Train Epoch: 6 [1920/3910 (48%)]\tLoss: 0.175237\n",
      "Train Epoch: 6 [2560/3910 (65%)]\tLoss: 0.041144\n",
      "Train Epoch: 6 [3200/3910 (81%)]\tLoss: 0.027437\n",
      "Train Epoch: 6 [3840/3910 (97%)]\tLoss: 0.019201\n",
      "Train Epoch: 7 [0/3910 (0%)]\tLoss: 0.062166\n",
      "Train Epoch: 7 [640/3910 (16%)]\tLoss: 0.067342\n",
      "Train Epoch: 7 [1280/3910 (32%)]\tLoss: 0.089817\n",
      "Train Epoch: 7 [1920/3910 (48%)]\tLoss: 0.033518\n",
      "Train Epoch: 7 [2560/3910 (65%)]\tLoss: 0.239116\n",
      "Train Epoch: 7 [3200/3910 (81%)]\tLoss: 0.058767\n",
      "Train Epoch: 7 [3840/3910 (97%)]\tLoss: 0.159498\n",
      "Train Epoch: 8 [0/3910 (0%)]\tLoss: 0.075015\n",
      "Train Epoch: 8 [640/3910 (16%)]\tLoss: 0.007663\n",
      "Train Epoch: 8 [1280/3910 (32%)]\tLoss: 0.048988\n",
      "Train Epoch: 8 [1920/3910 (48%)]\tLoss: 0.038833\n",
      "Train Epoch: 8 [2560/3910 (65%)]\tLoss: 0.022255\n",
      "Train Epoch: 8 [3200/3910 (81%)]\tLoss: 0.179271\n",
      "Train Epoch: 8 [3840/3910 (97%)]\tLoss: 0.044818\n",
      "Train Epoch: 9 [0/3910 (0%)]\tLoss: 0.025307\n",
      "Train Epoch: 9 [640/3910 (16%)]\tLoss: 0.027917\n",
      "Train Epoch: 9 [1280/3910 (32%)]\tLoss: 0.044193\n",
      "Train Epoch: 9 [1920/3910 (48%)]\tLoss: 0.047973\n",
      "Train Epoch: 9 [2560/3910 (65%)]\tLoss: 0.042051\n",
      "Train Epoch: 9 [3200/3910 (81%)]\tLoss: 0.035304\n",
      "Train Epoch: 9 [3840/3910 (97%)]\tLoss: 0.033229\n",
      "Train Epoch: 10 [0/3910 (0%)]\tLoss: 0.024887\n",
      "Train Epoch: 10 [640/3910 (16%)]\tLoss: 0.023363\n",
      "Train Epoch: 10 [1280/3910 (32%)]\tLoss: 0.007308\n",
      "Train Epoch: 10 [1920/3910 (48%)]\tLoss: 0.148325\n",
      "Train Epoch: 10 [2560/3910 (65%)]\tLoss: 0.004086\n",
      "Train Epoch: 10 [3200/3910 (81%)]\tLoss: 0.043694\n",
      "Train Epoch: 10 [3840/3910 (97%)]\tLoss: 0.017231\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 0.109947\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 0.117272\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 0.093876\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 0.153159\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 0.109175\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 0.051087\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 0.084220\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 0.150953\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 0.042021\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 0.084087\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.066325\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.028101\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 0.041159\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 0.070084\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 0.051905\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.074048\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.031645\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.119800\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.014100\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.087826\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.030269\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.061517\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.026054\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.151630\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.033108\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.052880\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.053893\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.010857\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.128345\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.027989\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.113696\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.032795\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.092629\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.060535\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.058874\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.093049\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.039915\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.037877\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.021053\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.130321\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.072205\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.071280\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.018477\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.075325\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.021550\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.083361\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.029117\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.039232\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.020853\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.031990\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.007484\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.038140\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.007907\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.023632\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.003011\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.032202\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.036895\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.089225\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.042819\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.024009\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.036822\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.025628\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.014256\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.118126\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.006663\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.129953\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.017151\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.018601\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.009540\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.042678\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.045722\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.010493\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.011447\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.027888\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.073281\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.019512\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.069346\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.137902\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.004550\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.097962\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.029008\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.045463\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.034911\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.004778\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.031193\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.019658\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.020399\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.025988\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.042896\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.048750\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.002906\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.012039\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.081501\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.029017\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.041023\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.003573\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.122922\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.027168\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.043546\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.044643\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.032697\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.022243\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.107240\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.035755\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.057062\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.019769\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.057035\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.058239\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.021975\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.029155\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.006457\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.004535\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.025838\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.065263\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.047123\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.009512\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.006213\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.039861\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.055143\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.006296\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/5096 (0%)]\tLoss: 0.139373\n",
      "Train Epoch: 1 [640/5096 (12%)]\tLoss: 0.058725\n",
      "Train Epoch: 1 [1280/5096 (25%)]\tLoss: 0.048551\n",
      "Train Epoch: 1 [1920/5096 (38%)]\tLoss: 0.020122\n",
      "Train Epoch: 1 [2560/5096 (50%)]\tLoss: 0.058660\n",
      "Train Epoch: 1 [3200/5096 (62%)]\tLoss: 0.029656\n",
      "Train Epoch: 1 [3840/5096 (75%)]\tLoss: 0.008370\n",
      "Train Epoch: 1 [4480/5096 (88%)]\tLoss: 0.048768\n",
      "Train Epoch: 2 [0/5096 (0%)]\tLoss: 0.031278\n",
      "Train Epoch: 2 [640/5096 (12%)]\tLoss: 0.050410\n",
      "Train Epoch: 2 [1280/5096 (25%)]\tLoss: 0.007656\n",
      "Train Epoch: 2 [1920/5096 (38%)]\tLoss: 0.025676\n",
      "Train Epoch: 2 [2560/5096 (50%)]\tLoss: 0.051010\n",
      "Train Epoch: 2 [3200/5096 (62%)]\tLoss: 0.050990\n",
      "Train Epoch: 2 [3840/5096 (75%)]\tLoss: 0.090226\n",
      "Train Epoch: 2 [4480/5096 (88%)]\tLoss: 0.002377\n",
      "Train Epoch: 3 [0/5096 (0%)]\tLoss: 0.103592\n",
      "Train Epoch: 3 [640/5096 (12%)]\tLoss: 0.065181\n",
      "Train Epoch: 3 [1280/5096 (25%)]\tLoss: 0.086131\n",
      "Train Epoch: 3 [1920/5096 (38%)]\tLoss: 0.017895\n",
      "Train Epoch: 3 [2560/5096 (50%)]\tLoss: 0.042650\n",
      "Train Epoch: 3 [3200/5096 (62%)]\tLoss: 0.087502\n",
      "Train Epoch: 3 [3840/5096 (75%)]\tLoss: 0.024319\n",
      "Train Epoch: 3 [4480/5096 (88%)]\tLoss: 0.022099\n",
      "Train Epoch: 4 [0/5096 (0%)]\tLoss: 0.027164\n",
      "Train Epoch: 4 [640/5096 (12%)]\tLoss: 0.017300\n",
      "Train Epoch: 4 [1280/5096 (25%)]\tLoss: 0.066575\n",
      "Train Epoch: 4 [1920/5096 (38%)]\tLoss: 0.009980\n",
      "Train Epoch: 4 [2560/5096 (50%)]\tLoss: 0.014701\n",
      "Train Epoch: 4 [3200/5096 (62%)]\tLoss: 0.034929\n",
      "Train Epoch: 4 [3840/5096 (75%)]\tLoss: 0.034812\n",
      "Train Epoch: 4 [4480/5096 (88%)]\tLoss: 0.061793\n",
      "Train Epoch: 5 [0/5096 (0%)]\tLoss: 0.011272\n",
      "Train Epoch: 5 [640/5096 (12%)]\tLoss: 0.016231\n",
      "Train Epoch: 5 [1280/5096 (25%)]\tLoss: 0.017388\n",
      "Train Epoch: 5 [1920/5096 (38%)]\tLoss: 0.012213\n",
      "Train Epoch: 5 [2560/5096 (50%)]\tLoss: 0.038927\n",
      "Train Epoch: 5 [3200/5096 (62%)]\tLoss: 0.008257\n",
      "Train Epoch: 5 [3840/5096 (75%)]\tLoss: 0.000945\n",
      "Train Epoch: 5 [4480/5096 (88%)]\tLoss: 0.002589\n",
      "Train Epoch: 6 [0/5096 (0%)]\tLoss: 0.012626\n",
      "Train Epoch: 6 [640/5096 (12%)]\tLoss: 0.079187\n",
      "Train Epoch: 6 [1280/5096 (25%)]\tLoss: 0.010489\n",
      "Train Epoch: 6 [1920/5096 (38%)]\tLoss: 0.053883\n",
      "Train Epoch: 6 [2560/5096 (50%)]\tLoss: 0.150014\n",
      "Train Epoch: 6 [3200/5096 (62%)]\tLoss: 0.015579\n",
      "Train Epoch: 6 [3840/5096 (75%)]\tLoss: 0.002798\n",
      "Train Epoch: 6 [4480/5096 (88%)]\tLoss: 0.008596\n",
      "Train Epoch: 7 [0/5096 (0%)]\tLoss: 0.007456\n",
      "Train Epoch: 7 [640/5096 (12%)]\tLoss: 0.032897\n",
      "Train Epoch: 7 [1280/5096 (25%)]\tLoss: 0.001443\n",
      "Train Epoch: 7 [1920/5096 (38%)]\tLoss: 0.003205\n",
      "Train Epoch: 7 [2560/5096 (50%)]\tLoss: 0.011090\n",
      "Train Epoch: 7 [3200/5096 (62%)]\tLoss: 0.006577\n",
      "Train Epoch: 7 [3840/5096 (75%)]\tLoss: 0.046684\n",
      "Train Epoch: 7 [4480/5096 (88%)]\tLoss: 0.073947\n",
      "Train Epoch: 8 [0/5096 (0%)]\tLoss: 0.010067\n",
      "Train Epoch: 8 [640/5096 (12%)]\tLoss: 0.001728\n",
      "Train Epoch: 8 [1280/5096 (25%)]\tLoss: 0.070960\n",
      "Train Epoch: 8 [1920/5096 (38%)]\tLoss: 0.015989\n",
      "Train Epoch: 8 [2560/5096 (50%)]\tLoss: 0.018265\n",
      "Train Epoch: 8 [3200/5096 (62%)]\tLoss: 0.003751\n",
      "Train Epoch: 8 [3840/5096 (75%)]\tLoss: 0.008194\n",
      "Train Epoch: 8 [4480/5096 (88%)]\tLoss: 0.016456\n",
      "Train Epoch: 9 [0/5096 (0%)]\tLoss: 0.007402\n",
      "Train Epoch: 9 [640/5096 (12%)]\tLoss: 0.027735\n",
      "Train Epoch: 9 [1280/5096 (25%)]\tLoss: 0.103986\n",
      "Train Epoch: 9 [1920/5096 (38%)]\tLoss: 0.005512\n",
      "Train Epoch: 9 [2560/5096 (50%)]\tLoss: 0.023081\n",
      "Train Epoch: 9 [3200/5096 (62%)]\tLoss: 0.106822\n",
      "Train Epoch: 9 [3840/5096 (75%)]\tLoss: 0.093479\n",
      "Train Epoch: 9 [4480/5096 (88%)]\tLoss: 0.049059\n",
      "Train Epoch: 10 [0/5096 (0%)]\tLoss: 0.030240\n",
      "Train Epoch: 10 [640/5096 (12%)]\tLoss: 0.008320\n",
      "Train Epoch: 10 [1280/5096 (25%)]\tLoss: 0.044728\n",
      "Train Epoch: 10 [1920/5096 (38%)]\tLoss: 0.000713\n",
      "Train Epoch: 10 [2560/5096 (50%)]\tLoss: 0.004036\n",
      "Train Epoch: 10 [3200/5096 (62%)]\tLoss: 0.044225\n",
      "Train Epoch: 10 [3840/5096 (75%)]\tLoss: 0.023410\n",
      "Train Epoch: 10 [4480/5096 (88%)]\tLoss: 0.006257\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/1599 (0%)]\tLoss: 0.157219\n",
      "Train Epoch: 1 [640/1599 (40%)]\tLoss: 0.095370\n",
      "Train Epoch: 1 [1280/1599 (80%)]\tLoss: 0.257526\n",
      "Train Epoch: 2 [0/1599 (0%)]\tLoss: 0.054569\n",
      "Train Epoch: 2 [640/1599 (40%)]\tLoss: 0.039161\n",
      "Train Epoch: 2 [1280/1599 (80%)]\tLoss: 0.040072\n",
      "Train Epoch: 3 [0/1599 (0%)]\tLoss: 0.042572\n",
      "Train Epoch: 3 [640/1599 (40%)]\tLoss: 0.112919\n",
      "Train Epoch: 3 [1280/1599 (80%)]\tLoss: 0.068741\n",
      "Train Epoch: 4 [0/1599 (0%)]\tLoss: 0.044576\n",
      "Train Epoch: 4 [640/1599 (40%)]\tLoss: 0.075951\n",
      "Train Epoch: 4 [1280/1599 (80%)]\tLoss: 0.030249\n",
      "Train Epoch: 5 [0/1599 (0%)]\tLoss: 0.005944\n",
      "Train Epoch: 5 [640/1599 (40%)]\tLoss: 0.050872\n",
      "Train Epoch: 5 [1280/1599 (80%)]\tLoss: 0.050452\n",
      "Train Epoch: 6 [0/1599 (0%)]\tLoss: 0.012366\n",
      "Train Epoch: 6 [640/1599 (40%)]\tLoss: 0.041045\n",
      "Train Epoch: 6 [1280/1599 (80%)]\tLoss: 0.036542\n",
      "Train Epoch: 7 [0/1599 (0%)]\tLoss: 0.028377\n",
      "Train Epoch: 7 [640/1599 (40%)]\tLoss: 0.024945\n",
      "Train Epoch: 7 [1280/1599 (80%)]\tLoss: 0.008829\n",
      "Train Epoch: 8 [0/1599 (0%)]\tLoss: 0.061504\n",
      "Train Epoch: 8 [640/1599 (40%)]\tLoss: 0.078044\n",
      "Train Epoch: 8 [1280/1599 (80%)]\tLoss: 0.048670\n",
      "Train Epoch: 9 [0/1599 (0%)]\tLoss: 0.086305\n",
      "Train Epoch: 9 [640/1599 (40%)]\tLoss: 0.058620\n",
      "Train Epoch: 9 [1280/1599 (80%)]\tLoss: 0.020242\n",
      "Train Epoch: 10 [0/1599 (0%)]\tLoss: 0.008499\n",
      "Train Epoch: 10 [640/1599 (40%)]\tLoss: 0.019883\n",
      "Train Epoch: 10 [1280/1599 (80%)]\tLoss: 0.017986\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/5266 (0%)]\tLoss: 0.148893\n",
      "Train Epoch: 1 [640/5266 (12%)]\tLoss: 0.056022\n",
      "Train Epoch: 1 [1280/5266 (24%)]\tLoss: 0.075525\n",
      "Train Epoch: 1 [1920/5266 (36%)]\tLoss: 0.002930\n",
      "Train Epoch: 1 [2560/5266 (48%)]\tLoss: 0.001454\n",
      "Train Epoch: 1 [3200/5266 (60%)]\tLoss: 0.035454\n",
      "Train Epoch: 1 [3840/5266 (72%)]\tLoss: 0.069834\n",
      "Train Epoch: 1 [4480/5266 (84%)]\tLoss: 0.031278\n",
      "Train Epoch: 1 [5120/5266 (96%)]\tLoss: 0.018978\n",
      "Train Epoch: 2 [0/5266 (0%)]\tLoss: 0.006182\n",
      "Train Epoch: 2 [640/5266 (12%)]\tLoss: 0.042689\n",
      "Train Epoch: 2 [1280/5266 (24%)]\tLoss: 0.030463\n",
      "Train Epoch: 2 [1920/5266 (36%)]\tLoss: 0.035930\n",
      "Train Epoch: 2 [2560/5266 (48%)]\tLoss: 0.038824\n",
      "Train Epoch: 2 [3200/5266 (60%)]\tLoss: 0.025119\n",
      "Train Epoch: 2 [3840/5266 (72%)]\tLoss: 0.001583\n",
      "Train Epoch: 2 [4480/5266 (84%)]\tLoss: 0.005137\n",
      "Train Epoch: 2 [5120/5266 (96%)]\tLoss: 0.006480\n",
      "Train Epoch: 3 [0/5266 (0%)]\tLoss: 0.006267\n",
      "Train Epoch: 3 [640/5266 (12%)]\tLoss: 0.020211\n",
      "Train Epoch: 3 [1280/5266 (24%)]\tLoss: 0.029292\n",
      "Train Epoch: 3 [1920/5266 (36%)]\tLoss: 0.003195\n",
      "Train Epoch: 3 [2560/5266 (48%)]\tLoss: 0.045755\n",
      "Train Epoch: 3 [3200/5266 (60%)]\tLoss: 0.031262\n",
      "Train Epoch: 3 [3840/5266 (72%)]\tLoss: 0.037063\n",
      "Train Epoch: 3 [4480/5266 (84%)]\tLoss: 0.077621\n",
      "Train Epoch: 3 [5120/5266 (96%)]\tLoss: 0.027874\n",
      "Train Epoch: 4 [0/5266 (0%)]\tLoss: 0.033378\n",
      "Train Epoch: 4 [640/5266 (12%)]\tLoss: 0.001983\n",
      "Train Epoch: 4 [1280/5266 (24%)]\tLoss: 0.020986\n",
      "Train Epoch: 4 [1920/5266 (36%)]\tLoss: 0.006255\n",
      "Train Epoch: 4 [2560/5266 (48%)]\tLoss: 0.021543\n",
      "Train Epoch: 4 [3200/5266 (60%)]\tLoss: 0.140079\n",
      "Train Epoch: 4 [3840/5266 (72%)]\tLoss: 0.003460\n",
      "Train Epoch: 4 [4480/5266 (84%)]\tLoss: 0.003619\n",
      "Train Epoch: 4 [5120/5266 (96%)]\tLoss: 0.020553\n",
      "Train Epoch: 5 [0/5266 (0%)]\tLoss: 0.002428\n",
      "Train Epoch: 5 [640/5266 (12%)]\tLoss: 0.001525\n",
      "Train Epoch: 5 [1280/5266 (24%)]\tLoss: 0.003586\n",
      "Train Epoch: 5 [1920/5266 (36%)]\tLoss: 0.016604\n",
      "Train Epoch: 5 [2560/5266 (48%)]\tLoss: 0.007122\n",
      "Train Epoch: 5 [3200/5266 (60%)]\tLoss: 0.068604\n",
      "Train Epoch: 5 [3840/5266 (72%)]\tLoss: 0.071559\n",
      "Train Epoch: 5 [4480/5266 (84%)]\tLoss: 0.141984\n",
      "Train Epoch: 5 [5120/5266 (96%)]\tLoss: 0.017019\n",
      "Train Epoch: 6 [0/5266 (0%)]\tLoss: 0.023790\n",
      "Train Epoch: 6 [640/5266 (12%)]\tLoss: 0.003746\n",
      "Train Epoch: 6 [1280/5266 (24%)]\tLoss: 0.005839\n",
      "Train Epoch: 6 [1920/5266 (36%)]\tLoss: 0.026423\n",
      "Train Epoch: 6 [2560/5266 (48%)]\tLoss: 0.047952\n",
      "Train Epoch: 6 [3200/5266 (60%)]\tLoss: 0.014766\n",
      "Train Epoch: 6 [3840/5266 (72%)]\tLoss: 0.006445\n",
      "Train Epoch: 6 [4480/5266 (84%)]\tLoss: 0.005656\n",
      "Train Epoch: 6 [5120/5266 (96%)]\tLoss: 0.002221\n",
      "Train Epoch: 7 [0/5266 (0%)]\tLoss: 0.003975\n",
      "Train Epoch: 7 [640/5266 (12%)]\tLoss: 0.026365\n",
      "Train Epoch: 7 [1280/5266 (24%)]\tLoss: 0.010515\n",
      "Train Epoch: 7 [1920/5266 (36%)]\tLoss: 0.001817\n",
      "Train Epoch: 7 [2560/5266 (48%)]\tLoss: 0.001541\n",
      "Train Epoch: 7 [3200/5266 (60%)]\tLoss: 0.011319\n",
      "Train Epoch: 7 [3840/5266 (72%)]\tLoss: 0.087231\n",
      "Train Epoch: 7 [4480/5266 (84%)]\tLoss: 0.118556\n",
      "Train Epoch: 7 [5120/5266 (96%)]\tLoss: 0.004881\n",
      "Train Epoch: 8 [0/5266 (0%)]\tLoss: 0.000285\n",
      "Train Epoch: 8 [640/5266 (12%)]\tLoss: 0.123245\n",
      "Train Epoch: 8 [1280/5266 (24%)]\tLoss: 0.023401\n",
      "Train Epoch: 8 [1920/5266 (36%)]\tLoss: 0.004365\n",
      "Train Epoch: 8 [2560/5266 (48%)]\tLoss: 0.002995\n",
      "Train Epoch: 8 [3200/5266 (60%)]\tLoss: 0.008957\n",
      "Train Epoch: 8 [3840/5266 (72%)]\tLoss: 0.004658\n",
      "Train Epoch: 8 [4480/5266 (84%)]\tLoss: 0.025103\n",
      "Train Epoch: 8 [5120/5266 (96%)]\tLoss: 0.022060\n",
      "Train Epoch: 9 [0/5266 (0%)]\tLoss: 0.011223\n",
      "Train Epoch: 9 [640/5266 (12%)]\tLoss: 0.099069\n",
      "Train Epoch: 9 [1280/5266 (24%)]\tLoss: 0.001427\n",
      "Train Epoch: 9 [1920/5266 (36%)]\tLoss: 0.003876\n",
      "Train Epoch: 9 [2560/5266 (48%)]\tLoss: 0.025654\n",
      "Train Epoch: 9 [3200/5266 (60%)]\tLoss: 0.018573\n",
      "Train Epoch: 9 [3840/5266 (72%)]\tLoss: 0.012649\n",
      "Train Epoch: 9 [4480/5266 (84%)]\tLoss: 0.060936\n",
      "Train Epoch: 9 [5120/5266 (96%)]\tLoss: 0.040723\n",
      "Train Epoch: 10 [0/5266 (0%)]\tLoss: 0.003499\n",
      "Train Epoch: 10 [640/5266 (12%)]\tLoss: 0.000370\n",
      "Train Epoch: 10 [1280/5266 (24%)]\tLoss: 0.001657\n",
      "Train Epoch: 10 [1920/5266 (36%)]\tLoss: 0.023353\n",
      "Train Epoch: 10 [2560/5266 (48%)]\tLoss: 0.002000\n",
      "Train Epoch: 10 [3200/5266 (60%)]\tLoss: 0.002006\n",
      "Train Epoch: 10 [3840/5266 (72%)]\tLoss: 0.012097\n",
      "Train Epoch: 10 [4480/5266 (84%)]\tLoss: 0.045175\n",
      "Train Epoch: 10 [5120/5266 (96%)]\tLoss: 0.094028\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/3530 (0%)]\tLoss: 0.046619\n",
      "Train Epoch: 1 [640/3530 (18%)]\tLoss: 0.046358\n",
      "Train Epoch: 1 [1280/3530 (36%)]\tLoss: 0.067918\n",
      "Train Epoch: 1 [1920/3530 (54%)]\tLoss: 0.037852\n",
      "Train Epoch: 1 [2560/3530 (71%)]\tLoss: 0.116557\n",
      "Train Epoch: 1 [3200/3530 (89%)]\tLoss: 0.041186\n",
      "Train Epoch: 2 [0/3530 (0%)]\tLoss: 0.054637\n",
      "Train Epoch: 2 [640/3530 (18%)]\tLoss: 0.058176\n",
      "Train Epoch: 2 [1280/3530 (36%)]\tLoss: 0.062981\n",
      "Train Epoch: 2 [1920/3530 (54%)]\tLoss: 0.022304\n",
      "Train Epoch: 2 [2560/3530 (71%)]\tLoss: 0.308705\n",
      "Train Epoch: 2 [3200/3530 (89%)]\tLoss: 0.039592\n",
      "Train Epoch: 3 [0/3530 (0%)]\tLoss: 0.252543\n",
      "Train Epoch: 3 [640/3530 (18%)]\tLoss: 0.054416\n",
      "Train Epoch: 3 [1280/3530 (36%)]\tLoss: 0.135582\n",
      "Train Epoch: 3 [1920/3530 (54%)]\tLoss: 0.017533\n",
      "Train Epoch: 3 [2560/3530 (71%)]\tLoss: 0.058003\n",
      "Train Epoch: 3 [3200/3530 (89%)]\tLoss: 0.161495\n",
      "Train Epoch: 4 [0/3530 (0%)]\tLoss: 0.031747\n",
      "Train Epoch: 4 [640/3530 (18%)]\tLoss: 0.045798\n",
      "Train Epoch: 4 [1280/3530 (36%)]\tLoss: 0.053604\n",
      "Train Epoch: 4 [1920/3530 (54%)]\tLoss: 0.231377\n",
      "Train Epoch: 4 [2560/3530 (71%)]\tLoss: 0.017722\n",
      "Train Epoch: 4 [3200/3530 (89%)]\tLoss: 0.071381\n",
      "Train Epoch: 5 [0/3530 (0%)]\tLoss: 0.153622\n",
      "Train Epoch: 5 [640/3530 (18%)]\tLoss: 0.074273\n",
      "Train Epoch: 5 [1280/3530 (36%)]\tLoss: 0.036375\n",
      "Train Epoch: 5 [1920/3530 (54%)]\tLoss: 0.036907\n",
      "Train Epoch: 5 [2560/3530 (71%)]\tLoss: 0.057876\n",
      "Train Epoch: 5 [3200/3530 (89%)]\tLoss: 0.116051\n",
      "Train Epoch: 6 [0/3530 (0%)]\tLoss: 0.151605\n",
      "Train Epoch: 6 [640/3530 (18%)]\tLoss: 0.045143\n",
      "Train Epoch: 6 [1280/3530 (36%)]\tLoss: 0.063239\n",
      "Train Epoch: 6 [1920/3530 (54%)]\tLoss: 0.020580\n",
      "Train Epoch: 6 [2560/3530 (71%)]\tLoss: 0.031769\n",
      "Train Epoch: 6 [3200/3530 (89%)]\tLoss: 0.051498\n",
      "Train Epoch: 7 [0/3530 (0%)]\tLoss: 0.055018\n",
      "Train Epoch: 7 [640/3530 (18%)]\tLoss: 0.007360\n",
      "Train Epoch: 7 [1280/3530 (36%)]\tLoss: 0.033471\n",
      "Train Epoch: 7 [1920/3530 (54%)]\tLoss: 0.091676\n",
      "Train Epoch: 7 [2560/3530 (71%)]\tLoss: 0.011567\n",
      "Train Epoch: 7 [3200/3530 (89%)]\tLoss: 0.069355\n",
      "Train Epoch: 8 [0/3530 (0%)]\tLoss: 0.038328\n",
      "Train Epoch: 8 [640/3530 (18%)]\tLoss: 0.173446\n",
      "Train Epoch: 8 [1280/3530 (36%)]\tLoss: 0.034106\n",
      "Train Epoch: 8 [1920/3530 (54%)]\tLoss: 0.063937\n",
      "Train Epoch: 8 [2560/3530 (71%)]\tLoss: 0.041937\n",
      "Train Epoch: 8 [3200/3530 (89%)]\tLoss: 0.041611\n",
      "Train Epoch: 9 [0/3530 (0%)]\tLoss: 0.078963\n",
      "Train Epoch: 9 [640/3530 (18%)]\tLoss: 0.083376\n",
      "Train Epoch: 9 [1280/3530 (36%)]\tLoss: 0.132092\n",
      "Train Epoch: 9 [1920/3530 (54%)]\tLoss: 0.013143\n",
      "Train Epoch: 9 [2560/3530 (71%)]\tLoss: 0.033501\n",
      "Train Epoch: 9 [3200/3530 (89%)]\tLoss: 0.119937\n",
      "Train Epoch: 10 [0/3530 (0%)]\tLoss: 0.011804\n",
      "Train Epoch: 10 [640/3530 (18%)]\tLoss: 0.040317\n",
      "Train Epoch: 10 [1280/3530 (36%)]\tLoss: 0.119447\n",
      "Train Epoch: 10 [1920/3530 (54%)]\tLoss: 0.041058\n",
      "Train Epoch: 10 [2560/3530 (71%)]\tLoss: 0.079678\n",
      "Train Epoch: 10 [3200/3530 (89%)]\tLoss: 0.051275\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0433, Accuracy: 9859/10000 (99%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 0.124696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 0.062808\n",
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 0.049627\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 0.053046\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 0.078811\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 0.010192\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 0.126616\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 0.367386\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 0.042292\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 0.027660\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 0.042008\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 0.095121\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 0.046720\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 0.148042\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 0.066147\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 0.070602\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 0.106007\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 0.101018\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 0.122701\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 0.068403\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.029704\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 0.117221\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 0.257552\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.110197\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.084904\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 0.061725\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.073609\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 0.094494\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.054426\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.037621\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.053845\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.148118\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.113148\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.011785\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.145131\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.156629\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.006570\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.094286\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.041155\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.030556\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.106166\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.091225\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.220241\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.168455\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.088645\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.050388\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.049281\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.182042\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.023841\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.023008\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.019244\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.035747\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.079846\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.148917\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.074690\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.052274\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.035429\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.051494\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.096784\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.172426\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.126213\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.020252\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.014258\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.119010\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.040815\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.015523\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.025471\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.064096\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.047230\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.204240\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.010262\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.075944\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.033764\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.041108\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.072222\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.015572\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.086555\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.099562\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.035325\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.015013\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.104426\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.056277\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.062097\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.068250\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.035959\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.092711\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.035143\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.026810\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.009266\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.029666\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.028307\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.119792\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.112540\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.065021\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.024326\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.032551\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.013015\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.023692\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.201569\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.022297\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.072750\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.011229\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.127005\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.112815\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.029023\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.048256\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.031269\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.037261\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 0.004886\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.036772\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.035870\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.047610\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.166623\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.075966\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.036144\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.108391\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.053529\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.055854\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.013276\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.041785\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.217620\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.049179\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.039414\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.052878\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.010233\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.068271\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.072247\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.057021\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.082842\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.053189\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.015127\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.020424\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.057515\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.037150\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.067012\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.105439\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.050268\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.008896\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.074547\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.102320\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.035571\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.013891\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.181615\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.052069\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.118542\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.049241\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.025838\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.073294\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.037070\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.184491\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.192582\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.083285\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.026188\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.060721\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.070994\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.170156\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.212498\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.198530\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.039050\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.139106\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.050282\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.013856\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.083991\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.027856\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.049612\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.013922\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.019097\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.045965\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.018935\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.012273\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.048144\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.002835\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.051828\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.005083\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.085831\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.081437\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.319397\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.033500\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.070939\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.014657\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/5110 (0%)]\tLoss: 0.037231\n",
      "Train Epoch: 1 [640/5110 (12%)]\tLoss: 0.062152\n",
      "Train Epoch: 1 [1280/5110 (25%)]\tLoss: 0.064989\n",
      "Train Epoch: 1 [1920/5110 (38%)]\tLoss: 0.025644\n",
      "Train Epoch: 1 [2560/5110 (50%)]\tLoss: 0.181965\n",
      "Train Epoch: 1 [3200/5110 (62%)]\tLoss: 0.136007\n",
      "Train Epoch: 1 [3840/5110 (75%)]\tLoss: 0.019553\n",
      "Train Epoch: 1 [4480/5110 (88%)]\tLoss: 0.119775\n",
      "Train Epoch: 2 [0/5110 (0%)]\tLoss: 0.079834\n",
      "Train Epoch: 2 [640/5110 (12%)]\tLoss: 0.017965\n",
      "Train Epoch: 2 [1280/5110 (25%)]\tLoss: 0.093113\n",
      "Train Epoch: 2 [1920/5110 (38%)]\tLoss: 0.075126\n",
      "Train Epoch: 2 [2560/5110 (50%)]\tLoss: 0.040951\n",
      "Train Epoch: 2 [3200/5110 (62%)]\tLoss: 0.036044\n",
      "Train Epoch: 2 [3840/5110 (75%)]\tLoss: 0.022275\n",
      "Train Epoch: 2 [4480/5110 (88%)]\tLoss: 0.040247\n",
      "Train Epoch: 3 [0/5110 (0%)]\tLoss: 0.067224\n",
      "Train Epoch: 3 [640/5110 (12%)]\tLoss: 0.042766\n",
      "Train Epoch: 3 [1280/5110 (25%)]\tLoss: 0.055250\n",
      "Train Epoch: 3 [1920/5110 (38%)]\tLoss: 0.019533\n",
      "Train Epoch: 3 [2560/5110 (50%)]\tLoss: 0.064247\n",
      "Train Epoch: 3 [3200/5110 (62%)]\tLoss: 0.083974\n",
      "Train Epoch: 3 [3840/5110 (75%)]\tLoss: 0.185890\n",
      "Train Epoch: 3 [4480/5110 (88%)]\tLoss: 0.048565\n",
      "Train Epoch: 4 [0/5110 (0%)]\tLoss: 0.048400\n",
      "Train Epoch: 4 [640/5110 (12%)]\tLoss: 0.085454\n",
      "Train Epoch: 4 [1280/5110 (25%)]\tLoss: 0.026657\n",
      "Train Epoch: 4 [1920/5110 (38%)]\tLoss: 0.018532\n",
      "Train Epoch: 4 [2560/5110 (50%)]\tLoss: 0.229948\n",
      "Train Epoch: 4 [3200/5110 (62%)]\tLoss: 0.019204\n",
      "Train Epoch: 4 [3840/5110 (75%)]\tLoss: 0.014179\n",
      "Train Epoch: 4 [4480/5110 (88%)]\tLoss: 0.057096\n",
      "Train Epoch: 5 [0/5110 (0%)]\tLoss: 0.030155\n",
      "Train Epoch: 5 [640/5110 (12%)]\tLoss: 0.057738\n",
      "Train Epoch: 5 [1280/5110 (25%)]\tLoss: 0.072630\n",
      "Train Epoch: 5 [1920/5110 (38%)]\tLoss: 0.070620\n",
      "Train Epoch: 5 [2560/5110 (50%)]\tLoss: 0.053006\n",
      "Train Epoch: 5 [3200/5110 (62%)]\tLoss: 0.021769\n",
      "Train Epoch: 5 [3840/5110 (75%)]\tLoss: 0.052726\n",
      "Train Epoch: 5 [4480/5110 (88%)]\tLoss: 0.014905\n",
      "Train Epoch: 6 [0/5110 (0%)]\tLoss: 0.067272\n",
      "Train Epoch: 6 [640/5110 (12%)]\tLoss: 0.020867\n",
      "Train Epoch: 6 [1280/5110 (25%)]\tLoss: 0.102472\n",
      "Train Epoch: 6 [1920/5110 (38%)]\tLoss: 0.067831\n",
      "Train Epoch: 6 [2560/5110 (50%)]\tLoss: 0.066469\n",
      "Train Epoch: 6 [3200/5110 (62%)]\tLoss: 0.048749\n",
      "Train Epoch: 6 [3840/5110 (75%)]\tLoss: 0.113525\n",
      "Train Epoch: 6 [4480/5110 (88%)]\tLoss: 0.035758\n",
      "Train Epoch: 7 [0/5110 (0%)]\tLoss: 0.011527\n",
      "Train Epoch: 7 [640/5110 (12%)]\tLoss: 0.064225\n",
      "Train Epoch: 7 [1280/5110 (25%)]\tLoss: 0.096951\n",
      "Train Epoch: 7 [1920/5110 (38%)]\tLoss: 0.011016\n",
      "Train Epoch: 7 [2560/5110 (50%)]\tLoss: 0.035092\n",
      "Train Epoch: 7 [3200/5110 (62%)]\tLoss: 0.047220\n",
      "Train Epoch: 7 [3840/5110 (75%)]\tLoss: 0.022645\n",
      "Train Epoch: 7 [4480/5110 (88%)]\tLoss: 0.005674\n",
      "Train Epoch: 8 [0/5110 (0%)]\tLoss: 0.032311\n",
      "Train Epoch: 8 [640/5110 (12%)]\tLoss: 0.059750\n",
      "Train Epoch: 8 [1280/5110 (25%)]\tLoss: 0.058879\n",
      "Train Epoch: 8 [1920/5110 (38%)]\tLoss: 0.083467\n",
      "Train Epoch: 8 [2560/5110 (50%)]\tLoss: 0.031156\n",
      "Train Epoch: 8 [3200/5110 (62%)]\tLoss: 0.086509\n",
      "Train Epoch: 8 [3840/5110 (75%)]\tLoss: 0.041490\n",
      "Train Epoch: 8 [4480/5110 (88%)]\tLoss: 0.009129\n",
      "Train Epoch: 9 [0/5110 (0%)]\tLoss: 0.041894\n",
      "Train Epoch: 9 [640/5110 (12%)]\tLoss: 0.004493\n",
      "Train Epoch: 9 [1280/5110 (25%)]\tLoss: 0.063034\n",
      "Train Epoch: 9 [1920/5110 (38%)]\tLoss: 0.018538\n",
      "Train Epoch: 9 [2560/5110 (50%)]\tLoss: 0.028842\n",
      "Train Epoch: 9 [3200/5110 (62%)]\tLoss: 0.052359\n",
      "Train Epoch: 9 [3840/5110 (75%)]\tLoss: 0.061694\n",
      "Train Epoch: 9 [4480/5110 (88%)]\tLoss: 0.043737\n",
      "Train Epoch: 10 [0/5110 (0%)]\tLoss: 0.050193\n",
      "Train Epoch: 10 [640/5110 (12%)]\tLoss: 0.156701\n",
      "Train Epoch: 10 [1280/5110 (25%)]\tLoss: 0.063397\n",
      "Train Epoch: 10 [1920/5110 (38%)]\tLoss: 0.038522\n",
      "Train Epoch: 10 [2560/5110 (50%)]\tLoss: 0.036006\n",
      "Train Epoch: 10 [3200/5110 (62%)]\tLoss: 0.038860\n",
      "Train Epoch: 10 [3840/5110 (75%)]\tLoss: 0.042122\n",
      "Train Epoch: 10 [4480/5110 (88%)]\tLoss: 0.173311\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6766 (0%)]\tLoss: 0.046386\n",
      "Train Epoch: 1 [640/6766 (9%)]\tLoss: 0.023326\n",
      "Train Epoch: 1 [1280/6766 (19%)]\tLoss: 0.095070\n",
      "Train Epoch: 1 [1920/6766 (28%)]\tLoss: 0.050519\n",
      "Train Epoch: 1 [2560/6766 (38%)]\tLoss: 0.023252\n",
      "Train Epoch: 1 [3200/6766 (47%)]\tLoss: 0.071115\n",
      "Train Epoch: 1 [3840/6766 (57%)]\tLoss: 0.035471\n",
      "Train Epoch: 1 [4480/6766 (66%)]\tLoss: 0.031411\n",
      "Train Epoch: 1 [5120/6766 (75%)]\tLoss: 0.035819\n",
      "Train Epoch: 1 [5760/6766 (85%)]\tLoss: 0.103438\n",
      "Train Epoch: 1 [6400/6766 (94%)]\tLoss: 0.044810\n",
      "Train Epoch: 2 [0/6766 (0%)]\tLoss: 0.178226\n",
      "Train Epoch: 2 [640/6766 (9%)]\tLoss: 0.077203\n",
      "Train Epoch: 2 [1280/6766 (19%)]\tLoss: 0.104106\n",
      "Train Epoch: 2 [1920/6766 (28%)]\tLoss: 0.047719\n",
      "Train Epoch: 2 [2560/6766 (38%)]\tLoss: 0.015210\n",
      "Train Epoch: 2 [3200/6766 (47%)]\tLoss: 0.073467\n",
      "Train Epoch: 2 [3840/6766 (57%)]\tLoss: 0.025263\n",
      "Train Epoch: 2 [4480/6766 (66%)]\tLoss: 0.009632\n",
      "Train Epoch: 2 [5120/6766 (75%)]\tLoss: 0.034710\n",
      "Train Epoch: 2 [5760/6766 (85%)]\tLoss: 0.031093\n",
      "Train Epoch: 2 [6400/6766 (94%)]\tLoss: 0.067095\n",
      "Train Epoch: 3 [0/6766 (0%)]\tLoss: 0.041075\n",
      "Train Epoch: 3 [640/6766 (9%)]\tLoss: 0.051049\n",
      "Train Epoch: 3 [1280/6766 (19%)]\tLoss: 0.057958\n",
      "Train Epoch: 3 [1920/6766 (28%)]\tLoss: 0.101966\n",
      "Train Epoch: 3 [2560/6766 (38%)]\tLoss: 0.106185\n",
      "Train Epoch: 3 [3200/6766 (47%)]\tLoss: 0.134519\n",
      "Train Epoch: 3 [3840/6766 (57%)]\tLoss: 0.118813\n",
      "Train Epoch: 3 [4480/6766 (66%)]\tLoss: 0.047539\n",
      "Train Epoch: 3 [5120/6766 (75%)]\tLoss: 0.023894\n",
      "Train Epoch: 3 [5760/6766 (85%)]\tLoss: 0.012780\n",
      "Train Epoch: 3 [6400/6766 (94%)]\tLoss: 0.011741\n",
      "Train Epoch: 4 [0/6766 (0%)]\tLoss: 0.009339\n",
      "Train Epoch: 4 [640/6766 (9%)]\tLoss: 0.083006\n",
      "Train Epoch: 4 [1280/6766 (19%)]\tLoss: 0.025378\n",
      "Train Epoch: 4 [1920/6766 (28%)]\tLoss: 0.015646\n",
      "Train Epoch: 4 [2560/6766 (38%)]\tLoss: 0.019516\n",
      "Train Epoch: 4 [3200/6766 (47%)]\tLoss: 0.058700\n",
      "Train Epoch: 4 [3840/6766 (57%)]\tLoss: 0.062791\n",
      "Train Epoch: 4 [4480/6766 (66%)]\tLoss: 0.200854\n",
      "Train Epoch: 4 [5120/6766 (75%)]\tLoss: 0.023829\n",
      "Train Epoch: 4 [5760/6766 (85%)]\tLoss: 0.037656\n",
      "Train Epoch: 4 [6400/6766 (94%)]\tLoss: 0.071248\n",
      "Train Epoch: 5 [0/6766 (0%)]\tLoss: 0.044462\n",
      "Train Epoch: 5 [640/6766 (9%)]\tLoss: 0.019451\n",
      "Train Epoch: 5 [1280/6766 (19%)]\tLoss: 0.013880\n",
      "Train Epoch: 5 [1920/6766 (28%)]\tLoss: 0.040661\n",
      "Train Epoch: 5 [2560/6766 (38%)]\tLoss: 0.024614\n",
      "Train Epoch: 5 [3200/6766 (47%)]\tLoss: 0.026235\n",
      "Train Epoch: 5 [3840/6766 (57%)]\tLoss: 0.091013\n",
      "Train Epoch: 5 [4480/6766 (66%)]\tLoss: 0.086154\n",
      "Train Epoch: 5 [5120/6766 (75%)]\tLoss: 0.079030\n",
      "Train Epoch: 5 [5760/6766 (85%)]\tLoss: 0.024729\n",
      "Train Epoch: 5 [6400/6766 (94%)]\tLoss: 0.012317\n",
      "Train Epoch: 6 [0/6766 (0%)]\tLoss: 0.096596\n",
      "Train Epoch: 6 [640/6766 (9%)]\tLoss: 0.011895\n",
      "Train Epoch: 6 [1280/6766 (19%)]\tLoss: 0.029909\n",
      "Train Epoch: 6 [1920/6766 (28%)]\tLoss: 0.056594\n",
      "Train Epoch: 6 [2560/6766 (38%)]\tLoss: 0.082438\n",
      "Train Epoch: 6 [3200/6766 (47%)]\tLoss: 0.036939\n",
      "Train Epoch: 6 [3840/6766 (57%)]\tLoss: 0.041227\n",
      "Train Epoch: 6 [4480/6766 (66%)]\tLoss: 0.068410\n",
      "Train Epoch: 6 [5120/6766 (75%)]\tLoss: 0.008947\n",
      "Train Epoch: 6 [5760/6766 (85%)]\tLoss: 0.021875\n",
      "Train Epoch: 6 [6400/6766 (94%)]\tLoss: 0.035085\n",
      "Train Epoch: 7 [0/6766 (0%)]\tLoss: 0.031183\n",
      "Train Epoch: 7 [640/6766 (9%)]\tLoss: 0.023947\n",
      "Train Epoch: 7 [1280/6766 (19%)]\tLoss: 0.011425\n",
      "Train Epoch: 7 [1920/6766 (28%)]\tLoss: 0.233350\n",
      "Train Epoch: 7 [2560/6766 (38%)]\tLoss: 0.004718\n",
      "Train Epoch: 7 [3200/6766 (47%)]\tLoss: 0.190600\n",
      "Train Epoch: 7 [3840/6766 (57%)]\tLoss: 0.085129\n",
      "Train Epoch: 7 [4480/6766 (66%)]\tLoss: 0.048664\n",
      "Train Epoch: 7 [5120/6766 (75%)]\tLoss: 0.044295\n",
      "Train Epoch: 7 [5760/6766 (85%)]\tLoss: 0.004803\n",
      "Train Epoch: 7 [6400/6766 (94%)]\tLoss: 0.213651\n",
      "Train Epoch: 8 [0/6766 (0%)]\tLoss: 0.024042\n",
      "Train Epoch: 8 [640/6766 (9%)]\tLoss: 0.022246\n",
      "Train Epoch: 8 [1280/6766 (19%)]\tLoss: 0.048812\n",
      "Train Epoch: 8 [1920/6766 (28%)]\tLoss: 0.059823\n",
      "Train Epoch: 8 [2560/6766 (38%)]\tLoss: 0.066710\n",
      "Train Epoch: 8 [3200/6766 (47%)]\tLoss: 0.017709\n",
      "Train Epoch: 8 [3840/6766 (57%)]\tLoss: 0.031897\n",
      "Train Epoch: 8 [4480/6766 (66%)]\tLoss: 0.018059\n",
      "Train Epoch: 8 [5120/6766 (75%)]\tLoss: 0.017277\n",
      "Train Epoch: 8 [5760/6766 (85%)]\tLoss: 0.011438\n",
      "Train Epoch: 8 [6400/6766 (94%)]\tLoss: 0.035015\n",
      "Train Epoch: 9 [0/6766 (0%)]\tLoss: 0.045142\n",
      "Train Epoch: 9 [640/6766 (9%)]\tLoss: 0.037311\n",
      "Train Epoch: 9 [1280/6766 (19%)]\tLoss: 0.006522\n",
      "Train Epoch: 9 [1920/6766 (28%)]\tLoss: 0.017463\n",
      "Train Epoch: 9 [2560/6766 (38%)]\tLoss: 0.009997\n",
      "Train Epoch: 9 [3200/6766 (47%)]\tLoss: 0.022467\n",
      "Train Epoch: 9 [3840/6766 (57%)]\tLoss: 0.019892\n",
      "Train Epoch: 9 [4480/6766 (66%)]\tLoss: 0.045282\n",
      "Train Epoch: 9 [5120/6766 (75%)]\tLoss: 0.041664\n",
      "Train Epoch: 9 [5760/6766 (85%)]\tLoss: 0.016627\n",
      "Train Epoch: 9 [6400/6766 (94%)]\tLoss: 0.020495\n",
      "Train Epoch: 10 [0/6766 (0%)]\tLoss: 0.091149\n",
      "Train Epoch: 10 [640/6766 (9%)]\tLoss: 0.004194\n",
      "Train Epoch: 10 [1280/6766 (19%)]\tLoss: 0.037976\n",
      "Train Epoch: 10 [1920/6766 (28%)]\tLoss: 0.036951\n",
      "Train Epoch: 10 [2560/6766 (38%)]\tLoss: 0.008677\n",
      "Train Epoch: 10 [3200/6766 (47%)]\tLoss: 0.089860\n",
      "Train Epoch: 10 [3840/6766 (57%)]\tLoss: 0.031721\n",
      "Train Epoch: 10 [4480/6766 (66%)]\tLoss: 0.018599\n",
      "Train Epoch: 10 [5120/6766 (75%)]\tLoss: 0.047586\n",
      "Train Epoch: 10 [5760/6766 (85%)]\tLoss: 0.157784\n",
      "Train Epoch: 10 [6400/6766 (94%)]\tLoss: 0.011341\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 0.092960\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 0.134319\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 0.040041\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 0.199761\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 0.065227\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 0.037760\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 0.082224\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 0.015626\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 0.115184\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 0.077923\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 0.054866\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 0.040237\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 0.051507\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 0.058806\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 0.008664\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 0.032753\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 0.028493\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.226700\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.229422\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.015149\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.019091\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.167100\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.052468\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.021998\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.065351\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.007943\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.085060\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.079772\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.225191\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.027967\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.058846\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.024756\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.059801\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.039607\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.080449\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.119321\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.042518\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.061019\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.035841\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.030382\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.062912\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.054115\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.018623\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.046102\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.020651\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.090087\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.019244\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.038995\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.016651\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.008525\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.101930\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.020761\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.044261\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.011699\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.179553\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.018535\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.076861\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.040263\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.018548\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.076430\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.058246\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.030046\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.020603\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.037960\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.013759\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.029012\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.008604\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.011891\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.052276\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.200621\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.007832\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.038577\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.152994\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.021036\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.109958\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.006043\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.150578\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.043360\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.009098\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.079370\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.049631\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.030406\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.098160\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.031273\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.027963\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.151981\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.105438\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.022770\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.009515\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.116472\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.009566\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.029395\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.002141\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.008389\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.068278\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.135392\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.006105\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.037434\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.040913\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.017217\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.010033\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.121740\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.031432\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.026977\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.108808\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.056219\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.055157\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.035739\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.005059\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.032567\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.060523\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.010366\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.210688\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.028412\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.025303\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.053362\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.114264\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.125768\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.037142\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.081445\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.058296\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.029773\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.004919\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.041892\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.016192\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.093620\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.022335\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.065939\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.028499\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.067336\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.074551\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.072606\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.059524\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.034874\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.062821\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.028391\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.006884\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.389310\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.060250\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.023925\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.040601\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.135104\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.016292\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.068265\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.015978\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.094929\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.040599\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.077857\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.023303\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.077041\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.113710\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.060174\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.012486\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.021775\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.028515\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.044637\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.063569\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.038928\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.079135\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.068001\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/3910 (0%)]\tLoss: 0.144200\n",
      "Train Epoch: 1 [640/3910 (16%)]\tLoss: 0.032641\n",
      "Train Epoch: 1 [1280/3910 (32%)]\tLoss: 0.074167\n",
      "Train Epoch: 1 [1920/3910 (48%)]\tLoss: 0.059647\n",
      "Train Epoch: 1 [2560/3910 (65%)]\tLoss: 0.025046\n",
      "Train Epoch: 1 [3200/3910 (81%)]\tLoss: 0.163839\n",
      "Train Epoch: 1 [3840/3910 (97%)]\tLoss: 0.018267\n",
      "Train Epoch: 2 [0/3910 (0%)]\tLoss: 0.198819\n",
      "Train Epoch: 2 [640/3910 (16%)]\tLoss: 0.041218\n",
      "Train Epoch: 2 [1280/3910 (32%)]\tLoss: 0.008804\n",
      "Train Epoch: 2 [1920/3910 (48%)]\tLoss: 0.052372\n",
      "Train Epoch: 2 [2560/3910 (65%)]\tLoss: 0.130467\n",
      "Train Epoch: 2 [3200/3910 (81%)]\tLoss: 0.171078\n",
      "Train Epoch: 2 [3840/3910 (97%)]\tLoss: 0.060679\n",
      "Train Epoch: 3 [0/3910 (0%)]\tLoss: 0.037539\n",
      "Train Epoch: 3 [640/3910 (16%)]\tLoss: 0.121874\n",
      "Train Epoch: 3 [1280/3910 (32%)]\tLoss: 0.080642\n",
      "Train Epoch: 3 [1920/3910 (48%)]\tLoss: 0.063108\n",
      "Train Epoch: 3 [2560/3910 (65%)]\tLoss: 0.068493\n",
      "Train Epoch: 3 [3200/3910 (81%)]\tLoss: 0.085605\n",
      "Train Epoch: 3 [3840/3910 (97%)]\tLoss: 0.095921\n",
      "Train Epoch: 4 [0/3910 (0%)]\tLoss: 0.087396\n",
      "Train Epoch: 4 [640/3910 (16%)]\tLoss: 0.078408\n",
      "Train Epoch: 4 [1280/3910 (32%)]\tLoss: 0.152901\n",
      "Train Epoch: 4 [1920/3910 (48%)]\tLoss: 0.055239\n",
      "Train Epoch: 4 [2560/3910 (65%)]\tLoss: 0.056099\n",
      "Train Epoch: 4 [3200/3910 (81%)]\tLoss: 0.142579\n",
      "Train Epoch: 4 [3840/3910 (97%)]\tLoss: 0.045129\n",
      "Train Epoch: 5 [0/3910 (0%)]\tLoss: 0.047074\n",
      "Train Epoch: 5 [640/3910 (16%)]\tLoss: 0.053544\n",
      "Train Epoch: 5 [1280/3910 (32%)]\tLoss: 0.055504\n",
      "Train Epoch: 5 [1920/3910 (48%)]\tLoss: 0.116465\n",
      "Train Epoch: 5 [2560/3910 (65%)]\tLoss: 0.196656\n",
      "Train Epoch: 5 [3200/3910 (81%)]\tLoss: 0.054824\n",
      "Train Epoch: 5 [3840/3910 (97%)]\tLoss: 0.014029\n",
      "Train Epoch: 6 [0/3910 (0%)]\tLoss: 0.120717\n",
      "Train Epoch: 6 [640/3910 (16%)]\tLoss: 0.007724\n",
      "Train Epoch: 6 [1280/3910 (32%)]\tLoss: 0.079835\n",
      "Train Epoch: 6 [1920/3910 (48%)]\tLoss: 0.053286\n",
      "Train Epoch: 6 [2560/3910 (65%)]\tLoss: 0.074882\n",
      "Train Epoch: 6 [3200/3910 (81%)]\tLoss: 0.184554\n",
      "Train Epoch: 6 [3840/3910 (97%)]\tLoss: 0.035877\n",
      "Train Epoch: 7 [0/3910 (0%)]\tLoss: 0.008930\n",
      "Train Epoch: 7 [640/3910 (16%)]\tLoss: 0.039545\n",
      "Train Epoch: 7 [1280/3910 (32%)]\tLoss: 0.032164\n",
      "Train Epoch: 7 [1920/3910 (48%)]\tLoss: 0.035175\n",
      "Train Epoch: 7 [2560/3910 (65%)]\tLoss: 0.063343\n",
      "Train Epoch: 7 [3200/3910 (81%)]\tLoss: 0.099863\n",
      "Train Epoch: 7 [3840/3910 (97%)]\tLoss: 0.060051\n",
      "Train Epoch: 8 [0/3910 (0%)]\tLoss: 0.007282\n",
      "Train Epoch: 8 [640/3910 (16%)]\tLoss: 0.045998\n",
      "Train Epoch: 8 [1280/3910 (32%)]\tLoss: 0.192510\n",
      "Train Epoch: 8 [1920/3910 (48%)]\tLoss: 0.226608\n",
      "Train Epoch: 8 [2560/3910 (65%)]\tLoss: 0.057352\n",
      "Train Epoch: 8 [3200/3910 (81%)]\tLoss: 0.048534\n",
      "Train Epoch: 8 [3840/3910 (97%)]\tLoss: 0.050597\n",
      "Train Epoch: 9 [0/3910 (0%)]\tLoss: 0.109641\n",
      "Train Epoch: 9 [640/3910 (16%)]\tLoss: 0.051990\n",
      "Train Epoch: 9 [1280/3910 (32%)]\tLoss: 0.019311\n",
      "Train Epoch: 9 [1920/3910 (48%)]\tLoss: 0.025147\n",
      "Train Epoch: 9 [2560/3910 (65%)]\tLoss: 0.049113\n",
      "Train Epoch: 9 [3200/3910 (81%)]\tLoss: 0.025948\n",
      "Train Epoch: 9 [3840/3910 (97%)]\tLoss: 0.035419\n",
      "Train Epoch: 10 [0/3910 (0%)]\tLoss: 0.079112\n",
      "Train Epoch: 10 [640/3910 (16%)]\tLoss: 0.024922\n",
      "Train Epoch: 10 [1280/3910 (32%)]\tLoss: 0.072600\n",
      "Train Epoch: 10 [1920/3910 (48%)]\tLoss: 0.086319\n",
      "Train Epoch: 10 [2560/3910 (65%)]\tLoss: 0.098373\n",
      "Train Epoch: 10 [3200/3910 (81%)]\tLoss: 0.144199\n",
      "Train Epoch: 10 [3840/3910 (97%)]\tLoss: 0.031515\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 0.207292\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 0.111441\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 0.013995\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 0.042198\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 0.296198\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 0.079946\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 0.093976\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 0.028515\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 0.042383\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 0.049299\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.039118\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.048491\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 0.057424\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 0.094382\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 0.024353\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.034732\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.069974\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.036244\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.050047\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.021183\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.005199\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.014760\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.010206\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.045354\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.004581\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.054522\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.056562\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.003103\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.087382\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.032402\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.030135\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.005125\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.068712\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.009129\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.091624\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.098680\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.019409\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.005649\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.028250\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.070964\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.013213\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.055462\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.052723\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.013478\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.032520\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.060076\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.005861\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.022789\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.159913\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.201963\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.026048\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.003788\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.088357\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.061369\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.036232\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.037524\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.016406\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.017429\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.076190\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.005496\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.036910\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.031355\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.038952\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.004923\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.020505\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.036408\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.065038\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.032272\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.332686\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.114156\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.006607\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.008868\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.142623\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.024036\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.040460\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.076305\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.019992\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.163731\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.032134\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.054079\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.014933\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.019721\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.006546\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.053954\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.013121\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.017445\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.144774\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.062387\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.007009\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.024126\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.028761\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.020826\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.028455\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.002192\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.056654\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.056546\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.003484\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.006199\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.017166\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.070375\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.013538\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.004032\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.021549\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.026101\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.014562\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.010298\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.058118\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.045559\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.045681\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.010850\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.011612\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.084619\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.051734\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.011712\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.043376\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.045422\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.099154\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.012683\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.053403\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.004666\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/5096 (0%)]\tLoss: 0.100185\n",
      "Train Epoch: 1 [640/5096 (12%)]\tLoss: 0.046634\n",
      "Train Epoch: 1 [1280/5096 (25%)]\tLoss: 0.016268\n",
      "Train Epoch: 1 [1920/5096 (38%)]\tLoss: 0.004078\n",
      "Train Epoch: 1 [2560/5096 (50%)]\tLoss: 0.052026\n",
      "Train Epoch: 1 [3200/5096 (62%)]\tLoss: 0.056326\n",
      "Train Epoch: 1 [3840/5096 (75%)]\tLoss: 0.016394\n",
      "Train Epoch: 1 [4480/5096 (88%)]\tLoss: 0.075758\n",
      "Train Epoch: 2 [0/5096 (0%)]\tLoss: 0.040347\n",
      "Train Epoch: 2 [640/5096 (12%)]\tLoss: 0.013663\n",
      "Train Epoch: 2 [1280/5096 (25%)]\tLoss: 0.003821\n",
      "Train Epoch: 2 [1920/5096 (38%)]\tLoss: 0.014718\n",
      "Train Epoch: 2 [2560/5096 (50%)]\tLoss: 0.030608\n",
      "Train Epoch: 2 [3200/5096 (62%)]\tLoss: 0.010619\n",
      "Train Epoch: 2 [3840/5096 (75%)]\tLoss: 0.206660\n",
      "Train Epoch: 2 [4480/5096 (88%)]\tLoss: 0.008946\n",
      "Train Epoch: 3 [0/5096 (0%)]\tLoss: 0.041073\n",
      "Train Epoch: 3 [640/5096 (12%)]\tLoss: 0.007392\n",
      "Train Epoch: 3 [1280/5096 (25%)]\tLoss: 0.045350\n",
      "Train Epoch: 3 [1920/5096 (38%)]\tLoss: 0.005091\n",
      "Train Epoch: 3 [2560/5096 (50%)]\tLoss: 0.017530\n",
      "Train Epoch: 3 [3200/5096 (62%)]\tLoss: 0.067269\n",
      "Train Epoch: 3 [3840/5096 (75%)]\tLoss: 0.011188\n",
      "Train Epoch: 3 [4480/5096 (88%)]\tLoss: 0.092094\n",
      "Train Epoch: 4 [0/5096 (0%)]\tLoss: 0.008366\n",
      "Train Epoch: 4 [640/5096 (12%)]\tLoss: 0.018121\n",
      "Train Epoch: 4 [1280/5096 (25%)]\tLoss: 0.003388\n",
      "Train Epoch: 4 [1920/5096 (38%)]\tLoss: 0.235502\n",
      "Train Epoch: 4 [2560/5096 (50%)]\tLoss: 0.094519\n",
      "Train Epoch: 4 [3200/5096 (62%)]\tLoss: 0.014375\n",
      "Train Epoch: 4 [3840/5096 (75%)]\tLoss: 0.061254\n",
      "Train Epoch: 4 [4480/5096 (88%)]\tLoss: 0.001033\n",
      "Train Epoch: 5 [0/5096 (0%)]\tLoss: 0.006634\n",
      "Train Epoch: 5 [640/5096 (12%)]\tLoss: 0.030357\n",
      "Train Epoch: 5 [1280/5096 (25%)]\tLoss: 0.024946\n",
      "Train Epoch: 5 [1920/5096 (38%)]\tLoss: 0.012714\n",
      "Train Epoch: 5 [2560/5096 (50%)]\tLoss: 0.038519\n",
      "Train Epoch: 5 [3200/5096 (62%)]\tLoss: 0.008845\n",
      "Train Epoch: 5 [3840/5096 (75%)]\tLoss: 0.036138\n",
      "Train Epoch: 5 [4480/5096 (88%)]\tLoss: 0.108370\n",
      "Train Epoch: 6 [0/5096 (0%)]\tLoss: 0.053551\n",
      "Train Epoch: 6 [640/5096 (12%)]\tLoss: 0.021736\n",
      "Train Epoch: 6 [1280/5096 (25%)]\tLoss: 0.008460\n",
      "Train Epoch: 6 [1920/5096 (38%)]\tLoss: 0.034815\n",
      "Train Epoch: 6 [2560/5096 (50%)]\tLoss: 0.063971\n",
      "Train Epoch: 6 [3200/5096 (62%)]\tLoss: 0.042722\n",
      "Train Epoch: 6 [3840/5096 (75%)]\tLoss: 0.005226\n",
      "Train Epoch: 6 [4480/5096 (88%)]\tLoss: 0.049555\n",
      "Train Epoch: 7 [0/5096 (0%)]\tLoss: 0.045877\n",
      "Train Epoch: 7 [640/5096 (12%)]\tLoss: 0.049738\n",
      "Train Epoch: 7 [1280/5096 (25%)]\tLoss: 0.087204\n",
      "Train Epoch: 7 [1920/5096 (38%)]\tLoss: 0.028492\n",
      "Train Epoch: 7 [2560/5096 (50%)]\tLoss: 0.005213\n",
      "Train Epoch: 7 [3200/5096 (62%)]\tLoss: 0.007725\n",
      "Train Epoch: 7 [3840/5096 (75%)]\tLoss: 0.008615\n",
      "Train Epoch: 7 [4480/5096 (88%)]\tLoss: 0.015393\n",
      "Train Epoch: 8 [0/5096 (0%)]\tLoss: 0.001578\n",
      "Train Epoch: 8 [640/5096 (12%)]\tLoss: 0.023283\n",
      "Train Epoch: 8 [1280/5096 (25%)]\tLoss: 0.062895\n",
      "Train Epoch: 8 [1920/5096 (38%)]\tLoss: 0.052296\n",
      "Train Epoch: 8 [2560/5096 (50%)]\tLoss: 0.019104\n",
      "Train Epoch: 8 [3200/5096 (62%)]\tLoss: 0.058344\n",
      "Train Epoch: 8 [3840/5096 (75%)]\tLoss: 0.115263\n",
      "Train Epoch: 8 [4480/5096 (88%)]\tLoss: 0.019074\n",
      "Train Epoch: 9 [0/5096 (0%)]\tLoss: 0.006965\n",
      "Train Epoch: 9 [640/5096 (12%)]\tLoss: 0.010705\n",
      "Train Epoch: 9 [1280/5096 (25%)]\tLoss: 0.001230\n",
      "Train Epoch: 9 [1920/5096 (38%)]\tLoss: 0.006688\n",
      "Train Epoch: 9 [2560/5096 (50%)]\tLoss: 0.056623\n",
      "Train Epoch: 9 [3200/5096 (62%)]\tLoss: 0.049797\n",
      "Train Epoch: 9 [3840/5096 (75%)]\tLoss: 0.035987\n",
      "Train Epoch: 9 [4480/5096 (88%)]\tLoss: 0.015173\n",
      "Train Epoch: 10 [0/5096 (0%)]\tLoss: 0.000974\n",
      "Train Epoch: 10 [640/5096 (12%)]\tLoss: 0.056359\n",
      "Train Epoch: 10 [1280/5096 (25%)]\tLoss: 0.043667\n",
      "Train Epoch: 10 [1920/5096 (38%)]\tLoss: 0.033496\n",
      "Train Epoch: 10 [2560/5096 (50%)]\tLoss: 0.029492\n",
      "Train Epoch: 10 [3200/5096 (62%)]\tLoss: 0.017643\n",
      "Train Epoch: 10 [3840/5096 (75%)]\tLoss: 0.015099\n",
      "Train Epoch: 10 [4480/5096 (88%)]\tLoss: 0.002350\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/1599 (0%)]\tLoss: 0.255457\n",
      "Train Epoch: 1 [640/1599 (40%)]\tLoss: 0.111621\n",
      "Train Epoch: 1 [1280/1599 (80%)]\tLoss: 0.023870\n",
      "Train Epoch: 2 [0/1599 (0%)]\tLoss: 0.051058\n",
      "Train Epoch: 2 [640/1599 (40%)]\tLoss: 0.093765\n",
      "Train Epoch: 2 [1280/1599 (80%)]\tLoss: 0.028538\n",
      "Train Epoch: 3 [0/1599 (0%)]\tLoss: 0.038246\n",
      "Train Epoch: 3 [640/1599 (40%)]\tLoss: 0.134048\n",
      "Train Epoch: 3 [1280/1599 (80%)]\tLoss: 0.034463\n",
      "Train Epoch: 4 [0/1599 (0%)]\tLoss: 0.029419\n",
      "Train Epoch: 4 [640/1599 (40%)]\tLoss: 0.010726\n",
      "Train Epoch: 4 [1280/1599 (80%)]\tLoss: 0.092976\n",
      "Train Epoch: 5 [0/1599 (0%)]\tLoss: 0.027759\n",
      "Train Epoch: 5 [640/1599 (40%)]\tLoss: 0.059349\n",
      "Train Epoch: 5 [1280/1599 (80%)]\tLoss: 0.086593\n",
      "Train Epoch: 6 [0/1599 (0%)]\tLoss: 0.056612\n",
      "Train Epoch: 6 [640/1599 (40%)]\tLoss: 0.138518\n",
      "Train Epoch: 6 [1280/1599 (80%)]\tLoss: 0.005269\n",
      "Train Epoch: 7 [0/1599 (0%)]\tLoss: 0.020102\n",
      "Train Epoch: 7 [640/1599 (40%)]\tLoss: 0.017185\n",
      "Train Epoch: 7 [1280/1599 (80%)]\tLoss: 0.077847\n",
      "Train Epoch: 8 [0/1599 (0%)]\tLoss: 0.123687\n",
      "Train Epoch: 8 [640/1599 (40%)]\tLoss: 0.029558\n",
      "Train Epoch: 8 [1280/1599 (80%)]\tLoss: 0.044687\n",
      "Train Epoch: 9 [0/1599 (0%)]\tLoss: 0.139946\n",
      "Train Epoch: 9 [640/1599 (40%)]\tLoss: 0.023213\n",
      "Train Epoch: 9 [1280/1599 (80%)]\tLoss: 0.025630\n",
      "Train Epoch: 10 [0/1599 (0%)]\tLoss: 0.032279\n",
      "Train Epoch: 10 [640/1599 (40%)]\tLoss: 0.029395\n",
      "Train Epoch: 10 [1280/1599 (80%)]\tLoss: 0.183372\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/5266 (0%)]\tLoss: 0.094444\n",
      "Train Epoch: 1 [640/5266 (12%)]\tLoss: 0.019784\n",
      "Train Epoch: 1 [1280/5266 (24%)]\tLoss: 0.021307\n",
      "Train Epoch: 1 [1920/5266 (36%)]\tLoss: 0.020227\n",
      "Train Epoch: 1 [2560/5266 (48%)]\tLoss: 0.035096\n",
      "Train Epoch: 1 [3200/5266 (60%)]\tLoss: 0.034093\n",
      "Train Epoch: 1 [3840/5266 (72%)]\tLoss: 0.005328\n",
      "Train Epoch: 1 [4480/5266 (84%)]\tLoss: 0.007013\n",
      "Train Epoch: 1 [5120/5266 (96%)]\tLoss: 0.084258\n",
      "Train Epoch: 2 [0/5266 (0%)]\tLoss: 0.086963\n",
      "Train Epoch: 2 [640/5266 (12%)]\tLoss: 0.030955\n",
      "Train Epoch: 2 [1280/5266 (24%)]\tLoss: 0.011052\n",
      "Train Epoch: 2 [1920/5266 (36%)]\tLoss: 0.003395\n",
      "Train Epoch: 2 [2560/5266 (48%)]\tLoss: 0.011786\n",
      "Train Epoch: 2 [3200/5266 (60%)]\tLoss: 0.018545\n",
      "Train Epoch: 2 [3840/5266 (72%)]\tLoss: 0.005153\n",
      "Train Epoch: 2 [4480/5266 (84%)]\tLoss: 0.003760\n",
      "Train Epoch: 2 [5120/5266 (96%)]\tLoss: 0.004579\n",
      "Train Epoch: 3 [0/5266 (0%)]\tLoss: 0.001347\n",
      "Train Epoch: 3 [640/5266 (12%)]\tLoss: 0.102814\n",
      "Train Epoch: 3 [1280/5266 (24%)]\tLoss: 0.031255\n",
      "Train Epoch: 3 [1920/5266 (36%)]\tLoss: 0.045804\n",
      "Train Epoch: 3 [2560/5266 (48%)]\tLoss: 0.005763\n",
      "Train Epoch: 3 [3200/5266 (60%)]\tLoss: 0.001601\n",
      "Train Epoch: 3 [3840/5266 (72%)]\tLoss: 0.006820\n",
      "Train Epoch: 3 [4480/5266 (84%)]\tLoss: 0.028270\n",
      "Train Epoch: 3 [5120/5266 (96%)]\tLoss: 0.010744\n",
      "Train Epoch: 4 [0/5266 (0%)]\tLoss: 0.003949\n",
      "Train Epoch: 4 [640/5266 (12%)]\tLoss: 0.009887\n",
      "Train Epoch: 4 [1280/5266 (24%)]\tLoss: 0.075387\n",
      "Train Epoch: 4 [1920/5266 (36%)]\tLoss: 0.008360\n",
      "Train Epoch: 4 [2560/5266 (48%)]\tLoss: 0.054446\n",
      "Train Epoch: 4 [3200/5266 (60%)]\tLoss: 0.005495\n",
      "Train Epoch: 4 [3840/5266 (72%)]\tLoss: 0.084963\n",
      "Train Epoch: 4 [4480/5266 (84%)]\tLoss: 0.054777\n",
      "Train Epoch: 4 [5120/5266 (96%)]\tLoss: 0.030603\n",
      "Train Epoch: 5 [0/5266 (0%)]\tLoss: 0.025709\n",
      "Train Epoch: 5 [640/5266 (12%)]\tLoss: 0.026840\n",
      "Train Epoch: 5 [1280/5266 (24%)]\tLoss: 0.013409\n",
      "Train Epoch: 5 [1920/5266 (36%)]\tLoss: 0.007484\n",
      "Train Epoch: 5 [2560/5266 (48%)]\tLoss: 0.007596\n",
      "Train Epoch: 5 [3200/5266 (60%)]\tLoss: 0.063660\n",
      "Train Epoch: 5 [3840/5266 (72%)]\tLoss: 0.011318\n",
      "Train Epoch: 5 [4480/5266 (84%)]\tLoss: 0.022590\n",
      "Train Epoch: 5 [5120/5266 (96%)]\tLoss: 0.152006\n",
      "Train Epoch: 6 [0/5266 (0%)]\tLoss: 0.058328\n",
      "Train Epoch: 6 [640/5266 (12%)]\tLoss: 0.000944\n",
      "Train Epoch: 6 [1280/5266 (24%)]\tLoss: 0.186585\n",
      "Train Epoch: 6 [1920/5266 (36%)]\tLoss: 0.003861\n",
      "Train Epoch: 6 [2560/5266 (48%)]\tLoss: 0.038479\n",
      "Train Epoch: 6 [3200/5266 (60%)]\tLoss: 0.007917\n",
      "Train Epoch: 6 [3840/5266 (72%)]\tLoss: 0.032143\n",
      "Train Epoch: 6 [4480/5266 (84%)]\tLoss: 0.014990\n",
      "Train Epoch: 6 [5120/5266 (96%)]\tLoss: 0.000650\n",
      "Train Epoch: 7 [0/5266 (0%)]\tLoss: 0.042300\n",
      "Train Epoch: 7 [640/5266 (12%)]\tLoss: 0.019405\n",
      "Train Epoch: 7 [1280/5266 (24%)]\tLoss: 0.012592\n",
      "Train Epoch: 7 [1920/5266 (36%)]\tLoss: 0.000873\n",
      "Train Epoch: 7 [2560/5266 (48%)]\tLoss: 0.070834\n",
      "Train Epoch: 7 [3200/5266 (60%)]\tLoss: 0.001666\n",
      "Train Epoch: 7 [3840/5266 (72%)]\tLoss: 0.001479\n",
      "Train Epoch: 7 [4480/5266 (84%)]\tLoss: 0.019210\n",
      "Train Epoch: 7 [5120/5266 (96%)]\tLoss: 0.011641\n",
      "Train Epoch: 8 [0/5266 (0%)]\tLoss: 0.041322\n",
      "Train Epoch: 8 [640/5266 (12%)]\tLoss: 0.010182\n",
      "Train Epoch: 8 [1280/5266 (24%)]\tLoss: 0.007619\n",
      "Train Epoch: 8 [1920/5266 (36%)]\tLoss: 0.013474\n",
      "Train Epoch: 8 [2560/5266 (48%)]\tLoss: 0.002846\n",
      "Train Epoch: 8 [3200/5266 (60%)]\tLoss: 0.019057\n",
      "Train Epoch: 8 [3840/5266 (72%)]\tLoss: 0.006981\n",
      "Train Epoch: 8 [4480/5266 (84%)]\tLoss: 0.096703\n",
      "Train Epoch: 8 [5120/5266 (96%)]\tLoss: 0.014372\n",
      "Train Epoch: 9 [0/5266 (0%)]\tLoss: 0.054760\n",
      "Train Epoch: 9 [640/5266 (12%)]\tLoss: 0.017870\n",
      "Train Epoch: 9 [1280/5266 (24%)]\tLoss: 0.041053\n",
      "Train Epoch: 9 [1920/5266 (36%)]\tLoss: 0.005389\n",
      "Train Epoch: 9 [2560/5266 (48%)]\tLoss: 0.044861\n",
      "Train Epoch: 9 [3200/5266 (60%)]\tLoss: 0.005572\n",
      "Train Epoch: 9 [3840/5266 (72%)]\tLoss: 0.035911\n",
      "Train Epoch: 9 [4480/5266 (84%)]\tLoss: 0.012138\n",
      "Train Epoch: 9 [5120/5266 (96%)]\tLoss: 0.022850\n",
      "Train Epoch: 10 [0/5266 (0%)]\tLoss: 0.011277\n",
      "Train Epoch: 10 [640/5266 (12%)]\tLoss: 0.000972\n",
      "Train Epoch: 10 [1280/5266 (24%)]\tLoss: 0.051476\n",
      "Train Epoch: 10 [1920/5266 (36%)]\tLoss: 0.036411\n",
      "Train Epoch: 10 [2560/5266 (48%)]\tLoss: 0.010684\n",
      "Train Epoch: 10 [3200/5266 (60%)]\tLoss: 0.050615\n",
      "Train Epoch: 10 [3840/5266 (72%)]\tLoss: 0.010186\n",
      "Train Epoch: 10 [4480/5266 (84%)]\tLoss: 0.015350\n",
      "Train Epoch: 10 [5120/5266 (96%)]\tLoss: 0.089448\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/3530 (0%)]\tLoss: 0.043389\n",
      "Train Epoch: 1 [640/3530 (18%)]\tLoss: 0.074638\n",
      "Train Epoch: 1 [1280/3530 (36%)]\tLoss: 0.037831\n",
      "Train Epoch: 1 [1920/3530 (54%)]\tLoss: 0.138182\n",
      "Train Epoch: 1 [2560/3530 (71%)]\tLoss: 0.072432\n",
      "Train Epoch: 1 [3200/3530 (89%)]\tLoss: 0.075089\n",
      "Train Epoch: 2 [0/3530 (0%)]\tLoss: 0.176230\n",
      "Train Epoch: 2 [640/3530 (18%)]\tLoss: 0.090249\n",
      "Train Epoch: 2 [1280/3530 (36%)]\tLoss: 0.083916\n",
      "Train Epoch: 2 [1920/3530 (54%)]\tLoss: 0.083589\n",
      "Train Epoch: 2 [2560/3530 (71%)]\tLoss: 0.043309\n",
      "Train Epoch: 2 [3200/3530 (89%)]\tLoss: 0.031522\n",
      "Train Epoch: 3 [0/3530 (0%)]\tLoss: 0.039186\n",
      "Train Epoch: 3 [640/3530 (18%)]\tLoss: 0.078039\n",
      "Train Epoch: 3 [1280/3530 (36%)]\tLoss: 0.029544\n",
      "Train Epoch: 3 [1920/3530 (54%)]\tLoss: 0.151268\n",
      "Train Epoch: 3 [2560/3530 (71%)]\tLoss: 0.031712\n",
      "Train Epoch: 3 [3200/3530 (89%)]\tLoss: 0.037981\n",
      "Train Epoch: 4 [0/3530 (0%)]\tLoss: 0.079236\n",
      "Train Epoch: 4 [640/3530 (18%)]\tLoss: 0.024518\n",
      "Train Epoch: 4 [1280/3530 (36%)]\tLoss: 0.067224\n",
      "Train Epoch: 4 [1920/3530 (54%)]\tLoss: 0.076236\n",
      "Train Epoch: 4 [2560/3530 (71%)]\tLoss: 0.010692\n",
      "Train Epoch: 4 [3200/3530 (89%)]\tLoss: 0.049567\n",
      "Train Epoch: 5 [0/3530 (0%)]\tLoss: 0.061965\n",
      "Train Epoch: 5 [640/3530 (18%)]\tLoss: 0.025265\n",
      "Train Epoch: 5 [1280/3530 (36%)]\tLoss: 0.044389\n",
      "Train Epoch: 5 [1920/3530 (54%)]\tLoss: 0.064086\n",
      "Train Epoch: 5 [2560/3530 (71%)]\tLoss: 0.072841\n",
      "Train Epoch: 5 [3200/3530 (89%)]\tLoss: 0.237536\n",
      "Train Epoch: 6 [0/3530 (0%)]\tLoss: 0.014697\n",
      "Train Epoch: 6 [640/3530 (18%)]\tLoss: 0.018204\n",
      "Train Epoch: 6 [1280/3530 (36%)]\tLoss: 0.034371\n",
      "Train Epoch: 6 [1920/3530 (54%)]\tLoss: 0.020588\n",
      "Train Epoch: 6 [2560/3530 (71%)]\tLoss: 0.049729\n",
      "Train Epoch: 6 [3200/3530 (89%)]\tLoss: 0.075956\n",
      "Train Epoch: 7 [0/3530 (0%)]\tLoss: 0.052720\n",
      "Train Epoch: 7 [640/3530 (18%)]\tLoss: 0.068546\n",
      "Train Epoch: 7 [1280/3530 (36%)]\tLoss: 0.108228\n",
      "Train Epoch: 7 [1920/3530 (54%)]\tLoss: 0.047107\n",
      "Train Epoch: 7 [2560/3530 (71%)]\tLoss: 0.039541\n",
      "Train Epoch: 7 [3200/3530 (89%)]\tLoss: 0.075008\n",
      "Train Epoch: 8 [0/3530 (0%)]\tLoss: 0.033277\n",
      "Train Epoch: 8 [640/3530 (18%)]\tLoss: 0.118912\n",
      "Train Epoch: 8 [1280/3530 (36%)]\tLoss: 0.075116\n",
      "Train Epoch: 8 [1920/3530 (54%)]\tLoss: 0.027001\n",
      "Train Epoch: 8 [2560/3530 (71%)]\tLoss: 0.053388\n",
      "Train Epoch: 8 [3200/3530 (89%)]\tLoss: 0.172181\n",
      "Train Epoch: 9 [0/3530 (0%)]\tLoss: 0.043620\n",
      "Train Epoch: 9 [640/3530 (18%)]\tLoss: 0.069114\n",
      "Train Epoch: 9 [1280/3530 (36%)]\tLoss: 0.163916\n",
      "Train Epoch: 9 [1920/3530 (54%)]\tLoss: 0.034168\n",
      "Train Epoch: 9 [2560/3530 (71%)]\tLoss: 0.198007\n",
      "Train Epoch: 9 [3200/3530 (89%)]\tLoss: 0.073658\n",
      "Train Epoch: 10 [0/3530 (0%)]\tLoss: 0.020185\n",
      "Train Epoch: 10 [640/3530 (18%)]\tLoss: 0.073033\n",
      "Train Epoch: 10 [1280/3530 (36%)]\tLoss: 0.055102\n",
      "Train Epoch: 10 [1920/3530 (54%)]\tLoss: 0.035435\n",
      "Train Epoch: 10 [2560/3530 (71%)]\tLoss: 0.070108\n",
      "Train Epoch: 10 [3200/3530 (89%)]\tLoss: 0.116964\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0432, Accuracy: 9862/10000 (99%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 0.130095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 0.105924\n",
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 0.070302\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 0.108909\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 0.073240\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 0.046218\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 0.041267\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 0.153208\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 0.016644\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 0.129425\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 0.062081\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 0.112117\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 0.080270\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 0.018125\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 0.054762\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 0.019562\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 0.049214\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 0.026438\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 0.133434\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 0.038624\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.062050\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 0.092491\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 0.047167\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.054115\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.021305\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 0.074731\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.022155\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 0.198332\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.025027\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.096278\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.173566\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.023682\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.022190\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.142712\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.069104\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.088243\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.064907\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.064967\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.068898\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.034405\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.028380\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.087225\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.045120\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.037197\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.006620\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.143824\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.122911\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.077099\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.045489\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.066575\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.115413\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.124428\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.144938\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.129040\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.025408\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.127621\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.044392\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.038674\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.045371\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.042413\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.080606\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.124950\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.019750\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.010846\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.027744\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.030027\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.037423\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.026216\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.019775\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.098251\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.005177\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.026930\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.065676\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.110002\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.003900\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.180585\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.254490\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.024724\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.045802\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.048741\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.091065\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.020728\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.040541\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.038882\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.072959\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.029061\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.178608\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.040965\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.055098\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.039687\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.086502\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.132534\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.089390\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.039605\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.184915\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.027990\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.091038\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.018847\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.050811\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.109700\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.025809\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.085571\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.011306\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.146933\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.164274\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.097504\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.050224\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.022508\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 0.153961\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.024365\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.024726\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.046408\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.002926\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.052459\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.041187\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.068440\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.023477\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.067150\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.105511\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.034663\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.022302\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.028657\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.050116\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.055662\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.016329\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.019508\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.015593\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.056567\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.117409\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.018749\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.026974\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.087472\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.056401\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.049907\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.110044\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.058816\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.099346\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.020248\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.055705\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.140856\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.008591\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.019063\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.089290\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.010490\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.175178\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.078346\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.041617\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.053620\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.050888\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.048431\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.034682\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.029040\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.080154\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.056541\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.080929\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.052309\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.068021\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.045524\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.011430\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.164716\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.029722\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.100385\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.106570\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.027425\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.036781\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.146684\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.098787\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.067552\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.058199\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.057663\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.046175\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.020253\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.086177\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.071067\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.080930\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.143677\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.199848\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.024704\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.031097\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.045010\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/5110 (0%)]\tLoss: 0.034777\n",
      "Train Epoch: 1 [640/5110 (12%)]\tLoss: 0.058706\n",
      "Train Epoch: 1 [1280/5110 (25%)]\tLoss: 0.107519\n",
      "Train Epoch: 1 [1920/5110 (38%)]\tLoss: 0.054289\n",
      "Train Epoch: 1 [2560/5110 (50%)]\tLoss: 0.086303\n",
      "Train Epoch: 1 [3200/5110 (62%)]\tLoss: 0.112178\n",
      "Train Epoch: 1 [3840/5110 (75%)]\tLoss: 0.070802\n",
      "Train Epoch: 1 [4480/5110 (88%)]\tLoss: 0.012202\n",
      "Train Epoch: 2 [0/5110 (0%)]\tLoss: 0.127151\n",
      "Train Epoch: 2 [640/5110 (12%)]\tLoss: 0.031571\n",
      "Train Epoch: 2 [1280/5110 (25%)]\tLoss: 0.033152\n",
      "Train Epoch: 2 [1920/5110 (38%)]\tLoss: 0.054668\n",
      "Train Epoch: 2 [2560/5110 (50%)]\tLoss: 0.030824\n",
      "Train Epoch: 2 [3200/5110 (62%)]\tLoss: 0.080285\n",
      "Train Epoch: 2 [3840/5110 (75%)]\tLoss: 0.070490\n",
      "Train Epoch: 2 [4480/5110 (88%)]\tLoss: 0.044705\n",
      "Train Epoch: 3 [0/5110 (0%)]\tLoss: 0.034814\n",
      "Train Epoch: 3 [640/5110 (12%)]\tLoss: 0.220899\n",
      "Train Epoch: 3 [1280/5110 (25%)]\tLoss: 0.031444\n",
      "Train Epoch: 3 [1920/5110 (38%)]\tLoss: 0.015316\n",
      "Train Epoch: 3 [2560/5110 (50%)]\tLoss: 0.033404\n",
      "Train Epoch: 3 [3200/5110 (62%)]\tLoss: 0.036995\n",
      "Train Epoch: 3 [3840/5110 (75%)]\tLoss: 0.041729\n",
      "Train Epoch: 3 [4480/5110 (88%)]\tLoss: 0.024981\n",
      "Train Epoch: 4 [0/5110 (0%)]\tLoss: 0.025642\n",
      "Train Epoch: 4 [640/5110 (12%)]\tLoss: 0.079547\n",
      "Train Epoch: 4 [1280/5110 (25%)]\tLoss: 0.060443\n",
      "Train Epoch: 4 [1920/5110 (38%)]\tLoss: 0.022042\n",
      "Train Epoch: 4 [2560/5110 (50%)]\tLoss: 0.012896\n",
      "Train Epoch: 4 [3200/5110 (62%)]\tLoss: 0.139939\n",
      "Train Epoch: 4 [3840/5110 (75%)]\tLoss: 0.038045\n",
      "Train Epoch: 4 [4480/5110 (88%)]\tLoss: 0.071504\n",
      "Train Epoch: 5 [0/5110 (0%)]\tLoss: 0.018307\n",
      "Train Epoch: 5 [640/5110 (12%)]\tLoss: 0.024936\n",
      "Train Epoch: 5 [1280/5110 (25%)]\tLoss: 0.172065\n",
      "Train Epoch: 5 [1920/5110 (38%)]\tLoss: 0.131132\n",
      "Train Epoch: 5 [2560/5110 (50%)]\tLoss: 0.146087\n",
      "Train Epoch: 5 [3200/5110 (62%)]\tLoss: 0.048872\n",
      "Train Epoch: 5 [3840/5110 (75%)]\tLoss: 0.020884\n",
      "Train Epoch: 5 [4480/5110 (88%)]\tLoss: 0.212613\n",
      "Train Epoch: 6 [0/5110 (0%)]\tLoss: 0.057319\n",
      "Train Epoch: 6 [640/5110 (12%)]\tLoss: 0.069216\n",
      "Train Epoch: 6 [1280/5110 (25%)]\tLoss: 0.074194\n",
      "Train Epoch: 6 [1920/5110 (38%)]\tLoss: 0.044932\n",
      "Train Epoch: 6 [2560/5110 (50%)]\tLoss: 0.077885\n",
      "Train Epoch: 6 [3200/5110 (62%)]\tLoss: 0.051993\n",
      "Train Epoch: 6 [3840/5110 (75%)]\tLoss: 0.014132\n",
      "Train Epoch: 6 [4480/5110 (88%)]\tLoss: 0.026254\n",
      "Train Epoch: 7 [0/5110 (0%)]\tLoss: 0.014411\n",
      "Train Epoch: 7 [640/5110 (12%)]\tLoss: 0.097349\n",
      "Train Epoch: 7 [1280/5110 (25%)]\tLoss: 0.083135\n",
      "Train Epoch: 7 [1920/5110 (38%)]\tLoss: 0.028104\n",
      "Train Epoch: 7 [2560/5110 (50%)]\tLoss: 0.065879\n",
      "Train Epoch: 7 [3200/5110 (62%)]\tLoss: 0.079048\n",
      "Train Epoch: 7 [3840/5110 (75%)]\tLoss: 0.029762\n",
      "Train Epoch: 7 [4480/5110 (88%)]\tLoss: 0.023522\n",
      "Train Epoch: 8 [0/5110 (0%)]\tLoss: 0.044586\n",
      "Train Epoch: 8 [640/5110 (12%)]\tLoss: 0.059151\n",
      "Train Epoch: 8 [1280/5110 (25%)]\tLoss: 0.032375\n",
      "Train Epoch: 8 [1920/5110 (38%)]\tLoss: 0.016679\n",
      "Train Epoch: 8 [2560/5110 (50%)]\tLoss: 0.157125\n",
      "Train Epoch: 8 [3200/5110 (62%)]\tLoss: 0.042256\n",
      "Train Epoch: 8 [3840/5110 (75%)]\tLoss: 0.065301\n",
      "Train Epoch: 8 [4480/5110 (88%)]\tLoss: 0.018777\n",
      "Train Epoch: 9 [0/5110 (0%)]\tLoss: 0.005619\n",
      "Train Epoch: 9 [640/5110 (12%)]\tLoss: 0.049502\n",
      "Train Epoch: 9 [1280/5110 (25%)]\tLoss: 0.096372\n",
      "Train Epoch: 9 [1920/5110 (38%)]\tLoss: 0.058700\n",
      "Train Epoch: 9 [2560/5110 (50%)]\tLoss: 0.019449\n",
      "Train Epoch: 9 [3200/5110 (62%)]\tLoss: 0.115489\n",
      "Train Epoch: 9 [3840/5110 (75%)]\tLoss: 0.012975\n",
      "Train Epoch: 9 [4480/5110 (88%)]\tLoss: 0.012566\n",
      "Train Epoch: 10 [0/5110 (0%)]\tLoss: 0.024471\n",
      "Train Epoch: 10 [640/5110 (12%)]\tLoss: 0.039255\n",
      "Train Epoch: 10 [1280/5110 (25%)]\tLoss: 0.012181\n",
      "Train Epoch: 10 [1920/5110 (38%)]\tLoss: 0.005794\n",
      "Train Epoch: 10 [2560/5110 (50%)]\tLoss: 0.069994\n",
      "Train Epoch: 10 [3200/5110 (62%)]\tLoss: 0.007257\n",
      "Train Epoch: 10 [3840/5110 (75%)]\tLoss: 0.016303\n",
      "Train Epoch: 10 [4480/5110 (88%)]\tLoss: 0.177726\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6766 (0%)]\tLoss: 0.031841\n",
      "Train Epoch: 1 [640/6766 (9%)]\tLoss: 0.157415\n",
      "Train Epoch: 1 [1280/6766 (19%)]\tLoss: 0.050781\n",
      "Train Epoch: 1 [1920/6766 (28%)]\tLoss: 0.056347\n",
      "Train Epoch: 1 [2560/6766 (38%)]\tLoss: 0.034392\n",
      "Train Epoch: 1 [3200/6766 (47%)]\tLoss: 0.053313\n",
      "Train Epoch: 1 [3840/6766 (57%)]\tLoss: 0.014882\n",
      "Train Epoch: 1 [4480/6766 (66%)]\tLoss: 0.027190\n",
      "Train Epoch: 1 [5120/6766 (75%)]\tLoss: 0.023487\n",
      "Train Epoch: 1 [5760/6766 (85%)]\tLoss: 0.042470\n",
      "Train Epoch: 1 [6400/6766 (94%)]\tLoss: 0.016411\n",
      "Train Epoch: 2 [0/6766 (0%)]\tLoss: 0.017395\n",
      "Train Epoch: 2 [640/6766 (9%)]\tLoss: 0.218242\n",
      "Train Epoch: 2 [1280/6766 (19%)]\tLoss: 0.021909\n",
      "Train Epoch: 2 [1920/6766 (28%)]\tLoss: 0.059619\n",
      "Train Epoch: 2 [2560/6766 (38%)]\tLoss: 0.164167\n",
      "Train Epoch: 2 [3200/6766 (47%)]\tLoss: 0.059267\n",
      "Train Epoch: 2 [3840/6766 (57%)]\tLoss: 0.041064\n",
      "Train Epoch: 2 [4480/6766 (66%)]\tLoss: 0.165278\n",
      "Train Epoch: 2 [5120/6766 (75%)]\tLoss: 0.039415\n",
      "Train Epoch: 2 [5760/6766 (85%)]\tLoss: 0.045443\n",
      "Train Epoch: 2 [6400/6766 (94%)]\tLoss: 0.005997\n",
      "Train Epoch: 3 [0/6766 (0%)]\tLoss: 0.026902\n",
      "Train Epoch: 3 [640/6766 (9%)]\tLoss: 0.013037\n",
      "Train Epoch: 3 [1280/6766 (19%)]\tLoss: 0.012415\n",
      "Train Epoch: 3 [1920/6766 (28%)]\tLoss: 0.035242\n",
      "Train Epoch: 3 [2560/6766 (38%)]\tLoss: 0.027365\n",
      "Train Epoch: 3 [3200/6766 (47%)]\tLoss: 0.006942\n",
      "Train Epoch: 3 [3840/6766 (57%)]\tLoss: 0.088683\n",
      "Train Epoch: 3 [4480/6766 (66%)]\tLoss: 0.049289\n",
      "Train Epoch: 3 [5120/6766 (75%)]\tLoss: 0.035525\n",
      "Train Epoch: 3 [5760/6766 (85%)]\tLoss: 0.015433\n",
      "Train Epoch: 3 [6400/6766 (94%)]\tLoss: 0.099127\n",
      "Train Epoch: 4 [0/6766 (0%)]\tLoss: 0.006130\n",
      "Train Epoch: 4 [640/6766 (9%)]\tLoss: 0.095746\n",
      "Train Epoch: 4 [1280/6766 (19%)]\tLoss: 0.024028\n",
      "Train Epoch: 4 [1920/6766 (28%)]\tLoss: 0.036055\n",
      "Train Epoch: 4 [2560/6766 (38%)]\tLoss: 0.013953\n",
      "Train Epoch: 4 [3200/6766 (47%)]\tLoss: 0.062261\n",
      "Train Epoch: 4 [3840/6766 (57%)]\tLoss: 0.042982\n",
      "Train Epoch: 4 [4480/6766 (66%)]\tLoss: 0.017816\n",
      "Train Epoch: 4 [5120/6766 (75%)]\tLoss: 0.039296\n",
      "Train Epoch: 4 [5760/6766 (85%)]\tLoss: 0.034096\n",
      "Train Epoch: 4 [6400/6766 (94%)]\tLoss: 0.083896\n",
      "Train Epoch: 5 [0/6766 (0%)]\tLoss: 0.021952\n",
      "Train Epoch: 5 [640/6766 (9%)]\tLoss: 0.048357\n",
      "Train Epoch: 5 [1280/6766 (19%)]\tLoss: 0.035173\n",
      "Train Epoch: 5 [1920/6766 (28%)]\tLoss: 0.016884\n",
      "Train Epoch: 5 [2560/6766 (38%)]\tLoss: 0.011693\n",
      "Train Epoch: 5 [3200/6766 (47%)]\tLoss: 0.011645\n",
      "Train Epoch: 5 [3840/6766 (57%)]\tLoss: 0.088763\n",
      "Train Epoch: 5 [4480/6766 (66%)]\tLoss: 0.064934\n",
      "Train Epoch: 5 [5120/6766 (75%)]\tLoss: 0.035430\n",
      "Train Epoch: 5 [5760/6766 (85%)]\tLoss: 0.122001\n",
      "Train Epoch: 5 [6400/6766 (94%)]\tLoss: 0.002305\n",
      "Train Epoch: 6 [0/6766 (0%)]\tLoss: 0.102260\n",
      "Train Epoch: 6 [640/6766 (9%)]\tLoss: 0.029687\n",
      "Train Epoch: 6 [1280/6766 (19%)]\tLoss: 0.144636\n",
      "Train Epoch: 6 [1920/6766 (28%)]\tLoss: 0.035084\n",
      "Train Epoch: 6 [2560/6766 (38%)]\tLoss: 0.098710\n",
      "Train Epoch: 6 [3200/6766 (47%)]\tLoss: 0.074346\n",
      "Train Epoch: 6 [3840/6766 (57%)]\tLoss: 0.058163\n",
      "Train Epoch: 6 [4480/6766 (66%)]\tLoss: 0.014961\n",
      "Train Epoch: 6 [5120/6766 (75%)]\tLoss: 0.116054\n",
      "Train Epoch: 6 [5760/6766 (85%)]\tLoss: 0.018578\n",
      "Train Epoch: 6 [6400/6766 (94%)]\tLoss: 0.039048\n",
      "Train Epoch: 7 [0/6766 (0%)]\tLoss: 0.012135\n",
      "Train Epoch: 7 [640/6766 (9%)]\tLoss: 0.008613\n",
      "Train Epoch: 7 [1280/6766 (19%)]\tLoss: 0.021801\n",
      "Train Epoch: 7 [1920/6766 (28%)]\tLoss: 0.004362\n",
      "Train Epoch: 7 [2560/6766 (38%)]\tLoss: 0.019074\n",
      "Train Epoch: 7 [3200/6766 (47%)]\tLoss: 0.063060\n",
      "Train Epoch: 7 [3840/6766 (57%)]\tLoss: 0.028586\n",
      "Train Epoch: 7 [4480/6766 (66%)]\tLoss: 0.042975\n",
      "Train Epoch: 7 [5120/6766 (75%)]\tLoss: 0.061829\n",
      "Train Epoch: 7 [5760/6766 (85%)]\tLoss: 0.022189\n",
      "Train Epoch: 7 [6400/6766 (94%)]\tLoss: 0.005627\n",
      "Train Epoch: 8 [0/6766 (0%)]\tLoss: 0.019729\n",
      "Train Epoch: 8 [640/6766 (9%)]\tLoss: 0.041590\n",
      "Train Epoch: 8 [1280/6766 (19%)]\tLoss: 0.025844\n",
      "Train Epoch: 8 [1920/6766 (28%)]\tLoss: 0.037312\n",
      "Train Epoch: 8 [2560/6766 (38%)]\tLoss: 0.026726\n",
      "Train Epoch: 8 [3200/6766 (47%)]\tLoss: 0.180579\n",
      "Train Epoch: 8 [3840/6766 (57%)]\tLoss: 0.024294\n",
      "Train Epoch: 8 [4480/6766 (66%)]\tLoss: 0.094435\n",
      "Train Epoch: 8 [5120/6766 (75%)]\tLoss: 0.124976\n",
      "Train Epoch: 8 [5760/6766 (85%)]\tLoss: 0.003228\n",
      "Train Epoch: 8 [6400/6766 (94%)]\tLoss: 0.021384\n",
      "Train Epoch: 9 [0/6766 (0%)]\tLoss: 0.014612\n",
      "Train Epoch: 9 [640/6766 (9%)]\tLoss: 0.030485\n",
      "Train Epoch: 9 [1280/6766 (19%)]\tLoss: 0.021628\n",
      "Train Epoch: 9 [1920/6766 (28%)]\tLoss: 0.024761\n",
      "Train Epoch: 9 [2560/6766 (38%)]\tLoss: 0.028335\n",
      "Train Epoch: 9 [3200/6766 (47%)]\tLoss: 0.039500\n",
      "Train Epoch: 9 [3840/6766 (57%)]\tLoss: 0.046199\n",
      "Train Epoch: 9 [4480/6766 (66%)]\tLoss: 0.063029\n",
      "Train Epoch: 9 [5120/6766 (75%)]\tLoss: 0.129933\n",
      "Train Epoch: 9 [5760/6766 (85%)]\tLoss: 0.024248\n",
      "Train Epoch: 9 [6400/6766 (94%)]\tLoss: 0.009553\n",
      "Train Epoch: 10 [0/6766 (0%)]\tLoss: 0.028174\n",
      "Train Epoch: 10 [640/6766 (9%)]\tLoss: 0.080679\n",
      "Train Epoch: 10 [1280/6766 (19%)]\tLoss: 0.015626\n",
      "Train Epoch: 10 [1920/6766 (28%)]\tLoss: 0.055416\n",
      "Train Epoch: 10 [2560/6766 (38%)]\tLoss: 0.037107\n",
      "Train Epoch: 10 [3200/6766 (47%)]\tLoss: 0.035922\n",
      "Train Epoch: 10 [3840/6766 (57%)]\tLoss: 0.001660\n",
      "Train Epoch: 10 [4480/6766 (66%)]\tLoss: 0.005322\n",
      "Train Epoch: 10 [5120/6766 (75%)]\tLoss: 0.232337\n",
      "Train Epoch: 10 [5760/6766 (85%)]\tLoss: 0.049263\n",
      "Train Epoch: 10 [6400/6766 (94%)]\tLoss: 0.024911\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 0.061158\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 0.054754\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 0.048901\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 0.093219\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 0.183495\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 0.017757\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 0.075606\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 0.032815\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 0.046631\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 0.202806\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 0.182780\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 0.015189\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 0.117876\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 0.076850\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 0.031369\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 0.083995\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 0.079427\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.020946\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.036549\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.010316\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.132519\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.170480\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.064107\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.021862\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.057603\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.013764\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.051136\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.006004\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.051402\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.014067\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.049347\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.015563\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.014640\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.069296\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.050148\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.010637\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.119869\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.039819\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.056557\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.088626\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.064512\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.031251\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.062454\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.141634\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.138558\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.043029\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.116982\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.056208\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.106372\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.013624\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.021818\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.319285\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.120367\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.036317\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.035335\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.030418\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.011253\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.026476\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.036094\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.017156\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.012177\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.022841\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.009996\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.041847\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.014740\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.088733\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.010488\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.093224\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.027583\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.011359\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.176332\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.011482\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.024351\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.035985\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.015323\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.053654\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.029830\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.010373\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.048422\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.077505\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.097916\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.076106\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.014722\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.090963\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.074854\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.032444\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.076610\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.033328\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.039624\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.039432\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.022036\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.048115\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.047446\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.014895\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.132259\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.236566\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.048850\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.027412\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.074352\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.065661\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.057744\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.086294\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.012139\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.030810\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.058327\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.058727\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.026391\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.042968\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.074965\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.028752\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.225751\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.088175\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.037218\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.014677\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.020981\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.012055\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.146294\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.018605\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.020322\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.039990\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.093702\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.038198\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.040823\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.037663\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.004856\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.022287\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.019918\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.020268\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.037571\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.059566\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.047876\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.041527\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.120866\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.036898\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.050762\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.033141\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.023719\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.048604\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.060609\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.013134\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.051081\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.050931\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.048848\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.048595\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.040500\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.034160\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.012361\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.168822\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.100395\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.113735\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.059377\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.037120\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.036249\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.074644\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.012782\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.044173\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.033970\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.168172\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.095789\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.028542\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/3910 (0%)]\tLoss: 0.315520\n",
      "Train Epoch: 1 [640/3910 (16%)]\tLoss: 0.067782\n",
      "Train Epoch: 1 [1280/3910 (32%)]\tLoss: 0.050330\n",
      "Train Epoch: 1 [1920/3910 (48%)]\tLoss: 0.065677\n",
      "Train Epoch: 1 [2560/3910 (65%)]\tLoss: 0.135793\n",
      "Train Epoch: 1 [3200/3910 (81%)]\tLoss: 0.355238\n",
      "Train Epoch: 1 [3840/3910 (97%)]\tLoss: 0.024184\n",
      "Train Epoch: 2 [0/3910 (0%)]\tLoss: 0.044044\n",
      "Train Epoch: 2 [640/3910 (16%)]\tLoss: 0.015839\n",
      "Train Epoch: 2 [1280/3910 (32%)]\tLoss: 0.024377\n",
      "Train Epoch: 2 [1920/3910 (48%)]\tLoss: 0.032760\n",
      "Train Epoch: 2 [2560/3910 (65%)]\tLoss: 0.014928\n",
      "Train Epoch: 2 [3200/3910 (81%)]\tLoss: 0.062356\n",
      "Train Epoch: 2 [3840/3910 (97%)]\tLoss: 0.058352\n",
      "Train Epoch: 3 [0/3910 (0%)]\tLoss: 0.066861\n",
      "Train Epoch: 3 [640/3910 (16%)]\tLoss: 0.119941\n",
      "Train Epoch: 3 [1280/3910 (32%)]\tLoss: 0.008057\n",
      "Train Epoch: 3 [1920/3910 (48%)]\tLoss: 0.022942\n",
      "Train Epoch: 3 [2560/3910 (65%)]\tLoss: 0.037920\n",
      "Train Epoch: 3 [3200/3910 (81%)]\tLoss: 0.049945\n",
      "Train Epoch: 3 [3840/3910 (97%)]\tLoss: 0.113998\n",
      "Train Epoch: 4 [0/3910 (0%)]\tLoss: 0.024537\n",
      "Train Epoch: 4 [640/3910 (16%)]\tLoss: 0.060421\n",
      "Train Epoch: 4 [1280/3910 (32%)]\tLoss: 0.029538\n",
      "Train Epoch: 4 [1920/3910 (48%)]\tLoss: 0.062411\n",
      "Train Epoch: 4 [2560/3910 (65%)]\tLoss: 0.056619\n",
      "Train Epoch: 4 [3200/3910 (81%)]\tLoss: 0.199256\n",
      "Train Epoch: 4 [3840/3910 (97%)]\tLoss: 0.068517\n",
      "Train Epoch: 5 [0/3910 (0%)]\tLoss: 0.044519\n",
      "Train Epoch: 5 [640/3910 (16%)]\tLoss: 0.107044\n",
      "Train Epoch: 5 [1280/3910 (32%)]\tLoss: 0.058062\n",
      "Train Epoch: 5 [1920/3910 (48%)]\tLoss: 0.009161\n",
      "Train Epoch: 5 [2560/3910 (65%)]\tLoss: 0.019626\n",
      "Train Epoch: 5 [3200/3910 (81%)]\tLoss: 0.175481\n",
      "Train Epoch: 5 [3840/3910 (97%)]\tLoss: 0.024024\n",
      "Train Epoch: 6 [0/3910 (0%)]\tLoss: 0.143566\n",
      "Train Epoch: 6 [640/3910 (16%)]\tLoss: 0.027430\n",
      "Train Epoch: 6 [1280/3910 (32%)]\tLoss: 0.030250\n",
      "Train Epoch: 6 [1920/3910 (48%)]\tLoss: 0.015295\n",
      "Train Epoch: 6 [2560/3910 (65%)]\tLoss: 0.056033\n",
      "Train Epoch: 6 [3200/3910 (81%)]\tLoss: 0.104238\n",
      "Train Epoch: 6 [3840/3910 (97%)]\tLoss: 0.011987\n",
      "Train Epoch: 7 [0/3910 (0%)]\tLoss: 0.100306\n",
      "Train Epoch: 7 [640/3910 (16%)]\tLoss: 0.096111\n",
      "Train Epoch: 7 [1280/3910 (32%)]\tLoss: 0.073407\n",
      "Train Epoch: 7 [1920/3910 (48%)]\tLoss: 0.055084\n",
      "Train Epoch: 7 [2560/3910 (65%)]\tLoss: 0.101406\n",
      "Train Epoch: 7 [3200/3910 (81%)]\tLoss: 0.095593\n",
      "Train Epoch: 7 [3840/3910 (97%)]\tLoss: 0.024836\n",
      "Train Epoch: 8 [0/3910 (0%)]\tLoss: 0.077433\n",
      "Train Epoch: 8 [640/3910 (16%)]\tLoss: 0.014348\n",
      "Train Epoch: 8 [1280/3910 (32%)]\tLoss: 0.034883\n",
      "Train Epoch: 8 [1920/3910 (48%)]\tLoss: 0.029187\n",
      "Train Epoch: 8 [2560/3910 (65%)]\tLoss: 0.183447\n",
      "Train Epoch: 8 [3200/3910 (81%)]\tLoss: 0.100389\n",
      "Train Epoch: 8 [3840/3910 (97%)]\tLoss: 0.012729\n",
      "Train Epoch: 9 [0/3910 (0%)]\tLoss: 0.045945\n",
      "Train Epoch: 9 [640/3910 (16%)]\tLoss: 0.145965\n",
      "Train Epoch: 9 [1280/3910 (32%)]\tLoss: 0.106925\n",
      "Train Epoch: 9 [1920/3910 (48%)]\tLoss: 0.050688\n",
      "Train Epoch: 9 [2560/3910 (65%)]\tLoss: 0.031644\n",
      "Train Epoch: 9 [3200/3910 (81%)]\tLoss: 0.023900\n",
      "Train Epoch: 9 [3840/3910 (97%)]\tLoss: 0.106389\n",
      "Train Epoch: 10 [0/3910 (0%)]\tLoss: 0.066198\n",
      "Train Epoch: 10 [640/3910 (16%)]\tLoss: 0.009120\n",
      "Train Epoch: 10 [1280/3910 (32%)]\tLoss: 0.029340\n",
      "Train Epoch: 10 [1920/3910 (48%)]\tLoss: 0.118482\n",
      "Train Epoch: 10 [2560/3910 (65%)]\tLoss: 0.023541\n",
      "Train Epoch: 10 [3200/3910 (81%)]\tLoss: 0.014587\n",
      "Train Epoch: 10 [3840/3910 (97%)]\tLoss: 0.155568\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 0.191839\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 0.203141\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 0.022034\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 0.075891\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 0.115930\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 0.134927\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 0.014227\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 0.046870\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 0.010737\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 0.044582\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.077897\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.057504\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 0.016287\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 0.024540\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 0.093442\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.033076\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.116330\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.121685\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.129391\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.077959\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.012571\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.077119\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.018600\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.022199\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.040481\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.046870\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.039834\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.039817\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.050011\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.050843\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.023340\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.041050\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.032303\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.008227\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.010347\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.030829\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.008450\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.017246\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.005829\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.029354\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.031541\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.050287\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.033024\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.030897\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.030333\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.013105\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.011485\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.031497\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.006599\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.024965\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.013109\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.025826\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.014305\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.011988\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.068365\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.020381\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.023652\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.011814\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.224336\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.011263\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.015793\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.003678\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.058223\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.003065\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.022034\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.010204\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.035008\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.018744\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.054719\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.046222\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.189100\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.150313\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.036712\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.009249\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.096926\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.005235\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.061912\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.007139\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.076798\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.010506\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.011301\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.064735\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.023647\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.009909\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.021655\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.009104\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.015125\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.034221\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.056437\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.038311\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.063181\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.046252\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.104580\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.028170\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.019043\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.003261\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.034255\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.084342\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.102984\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.014971\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.058993\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.025670\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.018855\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.014552\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.112080\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.032697\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.205660\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.016803\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.019219\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.019197\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.131265\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.020655\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.156300\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.075487\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.061410\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.019439\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.062245\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.007556\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.010653\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.086279\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/5096 (0%)]\tLoss: 0.056420\n",
      "Train Epoch: 1 [640/5096 (12%)]\tLoss: 0.049641\n",
      "Train Epoch: 1 [1280/5096 (25%)]\tLoss: 0.024790\n",
      "Train Epoch: 1 [1920/5096 (38%)]\tLoss: 0.017472\n",
      "Train Epoch: 1 [2560/5096 (50%)]\tLoss: 0.024607\n",
      "Train Epoch: 1 [3200/5096 (62%)]\tLoss: 0.026504\n",
      "Train Epoch: 1 [3840/5096 (75%)]\tLoss: 0.037191\n",
      "Train Epoch: 1 [4480/5096 (88%)]\tLoss: 0.039996\n",
      "Train Epoch: 2 [0/5096 (0%)]\tLoss: 0.004573\n",
      "Train Epoch: 2 [640/5096 (12%)]\tLoss: 0.208574\n",
      "Train Epoch: 2 [1280/5096 (25%)]\tLoss: 0.207685\n",
      "Train Epoch: 2 [1920/5096 (38%)]\tLoss: 0.016706\n",
      "Train Epoch: 2 [2560/5096 (50%)]\tLoss: 0.064798\n",
      "Train Epoch: 2 [3200/5096 (62%)]\tLoss: 0.037210\n",
      "Train Epoch: 2 [3840/5096 (75%)]\tLoss: 0.008969\n",
      "Train Epoch: 2 [4480/5096 (88%)]\tLoss: 0.017733\n",
      "Train Epoch: 3 [0/5096 (0%)]\tLoss: 0.011325\n",
      "Train Epoch: 3 [640/5096 (12%)]\tLoss: 0.018691\n",
      "Train Epoch: 3 [1280/5096 (25%)]\tLoss: 0.060934\n",
      "Train Epoch: 3 [1920/5096 (38%)]\tLoss: 0.004501\n",
      "Train Epoch: 3 [2560/5096 (50%)]\tLoss: 0.002018\n",
      "Train Epoch: 3 [3200/5096 (62%)]\tLoss: 0.002555\n",
      "Train Epoch: 3 [3840/5096 (75%)]\tLoss: 0.047778\n",
      "Train Epoch: 3 [4480/5096 (88%)]\tLoss: 0.011617\n",
      "Train Epoch: 4 [0/5096 (0%)]\tLoss: 0.009989\n",
      "Train Epoch: 4 [640/5096 (12%)]\tLoss: 0.048930\n",
      "Train Epoch: 4 [1280/5096 (25%)]\tLoss: 0.022140\n",
      "Train Epoch: 4 [1920/5096 (38%)]\tLoss: 0.028660\n",
      "Train Epoch: 4 [2560/5096 (50%)]\tLoss: 0.034229\n",
      "Train Epoch: 4 [3200/5096 (62%)]\tLoss: 0.002533\n",
      "Train Epoch: 4 [3840/5096 (75%)]\tLoss: 0.126178\n",
      "Train Epoch: 4 [4480/5096 (88%)]\tLoss: 0.088496\n",
      "Train Epoch: 5 [0/5096 (0%)]\tLoss: 0.009247\n",
      "Train Epoch: 5 [640/5096 (12%)]\tLoss: 0.023747\n",
      "Train Epoch: 5 [1280/5096 (25%)]\tLoss: 0.014686\n",
      "Train Epoch: 5 [1920/5096 (38%)]\tLoss: 0.006192\n",
      "Train Epoch: 5 [2560/5096 (50%)]\tLoss: 0.032203\n",
      "Train Epoch: 5 [3200/5096 (62%)]\tLoss: 0.010302\n",
      "Train Epoch: 5 [3840/5096 (75%)]\tLoss: 0.006893\n",
      "Train Epoch: 5 [4480/5096 (88%)]\tLoss: 0.024269\n",
      "Train Epoch: 6 [0/5096 (0%)]\tLoss: 0.042563\n",
      "Train Epoch: 6 [640/5096 (12%)]\tLoss: 0.014109\n",
      "Train Epoch: 6 [1280/5096 (25%)]\tLoss: 0.008415\n",
      "Train Epoch: 6 [1920/5096 (38%)]\tLoss: 0.016234\n",
      "Train Epoch: 6 [2560/5096 (50%)]\tLoss: 0.011967\n",
      "Train Epoch: 6 [3200/5096 (62%)]\tLoss: 0.004687\n",
      "Train Epoch: 6 [3840/5096 (75%)]\tLoss: 0.002664\n",
      "Train Epoch: 6 [4480/5096 (88%)]\tLoss: 0.076106\n",
      "Train Epoch: 7 [0/5096 (0%)]\tLoss: 0.009731\n",
      "Train Epoch: 7 [640/5096 (12%)]\tLoss: 0.031404\n",
      "Train Epoch: 7 [1280/5096 (25%)]\tLoss: 0.015100\n",
      "Train Epoch: 7 [1920/5096 (38%)]\tLoss: 0.019093\n",
      "Train Epoch: 7 [2560/5096 (50%)]\tLoss: 0.018786\n",
      "Train Epoch: 7 [3200/5096 (62%)]\tLoss: 0.018083\n",
      "Train Epoch: 7 [3840/5096 (75%)]\tLoss: 0.008352\n",
      "Train Epoch: 7 [4480/5096 (88%)]\tLoss: 0.097893\n",
      "Train Epoch: 8 [0/5096 (0%)]\tLoss: 0.018903\n",
      "Train Epoch: 8 [640/5096 (12%)]\tLoss: 0.005876\n",
      "Train Epoch: 8 [1280/5096 (25%)]\tLoss: 0.214468\n",
      "Train Epoch: 8 [1920/5096 (38%)]\tLoss: 0.038582\n",
      "Train Epoch: 8 [2560/5096 (50%)]\tLoss: 0.037893\n",
      "Train Epoch: 8 [3200/5096 (62%)]\tLoss: 0.033708\n",
      "Train Epoch: 8 [3840/5096 (75%)]\tLoss: 0.063589\n",
      "Train Epoch: 8 [4480/5096 (88%)]\tLoss: 0.023014\n",
      "Train Epoch: 9 [0/5096 (0%)]\tLoss: 0.007698\n",
      "Train Epoch: 9 [640/5096 (12%)]\tLoss: 0.027502\n",
      "Train Epoch: 9 [1280/5096 (25%)]\tLoss: 0.075234\n",
      "Train Epoch: 9 [1920/5096 (38%)]\tLoss: 0.075051\n",
      "Train Epoch: 9 [2560/5096 (50%)]\tLoss: 0.014268\n",
      "Train Epoch: 9 [3200/5096 (62%)]\tLoss: 0.001344\n",
      "Train Epoch: 9 [3840/5096 (75%)]\tLoss: 0.052653\n",
      "Train Epoch: 9 [4480/5096 (88%)]\tLoss: 0.058927\n",
      "Train Epoch: 10 [0/5096 (0%)]\tLoss: 0.011826\n",
      "Train Epoch: 10 [640/5096 (12%)]\tLoss: 0.013536\n",
      "Train Epoch: 10 [1280/5096 (25%)]\tLoss: 0.038774\n",
      "Train Epoch: 10 [1920/5096 (38%)]\tLoss: 0.032708\n",
      "Train Epoch: 10 [2560/5096 (50%)]\tLoss: 0.015115\n",
      "Train Epoch: 10 [3200/5096 (62%)]\tLoss: 0.014183\n",
      "Train Epoch: 10 [3840/5096 (75%)]\tLoss: 0.038458\n",
      "Train Epoch: 10 [4480/5096 (88%)]\tLoss: 0.018694\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/1599 (0%)]\tLoss: 0.063499\n",
      "Train Epoch: 1 [640/1599 (40%)]\tLoss: 0.031335\n",
      "Train Epoch: 1 [1280/1599 (80%)]\tLoss: 0.056219\n",
      "Train Epoch: 2 [0/1599 (0%)]\tLoss: 0.021003\n",
      "Train Epoch: 2 [640/1599 (40%)]\tLoss: 0.040213\n",
      "Train Epoch: 2 [1280/1599 (80%)]\tLoss: 0.029805\n",
      "Train Epoch: 3 [0/1599 (0%)]\tLoss: 0.072398\n",
      "Train Epoch: 3 [640/1599 (40%)]\tLoss: 0.069396\n",
      "Train Epoch: 3 [1280/1599 (80%)]\tLoss: 0.033478\n",
      "Train Epoch: 4 [0/1599 (0%)]\tLoss: 0.177464\n",
      "Train Epoch: 4 [640/1599 (40%)]\tLoss: 0.011932\n",
      "Train Epoch: 4 [1280/1599 (80%)]\tLoss: 0.074360\n",
      "Train Epoch: 5 [0/1599 (0%)]\tLoss: 0.025950\n",
      "Train Epoch: 5 [640/1599 (40%)]\tLoss: 0.059226\n",
      "Train Epoch: 5 [1280/1599 (80%)]\tLoss: 0.032668\n",
      "Train Epoch: 6 [0/1599 (0%)]\tLoss: 0.035838\n",
      "Train Epoch: 6 [640/1599 (40%)]\tLoss: 0.086910\n",
      "Train Epoch: 6 [1280/1599 (80%)]\tLoss: 0.170771\n",
      "Train Epoch: 7 [0/1599 (0%)]\tLoss: 0.008400\n",
      "Train Epoch: 7 [640/1599 (40%)]\tLoss: 0.110419\n",
      "Train Epoch: 7 [1280/1599 (80%)]\tLoss: 0.009860\n",
      "Train Epoch: 8 [0/1599 (0%)]\tLoss: 0.027787\n",
      "Train Epoch: 8 [640/1599 (40%)]\tLoss: 0.007643\n",
      "Train Epoch: 8 [1280/1599 (80%)]\tLoss: 0.016720\n",
      "Train Epoch: 9 [0/1599 (0%)]\tLoss: 0.012664\n",
      "Train Epoch: 9 [640/1599 (40%)]\tLoss: 0.009859\n",
      "Train Epoch: 9 [1280/1599 (80%)]\tLoss: 0.021637\n",
      "Train Epoch: 10 [0/1599 (0%)]\tLoss: 0.045178\n",
      "Train Epoch: 10 [640/1599 (40%)]\tLoss: 0.051718\n",
      "Train Epoch: 10 [1280/1599 (80%)]\tLoss: 0.066868\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/5266 (0%)]\tLoss: 0.089008\n",
      "Train Epoch: 1 [640/5266 (12%)]\tLoss: 0.020616\n",
      "Train Epoch: 1 [1280/5266 (24%)]\tLoss: 0.108489\n",
      "Train Epoch: 1 [1920/5266 (36%)]\tLoss: 0.092813\n",
      "Train Epoch: 1 [2560/5266 (48%)]\tLoss: 0.082499\n",
      "Train Epoch: 1 [3200/5266 (60%)]\tLoss: 0.016399\n",
      "Train Epoch: 1 [3840/5266 (72%)]\tLoss: 0.006410\n",
      "Train Epoch: 1 [4480/5266 (84%)]\tLoss: 0.008976\n",
      "Train Epoch: 1 [5120/5266 (96%)]\tLoss: 0.047628\n",
      "Train Epoch: 2 [0/5266 (0%)]\tLoss: 0.168097\n",
      "Train Epoch: 2 [640/5266 (12%)]\tLoss: 0.008050\n",
      "Train Epoch: 2 [1280/5266 (24%)]\tLoss: 0.040712\n",
      "Train Epoch: 2 [1920/5266 (36%)]\tLoss: 0.010058\n",
      "Train Epoch: 2 [2560/5266 (48%)]\tLoss: 0.024855\n",
      "Train Epoch: 2 [3200/5266 (60%)]\tLoss: 0.082237\n",
      "Train Epoch: 2 [3840/5266 (72%)]\tLoss: 0.002590\n",
      "Train Epoch: 2 [4480/5266 (84%)]\tLoss: 0.041798\n",
      "Train Epoch: 2 [5120/5266 (96%)]\tLoss: 0.066958\n",
      "Train Epoch: 3 [0/5266 (0%)]\tLoss: 0.006870\n",
      "Train Epoch: 3 [640/5266 (12%)]\tLoss: 0.075706\n",
      "Train Epoch: 3 [1280/5266 (24%)]\tLoss: 0.022593\n",
      "Train Epoch: 3 [1920/5266 (36%)]\tLoss: 0.092010\n",
      "Train Epoch: 3 [2560/5266 (48%)]\tLoss: 0.012859\n",
      "Train Epoch: 3 [3200/5266 (60%)]\tLoss: 0.011723\n",
      "Train Epoch: 3 [3840/5266 (72%)]\tLoss: 0.004870\n",
      "Train Epoch: 3 [4480/5266 (84%)]\tLoss: 0.000384\n",
      "Train Epoch: 3 [5120/5266 (96%)]\tLoss: 0.064042\n",
      "Train Epoch: 4 [0/5266 (0%)]\tLoss: 0.009804\n",
      "Train Epoch: 4 [640/5266 (12%)]\tLoss: 0.010506\n",
      "Train Epoch: 4 [1280/5266 (24%)]\tLoss: 0.025950\n",
      "Train Epoch: 4 [1920/5266 (36%)]\tLoss: 0.034714\n",
      "Train Epoch: 4 [2560/5266 (48%)]\tLoss: 0.011711\n",
      "Train Epoch: 4 [3200/5266 (60%)]\tLoss: 0.009339\n",
      "Train Epoch: 4 [3840/5266 (72%)]\tLoss: 0.058633\n",
      "Train Epoch: 4 [4480/5266 (84%)]\tLoss: 0.033356\n",
      "Train Epoch: 4 [5120/5266 (96%)]\tLoss: 0.043982\n",
      "Train Epoch: 5 [0/5266 (0%)]\tLoss: 0.023068\n",
      "Train Epoch: 5 [640/5266 (12%)]\tLoss: 0.032770\n",
      "Train Epoch: 5 [1280/5266 (24%)]\tLoss: 0.005401\n",
      "Train Epoch: 5 [1920/5266 (36%)]\tLoss: 0.016791\n",
      "Train Epoch: 5 [2560/5266 (48%)]\tLoss: 0.014532\n",
      "Train Epoch: 5 [3200/5266 (60%)]\tLoss: 0.007481\n",
      "Train Epoch: 5 [3840/5266 (72%)]\tLoss: 0.005821\n",
      "Train Epoch: 5 [4480/5266 (84%)]\tLoss: 0.003768\n",
      "Train Epoch: 5 [5120/5266 (96%)]\tLoss: 0.066255\n",
      "Train Epoch: 6 [0/5266 (0%)]\tLoss: 0.029595\n",
      "Train Epoch: 6 [640/5266 (12%)]\tLoss: 0.011370\n",
      "Train Epoch: 6 [1280/5266 (24%)]\tLoss: 0.004987\n",
      "Train Epoch: 6 [1920/5266 (36%)]\tLoss: 0.008957\n",
      "Train Epoch: 6 [2560/5266 (48%)]\tLoss: 0.006900\n",
      "Train Epoch: 6 [3200/5266 (60%)]\tLoss: 0.013941\n",
      "Train Epoch: 6 [3840/5266 (72%)]\tLoss: 0.030437\n",
      "Train Epoch: 6 [4480/5266 (84%)]\tLoss: 0.002112\n",
      "Train Epoch: 6 [5120/5266 (96%)]\tLoss: 0.003208\n",
      "Train Epoch: 7 [0/5266 (0%)]\tLoss: 0.000917\n",
      "Train Epoch: 7 [640/5266 (12%)]\tLoss: 0.010829\n",
      "Train Epoch: 7 [1280/5266 (24%)]\tLoss: 0.024574\n",
      "Train Epoch: 7 [1920/5266 (36%)]\tLoss: 0.000639\n",
      "Train Epoch: 7 [2560/5266 (48%)]\tLoss: 0.018815\n",
      "Train Epoch: 7 [3200/5266 (60%)]\tLoss: 0.000668\n",
      "Train Epoch: 7 [3840/5266 (72%)]\tLoss: 0.061522\n",
      "Train Epoch: 7 [4480/5266 (84%)]\tLoss: 0.010239\n",
      "Train Epoch: 7 [5120/5266 (96%)]\tLoss: 0.004014\n",
      "Train Epoch: 8 [0/5266 (0%)]\tLoss: 0.051577\n",
      "Train Epoch: 8 [640/5266 (12%)]\tLoss: 0.077905\n",
      "Train Epoch: 8 [1280/5266 (24%)]\tLoss: 0.008801\n",
      "Train Epoch: 8 [1920/5266 (36%)]\tLoss: 0.060482\n",
      "Train Epoch: 8 [2560/5266 (48%)]\tLoss: 0.027997\n",
      "Train Epoch: 8 [3200/5266 (60%)]\tLoss: 0.007228\n",
      "Train Epoch: 8 [3840/5266 (72%)]\tLoss: 0.009725\n",
      "Train Epoch: 8 [4480/5266 (84%)]\tLoss: 0.003077\n",
      "Train Epoch: 8 [5120/5266 (96%)]\tLoss: 0.000884\n",
      "Train Epoch: 9 [0/5266 (0%)]\tLoss: 0.008800\n",
      "Train Epoch: 9 [640/5266 (12%)]\tLoss: 0.036221\n",
      "Train Epoch: 9 [1280/5266 (24%)]\tLoss: 0.001637\n",
      "Train Epoch: 9 [1920/5266 (36%)]\tLoss: 0.009135\n",
      "Train Epoch: 9 [2560/5266 (48%)]\tLoss: 0.029448\n",
      "Train Epoch: 9 [3200/5266 (60%)]\tLoss: 0.051411\n",
      "Train Epoch: 9 [3840/5266 (72%)]\tLoss: 0.004131\n",
      "Train Epoch: 9 [4480/5266 (84%)]\tLoss: 0.011748\n",
      "Train Epoch: 9 [5120/5266 (96%)]\tLoss: 0.005022\n",
      "Train Epoch: 10 [0/5266 (0%)]\tLoss: 0.000131\n",
      "Train Epoch: 10 [640/5266 (12%)]\tLoss: 0.024888\n",
      "Train Epoch: 10 [1280/5266 (24%)]\tLoss: 0.016419\n",
      "Train Epoch: 10 [1920/5266 (36%)]\tLoss: 0.172882\n",
      "Train Epoch: 10 [2560/5266 (48%)]\tLoss: 0.012475\n",
      "Train Epoch: 10 [3200/5266 (60%)]\tLoss: 0.013793\n",
      "Train Epoch: 10 [3840/5266 (72%)]\tLoss: 0.027638\n",
      "Train Epoch: 10 [4480/5266 (84%)]\tLoss: 0.006008\n",
      "Train Epoch: 10 [5120/5266 (96%)]\tLoss: 0.011392\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/3530 (0%)]\tLoss: 0.064970\n",
      "Train Epoch: 1 [640/3530 (18%)]\tLoss: 0.077677\n",
      "Train Epoch: 1 [1280/3530 (36%)]\tLoss: 0.032034\n",
      "Train Epoch: 1 [1920/3530 (54%)]\tLoss: 0.036279\n",
      "Train Epoch: 1 [2560/3530 (71%)]\tLoss: 0.058996\n",
      "Train Epoch: 1 [3200/3530 (89%)]\tLoss: 0.072572\n",
      "Train Epoch: 2 [0/3530 (0%)]\tLoss: 0.058382\n",
      "Train Epoch: 2 [640/3530 (18%)]\tLoss: 0.039710\n",
      "Train Epoch: 2 [1280/3530 (36%)]\tLoss: 0.072840\n",
      "Train Epoch: 2 [1920/3530 (54%)]\tLoss: 0.079742\n",
      "Train Epoch: 2 [2560/3530 (71%)]\tLoss: 0.134331\n",
      "Train Epoch: 2 [3200/3530 (89%)]\tLoss: 0.026126\n",
      "Train Epoch: 3 [0/3530 (0%)]\tLoss: 0.080333\n",
      "Train Epoch: 3 [640/3530 (18%)]\tLoss: 0.031254\n",
      "Train Epoch: 3 [1280/3530 (36%)]\tLoss: 0.170769\n",
      "Train Epoch: 3 [1920/3530 (54%)]\tLoss: 0.214605\n",
      "Train Epoch: 3 [2560/3530 (71%)]\tLoss: 0.035383\n",
      "Train Epoch: 3 [3200/3530 (89%)]\tLoss: 0.062005\n",
      "Train Epoch: 4 [0/3530 (0%)]\tLoss: 0.023966\n",
      "Train Epoch: 4 [640/3530 (18%)]\tLoss: 0.033232\n",
      "Train Epoch: 4 [1280/3530 (36%)]\tLoss: 0.039163\n",
      "Train Epoch: 4 [1920/3530 (54%)]\tLoss: 0.090441\n",
      "Train Epoch: 4 [2560/3530 (71%)]\tLoss: 0.043822\n",
      "Train Epoch: 4 [3200/3530 (89%)]\tLoss: 0.029690\n",
      "Train Epoch: 5 [0/3530 (0%)]\tLoss: 0.072631\n",
      "Train Epoch: 5 [640/3530 (18%)]\tLoss: 0.032091\n",
      "Train Epoch: 5 [1280/3530 (36%)]\tLoss: 0.021893\n",
      "Train Epoch: 5 [1920/3530 (54%)]\tLoss: 0.099066\n",
      "Train Epoch: 5 [2560/3530 (71%)]\tLoss: 0.104818\n",
      "Train Epoch: 5 [3200/3530 (89%)]\tLoss: 0.041073\n",
      "Train Epoch: 6 [0/3530 (0%)]\tLoss: 0.153732\n",
      "Train Epoch: 6 [640/3530 (18%)]\tLoss: 0.041045\n",
      "Train Epoch: 6 [1280/3530 (36%)]\tLoss: 0.009352\n",
      "Train Epoch: 6 [1920/3530 (54%)]\tLoss: 0.077194\n",
      "Train Epoch: 6 [2560/3530 (71%)]\tLoss: 0.214325\n",
      "Train Epoch: 6 [3200/3530 (89%)]\tLoss: 0.132253\n",
      "Train Epoch: 7 [0/3530 (0%)]\tLoss: 0.016419\n",
      "Train Epoch: 7 [640/3530 (18%)]\tLoss: 0.104895\n",
      "Train Epoch: 7 [1280/3530 (36%)]\tLoss: 0.027295\n",
      "Train Epoch: 7 [1920/3530 (54%)]\tLoss: 0.091026\n",
      "Train Epoch: 7 [2560/3530 (71%)]\tLoss: 0.014100\n",
      "Train Epoch: 7 [3200/3530 (89%)]\tLoss: 0.011494\n",
      "Train Epoch: 8 [0/3530 (0%)]\tLoss: 0.118824\n",
      "Train Epoch: 8 [640/3530 (18%)]\tLoss: 0.176146\n",
      "Train Epoch: 8 [1280/3530 (36%)]\tLoss: 0.055657\n",
      "Train Epoch: 8 [1920/3530 (54%)]\tLoss: 0.158426\n",
      "Train Epoch: 8 [2560/3530 (71%)]\tLoss: 0.030056\n",
      "Train Epoch: 8 [3200/3530 (89%)]\tLoss: 0.010436\n",
      "Train Epoch: 9 [0/3530 (0%)]\tLoss: 0.055996\n",
      "Train Epoch: 9 [640/3530 (18%)]\tLoss: 0.021801\n",
      "Train Epoch: 9 [1280/3530 (36%)]\tLoss: 0.056495\n",
      "Train Epoch: 9 [1920/3530 (54%)]\tLoss: 0.020580\n",
      "Train Epoch: 9 [2560/3530 (71%)]\tLoss: 0.056439\n",
      "Train Epoch: 9 [3200/3530 (89%)]\tLoss: 0.084764\n",
      "Train Epoch: 10 [0/3530 (0%)]\tLoss: 0.053489\n",
      "Train Epoch: 10 [640/3530 (18%)]\tLoss: 0.034200\n",
      "Train Epoch: 10 [1280/3530 (36%)]\tLoss: 0.124526\n",
      "Train Epoch: 10 [1920/3530 (54%)]\tLoss: 0.033329\n",
      "Train Epoch: 10 [2560/3530 (71%)]\tLoss: 0.054603\n",
      "Train Epoch: 10 [3200/3530 (89%)]\tLoss: 0.074728\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0432, Accuracy: 9855/10000 (99%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 0.126867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 0.077407\n",
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 0.092123\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 0.067494\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 0.077227\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 0.072580\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 0.022173\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 0.066393\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 0.209039\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 0.028032\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 0.034528\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 0.097703\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 0.042766\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 0.137307\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 0.054304\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 0.081345\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 0.015977\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 0.014027\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 0.116962\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 0.064742\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.203477\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 0.068994\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 0.080858\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.125342\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.049756\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 0.097244\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.028687\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 0.019707\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.042626\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.048259\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.017677\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.025848\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.054285\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.085355\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.058252\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.010476\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.094615\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.106494\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.214633\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.121156\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.068716\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.064794\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.030616\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.132225\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.147818\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.075372\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.106814\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.148505\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.169683\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.144301\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.056292\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.182048\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.103552\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.141556\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.052780\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.026267\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.117083\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.064137\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.035017\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.047349\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.031549\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.068246\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.022937\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.039489\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.024875\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.053251\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.125062\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.032087\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.025696\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.096326\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.031412\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.071640\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.041526\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.041219\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.026639\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.361299\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.016378\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.031426\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.015153\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.094765\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.083666\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.043582\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.072367\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.142653\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.044292\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.201853\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.095729\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.126450\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.003219\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.038803\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.009046\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.120230\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.073704\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.122795\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.039569\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.008738\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.095539\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.011076\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.092933\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.072903\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.019598\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.240352\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.094065\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.073463\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.055023\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.041404\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.012589\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.126069\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 0.010966\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.033326\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.023000\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.354610\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.035444\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.076025\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.094090\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.025034\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.017876\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.013701\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.083442\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.014173\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.029456\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.061201\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.202459\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.037458\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.038676\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.052774\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.045738\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.261087\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.144472\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.032337\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.012015\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.063135\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.100799\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.090672\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.035234\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.072897\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.073757\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.098564\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.022212\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.022652\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.122035\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.095919\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.015289\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.006979\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.074546\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.042314\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.092633\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.249162\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.039613\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.023744\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.094745\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.078285\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.015317\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.154248\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.027719\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.096835\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.048474\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.043825\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.061632\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.035603\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.015319\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.082200\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.082863\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.007681\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.028432\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.016979\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.051231\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.030502\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.036880\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.069259\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.031578\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.126798\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.016859\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.024937\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.010104\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.010876\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.013403\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.077000\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.057761\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.023795\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/5110 (0%)]\tLoss: 0.093850\n",
      "Train Epoch: 1 [640/5110 (12%)]\tLoss: 0.110011\n",
      "Train Epoch: 1 [1280/5110 (25%)]\tLoss: 0.034758\n",
      "Train Epoch: 1 [1920/5110 (38%)]\tLoss: 0.034146\n",
      "Train Epoch: 1 [2560/5110 (50%)]\tLoss: 0.162107\n",
      "Train Epoch: 1 [3200/5110 (62%)]\tLoss: 0.104718\n",
      "Train Epoch: 1 [3840/5110 (75%)]\tLoss: 0.116577\n",
      "Train Epoch: 1 [4480/5110 (88%)]\tLoss: 0.038088\n",
      "Train Epoch: 2 [0/5110 (0%)]\tLoss: 0.178366\n",
      "Train Epoch: 2 [640/5110 (12%)]\tLoss: 0.044477\n",
      "Train Epoch: 2 [1280/5110 (25%)]\tLoss: 0.093588\n",
      "Train Epoch: 2 [1920/5110 (38%)]\tLoss: 0.027042\n",
      "Train Epoch: 2 [2560/5110 (50%)]\tLoss: 0.098999\n",
      "Train Epoch: 2 [3200/5110 (62%)]\tLoss: 0.019072\n",
      "Train Epoch: 2 [3840/5110 (75%)]\tLoss: 0.022997\n",
      "Train Epoch: 2 [4480/5110 (88%)]\tLoss: 0.043827\n",
      "Train Epoch: 3 [0/5110 (0%)]\tLoss: 0.016498\n",
      "Train Epoch: 3 [640/5110 (12%)]\tLoss: 0.061520\n",
      "Train Epoch: 3 [1280/5110 (25%)]\tLoss: 0.050011\n",
      "Train Epoch: 3 [1920/5110 (38%)]\tLoss: 0.130571\n",
      "Train Epoch: 3 [2560/5110 (50%)]\tLoss: 0.015430\n",
      "Train Epoch: 3 [3200/5110 (62%)]\tLoss: 0.051632\n",
      "Train Epoch: 3 [3840/5110 (75%)]\tLoss: 0.063155\n",
      "Train Epoch: 3 [4480/5110 (88%)]\tLoss: 0.099004\n",
      "Train Epoch: 4 [0/5110 (0%)]\tLoss: 0.114888\n",
      "Train Epoch: 4 [640/5110 (12%)]\tLoss: 0.097236\n",
      "Train Epoch: 4 [1280/5110 (25%)]\tLoss: 0.066377\n",
      "Train Epoch: 4 [1920/5110 (38%)]\tLoss: 0.042274\n",
      "Train Epoch: 4 [2560/5110 (50%)]\tLoss: 0.058692\n",
      "Train Epoch: 4 [3200/5110 (62%)]\tLoss: 0.036109\n",
      "Train Epoch: 4 [3840/5110 (75%)]\tLoss: 0.020526\n",
      "Train Epoch: 4 [4480/5110 (88%)]\tLoss: 0.076311\n",
      "Train Epoch: 5 [0/5110 (0%)]\tLoss: 0.132356\n",
      "Train Epoch: 5 [640/5110 (12%)]\tLoss: 0.048372\n",
      "Train Epoch: 5 [1280/5110 (25%)]\tLoss: 0.059706\n",
      "Train Epoch: 5 [1920/5110 (38%)]\tLoss: 0.123670\n",
      "Train Epoch: 5 [2560/5110 (50%)]\tLoss: 0.040226\n",
      "Train Epoch: 5 [3200/5110 (62%)]\tLoss: 0.052339\n",
      "Train Epoch: 5 [3840/5110 (75%)]\tLoss: 0.054193\n",
      "Train Epoch: 5 [4480/5110 (88%)]\tLoss: 0.003688\n",
      "Train Epoch: 6 [0/5110 (0%)]\tLoss: 0.081571\n",
      "Train Epoch: 6 [640/5110 (12%)]\tLoss: 0.079277\n",
      "Train Epoch: 6 [1280/5110 (25%)]\tLoss: 0.128896\n",
      "Train Epoch: 6 [1920/5110 (38%)]\tLoss: 0.039136\n",
      "Train Epoch: 6 [2560/5110 (50%)]\tLoss: 0.167075\n",
      "Train Epoch: 6 [3200/5110 (62%)]\tLoss: 0.040221\n",
      "Train Epoch: 6 [3840/5110 (75%)]\tLoss: 0.035994\n",
      "Train Epoch: 6 [4480/5110 (88%)]\tLoss: 0.059741\n",
      "Train Epoch: 7 [0/5110 (0%)]\tLoss: 0.028553\n",
      "Train Epoch: 7 [640/5110 (12%)]\tLoss: 0.041333\n",
      "Train Epoch: 7 [1280/5110 (25%)]\tLoss: 0.047773\n",
      "Train Epoch: 7 [1920/5110 (38%)]\tLoss: 0.148020\n",
      "Train Epoch: 7 [2560/5110 (50%)]\tLoss: 0.032397\n",
      "Train Epoch: 7 [3200/5110 (62%)]\tLoss: 0.004257\n",
      "Train Epoch: 7 [3840/5110 (75%)]\tLoss: 0.059857\n",
      "Train Epoch: 7 [4480/5110 (88%)]\tLoss: 0.026947\n",
      "Train Epoch: 8 [0/5110 (0%)]\tLoss: 0.013499\n",
      "Train Epoch: 8 [640/5110 (12%)]\tLoss: 0.019237\n",
      "Train Epoch: 8 [1280/5110 (25%)]\tLoss: 0.033654\n",
      "Train Epoch: 8 [1920/5110 (38%)]\tLoss: 0.009860\n",
      "Train Epoch: 8 [2560/5110 (50%)]\tLoss: 0.191115\n",
      "Train Epoch: 8 [3200/5110 (62%)]\tLoss: 0.015685\n",
      "Train Epoch: 8 [3840/5110 (75%)]\tLoss: 0.102981\n",
      "Train Epoch: 8 [4480/5110 (88%)]\tLoss: 0.038911\n",
      "Train Epoch: 9 [0/5110 (0%)]\tLoss: 0.020592\n",
      "Train Epoch: 9 [640/5110 (12%)]\tLoss: 0.047339\n",
      "Train Epoch: 9 [1280/5110 (25%)]\tLoss: 0.015698\n",
      "Train Epoch: 9 [1920/5110 (38%)]\tLoss: 0.065963\n",
      "Train Epoch: 9 [2560/5110 (50%)]\tLoss: 0.053831\n",
      "Train Epoch: 9 [3200/5110 (62%)]\tLoss: 0.081927\n",
      "Train Epoch: 9 [3840/5110 (75%)]\tLoss: 0.054687\n",
      "Train Epoch: 9 [4480/5110 (88%)]\tLoss: 0.031937\n",
      "Train Epoch: 10 [0/5110 (0%)]\tLoss: 0.016405\n",
      "Train Epoch: 10 [640/5110 (12%)]\tLoss: 0.008247\n",
      "Train Epoch: 10 [1280/5110 (25%)]\tLoss: 0.094012\n",
      "Train Epoch: 10 [1920/5110 (38%)]\tLoss: 0.073069\n",
      "Train Epoch: 10 [2560/5110 (50%)]\tLoss: 0.036876\n",
      "Train Epoch: 10 [3200/5110 (62%)]\tLoss: 0.033030\n",
      "Train Epoch: 10 [3840/5110 (75%)]\tLoss: 0.006174\n",
      "Train Epoch: 10 [4480/5110 (88%)]\tLoss: 0.040825\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6766 (0%)]\tLoss: 0.289347\n",
      "Train Epoch: 1 [640/6766 (9%)]\tLoss: 0.096397\n",
      "Train Epoch: 1 [1280/6766 (19%)]\tLoss: 0.027121\n",
      "Train Epoch: 1 [1920/6766 (28%)]\tLoss: 0.026785\n",
      "Train Epoch: 1 [2560/6766 (38%)]\tLoss: 0.056466\n",
      "Train Epoch: 1 [3200/6766 (47%)]\tLoss: 0.036272\n",
      "Train Epoch: 1 [3840/6766 (57%)]\tLoss: 0.151580\n",
      "Train Epoch: 1 [4480/6766 (66%)]\tLoss: 0.053241\n",
      "Train Epoch: 1 [5120/6766 (75%)]\tLoss: 0.100239\n",
      "Train Epoch: 1 [5760/6766 (85%)]\tLoss: 0.030320\n",
      "Train Epoch: 1 [6400/6766 (94%)]\tLoss: 0.009413\n",
      "Train Epoch: 2 [0/6766 (0%)]\tLoss: 0.034056\n",
      "Train Epoch: 2 [640/6766 (9%)]\tLoss: 0.063346\n",
      "Train Epoch: 2 [1280/6766 (19%)]\tLoss: 0.024475\n",
      "Train Epoch: 2 [1920/6766 (28%)]\tLoss: 0.019197\n",
      "Train Epoch: 2 [2560/6766 (38%)]\tLoss: 0.004699\n",
      "Train Epoch: 2 [3200/6766 (47%)]\tLoss: 0.140708\n",
      "Train Epoch: 2 [3840/6766 (57%)]\tLoss: 0.158226\n",
      "Train Epoch: 2 [4480/6766 (66%)]\tLoss: 0.024046\n",
      "Train Epoch: 2 [5120/6766 (75%)]\tLoss: 0.055091\n",
      "Train Epoch: 2 [5760/6766 (85%)]\tLoss: 0.068679\n",
      "Train Epoch: 2 [6400/6766 (94%)]\tLoss: 0.015691\n",
      "Train Epoch: 3 [0/6766 (0%)]\tLoss: 0.160308\n",
      "Train Epoch: 3 [640/6766 (9%)]\tLoss: 0.034512\n",
      "Train Epoch: 3 [1280/6766 (19%)]\tLoss: 0.031364\n",
      "Train Epoch: 3 [1920/6766 (28%)]\tLoss: 0.097933\n",
      "Train Epoch: 3 [2560/6766 (38%)]\tLoss: 0.050610\n",
      "Train Epoch: 3 [3200/6766 (47%)]\tLoss: 0.028534\n",
      "Train Epoch: 3 [3840/6766 (57%)]\tLoss: 0.046490\n",
      "Train Epoch: 3 [4480/6766 (66%)]\tLoss: 0.156392\n",
      "Train Epoch: 3 [5120/6766 (75%)]\tLoss: 0.015165\n",
      "Train Epoch: 3 [5760/6766 (85%)]\tLoss: 0.137668\n",
      "Train Epoch: 3 [6400/6766 (94%)]\tLoss: 0.111795\n",
      "Train Epoch: 4 [0/6766 (0%)]\tLoss: 0.002497\n",
      "Train Epoch: 4 [640/6766 (9%)]\tLoss: 0.021032\n",
      "Train Epoch: 4 [1280/6766 (19%)]\tLoss: 0.140797\n",
      "Train Epoch: 4 [1920/6766 (28%)]\tLoss: 0.018335\n",
      "Train Epoch: 4 [2560/6766 (38%)]\tLoss: 0.013742\n",
      "Train Epoch: 4 [3200/6766 (47%)]\tLoss: 0.040747\n",
      "Train Epoch: 4 [3840/6766 (57%)]\tLoss: 0.004580\n",
      "Train Epoch: 4 [4480/6766 (66%)]\tLoss: 0.031930\n",
      "Train Epoch: 4 [5120/6766 (75%)]\tLoss: 0.015158\n",
      "Train Epoch: 4 [5760/6766 (85%)]\tLoss: 0.050480\n",
      "Train Epoch: 4 [6400/6766 (94%)]\tLoss: 0.009328\n",
      "Train Epoch: 5 [0/6766 (0%)]\tLoss: 0.042401\n",
      "Train Epoch: 5 [640/6766 (9%)]\tLoss: 0.003532\n",
      "Train Epoch: 5 [1280/6766 (19%)]\tLoss: 0.049740\n",
      "Train Epoch: 5 [1920/6766 (28%)]\tLoss: 0.021077\n",
      "Train Epoch: 5 [2560/6766 (38%)]\tLoss: 0.024158\n",
      "Train Epoch: 5 [3200/6766 (47%)]\tLoss: 0.143508\n",
      "Train Epoch: 5 [3840/6766 (57%)]\tLoss: 0.006456\n",
      "Train Epoch: 5 [4480/6766 (66%)]\tLoss: 0.027216\n",
      "Train Epoch: 5 [5120/6766 (75%)]\tLoss: 0.101876\n",
      "Train Epoch: 5 [5760/6766 (85%)]\tLoss: 0.045522\n",
      "Train Epoch: 5 [6400/6766 (94%)]\tLoss: 0.015357\n",
      "Train Epoch: 6 [0/6766 (0%)]\tLoss: 0.049991\n",
      "Train Epoch: 6 [640/6766 (9%)]\tLoss: 0.032996\n",
      "Train Epoch: 6 [1280/6766 (19%)]\tLoss: 0.104833\n",
      "Train Epoch: 6 [1920/6766 (28%)]\tLoss: 0.028331\n",
      "Train Epoch: 6 [2560/6766 (38%)]\tLoss: 0.016800\n",
      "Train Epoch: 6 [3200/6766 (47%)]\tLoss: 0.187162\n",
      "Train Epoch: 6 [3840/6766 (57%)]\tLoss: 0.030695\n",
      "Train Epoch: 6 [4480/6766 (66%)]\tLoss: 0.055131\n",
      "Train Epoch: 6 [5120/6766 (75%)]\tLoss: 0.123796\n",
      "Train Epoch: 6 [5760/6766 (85%)]\tLoss: 0.015399\n",
      "Train Epoch: 6 [6400/6766 (94%)]\tLoss: 0.003666\n",
      "Train Epoch: 7 [0/6766 (0%)]\tLoss: 0.033940\n",
      "Train Epoch: 7 [640/6766 (9%)]\tLoss: 0.014028\n",
      "Train Epoch: 7 [1280/6766 (19%)]\tLoss: 0.107686\n",
      "Train Epoch: 7 [1920/6766 (28%)]\tLoss: 0.059999\n",
      "Train Epoch: 7 [2560/6766 (38%)]\tLoss: 0.005348\n",
      "Train Epoch: 7 [3200/6766 (47%)]\tLoss: 0.029648\n",
      "Train Epoch: 7 [3840/6766 (57%)]\tLoss: 0.044532\n",
      "Train Epoch: 7 [4480/6766 (66%)]\tLoss: 0.070392\n",
      "Train Epoch: 7 [5120/6766 (75%)]\tLoss: 0.014019\n",
      "Train Epoch: 7 [5760/6766 (85%)]\tLoss: 0.243539\n",
      "Train Epoch: 7 [6400/6766 (94%)]\tLoss: 0.005396\n",
      "Train Epoch: 8 [0/6766 (0%)]\tLoss: 0.068086\n",
      "Train Epoch: 8 [640/6766 (9%)]\tLoss: 0.022236\n",
      "Train Epoch: 8 [1280/6766 (19%)]\tLoss: 0.070303\n",
      "Train Epoch: 8 [1920/6766 (28%)]\tLoss: 0.003344\n",
      "Train Epoch: 8 [2560/6766 (38%)]\tLoss: 0.002818\n",
      "Train Epoch: 8 [3200/6766 (47%)]\tLoss: 0.132678\n",
      "Train Epoch: 8 [3840/6766 (57%)]\tLoss: 0.027350\n",
      "Train Epoch: 8 [4480/6766 (66%)]\tLoss: 0.016954\n",
      "Train Epoch: 8 [5120/6766 (75%)]\tLoss: 0.009235\n",
      "Train Epoch: 8 [5760/6766 (85%)]\tLoss: 0.149384\n",
      "Train Epoch: 8 [6400/6766 (94%)]\tLoss: 0.083571\n",
      "Train Epoch: 9 [0/6766 (0%)]\tLoss: 0.013875\n",
      "Train Epoch: 9 [640/6766 (9%)]\tLoss: 0.004271\n",
      "Train Epoch: 9 [1280/6766 (19%)]\tLoss: 0.005289\n",
      "Train Epoch: 9 [1920/6766 (28%)]\tLoss: 0.050317\n",
      "Train Epoch: 9 [2560/6766 (38%)]\tLoss: 0.059674\n",
      "Train Epoch: 9 [3200/6766 (47%)]\tLoss: 0.025200\n",
      "Train Epoch: 9 [3840/6766 (57%)]\tLoss: 0.031089\n",
      "Train Epoch: 9 [4480/6766 (66%)]\tLoss: 0.017418\n",
      "Train Epoch: 9 [5120/6766 (75%)]\tLoss: 0.011052\n",
      "Train Epoch: 9 [5760/6766 (85%)]\tLoss: 0.017714\n",
      "Train Epoch: 9 [6400/6766 (94%)]\tLoss: 0.076369\n",
      "Train Epoch: 10 [0/6766 (0%)]\tLoss: 0.056352\n",
      "Train Epoch: 10 [640/6766 (9%)]\tLoss: 0.131898\n",
      "Train Epoch: 10 [1280/6766 (19%)]\tLoss: 0.010054\n",
      "Train Epoch: 10 [1920/6766 (28%)]\tLoss: 0.009123\n",
      "Train Epoch: 10 [2560/6766 (38%)]\tLoss: 0.008916\n",
      "Train Epoch: 10 [3200/6766 (47%)]\tLoss: 0.017188\n",
      "Train Epoch: 10 [3840/6766 (57%)]\tLoss: 0.019992\n",
      "Train Epoch: 10 [4480/6766 (66%)]\tLoss: 0.101196\n",
      "Train Epoch: 10 [5120/6766 (75%)]\tLoss: 0.019076\n",
      "Train Epoch: 10 [5760/6766 (85%)]\tLoss: 0.016491\n",
      "Train Epoch: 10 [6400/6766 (94%)]\tLoss: 0.070122\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 0.093390\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 0.078443\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 0.020076\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 0.027859\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 0.018045\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 0.188563\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 0.069137\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 0.041259\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 0.019541\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 0.100310\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 0.080502\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 0.127962\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 0.091649\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 0.166898\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 0.013157\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 0.084476\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 0.063431\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.053969\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.018241\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.123674\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.127980\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.063259\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.005363\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.040168\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.029525\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.118234\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.055874\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.076991\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.031048\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.043875\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.024413\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.006910\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.058249\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.043968\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.024353\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.064829\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.015586\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.029093\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.072062\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.033961\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.084089\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.105089\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.023133\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.040168\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.054884\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.113861\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.012825\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.030663\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.014127\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.015957\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.067046\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.060392\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.029004\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.030166\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.188598\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.042903\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.123955\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.023329\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.016430\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.015594\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.016089\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.031715\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.009268\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.315423\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.037987\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.027337\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.064004\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.033534\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.092428\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.021125\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.016550\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.048949\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.080116\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.080056\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.020983\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.028758\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.014468\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.011881\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.028237\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.023901\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.060476\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.030972\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.034504\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.007052\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.019813\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.135494\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.013338\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.045029\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.019377\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.069591\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.009024\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.078821\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.049285\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.005823\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.025105\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.038013\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.041643\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.021835\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.103821\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.123230\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.025260\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.018607\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.033011\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.014197\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.101654\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.014428\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.031864\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.090969\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.037653\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.007317\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.144166\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.019769\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.003320\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.012689\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.040046\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.029099\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.028286\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.039548\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.065573\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.032969\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.022930\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.073548\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.018034\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.067839\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.063262\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.056513\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.079992\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.025679\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.077913\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.018712\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.012797\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.052474\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.013525\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.032997\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.141730\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.071568\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.087117\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.045695\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.021917\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.187368\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.044859\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.058023\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.019044\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.035839\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.022149\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.016364\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.097758\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.087402\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.009252\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.012828\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.062368\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.004229\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.035412\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.251353\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.033602\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.017137\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.045861\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.112683\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.025035\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.036104\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/3910 (0%)]\tLoss: 0.152593\n",
      "Train Epoch: 1 [640/3910 (16%)]\tLoss: 0.052553\n",
      "Train Epoch: 1 [1280/3910 (32%)]\tLoss: 0.256430\n",
      "Train Epoch: 1 [1920/3910 (48%)]\tLoss: 0.019282\n",
      "Train Epoch: 1 [2560/3910 (65%)]\tLoss: 0.038989\n",
      "Train Epoch: 1 [3200/3910 (81%)]\tLoss: 0.123208\n",
      "Train Epoch: 1 [3840/3910 (97%)]\tLoss: 0.055894\n",
      "Train Epoch: 2 [0/3910 (0%)]\tLoss: 0.059456\n",
      "Train Epoch: 2 [640/3910 (16%)]\tLoss: 0.082143\n",
      "Train Epoch: 2 [1280/3910 (32%)]\tLoss: 0.096650\n",
      "Train Epoch: 2 [1920/3910 (48%)]\tLoss: 0.101341\n",
      "Train Epoch: 2 [2560/3910 (65%)]\tLoss: 0.064451\n",
      "Train Epoch: 2 [3200/3910 (81%)]\tLoss: 0.026778\n",
      "Train Epoch: 2 [3840/3910 (97%)]\tLoss: 0.184887\n",
      "Train Epoch: 3 [0/3910 (0%)]\tLoss: 0.063627\n",
      "Train Epoch: 3 [640/3910 (16%)]\tLoss: 0.159482\n",
      "Train Epoch: 3 [1280/3910 (32%)]\tLoss: 0.150287\n",
      "Train Epoch: 3 [1920/3910 (48%)]\tLoss: 0.165654\n",
      "Train Epoch: 3 [2560/3910 (65%)]\tLoss: 0.041349\n",
      "Train Epoch: 3 [3200/3910 (81%)]\tLoss: 0.047249\n",
      "Train Epoch: 3 [3840/3910 (97%)]\tLoss: 0.012164\n",
      "Train Epoch: 4 [0/3910 (0%)]\tLoss: 0.027489\n",
      "Train Epoch: 4 [640/3910 (16%)]\tLoss: 0.066855\n",
      "Train Epoch: 4 [1280/3910 (32%)]\tLoss: 0.006199\n",
      "Train Epoch: 4 [1920/3910 (48%)]\tLoss: 0.048719\n",
      "Train Epoch: 4 [2560/3910 (65%)]\tLoss: 0.013164\n",
      "Train Epoch: 4 [3200/3910 (81%)]\tLoss: 0.225481\n",
      "Train Epoch: 4 [3840/3910 (97%)]\tLoss: 0.013054\n",
      "Train Epoch: 5 [0/3910 (0%)]\tLoss: 0.193541\n",
      "Train Epoch: 5 [640/3910 (16%)]\tLoss: 0.104712\n",
      "Train Epoch: 5 [1280/3910 (32%)]\tLoss: 0.041218\n",
      "Train Epoch: 5 [1920/3910 (48%)]\tLoss: 0.034184\n",
      "Train Epoch: 5 [2560/3910 (65%)]\tLoss: 0.036323\n",
      "Train Epoch: 5 [3200/3910 (81%)]\tLoss: 0.024387\n",
      "Train Epoch: 5 [3840/3910 (97%)]\tLoss: 0.131011\n",
      "Train Epoch: 6 [0/3910 (0%)]\tLoss: 0.044943\n",
      "Train Epoch: 6 [640/3910 (16%)]\tLoss: 0.044190\n",
      "Train Epoch: 6 [1280/3910 (32%)]\tLoss: 0.129544\n",
      "Train Epoch: 6 [1920/3910 (48%)]\tLoss: 0.018856\n",
      "Train Epoch: 6 [2560/3910 (65%)]\tLoss: 0.060429\n",
      "Train Epoch: 6 [3200/3910 (81%)]\tLoss: 0.094870\n",
      "Train Epoch: 6 [3840/3910 (97%)]\tLoss: 0.078438\n",
      "Train Epoch: 7 [0/3910 (0%)]\tLoss: 0.014439\n",
      "Train Epoch: 7 [640/3910 (16%)]\tLoss: 0.036954\n",
      "Train Epoch: 7 [1280/3910 (32%)]\tLoss: 0.031049\n",
      "Train Epoch: 7 [1920/3910 (48%)]\tLoss: 0.096668\n",
      "Train Epoch: 7 [2560/3910 (65%)]\tLoss: 0.095202\n",
      "Train Epoch: 7 [3200/3910 (81%)]\tLoss: 0.068198\n",
      "Train Epoch: 7 [3840/3910 (97%)]\tLoss: 0.122226\n",
      "Train Epoch: 8 [0/3910 (0%)]\tLoss: 0.053667\n",
      "Train Epoch: 8 [640/3910 (16%)]\tLoss: 0.020797\n",
      "Train Epoch: 8 [1280/3910 (32%)]\tLoss: 0.014324\n",
      "Train Epoch: 8 [1920/3910 (48%)]\tLoss: 0.042235\n",
      "Train Epoch: 8 [2560/3910 (65%)]\tLoss: 0.043635\n",
      "Train Epoch: 8 [3200/3910 (81%)]\tLoss: 0.004611\n",
      "Train Epoch: 8 [3840/3910 (97%)]\tLoss: 0.062120\n",
      "Train Epoch: 9 [0/3910 (0%)]\tLoss: 0.011851\n",
      "Train Epoch: 9 [640/3910 (16%)]\tLoss: 0.032410\n",
      "Train Epoch: 9 [1280/3910 (32%)]\tLoss: 0.103446\n",
      "Train Epoch: 9 [1920/3910 (48%)]\tLoss: 0.044293\n",
      "Train Epoch: 9 [2560/3910 (65%)]\tLoss: 0.027262\n",
      "Train Epoch: 9 [3200/3910 (81%)]\tLoss: 0.039218\n",
      "Train Epoch: 9 [3840/3910 (97%)]\tLoss: 0.033506\n",
      "Train Epoch: 10 [0/3910 (0%)]\tLoss: 0.111176\n",
      "Train Epoch: 10 [640/3910 (16%)]\tLoss: 0.011152\n",
      "Train Epoch: 10 [1280/3910 (32%)]\tLoss: 0.006016\n",
      "Train Epoch: 10 [1920/3910 (48%)]\tLoss: 0.069654\n",
      "Train Epoch: 10 [2560/3910 (65%)]\tLoss: 0.264421\n",
      "Train Epoch: 10 [3200/3910 (81%)]\tLoss: 0.071795\n",
      "Train Epoch: 10 [3840/3910 (97%)]\tLoss: 0.037664\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 0.193122\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 0.201866\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 0.020247\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 0.052675\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 0.166905\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 0.016879\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 0.059878\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 0.016285\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 0.014083\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 0.020842\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.061194\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.036302\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 0.080829\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 0.037405\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 0.045454\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.004763\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.134673\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.099185\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.052199\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.023076\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.009845\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.033177\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.008519\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.037270\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.017090\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.033779\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.031516\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.056884\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.019305\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.040308\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.104284\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.037937\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.034834\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.048682\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.053393\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.063352\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.009676\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.037070\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.025850\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.006981\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.066752\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.050007\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.019168\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.027039\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.037136\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.082269\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.020760\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.004331\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.095710\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.063976\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.006245\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.021889\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.010015\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.043502\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.035671\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.015424\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.120537\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.008088\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.067447\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.021026\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.003307\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.005858\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.158271\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.137497\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.003908\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.015175\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.023749\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.041991\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.116733\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.064127\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.144425\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.024106\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.003375\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.007199\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.035615\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.045869\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.003794\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.067217\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.022303\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.013381\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.043022\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.030294\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.004070\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.011111\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.053090\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.023251\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.033027\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.012885\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.015574\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.010553\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.019920\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.092679\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.003628\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.011343\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.036172\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.045062\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.002046\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.016333\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.010706\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.009644\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.036750\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.016319\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.085663\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.003375\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.007887\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.021365\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.015864\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.041934\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.120467\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.068809\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.022047\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.014621\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.007212\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.005713\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.006374\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.012394\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.028346\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.047649\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.002730\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.129022\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/5096 (0%)]\tLoss: 0.048076\n",
      "Train Epoch: 1 [640/5096 (12%)]\tLoss: 0.089624\n",
      "Train Epoch: 1 [1280/5096 (25%)]\tLoss: 0.135640\n",
      "Train Epoch: 1 [1920/5096 (38%)]\tLoss: 0.011454\n",
      "Train Epoch: 1 [2560/5096 (50%)]\tLoss: 0.045347\n",
      "Train Epoch: 1 [3200/5096 (62%)]\tLoss: 0.027131\n",
      "Train Epoch: 1 [3840/5096 (75%)]\tLoss: 0.017940\n",
      "Train Epoch: 1 [4480/5096 (88%)]\tLoss: 0.028880\n",
      "Train Epoch: 2 [0/5096 (0%)]\tLoss: 0.010130\n",
      "Train Epoch: 2 [640/5096 (12%)]\tLoss: 0.034997\n",
      "Train Epoch: 2 [1280/5096 (25%)]\tLoss: 0.012214\n",
      "Train Epoch: 2 [1920/5096 (38%)]\tLoss: 0.054461\n",
      "Train Epoch: 2 [2560/5096 (50%)]\tLoss: 0.015343\n",
      "Train Epoch: 2 [3200/5096 (62%)]\tLoss: 0.019951\n",
      "Train Epoch: 2 [3840/5096 (75%)]\tLoss: 0.012895\n",
      "Train Epoch: 2 [4480/5096 (88%)]\tLoss: 0.013528\n",
      "Train Epoch: 3 [0/5096 (0%)]\tLoss: 0.024696\n",
      "Train Epoch: 3 [640/5096 (12%)]\tLoss: 0.115517\n",
      "Train Epoch: 3 [1280/5096 (25%)]\tLoss: 0.038507\n",
      "Train Epoch: 3 [1920/5096 (38%)]\tLoss: 0.003912\n",
      "Train Epoch: 3 [2560/5096 (50%)]\tLoss: 0.182264\n",
      "Train Epoch: 3 [3200/5096 (62%)]\tLoss: 0.012713\n",
      "Train Epoch: 3 [3840/5096 (75%)]\tLoss: 0.085683\n",
      "Train Epoch: 3 [4480/5096 (88%)]\tLoss: 0.020326\n",
      "Train Epoch: 4 [0/5096 (0%)]\tLoss: 0.022730\n",
      "Train Epoch: 4 [640/5096 (12%)]\tLoss: 0.021637\n",
      "Train Epoch: 4 [1280/5096 (25%)]\tLoss: 0.009582\n",
      "Train Epoch: 4 [1920/5096 (38%)]\tLoss: 0.006255\n",
      "Train Epoch: 4 [2560/5096 (50%)]\tLoss: 0.023116\n",
      "Train Epoch: 4 [3200/5096 (62%)]\tLoss: 0.065364\n",
      "Train Epoch: 4 [3840/5096 (75%)]\tLoss: 0.029817\n",
      "Train Epoch: 4 [4480/5096 (88%)]\tLoss: 0.007026\n",
      "Train Epoch: 5 [0/5096 (0%)]\tLoss: 0.010118\n",
      "Train Epoch: 5 [640/5096 (12%)]\tLoss: 0.040045\n",
      "Train Epoch: 5 [1280/5096 (25%)]\tLoss: 0.037780\n",
      "Train Epoch: 5 [1920/5096 (38%)]\tLoss: 0.025135\n",
      "Train Epoch: 5 [2560/5096 (50%)]\tLoss: 0.004730\n",
      "Train Epoch: 5 [3200/5096 (62%)]\tLoss: 0.058130\n",
      "Train Epoch: 5 [3840/5096 (75%)]\tLoss: 0.021537\n",
      "Train Epoch: 5 [4480/5096 (88%)]\tLoss: 0.004866\n",
      "Train Epoch: 6 [0/5096 (0%)]\tLoss: 0.009853\n",
      "Train Epoch: 6 [640/5096 (12%)]\tLoss: 0.072742\n",
      "Train Epoch: 6 [1280/5096 (25%)]\tLoss: 0.005262\n",
      "Train Epoch: 6 [1920/5096 (38%)]\tLoss: 0.025198\n",
      "Train Epoch: 6 [2560/5096 (50%)]\tLoss: 0.189161\n",
      "Train Epoch: 6 [3200/5096 (62%)]\tLoss: 0.033007\n",
      "Train Epoch: 6 [3840/5096 (75%)]\tLoss: 0.007224\n",
      "Train Epoch: 6 [4480/5096 (88%)]\tLoss: 0.031141\n",
      "Train Epoch: 7 [0/5096 (0%)]\tLoss: 0.029068\n",
      "Train Epoch: 7 [640/5096 (12%)]\tLoss: 0.027017\n",
      "Train Epoch: 7 [1280/5096 (25%)]\tLoss: 0.025578\n",
      "Train Epoch: 7 [1920/5096 (38%)]\tLoss: 0.040297\n",
      "Train Epoch: 7 [2560/5096 (50%)]\tLoss: 0.021757\n",
      "Train Epoch: 7 [3200/5096 (62%)]\tLoss: 0.043332\n",
      "Train Epoch: 7 [3840/5096 (75%)]\tLoss: 0.005555\n",
      "Train Epoch: 7 [4480/5096 (88%)]\tLoss: 0.019303\n",
      "Train Epoch: 8 [0/5096 (0%)]\tLoss: 0.000910\n",
      "Train Epoch: 8 [640/5096 (12%)]\tLoss: 0.006415\n",
      "Train Epoch: 8 [1280/5096 (25%)]\tLoss: 0.082205\n",
      "Train Epoch: 8 [1920/5096 (38%)]\tLoss: 0.006176\n",
      "Train Epoch: 8 [2560/5096 (50%)]\tLoss: 0.011070\n",
      "Train Epoch: 8 [3200/5096 (62%)]\tLoss: 0.014645\n",
      "Train Epoch: 8 [3840/5096 (75%)]\tLoss: 0.008635\n",
      "Train Epoch: 8 [4480/5096 (88%)]\tLoss: 0.025872\n",
      "Train Epoch: 9 [0/5096 (0%)]\tLoss: 0.005191\n",
      "Train Epoch: 9 [640/5096 (12%)]\tLoss: 0.044821\n",
      "Train Epoch: 9 [1280/5096 (25%)]\tLoss: 0.104360\n",
      "Train Epoch: 9 [1920/5096 (38%)]\tLoss: 0.031665\n",
      "Train Epoch: 9 [2560/5096 (50%)]\tLoss: 0.011562\n",
      "Train Epoch: 9 [3200/5096 (62%)]\tLoss: 0.005989\n",
      "Train Epoch: 9 [3840/5096 (75%)]\tLoss: 0.028315\n",
      "Train Epoch: 9 [4480/5096 (88%)]\tLoss: 0.137521\n",
      "Train Epoch: 10 [0/5096 (0%)]\tLoss: 0.012895\n",
      "Train Epoch: 10 [640/5096 (12%)]\tLoss: 0.038079\n",
      "Train Epoch: 10 [1280/5096 (25%)]\tLoss: 0.033111\n",
      "Train Epoch: 10 [1920/5096 (38%)]\tLoss: 0.009808\n",
      "Train Epoch: 10 [2560/5096 (50%)]\tLoss: 0.005291\n",
      "Train Epoch: 10 [3200/5096 (62%)]\tLoss: 0.012590\n",
      "Train Epoch: 10 [3840/5096 (75%)]\tLoss: 0.020953\n",
      "Train Epoch: 10 [4480/5096 (88%)]\tLoss: 0.103374\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/1599 (0%)]\tLoss: 0.168234\n",
      "Train Epoch: 1 [640/1599 (40%)]\tLoss: 0.407503\n",
      "Train Epoch: 1 [1280/1599 (80%)]\tLoss: 0.049485\n",
      "Train Epoch: 2 [0/1599 (0%)]\tLoss: 0.027517\n",
      "Train Epoch: 2 [640/1599 (40%)]\tLoss: 0.062559\n",
      "Train Epoch: 2 [1280/1599 (80%)]\tLoss: 0.054680\n",
      "Train Epoch: 3 [0/1599 (0%)]\tLoss: 0.106879\n",
      "Train Epoch: 3 [640/1599 (40%)]\tLoss: 0.078635\n",
      "Train Epoch: 3 [1280/1599 (80%)]\tLoss: 0.058091\n",
      "Train Epoch: 4 [0/1599 (0%)]\tLoss: 0.042189\n",
      "Train Epoch: 4 [640/1599 (40%)]\tLoss: 0.067705\n",
      "Train Epoch: 4 [1280/1599 (80%)]\tLoss: 0.079325\n",
      "Train Epoch: 5 [0/1599 (0%)]\tLoss: 0.007232\n",
      "Train Epoch: 5 [640/1599 (40%)]\tLoss: 0.055167\n",
      "Train Epoch: 5 [1280/1599 (80%)]\tLoss: 0.064907\n",
      "Train Epoch: 6 [0/1599 (0%)]\tLoss: 0.036204\n",
      "Train Epoch: 6 [640/1599 (40%)]\tLoss: 0.052625\n",
      "Train Epoch: 6 [1280/1599 (80%)]\tLoss: 0.020569\n",
      "Train Epoch: 7 [0/1599 (0%)]\tLoss: 0.046144\n",
      "Train Epoch: 7 [640/1599 (40%)]\tLoss: 0.041459\n",
      "Train Epoch: 7 [1280/1599 (80%)]\tLoss: 0.053942\n",
      "Train Epoch: 8 [0/1599 (0%)]\tLoss: 0.015460\n",
      "Train Epoch: 8 [640/1599 (40%)]\tLoss: 0.056736\n",
      "Train Epoch: 8 [1280/1599 (80%)]\tLoss: 0.086220\n",
      "Train Epoch: 9 [0/1599 (0%)]\tLoss: 0.075894\n",
      "Train Epoch: 9 [640/1599 (40%)]\tLoss: 0.035388\n",
      "Train Epoch: 9 [1280/1599 (80%)]\tLoss: 0.030939\n",
      "Train Epoch: 10 [0/1599 (0%)]\tLoss: 0.042271\n",
      "Train Epoch: 10 [640/1599 (40%)]\tLoss: 0.008215\n",
      "Train Epoch: 10 [1280/1599 (80%)]\tLoss: 0.015600\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/5266 (0%)]\tLoss: 0.124063\n",
      "Train Epoch: 1 [640/5266 (12%)]\tLoss: 0.094338\n",
      "Train Epoch: 1 [1280/5266 (24%)]\tLoss: 0.018770\n",
      "Train Epoch: 1 [1920/5266 (36%)]\tLoss: 0.053724\n",
      "Train Epoch: 1 [2560/5266 (48%)]\tLoss: 0.011514\n",
      "Train Epoch: 1 [3200/5266 (60%)]\tLoss: 0.035869\n",
      "Train Epoch: 1 [3840/5266 (72%)]\tLoss: 0.024603\n",
      "Train Epoch: 1 [4480/5266 (84%)]\tLoss: 0.014393\n",
      "Train Epoch: 1 [5120/5266 (96%)]\tLoss: 0.005273\n",
      "Train Epoch: 2 [0/5266 (0%)]\tLoss: 0.035915\n",
      "Train Epoch: 2 [640/5266 (12%)]\tLoss: 0.032217\n",
      "Train Epoch: 2 [1280/5266 (24%)]\tLoss: 0.005914\n",
      "Train Epoch: 2 [1920/5266 (36%)]\tLoss: 0.017252\n",
      "Train Epoch: 2 [2560/5266 (48%)]\tLoss: 0.010429\n",
      "Train Epoch: 2 [3200/5266 (60%)]\tLoss: 0.019241\n",
      "Train Epoch: 2 [3840/5266 (72%)]\tLoss: 0.123830\n",
      "Train Epoch: 2 [4480/5266 (84%)]\tLoss: 0.016345\n",
      "Train Epoch: 2 [5120/5266 (96%)]\tLoss: 0.003724\n",
      "Train Epoch: 3 [0/5266 (0%)]\tLoss: 0.009113\n",
      "Train Epoch: 3 [640/5266 (12%)]\tLoss: 0.029513\n",
      "Train Epoch: 3 [1280/5266 (24%)]\tLoss: 0.160212\n",
      "Train Epoch: 3 [1920/5266 (36%)]\tLoss: 0.190659\n",
      "Train Epoch: 3 [2560/5266 (48%)]\tLoss: 0.000417\n",
      "Train Epoch: 3 [3200/5266 (60%)]\tLoss: 0.008255\n",
      "Train Epoch: 3 [3840/5266 (72%)]\tLoss: 0.035508\n",
      "Train Epoch: 3 [4480/5266 (84%)]\tLoss: 0.004109\n",
      "Train Epoch: 3 [5120/5266 (96%)]\tLoss: 0.006481\n",
      "Train Epoch: 4 [0/5266 (0%)]\tLoss: 0.019258\n",
      "Train Epoch: 4 [640/5266 (12%)]\tLoss: 0.001082\n",
      "Train Epoch: 4 [1280/5266 (24%)]\tLoss: 0.004583\n",
      "Train Epoch: 4 [1920/5266 (36%)]\tLoss: 0.035778\n",
      "Train Epoch: 4 [2560/5266 (48%)]\tLoss: 0.002072\n",
      "Train Epoch: 4 [3200/5266 (60%)]\tLoss: 0.045161\n",
      "Train Epoch: 4 [3840/5266 (72%)]\tLoss: 0.005458\n",
      "Train Epoch: 4 [4480/5266 (84%)]\tLoss: 0.041407\n",
      "Train Epoch: 4 [5120/5266 (96%)]\tLoss: 0.041020\n",
      "Train Epoch: 5 [0/5266 (0%)]\tLoss: 0.068540\n",
      "Train Epoch: 5 [640/5266 (12%)]\tLoss: 0.023806\n",
      "Train Epoch: 5 [1280/5266 (24%)]\tLoss: 0.003620\n",
      "Train Epoch: 5 [1920/5266 (36%)]\tLoss: 0.120750\n",
      "Train Epoch: 5 [2560/5266 (48%)]\tLoss: 0.004371\n",
      "Train Epoch: 5 [3200/5266 (60%)]\tLoss: 0.003748\n",
      "Train Epoch: 5 [3840/5266 (72%)]\tLoss: 0.028892\n",
      "Train Epoch: 5 [4480/5266 (84%)]\tLoss: 0.011528\n",
      "Train Epoch: 5 [5120/5266 (96%)]\tLoss: 0.066210\n",
      "Train Epoch: 6 [0/5266 (0%)]\tLoss: 0.026879\n",
      "Train Epoch: 6 [640/5266 (12%)]\tLoss: 0.000857\n",
      "Train Epoch: 6 [1280/5266 (24%)]\tLoss: 0.021951\n",
      "Train Epoch: 6 [1920/5266 (36%)]\tLoss: 0.000543\n",
      "Train Epoch: 6 [2560/5266 (48%)]\tLoss: 0.035635\n",
      "Train Epoch: 6 [3200/5266 (60%)]\tLoss: 0.002348\n",
      "Train Epoch: 6 [3840/5266 (72%)]\tLoss: 0.006760\n",
      "Train Epoch: 6 [4480/5266 (84%)]\tLoss: 0.004117\n",
      "Train Epoch: 6 [5120/5266 (96%)]\tLoss: 0.005553\n",
      "Train Epoch: 7 [0/5266 (0%)]\tLoss: 0.002779\n",
      "Train Epoch: 7 [640/5266 (12%)]\tLoss: 0.001283\n",
      "Train Epoch: 7 [1280/5266 (24%)]\tLoss: 0.012448\n",
      "Train Epoch: 7 [1920/5266 (36%)]\tLoss: 0.015102\n",
      "Train Epoch: 7 [2560/5266 (48%)]\tLoss: 0.051389\n",
      "Train Epoch: 7 [3200/5266 (60%)]\tLoss: 0.003391\n",
      "Train Epoch: 7 [3840/5266 (72%)]\tLoss: 0.005428\n",
      "Train Epoch: 7 [4480/5266 (84%)]\tLoss: 0.002517\n",
      "Train Epoch: 7 [5120/5266 (96%)]\tLoss: 0.006834\n",
      "Train Epoch: 8 [0/5266 (0%)]\tLoss: 0.000760\n",
      "Train Epoch: 8 [640/5266 (12%)]\tLoss: 0.002330\n",
      "Train Epoch: 8 [1280/5266 (24%)]\tLoss: 0.007560\n",
      "Train Epoch: 8 [1920/5266 (36%)]\tLoss: 0.001538\n",
      "Train Epoch: 8 [2560/5266 (48%)]\tLoss: 0.010875\n",
      "Train Epoch: 8 [3200/5266 (60%)]\tLoss: 0.005130\n",
      "Train Epoch: 8 [3840/5266 (72%)]\tLoss: 0.029665\n",
      "Train Epoch: 8 [4480/5266 (84%)]\tLoss: 0.004344\n",
      "Train Epoch: 8 [5120/5266 (96%)]\tLoss: 0.011387\n",
      "Train Epoch: 9 [0/5266 (0%)]\tLoss: 0.009340\n",
      "Train Epoch: 9 [640/5266 (12%)]\tLoss: 0.005757\n",
      "Train Epoch: 9 [1280/5266 (24%)]\tLoss: 0.031019\n",
      "Train Epoch: 9 [1920/5266 (36%)]\tLoss: 0.004237\n",
      "Train Epoch: 9 [2560/5266 (48%)]\tLoss: 0.003242\n",
      "Train Epoch: 9 [3200/5266 (60%)]\tLoss: 0.006099\n",
      "Train Epoch: 9 [3840/5266 (72%)]\tLoss: 0.001196\n",
      "Train Epoch: 9 [4480/5266 (84%)]\tLoss: 0.001235\n",
      "Train Epoch: 9 [5120/5266 (96%)]\tLoss: 0.016680\n",
      "Train Epoch: 10 [0/5266 (0%)]\tLoss: 0.006787\n",
      "Train Epoch: 10 [640/5266 (12%)]\tLoss: 0.003180\n",
      "Train Epoch: 10 [1280/5266 (24%)]\tLoss: 0.082605\n",
      "Train Epoch: 10 [1920/5266 (36%)]\tLoss: 0.059368\n",
      "Train Epoch: 10 [2560/5266 (48%)]\tLoss: 0.014133\n",
      "Train Epoch: 10 [3200/5266 (60%)]\tLoss: 0.019503\n",
      "Train Epoch: 10 [3840/5266 (72%)]\tLoss: 0.037445\n",
      "Train Epoch: 10 [4480/5266 (84%)]\tLoss: 0.007987\n",
      "Train Epoch: 10 [5120/5266 (96%)]\tLoss: 0.002386\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/3530 (0%)]\tLoss: 0.158877\n",
      "Train Epoch: 1 [640/3530 (18%)]\tLoss: 0.068264\n",
      "Train Epoch: 1 [1280/3530 (36%)]\tLoss: 0.123221\n",
      "Train Epoch: 1 [1920/3530 (54%)]\tLoss: 0.075019\n",
      "Train Epoch: 1 [2560/3530 (71%)]\tLoss: 0.152919\n",
      "Train Epoch: 1 [3200/3530 (89%)]\tLoss: 0.069664\n",
      "Train Epoch: 2 [0/3530 (0%)]\tLoss: 0.100123\n",
      "Train Epoch: 2 [640/3530 (18%)]\tLoss: 0.091221\n",
      "Train Epoch: 2 [1280/3530 (36%)]\tLoss: 0.095288\n",
      "Train Epoch: 2 [1920/3530 (54%)]\tLoss: 0.059904\n",
      "Train Epoch: 2 [2560/3530 (71%)]\tLoss: 0.024259\n",
      "Train Epoch: 2 [3200/3530 (89%)]\tLoss: 0.106403\n",
      "Train Epoch: 3 [0/3530 (0%)]\tLoss: 0.071176\n",
      "Train Epoch: 3 [640/3530 (18%)]\tLoss: 0.016568\n",
      "Train Epoch: 3 [1280/3530 (36%)]\tLoss: 0.044972\n",
      "Train Epoch: 3 [1920/3530 (54%)]\tLoss: 0.008170\n",
      "Train Epoch: 3 [2560/3530 (71%)]\tLoss: 0.014502\n",
      "Train Epoch: 3 [3200/3530 (89%)]\tLoss: 0.094743\n",
      "Train Epoch: 4 [0/3530 (0%)]\tLoss: 0.039629\n",
      "Train Epoch: 4 [640/3530 (18%)]\tLoss: 0.056960\n",
      "Train Epoch: 4 [1280/3530 (36%)]\tLoss: 0.119420\n",
      "Train Epoch: 4 [1920/3530 (54%)]\tLoss: 0.059052\n",
      "Train Epoch: 4 [2560/3530 (71%)]\tLoss: 0.028978\n",
      "Train Epoch: 4 [3200/3530 (89%)]\tLoss: 0.055822\n",
      "Train Epoch: 5 [0/3530 (0%)]\tLoss: 0.073271\n",
      "Train Epoch: 5 [640/3530 (18%)]\tLoss: 0.088017\n",
      "Train Epoch: 5 [1280/3530 (36%)]\tLoss: 0.089731\n",
      "Train Epoch: 5 [1920/3530 (54%)]\tLoss: 0.029344\n",
      "Train Epoch: 5 [2560/3530 (71%)]\tLoss: 0.047364\n",
      "Train Epoch: 5 [3200/3530 (89%)]\tLoss: 0.127555\n",
      "Train Epoch: 6 [0/3530 (0%)]\tLoss: 0.093256\n",
      "Train Epoch: 6 [640/3530 (18%)]\tLoss: 0.039456\n",
      "Train Epoch: 6 [1280/3530 (36%)]\tLoss: 0.108234\n",
      "Train Epoch: 6 [1920/3530 (54%)]\tLoss: 0.148561\n",
      "Train Epoch: 6 [2560/3530 (71%)]\tLoss: 0.260670\n",
      "Train Epoch: 6 [3200/3530 (89%)]\tLoss: 0.062327\n",
      "Train Epoch: 7 [0/3530 (0%)]\tLoss: 0.090338\n",
      "Train Epoch: 7 [640/3530 (18%)]\tLoss: 0.048255\n",
      "Train Epoch: 7 [1280/3530 (36%)]\tLoss: 0.030672\n",
      "Train Epoch: 7 [1920/3530 (54%)]\tLoss: 0.009449\n",
      "Train Epoch: 7 [2560/3530 (71%)]\tLoss: 0.122398\n",
      "Train Epoch: 7 [3200/3530 (89%)]\tLoss: 0.043749\n",
      "Train Epoch: 8 [0/3530 (0%)]\tLoss: 0.128629\n",
      "Train Epoch: 8 [640/3530 (18%)]\tLoss: 0.040607\n",
      "Train Epoch: 8 [1280/3530 (36%)]\tLoss: 0.025450\n",
      "Train Epoch: 8 [1920/3530 (54%)]\tLoss: 0.052341\n",
      "Train Epoch: 8 [2560/3530 (71%)]\tLoss: 0.108868\n",
      "Train Epoch: 8 [3200/3530 (89%)]\tLoss: 0.125553\n",
      "Train Epoch: 9 [0/3530 (0%)]\tLoss: 0.179060\n",
      "Train Epoch: 9 [640/3530 (18%)]\tLoss: 0.065171\n",
      "Train Epoch: 9 [1280/3530 (36%)]\tLoss: 0.016862\n",
      "Train Epoch: 9 [1920/3530 (54%)]\tLoss: 0.044788\n",
      "Train Epoch: 9 [2560/3530 (71%)]\tLoss: 0.065746\n",
      "Train Epoch: 9 [3200/3530 (89%)]\tLoss: 0.074180\n",
      "Train Epoch: 10 [0/3530 (0%)]\tLoss: 0.019444\n",
      "Train Epoch: 10 [640/3530 (18%)]\tLoss: 0.076315\n",
      "Train Epoch: 10 [1280/3530 (36%)]\tLoss: 0.069200\n",
      "Train Epoch: 10 [1920/3530 (54%)]\tLoss: 0.084442\n",
      "Train Epoch: 10 [2560/3530 (71%)]\tLoss: 0.035787\n",
      "Train Epoch: 10 [3200/3530 (89%)]\tLoss: 0.074758\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0431, Accuracy: 9857/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classic\n",
    "partitioned_data_classic = partition.balanced_dirichlet_partition(\n",
    "    trainingset, partitions_number=num_clients, alpha=alpha\n",
    ")\n",
    "\n",
    "classic_client_loaders = [\n",
    "    DataLoader(Subset(trainingset, indices), batch_size=batch_size_train, shuffle=True)\n",
    "    for indices in partitioned_data_classic.values()\n",
    "]\n",
    "\n",
    "\n",
    "local_models_classic = [copy.deepcopy(global_model_classic) for _ in range(num_clients)]\n",
    "\n",
    "\n",
    "\n",
    "for round_idx in range(rounds_classic):\n",
    "    print(f\"Round {round_idx + 1}/{rounds_classic}\")\n",
    "    t1 = time.time()\n",
    "\n",
    "    local_weights_classic = []\n",
    "    for client_idx, client_model in enumerate(local_models_classic):\n",
    "        print(f\"Training client {client_idx + 1}\")\n",
    "\n",
    "        optimizer = optim.SGD(client_model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "        train_losses = []\n",
    "        train_counter = []\n",
    "\n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            train(epoch, client_model, classic_client_loaders[client_idx], optimizer, log_interval, train_losses, train_counter)\n",
    "\n",
    "        client_weights = [param.data.numpy() for param in client_model.parameters()]\n",
    "        local_weights_classic.append(client_weights)\n",
    "\n",
    "    global_weights_classic = federated_averaging(local_weights_classic)\n",
    "\n",
    "    distribute_global_model(global_weights_classic, local_models_classic, single=False)\n",
    "    distribute_global_model(global_weights_classic, global_model_classic, single=True)\n",
    "\n",
    "    test_losses = []\n",
    "    test(global_model_classic, test_loader, test_losses)\n",
    "    t2= time.time()\n",
    "\n",
    "    \n",
    "    test_accuracies_classic = []\n",
    "    correct = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = global_model_classic(data)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            all_preds.extend(pred.cpu().numpy().flatten())\n",
    "            all_targets.extend(target.cpu().numpy().flatten())\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    test_accuracies_classic.append(accuracy)\n",
    "    precision = precision_score(all_targets, all_preds, average='macro')\n",
    "    recall = recall_score(all_targets, all_preds, average='macro')\n",
    "    f1 = f1_score(all_targets, all_preds, average='macro')\n",
    "\n",
    "    \n",
    "    results[\"classic\"][\"NoCluster\"] = {\"losses\": [], \"accuracy\": [],\"precision\": [], \"recall\": [], \"f1\": [], \"trainingTime\": []}\n",
    "\n",
    "    results[\"classic\"][\"NoCluster\"][\"losses\"].extend(test_losses)\n",
    "    results[\"classic\"][\"NoCluster\"][\"accuracy\"].extend(test_accuracies_classic)\n",
    "    results[\"classic\"][\"NoCluster\"][\"precision\"].append(precision)\n",
    "    results[\"classic\"][\"NoCluster\"][\"recall\"].append(recall)\n",
    "    results[\"classic\"][\"NoCluster\"][\"f1\"].append(f1)\n",
    "    results[\"classic\"][\"NoCluster\"][\"trainingTime\"].append(t2-t1)\n",
    "\n",
    "    ######################\n",
    "\n",
    "for num_cluster in num_clusters:\n",
    "    import cluster2\n",
    "\n",
    "    targets = trainingset.targets\n",
    "    num_classes = len(set(targets)) \n",
    "    clients = [cluster2.FederatedClient(cid, indices, targets, num_classes) for cid, indices in partitioned_data_classic.items()]\n",
    "    client_distributions = [client.compute_label_distribution() for client in clients]\n",
    "    server = cluster2.FederatedClusterServer(num_cluster)\n",
    "    aggregated_data = server.aggregate_client_data(client_distributions)\n",
    "    clustered_data = server.perform_greedy_clustering(aggregated_data, partitioned_data_classic)\n",
    "    \n",
    "    partitioned_data_classic_clustered = clustered_data\n",
    "\n",
    "    \"\"\"\n",
    "    import cluster\n",
    "\n",
    "    cluster = cluster.Cluster(num_clusters=num_cluster)\n",
    "\n",
    "    targets = trainingset.targets\n",
    "    num_classes = len(set(targets))\n",
    "    clustered_data = cluster.apply_clustering(partitioned_data_classic, targets, num_classes)\n",
    "\n",
    "    partitioned_data_classic_clustered = clustered_data\n",
    "    \"\"\"\n",
    "\n",
    "    classic_client_loaders_clustered = [\n",
    "        DataLoader(Subset(trainingset, indices), batch_size=batch_size_train, shuffle=True)\n",
    "        for indices in partitioned_data_classic_clustered.values()\n",
    "    ]\n",
    "\n",
    "    for round_idx in range(rounds_classic):\n",
    "        print(f\"Round {round_idx + 1}/{rounds_classic}\")\n",
    "        t1 = time.time()\n",
    "\n",
    "        local_weights_classic = []\n",
    "        for client_idx, client_model in enumerate(local_models_classic[0: num_cluster]):\n",
    "            print(f\"Training client {client_idx + 1}\")\n",
    "\n",
    "            optimizer = optim.SGD(client_model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "            train_losses = []\n",
    "            train_counter = []\n",
    "\n",
    "            for epoch in range(1, n_epochs + 1):\n",
    "                train(epoch, client_model, classic_client_loaders_clustered[client_idx], optimizer, log_interval, train_losses, train_counter)\n",
    "\n",
    "            client_weights = [param.data.numpy() for param in client_model.parameters()]\n",
    "            local_weights_classic.append(client_weights)\n",
    "\n",
    "        global_weights_classic = federated_averaging(local_weights_classic)\n",
    "\n",
    "        distribute_global_model(global_weights_classic, local_models_classic, single=False)\n",
    "        distribute_global_model(global_weights_classic, global_model_classic, single=True)\n",
    "\n",
    "        test_losses = []\n",
    "        test(global_model_classic, test_loader, test_losses)\n",
    "        t2= time.time()\n",
    "\n",
    "        test_accuracies_classic = []\n",
    "        correct = 0\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                output = global_model_classic(data)\n",
    "                pred = output.data.max(1, keepdim=True)[1]\n",
    "                all_preds.extend(pred.cpu().numpy().flatten())\n",
    "                all_targets.extend(target.cpu().numpy().flatten())\n",
    "                correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = 100. * correct / len(test_loader.dataset)\n",
    "        test_accuracies_classic.append(accuracy)\n",
    "        precision = precision_score(all_targets, all_preds, average='macro')\n",
    "        recall = recall_score(all_targets, all_preds, average='macro')\n",
    "        f1 = f1_score(all_targets, all_preds, average='macro')\n",
    "\n",
    "        # Save results for clustered classic\n",
    "        if num_cluster not in clusteredResults[\"classic\"]:\n",
    "            clusteredResults[\"classic\"][num_cluster] = {\"losses\": [], \"accuracy\": [],\"precision\": [], \"recall\": [], \"f1\": [], \"trainingTime\": []}\n",
    "\n",
    "        clusteredResults[\"classic\"][num_cluster][\"losses\"].extend(test_losses)\n",
    "        clusteredResults[\"classic\"][num_cluster][\"accuracy\"].extend(test_accuracies_classic)\n",
    "        clusteredResults[\"classic\"][num_cluster][\"precision\"].append(precision)\n",
    "        clusteredResults[\"classic\"][num_cluster][\"recall\"].append(recall)\n",
    "        clusteredResults[\"classic\"][num_cluster][\"f1\"].append(f1)\n",
    "        clusteredResults[\"classic\"][num_cluster][\"trainingTime\"].append(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results (Non-Clustered): {'classic': {'NoCluster': {'losses': [0.24501373596191406], 'accuracy': [92.9], 'precision': [0.9309098216561166], 'recall': [0.9276528452830002], 'f1': [0.9277434346191409], 'trainingTime': [435.5968379974365]}}, 'pca': {}, 'autoencoder': {}}\n",
      "Final Results (Clustered): {'classic': {2: {'losses': [0.1204822769165039, 0.08749838790893555, 0.07249506645202637, 0.060785656356811525], 'accuracy': [96.27, 97.19, 97.67, 98.14], 'precision': [0.9632515793011287, 0.9721386109418072, 0.9768669227165413, 0.9813319250860137], 'recall': [0.9621625225549579, 0.971475160915254, 0.9763796548629928, 0.9811212622375359], 'f1': [0.962393776406582, 0.9716119798862632, 0.9764990378783294, 0.9811580972366768], 'trainingTime': [504.0559151172638, 474.4601457118988, 544.6197488307953, 533.0191023349762]}, 4: {'losses': [0.06001741485595703, 0.05838548698425293, 0.05673707008361816, 0.05309056529998779], 'accuracy': [98.1, 98.12, 98.19, 98.32], 'precision': [0.9811562287140376, 0.9813572301612907, 0.9820578188825666, 0.9832905546122482], 'recall': [0.9806966420158905, 0.9809280375617003, 0.9815865702412536, 0.982929674820649], 'f1': [0.9808299287883108, 0.9810480411528595, 0.9817350006206664, 0.9830377366000199], 'trainingTime': [506.94481468200684, 487.1124300956726, 502.99854493141174, 540.8997662067413]}, 6: {'losses': [0.050726742553710936, 0.049660003662109375, 0.05301490592956543, 0.04876017589569092], 'accuracy': [98.29, 98.36, 98.24, 98.35], 'precision': [0.9830270901227113, 0.9837223443385896, 0.9825280751083889, 0.9836289937947296], 'recall': [0.9826906793827748, 0.9833908539464147, 0.9820702761851161, 0.9832994958661108], 'f1': [0.9827896753834622, 0.9835026378684859, 0.9821990093186598, 0.9833958293485185], 'trainingTime': [487.72357511520386, 487.9857530593872, 481.3204882144928, 481.73507380485535]}, 8: {'losses': [0.04373618450164795, 0.0432011287689209, 0.04283792133331299, 0.04246301174163818], 'accuracy': [98.51, 98.48, 98.55, 98.56], 'precision': [0.9851390092233403, 0.9848306150832388, 0.985544269984121, 0.9856251133296595], 'recall': [0.9849483653039044, 0.9846585158912736, 0.9853375684890302, 0.9854641304312904], 'f1': [0.9850139626087012, 0.9847181218625229, 0.9854145762840625, 0.9855161483147172], 'trainingTime': [470.2906153202057, 477.0972616672516, 477.7941300868988, 484.9117386341095]}, 10: {'losses': [0.04332637062072754, 0.04322692241668701, 0.04316799621582031, 0.04308138751983642], 'accuracy': [98.59, 98.62, 98.55, 98.57], 'precision': [0.9859315282208062, 0.9862215454862253, 0.9855366945805313, 0.9857353222220109], 'recall': [0.985714917083661, 0.986063449942234, 0.9853650010578623, 0.985537115772676], 'f1': [0.9857861761771047, 0.9860982591397848, 0.9854113291741188, 0.9855985790558354], 'trainingTime': [469.0093162059784, 478.97578620910645, 469.0331768989563, 456.13612842559814]}}, 'pca': {}, 'autoencoder': {}}\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Results (Non-Clustered):\", results)\n",
    "print(\"Final Results (Clustered):\", clusteredResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "#trainingset_pca = train_loader_reduced_pca.dataset\n",
    "trial_model_pca = classification_model()\n",
    "global_model_pca = classification_model() \n",
    "trainingset_pca = train_loader_pca.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 2.378425\n",
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 2.266339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 2.090875\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 1.805635\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 1.548152\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 1.558095\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 1.432572\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 1.255070\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 1.111838\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 1.057938\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 0.929447\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 0.866774\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 0.780119\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 0.849019\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 0.804700\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 0.833904\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 0.807055\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 0.787292\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 0.912307\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 0.443758\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.477500\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 0.586195\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 0.750722\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.467449\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.590091\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 0.576637\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.668414\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 0.603717\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.355141\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.366418\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.540736\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.554677\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.331203\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.533889\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.455668\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.468499\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.336120\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.395534\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.430835\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.477118\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.281309\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.310152\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.340628\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.419483\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.421358\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.290555\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.420108\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.363881\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.525841\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.397707\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.319748\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.330736\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.480656\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.165021\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.379331\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.239968\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.275509\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.214646\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.254627\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.320512\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.286504\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.285156\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.278053\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.258117\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.238929\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.252949\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.275852\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.512116\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.301155\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.370908\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.396025\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.362265\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.093072\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.299618\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.223785\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.287413\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.383853\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.282080\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.190476\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.164484\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.255207\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.459177\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.326695\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.216246\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.249857\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.084103\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.186365\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.320300\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.242008\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.239525\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.886774\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.426647\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.195818\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.194466\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.155482\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.153864\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.133375\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.218896\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.270865\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.507970\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.173193\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.332634\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.303333\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.285266\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.291470\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.178733\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.189249\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.329141\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 0.421616\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.098209\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.191066\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.184987\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.237471\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.205724\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.237102\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.177846\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.281948\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.186727\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.274718\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.331140\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.295056\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.228838\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.215324\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.326404\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.136494\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.092812\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.294519\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.183778\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.170085\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.225844\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.210140\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.386181\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.245327\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.467045\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.142734\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.424518\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.187774\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.339706\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.112564\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.175117\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.199970\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.132526\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.127937\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.172606\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.264752\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.313709\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.227304\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.169311\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.192598\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.189402\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.096715\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.149800\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.184433\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.288474\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.306872\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.298352\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.376149\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.282179\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.336923\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.165163\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.168321\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.129764\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.187669\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.074993\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.146358\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.145600\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.071326\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.159172\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.235694\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.079398\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.254059\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.394752\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.178749\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.300594\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.253826\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.223553\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.315430\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.236660\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.093900\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.183624\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/5110 (0%)]\tLoss: 2.378900\n",
      "Train Epoch: 1 [640/5110 (12%)]\tLoss: 2.031829\n",
      "Train Epoch: 1 [1280/5110 (25%)]\tLoss: 1.395379\n",
      "Train Epoch: 1 [1920/5110 (38%)]\tLoss: 1.588728\n",
      "Train Epoch: 1 [2560/5110 (50%)]\tLoss: 1.335068\n",
      "Train Epoch: 1 [3200/5110 (62%)]\tLoss: 1.087107\n",
      "Train Epoch: 1 [3840/5110 (75%)]\tLoss: 1.187303\n",
      "Train Epoch: 1 [4480/5110 (88%)]\tLoss: 0.964495\n",
      "Train Epoch: 2 [0/5110 (0%)]\tLoss: 0.863713\n",
      "Train Epoch: 2 [640/5110 (12%)]\tLoss: 0.793504\n",
      "Train Epoch: 2 [1280/5110 (25%)]\tLoss: 0.750298\n",
      "Train Epoch: 2 [1920/5110 (38%)]\tLoss: 0.981179\n",
      "Train Epoch: 2 [2560/5110 (50%)]\tLoss: 0.878851\n",
      "Train Epoch: 2 [3200/5110 (62%)]\tLoss: 0.483115\n",
      "Train Epoch: 2 [3840/5110 (75%)]\tLoss: 0.550534\n",
      "Train Epoch: 2 [4480/5110 (88%)]\tLoss: 0.748891\n",
      "Train Epoch: 3 [0/5110 (0%)]\tLoss: 0.732051\n",
      "Train Epoch: 3 [640/5110 (12%)]\tLoss: 0.566524\n",
      "Train Epoch: 3 [1280/5110 (25%)]\tLoss: 0.483805\n",
      "Train Epoch: 3 [1920/5110 (38%)]\tLoss: 0.517579\n",
      "Train Epoch: 3 [2560/5110 (50%)]\tLoss: 0.574056\n",
      "Train Epoch: 3 [3200/5110 (62%)]\tLoss: 0.342275\n",
      "Train Epoch: 3 [3840/5110 (75%)]\tLoss: 0.626898\n",
      "Train Epoch: 3 [4480/5110 (88%)]\tLoss: 0.311981\n",
      "Train Epoch: 4 [0/5110 (0%)]\tLoss: 0.286919\n",
      "Train Epoch: 4 [640/5110 (12%)]\tLoss: 0.274614\n",
      "Train Epoch: 4 [1280/5110 (25%)]\tLoss: 0.352650\n",
      "Train Epoch: 4 [1920/5110 (38%)]\tLoss: 0.248383\n",
      "Train Epoch: 4 [2560/5110 (50%)]\tLoss: 0.303421\n",
      "Train Epoch: 4 [3200/5110 (62%)]\tLoss: 0.379689\n",
      "Train Epoch: 4 [3840/5110 (75%)]\tLoss: 0.632403\n",
      "Train Epoch: 4 [4480/5110 (88%)]\tLoss: 0.280573\n",
      "Train Epoch: 5 [0/5110 (0%)]\tLoss: 0.235775\n",
      "Train Epoch: 5 [640/5110 (12%)]\tLoss: 0.471206\n",
      "Train Epoch: 5 [1280/5110 (25%)]\tLoss: 0.300519\n",
      "Train Epoch: 5 [1920/5110 (38%)]\tLoss: 0.200813\n",
      "Train Epoch: 5 [2560/5110 (50%)]\tLoss: 0.358005\n",
      "Train Epoch: 5 [3200/5110 (62%)]\tLoss: 0.284713\n",
      "Train Epoch: 5 [3840/5110 (75%)]\tLoss: 0.305547\n",
      "Train Epoch: 5 [4480/5110 (88%)]\tLoss: 0.572193\n",
      "Train Epoch: 6 [0/5110 (0%)]\tLoss: 0.230867\n",
      "Train Epoch: 6 [640/5110 (12%)]\tLoss: 0.282951\n",
      "Train Epoch: 6 [1280/5110 (25%)]\tLoss: 0.301783\n",
      "Train Epoch: 6 [1920/5110 (38%)]\tLoss: 0.215909\n",
      "Train Epoch: 6 [2560/5110 (50%)]\tLoss: 0.313406\n",
      "Train Epoch: 6 [3200/5110 (62%)]\tLoss: 0.229689\n",
      "Train Epoch: 6 [3840/5110 (75%)]\tLoss: 0.278289\n",
      "Train Epoch: 6 [4480/5110 (88%)]\tLoss: 0.147601\n",
      "Train Epoch: 7 [0/5110 (0%)]\tLoss: 0.270997\n",
      "Train Epoch: 7 [640/5110 (12%)]\tLoss: 0.309477\n",
      "Train Epoch: 7 [1280/5110 (25%)]\tLoss: 0.247198\n",
      "Train Epoch: 7 [1920/5110 (38%)]\tLoss: 0.116427\n",
      "Train Epoch: 7 [2560/5110 (50%)]\tLoss: 0.324122\n",
      "Train Epoch: 7 [3200/5110 (62%)]\tLoss: 0.068756\n",
      "Train Epoch: 7 [3840/5110 (75%)]\tLoss: 0.212096\n",
      "Train Epoch: 7 [4480/5110 (88%)]\tLoss: 0.238195\n",
      "Train Epoch: 8 [0/5110 (0%)]\tLoss: 0.382846\n",
      "Train Epoch: 8 [640/5110 (12%)]\tLoss: 0.094065\n",
      "Train Epoch: 8 [1280/5110 (25%)]\tLoss: 0.253329\n",
      "Train Epoch: 8 [1920/5110 (38%)]\tLoss: 0.149074\n",
      "Train Epoch: 8 [2560/5110 (50%)]\tLoss: 0.123407\n",
      "Train Epoch: 8 [3200/5110 (62%)]\tLoss: 0.124642\n",
      "Train Epoch: 8 [3840/5110 (75%)]\tLoss: 0.336316\n",
      "Train Epoch: 8 [4480/5110 (88%)]\tLoss: 0.270512\n",
      "Train Epoch: 9 [0/5110 (0%)]\tLoss: 0.293258\n",
      "Train Epoch: 9 [640/5110 (12%)]\tLoss: 0.248427\n",
      "Train Epoch: 9 [1280/5110 (25%)]\tLoss: 0.332912\n",
      "Train Epoch: 9 [1920/5110 (38%)]\tLoss: 0.203808\n",
      "Train Epoch: 9 [2560/5110 (50%)]\tLoss: 0.223212\n",
      "Train Epoch: 9 [3200/5110 (62%)]\tLoss: 0.172642\n",
      "Train Epoch: 9 [3840/5110 (75%)]\tLoss: 0.171486\n",
      "Train Epoch: 9 [4480/5110 (88%)]\tLoss: 0.350365\n",
      "Train Epoch: 10 [0/5110 (0%)]\tLoss: 0.178099\n",
      "Train Epoch: 10 [640/5110 (12%)]\tLoss: 0.217079\n",
      "Train Epoch: 10 [1280/5110 (25%)]\tLoss: 0.206247\n",
      "Train Epoch: 10 [1920/5110 (38%)]\tLoss: 0.169686\n",
      "Train Epoch: 10 [2560/5110 (50%)]\tLoss: 0.157481\n",
      "Train Epoch: 10 [3200/5110 (62%)]\tLoss: 0.215559\n",
      "Train Epoch: 10 [3840/5110 (75%)]\tLoss: 0.144764\n",
      "Train Epoch: 10 [4480/5110 (88%)]\tLoss: 0.150556\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6766 (0%)]\tLoss: 2.291423\n",
      "Train Epoch: 1 [640/6766 (9%)]\tLoss: 1.963776\n",
      "Train Epoch: 1 [1280/6766 (19%)]\tLoss: 1.454110\n",
      "Train Epoch: 1 [1920/6766 (28%)]\tLoss: 1.204578\n",
      "Train Epoch: 1 [2560/6766 (38%)]\tLoss: 1.311723\n",
      "Train Epoch: 1 [3200/6766 (47%)]\tLoss: 1.292256\n",
      "Train Epoch: 1 [3840/6766 (57%)]\tLoss: 0.887666\n",
      "Train Epoch: 1 [4480/6766 (66%)]\tLoss: 0.967110\n",
      "Train Epoch: 1 [5120/6766 (75%)]\tLoss: 0.640643\n",
      "Train Epoch: 1 [5760/6766 (85%)]\tLoss: 0.535550\n",
      "Train Epoch: 1 [6400/6766 (94%)]\tLoss: 0.571377\n",
      "Train Epoch: 2 [0/6766 (0%)]\tLoss: 0.616529\n",
      "Train Epoch: 2 [640/6766 (9%)]\tLoss: 0.644134\n",
      "Train Epoch: 2 [1280/6766 (19%)]\tLoss: 0.529785\n",
      "Train Epoch: 2 [1920/6766 (28%)]\tLoss: 0.479789\n",
      "Train Epoch: 2 [2560/6766 (38%)]\tLoss: 0.362049\n",
      "Train Epoch: 2 [3200/6766 (47%)]\tLoss: 0.354540\n",
      "Train Epoch: 2 [3840/6766 (57%)]\tLoss: 0.526458\n",
      "Train Epoch: 2 [4480/6766 (66%)]\tLoss: 0.520014\n",
      "Train Epoch: 2 [5120/6766 (75%)]\tLoss: 0.423052\n",
      "Train Epoch: 2 [5760/6766 (85%)]\tLoss: 0.324795\n",
      "Train Epoch: 2 [6400/6766 (94%)]\tLoss: 0.272187\n",
      "Train Epoch: 3 [0/6766 (0%)]\tLoss: 0.363214\n",
      "Train Epoch: 3 [640/6766 (9%)]\tLoss: 0.578580\n",
      "Train Epoch: 3 [1280/6766 (19%)]\tLoss: 0.348724\n",
      "Train Epoch: 3 [1920/6766 (28%)]\tLoss: 0.208377\n",
      "Train Epoch: 3 [2560/6766 (38%)]\tLoss: 0.392523\n",
      "Train Epoch: 3 [3200/6766 (47%)]\tLoss: 0.329604\n",
      "Train Epoch: 3 [3840/6766 (57%)]\tLoss: 0.302210\n",
      "Train Epoch: 3 [4480/6766 (66%)]\tLoss: 0.167401\n",
      "Train Epoch: 3 [5120/6766 (75%)]\tLoss: 0.254236\n",
      "Train Epoch: 3 [5760/6766 (85%)]\tLoss: 0.279234\n",
      "Train Epoch: 3 [6400/6766 (94%)]\tLoss: 0.347610\n",
      "Train Epoch: 4 [0/6766 (0%)]\tLoss: 0.293563\n",
      "Train Epoch: 4 [640/6766 (9%)]\tLoss: 0.405697\n",
      "Train Epoch: 4 [1280/6766 (19%)]\tLoss: 0.157101\n",
      "Train Epoch: 4 [1920/6766 (28%)]\tLoss: 0.290567\n",
      "Train Epoch: 4 [2560/6766 (38%)]\tLoss: 0.418418\n",
      "Train Epoch: 4 [3200/6766 (47%)]\tLoss: 0.233088\n",
      "Train Epoch: 4 [3840/6766 (57%)]\tLoss: 0.172573\n",
      "Train Epoch: 4 [4480/6766 (66%)]\tLoss: 0.213753\n",
      "Train Epoch: 4 [5120/6766 (75%)]\tLoss: 0.191687\n",
      "Train Epoch: 4 [5760/6766 (85%)]\tLoss: 0.284110\n",
      "Train Epoch: 4 [6400/6766 (94%)]\tLoss: 0.053489\n",
      "Train Epoch: 5 [0/6766 (0%)]\tLoss: 0.389200\n",
      "Train Epoch: 5 [640/6766 (9%)]\tLoss: 0.192484\n",
      "Train Epoch: 5 [1280/6766 (19%)]\tLoss: 0.363368\n",
      "Train Epoch: 5 [1920/6766 (28%)]\tLoss: 0.268307\n",
      "Train Epoch: 5 [2560/6766 (38%)]\tLoss: 0.269634\n",
      "Train Epoch: 5 [3200/6766 (47%)]\tLoss: 0.162287\n",
      "Train Epoch: 5 [3840/6766 (57%)]\tLoss: 0.307262\n",
      "Train Epoch: 5 [4480/6766 (66%)]\tLoss: 0.278040\n",
      "Train Epoch: 5 [5120/6766 (75%)]\tLoss: 0.247445\n",
      "Train Epoch: 5 [5760/6766 (85%)]\tLoss: 0.181653\n",
      "Train Epoch: 5 [6400/6766 (94%)]\tLoss: 0.244971\n",
      "Train Epoch: 6 [0/6766 (0%)]\tLoss: 0.225603\n",
      "Train Epoch: 6 [640/6766 (9%)]\tLoss: 0.409652\n",
      "Train Epoch: 6 [1280/6766 (19%)]\tLoss: 0.284360\n",
      "Train Epoch: 6 [1920/6766 (28%)]\tLoss: 0.308484\n",
      "Train Epoch: 6 [2560/6766 (38%)]\tLoss: 0.092826\n",
      "Train Epoch: 6 [3200/6766 (47%)]\tLoss: 0.220483\n",
      "Train Epoch: 6 [3840/6766 (57%)]\tLoss: 0.409867\n",
      "Train Epoch: 6 [4480/6766 (66%)]\tLoss: 0.295871\n",
      "Train Epoch: 6 [5120/6766 (75%)]\tLoss: 0.112961\n",
      "Train Epoch: 6 [5760/6766 (85%)]\tLoss: 0.176814\n",
      "Train Epoch: 6 [6400/6766 (94%)]\tLoss: 0.245416\n",
      "Train Epoch: 7 [0/6766 (0%)]\tLoss: 0.268599\n",
      "Train Epoch: 7 [640/6766 (9%)]\tLoss: 0.193082\n",
      "Train Epoch: 7 [1280/6766 (19%)]\tLoss: 0.150372\n",
      "Train Epoch: 7 [1920/6766 (28%)]\tLoss: 0.067631\n",
      "Train Epoch: 7 [2560/6766 (38%)]\tLoss: 0.181988\n",
      "Train Epoch: 7 [3200/6766 (47%)]\tLoss: 0.150962\n",
      "Train Epoch: 7 [3840/6766 (57%)]\tLoss: 0.142899\n",
      "Train Epoch: 7 [4480/6766 (66%)]\tLoss: 0.172737\n",
      "Train Epoch: 7 [5120/6766 (75%)]\tLoss: 0.342253\n",
      "Train Epoch: 7 [5760/6766 (85%)]\tLoss: 0.247523\n",
      "Train Epoch: 7 [6400/6766 (94%)]\tLoss: 0.168295\n",
      "Train Epoch: 8 [0/6766 (0%)]\tLoss: 0.172867\n",
      "Train Epoch: 8 [640/6766 (9%)]\tLoss: 0.238709\n",
      "Train Epoch: 8 [1280/6766 (19%)]\tLoss: 0.093486\n",
      "Train Epoch: 8 [1920/6766 (28%)]\tLoss: 0.228015\n",
      "Train Epoch: 8 [2560/6766 (38%)]\tLoss: 0.118997\n",
      "Train Epoch: 8 [3200/6766 (47%)]\tLoss: 0.114348\n",
      "Train Epoch: 8 [3840/6766 (57%)]\tLoss: 0.117397\n",
      "Train Epoch: 8 [4480/6766 (66%)]\tLoss: 0.176185\n",
      "Train Epoch: 8 [5120/6766 (75%)]\tLoss: 0.290660\n",
      "Train Epoch: 8 [5760/6766 (85%)]\tLoss: 0.260505\n",
      "Train Epoch: 8 [6400/6766 (94%)]\tLoss: 0.276985\n",
      "Train Epoch: 9 [0/6766 (0%)]\tLoss: 0.161200\n",
      "Train Epoch: 9 [640/6766 (9%)]\tLoss: 0.126469\n",
      "Train Epoch: 9 [1280/6766 (19%)]\tLoss: 0.135947\n",
      "Train Epoch: 9 [1920/6766 (28%)]\tLoss: 0.138302\n",
      "Train Epoch: 9 [2560/6766 (38%)]\tLoss: 0.164759\n",
      "Train Epoch: 9 [3200/6766 (47%)]\tLoss: 0.210740\n",
      "Train Epoch: 9 [3840/6766 (57%)]\tLoss: 0.116105\n",
      "Train Epoch: 9 [4480/6766 (66%)]\tLoss: 0.286919\n",
      "Train Epoch: 9 [5120/6766 (75%)]\tLoss: 0.078655\n",
      "Train Epoch: 9 [5760/6766 (85%)]\tLoss: 0.187130\n",
      "Train Epoch: 9 [6400/6766 (94%)]\tLoss: 0.218178\n",
      "Train Epoch: 10 [0/6766 (0%)]\tLoss: 0.098905\n",
      "Train Epoch: 10 [640/6766 (9%)]\tLoss: 0.211701\n",
      "Train Epoch: 10 [1280/6766 (19%)]\tLoss: 0.284097\n",
      "Train Epoch: 10 [1920/6766 (28%)]\tLoss: 0.032633\n",
      "Train Epoch: 10 [2560/6766 (38%)]\tLoss: 0.198204\n",
      "Train Epoch: 10 [3200/6766 (47%)]\tLoss: 0.202819\n",
      "Train Epoch: 10 [3840/6766 (57%)]\tLoss: 0.094077\n",
      "Train Epoch: 10 [4480/6766 (66%)]\tLoss: 0.041453\n",
      "Train Epoch: 10 [5120/6766 (75%)]\tLoss: 0.094895\n",
      "Train Epoch: 10 [5760/6766 (85%)]\tLoss: 0.237483\n",
      "Train Epoch: 10 [6400/6766 (94%)]\tLoss: 0.194528\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 2.396685\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 2.191598\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 1.871532\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 1.533232\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 1.378071\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 1.107039\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 0.924214\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 0.937679\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 0.813267\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 0.833135\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 0.623463\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 0.581923\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 0.668843\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 0.554087\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 0.611629\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 0.505229\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 0.315149\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.465947\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.541485\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.519316\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.264560\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.369092\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.407394\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.487227\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.396797\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.356774\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.589861\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.404000\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.464717\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.290031\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.221685\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.304956\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.295189\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.258508\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.367514\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.310024\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.384707\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.343384\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.218070\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.260250\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.302058\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.381006\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.216020\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.225913\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.193899\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.227720\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.335754\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.320056\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.218650\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.181809\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.487804\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.315037\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.186160\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.396055\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.331002\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.192385\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.140808\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.473195\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.181084\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.161004\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.412729\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.211883\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.250618\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.323180\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.282861\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.349188\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.205761\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.303487\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.246179\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.274396\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.329974\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.180356\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.137387\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.124493\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.211249\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.217427\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.362414\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.475605\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.127403\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.383679\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.179807\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.180007\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.268839\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.138569\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.121676\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.168194\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.282983\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.166938\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.113250\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.277775\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.337834\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.172693\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.190356\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.135875\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.202901\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.280055\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.178883\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.302458\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.129078\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.163587\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.212886\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.210805\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.127059\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.293017\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.085783\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.238404\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.423360\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.129551\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.253537\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.107392\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.111636\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.256278\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.158200\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.126812\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.156219\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.342733\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.155465\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.169662\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.191136\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.150752\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.191647\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.141797\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.155908\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.091391\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.161871\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.111445\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.152623\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.097623\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.232648\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.189303\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.211337\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.148451\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.215745\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.149630\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.232272\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.186740\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.055649\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.059558\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.123514\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.136169\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.285968\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.293541\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.139250\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.023192\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.090773\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.216631\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.416419\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.102588\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.072417\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.256428\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.195565\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.144918\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.122502\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.227460\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.201675\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.071750\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.108943\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.122290\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.028109\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.142047\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/3910 (0%)]\tLoss: 2.305721\n",
      "Train Epoch: 1 [640/3910 (16%)]\tLoss: 1.851732\n",
      "Train Epoch: 1 [1280/3910 (32%)]\tLoss: 1.475290\n",
      "Train Epoch: 1 [1920/3910 (48%)]\tLoss: 1.264552\n",
      "Train Epoch: 1 [2560/3910 (65%)]\tLoss: 1.131463\n",
      "Train Epoch: 1 [3200/3910 (81%)]\tLoss: 1.128230\n",
      "Train Epoch: 1 [3840/3910 (97%)]\tLoss: 1.135405\n",
      "Train Epoch: 2 [0/3910 (0%)]\tLoss: 0.798518\n",
      "Train Epoch: 2 [640/3910 (16%)]\tLoss: 0.876057\n",
      "Train Epoch: 2 [1280/3910 (32%)]\tLoss: 1.071091\n",
      "Train Epoch: 2 [1920/3910 (48%)]\tLoss: 0.797550\n",
      "Train Epoch: 2 [2560/3910 (65%)]\tLoss: 0.771935\n",
      "Train Epoch: 2 [3200/3910 (81%)]\tLoss: 0.824229\n",
      "Train Epoch: 2 [3840/3910 (97%)]\tLoss: 0.518610\n",
      "Train Epoch: 3 [0/3910 (0%)]\tLoss: 0.589215\n",
      "Train Epoch: 3 [640/3910 (16%)]\tLoss: 0.664382\n",
      "Train Epoch: 3 [1280/3910 (32%)]\tLoss: 0.667763\n",
      "Train Epoch: 3 [1920/3910 (48%)]\tLoss: 0.686944\n",
      "Train Epoch: 3 [2560/3910 (65%)]\tLoss: 0.722088\n",
      "Train Epoch: 3 [3200/3910 (81%)]\tLoss: 0.434875\n",
      "Train Epoch: 3 [3840/3910 (97%)]\tLoss: 0.518895\n",
      "Train Epoch: 4 [0/3910 (0%)]\tLoss: 0.488811\n",
      "Train Epoch: 4 [640/3910 (16%)]\tLoss: 0.437180\n",
      "Train Epoch: 4 [1280/3910 (32%)]\tLoss: 0.348980\n",
      "Train Epoch: 4 [1920/3910 (48%)]\tLoss: 0.572130\n",
      "Train Epoch: 4 [2560/3910 (65%)]\tLoss: 0.473056\n",
      "Train Epoch: 4 [3200/3910 (81%)]\tLoss: 0.389567\n",
      "Train Epoch: 4 [3840/3910 (97%)]\tLoss: 0.258293\n",
      "Train Epoch: 5 [0/3910 (0%)]\tLoss: 0.383578\n",
      "Train Epoch: 5 [640/3910 (16%)]\tLoss: 0.276986\n",
      "Train Epoch: 5 [1280/3910 (32%)]\tLoss: 0.584178\n",
      "Train Epoch: 5 [1920/3910 (48%)]\tLoss: 0.267079\n",
      "Train Epoch: 5 [2560/3910 (65%)]\tLoss: 0.372731\n",
      "Train Epoch: 5 [3200/3910 (81%)]\tLoss: 0.599050\n",
      "Train Epoch: 5 [3840/3910 (97%)]\tLoss: 0.347936\n",
      "Train Epoch: 6 [0/3910 (0%)]\tLoss: 0.155579\n",
      "Train Epoch: 6 [640/3910 (16%)]\tLoss: 0.484087\n",
      "Train Epoch: 6 [1280/3910 (32%)]\tLoss: 0.284347\n",
      "Train Epoch: 6 [1920/3910 (48%)]\tLoss: 0.287831\n",
      "Train Epoch: 6 [2560/3910 (65%)]\tLoss: 0.467344\n",
      "Train Epoch: 6 [3200/3910 (81%)]\tLoss: 0.205882\n",
      "Train Epoch: 6 [3840/3910 (97%)]\tLoss: 0.461908\n",
      "Train Epoch: 7 [0/3910 (0%)]\tLoss: 0.519250\n",
      "Train Epoch: 7 [640/3910 (16%)]\tLoss: 0.201367\n",
      "Train Epoch: 7 [1280/3910 (32%)]\tLoss: 0.445394\n",
      "Train Epoch: 7 [1920/3910 (48%)]\tLoss: 0.537691\n",
      "Train Epoch: 7 [2560/3910 (65%)]\tLoss: 0.230452\n",
      "Train Epoch: 7 [3200/3910 (81%)]\tLoss: 0.181393\n",
      "Train Epoch: 7 [3840/3910 (97%)]\tLoss: 0.220197\n",
      "Train Epoch: 8 [0/3910 (0%)]\tLoss: 0.303797\n",
      "Train Epoch: 8 [640/3910 (16%)]\tLoss: 0.197950\n",
      "Train Epoch: 8 [1280/3910 (32%)]\tLoss: 0.471678\n",
      "Train Epoch: 8 [1920/3910 (48%)]\tLoss: 0.282724\n",
      "Train Epoch: 8 [2560/3910 (65%)]\tLoss: 0.291664\n",
      "Train Epoch: 8 [3200/3910 (81%)]\tLoss: 0.463208\n",
      "Train Epoch: 8 [3840/3910 (97%)]\tLoss: 0.123594\n",
      "Train Epoch: 9 [0/3910 (0%)]\tLoss: 0.410181\n",
      "Train Epoch: 9 [640/3910 (16%)]\tLoss: 0.223471\n",
      "Train Epoch: 9 [1280/3910 (32%)]\tLoss: 0.249714\n",
      "Train Epoch: 9 [1920/3910 (48%)]\tLoss: 0.264669\n",
      "Train Epoch: 9 [2560/3910 (65%)]\tLoss: 0.097702\n",
      "Train Epoch: 9 [3200/3910 (81%)]\tLoss: 0.124706\n",
      "Train Epoch: 9 [3840/3910 (97%)]\tLoss: 0.276285\n",
      "Train Epoch: 10 [0/3910 (0%)]\tLoss: 0.519564\n",
      "Train Epoch: 10 [640/3910 (16%)]\tLoss: 0.126531\n",
      "Train Epoch: 10 [1280/3910 (32%)]\tLoss: 0.287171\n",
      "Train Epoch: 10 [1920/3910 (48%)]\tLoss: 0.197765\n",
      "Train Epoch: 10 [2560/3910 (65%)]\tLoss: 0.346693\n",
      "Train Epoch: 10 [3200/3910 (81%)]\tLoss: 0.216245\n",
      "Train Epoch: 10 [3840/3910 (97%)]\tLoss: 0.273551\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 2.267978\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 1.896965\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 1.217396\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 1.102310\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 0.933104\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 0.646543\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 0.622128\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 0.615840\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 0.639485\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 0.458434\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.454448\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.505834\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 0.400246\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 0.588263\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 0.626235\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.564980\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.497959\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.308866\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.418675\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.461792\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.344727\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.346836\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.234253\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.496306\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.269854\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.209366\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.369651\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.466469\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.572019\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.428521\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.240082\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.222896\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.443885\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.230115\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.301818\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.362029\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.143712\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.196415\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.233684\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.582485\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.174195\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.587595\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.261723\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.198677\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.119872\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.332576\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.362411\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.168222\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.314240\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.356543\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.168245\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.153243\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.273603\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.355461\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.107994\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.269103\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.522402\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.200849\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.262509\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.551765\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.253960\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.129664\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.136955\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.207232\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.170377\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.182556\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.165892\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.106089\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.177269\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.285453\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.233505\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.176016\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.098476\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.250287\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.273441\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.039502\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.111394\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.047033\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.148748\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.071833\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.282256\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.135350\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.313901\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.309264\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.152784\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.201467\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.097037\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.152826\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.202059\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.110588\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.139605\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.224345\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.486027\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.152314\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.095286\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.126532\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.179126\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.174784\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.237934\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.147396\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.184881\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.231365\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.074037\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.100492\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.064063\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.112081\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.118950\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.114924\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.200390\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.119012\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.097383\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.157356\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.134654\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.133787\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.111151\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.407982\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.165864\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.083556\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.247594\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.270028\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/5096 (0%)]\tLoss: 2.221152\n",
      "Train Epoch: 1 [640/5096 (12%)]\tLoss: 1.219289\n",
      "Train Epoch: 1 [1280/5096 (25%)]\tLoss: 1.467605\n",
      "Train Epoch: 1 [1920/5096 (38%)]\tLoss: 1.194452\n",
      "Train Epoch: 1 [2560/5096 (50%)]\tLoss: 1.042989\n",
      "Train Epoch: 1 [3200/5096 (62%)]\tLoss: 0.829462\n",
      "Train Epoch: 1 [3840/5096 (75%)]\tLoss: 0.705878\n",
      "Train Epoch: 1 [4480/5096 (88%)]\tLoss: 0.617716\n",
      "Train Epoch: 2 [0/5096 (0%)]\tLoss: 0.719690\n",
      "Train Epoch: 2 [640/5096 (12%)]\tLoss: 0.468323\n",
      "Train Epoch: 2 [1280/5096 (25%)]\tLoss: 0.527609\n",
      "Train Epoch: 2 [1920/5096 (38%)]\tLoss: 0.687786\n",
      "Train Epoch: 2 [2560/5096 (50%)]\tLoss: 0.411494\n",
      "Train Epoch: 2 [3200/5096 (62%)]\tLoss: 0.394900\n",
      "Train Epoch: 2 [3840/5096 (75%)]\tLoss: 0.460162\n",
      "Train Epoch: 2 [4480/5096 (88%)]\tLoss: 0.550521\n",
      "Train Epoch: 3 [0/5096 (0%)]\tLoss: 0.609850\n",
      "Train Epoch: 3 [640/5096 (12%)]\tLoss: 0.483999\n",
      "Train Epoch: 3 [1280/5096 (25%)]\tLoss: 0.476365\n",
      "Train Epoch: 3 [1920/5096 (38%)]\tLoss: 0.514579\n",
      "Train Epoch: 3 [2560/5096 (50%)]\tLoss: 0.376119\n",
      "Train Epoch: 3 [3200/5096 (62%)]\tLoss: 0.351308\n",
      "Train Epoch: 3 [3840/5096 (75%)]\tLoss: 0.307416\n",
      "Train Epoch: 3 [4480/5096 (88%)]\tLoss: 0.371725\n",
      "Train Epoch: 4 [0/5096 (0%)]\tLoss: 0.417768\n",
      "Train Epoch: 4 [640/5096 (12%)]\tLoss: 0.251016\n",
      "Train Epoch: 4 [1280/5096 (25%)]\tLoss: 0.343960\n",
      "Train Epoch: 4 [1920/5096 (38%)]\tLoss: 0.484266\n",
      "Train Epoch: 4 [2560/5096 (50%)]\tLoss: 0.472170\n",
      "Train Epoch: 4 [3200/5096 (62%)]\tLoss: 0.182675\n",
      "Train Epoch: 4 [3840/5096 (75%)]\tLoss: 0.254650\n",
      "Train Epoch: 4 [4480/5096 (88%)]\tLoss: 0.307869\n",
      "Train Epoch: 5 [0/5096 (0%)]\tLoss: 0.345348\n",
      "Train Epoch: 5 [640/5096 (12%)]\tLoss: 0.192234\n",
      "Train Epoch: 5 [1280/5096 (25%)]\tLoss: 0.161234\n",
      "Train Epoch: 5 [1920/5096 (38%)]\tLoss: 0.422113\n",
      "Train Epoch: 5 [2560/5096 (50%)]\tLoss: 0.251901\n",
      "Train Epoch: 5 [3200/5096 (62%)]\tLoss: 0.190666\n",
      "Train Epoch: 5 [3840/5096 (75%)]\tLoss: 0.279321\n",
      "Train Epoch: 5 [4480/5096 (88%)]\tLoss: 0.228054\n",
      "Train Epoch: 6 [0/5096 (0%)]\tLoss: 0.152584\n",
      "Train Epoch: 6 [640/5096 (12%)]\tLoss: 0.425557\n",
      "Train Epoch: 6 [1280/5096 (25%)]\tLoss: 0.165508\n",
      "Train Epoch: 6 [1920/5096 (38%)]\tLoss: 0.201070\n",
      "Train Epoch: 6 [2560/5096 (50%)]\tLoss: 0.243378\n",
      "Train Epoch: 6 [3200/5096 (62%)]\tLoss: 0.279190\n",
      "Train Epoch: 6 [3840/5096 (75%)]\tLoss: 0.214965\n",
      "Train Epoch: 6 [4480/5096 (88%)]\tLoss: 0.237347\n",
      "Train Epoch: 7 [0/5096 (0%)]\tLoss: 0.122404\n",
      "Train Epoch: 7 [640/5096 (12%)]\tLoss: 0.131997\n",
      "Train Epoch: 7 [1280/5096 (25%)]\tLoss: 0.092180\n",
      "Train Epoch: 7 [1920/5096 (38%)]\tLoss: 0.310878\n",
      "Train Epoch: 7 [2560/5096 (50%)]\tLoss: 0.222976\n",
      "Train Epoch: 7 [3200/5096 (62%)]\tLoss: 0.723391\n",
      "Train Epoch: 7 [3840/5096 (75%)]\tLoss: 0.195770\n",
      "Train Epoch: 7 [4480/5096 (88%)]\tLoss: 0.265516\n",
      "Train Epoch: 8 [0/5096 (0%)]\tLoss: 0.134982\n",
      "Train Epoch: 8 [640/5096 (12%)]\tLoss: 0.089284\n",
      "Train Epoch: 8 [1280/5096 (25%)]\tLoss: 0.209530\n",
      "Train Epoch: 8 [1920/5096 (38%)]\tLoss: 0.181151\n",
      "Train Epoch: 8 [2560/5096 (50%)]\tLoss: 0.145803\n",
      "Train Epoch: 8 [3200/5096 (62%)]\tLoss: 0.120591\n",
      "Train Epoch: 8 [3840/5096 (75%)]\tLoss: 0.177643\n",
      "Train Epoch: 8 [4480/5096 (88%)]\tLoss: 0.150127\n",
      "Train Epoch: 9 [0/5096 (0%)]\tLoss: 0.212888\n",
      "Train Epoch: 9 [640/5096 (12%)]\tLoss: 0.046906\n",
      "Train Epoch: 9 [1280/5096 (25%)]\tLoss: 0.082952\n",
      "Train Epoch: 9 [1920/5096 (38%)]\tLoss: 0.442263\n",
      "Train Epoch: 9 [2560/5096 (50%)]\tLoss: 0.094643\n",
      "Train Epoch: 9 [3200/5096 (62%)]\tLoss: 0.057574\n",
      "Train Epoch: 9 [3840/5096 (75%)]\tLoss: 0.130068\n",
      "Train Epoch: 9 [4480/5096 (88%)]\tLoss: 0.391767\n",
      "Train Epoch: 10 [0/5096 (0%)]\tLoss: 0.245982\n",
      "Train Epoch: 10 [640/5096 (12%)]\tLoss: 0.127334\n",
      "Train Epoch: 10 [1280/5096 (25%)]\tLoss: 0.234477\n",
      "Train Epoch: 10 [1920/5096 (38%)]\tLoss: 0.142125\n",
      "Train Epoch: 10 [2560/5096 (50%)]\tLoss: 0.087712\n",
      "Train Epoch: 10 [3200/5096 (62%)]\tLoss: 0.161719\n",
      "Train Epoch: 10 [3840/5096 (75%)]\tLoss: 0.231309\n",
      "Train Epoch: 10 [4480/5096 (88%)]\tLoss: 0.220964\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/1599 (0%)]\tLoss: 2.315778\n",
      "Train Epoch: 1 [640/1599 (40%)]\tLoss: 1.814475\n",
      "Train Epoch: 1 [1280/1599 (80%)]\tLoss: 1.449342\n",
      "Train Epoch: 2 [0/1599 (0%)]\tLoss: 1.598105\n",
      "Train Epoch: 2 [640/1599 (40%)]\tLoss: 1.096791\n",
      "Train Epoch: 2 [1280/1599 (80%)]\tLoss: 1.218302\n",
      "Train Epoch: 3 [0/1599 (0%)]\tLoss: 1.050366\n",
      "Train Epoch: 3 [640/1599 (40%)]\tLoss: 1.279666\n",
      "Train Epoch: 3 [1280/1599 (80%)]\tLoss: 0.907855\n",
      "Train Epoch: 4 [0/1599 (0%)]\tLoss: 0.921762\n",
      "Train Epoch: 4 [640/1599 (40%)]\tLoss: 0.790193\n",
      "Train Epoch: 4 [1280/1599 (80%)]\tLoss: 0.720873\n",
      "Train Epoch: 5 [0/1599 (0%)]\tLoss: 0.708311\n",
      "Train Epoch: 5 [640/1599 (40%)]\tLoss: 0.745522\n",
      "Train Epoch: 5 [1280/1599 (80%)]\tLoss: 0.626220\n",
      "Train Epoch: 6 [0/1599 (0%)]\tLoss: 0.500706\n",
      "Train Epoch: 6 [640/1599 (40%)]\tLoss: 0.878577\n",
      "Train Epoch: 6 [1280/1599 (80%)]\tLoss: 0.604511\n",
      "Train Epoch: 7 [0/1599 (0%)]\tLoss: 0.683397\n",
      "Train Epoch: 7 [640/1599 (40%)]\tLoss: 0.561494\n",
      "Train Epoch: 7 [1280/1599 (80%)]\tLoss: 0.534260\n",
      "Train Epoch: 8 [0/1599 (0%)]\tLoss: 0.533216\n",
      "Train Epoch: 8 [640/1599 (40%)]\tLoss: 0.623411\n",
      "Train Epoch: 8 [1280/1599 (80%)]\tLoss: 0.337745\n",
      "Train Epoch: 9 [0/1599 (0%)]\tLoss: 0.423545\n",
      "Train Epoch: 9 [640/1599 (40%)]\tLoss: 0.716807\n",
      "Train Epoch: 9 [1280/1599 (80%)]\tLoss: 0.451925\n",
      "Train Epoch: 10 [0/1599 (0%)]\tLoss: 0.283733\n",
      "Train Epoch: 10 [640/1599 (40%)]\tLoss: 0.558572\n",
      "Train Epoch: 10 [1280/1599 (80%)]\tLoss: 0.338297\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/5266 (0%)]\tLoss: 2.319263\n",
      "Train Epoch: 1 [640/5266 (12%)]\tLoss: 0.876238\n",
      "Train Epoch: 1 [1280/5266 (24%)]\tLoss: 1.036763\n",
      "Train Epoch: 1 [1920/5266 (36%)]\tLoss: 0.756025\n",
      "Train Epoch: 1 [2560/5266 (48%)]\tLoss: 0.772534\n",
      "Train Epoch: 1 [3200/5266 (60%)]\tLoss: 0.407487\n",
      "Train Epoch: 1 [3840/5266 (72%)]\tLoss: 0.471584\n",
      "Train Epoch: 1 [4480/5266 (84%)]\tLoss: 0.230657\n",
      "Train Epoch: 1 [5120/5266 (96%)]\tLoss: 0.489576\n",
      "Train Epoch: 2 [0/5266 (0%)]\tLoss: 0.711522\n",
      "Train Epoch: 2 [640/5266 (12%)]\tLoss: 0.338943\n",
      "Train Epoch: 2 [1280/5266 (24%)]\tLoss: 0.400279\n",
      "Train Epoch: 2 [1920/5266 (36%)]\tLoss: 0.295451\n",
      "Train Epoch: 2 [2560/5266 (48%)]\tLoss: 0.301479\n",
      "Train Epoch: 2 [3200/5266 (60%)]\tLoss: 0.103860\n",
      "Train Epoch: 2 [3840/5266 (72%)]\tLoss: 0.175066\n",
      "Train Epoch: 2 [4480/5266 (84%)]\tLoss: 0.205923\n",
      "Train Epoch: 2 [5120/5266 (96%)]\tLoss: 0.365475\n",
      "Train Epoch: 3 [0/5266 (0%)]\tLoss: 0.373873\n",
      "Train Epoch: 3 [640/5266 (12%)]\tLoss: 0.227924\n",
      "Train Epoch: 3 [1280/5266 (24%)]\tLoss: 0.206047\n",
      "Train Epoch: 3 [1920/5266 (36%)]\tLoss: 0.229972\n",
      "Train Epoch: 3 [2560/5266 (48%)]\tLoss: 0.155292\n",
      "Train Epoch: 3 [3200/5266 (60%)]\tLoss: 0.364486\n",
      "Train Epoch: 3 [3840/5266 (72%)]\tLoss: 0.142579\n",
      "Train Epoch: 3 [4480/5266 (84%)]\tLoss: 0.193879\n",
      "Train Epoch: 3 [5120/5266 (96%)]\tLoss: 0.125806\n",
      "Train Epoch: 4 [0/5266 (0%)]\tLoss: 0.118288\n",
      "Train Epoch: 4 [640/5266 (12%)]\tLoss: 0.174362\n",
      "Train Epoch: 4 [1280/5266 (24%)]\tLoss: 0.240410\n",
      "Train Epoch: 4 [1920/5266 (36%)]\tLoss: 0.457286\n",
      "Train Epoch: 4 [2560/5266 (48%)]\tLoss: 0.190334\n",
      "Train Epoch: 4 [3200/5266 (60%)]\tLoss: 0.318164\n",
      "Train Epoch: 4 [3840/5266 (72%)]\tLoss: 0.242142\n",
      "Train Epoch: 4 [4480/5266 (84%)]\tLoss: 0.170151\n",
      "Train Epoch: 4 [5120/5266 (96%)]\tLoss: 0.116732\n",
      "Train Epoch: 5 [0/5266 (0%)]\tLoss: 0.117168\n",
      "Train Epoch: 5 [640/5266 (12%)]\tLoss: 0.331664\n",
      "Train Epoch: 5 [1280/5266 (24%)]\tLoss: 0.220066\n",
      "Train Epoch: 5 [1920/5266 (36%)]\tLoss: 0.196158\n",
      "Train Epoch: 5 [2560/5266 (48%)]\tLoss: 0.211257\n",
      "Train Epoch: 5 [3200/5266 (60%)]\tLoss: 0.109427\n",
      "Train Epoch: 5 [3840/5266 (72%)]\tLoss: 0.229502\n",
      "Train Epoch: 5 [4480/5266 (84%)]\tLoss: 0.303807\n",
      "Train Epoch: 5 [5120/5266 (96%)]\tLoss: 0.373760\n",
      "Train Epoch: 6 [0/5266 (0%)]\tLoss: 0.185851\n",
      "Train Epoch: 6 [640/5266 (12%)]\tLoss: 0.301824\n",
      "Train Epoch: 6 [1280/5266 (24%)]\tLoss: 0.169768\n",
      "Train Epoch: 6 [1920/5266 (36%)]\tLoss: 0.362754\n",
      "Train Epoch: 6 [2560/5266 (48%)]\tLoss: 0.164310\n",
      "Train Epoch: 6 [3200/5266 (60%)]\tLoss: 0.096210\n",
      "Train Epoch: 6 [3840/5266 (72%)]\tLoss: 0.252957\n",
      "Train Epoch: 6 [4480/5266 (84%)]\tLoss: 0.102108\n",
      "Train Epoch: 6 [5120/5266 (96%)]\tLoss: 0.124869\n",
      "Train Epoch: 7 [0/5266 (0%)]\tLoss: 0.209573\n",
      "Train Epoch: 7 [640/5266 (12%)]\tLoss: 0.241731\n",
      "Train Epoch: 7 [1280/5266 (24%)]\tLoss: 0.387340\n",
      "Train Epoch: 7 [1920/5266 (36%)]\tLoss: 0.313621\n",
      "Train Epoch: 7 [2560/5266 (48%)]\tLoss: 0.226342\n",
      "Train Epoch: 7 [3200/5266 (60%)]\tLoss: 0.110432\n",
      "Train Epoch: 7 [3840/5266 (72%)]\tLoss: 0.048519\n",
      "Train Epoch: 7 [4480/5266 (84%)]\tLoss: 0.210072\n",
      "Train Epoch: 7 [5120/5266 (96%)]\tLoss: 0.200735\n",
      "Train Epoch: 8 [0/5266 (0%)]\tLoss: 0.079434\n",
      "Train Epoch: 8 [640/5266 (12%)]\tLoss: 0.091308\n",
      "Train Epoch: 8 [1280/5266 (24%)]\tLoss: 0.114300\n",
      "Train Epoch: 8 [1920/5266 (36%)]\tLoss: 0.108159\n",
      "Train Epoch: 8 [2560/5266 (48%)]\tLoss: 0.107355\n",
      "Train Epoch: 8 [3200/5266 (60%)]\tLoss: 0.127200\n",
      "Train Epoch: 8 [3840/5266 (72%)]\tLoss: 0.151492\n",
      "Train Epoch: 8 [4480/5266 (84%)]\tLoss: 0.128956\n",
      "Train Epoch: 8 [5120/5266 (96%)]\tLoss: 0.157205\n",
      "Train Epoch: 9 [0/5266 (0%)]\tLoss: 0.290237\n",
      "Train Epoch: 9 [640/5266 (12%)]\tLoss: 0.278993\n",
      "Train Epoch: 9 [1280/5266 (24%)]\tLoss: 0.059675\n",
      "Train Epoch: 9 [1920/5266 (36%)]\tLoss: 0.206811\n",
      "Train Epoch: 9 [2560/5266 (48%)]\tLoss: 0.135214\n",
      "Train Epoch: 9 [3200/5266 (60%)]\tLoss: 0.116525\n",
      "Train Epoch: 9 [3840/5266 (72%)]\tLoss: 0.017724\n",
      "Train Epoch: 9 [4480/5266 (84%)]\tLoss: 0.288118\n",
      "Train Epoch: 9 [5120/5266 (96%)]\tLoss: 0.083469\n",
      "Train Epoch: 10 [0/5266 (0%)]\tLoss: 0.134201\n",
      "Train Epoch: 10 [640/5266 (12%)]\tLoss: 0.203347\n",
      "Train Epoch: 10 [1280/5266 (24%)]\tLoss: 0.118314\n",
      "Train Epoch: 10 [1920/5266 (36%)]\tLoss: 0.149105\n",
      "Train Epoch: 10 [2560/5266 (48%)]\tLoss: 0.110776\n",
      "Train Epoch: 10 [3200/5266 (60%)]\tLoss: 0.313759\n",
      "Train Epoch: 10 [3840/5266 (72%)]\tLoss: 0.171074\n",
      "Train Epoch: 10 [4480/5266 (84%)]\tLoss: 0.125459\n",
      "Train Epoch: 10 [5120/5266 (96%)]\tLoss: 0.211995\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/3530 (0%)]\tLoss: 2.288764\n",
      "Train Epoch: 1 [640/3530 (18%)]\tLoss: 1.974333\n",
      "Train Epoch: 1 [1280/3530 (36%)]\tLoss: 1.660011\n",
      "Train Epoch: 1 [1920/3530 (54%)]\tLoss: 1.272829\n",
      "Train Epoch: 1 [2560/3530 (71%)]\tLoss: 1.160430\n",
      "Train Epoch: 1 [3200/3530 (89%)]\tLoss: 1.094401\n",
      "Train Epoch: 2 [0/3530 (0%)]\tLoss: 1.020098\n",
      "Train Epoch: 2 [640/3530 (18%)]\tLoss: 0.599532\n",
      "Train Epoch: 2 [1280/3530 (36%)]\tLoss: 0.627999\n",
      "Train Epoch: 2 [1920/3530 (54%)]\tLoss: 0.565933\n",
      "Train Epoch: 2 [2560/3530 (71%)]\tLoss: 0.602237\n",
      "Train Epoch: 2 [3200/3530 (89%)]\tLoss: 0.537636\n",
      "Train Epoch: 3 [0/3530 (0%)]\tLoss: 0.441362\n",
      "Train Epoch: 3 [640/3530 (18%)]\tLoss: 0.566067\n",
      "Train Epoch: 3 [1280/3530 (36%)]\tLoss: 0.350834\n",
      "Train Epoch: 3 [1920/3530 (54%)]\tLoss: 0.440127\n",
      "Train Epoch: 3 [2560/3530 (71%)]\tLoss: 0.534989\n",
      "Train Epoch: 3 [3200/3530 (89%)]\tLoss: 0.304998\n",
      "Train Epoch: 4 [0/3530 (0%)]\tLoss: 0.682249\n",
      "Train Epoch: 4 [640/3530 (18%)]\tLoss: 0.819808\n",
      "Train Epoch: 4 [1280/3530 (36%)]\tLoss: 0.655797\n",
      "Train Epoch: 4 [1920/3530 (54%)]\tLoss: 0.366576\n",
      "Train Epoch: 4 [2560/3530 (71%)]\tLoss: 0.337146\n",
      "Train Epoch: 4 [3200/3530 (89%)]\tLoss: 0.309041\n",
      "Train Epoch: 5 [0/3530 (0%)]\tLoss: 0.622497\n",
      "Train Epoch: 5 [640/3530 (18%)]\tLoss: 0.430753\n",
      "Train Epoch: 5 [1280/3530 (36%)]\tLoss: 0.417896\n",
      "Train Epoch: 5 [1920/3530 (54%)]\tLoss: 0.429507\n",
      "Train Epoch: 5 [2560/3530 (71%)]\tLoss: 0.485654\n",
      "Train Epoch: 5 [3200/3530 (89%)]\tLoss: 0.538789\n",
      "Train Epoch: 6 [0/3530 (0%)]\tLoss: 0.219069\n",
      "Train Epoch: 6 [640/3530 (18%)]\tLoss: 0.408624\n",
      "Train Epoch: 6 [1280/3530 (36%)]\tLoss: 0.286596\n",
      "Train Epoch: 6 [1920/3530 (54%)]\tLoss: 0.365445\n",
      "Train Epoch: 6 [2560/3530 (71%)]\tLoss: 0.534564\n",
      "Train Epoch: 6 [3200/3530 (89%)]\tLoss: 0.563194\n",
      "Train Epoch: 7 [0/3530 (0%)]\tLoss: 0.560868\n",
      "Train Epoch: 7 [640/3530 (18%)]\tLoss: 0.420804\n",
      "Train Epoch: 7 [1280/3530 (36%)]\tLoss: 0.264023\n",
      "Train Epoch: 7 [1920/3530 (54%)]\tLoss: 0.231892\n",
      "Train Epoch: 7 [2560/3530 (71%)]\tLoss: 0.145212\n",
      "Train Epoch: 7 [3200/3530 (89%)]\tLoss: 0.409150\n",
      "Train Epoch: 8 [0/3530 (0%)]\tLoss: 0.547251\n",
      "Train Epoch: 8 [640/3530 (18%)]\tLoss: 0.422985\n",
      "Train Epoch: 8 [1280/3530 (36%)]\tLoss: 0.296115\n",
      "Train Epoch: 8 [1920/3530 (54%)]\tLoss: 0.112755\n",
      "Train Epoch: 8 [2560/3530 (71%)]\tLoss: 0.277854\n",
      "Train Epoch: 8 [3200/3530 (89%)]\tLoss: 0.131514\n",
      "Train Epoch: 9 [0/3530 (0%)]\tLoss: 0.395050\n",
      "Train Epoch: 9 [640/3530 (18%)]\tLoss: 0.157723\n",
      "Train Epoch: 9 [1280/3530 (36%)]\tLoss: 0.257539\n",
      "Train Epoch: 9 [1920/3530 (54%)]\tLoss: 0.216336\n",
      "Train Epoch: 9 [2560/3530 (71%)]\tLoss: 0.245656\n",
      "Train Epoch: 9 [3200/3530 (89%)]\tLoss: 0.250500\n",
      "Train Epoch: 10 [0/3530 (0%)]\tLoss: 0.149463\n",
      "Train Epoch: 10 [640/3530 (18%)]\tLoss: 0.381775\n",
      "Train Epoch: 10 [1280/3530 (36%)]\tLoss: 0.374306\n",
      "Train Epoch: 10 [1920/3530 (54%)]\tLoss: 0.374938\n",
      "Train Epoch: 10 [2560/3530 (71%)]\tLoss: 0.177928\n",
      "Train Epoch: 10 [3200/3530 (89%)]\tLoss: 0.164165\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 1.8914, Accuracy: 7973/10000 (80%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 1.389173\n",
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 0.873566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 0.623142\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 0.518079\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 0.442181\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 0.358233\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 0.532897\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 0.555550\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 0.387432\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 0.452258\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 0.385345\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 0.270192\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 0.283214\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 0.514941\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 0.268585\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 0.502574\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 0.241033\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 0.209158\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 0.430082\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 0.263089\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.269706\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 0.256210\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 0.226821\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.455815\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.288656\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 0.179359\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.265707\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 0.425994\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.158133\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.342348\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.147583\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.199900\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.312293\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.268938\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.277278\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.203529\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.279516\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.211500\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.161797\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.216780\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.125114\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.237851\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.151856\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.193780\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.175480\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.173207\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.113128\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.245440\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.271735\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.227925\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.098677\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.383778\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.240805\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.439549\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.131402\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.545392\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.191474\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.245256\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.219494\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.153906\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.057013\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.178675\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.148284\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.154005\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.180793\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.178692\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.376915\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.193721\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.120835\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.392702\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.232989\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.172675\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.206306\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.183416\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.148939\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.167948\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.112082\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.334431\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.199825\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.204237\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.143457\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.174104\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.116056\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.140045\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.233151\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.175831\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.057739\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.221379\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.249983\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.154044\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.901006\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.178129\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.385512\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.211598\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.306392\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.371920\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.279210\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.133371\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.163846\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.646714\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.103848\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.142356\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.214320\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.122955\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.219586\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.310481\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.374444\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.132713\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 0.277071\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.145774\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.213349\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.202411\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.210860\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.330538\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.138901\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.248540\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.131222\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.386559\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.242738\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.178338\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.228482\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.361175\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.202969\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.209645\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.176957\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.139888\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.339254\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.176498\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.203495\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.240034\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.183860\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.105252\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.136385\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.407415\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.203055\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.133138\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.352698\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.087009\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.172438\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.246397\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.225260\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.153512\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.123817\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.139592\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.212915\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.123319\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.051613\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.042764\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.251246\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.086705\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.243659\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.094379\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.313397\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.141998\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.231653\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.245529\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.243022\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.253679\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.183828\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.093603\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.306997\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.227469\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.137498\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.287074\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.126586\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.301956\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.103113\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.050039\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.025945\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.246115\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.115751\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.131977\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.043736\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.113159\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.250850\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.085480\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.112295\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.124264\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.077046\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.136421\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/5110 (0%)]\tLoss: 1.251334\n",
      "Train Epoch: 1 [640/5110 (12%)]\tLoss: 0.816744\n",
      "Train Epoch: 1 [1280/5110 (25%)]\tLoss: 0.515770\n",
      "Train Epoch: 1 [1920/5110 (38%)]\tLoss: 0.680772\n",
      "Train Epoch: 1 [2560/5110 (50%)]\tLoss: 0.469906\n",
      "Train Epoch: 1 [3200/5110 (62%)]\tLoss: 0.491543\n",
      "Train Epoch: 1 [3840/5110 (75%)]\tLoss: 0.499276\n",
      "Train Epoch: 1 [4480/5110 (88%)]\tLoss: 0.382126\n",
      "Train Epoch: 2 [0/5110 (0%)]\tLoss: 0.405209\n",
      "Train Epoch: 2 [640/5110 (12%)]\tLoss: 0.226590\n",
      "Train Epoch: 2 [1280/5110 (25%)]\tLoss: 0.373318\n",
      "Train Epoch: 2 [1920/5110 (38%)]\tLoss: 0.427521\n",
      "Train Epoch: 2 [2560/5110 (50%)]\tLoss: 0.371916\n",
      "Train Epoch: 2 [3200/5110 (62%)]\tLoss: 0.259199\n",
      "Train Epoch: 2 [3840/5110 (75%)]\tLoss: 0.198682\n",
      "Train Epoch: 2 [4480/5110 (88%)]\tLoss: 0.253666\n",
      "Train Epoch: 3 [0/5110 (0%)]\tLoss: 0.303436\n",
      "Train Epoch: 3 [640/5110 (12%)]\tLoss: 0.151823\n",
      "Train Epoch: 3 [1280/5110 (25%)]\tLoss: 0.186373\n",
      "Train Epoch: 3 [1920/5110 (38%)]\tLoss: 0.289636\n",
      "Train Epoch: 3 [2560/5110 (50%)]\tLoss: 0.232719\n",
      "Train Epoch: 3 [3200/5110 (62%)]\tLoss: 0.185748\n",
      "Train Epoch: 3 [3840/5110 (75%)]\tLoss: 0.180564\n",
      "Train Epoch: 3 [4480/5110 (88%)]\tLoss: 0.223849\n",
      "Train Epoch: 4 [0/5110 (0%)]\tLoss: 0.147779\n",
      "Train Epoch: 4 [640/5110 (12%)]\tLoss: 0.243189\n",
      "Train Epoch: 4 [1280/5110 (25%)]\tLoss: 0.263930\n",
      "Train Epoch: 4 [1920/5110 (38%)]\tLoss: 0.270537\n",
      "Train Epoch: 4 [2560/5110 (50%)]\tLoss: 0.394969\n",
      "Train Epoch: 4 [3200/5110 (62%)]\tLoss: 0.322185\n",
      "Train Epoch: 4 [3840/5110 (75%)]\tLoss: 0.131036\n",
      "Train Epoch: 4 [4480/5110 (88%)]\tLoss: 0.289877\n",
      "Train Epoch: 5 [0/5110 (0%)]\tLoss: 0.279492\n",
      "Train Epoch: 5 [640/5110 (12%)]\tLoss: 0.127167\n",
      "Train Epoch: 5 [1280/5110 (25%)]\tLoss: 0.365092\n",
      "Train Epoch: 5 [1920/5110 (38%)]\tLoss: 0.131020\n",
      "Train Epoch: 5 [2560/5110 (50%)]\tLoss: 0.215560\n",
      "Train Epoch: 5 [3200/5110 (62%)]\tLoss: 0.183559\n",
      "Train Epoch: 5 [3840/5110 (75%)]\tLoss: 0.228075\n",
      "Train Epoch: 5 [4480/5110 (88%)]\tLoss: 0.235916\n",
      "Train Epoch: 6 [0/5110 (0%)]\tLoss: 0.142396\n",
      "Train Epoch: 6 [640/5110 (12%)]\tLoss: 0.216406\n",
      "Train Epoch: 6 [1280/5110 (25%)]\tLoss: 0.108852\n",
      "Train Epoch: 6 [1920/5110 (38%)]\tLoss: 0.133340\n",
      "Train Epoch: 6 [2560/5110 (50%)]\tLoss: 0.235991\n",
      "Train Epoch: 6 [3200/5110 (62%)]\tLoss: 0.434051\n",
      "Train Epoch: 6 [3840/5110 (75%)]\tLoss: 0.291171\n",
      "Train Epoch: 6 [4480/5110 (88%)]\tLoss: 0.100964\n",
      "Train Epoch: 7 [0/5110 (0%)]\tLoss: 0.124495\n",
      "Train Epoch: 7 [640/5110 (12%)]\tLoss: 0.131974\n",
      "Train Epoch: 7 [1280/5110 (25%)]\tLoss: 0.248903\n",
      "Train Epoch: 7 [1920/5110 (38%)]\tLoss: 0.125407\n",
      "Train Epoch: 7 [2560/5110 (50%)]\tLoss: 0.202508\n",
      "Train Epoch: 7 [3200/5110 (62%)]\tLoss: 0.205714\n",
      "Train Epoch: 7 [3840/5110 (75%)]\tLoss: 0.194412\n",
      "Train Epoch: 7 [4480/5110 (88%)]\tLoss: 0.322121\n",
      "Train Epoch: 8 [0/5110 (0%)]\tLoss: 0.252710\n",
      "Train Epoch: 8 [640/5110 (12%)]\tLoss: 0.085974\n",
      "Train Epoch: 8 [1280/5110 (25%)]\tLoss: 0.136229\n",
      "Train Epoch: 8 [1920/5110 (38%)]\tLoss: 0.113933\n",
      "Train Epoch: 8 [2560/5110 (50%)]\tLoss: 0.112080\n",
      "Train Epoch: 8 [3200/5110 (62%)]\tLoss: 0.123613\n",
      "Train Epoch: 8 [3840/5110 (75%)]\tLoss: 0.183941\n",
      "Train Epoch: 8 [4480/5110 (88%)]\tLoss: 0.093580\n",
      "Train Epoch: 9 [0/5110 (0%)]\tLoss: 0.086814\n",
      "Train Epoch: 9 [640/5110 (12%)]\tLoss: 0.169651\n",
      "Train Epoch: 9 [1280/5110 (25%)]\tLoss: 0.128806\n",
      "Train Epoch: 9 [1920/5110 (38%)]\tLoss: 0.361049\n",
      "Train Epoch: 9 [2560/5110 (50%)]\tLoss: 0.110748\n",
      "Train Epoch: 9 [3200/5110 (62%)]\tLoss: 0.224232\n",
      "Train Epoch: 9 [3840/5110 (75%)]\tLoss: 0.058199\n",
      "Train Epoch: 9 [4480/5110 (88%)]\tLoss: 0.194663\n",
      "Train Epoch: 10 [0/5110 (0%)]\tLoss: 0.086631\n",
      "Train Epoch: 10 [640/5110 (12%)]\tLoss: 0.136170\n",
      "Train Epoch: 10 [1280/5110 (25%)]\tLoss: 0.162072\n",
      "Train Epoch: 10 [1920/5110 (38%)]\tLoss: 0.147097\n",
      "Train Epoch: 10 [2560/5110 (50%)]\tLoss: 0.133502\n",
      "Train Epoch: 10 [3200/5110 (62%)]\tLoss: 0.228709\n",
      "Train Epoch: 10 [3840/5110 (75%)]\tLoss: 0.248037\n",
      "Train Epoch: 10 [4480/5110 (88%)]\tLoss: 0.153605\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6766 (0%)]\tLoss: 1.345879\n",
      "Train Epoch: 1 [640/6766 (9%)]\tLoss: 0.647902\n",
      "Train Epoch: 1 [1280/6766 (19%)]\tLoss: 0.330431\n",
      "Train Epoch: 1 [1920/6766 (28%)]\tLoss: 0.321383\n",
      "Train Epoch: 1 [2560/6766 (38%)]\tLoss: 0.294748\n",
      "Train Epoch: 1 [3200/6766 (47%)]\tLoss: 0.271199\n",
      "Train Epoch: 1 [3840/6766 (57%)]\tLoss: 0.489446\n",
      "Train Epoch: 1 [4480/6766 (66%)]\tLoss: 0.460590\n",
      "Train Epoch: 1 [5120/6766 (75%)]\tLoss: 0.205251\n",
      "Train Epoch: 1 [5760/6766 (85%)]\tLoss: 0.331258\n",
      "Train Epoch: 1 [6400/6766 (94%)]\tLoss: 0.328882\n",
      "Train Epoch: 2 [0/6766 (0%)]\tLoss: 0.198392\n",
      "Train Epoch: 2 [640/6766 (9%)]\tLoss: 0.119354\n",
      "Train Epoch: 2 [1280/6766 (19%)]\tLoss: 0.269370\n",
      "Train Epoch: 2 [1920/6766 (28%)]\tLoss: 0.287460\n",
      "Train Epoch: 2 [2560/6766 (38%)]\tLoss: 0.347521\n",
      "Train Epoch: 2 [3200/6766 (47%)]\tLoss: 0.212512\n",
      "Train Epoch: 2 [3840/6766 (57%)]\tLoss: 0.343888\n",
      "Train Epoch: 2 [4480/6766 (66%)]\tLoss: 0.116335\n",
      "Train Epoch: 2 [5120/6766 (75%)]\tLoss: 0.601887\n",
      "Train Epoch: 2 [5760/6766 (85%)]\tLoss: 0.225784\n",
      "Train Epoch: 2 [6400/6766 (94%)]\tLoss: 0.284527\n",
      "Train Epoch: 3 [0/6766 (0%)]\tLoss: 0.340544\n",
      "Train Epoch: 3 [640/6766 (9%)]\tLoss: 0.215790\n",
      "Train Epoch: 3 [1280/6766 (19%)]\tLoss: 0.033562\n",
      "Train Epoch: 3 [1920/6766 (28%)]\tLoss: 0.319878\n",
      "Train Epoch: 3 [2560/6766 (38%)]\tLoss: 0.204023\n",
      "Train Epoch: 3 [3200/6766 (47%)]\tLoss: 0.188681\n",
      "Train Epoch: 3 [3840/6766 (57%)]\tLoss: 0.191588\n",
      "Train Epoch: 3 [4480/6766 (66%)]\tLoss: 0.216089\n",
      "Train Epoch: 3 [5120/6766 (75%)]\tLoss: 0.408314\n",
      "Train Epoch: 3 [5760/6766 (85%)]\tLoss: 0.109736\n",
      "Train Epoch: 3 [6400/6766 (94%)]\tLoss: 0.310894\n",
      "Train Epoch: 4 [0/6766 (0%)]\tLoss: 0.177996\n",
      "Train Epoch: 4 [640/6766 (9%)]\tLoss: 0.190958\n",
      "Train Epoch: 4 [1280/6766 (19%)]\tLoss: 0.134286\n",
      "Train Epoch: 4 [1920/6766 (28%)]\tLoss: 0.087730\n",
      "Train Epoch: 4 [2560/6766 (38%)]\tLoss: 0.068072\n",
      "Train Epoch: 4 [3200/6766 (47%)]\tLoss: 0.186929\n",
      "Train Epoch: 4 [3840/6766 (57%)]\tLoss: 0.265593\n",
      "Train Epoch: 4 [4480/6766 (66%)]\tLoss: 0.103884\n",
      "Train Epoch: 4 [5120/6766 (75%)]\tLoss: 0.189103\n",
      "Train Epoch: 4 [5760/6766 (85%)]\tLoss: 0.074523\n",
      "Train Epoch: 4 [6400/6766 (94%)]\tLoss: 0.116944\n",
      "Train Epoch: 5 [0/6766 (0%)]\tLoss: 0.109237\n",
      "Train Epoch: 5 [640/6766 (9%)]\tLoss: 0.123257\n",
      "Train Epoch: 5 [1280/6766 (19%)]\tLoss: 0.066932\n",
      "Train Epoch: 5 [1920/6766 (28%)]\tLoss: 0.347121\n",
      "Train Epoch: 5 [2560/6766 (38%)]\tLoss: 0.114751\n",
      "Train Epoch: 5 [3200/6766 (47%)]\tLoss: 0.216978\n",
      "Train Epoch: 5 [3840/6766 (57%)]\tLoss: 0.183948\n",
      "Train Epoch: 5 [4480/6766 (66%)]\tLoss: 0.309676\n",
      "Train Epoch: 5 [5120/6766 (75%)]\tLoss: 0.146164\n",
      "Train Epoch: 5 [5760/6766 (85%)]\tLoss: 0.041083\n",
      "Train Epoch: 5 [6400/6766 (94%)]\tLoss: 0.320402\n",
      "Train Epoch: 6 [0/6766 (0%)]\tLoss: 0.240473\n",
      "Train Epoch: 6 [640/6766 (9%)]\tLoss: 0.039244\n",
      "Train Epoch: 6 [1280/6766 (19%)]\tLoss: 0.056332\n",
      "Train Epoch: 6 [1920/6766 (28%)]\tLoss: 0.246907\n",
      "Train Epoch: 6 [2560/6766 (38%)]\tLoss: 0.191768\n",
      "Train Epoch: 6 [3200/6766 (47%)]\tLoss: 0.145982\n",
      "Train Epoch: 6 [3840/6766 (57%)]\tLoss: 0.069369\n",
      "Train Epoch: 6 [4480/6766 (66%)]\tLoss: 0.160800\n",
      "Train Epoch: 6 [5120/6766 (75%)]\tLoss: 0.226631\n",
      "Train Epoch: 6 [5760/6766 (85%)]\tLoss: 0.097833\n",
      "Train Epoch: 6 [6400/6766 (94%)]\tLoss: 0.216588\n",
      "Train Epoch: 7 [0/6766 (0%)]\tLoss: 0.143135\n",
      "Train Epoch: 7 [640/6766 (9%)]\tLoss: 0.173279\n",
      "Train Epoch: 7 [1280/6766 (19%)]\tLoss: 0.072922\n",
      "Train Epoch: 7 [1920/6766 (28%)]\tLoss: 0.155775\n",
      "Train Epoch: 7 [2560/6766 (38%)]\tLoss: 0.049010\n",
      "Train Epoch: 7 [3200/6766 (47%)]\tLoss: 0.160346\n",
      "Train Epoch: 7 [3840/6766 (57%)]\tLoss: 0.106240\n",
      "Train Epoch: 7 [4480/6766 (66%)]\tLoss: 0.081566\n",
      "Train Epoch: 7 [5120/6766 (75%)]\tLoss: 0.204643\n",
      "Train Epoch: 7 [5760/6766 (85%)]\tLoss: 0.143092\n",
      "Train Epoch: 7 [6400/6766 (94%)]\tLoss: 0.106766\n",
      "Train Epoch: 8 [0/6766 (0%)]\tLoss: 0.180540\n",
      "Train Epoch: 8 [640/6766 (9%)]\tLoss: 0.186803\n",
      "Train Epoch: 8 [1280/6766 (19%)]\tLoss: 0.197423\n",
      "Train Epoch: 8 [1920/6766 (28%)]\tLoss: 0.101997\n",
      "Train Epoch: 8 [2560/6766 (38%)]\tLoss: 0.087058\n",
      "Train Epoch: 8 [3200/6766 (47%)]\tLoss: 0.147838\n",
      "Train Epoch: 8 [3840/6766 (57%)]\tLoss: 0.032274\n",
      "Train Epoch: 8 [4480/6766 (66%)]\tLoss: 0.196677\n",
      "Train Epoch: 8 [5120/6766 (75%)]\tLoss: 0.079833\n",
      "Train Epoch: 8 [5760/6766 (85%)]\tLoss: 0.187687\n",
      "Train Epoch: 8 [6400/6766 (94%)]\tLoss: 0.084369\n",
      "Train Epoch: 9 [0/6766 (0%)]\tLoss: 0.184583\n",
      "Train Epoch: 9 [640/6766 (9%)]\tLoss: 0.033882\n",
      "Train Epoch: 9 [1280/6766 (19%)]\tLoss: 0.113963\n",
      "Train Epoch: 9 [1920/6766 (28%)]\tLoss: 0.151514\n",
      "Train Epoch: 9 [2560/6766 (38%)]\tLoss: 0.136741\n",
      "Train Epoch: 9 [3200/6766 (47%)]\tLoss: 0.133272\n",
      "Train Epoch: 9 [3840/6766 (57%)]\tLoss: 0.257109\n",
      "Train Epoch: 9 [4480/6766 (66%)]\tLoss: 0.142993\n",
      "Train Epoch: 9 [5120/6766 (75%)]\tLoss: 0.019114\n",
      "Train Epoch: 9 [5760/6766 (85%)]\tLoss: 0.041883\n",
      "Train Epoch: 9 [6400/6766 (94%)]\tLoss: 0.128719\n",
      "Train Epoch: 10 [0/6766 (0%)]\tLoss: 0.055973\n",
      "Train Epoch: 10 [640/6766 (9%)]\tLoss: 0.196454\n",
      "Train Epoch: 10 [1280/6766 (19%)]\tLoss: 0.246255\n",
      "Train Epoch: 10 [1920/6766 (28%)]\tLoss: 0.140671\n",
      "Train Epoch: 10 [2560/6766 (38%)]\tLoss: 0.045090\n",
      "Train Epoch: 10 [3200/6766 (47%)]\tLoss: 0.255219\n",
      "Train Epoch: 10 [3840/6766 (57%)]\tLoss: 0.185091\n",
      "Train Epoch: 10 [4480/6766 (66%)]\tLoss: 0.173109\n",
      "Train Epoch: 10 [5120/6766 (75%)]\tLoss: 0.075707\n",
      "Train Epoch: 10 [5760/6766 (85%)]\tLoss: 0.091317\n",
      "Train Epoch: 10 [6400/6766 (94%)]\tLoss: 0.101572\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 1.362900\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 0.642551\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 0.385635\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 0.465153\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 0.516803\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 0.485740\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 0.288148\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 0.343264\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 0.313327\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 0.329131\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 0.243236\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 0.311989\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 0.319852\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 0.305688\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 0.291961\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 0.389730\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 0.283449\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.164883\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.238762\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.214943\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.295869\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.181147\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.307766\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.371252\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.278589\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.176084\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.158275\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.077960\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.209013\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.100037\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.169731\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.310029\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.168813\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.090064\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.387795\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.225048\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.216613\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.152979\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.162569\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.117092\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.326189\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.186827\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.163933\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.131205\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.121269\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.123379\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.151882\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.214389\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.160321\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.208875\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.322347\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.060242\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.248880\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.154397\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.137564\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.277790\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.184802\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.281116\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.192684\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.180974\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.279440\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.212826\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.256776\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.298468\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.145426\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.030377\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.159079\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.083172\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.107764\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.184804\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.197997\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.283965\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.102907\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.158263\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.128351\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.271991\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.233183\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.222233\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.077664\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.075381\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.263570\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.189843\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.155832\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.188380\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.137124\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.162129\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.082330\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.129941\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.110626\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.125482\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.122638\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.317912\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.046530\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.175616\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.151087\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.055500\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.252548\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.094380\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.034145\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.190022\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.185976\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.091228\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.145190\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.226703\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.106996\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.127241\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.178401\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.073602\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.106376\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.376574\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.136018\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.068142\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.198115\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.087066\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.274694\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.124907\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.299614\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.172714\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.101990\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.056707\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.125694\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.371887\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.184849\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.145945\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.074458\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.044069\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.125862\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.079779\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.086837\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.168634\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.219337\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.033741\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.195692\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.150214\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.041945\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.091679\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.143474\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.248225\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.218265\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.168120\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.117452\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.194441\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.071718\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.232274\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.133983\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.123694\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.206215\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.045907\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.209165\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.095567\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.097385\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.108809\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.132613\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.066426\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.231466\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.101856\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.121061\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.081925\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.247096\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.280629\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/3910 (0%)]\tLoss: 1.628741\n",
      "Train Epoch: 1 [640/3910 (16%)]\tLoss: 0.520309\n",
      "Train Epoch: 1 [1280/3910 (32%)]\tLoss: 0.565897\n",
      "Train Epoch: 1 [1920/3910 (48%)]\tLoss: 0.281176\n",
      "Train Epoch: 1 [2560/3910 (65%)]\tLoss: 0.339170\n",
      "Train Epoch: 1 [3200/3910 (81%)]\tLoss: 0.355586\n",
      "Train Epoch: 1 [3840/3910 (97%)]\tLoss: 0.305279\n",
      "Train Epoch: 2 [0/3910 (0%)]\tLoss: 0.386798\n",
      "Train Epoch: 2 [640/3910 (16%)]\tLoss: 0.321231\n",
      "Train Epoch: 2 [1280/3910 (32%)]\tLoss: 0.463479\n",
      "Train Epoch: 2 [1920/3910 (48%)]\tLoss: 0.291917\n",
      "Train Epoch: 2 [2560/3910 (65%)]\tLoss: 0.281174\n",
      "Train Epoch: 2 [3200/3910 (81%)]\tLoss: 0.525163\n",
      "Train Epoch: 2 [3840/3910 (97%)]\tLoss: 0.332314\n",
      "Train Epoch: 3 [0/3910 (0%)]\tLoss: 0.290738\n",
      "Train Epoch: 3 [640/3910 (16%)]\tLoss: 0.292006\n",
      "Train Epoch: 3 [1280/3910 (32%)]\tLoss: 0.592633\n",
      "Train Epoch: 3 [1920/3910 (48%)]\tLoss: 0.188741\n",
      "Train Epoch: 3 [2560/3910 (65%)]\tLoss: 0.195440\n",
      "Train Epoch: 3 [3200/3910 (81%)]\tLoss: 0.112370\n",
      "Train Epoch: 3 [3840/3910 (97%)]\tLoss: 0.384033\n",
      "Train Epoch: 4 [0/3910 (0%)]\tLoss: 0.471545\n",
      "Train Epoch: 4 [640/3910 (16%)]\tLoss: 0.274001\n",
      "Train Epoch: 4 [1280/3910 (32%)]\tLoss: 0.276371\n",
      "Train Epoch: 4 [1920/3910 (48%)]\tLoss: 0.465621\n",
      "Train Epoch: 4 [2560/3910 (65%)]\tLoss: 0.319675\n",
      "Train Epoch: 4 [3200/3910 (81%)]\tLoss: 0.117683\n",
      "Train Epoch: 4 [3840/3910 (97%)]\tLoss: 0.271579\n",
      "Train Epoch: 5 [0/3910 (0%)]\tLoss: 0.272573\n",
      "Train Epoch: 5 [640/3910 (16%)]\tLoss: 0.187094\n",
      "Train Epoch: 5 [1280/3910 (32%)]\tLoss: 0.323979\n",
      "Train Epoch: 5 [1920/3910 (48%)]\tLoss: 0.241583\n",
      "Train Epoch: 5 [2560/3910 (65%)]\tLoss: 0.286812\n",
      "Train Epoch: 5 [3200/3910 (81%)]\tLoss: 0.363692\n",
      "Train Epoch: 5 [3840/3910 (97%)]\tLoss: 0.139118\n",
      "Train Epoch: 6 [0/3910 (0%)]\tLoss: 0.151006\n",
      "Train Epoch: 6 [640/3910 (16%)]\tLoss: 0.244552\n",
      "Train Epoch: 6 [1280/3910 (32%)]\tLoss: 0.209659\n",
      "Train Epoch: 6 [1920/3910 (48%)]\tLoss: 0.254446\n",
      "Train Epoch: 6 [2560/3910 (65%)]\tLoss: 0.311505\n",
      "Train Epoch: 6 [3200/3910 (81%)]\tLoss: 0.164847\n",
      "Train Epoch: 6 [3840/3910 (97%)]\tLoss: 0.133429\n",
      "Train Epoch: 7 [0/3910 (0%)]\tLoss: 0.385090\n",
      "Train Epoch: 7 [640/3910 (16%)]\tLoss: 0.267477\n",
      "Train Epoch: 7 [1280/3910 (32%)]\tLoss: 0.185573\n",
      "Train Epoch: 7 [1920/3910 (48%)]\tLoss: 0.066030\n",
      "Train Epoch: 7 [2560/3910 (65%)]\tLoss: 0.332929\n",
      "Train Epoch: 7 [3200/3910 (81%)]\tLoss: 0.203947\n",
      "Train Epoch: 7 [3840/3910 (97%)]\tLoss: 0.236384\n",
      "Train Epoch: 8 [0/3910 (0%)]\tLoss: 0.181230\n",
      "Train Epoch: 8 [640/3910 (16%)]\tLoss: 0.313252\n",
      "Train Epoch: 8 [1280/3910 (32%)]\tLoss: 0.264256\n",
      "Train Epoch: 8 [1920/3910 (48%)]\tLoss: 0.196163\n",
      "Train Epoch: 8 [2560/3910 (65%)]\tLoss: 0.177489\n",
      "Train Epoch: 8 [3200/3910 (81%)]\tLoss: 0.105977\n",
      "Train Epoch: 8 [3840/3910 (97%)]\tLoss: 0.252742\n",
      "Train Epoch: 9 [0/3910 (0%)]\tLoss: 0.136018\n",
      "Train Epoch: 9 [640/3910 (16%)]\tLoss: 0.356774\n",
      "Train Epoch: 9 [1280/3910 (32%)]\tLoss: 0.130775\n",
      "Train Epoch: 9 [1920/3910 (48%)]\tLoss: 0.106052\n",
      "Train Epoch: 9 [2560/3910 (65%)]\tLoss: 0.088813\n",
      "Train Epoch: 9 [3200/3910 (81%)]\tLoss: 0.381850\n",
      "Train Epoch: 9 [3840/3910 (97%)]\tLoss: 0.220422\n",
      "Train Epoch: 10 [0/3910 (0%)]\tLoss: 0.296146\n",
      "Train Epoch: 10 [640/3910 (16%)]\tLoss: 0.189522\n",
      "Train Epoch: 10 [1280/3910 (32%)]\tLoss: 0.277572\n",
      "Train Epoch: 10 [1920/3910 (48%)]\tLoss: 0.146532\n",
      "Train Epoch: 10 [2560/3910 (65%)]\tLoss: 0.076290\n",
      "Train Epoch: 10 [3200/3910 (81%)]\tLoss: 0.188784\n",
      "Train Epoch: 10 [3840/3910 (97%)]\tLoss: 0.116431\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 1.664891\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 0.494352\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 0.229567\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 0.399610\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 0.307488\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 0.438749\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 0.306532\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 0.294218\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 0.242733\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 0.230861\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.296428\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.199413\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 0.174462\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 0.267240\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 0.204779\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.202706\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.320207\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.170502\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.183611\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.145604\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.251674\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.200394\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.191850\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.391804\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.202430\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.247246\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.233701\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.216672\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.283990\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.197456\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.235042\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.238911\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.179341\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.138231\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.416427\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.111105\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.069731\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.149325\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.096247\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.262986\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.259171\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.206319\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.065196\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.222952\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.078049\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.165230\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.083290\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.246403\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.048282\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.202849\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.176926\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.091230\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.068170\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.157750\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.114567\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.054550\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.107563\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.228760\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.299682\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.280571\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.067335\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.471114\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.220482\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.098183\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.337126\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.324711\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.129680\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.096506\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.114499\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.111962\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.239576\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.214258\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.108387\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.184290\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.047711\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.134497\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.104273\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.061782\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.154743\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.255564\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.200213\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.069098\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.185868\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.105213\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.110121\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.053031\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.188120\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.093118\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.141723\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.070009\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.209200\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.095364\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.083100\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.086308\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.221608\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.130518\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.143976\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.125011\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.050753\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.132031\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.116442\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.108093\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.050078\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.066238\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.019819\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.067926\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.177428\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.284959\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.155924\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.032791\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.184163\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.176806\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.058899\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.130913\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.212801\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.094168\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.098548\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.040095\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.094036\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.186999\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/5096 (0%)]\tLoss: 1.303052\n",
      "Train Epoch: 1 [640/5096 (12%)]\tLoss: 0.411272\n",
      "Train Epoch: 1 [1280/5096 (25%)]\tLoss: 0.482993\n",
      "Train Epoch: 1 [1920/5096 (38%)]\tLoss: 0.458034\n",
      "Train Epoch: 1 [2560/5096 (50%)]\tLoss: 0.404945\n",
      "Train Epoch: 1 [3200/5096 (62%)]\tLoss: 0.286464\n",
      "Train Epoch: 1 [3840/5096 (75%)]\tLoss: 0.284032\n",
      "Train Epoch: 1 [4480/5096 (88%)]\tLoss: 0.283070\n",
      "Train Epoch: 2 [0/5096 (0%)]\tLoss: 0.220542\n",
      "Train Epoch: 2 [640/5096 (12%)]\tLoss: 0.295944\n",
      "Train Epoch: 2 [1280/5096 (25%)]\tLoss: 0.161147\n",
      "Train Epoch: 2 [1920/5096 (38%)]\tLoss: 0.152783\n",
      "Train Epoch: 2 [2560/5096 (50%)]\tLoss: 0.184847\n",
      "Train Epoch: 2 [3200/5096 (62%)]\tLoss: 0.255273\n",
      "Train Epoch: 2 [3840/5096 (75%)]\tLoss: 0.148183\n",
      "Train Epoch: 2 [4480/5096 (88%)]\tLoss: 0.179301\n",
      "Train Epoch: 3 [0/5096 (0%)]\tLoss: 0.168001\n",
      "Train Epoch: 3 [640/5096 (12%)]\tLoss: 0.249966\n",
      "Train Epoch: 3 [1280/5096 (25%)]\tLoss: 0.305124\n",
      "Train Epoch: 3 [1920/5096 (38%)]\tLoss: 0.126063\n",
      "Train Epoch: 3 [2560/5096 (50%)]\tLoss: 0.147748\n",
      "Train Epoch: 3 [3200/5096 (62%)]\tLoss: 0.060831\n",
      "Train Epoch: 3 [3840/5096 (75%)]\tLoss: 0.195381\n",
      "Train Epoch: 3 [4480/5096 (88%)]\tLoss: 0.161423\n",
      "Train Epoch: 4 [0/5096 (0%)]\tLoss: 0.185376\n",
      "Train Epoch: 4 [640/5096 (12%)]\tLoss: 0.101588\n",
      "Train Epoch: 4 [1280/5096 (25%)]\tLoss: 0.169165\n",
      "Train Epoch: 4 [1920/5096 (38%)]\tLoss: 0.349479\n",
      "Train Epoch: 4 [2560/5096 (50%)]\tLoss: 0.183463\n",
      "Train Epoch: 4 [3200/5096 (62%)]\tLoss: 0.156017\n",
      "Train Epoch: 4 [3840/5096 (75%)]\tLoss: 0.161668\n",
      "Train Epoch: 4 [4480/5096 (88%)]\tLoss: 0.086006\n",
      "Train Epoch: 5 [0/5096 (0%)]\tLoss: 0.148105\n",
      "Train Epoch: 5 [640/5096 (12%)]\tLoss: 0.161870\n",
      "Train Epoch: 5 [1280/5096 (25%)]\tLoss: 0.228154\n",
      "Train Epoch: 5 [1920/5096 (38%)]\tLoss: 0.040682\n",
      "Train Epoch: 5 [2560/5096 (50%)]\tLoss: 0.083722\n",
      "Train Epoch: 5 [3200/5096 (62%)]\tLoss: 0.236130\n",
      "Train Epoch: 5 [3840/5096 (75%)]\tLoss: 0.106567\n",
      "Train Epoch: 5 [4480/5096 (88%)]\tLoss: 0.074666\n",
      "Train Epoch: 6 [0/5096 (0%)]\tLoss: 0.172029\n",
      "Train Epoch: 6 [640/5096 (12%)]\tLoss: 0.281680\n",
      "Train Epoch: 6 [1280/5096 (25%)]\tLoss: 0.138021\n",
      "Train Epoch: 6 [1920/5096 (38%)]\tLoss: 0.171302\n",
      "Train Epoch: 6 [2560/5096 (50%)]\tLoss: 0.110753\n",
      "Train Epoch: 6 [3200/5096 (62%)]\tLoss: 0.029540\n",
      "Train Epoch: 6 [3840/5096 (75%)]\tLoss: 0.197831\n",
      "Train Epoch: 6 [4480/5096 (88%)]\tLoss: 0.120347\n",
      "Train Epoch: 7 [0/5096 (0%)]\tLoss: 0.279869\n",
      "Train Epoch: 7 [640/5096 (12%)]\tLoss: 0.110416\n",
      "Train Epoch: 7 [1280/5096 (25%)]\tLoss: 0.195996\n",
      "Train Epoch: 7 [1920/5096 (38%)]\tLoss: 0.080552\n",
      "Train Epoch: 7 [2560/5096 (50%)]\tLoss: 0.057255\n",
      "Train Epoch: 7 [3200/5096 (62%)]\tLoss: 0.104342\n",
      "Train Epoch: 7 [3840/5096 (75%)]\tLoss: 0.172315\n",
      "Train Epoch: 7 [4480/5096 (88%)]\tLoss: 0.190056\n",
      "Train Epoch: 8 [0/5096 (0%)]\tLoss: 0.061632\n",
      "Train Epoch: 8 [640/5096 (12%)]\tLoss: 0.170936\n",
      "Train Epoch: 8 [1280/5096 (25%)]\tLoss: 0.152111\n",
      "Train Epoch: 8 [1920/5096 (38%)]\tLoss: 0.160539\n",
      "Train Epoch: 8 [2560/5096 (50%)]\tLoss: 0.046904\n",
      "Train Epoch: 8 [3200/5096 (62%)]\tLoss: 0.095385\n",
      "Train Epoch: 8 [3840/5096 (75%)]\tLoss: 0.052897\n",
      "Train Epoch: 8 [4480/5096 (88%)]\tLoss: 0.117099\n",
      "Train Epoch: 9 [0/5096 (0%)]\tLoss: 0.170080\n",
      "Train Epoch: 9 [640/5096 (12%)]\tLoss: 0.018225\n",
      "Train Epoch: 9 [1280/5096 (25%)]\tLoss: 0.135137\n",
      "Train Epoch: 9 [1920/5096 (38%)]\tLoss: 0.122854\n",
      "Train Epoch: 9 [2560/5096 (50%)]\tLoss: 0.120083\n",
      "Train Epoch: 9 [3200/5096 (62%)]\tLoss: 0.108192\n",
      "Train Epoch: 9 [3840/5096 (75%)]\tLoss: 0.102362\n",
      "Train Epoch: 9 [4480/5096 (88%)]\tLoss: 0.084250\n",
      "Train Epoch: 10 [0/5096 (0%)]\tLoss: 0.102524\n",
      "Train Epoch: 10 [640/5096 (12%)]\tLoss: 0.154585\n",
      "Train Epoch: 10 [1280/5096 (25%)]\tLoss: 0.199056\n",
      "Train Epoch: 10 [1920/5096 (38%)]\tLoss: 0.168222\n",
      "Train Epoch: 10 [2560/5096 (50%)]\tLoss: 0.092404\n",
      "Train Epoch: 10 [3200/5096 (62%)]\tLoss: 0.043495\n",
      "Train Epoch: 10 [3840/5096 (75%)]\tLoss: 0.157046\n",
      "Train Epoch: 10 [4480/5096 (88%)]\tLoss: 0.127977\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/1599 (0%)]\tLoss: 1.403570\n",
      "Train Epoch: 1 [640/1599 (40%)]\tLoss: 0.492320\n",
      "Train Epoch: 1 [1280/1599 (80%)]\tLoss: 0.695564\n",
      "Train Epoch: 2 [0/1599 (0%)]\tLoss: 0.471778\n",
      "Train Epoch: 2 [640/1599 (40%)]\tLoss: 0.472163\n",
      "Train Epoch: 2 [1280/1599 (80%)]\tLoss: 0.618514\n",
      "Train Epoch: 3 [0/1599 (0%)]\tLoss: 0.460816\n",
      "Train Epoch: 3 [640/1599 (40%)]\tLoss: 0.267292\n",
      "Train Epoch: 3 [1280/1599 (80%)]\tLoss: 0.338624\n",
      "Train Epoch: 4 [0/1599 (0%)]\tLoss: 0.319841\n",
      "Train Epoch: 4 [640/1599 (40%)]\tLoss: 0.303400\n",
      "Train Epoch: 4 [1280/1599 (80%)]\tLoss: 0.221116\n",
      "Train Epoch: 5 [0/1599 (0%)]\tLoss: 0.454546\n",
      "Train Epoch: 5 [640/1599 (40%)]\tLoss: 0.250683\n",
      "Train Epoch: 5 [1280/1599 (80%)]\tLoss: 0.230186\n",
      "Train Epoch: 6 [0/1599 (0%)]\tLoss: 0.380411\n",
      "Train Epoch: 6 [640/1599 (40%)]\tLoss: 0.340396\n",
      "Train Epoch: 6 [1280/1599 (80%)]\tLoss: 0.268221\n",
      "Train Epoch: 7 [0/1599 (0%)]\tLoss: 0.368561\n",
      "Train Epoch: 7 [640/1599 (40%)]\tLoss: 0.261845\n",
      "Train Epoch: 7 [1280/1599 (80%)]\tLoss: 0.459643\n",
      "Train Epoch: 8 [0/1599 (0%)]\tLoss: 0.239732\n",
      "Train Epoch: 8 [640/1599 (40%)]\tLoss: 0.258763\n",
      "Train Epoch: 8 [1280/1599 (80%)]\tLoss: 0.286691\n",
      "Train Epoch: 9 [0/1599 (0%)]\tLoss: 0.305040\n",
      "Train Epoch: 9 [640/1599 (40%)]\tLoss: 0.189140\n",
      "Train Epoch: 9 [1280/1599 (80%)]\tLoss: 0.311579\n",
      "Train Epoch: 10 [0/1599 (0%)]\tLoss: 0.207789\n",
      "Train Epoch: 10 [640/1599 (40%)]\tLoss: 0.205296\n",
      "Train Epoch: 10 [1280/1599 (80%)]\tLoss: 0.089181\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/5266 (0%)]\tLoss: 1.398899\n",
      "Train Epoch: 1 [640/5266 (12%)]\tLoss: 0.257397\n",
      "Train Epoch: 1 [1280/5266 (24%)]\tLoss: 0.128430\n",
      "Train Epoch: 1 [1920/5266 (36%)]\tLoss: 0.244265\n",
      "Train Epoch: 1 [2560/5266 (48%)]\tLoss: 0.225181\n",
      "Train Epoch: 1 [3200/5266 (60%)]\tLoss: 0.255294\n",
      "Train Epoch: 1 [3840/5266 (72%)]\tLoss: 0.200734\n",
      "Train Epoch: 1 [4480/5266 (84%)]\tLoss: 0.075624\n",
      "Train Epoch: 1 [5120/5266 (96%)]\tLoss: 0.117248\n",
      "Train Epoch: 2 [0/5266 (0%)]\tLoss: 0.120047\n",
      "Train Epoch: 2 [640/5266 (12%)]\tLoss: 0.196994\n",
      "Train Epoch: 2 [1280/5266 (24%)]\tLoss: 0.083679\n",
      "Train Epoch: 2 [1920/5266 (36%)]\tLoss: 0.137497\n",
      "Train Epoch: 2 [2560/5266 (48%)]\tLoss: 0.211640\n",
      "Train Epoch: 2 [3200/5266 (60%)]\tLoss: 0.212451\n",
      "Train Epoch: 2 [3840/5266 (72%)]\tLoss: 0.114532\n",
      "Train Epoch: 2 [4480/5266 (84%)]\tLoss: 0.131093\n",
      "Train Epoch: 2 [5120/5266 (96%)]\tLoss: 0.253181\n",
      "Train Epoch: 3 [0/5266 (0%)]\tLoss: 0.053887\n",
      "Train Epoch: 3 [640/5266 (12%)]\tLoss: 0.074514\n",
      "Train Epoch: 3 [1280/5266 (24%)]\tLoss: 0.156629\n",
      "Train Epoch: 3 [1920/5266 (36%)]\tLoss: 0.152738\n",
      "Train Epoch: 3 [2560/5266 (48%)]\tLoss: 0.262475\n",
      "Train Epoch: 3 [3200/5266 (60%)]\tLoss: 0.273551\n",
      "Train Epoch: 3 [3840/5266 (72%)]\tLoss: 0.114216\n",
      "Train Epoch: 3 [4480/5266 (84%)]\tLoss: 0.116226\n",
      "Train Epoch: 3 [5120/5266 (96%)]\tLoss: 0.087824\n",
      "Train Epoch: 4 [0/5266 (0%)]\tLoss: 0.095344\n",
      "Train Epoch: 4 [640/5266 (12%)]\tLoss: 0.235093\n",
      "Train Epoch: 4 [1280/5266 (24%)]\tLoss: 0.124463\n",
      "Train Epoch: 4 [1920/5266 (36%)]\tLoss: 0.126723\n",
      "Train Epoch: 4 [2560/5266 (48%)]\tLoss: 0.076247\n",
      "Train Epoch: 4 [3200/5266 (60%)]\tLoss: 0.257345\n",
      "Train Epoch: 4 [3840/5266 (72%)]\tLoss: 0.047652\n",
      "Train Epoch: 4 [4480/5266 (84%)]\tLoss: 0.171752\n",
      "Train Epoch: 4 [5120/5266 (96%)]\tLoss: 0.309264\n",
      "Train Epoch: 5 [0/5266 (0%)]\tLoss: 0.078153\n",
      "Train Epoch: 5 [640/5266 (12%)]\tLoss: 0.121820\n",
      "Train Epoch: 5 [1280/5266 (24%)]\tLoss: 0.062335\n",
      "Train Epoch: 5 [1920/5266 (36%)]\tLoss: 0.088925\n",
      "Train Epoch: 5 [2560/5266 (48%)]\tLoss: 0.155794\n",
      "Train Epoch: 5 [3200/5266 (60%)]\tLoss: 0.135935\n",
      "Train Epoch: 5 [3840/5266 (72%)]\tLoss: 0.031950\n",
      "Train Epoch: 5 [4480/5266 (84%)]\tLoss: 0.127579\n",
      "Train Epoch: 5 [5120/5266 (96%)]\tLoss: 0.030747\n",
      "Train Epoch: 6 [0/5266 (0%)]\tLoss: 0.105166\n",
      "Train Epoch: 6 [640/5266 (12%)]\tLoss: 0.079672\n",
      "Train Epoch: 6 [1280/5266 (24%)]\tLoss: 0.103407\n",
      "Train Epoch: 6 [1920/5266 (36%)]\tLoss: 0.047295\n",
      "Train Epoch: 6 [2560/5266 (48%)]\tLoss: 0.105864\n",
      "Train Epoch: 6 [3200/5266 (60%)]\tLoss: 0.170760\n",
      "Train Epoch: 6 [3840/5266 (72%)]\tLoss: 0.043355\n",
      "Train Epoch: 6 [4480/5266 (84%)]\tLoss: 0.106982\n",
      "Train Epoch: 6 [5120/5266 (96%)]\tLoss: 0.190941\n",
      "Train Epoch: 7 [0/5266 (0%)]\tLoss: 0.224654\n",
      "Train Epoch: 7 [640/5266 (12%)]\tLoss: 0.046547\n",
      "Train Epoch: 7 [1280/5266 (24%)]\tLoss: 0.108638\n",
      "Train Epoch: 7 [1920/5266 (36%)]\tLoss: 0.115381\n",
      "Train Epoch: 7 [2560/5266 (48%)]\tLoss: 0.125291\n",
      "Train Epoch: 7 [3200/5266 (60%)]\tLoss: 0.129973\n",
      "Train Epoch: 7 [3840/5266 (72%)]\tLoss: 0.197069\n",
      "Train Epoch: 7 [4480/5266 (84%)]\tLoss: 0.098931\n",
      "Train Epoch: 7 [5120/5266 (96%)]\tLoss: 0.153631\n",
      "Train Epoch: 8 [0/5266 (0%)]\tLoss: 0.179671\n",
      "Train Epoch: 8 [640/5266 (12%)]\tLoss: 0.088571\n",
      "Train Epoch: 8 [1280/5266 (24%)]\tLoss: 0.095643\n",
      "Train Epoch: 8 [1920/5266 (36%)]\tLoss: 0.059234\n",
      "Train Epoch: 8 [2560/5266 (48%)]\tLoss: 0.063973\n",
      "Train Epoch: 8 [3200/5266 (60%)]\tLoss: 0.175187\n",
      "Train Epoch: 8 [3840/5266 (72%)]\tLoss: 0.135864\n",
      "Train Epoch: 8 [4480/5266 (84%)]\tLoss: 0.063694\n",
      "Train Epoch: 8 [5120/5266 (96%)]\tLoss: 0.039782\n",
      "Train Epoch: 9 [0/5266 (0%)]\tLoss: 0.113584\n",
      "Train Epoch: 9 [640/5266 (12%)]\tLoss: 0.040330\n",
      "Train Epoch: 9 [1280/5266 (24%)]\tLoss: 0.020313\n",
      "Train Epoch: 9 [1920/5266 (36%)]\tLoss: 0.057257\n",
      "Train Epoch: 9 [2560/5266 (48%)]\tLoss: 0.113006\n",
      "Train Epoch: 9 [3200/5266 (60%)]\tLoss: 0.061208\n",
      "Train Epoch: 9 [3840/5266 (72%)]\tLoss: 0.135623\n",
      "Train Epoch: 9 [4480/5266 (84%)]\tLoss: 0.034604\n",
      "Train Epoch: 9 [5120/5266 (96%)]\tLoss: 0.101459\n",
      "Train Epoch: 10 [0/5266 (0%)]\tLoss: 0.088812\n",
      "Train Epoch: 10 [640/5266 (12%)]\tLoss: 0.110184\n",
      "Train Epoch: 10 [1280/5266 (24%)]\tLoss: 0.106386\n",
      "Train Epoch: 10 [1920/5266 (36%)]\tLoss: 0.053242\n",
      "Train Epoch: 10 [2560/5266 (48%)]\tLoss: 0.059357\n",
      "Train Epoch: 10 [3200/5266 (60%)]\tLoss: 0.022554\n",
      "Train Epoch: 10 [3840/5266 (72%)]\tLoss: 0.060680\n",
      "Train Epoch: 10 [4480/5266 (84%)]\tLoss: 0.070656\n",
      "Train Epoch: 10 [5120/5266 (96%)]\tLoss: 0.078893\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/3530 (0%)]\tLoss: 1.249938\n",
      "Train Epoch: 1 [640/3530 (18%)]\tLoss: 0.440093\n",
      "Train Epoch: 1 [1280/3530 (36%)]\tLoss: 0.437550\n",
      "Train Epoch: 1 [1920/3530 (54%)]\tLoss: 0.545815\n",
      "Train Epoch: 1 [2560/3530 (71%)]\tLoss: 0.392259\n",
      "Train Epoch: 1 [3200/3530 (89%)]\tLoss: 0.218135\n",
      "Train Epoch: 2 [0/3530 (0%)]\tLoss: 0.315372\n",
      "Train Epoch: 2 [640/3530 (18%)]\tLoss: 0.267912\n",
      "Train Epoch: 2 [1280/3530 (36%)]\tLoss: 0.370781\n",
      "Train Epoch: 2 [1920/3530 (54%)]\tLoss: 0.387709\n",
      "Train Epoch: 2 [2560/3530 (71%)]\tLoss: 0.310281\n",
      "Train Epoch: 2 [3200/3530 (89%)]\tLoss: 0.560491\n",
      "Train Epoch: 3 [0/3530 (0%)]\tLoss: 0.282668\n",
      "Train Epoch: 3 [640/3530 (18%)]\tLoss: 0.127223\n",
      "Train Epoch: 3 [1280/3530 (36%)]\tLoss: 0.214666\n",
      "Train Epoch: 3 [1920/3530 (54%)]\tLoss: 0.485680\n",
      "Train Epoch: 3 [2560/3530 (71%)]\tLoss: 0.302461\n",
      "Train Epoch: 3 [3200/3530 (89%)]\tLoss: 0.212328\n",
      "Train Epoch: 4 [0/3530 (0%)]\tLoss: 0.288979\n",
      "Train Epoch: 4 [640/3530 (18%)]\tLoss: 0.383221\n",
      "Train Epoch: 4 [1280/3530 (36%)]\tLoss: 0.399951\n",
      "Train Epoch: 4 [1920/3530 (54%)]\tLoss: 0.245587\n",
      "Train Epoch: 4 [2560/3530 (71%)]\tLoss: 0.290148\n",
      "Train Epoch: 4 [3200/3530 (89%)]\tLoss: 0.279347\n",
      "Train Epoch: 5 [0/3530 (0%)]\tLoss: 0.136633\n",
      "Train Epoch: 5 [640/3530 (18%)]\tLoss: 0.174125\n",
      "Train Epoch: 5 [1280/3530 (36%)]\tLoss: 0.192648\n",
      "Train Epoch: 5 [1920/3530 (54%)]\tLoss: 0.224638\n",
      "Train Epoch: 5 [2560/3530 (71%)]\tLoss: 0.189266\n",
      "Train Epoch: 5 [3200/3530 (89%)]\tLoss: 0.120076\n",
      "Train Epoch: 6 [0/3530 (0%)]\tLoss: 0.350468\n",
      "Train Epoch: 6 [640/3530 (18%)]\tLoss: 0.177444\n",
      "Train Epoch: 6 [1280/3530 (36%)]\tLoss: 0.275414\n",
      "Train Epoch: 6 [1920/3530 (54%)]\tLoss: 0.090222\n",
      "Train Epoch: 6 [2560/3530 (71%)]\tLoss: 0.159567\n",
      "Train Epoch: 6 [3200/3530 (89%)]\tLoss: 0.214600\n",
      "Train Epoch: 7 [0/3530 (0%)]\tLoss: 0.320741\n",
      "Train Epoch: 7 [640/3530 (18%)]\tLoss: 0.389043\n",
      "Train Epoch: 7 [1280/3530 (36%)]\tLoss: 0.162806\n",
      "Train Epoch: 7 [1920/3530 (54%)]\tLoss: 0.122051\n",
      "Train Epoch: 7 [2560/3530 (71%)]\tLoss: 0.230143\n",
      "Train Epoch: 7 [3200/3530 (89%)]\tLoss: 0.323888\n",
      "Train Epoch: 8 [0/3530 (0%)]\tLoss: 0.185737\n",
      "Train Epoch: 8 [640/3530 (18%)]\tLoss: 0.076867\n",
      "Train Epoch: 8 [1280/3530 (36%)]\tLoss: 0.303076\n",
      "Train Epoch: 8 [1920/3530 (54%)]\tLoss: 0.183829\n",
      "Train Epoch: 8 [2560/3530 (71%)]\tLoss: 0.425758\n",
      "Train Epoch: 8 [3200/3530 (89%)]\tLoss: 0.142581\n",
      "Train Epoch: 9 [0/3530 (0%)]\tLoss: 0.239345\n",
      "Train Epoch: 9 [640/3530 (18%)]\tLoss: 0.284655\n",
      "Train Epoch: 9 [1280/3530 (36%)]\tLoss: 0.227543\n",
      "Train Epoch: 9 [1920/3530 (54%)]\tLoss: 0.167031\n",
      "Train Epoch: 9 [2560/3530 (71%)]\tLoss: 0.058935\n",
      "Train Epoch: 9 [3200/3530 (89%)]\tLoss: 0.239647\n",
      "Train Epoch: 10 [0/3530 (0%)]\tLoss: 0.244218\n",
      "Train Epoch: 10 [640/3530 (18%)]\tLoss: 0.336210\n",
      "Train Epoch: 10 [1280/3530 (36%)]\tLoss: 0.145444\n",
      "Train Epoch: 10 [1920/3530 (54%)]\tLoss: 0.202053\n",
      "Train Epoch: 10 [2560/3530 (71%)]\tLoss: 0.237483\n",
      "Train Epoch: 10 [3200/3530 (89%)]\tLoss: 0.184816\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 1.1255, Accuracy: 9103/10000 (91%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 0.656765\n",
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 0.467823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 0.440722\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 0.357140\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 0.379293\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 0.181664\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 0.161472\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 0.192640\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 0.331492\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 0.290571\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 0.324555\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 0.340089\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 0.166748\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 0.355237\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 0.181294\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 0.130671\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 0.319549\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 0.358214\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 0.482858\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 0.345722\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.110358\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 0.257363\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 0.129056\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.215954\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.225188\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 0.222293\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.172540\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 0.423818\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.111739\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.238131\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.209687\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.218339\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.264572\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.304153\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.221825\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.210416\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.250149\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.167074\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.338297\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.179320\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.337816\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.129428\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.162889\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.231599\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.197281\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.101489\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.313491\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.096168\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.086401\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.077749\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.260972\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.250290\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.296534\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.301820\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.254334\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.170168\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.302322\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.192079\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.131718\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.226108\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.271343\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.019901\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.121853\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.154065\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.117027\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.214383\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.183358\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.140499\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.180920\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.206587\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.215940\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.283321\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.147157\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.252055\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.378469\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.144411\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.054555\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.292805\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.290327\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.135937\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.102636\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.185497\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.206544\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.189470\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.094180\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.081060\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.269394\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.198093\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.073782\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.215159\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.068632\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.077312\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.089640\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.097272\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.167627\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.115493\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.271992\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.138000\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.173296\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.152857\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.228477\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.140130\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.077770\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.305670\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.130372\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.400127\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.146022\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.125399\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 0.132529\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.215200\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.094778\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.284268\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.199497\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.108898\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.117055\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.127806\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.179706\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.042186\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.069800\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.095048\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.185152\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.158122\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.292666\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.092361\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.194131\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.166751\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.085468\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.158855\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.125121\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.105667\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.053360\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.123162\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.141876\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.198278\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.026627\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.232419\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.156917\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.121090\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.267953\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.229534\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.185619\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.233072\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.058688\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.149973\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.236897\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.067892\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.265552\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.145801\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.137385\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.128535\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.122372\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.283189\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.161727\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.154557\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.103907\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.218411\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.117215\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.070916\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.120248\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.245176\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.139055\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.126184\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.370405\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.089034\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.139588\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.166715\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.127693\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.061243\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.084641\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.177488\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.176275\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.154578\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.166053\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.046403\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.119968\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.208813\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.086366\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.113349\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.096831\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.142165\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/5110 (0%)]\tLoss: 0.588444\n",
      "Train Epoch: 1 [640/5110 (12%)]\tLoss: 0.429054\n",
      "Train Epoch: 1 [1280/5110 (25%)]\tLoss: 0.241494\n",
      "Train Epoch: 1 [1920/5110 (38%)]\tLoss: 0.180245\n",
      "Train Epoch: 1 [2560/5110 (50%)]\tLoss: 0.164549\n",
      "Train Epoch: 1 [3200/5110 (62%)]\tLoss: 0.170704\n",
      "Train Epoch: 1 [3840/5110 (75%)]\tLoss: 0.276259\n",
      "Train Epoch: 1 [4480/5110 (88%)]\tLoss: 0.266533\n",
      "Train Epoch: 2 [0/5110 (0%)]\tLoss: 0.192188\n",
      "Train Epoch: 2 [640/5110 (12%)]\tLoss: 0.214850\n",
      "Train Epoch: 2 [1280/5110 (25%)]\tLoss: 0.126787\n",
      "Train Epoch: 2 [1920/5110 (38%)]\tLoss: 0.193820\n",
      "Train Epoch: 2 [2560/5110 (50%)]\tLoss: 0.202919\n",
      "Train Epoch: 2 [3200/5110 (62%)]\tLoss: 0.209900\n",
      "Train Epoch: 2 [3840/5110 (75%)]\tLoss: 0.141948\n",
      "Train Epoch: 2 [4480/5110 (88%)]\tLoss: 0.291083\n",
      "Train Epoch: 3 [0/5110 (0%)]\tLoss: 0.137581\n",
      "Train Epoch: 3 [640/5110 (12%)]\tLoss: 0.153703\n",
      "Train Epoch: 3 [1280/5110 (25%)]\tLoss: 0.206114\n",
      "Train Epoch: 3 [1920/5110 (38%)]\tLoss: 0.143950\n",
      "Train Epoch: 3 [2560/5110 (50%)]\tLoss: 0.274771\n",
      "Train Epoch: 3 [3200/5110 (62%)]\tLoss: 0.219877\n",
      "Train Epoch: 3 [3840/5110 (75%)]\tLoss: 0.115518\n",
      "Train Epoch: 3 [4480/5110 (88%)]\tLoss: 0.114577\n",
      "Train Epoch: 4 [0/5110 (0%)]\tLoss: 0.100684\n",
      "Train Epoch: 4 [640/5110 (12%)]\tLoss: 0.225133\n",
      "Train Epoch: 4 [1280/5110 (25%)]\tLoss: 0.226934\n",
      "Train Epoch: 4 [1920/5110 (38%)]\tLoss: 0.213815\n",
      "Train Epoch: 4 [2560/5110 (50%)]\tLoss: 0.196569\n",
      "Train Epoch: 4 [3200/5110 (62%)]\tLoss: 0.213868\n",
      "Train Epoch: 4 [3840/5110 (75%)]\tLoss: 0.105024\n",
      "Train Epoch: 4 [4480/5110 (88%)]\tLoss: 0.102694\n",
      "Train Epoch: 5 [0/5110 (0%)]\tLoss: 0.093480\n",
      "Train Epoch: 5 [640/5110 (12%)]\tLoss: 0.194598\n",
      "Train Epoch: 5 [1280/5110 (25%)]\tLoss: 0.236353\n",
      "Train Epoch: 5 [1920/5110 (38%)]\tLoss: 0.216111\n",
      "Train Epoch: 5 [2560/5110 (50%)]\tLoss: 0.304300\n",
      "Train Epoch: 5 [3200/5110 (62%)]\tLoss: 0.114881\n",
      "Train Epoch: 5 [3840/5110 (75%)]\tLoss: 0.212005\n",
      "Train Epoch: 5 [4480/5110 (88%)]\tLoss: 0.041018\n",
      "Train Epoch: 6 [0/5110 (0%)]\tLoss: 0.129695\n",
      "Train Epoch: 6 [640/5110 (12%)]\tLoss: 0.161510\n",
      "Train Epoch: 6 [1280/5110 (25%)]\tLoss: 0.134705\n",
      "Train Epoch: 6 [1920/5110 (38%)]\tLoss: 0.144050\n",
      "Train Epoch: 6 [2560/5110 (50%)]\tLoss: 0.071750\n",
      "Train Epoch: 6 [3200/5110 (62%)]\tLoss: 0.085785\n",
      "Train Epoch: 6 [3840/5110 (75%)]\tLoss: 0.324751\n",
      "Train Epoch: 6 [4480/5110 (88%)]\tLoss: 0.125863\n",
      "Train Epoch: 7 [0/5110 (0%)]\tLoss: 0.177315\n",
      "Train Epoch: 7 [640/5110 (12%)]\tLoss: 0.197034\n",
      "Train Epoch: 7 [1280/5110 (25%)]\tLoss: 0.073621\n",
      "Train Epoch: 7 [1920/5110 (38%)]\tLoss: 0.183722\n",
      "Train Epoch: 7 [2560/5110 (50%)]\tLoss: 0.112158\n",
      "Train Epoch: 7 [3200/5110 (62%)]\tLoss: 0.068592\n",
      "Train Epoch: 7 [3840/5110 (75%)]\tLoss: 0.110694\n",
      "Train Epoch: 7 [4480/5110 (88%)]\tLoss: 0.144569\n",
      "Train Epoch: 8 [0/5110 (0%)]\tLoss: 0.190343\n",
      "Train Epoch: 8 [640/5110 (12%)]\tLoss: 0.094426\n",
      "Train Epoch: 8 [1280/5110 (25%)]\tLoss: 0.116385\n",
      "Train Epoch: 8 [1920/5110 (38%)]\tLoss: 0.121511\n",
      "Train Epoch: 8 [2560/5110 (50%)]\tLoss: 0.278116\n",
      "Train Epoch: 8 [3200/5110 (62%)]\tLoss: 0.084413\n",
      "Train Epoch: 8 [3840/5110 (75%)]\tLoss: 0.063741\n",
      "Train Epoch: 8 [4480/5110 (88%)]\tLoss: 0.249702\n",
      "Train Epoch: 9 [0/5110 (0%)]\tLoss: 0.140426\n",
      "Train Epoch: 9 [640/5110 (12%)]\tLoss: 0.147342\n",
      "Train Epoch: 9 [1280/5110 (25%)]\tLoss: 0.197657\n",
      "Train Epoch: 9 [1920/5110 (38%)]\tLoss: 0.162943\n",
      "Train Epoch: 9 [2560/5110 (50%)]\tLoss: 0.215993\n",
      "Train Epoch: 9 [3200/5110 (62%)]\tLoss: 0.103382\n",
      "Train Epoch: 9 [3840/5110 (75%)]\tLoss: 0.086012\n",
      "Train Epoch: 9 [4480/5110 (88%)]\tLoss: 0.120032\n",
      "Train Epoch: 10 [0/5110 (0%)]\tLoss: 0.206673\n",
      "Train Epoch: 10 [640/5110 (12%)]\tLoss: 0.172920\n",
      "Train Epoch: 10 [1280/5110 (25%)]\tLoss: 0.149707\n",
      "Train Epoch: 10 [1920/5110 (38%)]\tLoss: 0.081886\n",
      "Train Epoch: 10 [2560/5110 (50%)]\tLoss: 0.083244\n",
      "Train Epoch: 10 [3200/5110 (62%)]\tLoss: 0.099398\n",
      "Train Epoch: 10 [3840/5110 (75%)]\tLoss: 0.081417\n",
      "Train Epoch: 10 [4480/5110 (88%)]\tLoss: 0.093812\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6766 (0%)]\tLoss: 0.508702\n",
      "Train Epoch: 1 [640/6766 (9%)]\tLoss: 0.241338\n",
      "Train Epoch: 1 [1280/6766 (19%)]\tLoss: 0.301602\n",
      "Train Epoch: 1 [1920/6766 (28%)]\tLoss: 0.242650\n",
      "Train Epoch: 1 [2560/6766 (38%)]\tLoss: 0.142228\n",
      "Train Epoch: 1 [3200/6766 (47%)]\tLoss: 0.255056\n",
      "Train Epoch: 1 [3840/6766 (57%)]\tLoss: 0.086815\n",
      "Train Epoch: 1 [4480/6766 (66%)]\tLoss: 0.117049\n",
      "Train Epoch: 1 [5120/6766 (75%)]\tLoss: 0.231344\n",
      "Train Epoch: 1 [5760/6766 (85%)]\tLoss: 0.136057\n",
      "Train Epoch: 1 [6400/6766 (94%)]\tLoss: 0.188438\n",
      "Train Epoch: 2 [0/6766 (0%)]\tLoss: 0.040958\n",
      "Train Epoch: 2 [640/6766 (9%)]\tLoss: 0.250687\n",
      "Train Epoch: 2 [1280/6766 (19%)]\tLoss: 0.229770\n",
      "Train Epoch: 2 [1920/6766 (28%)]\tLoss: 0.145121\n",
      "Train Epoch: 2 [2560/6766 (38%)]\tLoss: 0.211130\n",
      "Train Epoch: 2 [3200/6766 (47%)]\tLoss: 0.099548\n",
      "Train Epoch: 2 [3840/6766 (57%)]\tLoss: 0.200500\n",
      "Train Epoch: 2 [4480/6766 (66%)]\tLoss: 0.150305\n",
      "Train Epoch: 2 [5120/6766 (75%)]\tLoss: 0.201225\n",
      "Train Epoch: 2 [5760/6766 (85%)]\tLoss: 0.120246\n",
      "Train Epoch: 2 [6400/6766 (94%)]\tLoss: 0.100246\n",
      "Train Epoch: 3 [0/6766 (0%)]\tLoss: 0.094449\n",
      "Train Epoch: 3 [640/6766 (9%)]\tLoss: 0.157950\n",
      "Train Epoch: 3 [1280/6766 (19%)]\tLoss: 0.138804\n",
      "Train Epoch: 3 [1920/6766 (28%)]\tLoss: 0.267984\n",
      "Train Epoch: 3 [2560/6766 (38%)]\tLoss: 0.216615\n",
      "Train Epoch: 3 [3200/6766 (47%)]\tLoss: 0.093931\n",
      "Train Epoch: 3 [3840/6766 (57%)]\tLoss: 0.074753\n",
      "Train Epoch: 3 [4480/6766 (66%)]\tLoss: 0.133859\n",
      "Train Epoch: 3 [5120/6766 (75%)]\tLoss: 0.125899\n",
      "Train Epoch: 3 [5760/6766 (85%)]\tLoss: 0.074392\n",
      "Train Epoch: 3 [6400/6766 (94%)]\tLoss: 0.160940\n",
      "Train Epoch: 4 [0/6766 (0%)]\tLoss: 0.110217\n",
      "Train Epoch: 4 [640/6766 (9%)]\tLoss: 0.061079\n",
      "Train Epoch: 4 [1280/6766 (19%)]\tLoss: 0.131947\n",
      "Train Epoch: 4 [1920/6766 (28%)]\tLoss: 0.245623\n",
      "Train Epoch: 4 [2560/6766 (38%)]\tLoss: 0.233220\n",
      "Train Epoch: 4 [3200/6766 (47%)]\tLoss: 0.102237\n",
      "Train Epoch: 4 [3840/6766 (57%)]\tLoss: 0.203216\n",
      "Train Epoch: 4 [4480/6766 (66%)]\tLoss: 0.067988\n",
      "Train Epoch: 4 [5120/6766 (75%)]\tLoss: 0.229913\n",
      "Train Epoch: 4 [5760/6766 (85%)]\tLoss: 0.149119\n",
      "Train Epoch: 4 [6400/6766 (94%)]\tLoss: 0.146975\n",
      "Train Epoch: 5 [0/6766 (0%)]\tLoss: 0.180294\n",
      "Train Epoch: 5 [640/6766 (9%)]\tLoss: 0.143450\n",
      "Train Epoch: 5 [1280/6766 (19%)]\tLoss: 0.085151\n",
      "Train Epoch: 5 [1920/6766 (28%)]\tLoss: 0.156759\n",
      "Train Epoch: 5 [2560/6766 (38%)]\tLoss: 0.181317\n",
      "Train Epoch: 5 [3200/6766 (47%)]\tLoss: 0.262839\n",
      "Train Epoch: 5 [3840/6766 (57%)]\tLoss: 0.248295\n",
      "Train Epoch: 5 [4480/6766 (66%)]\tLoss: 0.191315\n",
      "Train Epoch: 5 [5120/6766 (75%)]\tLoss: 0.078920\n",
      "Train Epoch: 5 [5760/6766 (85%)]\tLoss: 0.112677\n",
      "Train Epoch: 5 [6400/6766 (94%)]\tLoss: 0.085343\n",
      "Train Epoch: 6 [0/6766 (0%)]\tLoss: 0.213763\n",
      "Train Epoch: 6 [640/6766 (9%)]\tLoss: 0.151104\n",
      "Train Epoch: 6 [1280/6766 (19%)]\tLoss: 0.118201\n",
      "Train Epoch: 6 [1920/6766 (28%)]\tLoss: 0.074985\n",
      "Train Epoch: 6 [2560/6766 (38%)]\tLoss: 0.037462\n",
      "Train Epoch: 6 [3200/6766 (47%)]\tLoss: 0.177432\n",
      "Train Epoch: 6 [3840/6766 (57%)]\tLoss: 0.044274\n",
      "Train Epoch: 6 [4480/6766 (66%)]\tLoss: 0.106424\n",
      "Train Epoch: 6 [5120/6766 (75%)]\tLoss: 0.055206\n",
      "Train Epoch: 6 [5760/6766 (85%)]\tLoss: 0.092009\n",
      "Train Epoch: 6 [6400/6766 (94%)]\tLoss: 0.047021\n",
      "Train Epoch: 7 [0/6766 (0%)]\tLoss: 0.137423\n",
      "Train Epoch: 7 [640/6766 (9%)]\tLoss: 0.059448\n",
      "Train Epoch: 7 [1280/6766 (19%)]\tLoss: 0.058289\n",
      "Train Epoch: 7 [1920/6766 (28%)]\tLoss: 0.174622\n",
      "Train Epoch: 7 [2560/6766 (38%)]\tLoss: 0.052022\n",
      "Train Epoch: 7 [3200/6766 (47%)]\tLoss: 0.149912\n",
      "Train Epoch: 7 [3840/6766 (57%)]\tLoss: 0.184360\n",
      "Train Epoch: 7 [4480/6766 (66%)]\tLoss: 0.135714\n",
      "Train Epoch: 7 [5120/6766 (75%)]\tLoss: 0.189225\n",
      "Train Epoch: 7 [5760/6766 (85%)]\tLoss: 0.153615\n",
      "Train Epoch: 7 [6400/6766 (94%)]\tLoss: 0.133562\n",
      "Train Epoch: 8 [0/6766 (0%)]\tLoss: 0.024130\n",
      "Train Epoch: 8 [640/6766 (9%)]\tLoss: 0.083358\n",
      "Train Epoch: 8 [1280/6766 (19%)]\tLoss: 0.095475\n",
      "Train Epoch: 8 [1920/6766 (28%)]\tLoss: 0.055122\n",
      "Train Epoch: 8 [2560/6766 (38%)]\tLoss: 0.105060\n",
      "Train Epoch: 8 [3200/6766 (47%)]\tLoss: 0.147378\n",
      "Train Epoch: 8 [3840/6766 (57%)]\tLoss: 0.041055\n",
      "Train Epoch: 8 [4480/6766 (66%)]\tLoss: 0.051630\n",
      "Train Epoch: 8 [5120/6766 (75%)]\tLoss: 0.121754\n",
      "Train Epoch: 8 [5760/6766 (85%)]\tLoss: 0.088299\n",
      "Train Epoch: 8 [6400/6766 (94%)]\tLoss: 0.067864\n",
      "Train Epoch: 9 [0/6766 (0%)]\tLoss: 0.173181\n",
      "Train Epoch: 9 [640/6766 (9%)]\tLoss: 0.123538\n",
      "Train Epoch: 9 [1280/6766 (19%)]\tLoss: 0.056463\n",
      "Train Epoch: 9 [1920/6766 (28%)]\tLoss: 0.127852\n",
      "Train Epoch: 9 [2560/6766 (38%)]\tLoss: 0.039777\n",
      "Train Epoch: 9 [3200/6766 (47%)]\tLoss: 0.268351\n",
      "Train Epoch: 9 [3840/6766 (57%)]\tLoss: 0.090988\n",
      "Train Epoch: 9 [4480/6766 (66%)]\tLoss: 0.106997\n",
      "Train Epoch: 9 [5120/6766 (75%)]\tLoss: 0.035810\n",
      "Train Epoch: 9 [5760/6766 (85%)]\tLoss: 0.028925\n",
      "Train Epoch: 9 [6400/6766 (94%)]\tLoss: 0.227868\n",
      "Train Epoch: 10 [0/6766 (0%)]\tLoss: 0.285977\n",
      "Train Epoch: 10 [640/6766 (9%)]\tLoss: 0.092160\n",
      "Train Epoch: 10 [1280/6766 (19%)]\tLoss: 0.106278\n",
      "Train Epoch: 10 [1920/6766 (28%)]\tLoss: 0.244736\n",
      "Train Epoch: 10 [2560/6766 (38%)]\tLoss: 0.177066\n",
      "Train Epoch: 10 [3200/6766 (47%)]\tLoss: 0.079958\n",
      "Train Epoch: 10 [3840/6766 (57%)]\tLoss: 0.098398\n",
      "Train Epoch: 10 [4480/6766 (66%)]\tLoss: 0.121828\n",
      "Train Epoch: 10 [5120/6766 (75%)]\tLoss: 0.048635\n",
      "Train Epoch: 10 [5760/6766 (85%)]\tLoss: 0.244793\n",
      "Train Epoch: 10 [6400/6766 (94%)]\tLoss: 0.132404\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 0.613655\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 0.345037\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 0.521956\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 0.376498\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 0.190163\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 0.184408\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 0.270625\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 0.225199\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 0.315789\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 0.284083\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 0.297610\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 0.308469\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 0.215528\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 0.085246\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 0.124960\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 0.100520\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 0.127203\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.288854\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.209020\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.076070\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.189035\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.201179\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.087666\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.342939\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.108138\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.308317\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.262637\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.356372\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.211870\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.103122\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.186319\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.196603\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.198685\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.131023\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.203776\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.070392\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.112903\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.171576\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.102590\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.210718\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.156865\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.165582\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.145023\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.154155\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.102740\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.243255\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.128327\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.466216\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.146932\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.110620\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.274579\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.104804\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.161737\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.072824\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.110282\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.142285\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.077458\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.139963\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.096037\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.124739\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.173596\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.208810\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.139811\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.208598\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.084044\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.162952\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.100534\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.089120\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.036737\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.133255\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.052699\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.111005\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.057849\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.115012\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.063038\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.148793\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.149661\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.130270\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.052388\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.101524\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.047000\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.122897\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.049964\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.055448\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.084517\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.052204\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.051891\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.103315\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.161776\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.059698\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.104554\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.206700\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.276333\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.105827\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.461308\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.093259\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.062547\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.022241\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.163079\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.096488\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.269671\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.108569\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.067111\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.145187\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.160083\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.074076\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.086687\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.266197\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.205080\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.123083\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.245079\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.054713\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.191254\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.106099\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.088160\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.090540\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.114867\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.099842\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.089219\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.015615\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.159717\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.060689\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.095004\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.076416\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.073542\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.122443\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.150089\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.091474\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.377361\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.051691\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.084725\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.082904\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.168036\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.248989\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.189430\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.065027\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.207110\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.034882\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.038164\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.132654\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.073080\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.186513\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.081084\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.044957\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.114338\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.190048\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.059664\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.091378\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.059375\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.140008\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.071705\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.123123\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.201851\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.086850\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.057291\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.124762\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.089601\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.100055\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.069263\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.123446\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/3910 (0%)]\tLoss: 1.055183\n",
      "Train Epoch: 1 [640/3910 (16%)]\tLoss: 0.249254\n",
      "Train Epoch: 1 [1280/3910 (32%)]\tLoss: 0.294474\n",
      "Train Epoch: 1 [1920/3910 (48%)]\tLoss: 0.291169\n",
      "Train Epoch: 1 [2560/3910 (65%)]\tLoss: 0.277810\n",
      "Train Epoch: 1 [3200/3910 (81%)]\tLoss: 0.262118\n",
      "Train Epoch: 1 [3840/3910 (97%)]\tLoss: 0.250559\n",
      "Train Epoch: 2 [0/3910 (0%)]\tLoss: 0.183974\n",
      "Train Epoch: 2 [640/3910 (16%)]\tLoss: 0.112708\n",
      "Train Epoch: 2 [1280/3910 (32%)]\tLoss: 0.151800\n",
      "Train Epoch: 2 [1920/3910 (48%)]\tLoss: 0.144166\n",
      "Train Epoch: 2 [2560/3910 (65%)]\tLoss: 0.238847\n",
      "Train Epoch: 2 [3200/3910 (81%)]\tLoss: 0.134217\n",
      "Train Epoch: 2 [3840/3910 (97%)]\tLoss: 0.199758\n",
      "Train Epoch: 3 [0/3910 (0%)]\tLoss: 0.177504\n",
      "Train Epoch: 3 [640/3910 (16%)]\tLoss: 0.185165\n",
      "Train Epoch: 3 [1280/3910 (32%)]\tLoss: 0.251000\n",
      "Train Epoch: 3 [1920/3910 (48%)]\tLoss: 0.188478\n",
      "Train Epoch: 3 [2560/3910 (65%)]\tLoss: 0.348020\n",
      "Train Epoch: 3 [3200/3910 (81%)]\tLoss: 0.175119\n",
      "Train Epoch: 3 [3840/3910 (97%)]\tLoss: 0.066054\n",
      "Train Epoch: 4 [0/3910 (0%)]\tLoss: 0.197012\n",
      "Train Epoch: 4 [640/3910 (16%)]\tLoss: 0.156749\n",
      "Train Epoch: 4 [1280/3910 (32%)]\tLoss: 0.248025\n",
      "Train Epoch: 4 [1920/3910 (48%)]\tLoss: 0.134686\n",
      "Train Epoch: 4 [2560/3910 (65%)]\tLoss: 0.574066\n",
      "Train Epoch: 4 [3200/3910 (81%)]\tLoss: 0.259878\n",
      "Train Epoch: 4 [3840/3910 (97%)]\tLoss: 0.092648\n",
      "Train Epoch: 5 [0/3910 (0%)]\tLoss: 0.129739\n",
      "Train Epoch: 5 [640/3910 (16%)]\tLoss: 0.295626\n",
      "Train Epoch: 5 [1280/3910 (32%)]\tLoss: 0.194594\n",
      "Train Epoch: 5 [1920/3910 (48%)]\tLoss: 0.346854\n",
      "Train Epoch: 5 [2560/3910 (65%)]\tLoss: 0.346959\n",
      "Train Epoch: 5 [3200/3910 (81%)]\tLoss: 0.228522\n",
      "Train Epoch: 5 [3840/3910 (97%)]\tLoss: 0.193516\n",
      "Train Epoch: 6 [0/3910 (0%)]\tLoss: 0.078450\n",
      "Train Epoch: 6 [640/3910 (16%)]\tLoss: 0.245101\n",
      "Train Epoch: 6 [1280/3910 (32%)]\tLoss: 0.167184\n",
      "Train Epoch: 6 [1920/3910 (48%)]\tLoss: 0.143057\n",
      "Train Epoch: 6 [2560/3910 (65%)]\tLoss: 0.145179\n",
      "Train Epoch: 6 [3200/3910 (81%)]\tLoss: 0.119588\n",
      "Train Epoch: 6 [3840/3910 (97%)]\tLoss: 0.060745\n",
      "Train Epoch: 7 [0/3910 (0%)]\tLoss: 0.289855\n",
      "Train Epoch: 7 [640/3910 (16%)]\tLoss: 0.157214\n",
      "Train Epoch: 7 [1280/3910 (32%)]\tLoss: 0.196927\n",
      "Train Epoch: 7 [1920/3910 (48%)]\tLoss: 0.183711\n",
      "Train Epoch: 7 [2560/3910 (65%)]\tLoss: 0.306509\n",
      "Train Epoch: 7 [3200/3910 (81%)]\tLoss: 0.072767\n",
      "Train Epoch: 7 [3840/3910 (97%)]\tLoss: 0.126717\n",
      "Train Epoch: 8 [0/3910 (0%)]\tLoss: 0.218817\n",
      "Train Epoch: 8 [640/3910 (16%)]\tLoss: 0.121897\n",
      "Train Epoch: 8 [1280/3910 (32%)]\tLoss: 0.106063\n",
      "Train Epoch: 8 [1920/3910 (48%)]\tLoss: 0.058179\n",
      "Train Epoch: 8 [2560/3910 (65%)]\tLoss: 0.172723\n",
      "Train Epoch: 8 [3200/3910 (81%)]\tLoss: 0.201915\n",
      "Train Epoch: 8 [3840/3910 (97%)]\tLoss: 0.046003\n",
      "Train Epoch: 9 [0/3910 (0%)]\tLoss: 0.063590\n",
      "Train Epoch: 9 [640/3910 (16%)]\tLoss: 0.168484\n",
      "Train Epoch: 9 [1280/3910 (32%)]\tLoss: 0.066717\n",
      "Train Epoch: 9 [1920/3910 (48%)]\tLoss: 0.054152\n",
      "Train Epoch: 9 [2560/3910 (65%)]\tLoss: 0.221569\n",
      "Train Epoch: 9 [3200/3910 (81%)]\tLoss: 0.178829\n",
      "Train Epoch: 9 [3840/3910 (97%)]\tLoss: 0.141567\n",
      "Train Epoch: 10 [0/3910 (0%)]\tLoss: 0.052594\n",
      "Train Epoch: 10 [640/3910 (16%)]\tLoss: 0.209251\n",
      "Train Epoch: 10 [1280/3910 (32%)]\tLoss: 0.160157\n",
      "Train Epoch: 10 [1920/3910 (48%)]\tLoss: 0.080030\n",
      "Train Epoch: 10 [2560/3910 (65%)]\tLoss: 0.135178\n",
      "Train Epoch: 10 [3200/3910 (81%)]\tLoss: 0.097171\n",
      "Train Epoch: 10 [3840/3910 (97%)]\tLoss: 0.116285\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 0.891900\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 0.269570\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 0.146959\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 0.191798\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 0.227472\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 0.132497\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 0.210978\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 0.108556\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 0.060656\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 0.102276\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.155615\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.192212\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 0.082966\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 0.188234\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 0.115698\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.158088\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.127537\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.136858\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.095123\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.109987\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.179005\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.230547\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.096707\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.143462\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.111198\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.308443\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.220012\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.186010\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.140533\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.124132\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.068885\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.135146\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.126621\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.058644\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.064413\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.412515\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.211283\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.088883\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.133190\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.141097\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.166354\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.094921\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.101900\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.116402\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.458144\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.029293\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.122570\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.177381\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.109359\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.082350\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.061450\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.153440\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.130280\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.114375\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.167639\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.090090\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.039547\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.278421\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.268551\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.071138\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.137787\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.199230\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.227492\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.103484\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.152634\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.200499\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.149310\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.132192\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.089794\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.048136\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.097274\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.285224\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.038064\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.080875\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.105754\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.031943\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.084142\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.102893\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.202529\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.059267\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.037111\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.037154\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.110894\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.032037\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.062849\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.100088\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.219920\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.084862\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.059724\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.079502\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.163200\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.143869\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.096717\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.055872\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.118863\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.113992\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.158626\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.046969\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.167978\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.061078\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.028085\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.081348\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.085692\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.044057\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.071860\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.119560\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.097673\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.133413\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.110444\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.125045\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.141080\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.067046\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.100954\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.097931\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.070641\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.050691\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.025579\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.094287\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.279695\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.070600\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/5096 (0%)]\tLoss: 0.308938\n",
      "Train Epoch: 1 [640/5096 (12%)]\tLoss: 0.147353\n",
      "Train Epoch: 1 [1280/5096 (25%)]\tLoss: 0.109723\n",
      "Train Epoch: 1 [1920/5096 (38%)]\tLoss: 0.178631\n",
      "Train Epoch: 1 [2560/5096 (50%)]\tLoss: 0.118143\n",
      "Train Epoch: 1 [3200/5096 (62%)]\tLoss: 0.285182\n",
      "Train Epoch: 1 [3840/5096 (75%)]\tLoss: 0.121643\n",
      "Train Epoch: 1 [4480/5096 (88%)]\tLoss: 0.273062\n",
      "Train Epoch: 2 [0/5096 (0%)]\tLoss: 0.106937\n",
      "Train Epoch: 2 [640/5096 (12%)]\tLoss: 0.162929\n",
      "Train Epoch: 2 [1280/5096 (25%)]\tLoss: 0.136760\n",
      "Train Epoch: 2 [1920/5096 (38%)]\tLoss: 0.101559\n",
      "Train Epoch: 2 [2560/5096 (50%)]\tLoss: 0.085655\n",
      "Train Epoch: 2 [3200/5096 (62%)]\tLoss: 0.145710\n",
      "Train Epoch: 2 [3840/5096 (75%)]\tLoss: 0.104787\n",
      "Train Epoch: 2 [4480/5096 (88%)]\tLoss: 0.118879\n",
      "Train Epoch: 3 [0/5096 (0%)]\tLoss: 0.222931\n",
      "Train Epoch: 3 [640/5096 (12%)]\tLoss: 0.123780\n",
      "Train Epoch: 3 [1280/5096 (25%)]\tLoss: 0.045577\n",
      "Train Epoch: 3 [1920/5096 (38%)]\tLoss: 0.159944\n",
      "Train Epoch: 3 [2560/5096 (50%)]\tLoss: 0.084249\n",
      "Train Epoch: 3 [3200/5096 (62%)]\tLoss: 0.043573\n",
      "Train Epoch: 3 [3840/5096 (75%)]\tLoss: 0.081403\n",
      "Train Epoch: 3 [4480/5096 (88%)]\tLoss: 0.090127\n",
      "Train Epoch: 4 [0/5096 (0%)]\tLoss: 0.099545\n",
      "Train Epoch: 4 [640/5096 (12%)]\tLoss: 0.095200\n",
      "Train Epoch: 4 [1280/5096 (25%)]\tLoss: 0.214557\n",
      "Train Epoch: 4 [1920/5096 (38%)]\tLoss: 0.089219\n",
      "Train Epoch: 4 [2560/5096 (50%)]\tLoss: 0.163139\n",
      "Train Epoch: 4 [3200/5096 (62%)]\tLoss: 0.207639\n",
      "Train Epoch: 4 [3840/5096 (75%)]\tLoss: 0.035368\n",
      "Train Epoch: 4 [4480/5096 (88%)]\tLoss: 0.065366\n",
      "Train Epoch: 5 [0/5096 (0%)]\tLoss: 0.064600\n",
      "Train Epoch: 5 [640/5096 (12%)]\tLoss: 0.030628\n",
      "Train Epoch: 5 [1280/5096 (25%)]\tLoss: 0.219934\n",
      "Train Epoch: 5 [1920/5096 (38%)]\tLoss: 0.092119\n",
      "Train Epoch: 5 [2560/5096 (50%)]\tLoss: 0.163682\n",
      "Train Epoch: 5 [3200/5096 (62%)]\tLoss: 0.100711\n",
      "Train Epoch: 5 [3840/5096 (75%)]\tLoss: 0.157451\n",
      "Train Epoch: 5 [4480/5096 (88%)]\tLoss: 0.111959\n",
      "Train Epoch: 6 [0/5096 (0%)]\tLoss: 0.027677\n",
      "Train Epoch: 6 [640/5096 (12%)]\tLoss: 0.168809\n",
      "Train Epoch: 6 [1280/5096 (25%)]\tLoss: 0.047718\n",
      "Train Epoch: 6 [1920/5096 (38%)]\tLoss: 0.133371\n",
      "Train Epoch: 6 [2560/5096 (50%)]\tLoss: 0.057178\n",
      "Train Epoch: 6 [3200/5096 (62%)]\tLoss: 0.059471\n",
      "Train Epoch: 6 [3840/5096 (75%)]\tLoss: 0.120319\n",
      "Train Epoch: 6 [4480/5096 (88%)]\tLoss: 0.154420\n",
      "Train Epoch: 7 [0/5096 (0%)]\tLoss: 0.099471\n",
      "Train Epoch: 7 [640/5096 (12%)]\tLoss: 0.037327\n",
      "Train Epoch: 7 [1280/5096 (25%)]\tLoss: 0.221815\n",
      "Train Epoch: 7 [1920/5096 (38%)]\tLoss: 0.034882\n",
      "Train Epoch: 7 [2560/5096 (50%)]\tLoss: 0.033998\n",
      "Train Epoch: 7 [3200/5096 (62%)]\tLoss: 0.079315\n",
      "Train Epoch: 7 [3840/5096 (75%)]\tLoss: 0.100979\n",
      "Train Epoch: 7 [4480/5096 (88%)]\tLoss: 0.161718\n",
      "Train Epoch: 8 [0/5096 (0%)]\tLoss: 0.052979\n",
      "Train Epoch: 8 [640/5096 (12%)]\tLoss: 0.045558\n",
      "Train Epoch: 8 [1280/5096 (25%)]\tLoss: 0.102933\n",
      "Train Epoch: 8 [1920/5096 (38%)]\tLoss: 0.037397\n",
      "Train Epoch: 8 [2560/5096 (50%)]\tLoss: 0.070760\n",
      "Train Epoch: 8 [3200/5096 (62%)]\tLoss: 0.065423\n",
      "Train Epoch: 8 [3840/5096 (75%)]\tLoss: 0.061465\n",
      "Train Epoch: 8 [4480/5096 (88%)]\tLoss: 0.049634\n",
      "Train Epoch: 9 [0/5096 (0%)]\tLoss: 0.054350\n",
      "Train Epoch: 9 [640/5096 (12%)]\tLoss: 0.038827\n",
      "Train Epoch: 9 [1280/5096 (25%)]\tLoss: 0.077435\n",
      "Train Epoch: 9 [1920/5096 (38%)]\tLoss: 0.027652\n",
      "Train Epoch: 9 [2560/5096 (50%)]\tLoss: 0.125257\n",
      "Train Epoch: 9 [3200/5096 (62%)]\tLoss: 0.130601\n",
      "Train Epoch: 9 [3840/5096 (75%)]\tLoss: 0.043370\n",
      "Train Epoch: 9 [4480/5096 (88%)]\tLoss: 0.105268\n",
      "Train Epoch: 10 [0/5096 (0%)]\tLoss: 0.036191\n",
      "Train Epoch: 10 [640/5096 (12%)]\tLoss: 0.031107\n",
      "Train Epoch: 10 [1280/5096 (25%)]\tLoss: 0.093886\n",
      "Train Epoch: 10 [1920/5096 (38%)]\tLoss: 0.056952\n",
      "Train Epoch: 10 [2560/5096 (50%)]\tLoss: 0.217428\n",
      "Train Epoch: 10 [3200/5096 (62%)]\tLoss: 0.057740\n",
      "Train Epoch: 10 [3840/5096 (75%)]\tLoss: 0.022879\n",
      "Train Epoch: 10 [4480/5096 (88%)]\tLoss: 0.059298\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/1599 (0%)]\tLoss: 0.800098\n",
      "Train Epoch: 1 [640/1599 (40%)]\tLoss: 0.335139\n",
      "Train Epoch: 1 [1280/1599 (80%)]\tLoss: 0.240620\n",
      "Train Epoch: 2 [0/1599 (0%)]\tLoss: 0.216067\n",
      "Train Epoch: 2 [640/1599 (40%)]\tLoss: 0.436435\n",
      "Train Epoch: 2 [1280/1599 (80%)]\tLoss: 0.329942\n",
      "Train Epoch: 3 [0/1599 (0%)]\tLoss: 0.231507\n",
      "Train Epoch: 3 [640/1599 (40%)]\tLoss: 0.250423\n",
      "Train Epoch: 3 [1280/1599 (80%)]\tLoss: 0.161664\n",
      "Train Epoch: 4 [0/1599 (0%)]\tLoss: 0.170316\n",
      "Train Epoch: 4 [640/1599 (40%)]\tLoss: 0.170388\n",
      "Train Epoch: 4 [1280/1599 (80%)]\tLoss: 0.185959\n",
      "Train Epoch: 5 [0/1599 (0%)]\tLoss: 0.327544\n",
      "Train Epoch: 5 [640/1599 (40%)]\tLoss: 0.137283\n",
      "Train Epoch: 5 [1280/1599 (80%)]\tLoss: 0.158475\n",
      "Train Epoch: 6 [0/1599 (0%)]\tLoss: 0.233361\n",
      "Train Epoch: 6 [640/1599 (40%)]\tLoss: 0.168402\n",
      "Train Epoch: 6 [1280/1599 (80%)]\tLoss: 0.189260\n",
      "Train Epoch: 7 [0/1599 (0%)]\tLoss: 0.339689\n",
      "Train Epoch: 7 [640/1599 (40%)]\tLoss: 0.145100\n",
      "Train Epoch: 7 [1280/1599 (80%)]\tLoss: 0.110702\n",
      "Train Epoch: 8 [0/1599 (0%)]\tLoss: 0.247761\n",
      "Train Epoch: 8 [640/1599 (40%)]\tLoss: 0.213347\n",
      "Train Epoch: 8 [1280/1599 (80%)]\tLoss: 0.246218\n",
      "Train Epoch: 9 [0/1599 (0%)]\tLoss: 0.144175\n",
      "Train Epoch: 9 [640/1599 (40%)]\tLoss: 0.242550\n",
      "Train Epoch: 9 [1280/1599 (80%)]\tLoss: 0.189063\n",
      "Train Epoch: 10 [0/1599 (0%)]\tLoss: 0.155944\n",
      "Train Epoch: 10 [640/1599 (40%)]\tLoss: 0.080916\n",
      "Train Epoch: 10 [1280/1599 (80%)]\tLoss: 0.103024\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/5266 (0%)]\tLoss: 0.796694\n",
      "Train Epoch: 1 [640/5266 (12%)]\tLoss: 0.180305\n",
      "Train Epoch: 1 [1280/5266 (24%)]\tLoss: 0.085305\n",
      "Train Epoch: 1 [1920/5266 (36%)]\tLoss: 0.108501\n",
      "Train Epoch: 1 [2560/5266 (48%)]\tLoss: 0.146742\n",
      "Train Epoch: 1 [3200/5266 (60%)]\tLoss: 0.122475\n",
      "Train Epoch: 1 [3840/5266 (72%)]\tLoss: 0.051973\n",
      "Train Epoch: 1 [4480/5266 (84%)]\tLoss: 0.141169\n",
      "Train Epoch: 1 [5120/5266 (96%)]\tLoss: 0.120758\n",
      "Train Epoch: 2 [0/5266 (0%)]\tLoss: 0.068754\n",
      "Train Epoch: 2 [640/5266 (12%)]\tLoss: 0.027232\n",
      "Train Epoch: 2 [1280/5266 (24%)]\tLoss: 0.060322\n",
      "Train Epoch: 2 [1920/5266 (36%)]\tLoss: 0.249675\n",
      "Train Epoch: 2 [2560/5266 (48%)]\tLoss: 0.066697\n",
      "Train Epoch: 2 [3200/5266 (60%)]\tLoss: 0.058617\n",
      "Train Epoch: 2 [3840/5266 (72%)]\tLoss: 0.107821\n",
      "Train Epoch: 2 [4480/5266 (84%)]\tLoss: 0.103173\n",
      "Train Epoch: 2 [5120/5266 (96%)]\tLoss: 0.050530\n",
      "Train Epoch: 3 [0/5266 (0%)]\tLoss: 0.104172\n",
      "Train Epoch: 3 [640/5266 (12%)]\tLoss: 0.081266\n",
      "Train Epoch: 3 [1280/5266 (24%)]\tLoss: 0.073723\n",
      "Train Epoch: 3 [1920/5266 (36%)]\tLoss: 0.160445\n",
      "Train Epoch: 3 [2560/5266 (48%)]\tLoss: 0.217398\n",
      "Train Epoch: 3 [3200/5266 (60%)]\tLoss: 0.058056\n",
      "Train Epoch: 3 [3840/5266 (72%)]\tLoss: 0.053545\n",
      "Train Epoch: 3 [4480/5266 (84%)]\tLoss: 0.059353\n",
      "Train Epoch: 3 [5120/5266 (96%)]\tLoss: 0.014258\n",
      "Train Epoch: 4 [0/5266 (0%)]\tLoss: 0.111814\n",
      "Train Epoch: 4 [640/5266 (12%)]\tLoss: 0.081981\n",
      "Train Epoch: 4 [1280/5266 (24%)]\tLoss: 0.139930\n",
      "Train Epoch: 4 [1920/5266 (36%)]\tLoss: 0.014519\n",
      "Train Epoch: 4 [2560/5266 (48%)]\tLoss: 0.224486\n",
      "Train Epoch: 4 [3200/5266 (60%)]\tLoss: 0.157282\n",
      "Train Epoch: 4 [3840/5266 (72%)]\tLoss: 0.034554\n",
      "Train Epoch: 4 [4480/5266 (84%)]\tLoss: 0.066141\n",
      "Train Epoch: 4 [5120/5266 (96%)]\tLoss: 0.037179\n",
      "Train Epoch: 5 [0/5266 (0%)]\tLoss: 0.019105\n",
      "Train Epoch: 5 [640/5266 (12%)]\tLoss: 0.108293\n",
      "Train Epoch: 5 [1280/5266 (24%)]\tLoss: 0.126669\n",
      "Train Epoch: 5 [1920/5266 (36%)]\tLoss: 0.140413\n",
      "Train Epoch: 5 [2560/5266 (48%)]\tLoss: 0.054977\n",
      "Train Epoch: 5 [3200/5266 (60%)]\tLoss: 0.034605\n",
      "Train Epoch: 5 [3840/5266 (72%)]\tLoss: 0.019603\n",
      "Train Epoch: 5 [4480/5266 (84%)]\tLoss: 0.065255\n",
      "Train Epoch: 5 [5120/5266 (96%)]\tLoss: 0.044386\n",
      "Train Epoch: 6 [0/5266 (0%)]\tLoss: 0.069373\n",
      "Train Epoch: 6 [640/5266 (12%)]\tLoss: 0.124697\n",
      "Train Epoch: 6 [1280/5266 (24%)]\tLoss: 0.024772\n",
      "Train Epoch: 6 [1920/5266 (36%)]\tLoss: 0.110943\n",
      "Train Epoch: 6 [2560/5266 (48%)]\tLoss: 0.126908\n",
      "Train Epoch: 6 [3200/5266 (60%)]\tLoss: 0.113496\n",
      "Train Epoch: 6 [3840/5266 (72%)]\tLoss: 0.122896\n",
      "Train Epoch: 6 [4480/5266 (84%)]\tLoss: 0.011731\n",
      "Train Epoch: 6 [5120/5266 (96%)]\tLoss: 0.060535\n",
      "Train Epoch: 7 [0/5266 (0%)]\tLoss: 0.092921\n",
      "Train Epoch: 7 [640/5266 (12%)]\tLoss: 0.097914\n",
      "Train Epoch: 7 [1280/5266 (24%)]\tLoss: 0.084900\n",
      "Train Epoch: 7 [1920/5266 (36%)]\tLoss: 0.107551\n",
      "Train Epoch: 7 [2560/5266 (48%)]\tLoss: 0.043891\n",
      "Train Epoch: 7 [3200/5266 (60%)]\tLoss: 0.085744\n",
      "Train Epoch: 7 [3840/5266 (72%)]\tLoss: 0.002388\n",
      "Train Epoch: 7 [4480/5266 (84%)]\tLoss: 0.053965\n",
      "Train Epoch: 7 [5120/5266 (96%)]\tLoss: 0.125741\n",
      "Train Epoch: 8 [0/5266 (0%)]\tLoss: 0.100246\n",
      "Train Epoch: 8 [640/5266 (12%)]\tLoss: 0.106399\n",
      "Train Epoch: 8 [1280/5266 (24%)]\tLoss: 0.043024\n",
      "Train Epoch: 8 [1920/5266 (36%)]\tLoss: 0.002936\n",
      "Train Epoch: 8 [2560/5266 (48%)]\tLoss: 0.056827\n",
      "Train Epoch: 8 [3200/5266 (60%)]\tLoss: 0.060223\n",
      "Train Epoch: 8 [3840/5266 (72%)]\tLoss: 0.028175\n",
      "Train Epoch: 8 [4480/5266 (84%)]\tLoss: 0.025732\n",
      "Train Epoch: 8 [5120/5266 (96%)]\tLoss: 0.063329\n",
      "Train Epoch: 9 [0/5266 (0%)]\tLoss: 0.040158\n",
      "Train Epoch: 9 [640/5266 (12%)]\tLoss: 0.038384\n",
      "Train Epoch: 9 [1280/5266 (24%)]\tLoss: 0.079764\n",
      "Train Epoch: 9 [1920/5266 (36%)]\tLoss: 0.021683\n",
      "Train Epoch: 9 [2560/5266 (48%)]\tLoss: 0.088201\n",
      "Train Epoch: 9 [3200/5266 (60%)]\tLoss: 0.039488\n",
      "Train Epoch: 9 [3840/5266 (72%)]\tLoss: 0.139154\n",
      "Train Epoch: 9 [4480/5266 (84%)]\tLoss: 0.116094\n",
      "Train Epoch: 9 [5120/5266 (96%)]\tLoss: 0.108568\n",
      "Train Epoch: 10 [0/5266 (0%)]\tLoss: 0.041967\n",
      "Train Epoch: 10 [640/5266 (12%)]\tLoss: 0.064602\n",
      "Train Epoch: 10 [1280/5266 (24%)]\tLoss: 0.100534\n",
      "Train Epoch: 10 [1920/5266 (36%)]\tLoss: 0.115300\n",
      "Train Epoch: 10 [2560/5266 (48%)]\tLoss: 0.041844\n",
      "Train Epoch: 10 [3200/5266 (60%)]\tLoss: 0.043397\n",
      "Train Epoch: 10 [3840/5266 (72%)]\tLoss: 0.098929\n",
      "Train Epoch: 10 [4480/5266 (84%)]\tLoss: 0.170687\n",
      "Train Epoch: 10 [5120/5266 (96%)]\tLoss: 0.058483\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/3530 (0%)]\tLoss: 0.543099\n",
      "Train Epoch: 1 [640/3530 (18%)]\tLoss: 0.364847\n",
      "Train Epoch: 1 [1280/3530 (36%)]\tLoss: 0.218788\n",
      "Train Epoch: 1 [1920/3530 (54%)]\tLoss: 0.245497\n",
      "Train Epoch: 1 [2560/3530 (71%)]\tLoss: 0.328583\n",
      "Train Epoch: 1 [3200/3530 (89%)]\tLoss: 0.228641\n",
      "Train Epoch: 2 [0/3530 (0%)]\tLoss: 0.453897\n",
      "Train Epoch: 2 [640/3530 (18%)]\tLoss: 0.423021\n",
      "Train Epoch: 2 [1280/3530 (36%)]\tLoss: 0.264372\n",
      "Train Epoch: 2 [1920/3530 (54%)]\tLoss: 0.343046\n",
      "Train Epoch: 2 [2560/3530 (71%)]\tLoss: 0.177080\n",
      "Train Epoch: 2 [3200/3530 (89%)]\tLoss: 0.360667\n",
      "Train Epoch: 3 [0/3530 (0%)]\tLoss: 0.169473\n",
      "Train Epoch: 3 [640/3530 (18%)]\tLoss: 0.458350\n",
      "Train Epoch: 3 [1280/3530 (36%)]\tLoss: 0.129533\n",
      "Train Epoch: 3 [1920/3530 (54%)]\tLoss: 0.114316\n",
      "Train Epoch: 3 [2560/3530 (71%)]\tLoss: 0.271196\n",
      "Train Epoch: 3 [3200/3530 (89%)]\tLoss: 0.477571\n",
      "Train Epoch: 4 [0/3530 (0%)]\tLoss: 0.200080\n",
      "Train Epoch: 4 [640/3530 (18%)]\tLoss: 0.203067\n",
      "Train Epoch: 4 [1280/3530 (36%)]\tLoss: 0.175802\n",
      "Train Epoch: 4 [1920/3530 (54%)]\tLoss: 0.188110\n",
      "Train Epoch: 4 [2560/3530 (71%)]\tLoss: 0.056365\n",
      "Train Epoch: 4 [3200/3530 (89%)]\tLoss: 0.252301\n",
      "Train Epoch: 5 [0/3530 (0%)]\tLoss: 0.232076\n",
      "Train Epoch: 5 [640/3530 (18%)]\tLoss: 0.227458\n",
      "Train Epoch: 5 [1280/3530 (36%)]\tLoss: 0.157469\n",
      "Train Epoch: 5 [1920/3530 (54%)]\tLoss: 0.286391\n",
      "Train Epoch: 5 [2560/3530 (71%)]\tLoss: 0.402025\n",
      "Train Epoch: 5 [3200/3530 (89%)]\tLoss: 0.169553\n",
      "Train Epoch: 6 [0/3530 (0%)]\tLoss: 0.304917\n",
      "Train Epoch: 6 [640/3530 (18%)]\tLoss: 0.295023\n",
      "Train Epoch: 6 [1280/3530 (36%)]\tLoss: 0.150702\n",
      "Train Epoch: 6 [1920/3530 (54%)]\tLoss: 0.199785\n",
      "Train Epoch: 6 [2560/3530 (71%)]\tLoss: 0.193761\n",
      "Train Epoch: 6 [3200/3530 (89%)]\tLoss: 0.254200\n",
      "Train Epoch: 7 [0/3530 (0%)]\tLoss: 0.161418\n",
      "Train Epoch: 7 [640/3530 (18%)]\tLoss: 0.127027\n",
      "Train Epoch: 7 [1280/3530 (36%)]\tLoss: 0.067812\n",
      "Train Epoch: 7 [1920/3530 (54%)]\tLoss: 0.220934\n",
      "Train Epoch: 7 [2560/3530 (71%)]\tLoss: 0.138453\n",
      "Train Epoch: 7 [3200/3530 (89%)]\tLoss: 0.225449\n",
      "Train Epoch: 8 [0/3530 (0%)]\tLoss: 0.183825\n",
      "Train Epoch: 8 [640/3530 (18%)]\tLoss: 0.198482\n",
      "Train Epoch: 8 [1280/3530 (36%)]\tLoss: 0.139949\n",
      "Train Epoch: 8 [1920/3530 (54%)]\tLoss: 0.225682\n",
      "Train Epoch: 8 [2560/3530 (71%)]\tLoss: 0.070694\n",
      "Train Epoch: 8 [3200/3530 (89%)]\tLoss: 0.112895\n",
      "Train Epoch: 9 [0/3530 (0%)]\tLoss: 0.175856\n",
      "Train Epoch: 9 [640/3530 (18%)]\tLoss: 0.166275\n",
      "Train Epoch: 9 [1280/3530 (36%)]\tLoss: 0.099355\n",
      "Train Epoch: 9 [1920/3530 (54%)]\tLoss: 0.215609\n",
      "Train Epoch: 9 [2560/3530 (71%)]\tLoss: 0.118807\n",
      "Train Epoch: 9 [3200/3530 (89%)]\tLoss: 0.156240\n",
      "Train Epoch: 10 [0/3530 (0%)]\tLoss: 0.124662\n",
      "Train Epoch: 10 [640/3530 (18%)]\tLoss: 0.151062\n",
      "Train Epoch: 10 [1280/3530 (36%)]\tLoss: 0.056227\n",
      "Train Epoch: 10 [1920/3530 (54%)]\tLoss: 0.142867\n",
      "Train Epoch: 10 [2560/3530 (71%)]\tLoss: 0.283437\n",
      "Train Epoch: 10 [3200/3530 (89%)]\tLoss: 0.158252\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.7735, Accuracy: 9439/10000 (94%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 0.630743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 0.193285\n",
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 0.417640\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 0.324637\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 0.365713\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 0.318011\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 0.155222\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 0.275114\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 0.146484\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 0.116218\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 0.194644\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 0.181733\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 0.527763\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 0.189143\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 0.154969\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 0.320104\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 0.321695\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 0.106995\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 0.104865\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 0.223846\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.447480\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 0.173417\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 0.126484\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.363986\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.268648\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 0.193776\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.183425\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 0.249145\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.287597\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.154064\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.025459\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.094505\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.203252\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.197256\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.080393\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.070875\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.206943\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.109859\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.246242\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.170779\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.071876\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.139614\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.209211\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.127376\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.295677\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.138410\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.165155\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.062745\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.365532\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.156085\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.087135\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.170498\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.137972\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.042994\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.139594\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.110715\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.123779\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.307395\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.079979\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.250061\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.123267\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.066469\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.063223\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.174349\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.162268\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.311020\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.093633\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.326126\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.228167\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.122529\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.090000\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.197521\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.169677\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.436725\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.104740\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.118052\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.063675\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.376513\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.209057\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.267080\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.062330\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.156567\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.209369\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.137528\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.280099\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.176760\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.226419\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.352459\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.186170\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.244434\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.182481\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.097882\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.111872\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.055733\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.174959\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.068251\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.126310\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.115438\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.093563\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.047011\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.250193\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.099114\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.084602\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.123398\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.056463\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.153853\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.080223\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.164511\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 0.167339\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.131289\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.162105\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.280685\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.091726\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.078580\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.146290\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.235652\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.064046\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.046900\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.128893\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.149045\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.196918\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.065922\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.161602\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.170177\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.055610\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.065042\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.097624\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.204198\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.054138\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.118152\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.156114\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.088243\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.115291\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.291130\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.198021\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.172153\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.205471\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.146366\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.090763\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.050027\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.136444\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.117014\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.016990\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.262652\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.057307\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.094907\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.127210\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.283520\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.097490\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.449920\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.158790\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.212749\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.259743\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.124554\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.096608\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.076417\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.072144\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.105953\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.135185\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.136682\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.035895\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.068308\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.334736\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.135387\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.083910\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.145510\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.114806\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.303061\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.085467\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.146013\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.112190\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.071226\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.193425\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.087944\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.080256\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.126401\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.030870\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.105600\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.027007\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.095807\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/5110 (0%)]\tLoss: 0.385591\n",
      "Train Epoch: 1 [640/5110 (12%)]\tLoss: 0.225624\n",
      "Train Epoch: 1 [1280/5110 (25%)]\tLoss: 0.252311\n",
      "Train Epoch: 1 [1920/5110 (38%)]\tLoss: 0.153695\n",
      "Train Epoch: 1 [2560/5110 (50%)]\tLoss: 0.074005\n",
      "Train Epoch: 1 [3200/5110 (62%)]\tLoss: 0.341467\n",
      "Train Epoch: 1 [3840/5110 (75%)]\tLoss: 0.359231\n",
      "Train Epoch: 1 [4480/5110 (88%)]\tLoss: 0.170924\n",
      "Train Epoch: 2 [0/5110 (0%)]\tLoss: 0.185937\n",
      "Train Epoch: 2 [640/5110 (12%)]\tLoss: 0.124598\n",
      "Train Epoch: 2 [1280/5110 (25%)]\tLoss: 0.171737\n",
      "Train Epoch: 2 [1920/5110 (38%)]\tLoss: 0.114955\n",
      "Train Epoch: 2 [2560/5110 (50%)]\tLoss: 0.180859\n",
      "Train Epoch: 2 [3200/5110 (62%)]\tLoss: 0.196119\n",
      "Train Epoch: 2 [3840/5110 (75%)]\tLoss: 0.102919\n",
      "Train Epoch: 2 [4480/5110 (88%)]\tLoss: 0.179624\n",
      "Train Epoch: 3 [0/5110 (0%)]\tLoss: 0.288585\n",
      "Train Epoch: 3 [640/5110 (12%)]\tLoss: 0.150740\n",
      "Train Epoch: 3 [1280/5110 (25%)]\tLoss: 0.058860\n",
      "Train Epoch: 3 [1920/5110 (38%)]\tLoss: 0.113586\n",
      "Train Epoch: 3 [2560/5110 (50%)]\tLoss: 0.212812\n",
      "Train Epoch: 3 [3200/5110 (62%)]\tLoss: 0.125020\n",
      "Train Epoch: 3 [3840/5110 (75%)]\tLoss: 0.038512\n",
      "Train Epoch: 3 [4480/5110 (88%)]\tLoss: 0.140943\n",
      "Train Epoch: 4 [0/5110 (0%)]\tLoss: 0.308189\n",
      "Train Epoch: 4 [640/5110 (12%)]\tLoss: 0.313681\n",
      "Train Epoch: 4 [1280/5110 (25%)]\tLoss: 0.145689\n",
      "Train Epoch: 4 [1920/5110 (38%)]\tLoss: 0.107322\n",
      "Train Epoch: 4 [2560/5110 (50%)]\tLoss: 0.083393\n",
      "Train Epoch: 4 [3200/5110 (62%)]\tLoss: 0.134936\n",
      "Train Epoch: 4 [3840/5110 (75%)]\tLoss: 0.167430\n",
      "Train Epoch: 4 [4480/5110 (88%)]\tLoss: 0.042183\n",
      "Train Epoch: 5 [0/5110 (0%)]\tLoss: 0.116690\n",
      "Train Epoch: 5 [640/5110 (12%)]\tLoss: 0.183914\n",
      "Train Epoch: 5 [1280/5110 (25%)]\tLoss: 0.076680\n",
      "Train Epoch: 5 [1920/5110 (38%)]\tLoss: 0.350702\n",
      "Train Epoch: 5 [2560/5110 (50%)]\tLoss: 0.037943\n",
      "Train Epoch: 5 [3200/5110 (62%)]\tLoss: 0.294738\n",
      "Train Epoch: 5 [3840/5110 (75%)]\tLoss: 0.124890\n",
      "Train Epoch: 5 [4480/5110 (88%)]\tLoss: 0.177424\n",
      "Train Epoch: 6 [0/5110 (0%)]\tLoss: 0.173939\n",
      "Train Epoch: 6 [640/5110 (12%)]\tLoss: 0.156312\n",
      "Train Epoch: 6 [1280/5110 (25%)]\tLoss: 0.175336\n",
      "Train Epoch: 6 [1920/5110 (38%)]\tLoss: 0.085792\n",
      "Train Epoch: 6 [2560/5110 (50%)]\tLoss: 0.147389\n",
      "Train Epoch: 6 [3200/5110 (62%)]\tLoss: 0.235669\n",
      "Train Epoch: 6 [3840/5110 (75%)]\tLoss: 0.221886\n",
      "Train Epoch: 6 [4480/5110 (88%)]\tLoss: 0.141175\n",
      "Train Epoch: 7 [0/5110 (0%)]\tLoss: 0.163128\n",
      "Train Epoch: 7 [640/5110 (12%)]\tLoss: 0.074298\n",
      "Train Epoch: 7 [1280/5110 (25%)]\tLoss: 0.111787\n",
      "Train Epoch: 7 [1920/5110 (38%)]\tLoss: 0.151364\n",
      "Train Epoch: 7 [2560/5110 (50%)]\tLoss: 0.130990\n",
      "Train Epoch: 7 [3200/5110 (62%)]\tLoss: 0.086592\n",
      "Train Epoch: 7 [3840/5110 (75%)]\tLoss: 0.288493\n",
      "Train Epoch: 7 [4480/5110 (88%)]\tLoss: 0.154120\n",
      "Train Epoch: 8 [0/5110 (0%)]\tLoss: 0.140774\n",
      "Train Epoch: 8 [640/5110 (12%)]\tLoss: 0.103194\n",
      "Train Epoch: 8 [1280/5110 (25%)]\tLoss: 0.179619\n",
      "Train Epoch: 8 [1920/5110 (38%)]\tLoss: 0.070250\n",
      "Train Epoch: 8 [2560/5110 (50%)]\tLoss: 0.221023\n",
      "Train Epoch: 8 [3200/5110 (62%)]\tLoss: 0.108715\n",
      "Train Epoch: 8 [3840/5110 (75%)]\tLoss: 0.172764\n",
      "Train Epoch: 8 [4480/5110 (88%)]\tLoss: 0.061854\n",
      "Train Epoch: 9 [0/5110 (0%)]\tLoss: 0.259099\n",
      "Train Epoch: 9 [640/5110 (12%)]\tLoss: 0.100780\n",
      "Train Epoch: 9 [1280/5110 (25%)]\tLoss: 0.035198\n",
      "Train Epoch: 9 [1920/5110 (38%)]\tLoss: 0.185062\n",
      "Train Epoch: 9 [2560/5110 (50%)]\tLoss: 0.206034\n",
      "Train Epoch: 9 [3200/5110 (62%)]\tLoss: 0.090210\n",
      "Train Epoch: 9 [3840/5110 (75%)]\tLoss: 0.139021\n",
      "Train Epoch: 9 [4480/5110 (88%)]\tLoss: 0.076598\n",
      "Train Epoch: 10 [0/5110 (0%)]\tLoss: 0.052143\n",
      "Train Epoch: 10 [640/5110 (12%)]\tLoss: 0.042508\n",
      "Train Epoch: 10 [1280/5110 (25%)]\tLoss: 0.084461\n",
      "Train Epoch: 10 [1920/5110 (38%)]\tLoss: 0.079460\n",
      "Train Epoch: 10 [2560/5110 (50%)]\tLoss: 0.042105\n",
      "Train Epoch: 10 [3200/5110 (62%)]\tLoss: 0.108357\n",
      "Train Epoch: 10 [3840/5110 (75%)]\tLoss: 0.071923\n",
      "Train Epoch: 10 [4480/5110 (88%)]\tLoss: 0.092536\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6766 (0%)]\tLoss: 0.377774\n",
      "Train Epoch: 1 [640/6766 (9%)]\tLoss: 0.227129\n",
      "Train Epoch: 1 [1280/6766 (19%)]\tLoss: 0.267665\n",
      "Train Epoch: 1 [1920/6766 (28%)]\tLoss: 0.107156\n",
      "Train Epoch: 1 [2560/6766 (38%)]\tLoss: 0.181114\n",
      "Train Epoch: 1 [3200/6766 (47%)]\tLoss: 0.188298\n",
      "Train Epoch: 1 [3840/6766 (57%)]\tLoss: 0.303798\n",
      "Train Epoch: 1 [4480/6766 (66%)]\tLoss: 0.085493\n",
      "Train Epoch: 1 [5120/6766 (75%)]\tLoss: 0.102091\n",
      "Train Epoch: 1 [5760/6766 (85%)]\tLoss: 0.240970\n",
      "Train Epoch: 1 [6400/6766 (94%)]\tLoss: 0.148717\n",
      "Train Epoch: 2 [0/6766 (0%)]\tLoss: 0.100639\n",
      "Train Epoch: 2 [640/6766 (9%)]\tLoss: 0.245800\n",
      "Train Epoch: 2 [1280/6766 (19%)]\tLoss: 0.070424\n",
      "Train Epoch: 2 [1920/6766 (28%)]\tLoss: 0.314170\n",
      "Train Epoch: 2 [2560/6766 (38%)]\tLoss: 0.061661\n",
      "Train Epoch: 2 [3200/6766 (47%)]\tLoss: 0.043390\n",
      "Train Epoch: 2 [3840/6766 (57%)]\tLoss: 0.134502\n",
      "Train Epoch: 2 [4480/6766 (66%)]\tLoss: 0.081183\n",
      "Train Epoch: 2 [5120/6766 (75%)]\tLoss: 0.062274\n",
      "Train Epoch: 2 [5760/6766 (85%)]\tLoss: 0.077884\n",
      "Train Epoch: 2 [6400/6766 (94%)]\tLoss: 0.240433\n",
      "Train Epoch: 3 [0/6766 (0%)]\tLoss: 0.183315\n",
      "Train Epoch: 3 [640/6766 (9%)]\tLoss: 0.081124\n",
      "Train Epoch: 3 [1280/6766 (19%)]\tLoss: 0.092887\n",
      "Train Epoch: 3 [1920/6766 (28%)]\tLoss: 0.069614\n",
      "Train Epoch: 3 [2560/6766 (38%)]\tLoss: 0.034051\n",
      "Train Epoch: 3 [3200/6766 (47%)]\tLoss: 0.028723\n",
      "Train Epoch: 3 [3840/6766 (57%)]\tLoss: 0.115533\n",
      "Train Epoch: 3 [4480/6766 (66%)]\tLoss: 0.163422\n",
      "Train Epoch: 3 [5120/6766 (75%)]\tLoss: 0.331527\n",
      "Train Epoch: 3 [5760/6766 (85%)]\tLoss: 0.059268\n",
      "Train Epoch: 3 [6400/6766 (94%)]\tLoss: 0.044769\n",
      "Train Epoch: 4 [0/6766 (0%)]\tLoss: 0.062836\n",
      "Train Epoch: 4 [640/6766 (9%)]\tLoss: 0.173919\n",
      "Train Epoch: 4 [1280/6766 (19%)]\tLoss: 0.082990\n",
      "Train Epoch: 4 [1920/6766 (28%)]\tLoss: 0.199356\n",
      "Train Epoch: 4 [2560/6766 (38%)]\tLoss: 0.086717\n",
      "Train Epoch: 4 [3200/6766 (47%)]\tLoss: 0.149548\n",
      "Train Epoch: 4 [3840/6766 (57%)]\tLoss: 0.084160\n",
      "Train Epoch: 4 [4480/6766 (66%)]\tLoss: 0.156960\n",
      "Train Epoch: 4 [5120/6766 (75%)]\tLoss: 0.069130\n",
      "Train Epoch: 4 [5760/6766 (85%)]\tLoss: 0.262313\n",
      "Train Epoch: 4 [6400/6766 (94%)]\tLoss: 0.150471\n",
      "Train Epoch: 5 [0/6766 (0%)]\tLoss: 0.064791\n",
      "Train Epoch: 5 [640/6766 (9%)]\tLoss: 0.185746\n",
      "Train Epoch: 5 [1280/6766 (19%)]\tLoss: 0.148317\n",
      "Train Epoch: 5 [1920/6766 (28%)]\tLoss: 0.071526\n",
      "Train Epoch: 5 [2560/6766 (38%)]\tLoss: 0.080188\n",
      "Train Epoch: 5 [3200/6766 (47%)]\tLoss: 0.216934\n",
      "Train Epoch: 5 [3840/6766 (57%)]\tLoss: 0.034875\n",
      "Train Epoch: 5 [4480/6766 (66%)]\tLoss: 0.139122\n",
      "Train Epoch: 5 [5120/6766 (75%)]\tLoss: 0.107615\n",
      "Train Epoch: 5 [5760/6766 (85%)]\tLoss: 0.080788\n",
      "Train Epoch: 5 [6400/6766 (94%)]\tLoss: 0.051681\n",
      "Train Epoch: 6 [0/6766 (0%)]\tLoss: 0.014037\n",
      "Train Epoch: 6 [640/6766 (9%)]\tLoss: 0.114134\n",
      "Train Epoch: 6 [1280/6766 (19%)]\tLoss: 0.125817\n",
      "Train Epoch: 6 [1920/6766 (28%)]\tLoss: 0.219798\n",
      "Train Epoch: 6 [2560/6766 (38%)]\tLoss: 0.125720\n",
      "Train Epoch: 6 [3200/6766 (47%)]\tLoss: 0.221994\n",
      "Train Epoch: 6 [3840/6766 (57%)]\tLoss: 0.088541\n",
      "Train Epoch: 6 [4480/6766 (66%)]\tLoss: 0.165066\n",
      "Train Epoch: 6 [5120/6766 (75%)]\tLoss: 0.179237\n",
      "Train Epoch: 6 [5760/6766 (85%)]\tLoss: 0.260734\n",
      "Train Epoch: 6 [6400/6766 (94%)]\tLoss: 0.182364\n",
      "Train Epoch: 7 [0/6766 (0%)]\tLoss: 0.029960\n",
      "Train Epoch: 7 [640/6766 (9%)]\tLoss: 0.061188\n",
      "Train Epoch: 7 [1280/6766 (19%)]\tLoss: 0.267857\n",
      "Train Epoch: 7 [1920/6766 (28%)]\tLoss: 0.459800\n",
      "Train Epoch: 7 [2560/6766 (38%)]\tLoss: 0.089183\n",
      "Train Epoch: 7 [3200/6766 (47%)]\tLoss: 0.029641\n",
      "Train Epoch: 7 [3840/6766 (57%)]\tLoss: 0.063746\n",
      "Train Epoch: 7 [4480/6766 (66%)]\tLoss: 0.042955\n",
      "Train Epoch: 7 [5120/6766 (75%)]\tLoss: 0.043241\n",
      "Train Epoch: 7 [5760/6766 (85%)]\tLoss: 0.204613\n",
      "Train Epoch: 7 [6400/6766 (94%)]\tLoss: 0.024060\n",
      "Train Epoch: 8 [0/6766 (0%)]\tLoss: 0.070379\n",
      "Train Epoch: 8 [640/6766 (9%)]\tLoss: 0.019326\n",
      "Train Epoch: 8 [1280/6766 (19%)]\tLoss: 0.047152\n",
      "Train Epoch: 8 [1920/6766 (28%)]\tLoss: 0.086016\n",
      "Train Epoch: 8 [2560/6766 (38%)]\tLoss: 0.071325\n",
      "Train Epoch: 8 [3200/6766 (47%)]\tLoss: 0.098354\n",
      "Train Epoch: 8 [3840/6766 (57%)]\tLoss: 0.012935\n",
      "Train Epoch: 8 [4480/6766 (66%)]\tLoss: 0.085838\n",
      "Train Epoch: 8 [5120/6766 (75%)]\tLoss: 0.063430\n",
      "Train Epoch: 8 [5760/6766 (85%)]\tLoss: 0.083659\n",
      "Train Epoch: 8 [6400/6766 (94%)]\tLoss: 0.033944\n",
      "Train Epoch: 9 [0/6766 (0%)]\tLoss: 0.040634\n",
      "Train Epoch: 9 [640/6766 (9%)]\tLoss: 0.017784\n",
      "Train Epoch: 9 [1280/6766 (19%)]\tLoss: 0.048402\n",
      "Train Epoch: 9 [1920/6766 (28%)]\tLoss: 0.139650\n",
      "Train Epoch: 9 [2560/6766 (38%)]\tLoss: 0.112946\n",
      "Train Epoch: 9 [3200/6766 (47%)]\tLoss: 0.114297\n",
      "Train Epoch: 9 [3840/6766 (57%)]\tLoss: 0.033203\n",
      "Train Epoch: 9 [4480/6766 (66%)]\tLoss: 0.030964\n",
      "Train Epoch: 9 [5120/6766 (75%)]\tLoss: 0.067220\n",
      "Train Epoch: 9 [5760/6766 (85%)]\tLoss: 0.072131\n",
      "Train Epoch: 9 [6400/6766 (94%)]\tLoss: 0.082485\n",
      "Train Epoch: 10 [0/6766 (0%)]\tLoss: 0.052343\n",
      "Train Epoch: 10 [640/6766 (9%)]\tLoss: 0.105015\n",
      "Train Epoch: 10 [1280/6766 (19%)]\tLoss: 0.112336\n",
      "Train Epoch: 10 [1920/6766 (28%)]\tLoss: 0.050101\n",
      "Train Epoch: 10 [2560/6766 (38%)]\tLoss: 0.053358\n",
      "Train Epoch: 10 [3200/6766 (47%)]\tLoss: 0.224854\n",
      "Train Epoch: 10 [3840/6766 (57%)]\tLoss: 0.043151\n",
      "Train Epoch: 10 [4480/6766 (66%)]\tLoss: 0.079943\n",
      "Train Epoch: 10 [5120/6766 (75%)]\tLoss: 0.068382\n",
      "Train Epoch: 10 [5760/6766 (85%)]\tLoss: 0.114813\n",
      "Train Epoch: 10 [6400/6766 (94%)]\tLoss: 0.008451\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 0.393238\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 0.164507\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 0.113864\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 0.299624\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 0.253523\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 0.120221\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 0.065199\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 0.241547\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 0.206647\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 0.061251\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 0.253925\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 0.095187\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 0.215518\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 0.110662\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 0.140230\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 0.117102\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 0.147181\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.096592\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.074309\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.051538\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.295135\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.096039\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.080822\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.099693\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.213688\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.205979\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.232073\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.118002\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.178644\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.164520\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.139248\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.176299\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.245705\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.083953\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.173152\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.102151\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.159499\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.349157\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.105245\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.133981\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.269277\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.050394\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.068028\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.297739\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.087751\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.102962\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.058336\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.205729\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.171500\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.155313\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.146262\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.159618\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.020800\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.073962\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.031390\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.046321\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.103295\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.067633\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.227933\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.112164\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.128773\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.102309\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.095644\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.112439\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.032454\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.058362\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.141985\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.160230\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.133862\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.137488\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.149178\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.132045\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.319575\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.209642\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.156883\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.075374\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.182549\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.063060\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.079028\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.041971\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.066827\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.148386\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.283018\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.102939\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.084125\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.340151\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.110157\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.164227\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.078120\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.084736\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.028183\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.122623\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.091360\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.058382\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.222410\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.089059\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.117791\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.065717\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.068501\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.106934\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.033964\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.164338\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.042536\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.079647\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.163152\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.031124\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.039317\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.144775\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.060825\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.146779\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.028655\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.031754\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.088699\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.057136\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.137939\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.105986\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.059073\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.035546\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.067662\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.066201\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.094277\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.166714\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.228039\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.057565\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.171112\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.054582\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.175995\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.171553\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.056181\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.155827\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.148577\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.197473\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.192166\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.113167\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.057968\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.231617\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.136205\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.067150\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.054939\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.094333\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.015022\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.086164\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.194286\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.094685\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.169294\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.075726\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.049555\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.144924\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.158159\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.227719\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.095189\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.074259\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.127525\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.251245\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.053321\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.090748\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.059354\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.172807\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.174255\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.013020\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/3910 (0%)]\tLoss: 0.442108\n",
      "Train Epoch: 1 [640/3910 (16%)]\tLoss: 0.171742\n",
      "Train Epoch: 1 [1280/3910 (32%)]\tLoss: 0.223861\n",
      "Train Epoch: 1 [1920/3910 (48%)]\tLoss: 0.111254\n",
      "Train Epoch: 1 [2560/3910 (65%)]\tLoss: 0.224997\n",
      "Train Epoch: 1 [3200/3910 (81%)]\tLoss: 0.308472\n",
      "Train Epoch: 1 [3840/3910 (97%)]\tLoss: 0.131620\n",
      "Train Epoch: 2 [0/3910 (0%)]\tLoss: 0.302138\n",
      "Train Epoch: 2 [640/3910 (16%)]\tLoss: 0.147914\n",
      "Train Epoch: 2 [1280/3910 (32%)]\tLoss: 0.176562\n",
      "Train Epoch: 2 [1920/3910 (48%)]\tLoss: 0.091690\n",
      "Train Epoch: 2 [2560/3910 (65%)]\tLoss: 0.215422\n",
      "Train Epoch: 2 [3200/3910 (81%)]\tLoss: 0.234067\n",
      "Train Epoch: 2 [3840/3910 (97%)]\tLoss: 0.100487\n",
      "Train Epoch: 3 [0/3910 (0%)]\tLoss: 0.362252\n",
      "Train Epoch: 3 [640/3910 (16%)]\tLoss: 0.222949\n",
      "Train Epoch: 3 [1280/3910 (32%)]\tLoss: 0.045692\n",
      "Train Epoch: 3 [1920/3910 (48%)]\tLoss: 0.177471\n",
      "Train Epoch: 3 [2560/3910 (65%)]\tLoss: 0.187850\n",
      "Train Epoch: 3 [3200/3910 (81%)]\tLoss: 0.080337\n",
      "Train Epoch: 3 [3840/3910 (97%)]\tLoss: 0.097792\n",
      "Train Epoch: 4 [0/3910 (0%)]\tLoss: 0.130637\n",
      "Train Epoch: 4 [640/3910 (16%)]\tLoss: 0.123356\n",
      "Train Epoch: 4 [1280/3910 (32%)]\tLoss: 0.278202\n",
      "Train Epoch: 4 [1920/3910 (48%)]\tLoss: 0.110723\n",
      "Train Epoch: 4 [2560/3910 (65%)]\tLoss: 0.122955\n",
      "Train Epoch: 4 [3200/3910 (81%)]\tLoss: 0.146792\n",
      "Train Epoch: 4 [3840/3910 (97%)]\tLoss: 0.087305\n",
      "Train Epoch: 5 [0/3910 (0%)]\tLoss: 0.062414\n",
      "Train Epoch: 5 [640/3910 (16%)]\tLoss: 0.068507\n",
      "Train Epoch: 5 [1280/3910 (32%)]\tLoss: 0.086407\n",
      "Train Epoch: 5 [1920/3910 (48%)]\tLoss: 0.113719\n",
      "Train Epoch: 5 [2560/3910 (65%)]\tLoss: 0.122237\n",
      "Train Epoch: 5 [3200/3910 (81%)]\tLoss: 0.064480\n",
      "Train Epoch: 5 [3840/3910 (97%)]\tLoss: 0.135260\n",
      "Train Epoch: 6 [0/3910 (0%)]\tLoss: 0.083395\n",
      "Train Epoch: 6 [640/3910 (16%)]\tLoss: 0.159628\n",
      "Train Epoch: 6 [1280/3910 (32%)]\tLoss: 0.109737\n",
      "Train Epoch: 6 [1920/3910 (48%)]\tLoss: 0.299420\n",
      "Train Epoch: 6 [2560/3910 (65%)]\tLoss: 0.192906\n",
      "Train Epoch: 6 [3200/3910 (81%)]\tLoss: 0.114891\n",
      "Train Epoch: 6 [3840/3910 (97%)]\tLoss: 0.178951\n",
      "Train Epoch: 7 [0/3910 (0%)]\tLoss: 0.150398\n",
      "Train Epoch: 7 [640/3910 (16%)]\tLoss: 0.069295\n",
      "Train Epoch: 7 [1280/3910 (32%)]\tLoss: 0.130436\n",
      "Train Epoch: 7 [1920/3910 (48%)]\tLoss: 0.195659\n",
      "Train Epoch: 7 [2560/3910 (65%)]\tLoss: 0.147228\n",
      "Train Epoch: 7 [3200/3910 (81%)]\tLoss: 0.065286\n",
      "Train Epoch: 7 [3840/3910 (97%)]\tLoss: 0.080818\n",
      "Train Epoch: 8 [0/3910 (0%)]\tLoss: 0.128453\n",
      "Train Epoch: 8 [640/3910 (16%)]\tLoss: 0.108378\n",
      "Train Epoch: 8 [1280/3910 (32%)]\tLoss: 0.026119\n",
      "Train Epoch: 8 [1920/3910 (48%)]\tLoss: 0.110686\n",
      "Train Epoch: 8 [2560/3910 (65%)]\tLoss: 0.062922\n",
      "Train Epoch: 8 [3200/3910 (81%)]\tLoss: 0.079706\n",
      "Train Epoch: 8 [3840/3910 (97%)]\tLoss: 0.269138\n",
      "Train Epoch: 9 [0/3910 (0%)]\tLoss: 0.082590\n",
      "Train Epoch: 9 [640/3910 (16%)]\tLoss: 0.123244\n",
      "Train Epoch: 9 [1280/3910 (32%)]\tLoss: 0.131522\n",
      "Train Epoch: 9 [1920/3910 (48%)]\tLoss: 0.148981\n",
      "Train Epoch: 9 [2560/3910 (65%)]\tLoss: 0.088137\n",
      "Train Epoch: 9 [3200/3910 (81%)]\tLoss: 0.204501\n",
      "Train Epoch: 9 [3840/3910 (97%)]\tLoss: 0.104497\n",
      "Train Epoch: 10 [0/3910 (0%)]\tLoss: 0.062606\n",
      "Train Epoch: 10 [640/3910 (16%)]\tLoss: 0.070008\n",
      "Train Epoch: 10 [1280/3910 (32%)]\tLoss: 0.095904\n",
      "Train Epoch: 10 [1920/3910 (48%)]\tLoss: 0.255476\n",
      "Train Epoch: 10 [2560/3910 (65%)]\tLoss: 0.108346\n",
      "Train Epoch: 10 [3200/3910 (81%)]\tLoss: 0.202207\n",
      "Train Epoch: 10 [3840/3910 (97%)]\tLoss: 0.221657\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 0.610254\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 0.180017\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 0.117386\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 0.221027\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 0.137929\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 0.113066\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 0.163485\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 0.208765\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 0.107457\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 0.152355\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.067032\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.115249\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 0.171179\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 0.110457\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 0.089910\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.082397\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.086152\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.232908\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.332874\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.161953\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.045968\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.255866\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.058086\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.298609\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.089596\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.080200\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.065651\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.250162\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.061370\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.148462\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.110727\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.161277\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.108463\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.060934\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.221609\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.041511\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.223028\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.121970\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.075840\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.025636\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.036994\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.037820\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.095774\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.086484\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.051080\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.080590\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.124470\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.049110\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.063627\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.031367\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.096434\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.104149\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.202705\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.026911\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.032994\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.071261\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.167222\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.094085\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.064491\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.062260\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.043170\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.077625\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.085431\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.144871\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.043432\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.214915\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.057683\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.021106\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.160451\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.030557\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.121461\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.060897\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.196998\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.019299\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.112928\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.147943\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.058219\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.121605\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.020836\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.117152\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.024466\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.029202\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.330493\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.070015\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.079315\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.102690\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.096350\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.055556\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.034183\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.075734\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.013967\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.040820\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.073016\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.025580\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.029998\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.021471\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.018835\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.074014\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.066875\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.031734\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.122501\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.019967\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.198006\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.063972\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.046114\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.036596\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.103080\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.051633\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.055363\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.047609\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.193593\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.055142\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.334778\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.020478\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.060179\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.043448\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.070257\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.029054\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.213659\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.178108\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/5096 (0%)]\tLoss: 0.277275\n",
      "Train Epoch: 1 [640/5096 (12%)]\tLoss: 0.223432\n",
      "Train Epoch: 1 [1280/5096 (25%)]\tLoss: 0.123511\n",
      "Train Epoch: 1 [1920/5096 (38%)]\tLoss: 0.149232\n",
      "Train Epoch: 1 [2560/5096 (50%)]\tLoss: 0.251736\n",
      "Train Epoch: 1 [3200/5096 (62%)]\tLoss: 0.084686\n",
      "Train Epoch: 1 [3840/5096 (75%)]\tLoss: 0.076895\n",
      "Train Epoch: 1 [4480/5096 (88%)]\tLoss: 0.215028\n",
      "Train Epoch: 2 [0/5096 (0%)]\tLoss: 0.064959\n",
      "Train Epoch: 2 [640/5096 (12%)]\tLoss: 0.056543\n",
      "Train Epoch: 2 [1280/5096 (25%)]\tLoss: 0.047419\n",
      "Train Epoch: 2 [1920/5096 (38%)]\tLoss: 0.222117\n",
      "Train Epoch: 2 [2560/5096 (50%)]\tLoss: 0.079973\n",
      "Train Epoch: 2 [3200/5096 (62%)]\tLoss: 0.081160\n",
      "Train Epoch: 2 [3840/5096 (75%)]\tLoss: 0.038539\n",
      "Train Epoch: 2 [4480/5096 (88%)]\tLoss: 0.041639\n",
      "Train Epoch: 3 [0/5096 (0%)]\tLoss: 0.030916\n",
      "Train Epoch: 3 [640/5096 (12%)]\tLoss: 0.119056\n",
      "Train Epoch: 3 [1280/5096 (25%)]\tLoss: 0.184317\n",
      "Train Epoch: 3 [1920/5096 (38%)]\tLoss: 0.051042\n",
      "Train Epoch: 3 [2560/5096 (50%)]\tLoss: 0.046710\n",
      "Train Epoch: 3 [3200/5096 (62%)]\tLoss: 0.182137\n",
      "Train Epoch: 3 [3840/5096 (75%)]\tLoss: 0.092246\n",
      "Train Epoch: 3 [4480/5096 (88%)]\tLoss: 0.056529\n",
      "Train Epoch: 4 [0/5096 (0%)]\tLoss: 0.151826\n",
      "Train Epoch: 4 [640/5096 (12%)]\tLoss: 0.090145\n",
      "Train Epoch: 4 [1280/5096 (25%)]\tLoss: 0.017013\n",
      "Train Epoch: 4 [1920/5096 (38%)]\tLoss: 0.100485\n",
      "Train Epoch: 4 [2560/5096 (50%)]\tLoss: 0.143764\n",
      "Train Epoch: 4 [3200/5096 (62%)]\tLoss: 0.058762\n",
      "Train Epoch: 4 [3840/5096 (75%)]\tLoss: 0.095247\n",
      "Train Epoch: 4 [4480/5096 (88%)]\tLoss: 0.291509\n",
      "Train Epoch: 5 [0/5096 (0%)]\tLoss: 0.021552\n",
      "Train Epoch: 5 [640/5096 (12%)]\tLoss: 0.029320\n",
      "Train Epoch: 5 [1280/5096 (25%)]\tLoss: 0.051450\n",
      "Train Epoch: 5 [1920/5096 (38%)]\tLoss: 0.069303\n",
      "Train Epoch: 5 [2560/5096 (50%)]\tLoss: 0.048999\n",
      "Train Epoch: 5 [3200/5096 (62%)]\tLoss: 0.050657\n",
      "Train Epoch: 5 [3840/5096 (75%)]\tLoss: 0.077715\n",
      "Train Epoch: 5 [4480/5096 (88%)]\tLoss: 0.028845\n",
      "Train Epoch: 6 [0/5096 (0%)]\tLoss: 0.091364\n",
      "Train Epoch: 6 [640/5096 (12%)]\tLoss: 0.227273\n",
      "Train Epoch: 6 [1280/5096 (25%)]\tLoss: 0.039558\n",
      "Train Epoch: 6 [1920/5096 (38%)]\tLoss: 0.152112\n",
      "Train Epoch: 6 [2560/5096 (50%)]\tLoss: 0.055061\n",
      "Train Epoch: 6 [3200/5096 (62%)]\tLoss: 0.016207\n",
      "Train Epoch: 6 [3840/5096 (75%)]\tLoss: 0.087809\n",
      "Train Epoch: 6 [4480/5096 (88%)]\tLoss: 0.042534\n",
      "Train Epoch: 7 [0/5096 (0%)]\tLoss: 0.121469\n",
      "Train Epoch: 7 [640/5096 (12%)]\tLoss: 0.172153\n",
      "Train Epoch: 7 [1280/5096 (25%)]\tLoss: 0.092382\n",
      "Train Epoch: 7 [1920/5096 (38%)]\tLoss: 0.018367\n",
      "Train Epoch: 7 [2560/5096 (50%)]\tLoss: 0.087746\n",
      "Train Epoch: 7 [3200/5096 (62%)]\tLoss: 0.033726\n",
      "Train Epoch: 7 [3840/5096 (75%)]\tLoss: 0.201010\n",
      "Train Epoch: 7 [4480/5096 (88%)]\tLoss: 0.059181\n",
      "Train Epoch: 8 [0/5096 (0%)]\tLoss: 0.071789\n",
      "Train Epoch: 8 [640/5096 (12%)]\tLoss: 0.160870\n",
      "Train Epoch: 8 [1280/5096 (25%)]\tLoss: 0.051757\n",
      "Train Epoch: 8 [1920/5096 (38%)]\tLoss: 0.119493\n",
      "Train Epoch: 8 [2560/5096 (50%)]\tLoss: 0.013152\n",
      "Train Epoch: 8 [3200/5096 (62%)]\tLoss: 0.027627\n",
      "Train Epoch: 8 [3840/5096 (75%)]\tLoss: 0.069665\n",
      "Train Epoch: 8 [4480/5096 (88%)]\tLoss: 0.136368\n",
      "Train Epoch: 9 [0/5096 (0%)]\tLoss: 0.057918\n",
      "Train Epoch: 9 [640/5096 (12%)]\tLoss: 0.020649\n",
      "Train Epoch: 9 [1280/5096 (25%)]\tLoss: 0.012986\n",
      "Train Epoch: 9 [1920/5096 (38%)]\tLoss: 0.153491\n",
      "Train Epoch: 9 [2560/5096 (50%)]\tLoss: 0.074135\n",
      "Train Epoch: 9 [3200/5096 (62%)]\tLoss: 0.205866\n",
      "Train Epoch: 9 [3840/5096 (75%)]\tLoss: 0.092880\n",
      "Train Epoch: 9 [4480/5096 (88%)]\tLoss: 0.080928\n",
      "Train Epoch: 10 [0/5096 (0%)]\tLoss: 0.054983\n",
      "Train Epoch: 10 [640/5096 (12%)]\tLoss: 0.296705\n",
      "Train Epoch: 10 [1280/5096 (25%)]\tLoss: 0.119497\n",
      "Train Epoch: 10 [1920/5096 (38%)]\tLoss: 0.128032\n",
      "Train Epoch: 10 [2560/5096 (50%)]\tLoss: 0.114038\n",
      "Train Epoch: 10 [3200/5096 (62%)]\tLoss: 0.058704\n",
      "Train Epoch: 10 [3840/5096 (75%)]\tLoss: 0.165998\n",
      "Train Epoch: 10 [4480/5096 (88%)]\tLoss: 0.035842\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/1599 (0%)]\tLoss: 0.447069\n",
      "Train Epoch: 1 [640/1599 (40%)]\tLoss: 0.205446\n",
      "Train Epoch: 1 [1280/1599 (80%)]\tLoss: 0.166964\n",
      "Train Epoch: 2 [0/1599 (0%)]\tLoss: 0.073702\n",
      "Train Epoch: 2 [640/1599 (40%)]\tLoss: 0.255864\n",
      "Train Epoch: 2 [1280/1599 (80%)]\tLoss: 0.116160\n",
      "Train Epoch: 3 [0/1599 (0%)]\tLoss: 0.166492\n",
      "Train Epoch: 3 [640/1599 (40%)]\tLoss: 0.098380\n",
      "Train Epoch: 3 [1280/1599 (80%)]\tLoss: 0.230688\n",
      "Train Epoch: 4 [0/1599 (0%)]\tLoss: 0.098078\n",
      "Train Epoch: 4 [640/1599 (40%)]\tLoss: 0.120041\n",
      "Train Epoch: 4 [1280/1599 (80%)]\tLoss: 0.289853\n",
      "Train Epoch: 5 [0/1599 (0%)]\tLoss: 0.174799\n",
      "Train Epoch: 5 [640/1599 (40%)]\tLoss: 0.112079\n",
      "Train Epoch: 5 [1280/1599 (80%)]\tLoss: 0.122844\n",
      "Train Epoch: 6 [0/1599 (0%)]\tLoss: 0.155133\n",
      "Train Epoch: 6 [640/1599 (40%)]\tLoss: 0.321597\n",
      "Train Epoch: 6 [1280/1599 (80%)]\tLoss: 0.181379\n",
      "Train Epoch: 7 [0/1599 (0%)]\tLoss: 0.127184\n",
      "Train Epoch: 7 [640/1599 (40%)]\tLoss: 0.091761\n",
      "Train Epoch: 7 [1280/1599 (80%)]\tLoss: 0.061349\n",
      "Train Epoch: 8 [0/1599 (0%)]\tLoss: 0.149466\n",
      "Train Epoch: 8 [640/1599 (40%)]\tLoss: 0.191880\n",
      "Train Epoch: 8 [1280/1599 (80%)]\tLoss: 0.150890\n",
      "Train Epoch: 9 [0/1599 (0%)]\tLoss: 0.111752\n",
      "Train Epoch: 9 [640/1599 (40%)]\tLoss: 0.191844\n",
      "Train Epoch: 9 [1280/1599 (80%)]\tLoss: 0.147732\n",
      "Train Epoch: 10 [0/1599 (0%)]\tLoss: 0.048480\n",
      "Train Epoch: 10 [640/1599 (40%)]\tLoss: 0.108219\n",
      "Train Epoch: 10 [1280/1599 (80%)]\tLoss: 0.056978\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/5266 (0%)]\tLoss: 0.630618\n",
      "Train Epoch: 1 [640/5266 (12%)]\tLoss: 0.093768\n",
      "Train Epoch: 1 [1280/5266 (24%)]\tLoss: 0.087898\n",
      "Train Epoch: 1 [1920/5266 (36%)]\tLoss: 0.157396\n",
      "Train Epoch: 1 [2560/5266 (48%)]\tLoss: 0.275603\n",
      "Train Epoch: 1 [3200/5266 (60%)]\tLoss: 0.073248\n",
      "Train Epoch: 1 [3840/5266 (72%)]\tLoss: 0.073926\n",
      "Train Epoch: 1 [4480/5266 (84%)]\tLoss: 0.010154\n",
      "Train Epoch: 1 [5120/5266 (96%)]\tLoss: 0.023464\n",
      "Train Epoch: 2 [0/5266 (0%)]\tLoss: 0.076451\n",
      "Train Epoch: 2 [640/5266 (12%)]\tLoss: 0.226806\n",
      "Train Epoch: 2 [1280/5266 (24%)]\tLoss: 0.050509\n",
      "Train Epoch: 2 [1920/5266 (36%)]\tLoss: 0.079121\n",
      "Train Epoch: 2 [2560/5266 (48%)]\tLoss: 0.051553\n",
      "Train Epoch: 2 [3200/5266 (60%)]\tLoss: 0.020407\n",
      "Train Epoch: 2 [3840/5266 (72%)]\tLoss: 0.050862\n",
      "Train Epoch: 2 [4480/5266 (84%)]\tLoss: 0.035657\n",
      "Train Epoch: 2 [5120/5266 (96%)]\tLoss: 0.109807\n",
      "Train Epoch: 3 [0/5266 (0%)]\tLoss: 0.022555\n",
      "Train Epoch: 3 [640/5266 (12%)]\tLoss: 0.134474\n",
      "Train Epoch: 3 [1280/5266 (24%)]\tLoss: 0.133286\n",
      "Train Epoch: 3 [1920/5266 (36%)]\tLoss: 0.099081\n",
      "Train Epoch: 3 [2560/5266 (48%)]\tLoss: 0.030823\n",
      "Train Epoch: 3 [3200/5266 (60%)]\tLoss: 0.097522\n",
      "Train Epoch: 3 [3840/5266 (72%)]\tLoss: 0.129249\n",
      "Train Epoch: 3 [4480/5266 (84%)]\tLoss: 0.037692\n",
      "Train Epoch: 3 [5120/5266 (96%)]\tLoss: 0.030566\n",
      "Train Epoch: 4 [0/5266 (0%)]\tLoss: 0.042202\n",
      "Train Epoch: 4 [640/5266 (12%)]\tLoss: 0.089027\n",
      "Train Epoch: 4 [1280/5266 (24%)]\tLoss: 0.038888\n",
      "Train Epoch: 4 [1920/5266 (36%)]\tLoss: 0.121954\n",
      "Train Epoch: 4 [2560/5266 (48%)]\tLoss: 0.048818\n",
      "Train Epoch: 4 [3200/5266 (60%)]\tLoss: 0.086002\n",
      "Train Epoch: 4 [3840/5266 (72%)]\tLoss: 0.034992\n",
      "Train Epoch: 4 [4480/5266 (84%)]\tLoss: 0.039368\n",
      "Train Epoch: 4 [5120/5266 (96%)]\tLoss: 0.044471\n",
      "Train Epoch: 5 [0/5266 (0%)]\tLoss: 0.069987\n",
      "Train Epoch: 5 [640/5266 (12%)]\tLoss: 0.107198\n",
      "Train Epoch: 5 [1280/5266 (24%)]\tLoss: 0.068778\n",
      "Train Epoch: 5 [1920/5266 (36%)]\tLoss: 0.158362\n",
      "Train Epoch: 5 [2560/5266 (48%)]\tLoss: 0.069859\n",
      "Train Epoch: 5 [3200/5266 (60%)]\tLoss: 0.018870\n",
      "Train Epoch: 5 [3840/5266 (72%)]\tLoss: 0.123578\n",
      "Train Epoch: 5 [4480/5266 (84%)]\tLoss: 0.014317\n",
      "Train Epoch: 5 [5120/5266 (96%)]\tLoss: 0.024000\n",
      "Train Epoch: 6 [0/5266 (0%)]\tLoss: 0.015943\n",
      "Train Epoch: 6 [640/5266 (12%)]\tLoss: 0.218478\n",
      "Train Epoch: 6 [1280/5266 (24%)]\tLoss: 0.071689\n",
      "Train Epoch: 6 [1920/5266 (36%)]\tLoss: 0.031998\n",
      "Train Epoch: 6 [2560/5266 (48%)]\tLoss: 0.100704\n",
      "Train Epoch: 6 [3200/5266 (60%)]\tLoss: 0.071018\n",
      "Train Epoch: 6 [3840/5266 (72%)]\tLoss: 0.088171\n",
      "Train Epoch: 6 [4480/5266 (84%)]\tLoss: 0.039358\n",
      "Train Epoch: 6 [5120/5266 (96%)]\tLoss: 0.100281\n",
      "Train Epoch: 7 [0/5266 (0%)]\tLoss: 0.018958\n",
      "Train Epoch: 7 [640/5266 (12%)]\tLoss: 0.077553\n",
      "Train Epoch: 7 [1280/5266 (24%)]\tLoss: 0.039163\n",
      "Train Epoch: 7 [1920/5266 (36%)]\tLoss: 0.011802\n",
      "Train Epoch: 7 [2560/5266 (48%)]\tLoss: 0.042598\n",
      "Train Epoch: 7 [3200/5266 (60%)]\tLoss: 0.056445\n",
      "Train Epoch: 7 [3840/5266 (72%)]\tLoss: 0.039501\n",
      "Train Epoch: 7 [4480/5266 (84%)]\tLoss: 0.042524\n",
      "Train Epoch: 7 [5120/5266 (96%)]\tLoss: 0.104145\n",
      "Train Epoch: 8 [0/5266 (0%)]\tLoss: 0.076409\n",
      "Train Epoch: 8 [640/5266 (12%)]\tLoss: 0.014956\n",
      "Train Epoch: 8 [1280/5266 (24%)]\tLoss: 0.043444\n",
      "Train Epoch: 8 [1920/5266 (36%)]\tLoss: 0.027452\n",
      "Train Epoch: 8 [2560/5266 (48%)]\tLoss: 0.046296\n",
      "Train Epoch: 8 [3200/5266 (60%)]\tLoss: 0.034047\n",
      "Train Epoch: 8 [3840/5266 (72%)]\tLoss: 0.007733\n",
      "Train Epoch: 8 [4480/5266 (84%)]\tLoss: 0.077067\n",
      "Train Epoch: 8 [5120/5266 (96%)]\tLoss: 0.072016\n",
      "Train Epoch: 9 [0/5266 (0%)]\tLoss: 0.104991\n",
      "Train Epoch: 9 [640/5266 (12%)]\tLoss: 0.048637\n",
      "Train Epoch: 9 [1280/5266 (24%)]\tLoss: 0.071200\n",
      "Train Epoch: 9 [1920/5266 (36%)]\tLoss: 0.020138\n",
      "Train Epoch: 9 [2560/5266 (48%)]\tLoss: 0.066696\n",
      "Train Epoch: 9 [3200/5266 (60%)]\tLoss: 0.106905\n",
      "Train Epoch: 9 [3840/5266 (72%)]\tLoss: 0.032812\n",
      "Train Epoch: 9 [4480/5266 (84%)]\tLoss: 0.011426\n",
      "Train Epoch: 9 [5120/5266 (96%)]\tLoss: 0.069605\n",
      "Train Epoch: 10 [0/5266 (0%)]\tLoss: 0.124913\n",
      "Train Epoch: 10 [640/5266 (12%)]\tLoss: 0.050130\n",
      "Train Epoch: 10 [1280/5266 (24%)]\tLoss: 0.011540\n",
      "Train Epoch: 10 [1920/5266 (36%)]\tLoss: 0.062773\n",
      "Train Epoch: 10 [2560/5266 (48%)]\tLoss: 0.055364\n",
      "Train Epoch: 10 [3200/5266 (60%)]\tLoss: 0.046196\n",
      "Train Epoch: 10 [3840/5266 (72%)]\tLoss: 0.002634\n",
      "Train Epoch: 10 [4480/5266 (84%)]\tLoss: 0.014306\n",
      "Train Epoch: 10 [5120/5266 (96%)]\tLoss: 0.029127\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/3530 (0%)]\tLoss: 0.328475\n",
      "Train Epoch: 1 [640/3530 (18%)]\tLoss: 0.231032\n",
      "Train Epoch: 1 [1280/3530 (36%)]\tLoss: 0.385191\n",
      "Train Epoch: 1 [1920/3530 (54%)]\tLoss: 0.157620\n",
      "Train Epoch: 1 [2560/3530 (71%)]\tLoss: 0.159260\n",
      "Train Epoch: 1 [3200/3530 (89%)]\tLoss: 0.159861\n",
      "Train Epoch: 2 [0/3530 (0%)]\tLoss: 0.190089\n",
      "Train Epoch: 2 [640/3530 (18%)]\tLoss: 0.334134\n",
      "Train Epoch: 2 [1280/3530 (36%)]\tLoss: 0.147959\n",
      "Train Epoch: 2 [1920/3530 (54%)]\tLoss: 0.279681\n",
      "Train Epoch: 2 [2560/3530 (71%)]\tLoss: 0.093891\n",
      "Train Epoch: 2 [3200/3530 (89%)]\tLoss: 0.264130\n",
      "Train Epoch: 3 [0/3530 (0%)]\tLoss: 0.222409\n",
      "Train Epoch: 3 [640/3530 (18%)]\tLoss: 0.197406\n",
      "Train Epoch: 3 [1280/3530 (36%)]\tLoss: 0.162353\n",
      "Train Epoch: 3 [1920/3530 (54%)]\tLoss: 0.137175\n",
      "Train Epoch: 3 [2560/3530 (71%)]\tLoss: 0.184113\n",
      "Train Epoch: 3 [3200/3530 (89%)]\tLoss: 0.251657\n",
      "Train Epoch: 4 [0/3530 (0%)]\tLoss: 0.145218\n",
      "Train Epoch: 4 [640/3530 (18%)]\tLoss: 0.271623\n",
      "Train Epoch: 4 [1280/3530 (36%)]\tLoss: 0.104284\n",
      "Train Epoch: 4 [1920/3530 (54%)]\tLoss: 0.196959\n",
      "Train Epoch: 4 [2560/3530 (71%)]\tLoss: 0.074773\n",
      "Train Epoch: 4 [3200/3530 (89%)]\tLoss: 0.113010\n",
      "Train Epoch: 5 [0/3530 (0%)]\tLoss: 0.067094\n",
      "Train Epoch: 5 [640/3530 (18%)]\tLoss: 0.161960\n",
      "Train Epoch: 5 [1280/3530 (36%)]\tLoss: 0.206972\n",
      "Train Epoch: 5 [1920/3530 (54%)]\tLoss: 0.143573\n",
      "Train Epoch: 5 [2560/3530 (71%)]\tLoss: 0.223721\n",
      "Train Epoch: 5 [3200/3530 (89%)]\tLoss: 0.139139\n",
      "Train Epoch: 6 [0/3530 (0%)]\tLoss: 0.071893\n",
      "Train Epoch: 6 [640/3530 (18%)]\tLoss: 0.224876\n",
      "Train Epoch: 6 [1280/3530 (36%)]\tLoss: 0.185824\n",
      "Train Epoch: 6 [1920/3530 (54%)]\tLoss: 0.138151\n",
      "Train Epoch: 6 [2560/3530 (71%)]\tLoss: 0.124143\n",
      "Train Epoch: 6 [3200/3530 (89%)]\tLoss: 0.133465\n",
      "Train Epoch: 7 [0/3530 (0%)]\tLoss: 0.234137\n",
      "Train Epoch: 7 [640/3530 (18%)]\tLoss: 0.087009\n",
      "Train Epoch: 7 [1280/3530 (36%)]\tLoss: 0.171738\n",
      "Train Epoch: 7 [1920/3530 (54%)]\tLoss: 0.078044\n",
      "Train Epoch: 7 [2560/3530 (71%)]\tLoss: 0.216255\n",
      "Train Epoch: 7 [3200/3530 (89%)]\tLoss: 0.236917\n",
      "Train Epoch: 8 [0/3530 (0%)]\tLoss: 0.282133\n",
      "Train Epoch: 8 [640/3530 (18%)]\tLoss: 0.116097\n",
      "Train Epoch: 8 [1280/3530 (36%)]\tLoss: 0.250862\n",
      "Train Epoch: 8 [1920/3530 (54%)]\tLoss: 0.166861\n",
      "Train Epoch: 8 [2560/3530 (71%)]\tLoss: 0.169916\n",
      "Train Epoch: 8 [3200/3530 (89%)]\tLoss: 0.166612\n",
      "Train Epoch: 9 [0/3530 (0%)]\tLoss: 0.124062\n",
      "Train Epoch: 9 [640/3530 (18%)]\tLoss: 0.201766\n",
      "Train Epoch: 9 [1280/3530 (36%)]\tLoss: 0.078814\n",
      "Train Epoch: 9 [1920/3530 (54%)]\tLoss: 0.098765\n",
      "Train Epoch: 9 [2560/3530 (71%)]\tLoss: 0.123952\n",
      "Train Epoch: 9 [3200/3530 (89%)]\tLoss: 0.050388\n",
      "Train Epoch: 10 [0/3530 (0%)]\tLoss: 0.024052\n",
      "Train Epoch: 10 [640/3530 (18%)]\tLoss: 0.292764\n",
      "Train Epoch: 10 [1280/3530 (36%)]\tLoss: 0.116584\n",
      "Train Epoch: 10 [1920/3530 (54%)]\tLoss: 0.174925\n",
      "Train Epoch: 10 [2560/3530 (71%)]\tLoss: 0.029066\n",
      "Train Epoch: 10 [3200/3530 (89%)]\tLoss: 0.191581\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.6248, Accuracy: 9578/10000 (96%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/37519 (0%)]\tLoss: 0.316418\n",
      "Train Epoch: 1 [640/37519 (2%)]\tLoss: 0.240024\n",
      "Train Epoch: 1 [1280/37519 (3%)]\tLoss: 0.335694\n",
      "Train Epoch: 1 [1920/37519 (5%)]\tLoss: 0.220465\n",
      "Train Epoch: 1 [2560/37519 (7%)]\tLoss: 0.281629\n",
      "Train Epoch: 1 [3200/37519 (9%)]\tLoss: 0.278732\n",
      "Train Epoch: 1 [3840/37519 (10%)]\tLoss: 0.300203\n",
      "Train Epoch: 1 [4480/37519 (12%)]\tLoss: 0.220578\n",
      "Train Epoch: 1 [5120/37519 (14%)]\tLoss: 0.128649\n",
      "Train Epoch: 1 [5760/37519 (15%)]\tLoss: 0.218283\n",
      "Train Epoch: 1 [6400/37519 (17%)]\tLoss: 0.250189\n",
      "Train Epoch: 1 [7040/37519 (19%)]\tLoss: 0.338251\n",
      "Train Epoch: 1 [7680/37519 (20%)]\tLoss: 0.430511\n",
      "Train Epoch: 1 [8320/37519 (22%)]\tLoss: 0.211621\n",
      "Train Epoch: 1 [8960/37519 (24%)]\tLoss: 0.202913\n",
      "Train Epoch: 1 [9600/37519 (26%)]\tLoss: 0.255631\n",
      "Train Epoch: 1 [10240/37519 (27%)]\tLoss: 0.226106\n",
      "Train Epoch: 1 [10880/37519 (29%)]\tLoss: 0.295876\n",
      "Train Epoch: 1 [11520/37519 (31%)]\tLoss: 0.166613\n",
      "Train Epoch: 1 [12160/37519 (32%)]\tLoss: 0.125912\n",
      "Train Epoch: 1 [12800/37519 (34%)]\tLoss: 0.454790\n",
      "Train Epoch: 1 [13440/37519 (36%)]\tLoss: 0.321686\n",
      "Train Epoch: 1 [14080/37519 (37%)]\tLoss: 0.148734\n",
      "Train Epoch: 1 [14720/37519 (39%)]\tLoss: 0.238462\n",
      "Train Epoch: 1 [15360/37519 (41%)]\tLoss: 0.420637\n",
      "Train Epoch: 1 [16000/37519 (43%)]\tLoss: 0.238275\n",
      "Train Epoch: 1 [16640/37519 (44%)]\tLoss: 0.360446\n",
      "Train Epoch: 1 [17280/37519 (46%)]\tLoss: 0.266486\n",
      "Train Epoch: 1 [17920/37519 (48%)]\tLoss: 0.097461\n",
      "Train Epoch: 1 [18560/37519 (49%)]\tLoss: 0.273481\n",
      "Train Epoch: 1 [19200/37519 (51%)]\tLoss: 0.251824\n",
      "Train Epoch: 1 [19840/37519 (53%)]\tLoss: 0.216330\n",
      "Train Epoch: 1 [20480/37519 (55%)]\tLoss: 0.291793\n",
      "Train Epoch: 1 [21120/37519 (56%)]\tLoss: 0.354974\n",
      "Train Epoch: 1 [21760/37519 (58%)]\tLoss: 0.276201\n",
      "Train Epoch: 1 [22400/37519 (60%)]\tLoss: 0.310846\n",
      "Train Epoch: 1 [23040/37519 (61%)]\tLoss: 0.250875\n",
      "Train Epoch: 1 [23680/37519 (63%)]\tLoss: 0.229035\n",
      "Train Epoch: 1 [24320/37519 (65%)]\tLoss: 0.224003\n",
      "Train Epoch: 1 [24960/37519 (66%)]\tLoss: 0.177520\n",
      "Train Epoch: 1 [25600/37519 (68%)]\tLoss: 0.195712\n",
      "Train Epoch: 1 [26240/37519 (70%)]\tLoss: 0.362525\n",
      "Train Epoch: 1 [26880/37519 (72%)]\tLoss: 0.179461\n",
      "Train Epoch: 1 [27520/37519 (73%)]\tLoss: 0.253147\n",
      "Train Epoch: 1 [28160/37519 (75%)]\tLoss: 0.445582\n",
      "Train Epoch: 1 [28800/37519 (77%)]\tLoss: 0.220736\n",
      "Train Epoch: 1 [29440/37519 (78%)]\tLoss: 0.241369\n",
      "Train Epoch: 1 [30080/37519 (80%)]\tLoss: 0.279519\n",
      "Train Epoch: 1 [30720/37519 (82%)]\tLoss: 0.306869\n",
      "Train Epoch: 1 [31360/37519 (83%)]\tLoss: 0.261015\n",
      "Train Epoch: 1 [32000/37519 (85%)]\tLoss: 0.206168\n",
      "Train Epoch: 1 [32640/37519 (87%)]\tLoss: 0.241530\n",
      "Train Epoch: 1 [33280/37519 (89%)]\tLoss: 0.231680\n",
      "Train Epoch: 1 [33920/37519 (90%)]\tLoss: 0.103920\n",
      "Train Epoch: 1 [34560/37519 (92%)]\tLoss: 0.125137\n",
      "Train Epoch: 1 [35200/37519 (94%)]\tLoss: 0.287780\n",
      "Train Epoch: 1 [35840/37519 (95%)]\tLoss: 0.243920\n",
      "Train Epoch: 1 [36480/37519 (97%)]\tLoss: 0.194190\n",
      "Train Epoch: 1 [37120/37519 (99%)]\tLoss: 0.213041\n",
      "Train Epoch: 2 [0/37519 (0%)]\tLoss: 0.253088\n",
      "Train Epoch: 2 [640/37519 (2%)]\tLoss: 0.432297\n",
      "Train Epoch: 2 [1280/37519 (3%)]\tLoss: 0.259000\n",
      "Train Epoch: 2 [1920/37519 (5%)]\tLoss: 0.273224\n",
      "Train Epoch: 2 [2560/37519 (7%)]\tLoss: 0.277906\n",
      "Train Epoch: 2 [3200/37519 (9%)]\tLoss: 0.329247\n",
      "Train Epoch: 2 [3840/37519 (10%)]\tLoss: 0.294431\n",
      "Train Epoch: 2 [4480/37519 (12%)]\tLoss: 0.259887\n",
      "Train Epoch: 2 [5120/37519 (14%)]\tLoss: 0.315553\n",
      "Train Epoch: 2 [5760/37519 (15%)]\tLoss: 0.552189\n",
      "Train Epoch: 2 [6400/37519 (17%)]\tLoss: 0.298012\n",
      "Train Epoch: 2 [7040/37519 (19%)]\tLoss: 0.198944\n",
      "Train Epoch: 2 [7680/37519 (20%)]\tLoss: 0.138004\n",
      "Train Epoch: 2 [8320/37519 (22%)]\tLoss: 0.310561\n",
      "Train Epoch: 2 [8960/37519 (24%)]\tLoss: 0.123586\n",
      "Train Epoch: 2 [9600/37519 (26%)]\tLoss: 0.289773\n",
      "Train Epoch: 2 [10240/37519 (27%)]\tLoss: 0.134155\n",
      "Train Epoch: 2 [10880/37519 (29%)]\tLoss: 0.151958\n",
      "Train Epoch: 2 [11520/37519 (31%)]\tLoss: 0.282278\n",
      "Train Epoch: 2 [12160/37519 (32%)]\tLoss: 0.184143\n",
      "Train Epoch: 2 [12800/37519 (34%)]\tLoss: 0.155512\n",
      "Train Epoch: 2 [13440/37519 (36%)]\tLoss: 0.110904\n",
      "Train Epoch: 2 [14080/37519 (37%)]\tLoss: 0.211184\n",
      "Train Epoch: 2 [14720/37519 (39%)]\tLoss: 0.190340\n",
      "Train Epoch: 2 [15360/37519 (41%)]\tLoss: 0.224326\n",
      "Train Epoch: 2 [16000/37519 (43%)]\tLoss: 0.296172\n",
      "Train Epoch: 2 [16640/37519 (44%)]\tLoss: 0.197544\n",
      "Train Epoch: 2 [17280/37519 (46%)]\tLoss: 0.307811\n",
      "Train Epoch: 2 [17920/37519 (48%)]\tLoss: 0.107447\n",
      "Train Epoch: 2 [18560/37519 (49%)]\tLoss: 0.299636\n",
      "Train Epoch: 2 [19200/37519 (51%)]\tLoss: 0.210931\n",
      "Train Epoch: 2 [19840/37519 (53%)]\tLoss: 0.284129\n",
      "Train Epoch: 2 [20480/37519 (55%)]\tLoss: 0.237087\n",
      "Train Epoch: 2 [21120/37519 (56%)]\tLoss: 0.179514\n",
      "Train Epoch: 2 [21760/37519 (58%)]\tLoss: 0.171202\n",
      "Train Epoch: 2 [22400/37519 (60%)]\tLoss: 0.176355\n",
      "Train Epoch: 2 [23040/37519 (61%)]\tLoss: 0.126035\n",
      "Train Epoch: 2 [23680/37519 (63%)]\tLoss: 0.266933\n",
      "Train Epoch: 2 [24320/37519 (65%)]\tLoss: 0.128460\n",
      "Train Epoch: 2 [24960/37519 (66%)]\tLoss: 0.523778\n",
      "Train Epoch: 2 [25600/37519 (68%)]\tLoss: 0.237261\n",
      "Train Epoch: 2 [26240/37519 (70%)]\tLoss: 0.233109\n",
      "Train Epoch: 2 [26880/37519 (72%)]\tLoss: 0.225492\n",
      "Train Epoch: 2 [27520/37519 (73%)]\tLoss: 0.308336\n",
      "Train Epoch: 2 [28160/37519 (75%)]\tLoss: 0.286067\n",
      "Train Epoch: 2 [28800/37519 (77%)]\tLoss: 0.153062\n",
      "Train Epoch: 2 [29440/37519 (78%)]\tLoss: 0.264114\n",
      "Train Epoch: 2 [30080/37519 (80%)]\tLoss: 0.122361\n",
      "Train Epoch: 2 [30720/37519 (82%)]\tLoss: 0.198409\n",
      "Train Epoch: 2 [31360/37519 (83%)]\tLoss: 0.066207\n",
      "Train Epoch: 2 [32000/37519 (85%)]\tLoss: 0.298761\n",
      "Train Epoch: 2 [32640/37519 (87%)]\tLoss: 0.276831\n",
      "Train Epoch: 2 [33280/37519 (89%)]\tLoss: 0.169604\n",
      "Train Epoch: 2 [33920/37519 (90%)]\tLoss: 0.170107\n",
      "Train Epoch: 2 [34560/37519 (92%)]\tLoss: 0.279778\n",
      "Train Epoch: 2 [35200/37519 (94%)]\tLoss: 0.280771\n",
      "Train Epoch: 2 [35840/37519 (95%)]\tLoss: 0.218875\n",
      "Train Epoch: 2 [36480/37519 (97%)]\tLoss: 0.109262\n",
      "Train Epoch: 2 [37120/37519 (99%)]\tLoss: 0.181793\n",
      "Train Epoch: 3 [0/37519 (0%)]\tLoss: 0.098792\n",
      "Train Epoch: 3 [640/37519 (2%)]\tLoss: 0.229250\n",
      "Train Epoch: 3 [1280/37519 (3%)]\tLoss: 0.192615\n",
      "Train Epoch: 3 [1920/37519 (5%)]\tLoss: 0.228225\n",
      "Train Epoch: 3 [2560/37519 (7%)]\tLoss: 0.208792\n",
      "Train Epoch: 3 [3200/37519 (9%)]\tLoss: 0.199428\n",
      "Train Epoch: 3 [3840/37519 (10%)]\tLoss: 0.116371\n",
      "Train Epoch: 3 [4480/37519 (12%)]\tLoss: 0.147271\n",
      "Train Epoch: 3 [5120/37519 (14%)]\tLoss: 0.189381\n",
      "Train Epoch: 3 [5760/37519 (15%)]\tLoss: 0.267224\n",
      "Train Epoch: 3 [6400/37519 (17%)]\tLoss: 0.297569\n",
      "Train Epoch: 3 [7040/37519 (19%)]\tLoss: 0.210028\n",
      "Train Epoch: 3 [7680/37519 (20%)]\tLoss: 0.168055\n",
      "Train Epoch: 3 [8320/37519 (22%)]\tLoss: 0.118390\n",
      "Train Epoch: 3 [8960/37519 (24%)]\tLoss: 0.284370\n",
      "Train Epoch: 3 [9600/37519 (26%)]\tLoss: 0.230669\n",
      "Train Epoch: 3 [10240/37519 (27%)]\tLoss: 0.306269\n",
      "Train Epoch: 3 [10880/37519 (29%)]\tLoss: 0.261091\n",
      "Train Epoch: 3 [11520/37519 (31%)]\tLoss: 0.202572\n",
      "Train Epoch: 3 [12160/37519 (32%)]\tLoss: 0.146271\n",
      "Train Epoch: 3 [12800/37519 (34%)]\tLoss: 0.201469\n",
      "Train Epoch: 3 [13440/37519 (36%)]\tLoss: 0.214901\n",
      "Train Epoch: 3 [14080/37519 (37%)]\tLoss: 0.311731\n",
      "Train Epoch: 3 [14720/37519 (39%)]\tLoss: 0.110206\n",
      "Train Epoch: 3 [15360/37519 (41%)]\tLoss: 0.121070\n",
      "Train Epoch: 3 [16000/37519 (43%)]\tLoss: 0.276585\n",
      "Train Epoch: 3 [16640/37519 (44%)]\tLoss: 0.111102\n",
      "Train Epoch: 3 [17280/37519 (46%)]\tLoss: 0.251345\n",
      "Train Epoch: 3 [17920/37519 (48%)]\tLoss: 0.217076\n",
      "Train Epoch: 3 [18560/37519 (49%)]\tLoss: 0.157687\n",
      "Train Epoch: 3 [19200/37519 (51%)]\tLoss: 0.370200\n",
      "Train Epoch: 3 [19840/37519 (53%)]\tLoss: 0.128741\n",
      "Train Epoch: 3 [20480/37519 (55%)]\tLoss: 0.593326\n",
      "Train Epoch: 3 [21120/37519 (56%)]\tLoss: 0.526492\n",
      "Train Epoch: 3 [21760/37519 (58%)]\tLoss: 0.177903\n",
      "Train Epoch: 3 [22400/37519 (60%)]\tLoss: 0.178060\n",
      "Train Epoch: 3 [23040/37519 (61%)]\tLoss: 0.097719\n",
      "Train Epoch: 3 [23680/37519 (63%)]\tLoss: 0.087913\n",
      "Train Epoch: 3 [24320/37519 (65%)]\tLoss: 0.213337\n",
      "Train Epoch: 3 [24960/37519 (66%)]\tLoss: 0.233354\n",
      "Train Epoch: 3 [25600/37519 (68%)]\tLoss: 0.620862\n",
      "Train Epoch: 3 [26240/37519 (70%)]\tLoss: 0.267781\n",
      "Train Epoch: 3 [26880/37519 (72%)]\tLoss: 0.211909\n",
      "Train Epoch: 3 [27520/37519 (73%)]\tLoss: 0.366503\n",
      "Train Epoch: 3 [28160/37519 (75%)]\tLoss: 0.115453\n",
      "Train Epoch: 3 [28800/37519 (77%)]\tLoss: 0.235243\n",
      "Train Epoch: 3 [29440/37519 (78%)]\tLoss: 0.182315\n",
      "Train Epoch: 3 [30080/37519 (80%)]\tLoss: 0.127397\n",
      "Train Epoch: 3 [30720/37519 (82%)]\tLoss: 0.252178\n",
      "Train Epoch: 3 [31360/37519 (83%)]\tLoss: 0.152547\n",
      "Train Epoch: 3 [32000/37519 (85%)]\tLoss: 0.314042\n",
      "Train Epoch: 3 [32640/37519 (87%)]\tLoss: 0.143904\n",
      "Train Epoch: 3 [33280/37519 (89%)]\tLoss: 0.036181\n",
      "Train Epoch: 3 [33920/37519 (90%)]\tLoss: 0.083819\n",
      "Train Epoch: 3 [34560/37519 (92%)]\tLoss: 0.099849\n",
      "Train Epoch: 3 [35200/37519 (94%)]\tLoss: 0.313490\n",
      "Train Epoch: 3 [35840/37519 (95%)]\tLoss: 0.135747\n",
      "Train Epoch: 3 [36480/37519 (97%)]\tLoss: 0.206883\n",
      "Train Epoch: 3 [37120/37519 (99%)]\tLoss: 0.101731\n",
      "Train Epoch: 4 [0/37519 (0%)]\tLoss: 0.280774\n",
      "Train Epoch: 4 [640/37519 (2%)]\tLoss: 0.214849\n",
      "Train Epoch: 4 [1280/37519 (3%)]\tLoss: 0.294635\n",
      "Train Epoch: 4 [1920/37519 (5%)]\tLoss: 0.083738\n",
      "Train Epoch: 4 [2560/37519 (7%)]\tLoss: 0.208058\n",
      "Train Epoch: 4 [3200/37519 (9%)]\tLoss: 0.103484\n",
      "Train Epoch: 4 [3840/37519 (10%)]\tLoss: 0.357177\n",
      "Train Epoch: 4 [4480/37519 (12%)]\tLoss: 0.148776\n",
      "Train Epoch: 4 [5120/37519 (14%)]\tLoss: 0.456379\n",
      "Train Epoch: 4 [5760/37519 (15%)]\tLoss: 0.067484\n",
      "Train Epoch: 4 [6400/37519 (17%)]\tLoss: 0.322542\n",
      "Train Epoch: 4 [7040/37519 (19%)]\tLoss: 0.221559\n",
      "Train Epoch: 4 [7680/37519 (20%)]\tLoss: 0.173408\n",
      "Train Epoch: 4 [8320/37519 (22%)]\tLoss: 0.123083\n",
      "Train Epoch: 4 [8960/37519 (24%)]\tLoss: 0.123644\n",
      "Train Epoch: 4 [9600/37519 (26%)]\tLoss: 0.325860\n",
      "Train Epoch: 4 [10240/37519 (27%)]\tLoss: 0.084130\n",
      "Train Epoch: 4 [10880/37519 (29%)]\tLoss: 0.101657\n",
      "Train Epoch: 4 [11520/37519 (31%)]\tLoss: 0.171184\n",
      "Train Epoch: 4 [12160/37519 (32%)]\tLoss: 0.235109\n",
      "Train Epoch: 4 [12800/37519 (34%)]\tLoss: 0.123368\n",
      "Train Epoch: 4 [13440/37519 (36%)]\tLoss: 0.340195\n",
      "Train Epoch: 4 [14080/37519 (37%)]\tLoss: 0.152214\n",
      "Train Epoch: 4 [14720/37519 (39%)]\tLoss: 0.171472\n",
      "Train Epoch: 4 [15360/37519 (41%)]\tLoss: 0.205014\n",
      "Train Epoch: 4 [16000/37519 (43%)]\tLoss: 0.061457\n",
      "Train Epoch: 4 [16640/37519 (44%)]\tLoss: 0.173195\n",
      "Train Epoch: 4 [17280/37519 (46%)]\tLoss: 0.086695\n",
      "Train Epoch: 4 [17920/37519 (48%)]\tLoss: 0.169114\n",
      "Train Epoch: 4 [18560/37519 (49%)]\tLoss: 0.306687\n",
      "Train Epoch: 4 [19200/37519 (51%)]\tLoss: 0.140316\n",
      "Train Epoch: 4 [19840/37519 (53%)]\tLoss: 0.136258\n",
      "Train Epoch: 4 [20480/37519 (55%)]\tLoss: 0.142442\n",
      "Train Epoch: 4 [21120/37519 (56%)]\tLoss: 0.164677\n",
      "Train Epoch: 4 [21760/37519 (58%)]\tLoss: 0.137741\n",
      "Train Epoch: 4 [22400/37519 (60%)]\tLoss: 0.168057\n",
      "Train Epoch: 4 [23040/37519 (61%)]\tLoss: 0.200931\n",
      "Train Epoch: 4 [23680/37519 (63%)]\tLoss: 0.142787\n",
      "Train Epoch: 4 [24320/37519 (65%)]\tLoss: 0.207201\n",
      "Train Epoch: 4 [24960/37519 (66%)]\tLoss: 0.341110\n",
      "Train Epoch: 4 [25600/37519 (68%)]\tLoss: 0.193130\n",
      "Train Epoch: 4 [26240/37519 (70%)]\tLoss: 0.087224\n",
      "Train Epoch: 4 [26880/37519 (72%)]\tLoss: 0.093271\n",
      "Train Epoch: 4 [27520/37519 (73%)]\tLoss: 0.130731\n",
      "Train Epoch: 4 [28160/37519 (75%)]\tLoss: 0.205874\n",
      "Train Epoch: 4 [28800/37519 (77%)]\tLoss: 0.164037\n",
      "Train Epoch: 4 [29440/37519 (78%)]\tLoss: 0.229083\n",
      "Train Epoch: 4 [30080/37519 (80%)]\tLoss: 0.050959\n",
      "Train Epoch: 4 [30720/37519 (82%)]\tLoss: 0.212846\n",
      "Train Epoch: 4 [31360/37519 (83%)]\tLoss: 0.290418\n",
      "Train Epoch: 4 [32000/37519 (85%)]\tLoss: 0.275342\n",
      "Train Epoch: 4 [32640/37519 (87%)]\tLoss: 0.344560\n",
      "Train Epoch: 4 [33280/37519 (89%)]\tLoss: 0.155358\n",
      "Train Epoch: 4 [33920/37519 (90%)]\tLoss: 0.134902\n",
      "Train Epoch: 4 [34560/37519 (92%)]\tLoss: 0.136575\n",
      "Train Epoch: 4 [35200/37519 (94%)]\tLoss: 0.334646\n",
      "Train Epoch: 4 [35840/37519 (95%)]\tLoss: 0.180241\n",
      "Train Epoch: 4 [36480/37519 (97%)]\tLoss: 0.053001\n",
      "Train Epoch: 4 [37120/37519 (99%)]\tLoss: 0.172518\n",
      "Train Epoch: 5 [0/37519 (0%)]\tLoss: 0.128933\n",
      "Train Epoch: 5 [640/37519 (2%)]\tLoss: 0.107799\n",
      "Train Epoch: 5 [1280/37519 (3%)]\tLoss: 0.230395\n",
      "Train Epoch: 5 [1920/37519 (5%)]\tLoss: 0.197599\n",
      "Train Epoch: 5 [2560/37519 (7%)]\tLoss: 0.192554\n",
      "Train Epoch: 5 [3200/37519 (9%)]\tLoss: 0.151415\n",
      "Train Epoch: 5 [3840/37519 (10%)]\tLoss: 0.306763\n",
      "Train Epoch: 5 [4480/37519 (12%)]\tLoss: 0.196883\n",
      "Train Epoch: 5 [5120/37519 (14%)]\tLoss: 0.107964\n",
      "Train Epoch: 5 [5760/37519 (15%)]\tLoss: 0.142810\n",
      "Train Epoch: 5 [6400/37519 (17%)]\tLoss: 0.132556\n",
      "Train Epoch: 5 [7040/37519 (19%)]\tLoss: 0.123021\n",
      "Train Epoch: 5 [7680/37519 (20%)]\tLoss: 0.087919\n",
      "Train Epoch: 5 [8320/37519 (22%)]\tLoss: 0.166069\n",
      "Train Epoch: 5 [8960/37519 (24%)]\tLoss: 0.141981\n",
      "Train Epoch: 5 [9600/37519 (26%)]\tLoss: 0.086653\n",
      "Train Epoch: 5 [10240/37519 (27%)]\tLoss: 0.305587\n",
      "Train Epoch: 5 [10880/37519 (29%)]\tLoss: 0.087277\n",
      "Train Epoch: 5 [11520/37519 (31%)]\tLoss: 0.092454\n",
      "Train Epoch: 5 [12160/37519 (32%)]\tLoss: 0.109038\n",
      "Train Epoch: 5 [12800/37519 (34%)]\tLoss: 0.165462\n",
      "Train Epoch: 5 [13440/37519 (36%)]\tLoss: 0.131415\n",
      "Train Epoch: 5 [14080/37519 (37%)]\tLoss: 0.191537\n",
      "Train Epoch: 5 [14720/37519 (39%)]\tLoss: 0.139175\n",
      "Train Epoch: 5 [15360/37519 (41%)]\tLoss: 0.107565\n",
      "Train Epoch: 5 [16000/37519 (43%)]\tLoss: 0.123178\n",
      "Train Epoch: 5 [16640/37519 (44%)]\tLoss: 0.161050\n",
      "Train Epoch: 5 [17280/37519 (46%)]\tLoss: 0.187430\n",
      "Train Epoch: 5 [17920/37519 (48%)]\tLoss: 0.360245\n",
      "Train Epoch: 5 [18560/37519 (49%)]\tLoss: 0.184289\n",
      "Train Epoch: 5 [19200/37519 (51%)]\tLoss: 0.075268\n",
      "Train Epoch: 5 [19840/37519 (53%)]\tLoss: 0.176478\n",
      "Train Epoch: 5 [20480/37519 (55%)]\tLoss: 0.205358\n",
      "Train Epoch: 5 [21120/37519 (56%)]\tLoss: 0.426097\n",
      "Train Epoch: 5 [21760/37519 (58%)]\tLoss: 0.151571\n",
      "Train Epoch: 5 [22400/37519 (60%)]\tLoss: 0.081817\n",
      "Train Epoch: 5 [23040/37519 (61%)]\tLoss: 0.089110\n",
      "Train Epoch: 5 [23680/37519 (63%)]\tLoss: 0.164882\n",
      "Train Epoch: 5 [24320/37519 (65%)]\tLoss: 0.256776\n",
      "Train Epoch: 5 [24960/37519 (66%)]\tLoss: 0.201716\n",
      "Train Epoch: 5 [25600/37519 (68%)]\tLoss: 0.087667\n",
      "Train Epoch: 5 [26240/37519 (70%)]\tLoss: 0.194240\n",
      "Train Epoch: 5 [26880/37519 (72%)]\tLoss: 0.120761\n",
      "Train Epoch: 5 [27520/37519 (73%)]\tLoss: 0.114682\n",
      "Train Epoch: 5 [28160/37519 (75%)]\tLoss: 0.113283\n",
      "Train Epoch: 5 [28800/37519 (77%)]\tLoss: 0.125173\n",
      "Train Epoch: 5 [29440/37519 (78%)]\tLoss: 0.127411\n",
      "Train Epoch: 5 [30080/37519 (80%)]\tLoss: 0.088027\n",
      "Train Epoch: 5 [30720/37519 (82%)]\tLoss: 0.118263\n",
      "Train Epoch: 5 [31360/37519 (83%)]\tLoss: 0.113551\n",
      "Train Epoch: 5 [32000/37519 (85%)]\tLoss: 0.200244\n",
      "Train Epoch: 5 [32640/37519 (87%)]\tLoss: 0.192926\n",
      "Train Epoch: 5 [33280/37519 (89%)]\tLoss: 0.330444\n",
      "Train Epoch: 5 [33920/37519 (90%)]\tLoss: 0.258214\n",
      "Train Epoch: 5 [34560/37519 (92%)]\tLoss: 0.253095\n",
      "Train Epoch: 5 [35200/37519 (94%)]\tLoss: 0.169766\n",
      "Train Epoch: 5 [35840/37519 (95%)]\tLoss: 0.125245\n",
      "Train Epoch: 5 [36480/37519 (97%)]\tLoss: 0.056554\n",
      "Train Epoch: 5 [37120/37519 (99%)]\tLoss: 0.230737\n",
      "Train Epoch: 6 [0/37519 (0%)]\tLoss: 0.189733\n",
      "Train Epoch: 6 [640/37519 (2%)]\tLoss: 0.280980\n",
      "Train Epoch: 6 [1280/37519 (3%)]\tLoss: 0.127638\n",
      "Train Epoch: 6 [1920/37519 (5%)]\tLoss: 0.319941\n",
      "Train Epoch: 6 [2560/37519 (7%)]\tLoss: 0.099099\n",
      "Train Epoch: 6 [3200/37519 (9%)]\tLoss: 0.079602\n",
      "Train Epoch: 6 [3840/37519 (10%)]\tLoss: 0.164994\n",
      "Train Epoch: 6 [4480/37519 (12%)]\tLoss: 0.134286\n",
      "Train Epoch: 6 [5120/37519 (14%)]\tLoss: 0.367602\n",
      "Train Epoch: 6 [5760/37519 (15%)]\tLoss: 0.088635\n",
      "Train Epoch: 6 [6400/37519 (17%)]\tLoss: 0.135400\n",
      "Train Epoch: 6 [7040/37519 (19%)]\tLoss: 0.190976\n",
      "Train Epoch: 6 [7680/37519 (20%)]\tLoss: 0.052334\n",
      "Train Epoch: 6 [8320/37519 (22%)]\tLoss: 0.092318\n",
      "Train Epoch: 6 [8960/37519 (24%)]\tLoss: 0.149817\n",
      "Train Epoch: 6 [9600/37519 (26%)]\tLoss: 0.123856\n",
      "Train Epoch: 6 [10240/37519 (27%)]\tLoss: 0.191685\n",
      "Train Epoch: 6 [10880/37519 (29%)]\tLoss: 0.173876\n",
      "Train Epoch: 6 [11520/37519 (31%)]\tLoss: 0.106674\n",
      "Train Epoch: 6 [12160/37519 (32%)]\tLoss: 0.176376\n",
      "Train Epoch: 6 [12800/37519 (34%)]\tLoss: 0.064952\n",
      "Train Epoch: 6 [13440/37519 (36%)]\tLoss: 0.208275\n",
      "Train Epoch: 6 [14080/37519 (37%)]\tLoss: 0.175256\n",
      "Train Epoch: 6 [14720/37519 (39%)]\tLoss: 0.209555\n",
      "Train Epoch: 6 [15360/37519 (41%)]\tLoss: 0.097038\n",
      "Train Epoch: 6 [16000/37519 (43%)]\tLoss: 0.382418\n",
      "Train Epoch: 6 [16640/37519 (44%)]\tLoss: 0.179883\n",
      "Train Epoch: 6 [17280/37519 (46%)]\tLoss: 0.195521\n",
      "Train Epoch: 6 [17920/37519 (48%)]\tLoss: 0.078458\n",
      "Train Epoch: 6 [18560/37519 (49%)]\tLoss: 0.067456\n",
      "Train Epoch: 6 [19200/37519 (51%)]\tLoss: 0.138690\n",
      "Train Epoch: 6 [19840/37519 (53%)]\tLoss: 0.226056\n",
      "Train Epoch: 6 [20480/37519 (55%)]\tLoss: 0.195772\n",
      "Train Epoch: 6 [21120/37519 (56%)]\tLoss: 0.278217\n",
      "Train Epoch: 6 [21760/37519 (58%)]\tLoss: 0.150289\n",
      "Train Epoch: 6 [22400/37519 (60%)]\tLoss: 0.372244\n",
      "Train Epoch: 6 [23040/37519 (61%)]\tLoss: 0.091824\n",
      "Train Epoch: 6 [23680/37519 (63%)]\tLoss: 0.045126\n",
      "Train Epoch: 6 [24320/37519 (65%)]\tLoss: 0.074075\n",
      "Train Epoch: 6 [24960/37519 (66%)]\tLoss: 0.270709\n",
      "Train Epoch: 6 [25600/37519 (68%)]\tLoss: 0.237875\n",
      "Train Epoch: 6 [26240/37519 (70%)]\tLoss: 0.081695\n",
      "Train Epoch: 6 [26880/37519 (72%)]\tLoss: 0.147386\n",
      "Train Epoch: 6 [27520/37519 (73%)]\tLoss: 0.204355\n",
      "Train Epoch: 6 [28160/37519 (75%)]\tLoss: 0.156853\n",
      "Train Epoch: 6 [28800/37519 (77%)]\tLoss: 0.231140\n",
      "Train Epoch: 6 [29440/37519 (78%)]\tLoss: 0.280488\n",
      "Train Epoch: 6 [30080/37519 (80%)]\tLoss: 0.093573\n",
      "Train Epoch: 6 [30720/37519 (82%)]\tLoss: 0.075557\n",
      "Train Epoch: 6 [31360/37519 (83%)]\tLoss: 0.165055\n",
      "Train Epoch: 6 [32000/37519 (85%)]\tLoss: 0.234184\n",
      "Train Epoch: 6 [32640/37519 (87%)]\tLoss: 0.150850\n",
      "Train Epoch: 6 [33280/37519 (89%)]\tLoss: 0.163453\n",
      "Train Epoch: 6 [33920/37519 (90%)]\tLoss: 0.296789\n",
      "Train Epoch: 6 [34560/37519 (92%)]\tLoss: 0.254922\n",
      "Train Epoch: 6 [35200/37519 (94%)]\tLoss: 0.121254\n",
      "Train Epoch: 6 [35840/37519 (95%)]\tLoss: 0.298390\n",
      "Train Epoch: 6 [36480/37519 (97%)]\tLoss: 0.065961\n",
      "Train Epoch: 6 [37120/37519 (99%)]\tLoss: 0.081044\n",
      "Train Epoch: 7 [0/37519 (0%)]\tLoss: 0.131346\n",
      "Train Epoch: 7 [640/37519 (2%)]\tLoss: 0.128991\n",
      "Train Epoch: 7 [1280/37519 (3%)]\tLoss: 0.065808\n",
      "Train Epoch: 7 [1920/37519 (5%)]\tLoss: 0.104784\n",
      "Train Epoch: 7 [2560/37519 (7%)]\tLoss: 0.076614\n",
      "Train Epoch: 7 [3200/37519 (9%)]\tLoss: 0.276345\n",
      "Train Epoch: 7 [3840/37519 (10%)]\tLoss: 0.111323\n",
      "Train Epoch: 7 [4480/37519 (12%)]\tLoss: 0.362584\n",
      "Train Epoch: 7 [5120/37519 (14%)]\tLoss: 0.159587\n",
      "Train Epoch: 7 [5760/37519 (15%)]\tLoss: 0.116497\n",
      "Train Epoch: 7 [6400/37519 (17%)]\tLoss: 0.168728\n",
      "Train Epoch: 7 [7040/37519 (19%)]\tLoss: 0.129325\n",
      "Train Epoch: 7 [7680/37519 (20%)]\tLoss: 0.203902\n",
      "Train Epoch: 7 [8320/37519 (22%)]\tLoss: 0.175666\n",
      "Train Epoch: 7 [8960/37519 (24%)]\tLoss: 0.172575\n",
      "Train Epoch: 7 [9600/37519 (26%)]\tLoss: 0.162250\n",
      "Train Epoch: 7 [10240/37519 (27%)]\tLoss: 0.383897\n",
      "Train Epoch: 7 [10880/37519 (29%)]\tLoss: 0.101454\n",
      "Train Epoch: 7 [11520/37519 (31%)]\tLoss: 0.101351\n",
      "Train Epoch: 7 [12160/37519 (32%)]\tLoss: 0.227067\n",
      "Train Epoch: 7 [12800/37519 (34%)]\tLoss: 0.191646\n",
      "Train Epoch: 7 [13440/37519 (36%)]\tLoss: 0.233268\n",
      "Train Epoch: 7 [14080/37519 (37%)]\tLoss: 0.114686\n",
      "Train Epoch: 7 [14720/37519 (39%)]\tLoss: 0.202960\n",
      "Train Epoch: 7 [15360/37519 (41%)]\tLoss: 0.115891\n",
      "Train Epoch: 7 [16000/37519 (43%)]\tLoss: 0.030138\n",
      "Train Epoch: 7 [16640/37519 (44%)]\tLoss: 0.295916\n",
      "Train Epoch: 7 [17280/37519 (46%)]\tLoss: 0.146594\n",
      "Train Epoch: 7 [17920/37519 (48%)]\tLoss: 0.172970\n",
      "Train Epoch: 7 [18560/37519 (49%)]\tLoss: 0.120836\n",
      "Train Epoch: 7 [19200/37519 (51%)]\tLoss: 0.082264\n",
      "Train Epoch: 7 [19840/37519 (53%)]\tLoss: 0.122205\n",
      "Train Epoch: 7 [20480/37519 (55%)]\tLoss: 0.059143\n",
      "Train Epoch: 7 [21120/37519 (56%)]\tLoss: 0.140777\n",
      "Train Epoch: 7 [21760/37519 (58%)]\tLoss: 0.134885\n",
      "Train Epoch: 7 [22400/37519 (60%)]\tLoss: 0.151937\n",
      "Train Epoch: 7 [23040/37519 (61%)]\tLoss: 0.181911\n",
      "Train Epoch: 7 [23680/37519 (63%)]\tLoss: 0.093325\n",
      "Train Epoch: 7 [24320/37519 (65%)]\tLoss: 0.218348\n",
      "Train Epoch: 7 [24960/37519 (66%)]\tLoss: 0.052240\n",
      "Train Epoch: 7 [25600/37519 (68%)]\tLoss: 0.120139\n",
      "Train Epoch: 7 [26240/37519 (70%)]\tLoss: 0.269088\n",
      "Train Epoch: 7 [26880/37519 (72%)]\tLoss: 0.182544\n",
      "Train Epoch: 7 [27520/37519 (73%)]\tLoss: 0.174738\n",
      "Train Epoch: 7 [28160/37519 (75%)]\tLoss: 0.070258\n",
      "Train Epoch: 7 [28800/37519 (77%)]\tLoss: 0.143749\n",
      "Train Epoch: 7 [29440/37519 (78%)]\tLoss: 0.304348\n",
      "Train Epoch: 7 [30080/37519 (80%)]\tLoss: 0.243268\n",
      "Train Epoch: 7 [30720/37519 (82%)]\tLoss: 0.101915\n",
      "Train Epoch: 7 [31360/37519 (83%)]\tLoss: 0.098533\n",
      "Train Epoch: 7 [32000/37519 (85%)]\tLoss: 0.073976\n",
      "Train Epoch: 7 [32640/37519 (87%)]\tLoss: 0.123627\n",
      "Train Epoch: 7 [33280/37519 (89%)]\tLoss: 0.204615\n",
      "Train Epoch: 7 [33920/37519 (90%)]\tLoss: 0.133073\n",
      "Train Epoch: 7 [34560/37519 (92%)]\tLoss: 0.096181\n",
      "Train Epoch: 7 [35200/37519 (94%)]\tLoss: 0.147953\n",
      "Train Epoch: 7 [35840/37519 (95%)]\tLoss: 0.153681\n",
      "Train Epoch: 7 [36480/37519 (97%)]\tLoss: 0.153726\n",
      "Train Epoch: 7 [37120/37519 (99%)]\tLoss: 0.091924\n",
      "Train Epoch: 8 [0/37519 (0%)]\tLoss: 0.194541\n",
      "Train Epoch: 8 [640/37519 (2%)]\tLoss: 0.164122\n",
      "Train Epoch: 8 [1280/37519 (3%)]\tLoss: 0.212927\n",
      "Train Epoch: 8 [1920/37519 (5%)]\tLoss: 0.198898\n",
      "Train Epoch: 8 [2560/37519 (7%)]\tLoss: 0.114278\n",
      "Train Epoch: 8 [3200/37519 (9%)]\tLoss: 0.048937\n",
      "Train Epoch: 8 [3840/37519 (10%)]\tLoss: 0.197177\n",
      "Train Epoch: 8 [4480/37519 (12%)]\tLoss: 0.227199\n",
      "Train Epoch: 8 [5120/37519 (14%)]\tLoss: 0.157932\n",
      "Train Epoch: 8 [5760/37519 (15%)]\tLoss: 0.172889\n",
      "Train Epoch: 8 [6400/37519 (17%)]\tLoss: 0.139527\n",
      "Train Epoch: 8 [7040/37519 (19%)]\tLoss: 0.176481\n",
      "Train Epoch: 8 [7680/37519 (20%)]\tLoss: 0.124667\n",
      "Train Epoch: 8 [8320/37519 (22%)]\tLoss: 0.097717\n",
      "Train Epoch: 8 [8960/37519 (24%)]\tLoss: 0.176692\n",
      "Train Epoch: 8 [9600/37519 (26%)]\tLoss: 0.068901\n",
      "Train Epoch: 8 [10240/37519 (27%)]\tLoss: 0.107048\n",
      "Train Epoch: 8 [10880/37519 (29%)]\tLoss: 0.098203\n",
      "Train Epoch: 8 [11520/37519 (31%)]\tLoss: 0.219618\n",
      "Train Epoch: 8 [12160/37519 (32%)]\tLoss: 0.145153\n",
      "Train Epoch: 8 [12800/37519 (34%)]\tLoss: 0.276275\n",
      "Train Epoch: 8 [13440/37519 (36%)]\tLoss: 0.159527\n",
      "Train Epoch: 8 [14080/37519 (37%)]\tLoss: 0.131648\n",
      "Train Epoch: 8 [14720/37519 (39%)]\tLoss: 0.049072\n",
      "Train Epoch: 8 [15360/37519 (41%)]\tLoss: 0.055394\n",
      "Train Epoch: 8 [16000/37519 (43%)]\tLoss: 0.142576\n",
      "Train Epoch: 8 [16640/37519 (44%)]\tLoss: 0.139004\n",
      "Train Epoch: 8 [17280/37519 (46%)]\tLoss: 0.248335\n",
      "Train Epoch: 8 [17920/37519 (48%)]\tLoss: 0.143446\n",
      "Train Epoch: 8 [18560/37519 (49%)]\tLoss: 0.073018\n",
      "Train Epoch: 8 [19200/37519 (51%)]\tLoss: 0.144593\n",
      "Train Epoch: 8 [19840/37519 (53%)]\tLoss: 0.263442\n",
      "Train Epoch: 8 [20480/37519 (55%)]\tLoss: 0.123835\n",
      "Train Epoch: 8 [21120/37519 (56%)]\tLoss: 0.083031\n",
      "Train Epoch: 8 [21760/37519 (58%)]\tLoss: 0.282606\n",
      "Train Epoch: 8 [22400/37519 (60%)]\tLoss: 0.159193\n",
      "Train Epoch: 8 [23040/37519 (61%)]\tLoss: 0.205373\n",
      "Train Epoch: 8 [23680/37519 (63%)]\tLoss: 0.078151\n",
      "Train Epoch: 8 [24320/37519 (65%)]\tLoss: 0.062602\n",
      "Train Epoch: 8 [24960/37519 (66%)]\tLoss: 0.184531\n",
      "Train Epoch: 8 [25600/37519 (68%)]\tLoss: 0.240252\n",
      "Train Epoch: 8 [26240/37519 (70%)]\tLoss: 0.258334\n",
      "Train Epoch: 8 [26880/37519 (72%)]\tLoss: 0.315215\n",
      "Train Epoch: 8 [27520/37519 (73%)]\tLoss: 0.100473\n",
      "Train Epoch: 8 [28160/37519 (75%)]\tLoss: 0.174341\n",
      "Train Epoch: 8 [28800/37519 (77%)]\tLoss: 0.200623\n",
      "Train Epoch: 8 [29440/37519 (78%)]\tLoss: 0.113461\n",
      "Train Epoch: 8 [30080/37519 (80%)]\tLoss: 0.110428\n",
      "Train Epoch: 8 [30720/37519 (82%)]\tLoss: 0.063181\n",
      "Train Epoch: 8 [31360/37519 (83%)]\tLoss: 0.126020\n",
      "Train Epoch: 8 [32000/37519 (85%)]\tLoss: 0.314205\n",
      "Train Epoch: 8 [32640/37519 (87%)]\tLoss: 0.342719\n",
      "Train Epoch: 8 [33280/37519 (89%)]\tLoss: 0.141040\n",
      "Train Epoch: 8 [33920/37519 (90%)]\tLoss: 0.040370\n",
      "Train Epoch: 8 [34560/37519 (92%)]\tLoss: 0.152853\n",
      "Train Epoch: 8 [35200/37519 (94%)]\tLoss: 0.122521\n",
      "Train Epoch: 8 [35840/37519 (95%)]\tLoss: 0.316529\n",
      "Train Epoch: 8 [36480/37519 (97%)]\tLoss: 0.268907\n",
      "Train Epoch: 8 [37120/37519 (99%)]\tLoss: 0.102902\n",
      "Train Epoch: 9 [0/37519 (0%)]\tLoss: 0.228612\n",
      "Train Epoch: 9 [640/37519 (2%)]\tLoss: 0.223570\n",
      "Train Epoch: 9 [1280/37519 (3%)]\tLoss: 0.208918\n",
      "Train Epoch: 9 [1920/37519 (5%)]\tLoss: 0.079204\n",
      "Train Epoch: 9 [2560/37519 (7%)]\tLoss: 0.284232\n",
      "Train Epoch: 9 [3200/37519 (9%)]\tLoss: 0.124493\n",
      "Train Epoch: 9 [3840/37519 (10%)]\tLoss: 0.106035\n",
      "Train Epoch: 9 [4480/37519 (12%)]\tLoss: 0.229771\n",
      "Train Epoch: 9 [5120/37519 (14%)]\tLoss: 0.104122\n",
      "Train Epoch: 9 [5760/37519 (15%)]\tLoss: 0.083739\n",
      "Train Epoch: 9 [6400/37519 (17%)]\tLoss: 0.118638\n",
      "Train Epoch: 9 [7040/37519 (19%)]\tLoss: 0.130252\n",
      "Train Epoch: 9 [7680/37519 (20%)]\tLoss: 0.186020\n",
      "Train Epoch: 9 [8320/37519 (22%)]\tLoss: 0.271582\n",
      "Train Epoch: 9 [8960/37519 (24%)]\tLoss: 0.149877\n",
      "Train Epoch: 9 [9600/37519 (26%)]\tLoss: 0.277402\n",
      "Train Epoch: 9 [10240/37519 (27%)]\tLoss: 0.105853\n",
      "Train Epoch: 9 [10880/37519 (29%)]\tLoss: 0.174487\n",
      "Train Epoch: 9 [11520/37519 (31%)]\tLoss: 0.179170\n",
      "Train Epoch: 9 [12160/37519 (32%)]\tLoss: 0.102567\n",
      "Train Epoch: 9 [12800/37519 (34%)]\tLoss: 0.112472\n",
      "Train Epoch: 9 [13440/37519 (36%)]\tLoss: 0.098370\n",
      "Train Epoch: 9 [14080/37519 (37%)]\tLoss: 0.260951\n",
      "Train Epoch: 9 [14720/37519 (39%)]\tLoss: 0.194053\n",
      "Train Epoch: 9 [15360/37519 (41%)]\tLoss: 0.145922\n",
      "Train Epoch: 9 [16000/37519 (43%)]\tLoss: 0.156518\n",
      "Train Epoch: 9 [16640/37519 (44%)]\tLoss: 0.252803\n",
      "Train Epoch: 9 [17280/37519 (46%)]\tLoss: 0.356450\n",
      "Train Epoch: 9 [17920/37519 (48%)]\tLoss: 0.114891\n",
      "Train Epoch: 9 [18560/37519 (49%)]\tLoss: 0.077784\n",
      "Train Epoch: 9 [19200/37519 (51%)]\tLoss: 0.145097\n",
      "Train Epoch: 9 [19840/37519 (53%)]\tLoss: 0.058094\n",
      "Train Epoch: 9 [20480/37519 (55%)]\tLoss: 0.213731\n",
      "Train Epoch: 9 [21120/37519 (56%)]\tLoss: 0.309747\n",
      "Train Epoch: 9 [21760/37519 (58%)]\tLoss: 0.115704\n",
      "Train Epoch: 9 [22400/37519 (60%)]\tLoss: 0.231093\n",
      "Train Epoch: 9 [23040/37519 (61%)]\tLoss: 0.101238\n",
      "Train Epoch: 9 [23680/37519 (63%)]\tLoss: 0.172547\n",
      "Train Epoch: 9 [24320/37519 (65%)]\tLoss: 0.089702\n",
      "Train Epoch: 9 [24960/37519 (66%)]\tLoss: 0.090176\n",
      "Train Epoch: 9 [25600/37519 (68%)]\tLoss: 0.050361\n",
      "Train Epoch: 9 [26240/37519 (70%)]\tLoss: 0.087385\n",
      "Train Epoch: 9 [26880/37519 (72%)]\tLoss: 0.116024\n",
      "Train Epoch: 9 [27520/37519 (73%)]\tLoss: 0.144791\n",
      "Train Epoch: 9 [28160/37519 (75%)]\tLoss: 0.082419\n",
      "Train Epoch: 9 [28800/37519 (77%)]\tLoss: 0.074152\n",
      "Train Epoch: 9 [29440/37519 (78%)]\tLoss: 0.036880\n",
      "Train Epoch: 9 [30080/37519 (80%)]\tLoss: 0.147592\n",
      "Train Epoch: 9 [30720/37519 (82%)]\tLoss: 0.153469\n",
      "Train Epoch: 9 [31360/37519 (83%)]\tLoss: 0.241303\n",
      "Train Epoch: 9 [32000/37519 (85%)]\tLoss: 0.083763\n",
      "Train Epoch: 9 [32640/37519 (87%)]\tLoss: 0.281251\n",
      "Train Epoch: 9 [33280/37519 (89%)]\tLoss: 0.086030\n",
      "Train Epoch: 9 [33920/37519 (90%)]\tLoss: 0.076523\n",
      "Train Epoch: 9 [34560/37519 (92%)]\tLoss: 0.164256\n",
      "Train Epoch: 9 [35200/37519 (94%)]\tLoss: 0.061702\n",
      "Train Epoch: 9 [35840/37519 (95%)]\tLoss: 0.306270\n",
      "Train Epoch: 9 [36480/37519 (97%)]\tLoss: 0.121989\n",
      "Train Epoch: 9 [37120/37519 (99%)]\tLoss: 0.256482\n",
      "Train Epoch: 10 [0/37519 (0%)]\tLoss: 0.125906\n",
      "Train Epoch: 10 [640/37519 (2%)]\tLoss: 0.141437\n",
      "Train Epoch: 10 [1280/37519 (3%)]\tLoss: 0.234269\n",
      "Train Epoch: 10 [1920/37519 (5%)]\tLoss: 0.512038\n",
      "Train Epoch: 10 [2560/37519 (7%)]\tLoss: 0.176766\n",
      "Train Epoch: 10 [3200/37519 (9%)]\tLoss: 0.099283\n",
      "Train Epoch: 10 [3840/37519 (10%)]\tLoss: 0.190261\n",
      "Train Epoch: 10 [4480/37519 (12%)]\tLoss: 0.091104\n",
      "Train Epoch: 10 [5120/37519 (14%)]\tLoss: 0.064453\n",
      "Train Epoch: 10 [5760/37519 (15%)]\tLoss: 0.143259\n",
      "Train Epoch: 10 [6400/37519 (17%)]\tLoss: 0.163978\n",
      "Train Epoch: 10 [7040/37519 (19%)]\tLoss: 0.193620\n",
      "Train Epoch: 10 [7680/37519 (20%)]\tLoss: 0.109028\n",
      "Train Epoch: 10 [8320/37519 (22%)]\tLoss: 0.313444\n",
      "Train Epoch: 10 [8960/37519 (24%)]\tLoss: 0.076989\n",
      "Train Epoch: 10 [9600/37519 (26%)]\tLoss: 0.187258\n",
      "Train Epoch: 10 [10240/37519 (27%)]\tLoss: 0.119223\n",
      "Train Epoch: 10 [10880/37519 (29%)]\tLoss: 0.071493\n",
      "Train Epoch: 10 [11520/37519 (31%)]\tLoss: 0.352307\n",
      "Train Epoch: 10 [12160/37519 (32%)]\tLoss: 0.154335\n",
      "Train Epoch: 10 [12800/37519 (34%)]\tLoss: 0.063049\n",
      "Train Epoch: 10 [13440/37519 (36%)]\tLoss: 0.087281\n",
      "Train Epoch: 10 [14080/37519 (37%)]\tLoss: 0.145536\n",
      "Train Epoch: 10 [14720/37519 (39%)]\tLoss: 0.160631\n",
      "Train Epoch: 10 [15360/37519 (41%)]\tLoss: 0.028831\n",
      "Train Epoch: 10 [16000/37519 (43%)]\tLoss: 0.107496\n",
      "Train Epoch: 10 [16640/37519 (44%)]\tLoss: 0.226940\n",
      "Train Epoch: 10 [17280/37519 (46%)]\tLoss: 0.247211\n",
      "Train Epoch: 10 [17920/37519 (48%)]\tLoss: 0.104194\n",
      "Train Epoch: 10 [18560/37519 (49%)]\tLoss: 0.291305\n",
      "Train Epoch: 10 [19200/37519 (51%)]\tLoss: 0.053053\n",
      "Train Epoch: 10 [19840/37519 (53%)]\tLoss: 0.148381\n",
      "Train Epoch: 10 [20480/37519 (55%)]\tLoss: 0.324463\n",
      "Train Epoch: 10 [21120/37519 (56%)]\tLoss: 0.092008\n",
      "Train Epoch: 10 [21760/37519 (58%)]\tLoss: 0.075381\n",
      "Train Epoch: 10 [22400/37519 (60%)]\tLoss: 0.274374\n",
      "Train Epoch: 10 [23040/37519 (61%)]\tLoss: 0.248663\n",
      "Train Epoch: 10 [23680/37519 (63%)]\tLoss: 0.266413\n",
      "Train Epoch: 10 [24320/37519 (65%)]\tLoss: 0.330194\n",
      "Train Epoch: 10 [24960/37519 (66%)]\tLoss: 0.168660\n",
      "Train Epoch: 10 [25600/37519 (68%)]\tLoss: 0.067141\n",
      "Train Epoch: 10 [26240/37519 (70%)]\tLoss: 0.103042\n",
      "Train Epoch: 10 [26880/37519 (72%)]\tLoss: 0.317105\n",
      "Train Epoch: 10 [27520/37519 (73%)]\tLoss: 0.148983\n",
      "Train Epoch: 10 [28160/37519 (75%)]\tLoss: 0.160217\n",
      "Train Epoch: 10 [28800/37519 (77%)]\tLoss: 0.158043\n",
      "Train Epoch: 10 [29440/37519 (78%)]\tLoss: 0.155188\n",
      "Train Epoch: 10 [30080/37519 (80%)]\tLoss: 0.303099\n",
      "Train Epoch: 10 [30720/37519 (82%)]\tLoss: 0.207275\n",
      "Train Epoch: 10 [31360/37519 (83%)]\tLoss: 0.118667\n",
      "Train Epoch: 10 [32000/37519 (85%)]\tLoss: 0.151856\n",
      "Train Epoch: 10 [32640/37519 (87%)]\tLoss: 0.240634\n",
      "Train Epoch: 10 [33280/37519 (89%)]\tLoss: 0.059486\n",
      "Train Epoch: 10 [33920/37519 (90%)]\tLoss: 0.201582\n",
      "Train Epoch: 10 [34560/37519 (92%)]\tLoss: 0.119125\n",
      "Train Epoch: 10 [35200/37519 (94%)]\tLoss: 0.091045\n",
      "Train Epoch: 10 [35840/37519 (95%)]\tLoss: 0.057311\n",
      "Train Epoch: 10 [36480/37519 (97%)]\tLoss: 0.189206\n",
      "Train Epoch: 10 [37120/37519 (99%)]\tLoss: 0.093720\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/22481 (0%)]\tLoss: 0.258469\n",
      "Train Epoch: 1 [640/22481 (3%)]\tLoss: 0.238875\n",
      "Train Epoch: 1 [1280/22481 (6%)]\tLoss: 0.287526\n",
      "Train Epoch: 1 [1920/22481 (9%)]\tLoss: 0.152915\n",
      "Train Epoch: 1 [2560/22481 (11%)]\tLoss: 0.144198\n",
      "Train Epoch: 1 [3200/22481 (14%)]\tLoss: 0.243943\n",
      "Train Epoch: 1 [3840/22481 (17%)]\tLoss: 0.154632\n",
      "Train Epoch: 1 [4480/22481 (20%)]\tLoss: 0.337565\n",
      "Train Epoch: 1 [5120/22481 (23%)]\tLoss: 0.270664\n",
      "Train Epoch: 1 [5760/22481 (26%)]\tLoss: 0.182866\n",
      "Train Epoch: 1 [6400/22481 (28%)]\tLoss: 0.379623\n",
      "Train Epoch: 1 [7040/22481 (31%)]\tLoss: 0.330016\n",
      "Train Epoch: 1 [7680/22481 (34%)]\tLoss: 0.150381\n",
      "Train Epoch: 1 [8320/22481 (37%)]\tLoss: 0.097845\n",
      "Train Epoch: 1 [8960/22481 (40%)]\tLoss: 0.127738\n",
      "Train Epoch: 1 [9600/22481 (43%)]\tLoss: 0.133531\n",
      "Train Epoch: 1 [10240/22481 (45%)]\tLoss: 0.194001\n",
      "Train Epoch: 1 [10880/22481 (48%)]\tLoss: 0.126672\n",
      "Train Epoch: 1 [11520/22481 (51%)]\tLoss: 0.129119\n",
      "Train Epoch: 1 [12160/22481 (54%)]\tLoss: 0.174071\n",
      "Train Epoch: 1 [12800/22481 (57%)]\tLoss: 0.112064\n",
      "Train Epoch: 1 [13440/22481 (60%)]\tLoss: 0.209515\n",
      "Train Epoch: 1 [14080/22481 (62%)]\tLoss: 0.299214\n",
      "Train Epoch: 1 [14720/22481 (65%)]\tLoss: 0.209864\n",
      "Train Epoch: 1 [15360/22481 (68%)]\tLoss: 0.192376\n",
      "Train Epoch: 1 [16000/22481 (71%)]\tLoss: 0.145884\n",
      "Train Epoch: 1 [16640/22481 (74%)]\tLoss: 0.354155\n",
      "Train Epoch: 1 [17280/22481 (77%)]\tLoss: 0.151205\n",
      "Train Epoch: 1 [17920/22481 (80%)]\tLoss: 0.185361\n",
      "Train Epoch: 1 [18560/22481 (82%)]\tLoss: 0.139977\n",
      "Train Epoch: 1 [19200/22481 (85%)]\tLoss: 0.169021\n",
      "Train Epoch: 1 [19840/22481 (88%)]\tLoss: 0.193029\n",
      "Train Epoch: 1 [20480/22481 (91%)]\tLoss: 0.237154\n",
      "Train Epoch: 1 [21120/22481 (94%)]\tLoss: 0.242852\n",
      "Train Epoch: 1 [21760/22481 (97%)]\tLoss: 0.256684\n",
      "Train Epoch: 1 [22400/22481 (99%)]\tLoss: 0.239911\n",
      "Train Epoch: 2 [0/22481 (0%)]\tLoss: 0.255296\n",
      "Train Epoch: 2 [640/22481 (3%)]\tLoss: 0.110502\n",
      "Train Epoch: 2 [1280/22481 (6%)]\tLoss: 0.307429\n",
      "Train Epoch: 2 [1920/22481 (9%)]\tLoss: 0.239590\n",
      "Train Epoch: 2 [2560/22481 (11%)]\tLoss: 0.192272\n",
      "Train Epoch: 2 [3200/22481 (14%)]\tLoss: 0.189735\n",
      "Train Epoch: 2 [3840/22481 (17%)]\tLoss: 0.076768\n",
      "Train Epoch: 2 [4480/22481 (20%)]\tLoss: 0.151569\n",
      "Train Epoch: 2 [5120/22481 (23%)]\tLoss: 0.163135\n",
      "Train Epoch: 2 [5760/22481 (26%)]\tLoss: 0.159655\n",
      "Train Epoch: 2 [6400/22481 (28%)]\tLoss: 0.153930\n",
      "Train Epoch: 2 [7040/22481 (31%)]\tLoss: 0.358281\n",
      "Train Epoch: 2 [7680/22481 (34%)]\tLoss: 0.134508\n",
      "Train Epoch: 2 [8320/22481 (37%)]\tLoss: 0.315075\n",
      "Train Epoch: 2 [8960/22481 (40%)]\tLoss: 0.219359\n",
      "Train Epoch: 2 [9600/22481 (43%)]\tLoss: 0.228828\n",
      "Train Epoch: 2 [10240/22481 (45%)]\tLoss: 0.294706\n",
      "Train Epoch: 2 [10880/22481 (48%)]\tLoss: 0.247404\n",
      "Train Epoch: 2 [11520/22481 (51%)]\tLoss: 0.191440\n",
      "Train Epoch: 2 [12160/22481 (54%)]\tLoss: 0.207820\n",
      "Train Epoch: 2 [12800/22481 (57%)]\tLoss: 0.281607\n",
      "Train Epoch: 2 [13440/22481 (60%)]\tLoss: 0.106213\n",
      "Train Epoch: 2 [14080/22481 (62%)]\tLoss: 0.146739\n",
      "Train Epoch: 2 [14720/22481 (65%)]\tLoss: 0.093912\n",
      "Train Epoch: 2 [15360/22481 (68%)]\tLoss: 0.076648\n",
      "Train Epoch: 2 [16000/22481 (71%)]\tLoss: 0.202963\n",
      "Train Epoch: 2 [16640/22481 (74%)]\tLoss: 0.177046\n",
      "Train Epoch: 2 [17280/22481 (77%)]\tLoss: 0.123762\n",
      "Train Epoch: 2 [17920/22481 (80%)]\tLoss: 0.289062\n",
      "Train Epoch: 2 [18560/22481 (82%)]\tLoss: 0.126661\n",
      "Train Epoch: 2 [19200/22481 (85%)]\tLoss: 0.103447\n",
      "Train Epoch: 2 [19840/22481 (88%)]\tLoss: 0.200911\n",
      "Train Epoch: 2 [20480/22481 (91%)]\tLoss: 0.159284\n",
      "Train Epoch: 2 [21120/22481 (94%)]\tLoss: 0.196525\n",
      "Train Epoch: 2 [21760/22481 (97%)]\tLoss: 0.094185\n",
      "Train Epoch: 2 [22400/22481 (99%)]\tLoss: 0.164501\n",
      "Train Epoch: 3 [0/22481 (0%)]\tLoss: 0.321463\n",
      "Train Epoch: 3 [640/22481 (3%)]\tLoss: 0.151345\n",
      "Train Epoch: 3 [1280/22481 (6%)]\tLoss: 0.058003\n",
      "Train Epoch: 3 [1920/22481 (9%)]\tLoss: 0.133882\n",
      "Train Epoch: 3 [2560/22481 (11%)]\tLoss: 0.121706\n",
      "Train Epoch: 3 [3200/22481 (14%)]\tLoss: 0.159296\n",
      "Train Epoch: 3 [3840/22481 (17%)]\tLoss: 0.118445\n",
      "Train Epoch: 3 [4480/22481 (20%)]\tLoss: 0.236748\n",
      "Train Epoch: 3 [5120/22481 (23%)]\tLoss: 0.069268\n",
      "Train Epoch: 3 [5760/22481 (26%)]\tLoss: 0.091360\n",
      "Train Epoch: 3 [6400/22481 (28%)]\tLoss: 0.204115\n",
      "Train Epoch: 3 [7040/22481 (31%)]\tLoss: 0.257756\n",
      "Train Epoch: 3 [7680/22481 (34%)]\tLoss: 0.273984\n",
      "Train Epoch: 3 [8320/22481 (37%)]\tLoss: 0.102336\n",
      "Train Epoch: 3 [8960/22481 (40%)]\tLoss: 0.198072\n",
      "Train Epoch: 3 [9600/22481 (43%)]\tLoss: 0.134576\n",
      "Train Epoch: 3 [10240/22481 (45%)]\tLoss: 0.180456\n",
      "Train Epoch: 3 [10880/22481 (48%)]\tLoss: 0.231972\n",
      "Train Epoch: 3 [11520/22481 (51%)]\tLoss: 0.157385\n",
      "Train Epoch: 3 [12160/22481 (54%)]\tLoss: 0.126284\n",
      "Train Epoch: 3 [12800/22481 (57%)]\tLoss: 0.170877\n",
      "Train Epoch: 3 [13440/22481 (60%)]\tLoss: 0.176465\n",
      "Train Epoch: 3 [14080/22481 (62%)]\tLoss: 0.081873\n",
      "Train Epoch: 3 [14720/22481 (65%)]\tLoss: 0.104504\n",
      "Train Epoch: 3 [15360/22481 (68%)]\tLoss: 0.137089\n",
      "Train Epoch: 3 [16000/22481 (71%)]\tLoss: 0.165391\n",
      "Train Epoch: 3 [16640/22481 (74%)]\tLoss: 0.169072\n",
      "Train Epoch: 3 [17280/22481 (77%)]\tLoss: 0.143742\n",
      "Train Epoch: 3 [17920/22481 (80%)]\tLoss: 0.139665\n",
      "Train Epoch: 3 [18560/22481 (82%)]\tLoss: 0.107405\n",
      "Train Epoch: 3 [19200/22481 (85%)]\tLoss: 0.228363\n",
      "Train Epoch: 3 [19840/22481 (88%)]\tLoss: 0.049592\n",
      "Train Epoch: 3 [20480/22481 (91%)]\tLoss: 0.248562\n",
      "Train Epoch: 3 [21120/22481 (94%)]\tLoss: 0.134509\n",
      "Train Epoch: 3 [21760/22481 (97%)]\tLoss: 0.135990\n",
      "Train Epoch: 3 [22400/22481 (99%)]\tLoss: 0.125185\n",
      "Train Epoch: 4 [0/22481 (0%)]\tLoss: 0.061678\n",
      "Train Epoch: 4 [640/22481 (3%)]\tLoss: 0.124740\n",
      "Train Epoch: 4 [1280/22481 (6%)]\tLoss: 0.170040\n",
      "Train Epoch: 4 [1920/22481 (9%)]\tLoss: 0.220332\n",
      "Train Epoch: 4 [2560/22481 (11%)]\tLoss: 0.201539\n",
      "Train Epoch: 4 [3200/22481 (14%)]\tLoss: 0.228113\n",
      "Train Epoch: 4 [3840/22481 (17%)]\tLoss: 0.175374\n",
      "Train Epoch: 4 [4480/22481 (20%)]\tLoss: 0.151540\n",
      "Train Epoch: 4 [5120/22481 (23%)]\tLoss: 0.209713\n",
      "Train Epoch: 4 [5760/22481 (26%)]\tLoss: 0.073110\n",
      "Train Epoch: 4 [6400/22481 (28%)]\tLoss: 0.087861\n",
      "Train Epoch: 4 [7040/22481 (31%)]\tLoss: 0.312033\n",
      "Train Epoch: 4 [7680/22481 (34%)]\tLoss: 0.194167\n",
      "Train Epoch: 4 [8320/22481 (37%)]\tLoss: 0.205035\n",
      "Train Epoch: 4 [8960/22481 (40%)]\tLoss: 0.126650\n",
      "Train Epoch: 4 [9600/22481 (43%)]\tLoss: 0.160635\n",
      "Train Epoch: 4 [10240/22481 (45%)]\tLoss: 0.144351\n",
      "Train Epoch: 4 [10880/22481 (48%)]\tLoss: 0.232543\n",
      "Train Epoch: 4 [11520/22481 (51%)]\tLoss: 0.166348\n",
      "Train Epoch: 4 [12160/22481 (54%)]\tLoss: 0.148879\n",
      "Train Epoch: 4 [12800/22481 (57%)]\tLoss: 0.203467\n",
      "Train Epoch: 4 [13440/22481 (60%)]\tLoss: 0.137389\n",
      "Train Epoch: 4 [14080/22481 (62%)]\tLoss: 0.242872\n",
      "Train Epoch: 4 [14720/22481 (65%)]\tLoss: 0.133626\n",
      "Train Epoch: 4 [15360/22481 (68%)]\tLoss: 0.248341\n",
      "Train Epoch: 4 [16000/22481 (71%)]\tLoss: 0.231731\n",
      "Train Epoch: 4 [16640/22481 (74%)]\tLoss: 0.217399\n",
      "Train Epoch: 4 [17280/22481 (77%)]\tLoss: 0.255813\n",
      "Train Epoch: 4 [17920/22481 (80%)]\tLoss: 0.102074\n",
      "Train Epoch: 4 [18560/22481 (82%)]\tLoss: 0.139520\n",
      "Train Epoch: 4 [19200/22481 (85%)]\tLoss: 0.082876\n",
      "Train Epoch: 4 [19840/22481 (88%)]\tLoss: 0.299943\n",
      "Train Epoch: 4 [20480/22481 (91%)]\tLoss: 0.094570\n",
      "Train Epoch: 4 [21120/22481 (94%)]\tLoss: 0.301166\n",
      "Train Epoch: 4 [21760/22481 (97%)]\tLoss: 0.054313\n",
      "Train Epoch: 4 [22400/22481 (99%)]\tLoss: 0.310600\n",
      "Train Epoch: 5 [0/22481 (0%)]\tLoss: 0.111026\n",
      "Train Epoch: 5 [640/22481 (3%)]\tLoss: 0.133582\n",
      "Train Epoch: 5 [1280/22481 (6%)]\tLoss: 0.435709\n",
      "Train Epoch: 5 [1920/22481 (9%)]\tLoss: 0.348108\n",
      "Train Epoch: 5 [2560/22481 (11%)]\tLoss: 0.120662\n",
      "Train Epoch: 5 [3200/22481 (14%)]\tLoss: 0.079042\n",
      "Train Epoch: 5 [3840/22481 (17%)]\tLoss: 0.252604\n",
      "Train Epoch: 5 [4480/22481 (20%)]\tLoss: 0.086705\n",
      "Train Epoch: 5 [5120/22481 (23%)]\tLoss: 0.060033\n",
      "Train Epoch: 5 [5760/22481 (26%)]\tLoss: 0.114274\n",
      "Train Epoch: 5 [6400/22481 (28%)]\tLoss: 0.099286\n",
      "Train Epoch: 5 [7040/22481 (31%)]\tLoss: 0.074727\n",
      "Train Epoch: 5 [7680/22481 (34%)]\tLoss: 0.177460\n",
      "Train Epoch: 5 [8320/22481 (37%)]\tLoss: 0.129961\n",
      "Train Epoch: 5 [8960/22481 (40%)]\tLoss: 0.087683\n",
      "Train Epoch: 5 [9600/22481 (43%)]\tLoss: 0.097423\n",
      "Train Epoch: 5 [10240/22481 (45%)]\tLoss: 0.083835\n",
      "Train Epoch: 5 [10880/22481 (48%)]\tLoss: 0.421701\n",
      "Train Epoch: 5 [11520/22481 (51%)]\tLoss: 0.128560\n",
      "Train Epoch: 5 [12160/22481 (54%)]\tLoss: 0.096065\n",
      "Train Epoch: 5 [12800/22481 (57%)]\tLoss: 0.203808\n",
      "Train Epoch: 5 [13440/22481 (60%)]\tLoss: 0.068076\n",
      "Train Epoch: 5 [14080/22481 (62%)]\tLoss: 0.119219\n",
      "Train Epoch: 5 [14720/22481 (65%)]\tLoss: 0.150107\n",
      "Train Epoch: 5 [15360/22481 (68%)]\tLoss: 0.055725\n",
      "Train Epoch: 5 [16000/22481 (71%)]\tLoss: 0.221810\n",
      "Train Epoch: 5 [16640/22481 (74%)]\tLoss: 0.131218\n",
      "Train Epoch: 5 [17280/22481 (77%)]\tLoss: 0.165534\n",
      "Train Epoch: 5 [17920/22481 (80%)]\tLoss: 0.072309\n",
      "Train Epoch: 5 [18560/22481 (82%)]\tLoss: 0.081260\n",
      "Train Epoch: 5 [19200/22481 (85%)]\tLoss: 0.228817\n",
      "Train Epoch: 5 [19840/22481 (88%)]\tLoss: 0.205456\n",
      "Train Epoch: 5 [20480/22481 (91%)]\tLoss: 0.160814\n",
      "Train Epoch: 5 [21120/22481 (94%)]\tLoss: 0.226061\n",
      "Train Epoch: 5 [21760/22481 (97%)]\tLoss: 0.201006\n",
      "Train Epoch: 5 [22400/22481 (99%)]\tLoss: 0.123923\n",
      "Train Epoch: 6 [0/22481 (0%)]\tLoss: 0.104326\n",
      "Train Epoch: 6 [640/22481 (3%)]\tLoss: 0.125867\n",
      "Train Epoch: 6 [1280/22481 (6%)]\tLoss: 0.148740\n",
      "Train Epoch: 6 [1920/22481 (9%)]\tLoss: 0.131189\n",
      "Train Epoch: 6 [2560/22481 (11%)]\tLoss: 0.116431\n",
      "Train Epoch: 6 [3200/22481 (14%)]\tLoss: 0.211597\n",
      "Train Epoch: 6 [3840/22481 (17%)]\tLoss: 0.266553\n",
      "Train Epoch: 6 [4480/22481 (20%)]\tLoss: 0.084552\n",
      "Train Epoch: 6 [5120/22481 (23%)]\tLoss: 0.184220\n",
      "Train Epoch: 6 [5760/22481 (26%)]\tLoss: 0.297089\n",
      "Train Epoch: 6 [6400/22481 (28%)]\tLoss: 0.222639\n",
      "Train Epoch: 6 [7040/22481 (31%)]\tLoss: 0.098758\n",
      "Train Epoch: 6 [7680/22481 (34%)]\tLoss: 0.299826\n",
      "Train Epoch: 6 [8320/22481 (37%)]\tLoss: 0.200250\n",
      "Train Epoch: 6 [8960/22481 (40%)]\tLoss: 0.377005\n",
      "Train Epoch: 6 [9600/22481 (43%)]\tLoss: 0.070929\n",
      "Train Epoch: 6 [10240/22481 (45%)]\tLoss: 0.030780\n",
      "Train Epoch: 6 [10880/22481 (48%)]\tLoss: 0.165069\n",
      "Train Epoch: 6 [11520/22481 (51%)]\tLoss: 0.150331\n",
      "Train Epoch: 6 [12160/22481 (54%)]\tLoss: 0.114731\n",
      "Train Epoch: 6 [12800/22481 (57%)]\tLoss: 0.040036\n",
      "Train Epoch: 6 [13440/22481 (60%)]\tLoss: 0.084337\n",
      "Train Epoch: 6 [14080/22481 (62%)]\tLoss: 0.136204\n",
      "Train Epoch: 6 [14720/22481 (65%)]\tLoss: 0.090915\n",
      "Train Epoch: 6 [15360/22481 (68%)]\tLoss: 0.285514\n",
      "Train Epoch: 6 [16000/22481 (71%)]\tLoss: 0.116284\n",
      "Train Epoch: 6 [16640/22481 (74%)]\tLoss: 0.136016\n",
      "Train Epoch: 6 [17280/22481 (77%)]\tLoss: 0.315213\n",
      "Train Epoch: 6 [17920/22481 (80%)]\tLoss: 0.184228\n",
      "Train Epoch: 6 [18560/22481 (82%)]\tLoss: 0.253362\n",
      "Train Epoch: 6 [19200/22481 (85%)]\tLoss: 0.139907\n",
      "Train Epoch: 6 [19840/22481 (88%)]\tLoss: 0.233641\n",
      "Train Epoch: 6 [20480/22481 (91%)]\tLoss: 0.077041\n",
      "Train Epoch: 6 [21120/22481 (94%)]\tLoss: 0.093206\n",
      "Train Epoch: 6 [21760/22481 (97%)]\tLoss: 0.112922\n",
      "Train Epoch: 6 [22400/22481 (99%)]\tLoss: 0.154766\n",
      "Train Epoch: 7 [0/22481 (0%)]\tLoss: 0.172926\n",
      "Train Epoch: 7 [640/22481 (3%)]\tLoss: 0.093565\n",
      "Train Epoch: 7 [1280/22481 (6%)]\tLoss: 0.105237\n",
      "Train Epoch: 7 [1920/22481 (9%)]\tLoss: 0.185111\n",
      "Train Epoch: 7 [2560/22481 (11%)]\tLoss: 0.096012\n",
      "Train Epoch: 7 [3200/22481 (14%)]\tLoss: 0.162323\n",
      "Train Epoch: 7 [3840/22481 (17%)]\tLoss: 0.070426\n",
      "Train Epoch: 7 [4480/22481 (20%)]\tLoss: 0.243948\n",
      "Train Epoch: 7 [5120/22481 (23%)]\tLoss: 0.269605\n",
      "Train Epoch: 7 [5760/22481 (26%)]\tLoss: 0.021872\n",
      "Train Epoch: 7 [6400/22481 (28%)]\tLoss: 0.163989\n",
      "Train Epoch: 7 [7040/22481 (31%)]\tLoss: 0.093304\n",
      "Train Epoch: 7 [7680/22481 (34%)]\tLoss: 0.043677\n",
      "Train Epoch: 7 [8320/22481 (37%)]\tLoss: 0.096958\n",
      "Train Epoch: 7 [8960/22481 (40%)]\tLoss: 0.141680\n",
      "Train Epoch: 7 [9600/22481 (43%)]\tLoss: 0.174478\n",
      "Train Epoch: 7 [10240/22481 (45%)]\tLoss: 0.158507\n",
      "Train Epoch: 7 [10880/22481 (48%)]\tLoss: 0.214687\n",
      "Train Epoch: 7 [11520/22481 (51%)]\tLoss: 0.159418\n",
      "Train Epoch: 7 [12160/22481 (54%)]\tLoss: 0.114733\n",
      "Train Epoch: 7 [12800/22481 (57%)]\tLoss: 0.103719\n",
      "Train Epoch: 7 [13440/22481 (60%)]\tLoss: 0.095675\n",
      "Train Epoch: 7 [14080/22481 (62%)]\tLoss: 0.164876\n",
      "Train Epoch: 7 [14720/22481 (65%)]\tLoss: 0.130247\n",
      "Train Epoch: 7 [15360/22481 (68%)]\tLoss: 0.061420\n",
      "Train Epoch: 7 [16000/22481 (71%)]\tLoss: 0.170403\n",
      "Train Epoch: 7 [16640/22481 (74%)]\tLoss: 0.249303\n",
      "Train Epoch: 7 [17280/22481 (77%)]\tLoss: 0.051455\n",
      "Train Epoch: 7 [17920/22481 (80%)]\tLoss: 0.189108\n",
      "Train Epoch: 7 [18560/22481 (82%)]\tLoss: 0.212763\n",
      "Train Epoch: 7 [19200/22481 (85%)]\tLoss: 0.214129\n",
      "Train Epoch: 7 [19840/22481 (88%)]\tLoss: 0.115432\n",
      "Train Epoch: 7 [20480/22481 (91%)]\tLoss: 0.201756\n",
      "Train Epoch: 7 [21120/22481 (94%)]\tLoss: 0.173788\n",
      "Train Epoch: 7 [21760/22481 (97%)]\tLoss: 0.053995\n",
      "Train Epoch: 7 [22400/22481 (99%)]\tLoss: 0.167915\n",
      "Train Epoch: 8 [0/22481 (0%)]\tLoss: 0.064433\n",
      "Train Epoch: 8 [640/22481 (3%)]\tLoss: 0.074051\n",
      "Train Epoch: 8 [1280/22481 (6%)]\tLoss: 0.086454\n",
      "Train Epoch: 8 [1920/22481 (9%)]\tLoss: 0.098352\n",
      "Train Epoch: 8 [2560/22481 (11%)]\tLoss: 0.082187\n",
      "Train Epoch: 8 [3200/22481 (14%)]\tLoss: 0.198906\n",
      "Train Epoch: 8 [3840/22481 (17%)]\tLoss: 0.094808\n",
      "Train Epoch: 8 [4480/22481 (20%)]\tLoss: 0.153541\n",
      "Train Epoch: 8 [5120/22481 (23%)]\tLoss: 0.225719\n",
      "Train Epoch: 8 [5760/22481 (26%)]\tLoss: 0.126289\n",
      "Train Epoch: 8 [6400/22481 (28%)]\tLoss: 0.077823\n",
      "Train Epoch: 8 [7040/22481 (31%)]\tLoss: 0.054546\n",
      "Train Epoch: 8 [7680/22481 (34%)]\tLoss: 0.060805\n",
      "Train Epoch: 8 [8320/22481 (37%)]\tLoss: 0.252629\n",
      "Train Epoch: 8 [8960/22481 (40%)]\tLoss: 0.139799\n",
      "Train Epoch: 8 [9600/22481 (43%)]\tLoss: 0.066874\n",
      "Train Epoch: 8 [10240/22481 (45%)]\tLoss: 0.160800\n",
      "Train Epoch: 8 [10880/22481 (48%)]\tLoss: 0.135089\n",
      "Train Epoch: 8 [11520/22481 (51%)]\tLoss: 0.114858\n",
      "Train Epoch: 8 [12160/22481 (54%)]\tLoss: 0.233319\n",
      "Train Epoch: 8 [12800/22481 (57%)]\tLoss: 0.207759\n",
      "Train Epoch: 8 [13440/22481 (60%)]\tLoss: 0.142821\n",
      "Train Epoch: 8 [14080/22481 (62%)]\tLoss: 0.133858\n",
      "Train Epoch: 8 [14720/22481 (65%)]\tLoss: 0.317636\n",
      "Train Epoch: 8 [15360/22481 (68%)]\tLoss: 0.220470\n",
      "Train Epoch: 8 [16000/22481 (71%)]\tLoss: 0.174884\n",
      "Train Epoch: 8 [16640/22481 (74%)]\tLoss: 0.150357\n",
      "Train Epoch: 8 [17280/22481 (77%)]\tLoss: 0.095477\n",
      "Train Epoch: 8 [17920/22481 (80%)]\tLoss: 0.147681\n",
      "Train Epoch: 8 [18560/22481 (82%)]\tLoss: 0.049105\n",
      "Train Epoch: 8 [19200/22481 (85%)]\tLoss: 0.078983\n",
      "Train Epoch: 8 [19840/22481 (88%)]\tLoss: 0.178173\n",
      "Train Epoch: 8 [20480/22481 (91%)]\tLoss: 0.263858\n",
      "Train Epoch: 8 [21120/22481 (94%)]\tLoss: 0.073353\n",
      "Train Epoch: 8 [21760/22481 (97%)]\tLoss: 0.133742\n",
      "Train Epoch: 8 [22400/22481 (99%)]\tLoss: 0.163644\n",
      "Train Epoch: 9 [0/22481 (0%)]\tLoss: 0.100213\n",
      "Train Epoch: 9 [640/22481 (3%)]\tLoss: 0.303275\n",
      "Train Epoch: 9 [1280/22481 (6%)]\tLoss: 0.078754\n",
      "Train Epoch: 9 [1920/22481 (9%)]\tLoss: 0.373032\n",
      "Train Epoch: 9 [2560/22481 (11%)]\tLoss: 0.186107\n",
      "Train Epoch: 9 [3200/22481 (14%)]\tLoss: 0.115101\n",
      "Train Epoch: 9 [3840/22481 (17%)]\tLoss: 0.141286\n",
      "Train Epoch: 9 [4480/22481 (20%)]\tLoss: 0.116365\n",
      "Train Epoch: 9 [5120/22481 (23%)]\tLoss: 0.084935\n",
      "Train Epoch: 9 [5760/22481 (26%)]\tLoss: 0.179087\n",
      "Train Epoch: 9 [6400/22481 (28%)]\tLoss: 0.172995\n",
      "Train Epoch: 9 [7040/22481 (31%)]\tLoss: 0.248182\n",
      "Train Epoch: 9 [7680/22481 (34%)]\tLoss: 0.100460\n",
      "Train Epoch: 9 [8320/22481 (37%)]\tLoss: 0.276477\n",
      "Train Epoch: 9 [8960/22481 (40%)]\tLoss: 0.162849\n",
      "Train Epoch: 9 [9600/22481 (43%)]\tLoss: 0.216729\n",
      "Train Epoch: 9 [10240/22481 (45%)]\tLoss: 0.152886\n",
      "Train Epoch: 9 [10880/22481 (48%)]\tLoss: 0.131395\n",
      "Train Epoch: 9 [11520/22481 (51%)]\tLoss: 0.061452\n",
      "Train Epoch: 9 [12160/22481 (54%)]\tLoss: 0.074067\n",
      "Train Epoch: 9 [12800/22481 (57%)]\tLoss: 0.110770\n",
      "Train Epoch: 9 [13440/22481 (60%)]\tLoss: 0.171692\n",
      "Train Epoch: 9 [14080/22481 (62%)]\tLoss: 0.046970\n",
      "Train Epoch: 9 [14720/22481 (65%)]\tLoss: 0.091224\n",
      "Train Epoch: 9 [15360/22481 (68%)]\tLoss: 0.116187\n",
      "Train Epoch: 9 [16000/22481 (71%)]\tLoss: 0.163000\n",
      "Train Epoch: 9 [16640/22481 (74%)]\tLoss: 0.111406\n",
      "Train Epoch: 9 [17280/22481 (77%)]\tLoss: 0.174649\n",
      "Train Epoch: 9 [17920/22481 (80%)]\tLoss: 0.147147\n",
      "Train Epoch: 9 [18560/22481 (82%)]\tLoss: 0.143308\n",
      "Train Epoch: 9 [19200/22481 (85%)]\tLoss: 0.130582\n",
      "Train Epoch: 9 [19840/22481 (88%)]\tLoss: 0.144834\n",
      "Train Epoch: 9 [20480/22481 (91%)]\tLoss: 0.020113\n",
      "Train Epoch: 9 [21120/22481 (94%)]\tLoss: 0.150038\n",
      "Train Epoch: 9 [21760/22481 (97%)]\tLoss: 0.175712\n",
      "Train Epoch: 9 [22400/22481 (99%)]\tLoss: 0.020327\n",
      "Train Epoch: 10 [0/22481 (0%)]\tLoss: 0.041605\n",
      "Train Epoch: 10 [640/22481 (3%)]\tLoss: 0.111826\n",
      "Train Epoch: 10 [1280/22481 (6%)]\tLoss: 0.129285\n",
      "Train Epoch: 10 [1920/22481 (9%)]\tLoss: 0.066480\n",
      "Train Epoch: 10 [2560/22481 (11%)]\tLoss: 0.083024\n",
      "Train Epoch: 10 [3200/22481 (14%)]\tLoss: 0.114767\n",
      "Train Epoch: 10 [3840/22481 (17%)]\tLoss: 0.128088\n",
      "Train Epoch: 10 [4480/22481 (20%)]\tLoss: 0.213194\n",
      "Train Epoch: 10 [5120/22481 (23%)]\tLoss: 0.089229\n",
      "Train Epoch: 10 [5760/22481 (26%)]\tLoss: 0.108673\n",
      "Train Epoch: 10 [6400/22481 (28%)]\tLoss: 0.091874\n",
      "Train Epoch: 10 [7040/22481 (31%)]\tLoss: 0.048655\n",
      "Train Epoch: 10 [7680/22481 (34%)]\tLoss: 0.064017\n",
      "Train Epoch: 10 [8320/22481 (37%)]\tLoss: 0.174943\n",
      "Train Epoch: 10 [8960/22481 (40%)]\tLoss: 0.193971\n",
      "Train Epoch: 10 [9600/22481 (43%)]\tLoss: 0.187447\n",
      "Train Epoch: 10 [10240/22481 (45%)]\tLoss: 0.241554\n",
      "Train Epoch: 10 [10880/22481 (48%)]\tLoss: 0.206597\n",
      "Train Epoch: 10 [11520/22481 (51%)]\tLoss: 0.182892\n",
      "Train Epoch: 10 [12160/22481 (54%)]\tLoss: 0.115607\n",
      "Train Epoch: 10 [12800/22481 (57%)]\tLoss: 0.203234\n",
      "Train Epoch: 10 [13440/22481 (60%)]\tLoss: 0.086508\n",
      "Train Epoch: 10 [14080/22481 (62%)]\tLoss: 0.102697\n",
      "Train Epoch: 10 [14720/22481 (65%)]\tLoss: 0.188105\n",
      "Train Epoch: 10 [15360/22481 (68%)]\tLoss: 0.192136\n",
      "Train Epoch: 10 [16000/22481 (71%)]\tLoss: 0.098532\n",
      "Train Epoch: 10 [16640/22481 (74%)]\tLoss: 0.120679\n",
      "Train Epoch: 10 [17280/22481 (77%)]\tLoss: 0.071450\n",
      "Train Epoch: 10 [17920/22481 (80%)]\tLoss: 0.143016\n",
      "Train Epoch: 10 [18560/22481 (82%)]\tLoss: 0.126617\n",
      "Train Epoch: 10 [19200/22481 (85%)]\tLoss: 0.260758\n",
      "Train Epoch: 10 [19840/22481 (88%)]\tLoss: 0.173713\n",
      "Train Epoch: 10 [20480/22481 (91%)]\tLoss: 0.167962\n",
      "Train Epoch: 10 [21120/22481 (94%)]\tLoss: 0.071807\n",
      "Train Epoch: 10 [21760/22481 (97%)]\tLoss: 0.131641\n",
      "Train Epoch: 10 [22400/22481 (99%)]\tLoss: 0.117812\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.3804, Accuracy: 9765/10000 (98%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/37519 (0%)]\tLoss: 0.310382\n",
      "Train Epoch: 1 [640/37519 (2%)]\tLoss: 0.173699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1280/37519 (3%)]\tLoss: 0.172146\n",
      "Train Epoch: 1 [1920/37519 (5%)]\tLoss: 0.122575\n",
      "Train Epoch: 1 [2560/37519 (7%)]\tLoss: 0.084127\n",
      "Train Epoch: 1 [3200/37519 (9%)]\tLoss: 0.036100\n",
      "Train Epoch: 1 [3840/37519 (10%)]\tLoss: 0.142697\n",
      "Train Epoch: 1 [4480/37519 (12%)]\tLoss: 0.111367\n",
      "Train Epoch: 1 [5120/37519 (14%)]\tLoss: 0.114504\n",
      "Train Epoch: 1 [5760/37519 (15%)]\tLoss: 0.163436\n",
      "Train Epoch: 1 [6400/37519 (17%)]\tLoss: 0.113872\n",
      "Train Epoch: 1 [7040/37519 (19%)]\tLoss: 0.382870\n",
      "Train Epoch: 1 [7680/37519 (20%)]\tLoss: 0.190009\n",
      "Train Epoch: 1 [8320/37519 (22%)]\tLoss: 0.178018\n",
      "Train Epoch: 1 [8960/37519 (24%)]\tLoss: 0.313520\n",
      "Train Epoch: 1 [9600/37519 (26%)]\tLoss: 0.168612\n",
      "Train Epoch: 1 [10240/37519 (27%)]\tLoss: 0.192968\n",
      "Train Epoch: 1 [10880/37519 (29%)]\tLoss: 0.154801\n",
      "Train Epoch: 1 [11520/37519 (31%)]\tLoss: 0.059780\n",
      "Train Epoch: 1 [12160/37519 (32%)]\tLoss: 0.077199\n",
      "Train Epoch: 1 [12800/37519 (34%)]\tLoss: 0.240510\n",
      "Train Epoch: 1 [13440/37519 (36%)]\tLoss: 0.102026\n",
      "Train Epoch: 1 [14080/37519 (37%)]\tLoss: 0.220413\n",
      "Train Epoch: 1 [14720/37519 (39%)]\tLoss: 0.133494\n",
      "Train Epoch: 1 [15360/37519 (41%)]\tLoss: 0.235646\n",
      "Train Epoch: 1 [16000/37519 (43%)]\tLoss: 0.132334\n",
      "Train Epoch: 1 [16640/37519 (44%)]\tLoss: 0.323724\n",
      "Train Epoch: 1 [17280/37519 (46%)]\tLoss: 0.187884\n",
      "Train Epoch: 1 [17920/37519 (48%)]\tLoss: 0.107887\n",
      "Train Epoch: 1 [18560/37519 (49%)]\tLoss: 0.220800\n",
      "Train Epoch: 1 [19200/37519 (51%)]\tLoss: 0.128360\n",
      "Train Epoch: 1 [19840/37519 (53%)]\tLoss: 0.336188\n",
      "Train Epoch: 1 [20480/37519 (55%)]\tLoss: 0.159851\n",
      "Train Epoch: 1 [21120/37519 (56%)]\tLoss: 0.175608\n",
      "Train Epoch: 1 [21760/37519 (58%)]\tLoss: 0.250987\n",
      "Train Epoch: 1 [22400/37519 (60%)]\tLoss: 0.178045\n",
      "Train Epoch: 1 [23040/37519 (61%)]\tLoss: 0.146232\n",
      "Train Epoch: 1 [23680/37519 (63%)]\tLoss: 0.318062\n",
      "Train Epoch: 1 [24320/37519 (65%)]\tLoss: 0.193512\n",
      "Train Epoch: 1 [24960/37519 (66%)]\tLoss: 0.204292\n",
      "Train Epoch: 1 [25600/37519 (68%)]\tLoss: 0.070322\n",
      "Train Epoch: 1 [26240/37519 (70%)]\tLoss: 0.343074\n",
      "Train Epoch: 1 [26880/37519 (72%)]\tLoss: 0.148314\n",
      "Train Epoch: 1 [27520/37519 (73%)]\tLoss: 0.200981\n",
      "Train Epoch: 1 [28160/37519 (75%)]\tLoss: 0.130609\n",
      "Train Epoch: 1 [28800/37519 (77%)]\tLoss: 0.112952\n",
      "Train Epoch: 1 [29440/37519 (78%)]\tLoss: 0.237902\n",
      "Train Epoch: 1 [30080/37519 (80%)]\tLoss: 0.097252\n",
      "Train Epoch: 1 [30720/37519 (82%)]\tLoss: 0.279818\n",
      "Train Epoch: 1 [31360/37519 (83%)]\tLoss: 0.155201\n",
      "Train Epoch: 1 [32000/37519 (85%)]\tLoss: 0.105365\n",
      "Train Epoch: 1 [32640/37519 (87%)]\tLoss: 0.128879\n",
      "Train Epoch: 1 [33280/37519 (89%)]\tLoss: 0.141041\n",
      "Train Epoch: 1 [33920/37519 (90%)]\tLoss: 0.254850\n",
      "Train Epoch: 1 [34560/37519 (92%)]\tLoss: 0.112734\n",
      "Train Epoch: 1 [35200/37519 (94%)]\tLoss: 0.097792\n",
      "Train Epoch: 1 [35840/37519 (95%)]\tLoss: 0.173503\n",
      "Train Epoch: 1 [36480/37519 (97%)]\tLoss: 0.093428\n",
      "Train Epoch: 1 [37120/37519 (99%)]\tLoss: 0.096255\n",
      "Train Epoch: 2 [0/37519 (0%)]\tLoss: 0.222540\n",
      "Train Epoch: 2 [640/37519 (2%)]\tLoss: 0.297012\n",
      "Train Epoch: 2 [1280/37519 (3%)]\tLoss: 0.319567\n",
      "Train Epoch: 2 [1920/37519 (5%)]\tLoss: 0.132218\n",
      "Train Epoch: 2 [2560/37519 (7%)]\tLoss: 0.160648\n",
      "Train Epoch: 2 [3200/37519 (9%)]\tLoss: 0.194891\n",
      "Train Epoch: 2 [3840/37519 (10%)]\tLoss: 0.209217\n",
      "Train Epoch: 2 [4480/37519 (12%)]\tLoss: 0.182186\n",
      "Train Epoch: 2 [5120/37519 (14%)]\tLoss: 0.234752\n",
      "Train Epoch: 2 [5760/37519 (15%)]\tLoss: 0.069384\n",
      "Train Epoch: 2 [6400/37519 (17%)]\tLoss: 0.057309\n",
      "Train Epoch: 2 [7040/37519 (19%)]\tLoss: 0.209262\n",
      "Train Epoch: 2 [7680/37519 (20%)]\tLoss: 0.217907\n",
      "Train Epoch: 2 [8320/37519 (22%)]\tLoss: 0.096332\n",
      "Train Epoch: 2 [8960/37519 (24%)]\tLoss: 0.091434\n",
      "Train Epoch: 2 [9600/37519 (26%)]\tLoss: 0.072298\n",
      "Train Epoch: 2 [10240/37519 (27%)]\tLoss: 0.154685\n",
      "Train Epoch: 2 [10880/37519 (29%)]\tLoss: 0.151642\n",
      "Train Epoch: 2 [11520/37519 (31%)]\tLoss: 0.299406\n",
      "Train Epoch: 2 [12160/37519 (32%)]\tLoss: 0.186939\n",
      "Train Epoch: 2 [12800/37519 (34%)]\tLoss: 0.215465\n",
      "Train Epoch: 2 [13440/37519 (36%)]\tLoss: 0.095989\n",
      "Train Epoch: 2 [14080/37519 (37%)]\tLoss: 0.152351\n",
      "Train Epoch: 2 [14720/37519 (39%)]\tLoss: 0.195719\n",
      "Train Epoch: 2 [15360/37519 (41%)]\tLoss: 0.097061\n",
      "Train Epoch: 2 [16000/37519 (43%)]\tLoss: 0.165157\n",
      "Train Epoch: 2 [16640/37519 (44%)]\tLoss: 0.102164\n",
      "Train Epoch: 2 [17280/37519 (46%)]\tLoss: 0.072758\n",
      "Train Epoch: 2 [17920/37519 (48%)]\tLoss: 0.172620\n",
      "Train Epoch: 2 [18560/37519 (49%)]\tLoss: 0.185319\n",
      "Train Epoch: 2 [19200/37519 (51%)]\tLoss: 0.241097\n",
      "Train Epoch: 2 [19840/37519 (53%)]\tLoss: 0.191133\n",
      "Train Epoch: 2 [20480/37519 (55%)]\tLoss: 0.200940\n",
      "Train Epoch: 2 [21120/37519 (56%)]\tLoss: 0.157739\n",
      "Train Epoch: 2 [21760/37519 (58%)]\tLoss: 0.224866\n",
      "Train Epoch: 2 [22400/37519 (60%)]\tLoss: 0.055954\n",
      "Train Epoch: 2 [23040/37519 (61%)]\tLoss: 0.188784\n",
      "Train Epoch: 2 [23680/37519 (63%)]\tLoss: 0.276880\n",
      "Train Epoch: 2 [24320/37519 (65%)]\tLoss: 0.242020\n",
      "Train Epoch: 2 [24960/37519 (66%)]\tLoss: 0.091374\n",
      "Train Epoch: 2 [25600/37519 (68%)]\tLoss: 0.098535\n",
      "Train Epoch: 2 [26240/37519 (70%)]\tLoss: 0.158611\n",
      "Train Epoch: 2 [26880/37519 (72%)]\tLoss: 0.050299\n",
      "Train Epoch: 2 [27520/37519 (73%)]\tLoss: 0.131531\n",
      "Train Epoch: 2 [28160/37519 (75%)]\tLoss: 0.273601\n",
      "Train Epoch: 2 [28800/37519 (77%)]\tLoss: 0.169472\n",
      "Train Epoch: 2 [29440/37519 (78%)]\tLoss: 0.264100\n",
      "Train Epoch: 2 [30080/37519 (80%)]\tLoss: 0.127596\n",
      "Train Epoch: 2 [30720/37519 (82%)]\tLoss: 0.123815\n",
      "Train Epoch: 2 [31360/37519 (83%)]\tLoss: 0.191269\n",
      "Train Epoch: 2 [32000/37519 (85%)]\tLoss: 0.188316\n",
      "Train Epoch: 2 [32640/37519 (87%)]\tLoss: 0.113298\n",
      "Train Epoch: 2 [33280/37519 (89%)]\tLoss: 0.158278\n",
      "Train Epoch: 2 [33920/37519 (90%)]\tLoss: 0.177478\n",
      "Train Epoch: 2 [34560/37519 (92%)]\tLoss: 0.370182\n",
      "Train Epoch: 2 [35200/37519 (94%)]\tLoss: 0.130265\n",
      "Train Epoch: 2 [35840/37519 (95%)]\tLoss: 0.119727\n",
      "Train Epoch: 2 [36480/37519 (97%)]\tLoss: 0.223706\n",
      "Train Epoch: 2 [37120/37519 (99%)]\tLoss: 0.102303\n",
      "Train Epoch: 3 [0/37519 (0%)]\tLoss: 0.236825\n",
      "Train Epoch: 3 [640/37519 (2%)]\tLoss: 0.035871\n",
      "Train Epoch: 3 [1280/37519 (3%)]\tLoss: 0.146955\n",
      "Train Epoch: 3 [1920/37519 (5%)]\tLoss: 0.168004\n",
      "Train Epoch: 3 [2560/37519 (7%)]\tLoss: 0.069711\n",
      "Train Epoch: 3 [3200/37519 (9%)]\tLoss: 0.251585\n",
      "Train Epoch: 3 [3840/37519 (10%)]\tLoss: 0.228877\n",
      "Train Epoch: 3 [4480/37519 (12%)]\tLoss: 0.238882\n",
      "Train Epoch: 3 [5120/37519 (14%)]\tLoss: 0.188565\n",
      "Train Epoch: 3 [5760/37519 (15%)]\tLoss: 0.207743\n",
      "Train Epoch: 3 [6400/37519 (17%)]\tLoss: 0.061764\n",
      "Train Epoch: 3 [7040/37519 (19%)]\tLoss: 0.113134\n",
      "Train Epoch: 3 [7680/37519 (20%)]\tLoss: 0.121029\n",
      "Train Epoch: 3 [8320/37519 (22%)]\tLoss: 0.131516\n",
      "Train Epoch: 3 [8960/37519 (24%)]\tLoss: 0.204978\n",
      "Train Epoch: 3 [9600/37519 (26%)]\tLoss: 0.197543\n",
      "Train Epoch: 3 [10240/37519 (27%)]\tLoss: 0.127637\n",
      "Train Epoch: 3 [10880/37519 (29%)]\tLoss: 0.062903\n",
      "Train Epoch: 3 [11520/37519 (31%)]\tLoss: 0.187567\n",
      "Train Epoch: 3 [12160/37519 (32%)]\tLoss: 0.069906\n",
      "Train Epoch: 3 [12800/37519 (34%)]\tLoss: 0.128243\n",
      "Train Epoch: 3 [13440/37519 (36%)]\tLoss: 0.210435\n",
      "Train Epoch: 3 [14080/37519 (37%)]\tLoss: 0.253420\n",
      "Train Epoch: 3 [14720/37519 (39%)]\tLoss: 0.223899\n",
      "Train Epoch: 3 [15360/37519 (41%)]\tLoss: 0.112528\n",
      "Train Epoch: 3 [16000/37519 (43%)]\tLoss: 0.071060\n",
      "Train Epoch: 3 [16640/37519 (44%)]\tLoss: 0.378107\n",
      "Train Epoch: 3 [17280/37519 (46%)]\tLoss: 0.331076\n",
      "Train Epoch: 3 [17920/37519 (48%)]\tLoss: 0.105534\n",
      "Train Epoch: 3 [18560/37519 (49%)]\tLoss: 0.141373\n",
      "Train Epoch: 3 [19200/37519 (51%)]\tLoss: 0.292704\n",
      "Train Epoch: 3 [19840/37519 (53%)]\tLoss: 0.139802\n",
      "Train Epoch: 3 [20480/37519 (55%)]\tLoss: 0.167478\n",
      "Train Epoch: 3 [21120/37519 (56%)]\tLoss: 0.062452\n",
      "Train Epoch: 3 [21760/37519 (58%)]\tLoss: 0.067365\n",
      "Train Epoch: 3 [22400/37519 (60%)]\tLoss: 0.066624\n",
      "Train Epoch: 3 [23040/37519 (61%)]\tLoss: 0.209650\n",
      "Train Epoch: 3 [23680/37519 (63%)]\tLoss: 0.123106\n",
      "Train Epoch: 3 [24320/37519 (65%)]\tLoss: 0.074844\n",
      "Train Epoch: 3 [24960/37519 (66%)]\tLoss: 0.165348\n",
      "Train Epoch: 3 [25600/37519 (68%)]\tLoss: 0.162286\n",
      "Train Epoch: 3 [26240/37519 (70%)]\tLoss: 0.047908\n",
      "Train Epoch: 3 [26880/37519 (72%)]\tLoss: 0.088313\n",
      "Train Epoch: 3 [27520/37519 (73%)]\tLoss: 0.092627\n",
      "Train Epoch: 3 [28160/37519 (75%)]\tLoss: 0.200330\n",
      "Train Epoch: 3 [28800/37519 (77%)]\tLoss: 0.258357\n",
      "Train Epoch: 3 [29440/37519 (78%)]\tLoss: 0.068344\n",
      "Train Epoch: 3 [30080/37519 (80%)]\tLoss: 0.065798\n",
      "Train Epoch: 3 [30720/37519 (82%)]\tLoss: 0.158228\n",
      "Train Epoch: 3 [31360/37519 (83%)]\tLoss: 0.074058\n",
      "Train Epoch: 3 [32000/37519 (85%)]\tLoss: 0.220053\n",
      "Train Epoch: 3 [32640/37519 (87%)]\tLoss: 0.098989\n",
      "Train Epoch: 3 [33280/37519 (89%)]\tLoss: 0.054397\n",
      "Train Epoch: 3 [33920/37519 (90%)]\tLoss: 0.090992\n",
      "Train Epoch: 3 [34560/37519 (92%)]\tLoss: 0.164348\n",
      "Train Epoch: 3 [35200/37519 (94%)]\tLoss: 0.075200\n",
      "Train Epoch: 3 [35840/37519 (95%)]\tLoss: 0.159785\n",
      "Train Epoch: 3 [36480/37519 (97%)]\tLoss: 0.113546\n",
      "Train Epoch: 3 [37120/37519 (99%)]\tLoss: 0.125365\n",
      "Train Epoch: 4 [0/37519 (0%)]\tLoss: 0.150264\n",
      "Train Epoch: 4 [640/37519 (2%)]\tLoss: 0.130793\n",
      "Train Epoch: 4 [1280/37519 (3%)]\tLoss: 0.091198\n",
      "Train Epoch: 4 [1920/37519 (5%)]\tLoss: 0.170275\n",
      "Train Epoch: 4 [2560/37519 (7%)]\tLoss: 0.402191\n",
      "Train Epoch: 4 [3200/37519 (9%)]\tLoss: 0.056845\n",
      "Train Epoch: 4 [3840/37519 (10%)]\tLoss: 0.230419\n",
      "Train Epoch: 4 [4480/37519 (12%)]\tLoss: 0.094981\n",
      "Train Epoch: 4 [5120/37519 (14%)]\tLoss: 0.139791\n",
      "Train Epoch: 4 [5760/37519 (15%)]\tLoss: 0.203573\n",
      "Train Epoch: 4 [6400/37519 (17%)]\tLoss: 0.275368\n",
      "Train Epoch: 4 [7040/37519 (19%)]\tLoss: 0.242061\n",
      "Train Epoch: 4 [7680/37519 (20%)]\tLoss: 0.092384\n",
      "Train Epoch: 4 [8320/37519 (22%)]\tLoss: 0.142265\n",
      "Train Epoch: 4 [8960/37519 (24%)]\tLoss: 0.126467\n",
      "Train Epoch: 4 [9600/37519 (26%)]\tLoss: 0.150536\n",
      "Train Epoch: 4 [10240/37519 (27%)]\tLoss: 0.065839\n",
      "Train Epoch: 4 [10880/37519 (29%)]\tLoss: 0.286309\n",
      "Train Epoch: 4 [11520/37519 (31%)]\tLoss: 0.133924\n",
      "Train Epoch: 4 [12160/37519 (32%)]\tLoss: 0.060316\n",
      "Train Epoch: 4 [12800/37519 (34%)]\tLoss: 0.116184\n",
      "Train Epoch: 4 [13440/37519 (36%)]\tLoss: 0.252923\n",
      "Train Epoch: 4 [14080/37519 (37%)]\tLoss: 0.309092\n",
      "Train Epoch: 4 [14720/37519 (39%)]\tLoss: 0.197779\n",
      "Train Epoch: 4 [15360/37519 (41%)]\tLoss: 0.073284\n",
      "Train Epoch: 4 [16000/37519 (43%)]\tLoss: 0.255633\n",
      "Train Epoch: 4 [16640/37519 (44%)]\tLoss: 0.192796\n",
      "Train Epoch: 4 [17280/37519 (46%)]\tLoss: 0.171903\n",
      "Train Epoch: 4 [17920/37519 (48%)]\tLoss: 0.226074\n",
      "Train Epoch: 4 [18560/37519 (49%)]\tLoss: 0.115497\n",
      "Train Epoch: 4 [19200/37519 (51%)]\tLoss: 0.149761\n",
      "Train Epoch: 4 [19840/37519 (53%)]\tLoss: 0.086985\n",
      "Train Epoch: 4 [20480/37519 (55%)]\tLoss: 0.116887\n",
      "Train Epoch: 4 [21120/37519 (56%)]\tLoss: 0.112671\n",
      "Train Epoch: 4 [21760/37519 (58%)]\tLoss: 0.152696\n",
      "Train Epoch: 4 [22400/37519 (60%)]\tLoss: 0.137813\n",
      "Train Epoch: 4 [23040/37519 (61%)]\tLoss: 0.079837\n",
      "Train Epoch: 4 [23680/37519 (63%)]\tLoss: 0.035121\n",
      "Train Epoch: 4 [24320/37519 (65%)]\tLoss: 0.084513\n",
      "Train Epoch: 4 [24960/37519 (66%)]\tLoss: 0.026465\n",
      "Train Epoch: 4 [25600/37519 (68%)]\tLoss: 0.227452\n",
      "Train Epoch: 4 [26240/37519 (70%)]\tLoss: 0.153781\n",
      "Train Epoch: 4 [26880/37519 (72%)]\tLoss: 0.084790\n",
      "Train Epoch: 4 [27520/37519 (73%)]\tLoss: 0.130728\n",
      "Train Epoch: 4 [28160/37519 (75%)]\tLoss: 0.070452\n",
      "Train Epoch: 4 [28800/37519 (77%)]\tLoss: 0.201597\n",
      "Train Epoch: 4 [29440/37519 (78%)]\tLoss: 0.147101\n",
      "Train Epoch: 4 [30080/37519 (80%)]\tLoss: 0.082527\n",
      "Train Epoch: 4 [30720/37519 (82%)]\tLoss: 0.160846\n",
      "Train Epoch: 4 [31360/37519 (83%)]\tLoss: 0.208191\n",
      "Train Epoch: 4 [32000/37519 (85%)]\tLoss: 0.231489\n",
      "Train Epoch: 4 [32640/37519 (87%)]\tLoss: 0.192171\n",
      "Train Epoch: 4 [33280/37519 (89%)]\tLoss: 0.041973\n",
      "Train Epoch: 4 [33920/37519 (90%)]\tLoss: 0.100576\n",
      "Train Epoch: 4 [34560/37519 (92%)]\tLoss: 0.137871\n",
      "Train Epoch: 4 [35200/37519 (94%)]\tLoss: 0.213937\n",
      "Train Epoch: 4 [35840/37519 (95%)]\tLoss: 0.103040\n",
      "Train Epoch: 4 [36480/37519 (97%)]\tLoss: 0.321459\n",
      "Train Epoch: 4 [37120/37519 (99%)]\tLoss: 0.075644\n",
      "Train Epoch: 5 [0/37519 (0%)]\tLoss: 0.138668\n",
      "Train Epoch: 5 [640/37519 (2%)]\tLoss: 0.131925\n",
      "Train Epoch: 5 [1280/37519 (3%)]\tLoss: 0.135445\n",
      "Train Epoch: 5 [1920/37519 (5%)]\tLoss: 0.127417\n",
      "Train Epoch: 5 [2560/37519 (7%)]\tLoss: 0.314781\n",
      "Train Epoch: 5 [3200/37519 (9%)]\tLoss: 0.119281\n",
      "Train Epoch: 5 [3840/37519 (10%)]\tLoss: 0.090866\n",
      "Train Epoch: 5 [4480/37519 (12%)]\tLoss: 0.213810\n",
      "Train Epoch: 5 [5120/37519 (14%)]\tLoss: 0.107224\n",
      "Train Epoch: 5 [5760/37519 (15%)]\tLoss: 0.153862\n",
      "Train Epoch: 5 [6400/37519 (17%)]\tLoss: 0.159506\n",
      "Train Epoch: 5 [7040/37519 (19%)]\tLoss: 0.104762\n",
      "Train Epoch: 5 [7680/37519 (20%)]\tLoss: 0.144590\n",
      "Train Epoch: 5 [8320/37519 (22%)]\tLoss: 0.157683\n",
      "Train Epoch: 5 [8960/37519 (24%)]\tLoss: 0.219011\n",
      "Train Epoch: 5 [9600/37519 (26%)]\tLoss: 0.154051\n",
      "Train Epoch: 5 [10240/37519 (27%)]\tLoss: 0.070202\n",
      "Train Epoch: 5 [10880/37519 (29%)]\tLoss: 0.116696\n",
      "Train Epoch: 5 [11520/37519 (31%)]\tLoss: 0.181636\n",
      "Train Epoch: 5 [12160/37519 (32%)]\tLoss: 0.117957\n",
      "Train Epoch: 5 [12800/37519 (34%)]\tLoss: 0.369409\n",
      "Train Epoch: 5 [13440/37519 (36%)]\tLoss: 0.092385\n",
      "Train Epoch: 5 [14080/37519 (37%)]\tLoss: 0.080881\n",
      "Train Epoch: 5 [14720/37519 (39%)]\tLoss: 0.159154\n",
      "Train Epoch: 5 [15360/37519 (41%)]\tLoss: 0.077615\n",
      "Train Epoch: 5 [16000/37519 (43%)]\tLoss: 0.383202\n",
      "Train Epoch: 5 [16640/37519 (44%)]\tLoss: 0.185001\n",
      "Train Epoch: 5 [17280/37519 (46%)]\tLoss: 0.109006\n",
      "Train Epoch: 5 [17920/37519 (48%)]\tLoss: 0.110193\n",
      "Train Epoch: 5 [18560/37519 (49%)]\tLoss: 0.097309\n",
      "Train Epoch: 5 [19200/37519 (51%)]\tLoss: 0.081754\n",
      "Train Epoch: 5 [19840/37519 (53%)]\tLoss: 0.077167\n",
      "Train Epoch: 5 [20480/37519 (55%)]\tLoss: 0.052736\n",
      "Train Epoch: 5 [21120/37519 (56%)]\tLoss: 0.081894\n",
      "Train Epoch: 5 [21760/37519 (58%)]\tLoss: 0.045282\n",
      "Train Epoch: 5 [22400/37519 (60%)]\tLoss: 0.330476\n",
      "Train Epoch: 5 [23040/37519 (61%)]\tLoss: 0.045868\n",
      "Train Epoch: 5 [23680/37519 (63%)]\tLoss: 0.184671\n",
      "Train Epoch: 5 [24320/37519 (65%)]\tLoss: 0.052405\n",
      "Train Epoch: 5 [24960/37519 (66%)]\tLoss: 0.098972\n",
      "Train Epoch: 5 [25600/37519 (68%)]\tLoss: 0.080034\n",
      "Train Epoch: 5 [26240/37519 (70%)]\tLoss: 0.110101\n",
      "Train Epoch: 5 [26880/37519 (72%)]\tLoss: 0.132163\n",
      "Train Epoch: 5 [27520/37519 (73%)]\tLoss: 0.141377\n",
      "Train Epoch: 5 [28160/37519 (75%)]\tLoss: 0.044422\n",
      "Train Epoch: 5 [28800/37519 (77%)]\tLoss: 0.133361\n",
      "Train Epoch: 5 [29440/37519 (78%)]\tLoss: 0.218004\n",
      "Train Epoch: 5 [30080/37519 (80%)]\tLoss: 0.137026\n",
      "Train Epoch: 5 [30720/37519 (82%)]\tLoss: 0.196207\n",
      "Train Epoch: 5 [31360/37519 (83%)]\tLoss: 0.114340\n",
      "Train Epoch: 5 [32000/37519 (85%)]\tLoss: 0.035513\n",
      "Train Epoch: 5 [32640/37519 (87%)]\tLoss: 0.164293\n",
      "Train Epoch: 5 [33280/37519 (89%)]\tLoss: 0.131674\n",
      "Train Epoch: 5 [33920/37519 (90%)]\tLoss: 0.252809\n",
      "Train Epoch: 5 [34560/37519 (92%)]\tLoss: 0.171586\n",
      "Train Epoch: 5 [35200/37519 (94%)]\tLoss: 0.122584\n",
      "Train Epoch: 5 [35840/37519 (95%)]\tLoss: 0.132344\n",
      "Train Epoch: 5 [36480/37519 (97%)]\tLoss: 0.208546\n",
      "Train Epoch: 5 [37120/37519 (99%)]\tLoss: 0.056247\n",
      "Train Epoch: 6 [0/37519 (0%)]\tLoss: 0.076046\n",
      "Train Epoch: 6 [640/37519 (2%)]\tLoss: 0.019753\n",
      "Train Epoch: 6 [1280/37519 (3%)]\tLoss: 0.215103\n",
      "Train Epoch: 6 [1920/37519 (5%)]\tLoss: 0.100431\n",
      "Train Epoch: 6 [2560/37519 (7%)]\tLoss: 0.223231\n",
      "Train Epoch: 6 [3200/37519 (9%)]\tLoss: 0.163873\n",
      "Train Epoch: 6 [3840/37519 (10%)]\tLoss: 0.078279\n",
      "Train Epoch: 6 [4480/37519 (12%)]\tLoss: 0.082158\n",
      "Train Epoch: 6 [5120/37519 (14%)]\tLoss: 0.223667\n",
      "Train Epoch: 6 [5760/37519 (15%)]\tLoss: 0.198982\n",
      "Train Epoch: 6 [6400/37519 (17%)]\tLoss: 0.147023\n",
      "Train Epoch: 6 [7040/37519 (19%)]\tLoss: 0.045666\n",
      "Train Epoch: 6 [7680/37519 (20%)]\tLoss: 0.082450\n",
      "Train Epoch: 6 [8320/37519 (22%)]\tLoss: 0.078423\n",
      "Train Epoch: 6 [8960/37519 (24%)]\tLoss: 0.135915\n",
      "Train Epoch: 6 [9600/37519 (26%)]\tLoss: 0.179165\n",
      "Train Epoch: 6 [10240/37519 (27%)]\tLoss: 0.244590\n",
      "Train Epoch: 6 [10880/37519 (29%)]\tLoss: 0.109156\n",
      "Train Epoch: 6 [11520/37519 (31%)]\tLoss: 0.134595\n",
      "Train Epoch: 6 [12160/37519 (32%)]\tLoss: 0.035670\n",
      "Train Epoch: 6 [12800/37519 (34%)]\tLoss: 0.212662\n",
      "Train Epoch: 6 [13440/37519 (36%)]\tLoss: 0.209315\n",
      "Train Epoch: 6 [14080/37519 (37%)]\tLoss: 0.110098\n",
      "Train Epoch: 6 [14720/37519 (39%)]\tLoss: 0.164760\n",
      "Train Epoch: 6 [15360/37519 (41%)]\tLoss: 0.132245\n",
      "Train Epoch: 6 [16000/37519 (43%)]\tLoss: 0.088795\n",
      "Train Epoch: 6 [16640/37519 (44%)]\tLoss: 0.221131\n",
      "Train Epoch: 6 [17280/37519 (46%)]\tLoss: 0.110413\n",
      "Train Epoch: 6 [17920/37519 (48%)]\tLoss: 0.085422\n",
      "Train Epoch: 6 [18560/37519 (49%)]\tLoss: 0.022909\n",
      "Train Epoch: 6 [19200/37519 (51%)]\tLoss: 0.147569\n",
      "Train Epoch: 6 [19840/37519 (53%)]\tLoss: 0.053620\n",
      "Train Epoch: 6 [20480/37519 (55%)]\tLoss: 0.098824\n",
      "Train Epoch: 6 [21120/37519 (56%)]\tLoss: 0.057580\n",
      "Train Epoch: 6 [21760/37519 (58%)]\tLoss: 0.153359\n",
      "Train Epoch: 6 [22400/37519 (60%)]\tLoss: 0.222919\n",
      "Train Epoch: 6 [23040/37519 (61%)]\tLoss: 0.047293\n",
      "Train Epoch: 6 [23680/37519 (63%)]\tLoss: 0.157076\n",
      "Train Epoch: 6 [24320/37519 (65%)]\tLoss: 0.046480\n",
      "Train Epoch: 6 [24960/37519 (66%)]\tLoss: 0.212456\n",
      "Train Epoch: 6 [25600/37519 (68%)]\tLoss: 0.085030\n",
      "Train Epoch: 6 [26240/37519 (70%)]\tLoss: 0.061245\n",
      "Train Epoch: 6 [26880/37519 (72%)]\tLoss: 0.162028\n",
      "Train Epoch: 6 [27520/37519 (73%)]\tLoss: 0.063510\n",
      "Train Epoch: 6 [28160/37519 (75%)]\tLoss: 0.086768\n",
      "Train Epoch: 6 [28800/37519 (77%)]\tLoss: 0.088370\n",
      "Train Epoch: 6 [29440/37519 (78%)]\tLoss: 0.071972\n",
      "Train Epoch: 6 [30080/37519 (80%)]\tLoss: 0.105259\n",
      "Train Epoch: 6 [30720/37519 (82%)]\tLoss: 0.082374\n",
      "Train Epoch: 6 [31360/37519 (83%)]\tLoss: 0.111729\n",
      "Train Epoch: 6 [32000/37519 (85%)]\tLoss: 0.077705\n",
      "Train Epoch: 6 [32640/37519 (87%)]\tLoss: 0.266845\n",
      "Train Epoch: 6 [33280/37519 (89%)]\tLoss: 0.152725\n",
      "Train Epoch: 6 [33920/37519 (90%)]\tLoss: 0.037898\n",
      "Train Epoch: 6 [34560/37519 (92%)]\tLoss: 0.166871\n",
      "Train Epoch: 6 [35200/37519 (94%)]\tLoss: 0.069432\n",
      "Train Epoch: 6 [35840/37519 (95%)]\tLoss: 0.234781\n",
      "Train Epoch: 6 [36480/37519 (97%)]\tLoss: 0.105887\n",
      "Train Epoch: 6 [37120/37519 (99%)]\tLoss: 0.216128\n",
      "Train Epoch: 7 [0/37519 (0%)]\tLoss: 0.085482\n",
      "Train Epoch: 7 [640/37519 (2%)]\tLoss: 0.108003\n",
      "Train Epoch: 7 [1280/37519 (3%)]\tLoss: 0.092382\n",
      "Train Epoch: 7 [1920/37519 (5%)]\tLoss: 0.363602\n",
      "Train Epoch: 7 [2560/37519 (7%)]\tLoss: 0.100980\n",
      "Train Epoch: 7 [3200/37519 (9%)]\tLoss: 0.088956\n",
      "Train Epoch: 7 [3840/37519 (10%)]\tLoss: 0.061199\n",
      "Train Epoch: 7 [4480/37519 (12%)]\tLoss: 0.165116\n",
      "Train Epoch: 7 [5120/37519 (14%)]\tLoss: 0.110053\n",
      "Train Epoch: 7 [5760/37519 (15%)]\tLoss: 0.222061\n",
      "Train Epoch: 7 [6400/37519 (17%)]\tLoss: 0.077257\n",
      "Train Epoch: 7 [7040/37519 (19%)]\tLoss: 0.074373\n",
      "Train Epoch: 7 [7680/37519 (20%)]\tLoss: 0.024863\n",
      "Train Epoch: 7 [8320/37519 (22%)]\tLoss: 0.194227\n",
      "Train Epoch: 7 [8960/37519 (24%)]\tLoss: 0.174872\n",
      "Train Epoch: 7 [9600/37519 (26%)]\tLoss: 0.144328\n",
      "Train Epoch: 7 [10240/37519 (27%)]\tLoss: 0.043406\n",
      "Train Epoch: 7 [10880/37519 (29%)]\tLoss: 0.243873\n",
      "Train Epoch: 7 [11520/37519 (31%)]\tLoss: 0.040128\n",
      "Train Epoch: 7 [12160/37519 (32%)]\tLoss: 0.103505\n",
      "Train Epoch: 7 [12800/37519 (34%)]\tLoss: 0.322155\n",
      "Train Epoch: 7 [13440/37519 (36%)]\tLoss: 0.099426\n",
      "Train Epoch: 7 [14080/37519 (37%)]\tLoss: 0.174321\n",
      "Train Epoch: 7 [14720/37519 (39%)]\tLoss: 0.157198\n",
      "Train Epoch: 7 [15360/37519 (41%)]\tLoss: 0.031028\n",
      "Train Epoch: 7 [16000/37519 (43%)]\tLoss: 0.133678\n",
      "Train Epoch: 7 [16640/37519 (44%)]\tLoss: 0.209990\n",
      "Train Epoch: 7 [17280/37519 (46%)]\tLoss: 0.447024\n",
      "Train Epoch: 7 [17920/37519 (48%)]\tLoss: 0.098960\n",
      "Train Epoch: 7 [18560/37519 (49%)]\tLoss: 0.112789\n",
      "Train Epoch: 7 [19200/37519 (51%)]\tLoss: 0.118685\n",
      "Train Epoch: 7 [19840/37519 (53%)]\tLoss: 0.044685\n",
      "Train Epoch: 7 [20480/37519 (55%)]\tLoss: 0.197141\n",
      "Train Epoch: 7 [21120/37519 (56%)]\tLoss: 0.205302\n",
      "Train Epoch: 7 [21760/37519 (58%)]\tLoss: 0.101056\n",
      "Train Epoch: 7 [22400/37519 (60%)]\tLoss: 0.023122\n",
      "Train Epoch: 7 [23040/37519 (61%)]\tLoss: 0.123148\n",
      "Train Epoch: 7 [23680/37519 (63%)]\tLoss: 0.292990\n",
      "Train Epoch: 7 [24320/37519 (65%)]\tLoss: 0.077316\n",
      "Train Epoch: 7 [24960/37519 (66%)]\tLoss: 0.063181\n",
      "Train Epoch: 7 [25600/37519 (68%)]\tLoss: 0.032164\n",
      "Train Epoch: 7 [26240/37519 (70%)]\tLoss: 0.224948\n",
      "Train Epoch: 7 [26880/37519 (72%)]\tLoss: 0.232186\n",
      "Train Epoch: 7 [27520/37519 (73%)]\tLoss: 0.217440\n",
      "Train Epoch: 7 [28160/37519 (75%)]\tLoss: 0.445534\n",
      "Train Epoch: 7 [28800/37519 (77%)]\tLoss: 0.263150\n",
      "Train Epoch: 7 [29440/37519 (78%)]\tLoss: 0.125475\n",
      "Train Epoch: 7 [30080/37519 (80%)]\tLoss: 0.114095\n",
      "Train Epoch: 7 [30720/37519 (82%)]\tLoss: 0.094652\n",
      "Train Epoch: 7 [31360/37519 (83%)]\tLoss: 0.203516\n",
      "Train Epoch: 7 [32000/37519 (85%)]\tLoss: 0.100399\n",
      "Train Epoch: 7 [32640/37519 (87%)]\tLoss: 0.116104\n",
      "Train Epoch: 7 [33280/37519 (89%)]\tLoss: 0.163971\n",
      "Train Epoch: 7 [33920/37519 (90%)]\tLoss: 0.058142\n",
      "Train Epoch: 7 [34560/37519 (92%)]\tLoss: 0.089640\n",
      "Train Epoch: 7 [35200/37519 (94%)]\tLoss: 0.255956\n",
      "Train Epoch: 7 [35840/37519 (95%)]\tLoss: 0.104531\n",
      "Train Epoch: 7 [36480/37519 (97%)]\tLoss: 0.213820\n",
      "Train Epoch: 7 [37120/37519 (99%)]\tLoss: 0.271561\n",
      "Train Epoch: 8 [0/37519 (0%)]\tLoss: 0.087944\n",
      "Train Epoch: 8 [640/37519 (2%)]\tLoss: 0.074337\n",
      "Train Epoch: 8 [1280/37519 (3%)]\tLoss: 0.101353\n",
      "Train Epoch: 8 [1920/37519 (5%)]\tLoss: 0.093301\n",
      "Train Epoch: 8 [2560/37519 (7%)]\tLoss: 0.050723\n",
      "Train Epoch: 8 [3200/37519 (9%)]\tLoss: 0.067959\n",
      "Train Epoch: 8 [3840/37519 (10%)]\tLoss: 0.069318\n",
      "Train Epoch: 8 [4480/37519 (12%)]\tLoss: 0.060106\n",
      "Train Epoch: 8 [5120/37519 (14%)]\tLoss: 0.277280\n",
      "Train Epoch: 8 [5760/37519 (15%)]\tLoss: 0.105199\n",
      "Train Epoch: 8 [6400/37519 (17%)]\tLoss: 0.092579\n",
      "Train Epoch: 8 [7040/37519 (19%)]\tLoss: 0.129997\n",
      "Train Epoch: 8 [7680/37519 (20%)]\tLoss: 0.069354\n",
      "Train Epoch: 8 [8320/37519 (22%)]\tLoss: 0.111816\n",
      "Train Epoch: 8 [8960/37519 (24%)]\tLoss: 0.089096\n",
      "Train Epoch: 8 [9600/37519 (26%)]\tLoss: 0.125831\n",
      "Train Epoch: 8 [10240/37519 (27%)]\tLoss: 0.286304\n",
      "Train Epoch: 8 [10880/37519 (29%)]\tLoss: 0.168758\n",
      "Train Epoch: 8 [11520/37519 (31%)]\tLoss: 0.077620\n",
      "Train Epoch: 8 [12160/37519 (32%)]\tLoss: 0.195206\n",
      "Train Epoch: 8 [12800/37519 (34%)]\tLoss: 0.075875\n",
      "Train Epoch: 8 [13440/37519 (36%)]\tLoss: 0.033982\n",
      "Train Epoch: 8 [14080/37519 (37%)]\tLoss: 0.072284\n",
      "Train Epoch: 8 [14720/37519 (39%)]\tLoss: 0.098639\n",
      "Train Epoch: 8 [15360/37519 (41%)]\tLoss: 0.174471\n",
      "Train Epoch: 8 [16000/37519 (43%)]\tLoss: 0.120094\n",
      "Train Epoch: 8 [16640/37519 (44%)]\tLoss: 0.082228\n",
      "Train Epoch: 8 [17280/37519 (46%)]\tLoss: 0.127337\n",
      "Train Epoch: 8 [17920/37519 (48%)]\tLoss: 0.178733\n",
      "Train Epoch: 8 [18560/37519 (49%)]\tLoss: 0.087550\n",
      "Train Epoch: 8 [19200/37519 (51%)]\tLoss: 0.131649\n",
      "Train Epoch: 8 [19840/37519 (53%)]\tLoss: 0.124395\n",
      "Train Epoch: 8 [20480/37519 (55%)]\tLoss: 0.159238\n",
      "Train Epoch: 8 [21120/37519 (56%)]\tLoss: 0.063377\n",
      "Train Epoch: 8 [21760/37519 (58%)]\tLoss: 0.034626\n",
      "Train Epoch: 8 [22400/37519 (60%)]\tLoss: 0.069692\n",
      "Train Epoch: 8 [23040/37519 (61%)]\tLoss: 0.145416\n",
      "Train Epoch: 8 [23680/37519 (63%)]\tLoss: 0.185472\n",
      "Train Epoch: 8 [24320/37519 (65%)]\tLoss: 0.057344\n",
      "Train Epoch: 8 [24960/37519 (66%)]\tLoss: 0.077068\n",
      "Train Epoch: 8 [25600/37519 (68%)]\tLoss: 0.192479\n",
      "Train Epoch: 8 [26240/37519 (70%)]\tLoss: 0.181510\n",
      "Train Epoch: 8 [26880/37519 (72%)]\tLoss: 0.115515\n",
      "Train Epoch: 8 [27520/37519 (73%)]\tLoss: 0.055265\n",
      "Train Epoch: 8 [28160/37519 (75%)]\tLoss: 0.470171\n",
      "Train Epoch: 8 [28800/37519 (77%)]\tLoss: 0.139911\n",
      "Train Epoch: 8 [29440/37519 (78%)]\tLoss: 0.056498\n",
      "Train Epoch: 8 [30080/37519 (80%)]\tLoss: 0.153290\n",
      "Train Epoch: 8 [30720/37519 (82%)]\tLoss: 0.038920\n",
      "Train Epoch: 8 [31360/37519 (83%)]\tLoss: 0.044889\n",
      "Train Epoch: 8 [32000/37519 (85%)]\tLoss: 0.120655\n",
      "Train Epoch: 8 [32640/37519 (87%)]\tLoss: 0.130187\n",
      "Train Epoch: 8 [33280/37519 (89%)]\tLoss: 0.069196\n",
      "Train Epoch: 8 [33920/37519 (90%)]\tLoss: 0.177930\n",
      "Train Epoch: 8 [34560/37519 (92%)]\tLoss: 0.060391\n",
      "Train Epoch: 8 [35200/37519 (94%)]\tLoss: 0.148412\n",
      "Train Epoch: 8 [35840/37519 (95%)]\tLoss: 0.099033\n",
      "Train Epoch: 8 [36480/37519 (97%)]\tLoss: 0.048949\n",
      "Train Epoch: 8 [37120/37519 (99%)]\tLoss: 0.072453\n",
      "Train Epoch: 9 [0/37519 (0%)]\tLoss: 0.088949\n",
      "Train Epoch: 9 [640/37519 (2%)]\tLoss: 0.093638\n",
      "Train Epoch: 9 [1280/37519 (3%)]\tLoss: 0.096334\n",
      "Train Epoch: 9 [1920/37519 (5%)]\tLoss: 0.050245\n",
      "Train Epoch: 9 [2560/37519 (7%)]\tLoss: 0.201697\n",
      "Train Epoch: 9 [3200/37519 (9%)]\tLoss: 0.140533\n",
      "Train Epoch: 9 [3840/37519 (10%)]\tLoss: 0.130762\n",
      "Train Epoch: 9 [4480/37519 (12%)]\tLoss: 0.050080\n",
      "Train Epoch: 9 [5120/37519 (14%)]\tLoss: 0.078880\n",
      "Train Epoch: 9 [5760/37519 (15%)]\tLoss: 0.092255\n",
      "Train Epoch: 9 [6400/37519 (17%)]\tLoss: 0.085734\n",
      "Train Epoch: 9 [7040/37519 (19%)]\tLoss: 0.062468\n",
      "Train Epoch: 9 [7680/37519 (20%)]\tLoss: 0.229975\n",
      "Train Epoch: 9 [8320/37519 (22%)]\tLoss: 0.075984\n",
      "Train Epoch: 9 [8960/37519 (24%)]\tLoss: 0.153133\n",
      "Train Epoch: 9 [9600/37519 (26%)]\tLoss: 0.057757\n",
      "Train Epoch: 9 [10240/37519 (27%)]\tLoss: 0.132776\n",
      "Train Epoch: 9 [10880/37519 (29%)]\tLoss: 0.273960\n",
      "Train Epoch: 9 [11520/37519 (31%)]\tLoss: 0.075448\n",
      "Train Epoch: 9 [12160/37519 (32%)]\tLoss: 0.111487\n",
      "Train Epoch: 9 [12800/37519 (34%)]\tLoss: 0.138661\n",
      "Train Epoch: 9 [13440/37519 (36%)]\tLoss: 0.068207\n",
      "Train Epoch: 9 [14080/37519 (37%)]\tLoss: 0.259404\n",
      "Train Epoch: 9 [14720/37519 (39%)]\tLoss: 0.084219\n",
      "Train Epoch: 9 [15360/37519 (41%)]\tLoss: 0.049349\n",
      "Train Epoch: 9 [16000/37519 (43%)]\tLoss: 0.100004\n",
      "Train Epoch: 9 [16640/37519 (44%)]\tLoss: 0.122711\n",
      "Train Epoch: 9 [17280/37519 (46%)]\tLoss: 0.074705\n",
      "Train Epoch: 9 [17920/37519 (48%)]\tLoss: 0.119153\n",
      "Train Epoch: 9 [18560/37519 (49%)]\tLoss: 0.054794\n",
      "Train Epoch: 9 [19200/37519 (51%)]\tLoss: 0.166587\n",
      "Train Epoch: 9 [19840/37519 (53%)]\tLoss: 0.051326\n",
      "Train Epoch: 9 [20480/37519 (55%)]\tLoss: 0.074024\n",
      "Train Epoch: 9 [21120/37519 (56%)]\tLoss: 0.132958\n",
      "Train Epoch: 9 [21760/37519 (58%)]\tLoss: 0.099402\n",
      "Train Epoch: 9 [22400/37519 (60%)]\tLoss: 0.073994\n",
      "Train Epoch: 9 [23040/37519 (61%)]\tLoss: 0.068524\n",
      "Train Epoch: 9 [23680/37519 (63%)]\tLoss: 0.055293\n",
      "Train Epoch: 9 [24320/37519 (65%)]\tLoss: 0.036751\n",
      "Train Epoch: 9 [24960/37519 (66%)]\tLoss: 0.084609\n",
      "Train Epoch: 9 [25600/37519 (68%)]\tLoss: 0.146938\n",
      "Train Epoch: 9 [26240/37519 (70%)]\tLoss: 0.092387\n",
      "Train Epoch: 9 [26880/37519 (72%)]\tLoss: 0.051993\n",
      "Train Epoch: 9 [27520/37519 (73%)]\tLoss: 0.063319\n",
      "Train Epoch: 9 [28160/37519 (75%)]\tLoss: 0.188222\n",
      "Train Epoch: 9 [28800/37519 (77%)]\tLoss: 0.132382\n",
      "Train Epoch: 9 [29440/37519 (78%)]\tLoss: 0.059548\n",
      "Train Epoch: 9 [30080/37519 (80%)]\tLoss: 0.074254\n",
      "Train Epoch: 9 [30720/37519 (82%)]\tLoss: 0.110825\n",
      "Train Epoch: 9 [31360/37519 (83%)]\tLoss: 0.082650\n",
      "Train Epoch: 9 [32000/37519 (85%)]\tLoss: 0.146915\n",
      "Train Epoch: 9 [32640/37519 (87%)]\tLoss: 0.153339\n",
      "Train Epoch: 9 [33280/37519 (89%)]\tLoss: 0.103980\n",
      "Train Epoch: 9 [33920/37519 (90%)]\tLoss: 0.101369\n",
      "Train Epoch: 9 [34560/37519 (92%)]\tLoss: 0.143021\n",
      "Train Epoch: 9 [35200/37519 (94%)]\tLoss: 0.173422\n",
      "Train Epoch: 9 [35840/37519 (95%)]\tLoss: 0.082222\n",
      "Train Epoch: 9 [36480/37519 (97%)]\tLoss: 0.112088\n",
      "Train Epoch: 9 [37120/37519 (99%)]\tLoss: 0.095622\n",
      "Train Epoch: 10 [0/37519 (0%)]\tLoss: 0.086763\n",
      "Train Epoch: 10 [640/37519 (2%)]\tLoss: 0.122656\n",
      "Train Epoch: 10 [1280/37519 (3%)]\tLoss: 0.218971\n",
      "Train Epoch: 10 [1920/37519 (5%)]\tLoss: 0.090645\n",
      "Train Epoch: 10 [2560/37519 (7%)]\tLoss: 0.192863\n",
      "Train Epoch: 10 [3200/37519 (9%)]\tLoss: 0.081919\n",
      "Train Epoch: 10 [3840/37519 (10%)]\tLoss: 0.091994\n",
      "Train Epoch: 10 [4480/37519 (12%)]\tLoss: 0.165139\n",
      "Train Epoch: 10 [5120/37519 (14%)]\tLoss: 0.040061\n",
      "Train Epoch: 10 [5760/37519 (15%)]\tLoss: 0.224101\n",
      "Train Epoch: 10 [6400/37519 (17%)]\tLoss: 0.057359\n",
      "Train Epoch: 10 [7040/37519 (19%)]\tLoss: 0.324933\n",
      "Train Epoch: 10 [7680/37519 (20%)]\tLoss: 0.093531\n",
      "Train Epoch: 10 [8320/37519 (22%)]\tLoss: 0.041358\n",
      "Train Epoch: 10 [8960/37519 (24%)]\tLoss: 0.065521\n",
      "Train Epoch: 10 [9600/37519 (26%)]\tLoss: 0.061583\n",
      "Train Epoch: 10 [10240/37519 (27%)]\tLoss: 0.081917\n",
      "Train Epoch: 10 [10880/37519 (29%)]\tLoss: 0.095166\n",
      "Train Epoch: 10 [11520/37519 (31%)]\tLoss: 0.157645\n",
      "Train Epoch: 10 [12160/37519 (32%)]\tLoss: 0.064760\n",
      "Train Epoch: 10 [12800/37519 (34%)]\tLoss: 0.031145\n",
      "Train Epoch: 10 [13440/37519 (36%)]\tLoss: 0.060979\n",
      "Train Epoch: 10 [14080/37519 (37%)]\tLoss: 0.100410\n",
      "Train Epoch: 10 [14720/37519 (39%)]\tLoss: 0.061413\n",
      "Train Epoch: 10 [15360/37519 (41%)]\tLoss: 0.093306\n",
      "Train Epoch: 10 [16000/37519 (43%)]\tLoss: 0.107569\n",
      "Train Epoch: 10 [16640/37519 (44%)]\tLoss: 0.152595\n",
      "Train Epoch: 10 [17280/37519 (46%)]\tLoss: 0.390116\n",
      "Train Epoch: 10 [17920/37519 (48%)]\tLoss: 0.093405\n",
      "Train Epoch: 10 [18560/37519 (49%)]\tLoss: 0.025903\n",
      "Train Epoch: 10 [19200/37519 (51%)]\tLoss: 0.240938\n",
      "Train Epoch: 10 [19840/37519 (53%)]\tLoss: 0.065212\n",
      "Train Epoch: 10 [20480/37519 (55%)]\tLoss: 0.192719\n",
      "Train Epoch: 10 [21120/37519 (56%)]\tLoss: 0.092220\n",
      "Train Epoch: 10 [21760/37519 (58%)]\tLoss: 0.215003\n",
      "Train Epoch: 10 [22400/37519 (60%)]\tLoss: 0.054351\n",
      "Train Epoch: 10 [23040/37519 (61%)]\tLoss: 0.191059\n",
      "Train Epoch: 10 [23680/37519 (63%)]\tLoss: 0.080304\n",
      "Train Epoch: 10 [24320/37519 (65%)]\tLoss: 0.223672\n",
      "Train Epoch: 10 [24960/37519 (66%)]\tLoss: 0.110228\n",
      "Train Epoch: 10 [25600/37519 (68%)]\tLoss: 0.082380\n",
      "Train Epoch: 10 [26240/37519 (70%)]\tLoss: 0.213801\n",
      "Train Epoch: 10 [26880/37519 (72%)]\tLoss: 0.166510\n",
      "Train Epoch: 10 [27520/37519 (73%)]\tLoss: 0.136233\n",
      "Train Epoch: 10 [28160/37519 (75%)]\tLoss: 0.138548\n",
      "Train Epoch: 10 [28800/37519 (77%)]\tLoss: 0.229111\n",
      "Train Epoch: 10 [29440/37519 (78%)]\tLoss: 0.045319\n",
      "Train Epoch: 10 [30080/37519 (80%)]\tLoss: 0.032972\n",
      "Train Epoch: 10 [30720/37519 (82%)]\tLoss: 0.273846\n",
      "Train Epoch: 10 [31360/37519 (83%)]\tLoss: 0.218237\n",
      "Train Epoch: 10 [32000/37519 (85%)]\tLoss: 0.085284\n",
      "Train Epoch: 10 [32640/37519 (87%)]\tLoss: 0.101681\n",
      "Train Epoch: 10 [33280/37519 (89%)]\tLoss: 0.075968\n",
      "Train Epoch: 10 [33920/37519 (90%)]\tLoss: 0.081558\n",
      "Train Epoch: 10 [34560/37519 (92%)]\tLoss: 0.082766\n",
      "Train Epoch: 10 [35200/37519 (94%)]\tLoss: 0.219328\n",
      "Train Epoch: 10 [35840/37519 (95%)]\tLoss: 0.080871\n",
      "Train Epoch: 10 [36480/37519 (97%)]\tLoss: 0.179072\n",
      "Train Epoch: 10 [37120/37519 (99%)]\tLoss: 0.060619\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/22481 (0%)]\tLoss: 0.206590\n",
      "Train Epoch: 1 [640/22481 (3%)]\tLoss: 0.232524\n",
      "Train Epoch: 1 [1280/22481 (6%)]\tLoss: 0.266218\n",
      "Train Epoch: 1 [1920/22481 (9%)]\tLoss: 0.117677\n",
      "Train Epoch: 1 [2560/22481 (11%)]\tLoss: 0.086751\n",
      "Train Epoch: 1 [3200/22481 (14%)]\tLoss: 0.098220\n",
      "Train Epoch: 1 [3840/22481 (17%)]\tLoss: 0.153401\n",
      "Train Epoch: 1 [4480/22481 (20%)]\tLoss: 0.079544\n",
      "Train Epoch: 1 [5120/22481 (23%)]\tLoss: 0.168121\n",
      "Train Epoch: 1 [5760/22481 (26%)]\tLoss: 0.139997\n",
      "Train Epoch: 1 [6400/22481 (28%)]\tLoss: 0.131150\n",
      "Train Epoch: 1 [7040/22481 (31%)]\tLoss: 0.168841\n",
      "Train Epoch: 1 [7680/22481 (34%)]\tLoss: 0.349949\n",
      "Train Epoch: 1 [8320/22481 (37%)]\tLoss: 0.145270\n",
      "Train Epoch: 1 [8960/22481 (40%)]\tLoss: 0.258883\n",
      "Train Epoch: 1 [9600/22481 (43%)]\tLoss: 0.068215\n",
      "Train Epoch: 1 [10240/22481 (45%)]\tLoss: 0.237676\n",
      "Train Epoch: 1 [10880/22481 (48%)]\tLoss: 0.054205\n",
      "Train Epoch: 1 [11520/22481 (51%)]\tLoss: 0.118735\n",
      "Train Epoch: 1 [12160/22481 (54%)]\tLoss: 0.191316\n",
      "Train Epoch: 1 [12800/22481 (57%)]\tLoss: 0.090341\n",
      "Train Epoch: 1 [13440/22481 (60%)]\tLoss: 0.068378\n",
      "Train Epoch: 1 [14080/22481 (62%)]\tLoss: 0.084936\n",
      "Train Epoch: 1 [14720/22481 (65%)]\tLoss: 0.066294\n",
      "Train Epoch: 1 [15360/22481 (68%)]\tLoss: 0.118317\n",
      "Train Epoch: 1 [16000/22481 (71%)]\tLoss: 0.095960\n",
      "Train Epoch: 1 [16640/22481 (74%)]\tLoss: 0.045858\n",
      "Train Epoch: 1 [17280/22481 (77%)]\tLoss: 0.195603\n",
      "Train Epoch: 1 [17920/22481 (80%)]\tLoss: 0.048364\n",
      "Train Epoch: 1 [18560/22481 (82%)]\tLoss: 0.094047\n",
      "Train Epoch: 1 [19200/22481 (85%)]\tLoss: 0.132498\n",
      "Train Epoch: 1 [19840/22481 (88%)]\tLoss: 0.074004\n",
      "Train Epoch: 1 [20480/22481 (91%)]\tLoss: 0.182154\n",
      "Train Epoch: 1 [21120/22481 (94%)]\tLoss: 0.031207\n",
      "Train Epoch: 1 [21760/22481 (97%)]\tLoss: 0.149007\n",
      "Train Epoch: 1 [22400/22481 (99%)]\tLoss: 0.030913\n",
      "Train Epoch: 2 [0/22481 (0%)]\tLoss: 0.180769\n",
      "Train Epoch: 2 [640/22481 (3%)]\tLoss: 0.091636\n",
      "Train Epoch: 2 [1280/22481 (6%)]\tLoss: 0.065407\n",
      "Train Epoch: 2 [1920/22481 (9%)]\tLoss: 0.083145\n",
      "Train Epoch: 2 [2560/22481 (11%)]\tLoss: 0.060121\n",
      "Train Epoch: 2 [3200/22481 (14%)]\tLoss: 0.179962\n",
      "Train Epoch: 2 [3840/22481 (17%)]\tLoss: 0.113890\n",
      "Train Epoch: 2 [4480/22481 (20%)]\tLoss: 0.275420\n",
      "Train Epoch: 2 [5120/22481 (23%)]\tLoss: 0.110168\n",
      "Train Epoch: 2 [5760/22481 (26%)]\tLoss: 0.117804\n",
      "Train Epoch: 2 [6400/22481 (28%)]\tLoss: 0.139043\n",
      "Train Epoch: 2 [7040/22481 (31%)]\tLoss: 0.152291\n",
      "Train Epoch: 2 [7680/22481 (34%)]\tLoss: 0.169935\n",
      "Train Epoch: 2 [8320/22481 (37%)]\tLoss: 0.075217\n",
      "Train Epoch: 2 [8960/22481 (40%)]\tLoss: 0.179733\n",
      "Train Epoch: 2 [9600/22481 (43%)]\tLoss: 0.179120\n",
      "Train Epoch: 2 [10240/22481 (45%)]\tLoss: 0.082815\n",
      "Train Epoch: 2 [10880/22481 (48%)]\tLoss: 0.232071\n",
      "Train Epoch: 2 [11520/22481 (51%)]\tLoss: 0.268244\n",
      "Train Epoch: 2 [12160/22481 (54%)]\tLoss: 0.211926\n",
      "Train Epoch: 2 [12800/22481 (57%)]\tLoss: 0.363877\n",
      "Train Epoch: 2 [13440/22481 (60%)]\tLoss: 0.082234\n",
      "Train Epoch: 2 [14080/22481 (62%)]\tLoss: 0.023894\n",
      "Train Epoch: 2 [14720/22481 (65%)]\tLoss: 0.155097\n",
      "Train Epoch: 2 [15360/22481 (68%)]\tLoss: 0.071208\n",
      "Train Epoch: 2 [16000/22481 (71%)]\tLoss: 0.276169\n",
      "Train Epoch: 2 [16640/22481 (74%)]\tLoss: 0.100142\n",
      "Train Epoch: 2 [17280/22481 (77%)]\tLoss: 0.037650\n",
      "Train Epoch: 2 [17920/22481 (80%)]\tLoss: 0.044691\n",
      "Train Epoch: 2 [18560/22481 (82%)]\tLoss: 0.113332\n",
      "Train Epoch: 2 [19200/22481 (85%)]\tLoss: 0.183152\n",
      "Train Epoch: 2 [19840/22481 (88%)]\tLoss: 0.128885\n",
      "Train Epoch: 2 [20480/22481 (91%)]\tLoss: 0.232669\n",
      "Train Epoch: 2 [21120/22481 (94%)]\tLoss: 0.107355\n",
      "Train Epoch: 2 [21760/22481 (97%)]\tLoss: 0.082302\n",
      "Train Epoch: 2 [22400/22481 (99%)]\tLoss: 0.081534\n",
      "Train Epoch: 3 [0/22481 (0%)]\tLoss: 0.046571\n",
      "Train Epoch: 3 [640/22481 (3%)]\tLoss: 0.179372\n",
      "Train Epoch: 3 [1280/22481 (6%)]\tLoss: 0.284979\n",
      "Train Epoch: 3 [1920/22481 (9%)]\tLoss: 0.115061\n",
      "Train Epoch: 3 [2560/22481 (11%)]\tLoss: 0.148575\n",
      "Train Epoch: 3 [3200/22481 (14%)]\tLoss: 0.039184\n",
      "Train Epoch: 3 [3840/22481 (17%)]\tLoss: 0.077074\n",
      "Train Epoch: 3 [4480/22481 (20%)]\tLoss: 0.091812\n",
      "Train Epoch: 3 [5120/22481 (23%)]\tLoss: 0.053176\n",
      "Train Epoch: 3 [5760/22481 (26%)]\tLoss: 0.059477\n",
      "Train Epoch: 3 [6400/22481 (28%)]\tLoss: 0.103584\n",
      "Train Epoch: 3 [7040/22481 (31%)]\tLoss: 0.071980\n",
      "Train Epoch: 3 [7680/22481 (34%)]\tLoss: 0.022012\n",
      "Train Epoch: 3 [8320/22481 (37%)]\tLoss: 0.254437\n",
      "Train Epoch: 3 [8960/22481 (40%)]\tLoss: 0.142700\n",
      "Train Epoch: 3 [9600/22481 (43%)]\tLoss: 0.120255\n",
      "Train Epoch: 3 [10240/22481 (45%)]\tLoss: 0.136298\n",
      "Train Epoch: 3 [10880/22481 (48%)]\tLoss: 0.155818\n",
      "Train Epoch: 3 [11520/22481 (51%)]\tLoss: 0.040152\n",
      "Train Epoch: 3 [12160/22481 (54%)]\tLoss: 0.026512\n",
      "Train Epoch: 3 [12800/22481 (57%)]\tLoss: 0.210589\n",
      "Train Epoch: 3 [13440/22481 (60%)]\tLoss: 0.132523\n",
      "Train Epoch: 3 [14080/22481 (62%)]\tLoss: 0.119663\n",
      "Train Epoch: 3 [14720/22481 (65%)]\tLoss: 0.107382\n",
      "Train Epoch: 3 [15360/22481 (68%)]\tLoss: 0.047925\n",
      "Train Epoch: 3 [16000/22481 (71%)]\tLoss: 0.183725\n",
      "Train Epoch: 3 [16640/22481 (74%)]\tLoss: 0.167065\n",
      "Train Epoch: 3 [17280/22481 (77%)]\tLoss: 0.111350\n",
      "Train Epoch: 3 [17920/22481 (80%)]\tLoss: 0.146744\n",
      "Train Epoch: 3 [18560/22481 (82%)]\tLoss: 0.152919\n",
      "Train Epoch: 3 [19200/22481 (85%)]\tLoss: 0.043702\n",
      "Train Epoch: 3 [19840/22481 (88%)]\tLoss: 0.247405\n",
      "Train Epoch: 3 [20480/22481 (91%)]\tLoss: 0.043539\n",
      "Train Epoch: 3 [21120/22481 (94%)]\tLoss: 0.124250\n",
      "Train Epoch: 3 [21760/22481 (97%)]\tLoss: 0.122491\n",
      "Train Epoch: 3 [22400/22481 (99%)]\tLoss: 0.045657\n",
      "Train Epoch: 4 [0/22481 (0%)]\tLoss: 0.183451\n",
      "Train Epoch: 4 [640/22481 (3%)]\tLoss: 0.236598\n",
      "Train Epoch: 4 [1280/22481 (6%)]\tLoss: 0.104272\n",
      "Train Epoch: 4 [1920/22481 (9%)]\tLoss: 0.068502\n",
      "Train Epoch: 4 [2560/22481 (11%)]\tLoss: 0.222698\n",
      "Train Epoch: 4 [3200/22481 (14%)]\tLoss: 0.048522\n",
      "Train Epoch: 4 [3840/22481 (17%)]\tLoss: 0.060645\n",
      "Train Epoch: 4 [4480/22481 (20%)]\tLoss: 0.088109\n",
      "Train Epoch: 4 [5120/22481 (23%)]\tLoss: 0.020889\n",
      "Train Epoch: 4 [5760/22481 (26%)]\tLoss: 0.031479\n",
      "Train Epoch: 4 [6400/22481 (28%)]\tLoss: 0.068735\n",
      "Train Epoch: 4 [7040/22481 (31%)]\tLoss: 0.192526\n",
      "Train Epoch: 4 [7680/22481 (34%)]\tLoss: 0.350373\n",
      "Train Epoch: 4 [8320/22481 (37%)]\tLoss: 0.163114\n",
      "Train Epoch: 4 [8960/22481 (40%)]\tLoss: 0.218943\n",
      "Train Epoch: 4 [9600/22481 (43%)]\tLoss: 0.094173\n",
      "Train Epoch: 4 [10240/22481 (45%)]\tLoss: 0.131307\n",
      "Train Epoch: 4 [10880/22481 (48%)]\tLoss: 0.202546\n",
      "Train Epoch: 4 [11520/22481 (51%)]\tLoss: 0.126485\n",
      "Train Epoch: 4 [12160/22481 (54%)]\tLoss: 0.100227\n",
      "Train Epoch: 4 [12800/22481 (57%)]\tLoss: 0.138429\n",
      "Train Epoch: 4 [13440/22481 (60%)]\tLoss: 0.121290\n",
      "Train Epoch: 4 [14080/22481 (62%)]\tLoss: 0.133544\n",
      "Train Epoch: 4 [14720/22481 (65%)]\tLoss: 0.128982\n",
      "Train Epoch: 4 [15360/22481 (68%)]\tLoss: 0.049249\n",
      "Train Epoch: 4 [16000/22481 (71%)]\tLoss: 0.110878\n",
      "Train Epoch: 4 [16640/22481 (74%)]\tLoss: 0.149966\n",
      "Train Epoch: 4 [17280/22481 (77%)]\tLoss: 0.181638\n",
      "Train Epoch: 4 [17920/22481 (80%)]\tLoss: 0.110610\n",
      "Train Epoch: 4 [18560/22481 (82%)]\tLoss: 0.252152\n",
      "Train Epoch: 4 [19200/22481 (85%)]\tLoss: 0.077375\n",
      "Train Epoch: 4 [19840/22481 (88%)]\tLoss: 0.111504\n",
      "Train Epoch: 4 [20480/22481 (91%)]\tLoss: 0.143769\n",
      "Train Epoch: 4 [21120/22481 (94%)]\tLoss: 0.116012\n",
      "Train Epoch: 4 [21760/22481 (97%)]\tLoss: 0.212309\n",
      "Train Epoch: 4 [22400/22481 (99%)]\tLoss: 0.094038\n",
      "Train Epoch: 5 [0/22481 (0%)]\tLoss: 0.070266\n",
      "Train Epoch: 5 [640/22481 (3%)]\tLoss: 0.080852\n",
      "Train Epoch: 5 [1280/22481 (6%)]\tLoss: 0.184951\n",
      "Train Epoch: 5 [1920/22481 (9%)]\tLoss: 0.068220\n",
      "Train Epoch: 5 [2560/22481 (11%)]\tLoss: 0.032054\n",
      "Train Epoch: 5 [3200/22481 (14%)]\tLoss: 0.317478\n",
      "Train Epoch: 5 [3840/22481 (17%)]\tLoss: 0.208418\n",
      "Train Epoch: 5 [4480/22481 (20%)]\tLoss: 0.040513\n",
      "Train Epoch: 5 [5120/22481 (23%)]\tLoss: 0.137564\n",
      "Train Epoch: 5 [5760/22481 (26%)]\tLoss: 0.040977\n",
      "Train Epoch: 5 [6400/22481 (28%)]\tLoss: 0.071475\n",
      "Train Epoch: 5 [7040/22481 (31%)]\tLoss: 0.179452\n",
      "Train Epoch: 5 [7680/22481 (34%)]\tLoss: 0.207266\n",
      "Train Epoch: 5 [8320/22481 (37%)]\tLoss: 0.125158\n",
      "Train Epoch: 5 [8960/22481 (40%)]\tLoss: 0.137737\n",
      "Train Epoch: 5 [9600/22481 (43%)]\tLoss: 0.101567\n",
      "Train Epoch: 5 [10240/22481 (45%)]\tLoss: 0.212125\n",
      "Train Epoch: 5 [10880/22481 (48%)]\tLoss: 0.177999\n",
      "Train Epoch: 5 [11520/22481 (51%)]\tLoss: 0.092555\n",
      "Train Epoch: 5 [12160/22481 (54%)]\tLoss: 0.185169\n",
      "Train Epoch: 5 [12800/22481 (57%)]\tLoss: 0.180963\n",
      "Train Epoch: 5 [13440/22481 (60%)]\tLoss: 0.055578\n",
      "Train Epoch: 5 [14080/22481 (62%)]\tLoss: 0.081810\n",
      "Train Epoch: 5 [14720/22481 (65%)]\tLoss: 0.087065\n",
      "Train Epoch: 5 [15360/22481 (68%)]\tLoss: 0.114982\n",
      "Train Epoch: 5 [16000/22481 (71%)]\tLoss: 0.045257\n",
      "Train Epoch: 5 [16640/22481 (74%)]\tLoss: 0.031522\n",
      "Train Epoch: 5 [17280/22481 (77%)]\tLoss: 0.056936\n",
      "Train Epoch: 5 [17920/22481 (80%)]\tLoss: 0.066479\n",
      "Train Epoch: 5 [18560/22481 (82%)]\tLoss: 0.165490\n",
      "Train Epoch: 5 [19200/22481 (85%)]\tLoss: 0.124699\n",
      "Train Epoch: 5 [19840/22481 (88%)]\tLoss: 0.140798\n",
      "Train Epoch: 5 [20480/22481 (91%)]\tLoss: 0.054263\n",
      "Train Epoch: 5 [21120/22481 (94%)]\tLoss: 0.166299\n",
      "Train Epoch: 5 [21760/22481 (97%)]\tLoss: 0.065141\n",
      "Train Epoch: 5 [22400/22481 (99%)]\tLoss: 0.125394\n",
      "Train Epoch: 6 [0/22481 (0%)]\tLoss: 0.368411\n",
      "Train Epoch: 6 [640/22481 (3%)]\tLoss: 0.092961\n",
      "Train Epoch: 6 [1280/22481 (6%)]\tLoss: 0.151495\n",
      "Train Epoch: 6 [1920/22481 (9%)]\tLoss: 0.122744\n",
      "Train Epoch: 6 [2560/22481 (11%)]\tLoss: 0.174319\n",
      "Train Epoch: 6 [3200/22481 (14%)]\tLoss: 0.193668\n",
      "Train Epoch: 6 [3840/22481 (17%)]\tLoss: 0.130266\n",
      "Train Epoch: 6 [4480/22481 (20%)]\tLoss: 0.200625\n",
      "Train Epoch: 6 [5120/22481 (23%)]\tLoss: 0.121650\n",
      "Train Epoch: 6 [5760/22481 (26%)]\tLoss: 0.053519\n",
      "Train Epoch: 6 [6400/22481 (28%)]\tLoss: 0.061311\n",
      "Train Epoch: 6 [7040/22481 (31%)]\tLoss: 0.047064\n",
      "Train Epoch: 6 [7680/22481 (34%)]\tLoss: 0.065865\n",
      "Train Epoch: 6 [8320/22481 (37%)]\tLoss: 0.089211\n",
      "Train Epoch: 6 [8960/22481 (40%)]\tLoss: 0.118958\n",
      "Train Epoch: 6 [9600/22481 (43%)]\tLoss: 0.089624\n",
      "Train Epoch: 6 [10240/22481 (45%)]\tLoss: 0.133504\n",
      "Train Epoch: 6 [10880/22481 (48%)]\tLoss: 0.161833\n",
      "Train Epoch: 6 [11520/22481 (51%)]\tLoss: 0.125128\n",
      "Train Epoch: 6 [12160/22481 (54%)]\tLoss: 0.155291\n",
      "Train Epoch: 6 [12800/22481 (57%)]\tLoss: 0.131527\n",
      "Train Epoch: 6 [13440/22481 (60%)]\tLoss: 0.095187\n",
      "Train Epoch: 6 [14080/22481 (62%)]\tLoss: 0.136472\n",
      "Train Epoch: 6 [14720/22481 (65%)]\tLoss: 0.286059\n",
      "Train Epoch: 6 [15360/22481 (68%)]\tLoss: 0.180055\n",
      "Train Epoch: 6 [16000/22481 (71%)]\tLoss: 0.035700\n",
      "Train Epoch: 6 [16640/22481 (74%)]\tLoss: 0.160208\n",
      "Train Epoch: 6 [17280/22481 (77%)]\tLoss: 0.082181\n",
      "Train Epoch: 6 [17920/22481 (80%)]\tLoss: 0.121558\n",
      "Train Epoch: 6 [18560/22481 (82%)]\tLoss: 0.113185\n",
      "Train Epoch: 6 [19200/22481 (85%)]\tLoss: 0.170352\n",
      "Train Epoch: 6 [19840/22481 (88%)]\tLoss: 0.065512\n",
      "Train Epoch: 6 [20480/22481 (91%)]\tLoss: 0.122982\n",
      "Train Epoch: 6 [21120/22481 (94%)]\tLoss: 0.129083\n",
      "Train Epoch: 6 [21760/22481 (97%)]\tLoss: 0.153945\n",
      "Train Epoch: 6 [22400/22481 (99%)]\tLoss: 0.128258\n",
      "Train Epoch: 7 [0/22481 (0%)]\tLoss: 0.070641\n",
      "Train Epoch: 7 [640/22481 (3%)]\tLoss: 0.373473\n",
      "Train Epoch: 7 [1280/22481 (6%)]\tLoss: 0.107244\n",
      "Train Epoch: 7 [1920/22481 (9%)]\tLoss: 0.056022\n",
      "Train Epoch: 7 [2560/22481 (11%)]\tLoss: 0.169651\n",
      "Train Epoch: 7 [3200/22481 (14%)]\tLoss: 0.150241\n",
      "Train Epoch: 7 [3840/22481 (17%)]\tLoss: 0.076900\n",
      "Train Epoch: 7 [4480/22481 (20%)]\tLoss: 0.040576\n",
      "Train Epoch: 7 [5120/22481 (23%)]\tLoss: 0.162186\n",
      "Train Epoch: 7 [5760/22481 (26%)]\tLoss: 0.039636\n",
      "Train Epoch: 7 [6400/22481 (28%)]\tLoss: 0.196522\n",
      "Train Epoch: 7 [7040/22481 (31%)]\tLoss: 0.100355\n",
      "Train Epoch: 7 [7680/22481 (34%)]\tLoss: 0.210193\n",
      "Train Epoch: 7 [8320/22481 (37%)]\tLoss: 0.163613\n",
      "Train Epoch: 7 [8960/22481 (40%)]\tLoss: 0.161022\n",
      "Train Epoch: 7 [9600/22481 (43%)]\tLoss: 0.224628\n",
      "Train Epoch: 7 [10240/22481 (45%)]\tLoss: 0.099001\n",
      "Train Epoch: 7 [10880/22481 (48%)]\tLoss: 0.152732\n",
      "Train Epoch: 7 [11520/22481 (51%)]\tLoss: 0.061184\n",
      "Train Epoch: 7 [12160/22481 (54%)]\tLoss: 0.164722\n",
      "Train Epoch: 7 [12800/22481 (57%)]\tLoss: 0.091494\n",
      "Train Epoch: 7 [13440/22481 (60%)]\tLoss: 0.029685\n",
      "Train Epoch: 7 [14080/22481 (62%)]\tLoss: 0.035510\n",
      "Train Epoch: 7 [14720/22481 (65%)]\tLoss: 0.053598\n",
      "Train Epoch: 7 [15360/22481 (68%)]\tLoss: 0.048614\n",
      "Train Epoch: 7 [16000/22481 (71%)]\tLoss: 0.173525\n",
      "Train Epoch: 7 [16640/22481 (74%)]\tLoss: 0.174690\n",
      "Train Epoch: 7 [17280/22481 (77%)]\tLoss: 0.171432\n",
      "Train Epoch: 7 [17920/22481 (80%)]\tLoss: 0.139691\n",
      "Train Epoch: 7 [18560/22481 (82%)]\tLoss: 0.040995\n",
      "Train Epoch: 7 [19200/22481 (85%)]\tLoss: 0.135257\n",
      "Train Epoch: 7 [19840/22481 (88%)]\tLoss: 0.046333\n",
      "Train Epoch: 7 [20480/22481 (91%)]\tLoss: 0.074320\n",
      "Train Epoch: 7 [21120/22481 (94%)]\tLoss: 0.283390\n",
      "Train Epoch: 7 [21760/22481 (97%)]\tLoss: 0.119045\n",
      "Train Epoch: 7 [22400/22481 (99%)]\tLoss: 0.244894\n",
      "Train Epoch: 8 [0/22481 (0%)]\tLoss: 0.087466\n",
      "Train Epoch: 8 [640/22481 (3%)]\tLoss: 0.185255\n",
      "Train Epoch: 8 [1280/22481 (6%)]\tLoss: 0.231869\n",
      "Train Epoch: 8 [1920/22481 (9%)]\tLoss: 0.104381\n",
      "Train Epoch: 8 [2560/22481 (11%)]\tLoss: 0.077702\n",
      "Train Epoch: 8 [3200/22481 (14%)]\tLoss: 0.191782\n",
      "Train Epoch: 8 [3840/22481 (17%)]\tLoss: 0.066643\n",
      "Train Epoch: 8 [4480/22481 (20%)]\tLoss: 0.049031\n",
      "Train Epoch: 8 [5120/22481 (23%)]\tLoss: 0.186308\n",
      "Train Epoch: 8 [5760/22481 (26%)]\tLoss: 0.046180\n",
      "Train Epoch: 8 [6400/22481 (28%)]\tLoss: 0.135421\n",
      "Train Epoch: 8 [7040/22481 (31%)]\tLoss: 0.150709\n",
      "Train Epoch: 8 [7680/22481 (34%)]\tLoss: 0.242304\n",
      "Train Epoch: 8 [8320/22481 (37%)]\tLoss: 0.049496\n",
      "Train Epoch: 8 [8960/22481 (40%)]\tLoss: 0.116410\n",
      "Train Epoch: 8 [9600/22481 (43%)]\tLoss: 0.121817\n",
      "Train Epoch: 8 [10240/22481 (45%)]\tLoss: 0.085484\n",
      "Train Epoch: 8 [10880/22481 (48%)]\tLoss: 0.037066\n",
      "Train Epoch: 8 [11520/22481 (51%)]\tLoss: 0.097027\n",
      "Train Epoch: 8 [12160/22481 (54%)]\tLoss: 0.065157\n",
      "Train Epoch: 8 [12800/22481 (57%)]\tLoss: 0.071986\n",
      "Train Epoch: 8 [13440/22481 (60%)]\tLoss: 0.190962\n",
      "Train Epoch: 8 [14080/22481 (62%)]\tLoss: 0.125116\n",
      "Train Epoch: 8 [14720/22481 (65%)]\tLoss: 0.084355\n",
      "Train Epoch: 8 [15360/22481 (68%)]\tLoss: 0.098828\n",
      "Train Epoch: 8 [16000/22481 (71%)]\tLoss: 0.096471\n",
      "Train Epoch: 8 [16640/22481 (74%)]\tLoss: 0.036047\n",
      "Train Epoch: 8 [17280/22481 (77%)]\tLoss: 0.081581\n",
      "Train Epoch: 8 [17920/22481 (80%)]\tLoss: 0.125808\n",
      "Train Epoch: 8 [18560/22481 (82%)]\tLoss: 0.077796\n",
      "Train Epoch: 8 [19200/22481 (85%)]\tLoss: 0.071142\n",
      "Train Epoch: 8 [19840/22481 (88%)]\tLoss: 0.043112\n",
      "Train Epoch: 8 [20480/22481 (91%)]\tLoss: 0.026237\n",
      "Train Epoch: 8 [21120/22481 (94%)]\tLoss: 0.110893\n",
      "Train Epoch: 8 [21760/22481 (97%)]\tLoss: 0.072207\n",
      "Train Epoch: 8 [22400/22481 (99%)]\tLoss: 0.202341\n",
      "Train Epoch: 9 [0/22481 (0%)]\tLoss: 0.102956\n",
      "Train Epoch: 9 [640/22481 (3%)]\tLoss: 0.144752\n",
      "Train Epoch: 9 [1280/22481 (6%)]\tLoss: 0.065665\n",
      "Train Epoch: 9 [1920/22481 (9%)]\tLoss: 0.133456\n",
      "Train Epoch: 9 [2560/22481 (11%)]\tLoss: 0.062993\n",
      "Train Epoch: 9 [3200/22481 (14%)]\tLoss: 0.223225\n",
      "Train Epoch: 9 [3840/22481 (17%)]\tLoss: 0.170865\n",
      "Train Epoch: 9 [4480/22481 (20%)]\tLoss: 0.236968\n",
      "Train Epoch: 9 [5120/22481 (23%)]\tLoss: 0.088961\n",
      "Train Epoch: 9 [5760/22481 (26%)]\tLoss: 0.073728\n",
      "Train Epoch: 9 [6400/22481 (28%)]\tLoss: 0.156863\n",
      "Train Epoch: 9 [7040/22481 (31%)]\tLoss: 0.130125\n",
      "Train Epoch: 9 [7680/22481 (34%)]\tLoss: 0.058953\n",
      "Train Epoch: 9 [8320/22481 (37%)]\tLoss: 0.182743\n",
      "Train Epoch: 9 [8960/22481 (40%)]\tLoss: 0.071383\n",
      "Train Epoch: 9 [9600/22481 (43%)]\tLoss: 0.081279\n",
      "Train Epoch: 9 [10240/22481 (45%)]\tLoss: 0.089538\n",
      "Train Epoch: 9 [10880/22481 (48%)]\tLoss: 0.073285\n",
      "Train Epoch: 9 [11520/22481 (51%)]\tLoss: 0.157795\n",
      "Train Epoch: 9 [12160/22481 (54%)]\tLoss: 0.122590\n",
      "Train Epoch: 9 [12800/22481 (57%)]\tLoss: 0.161442\n",
      "Train Epoch: 9 [13440/22481 (60%)]\tLoss: 0.032201\n",
      "Train Epoch: 9 [14080/22481 (62%)]\tLoss: 0.008251\n",
      "Train Epoch: 9 [14720/22481 (65%)]\tLoss: 0.163702\n",
      "Train Epoch: 9 [15360/22481 (68%)]\tLoss: 0.126500\n",
      "Train Epoch: 9 [16000/22481 (71%)]\tLoss: 0.149215\n",
      "Train Epoch: 9 [16640/22481 (74%)]\tLoss: 0.053070\n",
      "Train Epoch: 9 [17280/22481 (77%)]\tLoss: 0.191969\n",
      "Train Epoch: 9 [17920/22481 (80%)]\tLoss: 0.035314\n",
      "Train Epoch: 9 [18560/22481 (82%)]\tLoss: 0.126289\n",
      "Train Epoch: 9 [19200/22481 (85%)]\tLoss: 0.075788\n",
      "Train Epoch: 9 [19840/22481 (88%)]\tLoss: 0.165554\n",
      "Train Epoch: 9 [20480/22481 (91%)]\tLoss: 0.197977\n",
      "Train Epoch: 9 [21120/22481 (94%)]\tLoss: 0.172122\n",
      "Train Epoch: 9 [21760/22481 (97%)]\tLoss: 0.035237\n",
      "Train Epoch: 9 [22400/22481 (99%)]\tLoss: 0.197566\n",
      "Train Epoch: 10 [0/22481 (0%)]\tLoss: 0.091739\n",
      "Train Epoch: 10 [640/22481 (3%)]\tLoss: 0.198281\n",
      "Train Epoch: 10 [1280/22481 (6%)]\tLoss: 0.078253\n",
      "Train Epoch: 10 [1920/22481 (9%)]\tLoss: 0.164524\n",
      "Train Epoch: 10 [2560/22481 (11%)]\tLoss: 0.079281\n",
      "Train Epoch: 10 [3200/22481 (14%)]\tLoss: 0.068828\n",
      "Train Epoch: 10 [3840/22481 (17%)]\tLoss: 0.085905\n",
      "Train Epoch: 10 [4480/22481 (20%)]\tLoss: 0.091861\n",
      "Train Epoch: 10 [5120/22481 (23%)]\tLoss: 0.016445\n",
      "Train Epoch: 10 [5760/22481 (26%)]\tLoss: 0.143242\n",
      "Train Epoch: 10 [6400/22481 (28%)]\tLoss: 0.072696\n",
      "Train Epoch: 10 [7040/22481 (31%)]\tLoss: 0.087459\n",
      "Train Epoch: 10 [7680/22481 (34%)]\tLoss: 0.028353\n",
      "Train Epoch: 10 [8320/22481 (37%)]\tLoss: 0.149606\n",
      "Train Epoch: 10 [8960/22481 (40%)]\tLoss: 0.182648\n",
      "Train Epoch: 10 [9600/22481 (43%)]\tLoss: 0.034330\n",
      "Train Epoch: 10 [10240/22481 (45%)]\tLoss: 0.059385\n",
      "Train Epoch: 10 [10880/22481 (48%)]\tLoss: 0.076424\n",
      "Train Epoch: 10 [11520/22481 (51%)]\tLoss: 0.100902\n",
      "Train Epoch: 10 [12160/22481 (54%)]\tLoss: 0.038680\n",
      "Train Epoch: 10 [12800/22481 (57%)]\tLoss: 0.144743\n",
      "Train Epoch: 10 [13440/22481 (60%)]\tLoss: 0.056024\n",
      "Train Epoch: 10 [14080/22481 (62%)]\tLoss: 0.037695\n",
      "Train Epoch: 10 [14720/22481 (65%)]\tLoss: 0.077860\n",
      "Train Epoch: 10 [15360/22481 (68%)]\tLoss: 0.124755\n",
      "Train Epoch: 10 [16000/22481 (71%)]\tLoss: 0.213401\n",
      "Train Epoch: 10 [16640/22481 (74%)]\tLoss: 0.088479\n",
      "Train Epoch: 10 [17280/22481 (77%)]\tLoss: 0.091913\n",
      "Train Epoch: 10 [17920/22481 (80%)]\tLoss: 0.058413\n",
      "Train Epoch: 10 [18560/22481 (82%)]\tLoss: 0.030634\n",
      "Train Epoch: 10 [19200/22481 (85%)]\tLoss: 0.068634\n",
      "Train Epoch: 10 [19840/22481 (88%)]\tLoss: 0.068660\n",
      "Train Epoch: 10 [20480/22481 (91%)]\tLoss: 0.079466\n",
      "Train Epoch: 10 [21120/22481 (94%)]\tLoss: 0.182948\n",
      "Train Epoch: 10 [21760/22481 (97%)]\tLoss: 0.259738\n",
      "Train Epoch: 10 [22400/22481 (99%)]\tLoss: 0.088799\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.2579, Accuracy: 9830/10000 (98%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/37519 (0%)]\tLoss: 0.235235\n",
      "Train Epoch: 1 [640/37519 (2%)]\tLoss: 0.109078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1280/37519 (3%)]\tLoss: 0.417915\n",
      "Train Epoch: 1 [1920/37519 (5%)]\tLoss: 0.230500\n",
      "Train Epoch: 1 [2560/37519 (7%)]\tLoss: 0.088015\n",
      "Train Epoch: 1 [3200/37519 (9%)]\tLoss: 0.143398\n",
      "Train Epoch: 1 [3840/37519 (10%)]\tLoss: 0.274476\n",
      "Train Epoch: 1 [4480/37519 (12%)]\tLoss: 0.135828\n",
      "Train Epoch: 1 [5120/37519 (14%)]\tLoss: 0.180583\n",
      "Train Epoch: 1 [5760/37519 (15%)]\tLoss: 0.244108\n",
      "Train Epoch: 1 [6400/37519 (17%)]\tLoss: 0.165536\n",
      "Train Epoch: 1 [7040/37519 (19%)]\tLoss: 0.093092\n",
      "Train Epoch: 1 [7680/37519 (20%)]\tLoss: 0.123051\n",
      "Train Epoch: 1 [8320/37519 (22%)]\tLoss: 0.244277\n",
      "Train Epoch: 1 [8960/37519 (24%)]\tLoss: 0.076348\n",
      "Train Epoch: 1 [9600/37519 (26%)]\tLoss: 0.107322\n",
      "Train Epoch: 1 [10240/37519 (27%)]\tLoss: 0.120053\n",
      "Train Epoch: 1 [10880/37519 (29%)]\tLoss: 0.193073\n",
      "Train Epoch: 1 [11520/37519 (31%)]\tLoss: 0.134682\n",
      "Train Epoch: 1 [12160/37519 (32%)]\tLoss: 0.118665\n",
      "Train Epoch: 1 [12800/37519 (34%)]\tLoss: 0.253588\n",
      "Train Epoch: 1 [13440/37519 (36%)]\tLoss: 0.113956\n",
      "Train Epoch: 1 [14080/37519 (37%)]\tLoss: 0.232377\n",
      "Train Epoch: 1 [14720/37519 (39%)]\tLoss: 0.136377\n",
      "Train Epoch: 1 [15360/37519 (41%)]\tLoss: 0.209619\n",
      "Train Epoch: 1 [16000/37519 (43%)]\tLoss: 0.114234\n",
      "Train Epoch: 1 [16640/37519 (44%)]\tLoss: 0.065948\n",
      "Train Epoch: 1 [17280/37519 (46%)]\tLoss: 0.055566\n",
      "Train Epoch: 1 [17920/37519 (48%)]\tLoss: 0.051138\n",
      "Train Epoch: 1 [18560/37519 (49%)]\tLoss: 0.164279\n",
      "Train Epoch: 1 [19200/37519 (51%)]\tLoss: 0.290376\n",
      "Train Epoch: 1 [19840/37519 (53%)]\tLoss: 0.076315\n",
      "Train Epoch: 1 [20480/37519 (55%)]\tLoss: 0.148473\n",
      "Train Epoch: 1 [21120/37519 (56%)]\tLoss: 0.072916\n",
      "Train Epoch: 1 [21760/37519 (58%)]\tLoss: 0.058220\n",
      "Train Epoch: 1 [22400/37519 (60%)]\tLoss: 0.084448\n",
      "Train Epoch: 1 [23040/37519 (61%)]\tLoss: 0.251536\n",
      "Train Epoch: 1 [23680/37519 (63%)]\tLoss: 0.106161\n",
      "Train Epoch: 1 [24320/37519 (65%)]\tLoss: 0.166027\n",
      "Train Epoch: 1 [24960/37519 (66%)]\tLoss: 0.090572\n",
      "Train Epoch: 1 [25600/37519 (68%)]\tLoss: 0.037567\n",
      "Train Epoch: 1 [26240/37519 (70%)]\tLoss: 0.173576\n",
      "Train Epoch: 1 [26880/37519 (72%)]\tLoss: 0.089590\n",
      "Train Epoch: 1 [27520/37519 (73%)]\tLoss: 0.260098\n",
      "Train Epoch: 1 [28160/37519 (75%)]\tLoss: 0.118169\n",
      "Train Epoch: 1 [28800/37519 (77%)]\tLoss: 0.152055\n",
      "Train Epoch: 1 [29440/37519 (78%)]\tLoss: 0.065266\n",
      "Train Epoch: 1 [30080/37519 (80%)]\tLoss: 0.075861\n",
      "Train Epoch: 1 [30720/37519 (82%)]\tLoss: 0.109445\n",
      "Train Epoch: 1 [31360/37519 (83%)]\tLoss: 0.134838\n",
      "Train Epoch: 1 [32000/37519 (85%)]\tLoss: 0.291880\n",
      "Train Epoch: 1 [32640/37519 (87%)]\tLoss: 0.273029\n",
      "Train Epoch: 1 [33280/37519 (89%)]\tLoss: 0.077736\n",
      "Train Epoch: 1 [33920/37519 (90%)]\tLoss: 0.097815\n",
      "Train Epoch: 1 [34560/37519 (92%)]\tLoss: 0.035050\n",
      "Train Epoch: 1 [35200/37519 (94%)]\tLoss: 0.097977\n",
      "Train Epoch: 1 [35840/37519 (95%)]\tLoss: 0.138681\n",
      "Train Epoch: 1 [36480/37519 (97%)]\tLoss: 0.090441\n",
      "Train Epoch: 1 [37120/37519 (99%)]\tLoss: 0.130247\n",
      "Train Epoch: 2 [0/37519 (0%)]\tLoss: 0.091414\n",
      "Train Epoch: 2 [640/37519 (2%)]\tLoss: 0.061378\n",
      "Train Epoch: 2 [1280/37519 (3%)]\tLoss: 0.223194\n",
      "Train Epoch: 2 [1920/37519 (5%)]\tLoss: 0.120191\n",
      "Train Epoch: 2 [2560/37519 (7%)]\tLoss: 0.170615\n",
      "Train Epoch: 2 [3200/37519 (9%)]\tLoss: 0.143176\n",
      "Train Epoch: 2 [3840/37519 (10%)]\tLoss: 0.155812\n",
      "Train Epoch: 2 [4480/37519 (12%)]\tLoss: 0.130842\n",
      "Train Epoch: 2 [5120/37519 (14%)]\tLoss: 0.093118\n",
      "Train Epoch: 2 [5760/37519 (15%)]\tLoss: 0.289884\n",
      "Train Epoch: 2 [6400/37519 (17%)]\tLoss: 0.121296\n",
      "Train Epoch: 2 [7040/37519 (19%)]\tLoss: 0.161401\n",
      "Train Epoch: 2 [7680/37519 (20%)]\tLoss: 0.055593\n",
      "Train Epoch: 2 [8320/37519 (22%)]\tLoss: 0.027357\n",
      "Train Epoch: 2 [8960/37519 (24%)]\tLoss: 0.120218\n",
      "Train Epoch: 2 [9600/37519 (26%)]\tLoss: 0.025657\n",
      "Train Epoch: 2 [10240/37519 (27%)]\tLoss: 0.038833\n",
      "Train Epoch: 2 [10880/37519 (29%)]\tLoss: 0.106240\n",
      "Train Epoch: 2 [11520/37519 (31%)]\tLoss: 0.078514\n",
      "Train Epoch: 2 [12160/37519 (32%)]\tLoss: 0.084176\n",
      "Train Epoch: 2 [12800/37519 (34%)]\tLoss: 0.063460\n",
      "Train Epoch: 2 [13440/37519 (36%)]\tLoss: 0.012880\n",
      "Train Epoch: 2 [14080/37519 (37%)]\tLoss: 0.070341\n",
      "Train Epoch: 2 [14720/37519 (39%)]\tLoss: 0.152950\n",
      "Train Epoch: 2 [15360/37519 (41%)]\tLoss: 0.153443\n",
      "Train Epoch: 2 [16000/37519 (43%)]\tLoss: 0.097708\n",
      "Train Epoch: 2 [16640/37519 (44%)]\tLoss: 0.071949\n",
      "Train Epoch: 2 [17280/37519 (46%)]\tLoss: 0.045849\n",
      "Train Epoch: 2 [17920/37519 (48%)]\tLoss: 0.188695\n",
      "Train Epoch: 2 [18560/37519 (49%)]\tLoss: 0.096645\n",
      "Train Epoch: 2 [19200/37519 (51%)]\tLoss: 0.150209\n",
      "Train Epoch: 2 [19840/37519 (53%)]\tLoss: 0.117745\n",
      "Train Epoch: 2 [20480/37519 (55%)]\tLoss: 0.095094\n",
      "Train Epoch: 2 [21120/37519 (56%)]\tLoss: 0.133516\n",
      "Train Epoch: 2 [21760/37519 (58%)]\tLoss: 0.058447\n",
      "Train Epoch: 2 [22400/37519 (60%)]\tLoss: 0.100511\n",
      "Train Epoch: 2 [23040/37519 (61%)]\tLoss: 0.050510\n",
      "Train Epoch: 2 [23680/37519 (63%)]\tLoss: 0.042060\n",
      "Train Epoch: 2 [24320/37519 (65%)]\tLoss: 0.169209\n",
      "Train Epoch: 2 [24960/37519 (66%)]\tLoss: 0.047463\n",
      "Train Epoch: 2 [25600/37519 (68%)]\tLoss: 0.095203\n",
      "Train Epoch: 2 [26240/37519 (70%)]\tLoss: 0.136063\n",
      "Train Epoch: 2 [26880/37519 (72%)]\tLoss: 0.073460\n",
      "Train Epoch: 2 [27520/37519 (73%)]\tLoss: 0.412298\n",
      "Train Epoch: 2 [28160/37519 (75%)]\tLoss: 0.049819\n",
      "Train Epoch: 2 [28800/37519 (77%)]\tLoss: 0.036557\n",
      "Train Epoch: 2 [29440/37519 (78%)]\tLoss: 0.338539\n",
      "Train Epoch: 2 [30080/37519 (80%)]\tLoss: 0.075844\n",
      "Train Epoch: 2 [30720/37519 (82%)]\tLoss: 0.116684\n",
      "Train Epoch: 2 [31360/37519 (83%)]\tLoss: 0.087212\n",
      "Train Epoch: 2 [32000/37519 (85%)]\tLoss: 0.116300\n",
      "Train Epoch: 2 [32640/37519 (87%)]\tLoss: 0.069644\n",
      "Train Epoch: 2 [33280/37519 (89%)]\tLoss: 0.079713\n",
      "Train Epoch: 2 [33920/37519 (90%)]\tLoss: 0.241064\n",
      "Train Epoch: 2 [34560/37519 (92%)]\tLoss: 0.036802\n",
      "Train Epoch: 2 [35200/37519 (94%)]\tLoss: 0.115788\n",
      "Train Epoch: 2 [35840/37519 (95%)]\tLoss: 0.065583\n",
      "Train Epoch: 2 [36480/37519 (97%)]\tLoss: 0.096969\n",
      "Train Epoch: 2 [37120/37519 (99%)]\tLoss: 0.194115\n",
      "Train Epoch: 3 [0/37519 (0%)]\tLoss: 0.059557\n",
      "Train Epoch: 3 [640/37519 (2%)]\tLoss: 0.140611\n",
      "Train Epoch: 3 [1280/37519 (3%)]\tLoss: 0.111796\n",
      "Train Epoch: 3 [1920/37519 (5%)]\tLoss: 0.240135\n",
      "Train Epoch: 3 [2560/37519 (7%)]\tLoss: 0.100287\n",
      "Train Epoch: 3 [3200/37519 (9%)]\tLoss: 0.070756\n",
      "Train Epoch: 3 [3840/37519 (10%)]\tLoss: 0.033346\n",
      "Train Epoch: 3 [4480/37519 (12%)]\tLoss: 0.122291\n",
      "Train Epoch: 3 [5120/37519 (14%)]\tLoss: 0.130330\n",
      "Train Epoch: 3 [5760/37519 (15%)]\tLoss: 0.039527\n",
      "Train Epoch: 3 [6400/37519 (17%)]\tLoss: 0.104922\n",
      "Train Epoch: 3 [7040/37519 (19%)]\tLoss: 0.210266\n",
      "Train Epoch: 3 [7680/37519 (20%)]\tLoss: 0.138331\n",
      "Train Epoch: 3 [8320/37519 (22%)]\tLoss: 0.127240\n",
      "Train Epoch: 3 [8960/37519 (24%)]\tLoss: 0.186094\n",
      "Train Epoch: 3 [9600/37519 (26%)]\tLoss: 0.130056\n",
      "Train Epoch: 3 [10240/37519 (27%)]\tLoss: 0.133286\n",
      "Train Epoch: 3 [10880/37519 (29%)]\tLoss: 0.089148\n",
      "Train Epoch: 3 [11520/37519 (31%)]\tLoss: 0.078213\n",
      "Train Epoch: 3 [12160/37519 (32%)]\tLoss: 0.197093\n",
      "Train Epoch: 3 [12800/37519 (34%)]\tLoss: 0.082392\n",
      "Train Epoch: 3 [13440/37519 (36%)]\tLoss: 0.152804\n",
      "Train Epoch: 3 [14080/37519 (37%)]\tLoss: 0.192733\n",
      "Train Epoch: 3 [14720/37519 (39%)]\tLoss: 0.170644\n",
      "Train Epoch: 3 [15360/37519 (41%)]\tLoss: 0.356986\n",
      "Train Epoch: 3 [16000/37519 (43%)]\tLoss: 0.098747\n",
      "Train Epoch: 3 [16640/37519 (44%)]\tLoss: 0.161182\n",
      "Train Epoch: 3 [17280/37519 (46%)]\tLoss: 0.052994\n",
      "Train Epoch: 3 [17920/37519 (48%)]\tLoss: 0.036971\n",
      "Train Epoch: 3 [18560/37519 (49%)]\tLoss: 0.180700\n",
      "Train Epoch: 3 [19200/37519 (51%)]\tLoss: 0.105306\n",
      "Train Epoch: 3 [19840/37519 (53%)]\tLoss: 0.161990\n",
      "Train Epoch: 3 [20480/37519 (55%)]\tLoss: 0.075938\n",
      "Train Epoch: 3 [21120/37519 (56%)]\tLoss: 0.216497\n",
      "Train Epoch: 3 [21760/37519 (58%)]\tLoss: 0.145553\n",
      "Train Epoch: 3 [22400/37519 (60%)]\tLoss: 0.117382\n",
      "Train Epoch: 3 [23040/37519 (61%)]\tLoss: 0.082314\n",
      "Train Epoch: 3 [23680/37519 (63%)]\tLoss: 0.093057\n",
      "Train Epoch: 3 [24320/37519 (65%)]\tLoss: 0.119259\n",
      "Train Epoch: 3 [24960/37519 (66%)]\tLoss: 0.050340\n",
      "Train Epoch: 3 [25600/37519 (68%)]\tLoss: 0.120456\n",
      "Train Epoch: 3 [26240/37519 (70%)]\tLoss: 0.110271\n",
      "Train Epoch: 3 [26880/37519 (72%)]\tLoss: 0.061058\n",
      "Train Epoch: 3 [27520/37519 (73%)]\tLoss: 0.095885\n",
      "Train Epoch: 3 [28160/37519 (75%)]\tLoss: 0.086876\n",
      "Train Epoch: 3 [28800/37519 (77%)]\tLoss: 0.302177\n",
      "Train Epoch: 3 [29440/37519 (78%)]\tLoss: 0.080478\n",
      "Train Epoch: 3 [30080/37519 (80%)]\tLoss: 0.091980\n",
      "Train Epoch: 3 [30720/37519 (82%)]\tLoss: 0.103373\n",
      "Train Epoch: 3 [31360/37519 (83%)]\tLoss: 0.056253\n",
      "Train Epoch: 3 [32000/37519 (85%)]\tLoss: 0.185544\n",
      "Train Epoch: 3 [32640/37519 (87%)]\tLoss: 0.110426\n",
      "Train Epoch: 3 [33280/37519 (89%)]\tLoss: 0.088716\n",
      "Train Epoch: 3 [33920/37519 (90%)]\tLoss: 0.116197\n",
      "Train Epoch: 3 [34560/37519 (92%)]\tLoss: 0.078500\n",
      "Train Epoch: 3 [35200/37519 (94%)]\tLoss: 0.198785\n",
      "Train Epoch: 3 [35840/37519 (95%)]\tLoss: 0.038183\n",
      "Train Epoch: 3 [36480/37519 (97%)]\tLoss: 0.188834\n",
      "Train Epoch: 3 [37120/37519 (99%)]\tLoss: 0.219996\n",
      "Train Epoch: 4 [0/37519 (0%)]\tLoss: 0.262284\n",
      "Train Epoch: 4 [640/37519 (2%)]\tLoss: 0.168869\n",
      "Train Epoch: 4 [1280/37519 (3%)]\tLoss: 0.080392\n",
      "Train Epoch: 4 [1920/37519 (5%)]\tLoss: 0.156052\n",
      "Train Epoch: 4 [2560/37519 (7%)]\tLoss: 0.151859\n",
      "Train Epoch: 4 [3200/37519 (9%)]\tLoss: 0.114046\n",
      "Train Epoch: 4 [3840/37519 (10%)]\tLoss: 0.065855\n",
      "Train Epoch: 4 [4480/37519 (12%)]\tLoss: 0.135519\n",
      "Train Epoch: 4 [5120/37519 (14%)]\tLoss: 0.083124\n",
      "Train Epoch: 4 [5760/37519 (15%)]\tLoss: 0.068621\n",
      "Train Epoch: 4 [6400/37519 (17%)]\tLoss: 0.153448\n",
      "Train Epoch: 4 [7040/37519 (19%)]\tLoss: 0.083033\n",
      "Train Epoch: 4 [7680/37519 (20%)]\tLoss: 0.074224\n",
      "Train Epoch: 4 [8320/37519 (22%)]\tLoss: 0.111629\n",
      "Train Epoch: 4 [8960/37519 (24%)]\tLoss: 0.056852\n",
      "Train Epoch: 4 [9600/37519 (26%)]\tLoss: 0.111499\n",
      "Train Epoch: 4 [10240/37519 (27%)]\tLoss: 0.122886\n",
      "Train Epoch: 4 [10880/37519 (29%)]\tLoss: 0.092447\n",
      "Train Epoch: 4 [11520/37519 (31%)]\tLoss: 0.043928\n",
      "Train Epoch: 4 [12160/37519 (32%)]\tLoss: 0.072988\n",
      "Train Epoch: 4 [12800/37519 (34%)]\tLoss: 0.076414\n",
      "Train Epoch: 4 [13440/37519 (36%)]\tLoss: 0.071818\n",
      "Train Epoch: 4 [14080/37519 (37%)]\tLoss: 0.097394\n",
      "Train Epoch: 4 [14720/37519 (39%)]\tLoss: 0.136989\n",
      "Train Epoch: 4 [15360/37519 (41%)]\tLoss: 0.176819\n",
      "Train Epoch: 4 [16000/37519 (43%)]\tLoss: 0.185729\n",
      "Train Epoch: 4 [16640/37519 (44%)]\tLoss: 0.081890\n",
      "Train Epoch: 4 [17280/37519 (46%)]\tLoss: 0.152130\n",
      "Train Epoch: 4 [17920/37519 (48%)]\tLoss: 0.077289\n",
      "Train Epoch: 4 [18560/37519 (49%)]\tLoss: 0.174278\n",
      "Train Epoch: 4 [19200/37519 (51%)]\tLoss: 0.169035\n",
      "Train Epoch: 4 [19840/37519 (53%)]\tLoss: 0.089886\n",
      "Train Epoch: 4 [20480/37519 (55%)]\tLoss: 0.054604\n",
      "Train Epoch: 4 [21120/37519 (56%)]\tLoss: 0.043716\n",
      "Train Epoch: 4 [21760/37519 (58%)]\tLoss: 0.096017\n",
      "Train Epoch: 4 [22400/37519 (60%)]\tLoss: 0.058102\n",
      "Train Epoch: 4 [23040/37519 (61%)]\tLoss: 0.111788\n",
      "Train Epoch: 4 [23680/37519 (63%)]\tLoss: 0.072579\n",
      "Train Epoch: 4 [24320/37519 (65%)]\tLoss: 0.045675\n",
      "Train Epoch: 4 [24960/37519 (66%)]\tLoss: 0.052707\n",
      "Train Epoch: 4 [25600/37519 (68%)]\tLoss: 0.068272\n",
      "Train Epoch: 4 [26240/37519 (70%)]\tLoss: 0.169309\n",
      "Train Epoch: 4 [26880/37519 (72%)]\tLoss: 0.041602\n",
      "Train Epoch: 4 [27520/37519 (73%)]\tLoss: 0.203145\n",
      "Train Epoch: 4 [28160/37519 (75%)]\tLoss: 0.133726\n",
      "Train Epoch: 4 [28800/37519 (77%)]\tLoss: 0.123112\n",
      "Train Epoch: 4 [29440/37519 (78%)]\tLoss: 0.295807\n",
      "Train Epoch: 4 [30080/37519 (80%)]\tLoss: 0.087438\n",
      "Train Epoch: 4 [30720/37519 (82%)]\tLoss: 0.087897\n",
      "Train Epoch: 4 [31360/37519 (83%)]\tLoss: 0.072054\n",
      "Train Epoch: 4 [32000/37519 (85%)]\tLoss: 0.028165\n",
      "Train Epoch: 4 [32640/37519 (87%)]\tLoss: 0.206413\n",
      "Train Epoch: 4 [33280/37519 (89%)]\tLoss: 0.057730\n",
      "Train Epoch: 4 [33920/37519 (90%)]\tLoss: 0.131201\n",
      "Train Epoch: 4 [34560/37519 (92%)]\tLoss: 0.125194\n",
      "Train Epoch: 4 [35200/37519 (94%)]\tLoss: 0.047566\n",
      "Train Epoch: 4 [35840/37519 (95%)]\tLoss: 0.147639\n",
      "Train Epoch: 4 [36480/37519 (97%)]\tLoss: 0.084751\n",
      "Train Epoch: 4 [37120/37519 (99%)]\tLoss: 0.148987\n",
      "Train Epoch: 5 [0/37519 (0%)]\tLoss: 0.120158\n",
      "Train Epoch: 5 [640/37519 (2%)]\tLoss: 0.065814\n",
      "Train Epoch: 5 [1280/37519 (3%)]\tLoss: 0.110312\n",
      "Train Epoch: 5 [1920/37519 (5%)]\tLoss: 0.135383\n",
      "Train Epoch: 5 [2560/37519 (7%)]\tLoss: 0.046385\n",
      "Train Epoch: 5 [3200/37519 (9%)]\tLoss: 0.088136\n",
      "Train Epoch: 5 [3840/37519 (10%)]\tLoss: 0.236722\n",
      "Train Epoch: 5 [4480/37519 (12%)]\tLoss: 0.117296\n",
      "Train Epoch: 5 [5120/37519 (14%)]\tLoss: 0.276093\n",
      "Train Epoch: 5 [5760/37519 (15%)]\tLoss: 0.227834\n",
      "Train Epoch: 5 [6400/37519 (17%)]\tLoss: 0.102589\n",
      "Train Epoch: 5 [7040/37519 (19%)]\tLoss: 0.144449\n",
      "Train Epoch: 5 [7680/37519 (20%)]\tLoss: 0.043969\n",
      "Train Epoch: 5 [8320/37519 (22%)]\tLoss: 0.034896\n",
      "Train Epoch: 5 [8960/37519 (24%)]\tLoss: 0.051008\n",
      "Train Epoch: 5 [9600/37519 (26%)]\tLoss: 0.038479\n",
      "Train Epoch: 5 [10240/37519 (27%)]\tLoss: 0.064875\n",
      "Train Epoch: 5 [10880/37519 (29%)]\tLoss: 0.094459\n",
      "Train Epoch: 5 [11520/37519 (31%)]\tLoss: 0.070705\n",
      "Train Epoch: 5 [12160/37519 (32%)]\tLoss: 0.159755\n",
      "Train Epoch: 5 [12800/37519 (34%)]\tLoss: 0.111142\n",
      "Train Epoch: 5 [13440/37519 (36%)]\tLoss: 0.098085\n",
      "Train Epoch: 5 [14080/37519 (37%)]\tLoss: 0.096450\n",
      "Train Epoch: 5 [14720/37519 (39%)]\tLoss: 0.135773\n",
      "Train Epoch: 5 [15360/37519 (41%)]\tLoss: 0.052662\n",
      "Train Epoch: 5 [16000/37519 (43%)]\tLoss: 0.107014\n",
      "Train Epoch: 5 [16640/37519 (44%)]\tLoss: 0.285673\n",
      "Train Epoch: 5 [17280/37519 (46%)]\tLoss: 0.131013\n",
      "Train Epoch: 5 [17920/37519 (48%)]\tLoss: 0.383066\n",
      "Train Epoch: 5 [18560/37519 (49%)]\tLoss: 0.224593\n",
      "Train Epoch: 5 [19200/37519 (51%)]\tLoss: 0.136207\n",
      "Train Epoch: 5 [19840/37519 (53%)]\tLoss: 0.055169\n",
      "Train Epoch: 5 [20480/37519 (55%)]\tLoss: 0.136356\n",
      "Train Epoch: 5 [21120/37519 (56%)]\tLoss: 0.240907\n",
      "Train Epoch: 5 [21760/37519 (58%)]\tLoss: 0.076852\n",
      "Train Epoch: 5 [22400/37519 (60%)]\tLoss: 0.120094\n",
      "Train Epoch: 5 [23040/37519 (61%)]\tLoss: 0.136946\n",
      "Train Epoch: 5 [23680/37519 (63%)]\tLoss: 0.136681\n",
      "Train Epoch: 5 [24320/37519 (65%)]\tLoss: 0.209997\n",
      "Train Epoch: 5 [24960/37519 (66%)]\tLoss: 0.057930\n",
      "Train Epoch: 5 [25600/37519 (68%)]\tLoss: 0.031338\n",
      "Train Epoch: 5 [26240/37519 (70%)]\tLoss: 0.161982\n",
      "Train Epoch: 5 [26880/37519 (72%)]\tLoss: 0.081042\n",
      "Train Epoch: 5 [27520/37519 (73%)]\tLoss: 0.078124\n",
      "Train Epoch: 5 [28160/37519 (75%)]\tLoss: 0.073190\n",
      "Train Epoch: 5 [28800/37519 (77%)]\tLoss: 0.040503\n",
      "Train Epoch: 5 [29440/37519 (78%)]\tLoss: 0.031902\n",
      "Train Epoch: 5 [30080/37519 (80%)]\tLoss: 0.039009\n",
      "Train Epoch: 5 [30720/37519 (82%)]\tLoss: 0.055002\n",
      "Train Epoch: 5 [31360/37519 (83%)]\tLoss: 0.048409\n",
      "Train Epoch: 5 [32000/37519 (85%)]\tLoss: 0.065453\n",
      "Train Epoch: 5 [32640/37519 (87%)]\tLoss: 0.312786\n",
      "Train Epoch: 5 [33280/37519 (89%)]\tLoss: 0.201264\n",
      "Train Epoch: 5 [33920/37519 (90%)]\tLoss: 0.072841\n",
      "Train Epoch: 5 [34560/37519 (92%)]\tLoss: 0.178539\n",
      "Train Epoch: 5 [35200/37519 (94%)]\tLoss: 0.214449\n",
      "Train Epoch: 5 [35840/37519 (95%)]\tLoss: 0.112265\n",
      "Train Epoch: 5 [36480/37519 (97%)]\tLoss: 0.096201\n",
      "Train Epoch: 5 [37120/37519 (99%)]\tLoss: 0.142091\n",
      "Train Epoch: 6 [0/37519 (0%)]\tLoss: 0.251240\n",
      "Train Epoch: 6 [640/37519 (2%)]\tLoss: 0.120994\n",
      "Train Epoch: 6 [1280/37519 (3%)]\tLoss: 0.143812\n",
      "Train Epoch: 6 [1920/37519 (5%)]\tLoss: 0.147422\n",
      "Train Epoch: 6 [2560/37519 (7%)]\tLoss: 0.131867\n",
      "Train Epoch: 6 [3200/37519 (9%)]\tLoss: 0.094459\n",
      "Train Epoch: 6 [3840/37519 (10%)]\tLoss: 0.104495\n",
      "Train Epoch: 6 [4480/37519 (12%)]\tLoss: 0.133675\n",
      "Train Epoch: 6 [5120/37519 (14%)]\tLoss: 0.054865\n",
      "Train Epoch: 6 [5760/37519 (15%)]\tLoss: 0.099705\n",
      "Train Epoch: 6 [6400/37519 (17%)]\tLoss: 0.053109\n",
      "Train Epoch: 6 [7040/37519 (19%)]\tLoss: 0.199855\n",
      "Train Epoch: 6 [7680/37519 (20%)]\tLoss: 0.071081\n",
      "Train Epoch: 6 [8320/37519 (22%)]\tLoss: 0.073166\n",
      "Train Epoch: 6 [8960/37519 (24%)]\tLoss: 0.085545\n",
      "Train Epoch: 6 [9600/37519 (26%)]\tLoss: 0.082449\n",
      "Train Epoch: 6 [10240/37519 (27%)]\tLoss: 0.286725\n",
      "Train Epoch: 6 [10880/37519 (29%)]\tLoss: 0.147144\n",
      "Train Epoch: 6 [11520/37519 (31%)]\tLoss: 0.150154\n",
      "Train Epoch: 6 [12160/37519 (32%)]\tLoss: 0.139962\n",
      "Train Epoch: 6 [12800/37519 (34%)]\tLoss: 0.069175\n",
      "Train Epoch: 6 [13440/37519 (36%)]\tLoss: 0.136745\n",
      "Train Epoch: 6 [14080/37519 (37%)]\tLoss: 0.081556\n",
      "Train Epoch: 6 [14720/37519 (39%)]\tLoss: 0.127088\n",
      "Train Epoch: 6 [15360/37519 (41%)]\tLoss: 0.089732\n",
      "Train Epoch: 6 [16000/37519 (43%)]\tLoss: 0.208562\n",
      "Train Epoch: 6 [16640/37519 (44%)]\tLoss: 0.096628\n",
      "Train Epoch: 6 [17280/37519 (46%)]\tLoss: 0.069369\n",
      "Train Epoch: 6 [17920/37519 (48%)]\tLoss: 0.142840\n",
      "Train Epoch: 6 [18560/37519 (49%)]\tLoss: 0.073336\n",
      "Train Epoch: 6 [19200/37519 (51%)]\tLoss: 0.059862\n",
      "Train Epoch: 6 [19840/37519 (53%)]\tLoss: 0.107309\n",
      "Train Epoch: 6 [20480/37519 (55%)]\tLoss: 0.049037\n",
      "Train Epoch: 6 [21120/37519 (56%)]\tLoss: 0.278605\n",
      "Train Epoch: 6 [21760/37519 (58%)]\tLoss: 0.076680\n",
      "Train Epoch: 6 [22400/37519 (60%)]\tLoss: 0.100565\n",
      "Train Epoch: 6 [23040/37519 (61%)]\tLoss: 0.079175\n",
      "Train Epoch: 6 [23680/37519 (63%)]\tLoss: 0.287131\n",
      "Train Epoch: 6 [24320/37519 (65%)]\tLoss: 0.089049\n",
      "Train Epoch: 6 [24960/37519 (66%)]\tLoss: 0.105404\n",
      "Train Epoch: 6 [25600/37519 (68%)]\tLoss: 0.066104\n",
      "Train Epoch: 6 [26240/37519 (70%)]\tLoss: 0.184738\n",
      "Train Epoch: 6 [26880/37519 (72%)]\tLoss: 0.034309\n",
      "Train Epoch: 6 [27520/37519 (73%)]\tLoss: 0.046247\n",
      "Train Epoch: 6 [28160/37519 (75%)]\tLoss: 0.059822\n",
      "Train Epoch: 6 [28800/37519 (77%)]\tLoss: 0.129105\n",
      "Train Epoch: 6 [29440/37519 (78%)]\tLoss: 0.112577\n",
      "Train Epoch: 6 [30080/37519 (80%)]\tLoss: 0.111108\n",
      "Train Epoch: 6 [30720/37519 (82%)]\tLoss: 0.200334\n",
      "Train Epoch: 6 [31360/37519 (83%)]\tLoss: 0.136876\n",
      "Train Epoch: 6 [32000/37519 (85%)]\tLoss: 0.084672\n",
      "Train Epoch: 6 [32640/37519 (87%)]\tLoss: 0.097297\n",
      "Train Epoch: 6 [33280/37519 (89%)]\tLoss: 0.057829\n",
      "Train Epoch: 6 [33920/37519 (90%)]\tLoss: 0.065510\n",
      "Train Epoch: 6 [34560/37519 (92%)]\tLoss: 0.089893\n",
      "Train Epoch: 6 [35200/37519 (94%)]\tLoss: 0.107344\n",
      "Train Epoch: 6 [35840/37519 (95%)]\tLoss: 0.052333\n",
      "Train Epoch: 6 [36480/37519 (97%)]\tLoss: 0.033639\n",
      "Train Epoch: 6 [37120/37519 (99%)]\tLoss: 0.203394\n",
      "Train Epoch: 7 [0/37519 (0%)]\tLoss: 0.139083\n",
      "Train Epoch: 7 [640/37519 (2%)]\tLoss: 0.128845\n",
      "Train Epoch: 7 [1280/37519 (3%)]\tLoss: 0.096221\n",
      "Train Epoch: 7 [1920/37519 (5%)]\tLoss: 0.060123\n",
      "Train Epoch: 7 [2560/37519 (7%)]\tLoss: 0.126691\n",
      "Train Epoch: 7 [3200/37519 (9%)]\tLoss: 0.119332\n",
      "Train Epoch: 7 [3840/37519 (10%)]\tLoss: 0.145819\n",
      "Train Epoch: 7 [4480/37519 (12%)]\tLoss: 0.023747\n",
      "Train Epoch: 7 [5120/37519 (14%)]\tLoss: 0.032916\n",
      "Train Epoch: 7 [5760/37519 (15%)]\tLoss: 0.211304\n",
      "Train Epoch: 7 [6400/37519 (17%)]\tLoss: 0.067662\n",
      "Train Epoch: 7 [7040/37519 (19%)]\tLoss: 0.132560\n",
      "Train Epoch: 7 [7680/37519 (20%)]\tLoss: 0.025974\n",
      "Train Epoch: 7 [8320/37519 (22%)]\tLoss: 0.165633\n",
      "Train Epoch: 7 [8960/37519 (24%)]\tLoss: 0.081707\n",
      "Train Epoch: 7 [9600/37519 (26%)]\tLoss: 0.039285\n",
      "Train Epoch: 7 [10240/37519 (27%)]\tLoss: 0.062655\n",
      "Train Epoch: 7 [10880/37519 (29%)]\tLoss: 0.134697\n",
      "Train Epoch: 7 [11520/37519 (31%)]\tLoss: 0.020121\n",
      "Train Epoch: 7 [12160/37519 (32%)]\tLoss: 0.087195\n",
      "Train Epoch: 7 [12800/37519 (34%)]\tLoss: 0.279830\n",
      "Train Epoch: 7 [13440/37519 (36%)]\tLoss: 0.148512\n",
      "Train Epoch: 7 [14080/37519 (37%)]\tLoss: 0.022088\n",
      "Train Epoch: 7 [14720/37519 (39%)]\tLoss: 0.113093\n",
      "Train Epoch: 7 [15360/37519 (41%)]\tLoss: 0.075098\n",
      "Train Epoch: 7 [16000/37519 (43%)]\tLoss: 0.062643\n",
      "Train Epoch: 7 [16640/37519 (44%)]\tLoss: 0.191866\n",
      "Train Epoch: 7 [17280/37519 (46%)]\tLoss: 0.197300\n",
      "Train Epoch: 7 [17920/37519 (48%)]\tLoss: 0.089972\n",
      "Train Epoch: 7 [18560/37519 (49%)]\tLoss: 0.128132\n",
      "Train Epoch: 7 [19200/37519 (51%)]\tLoss: 0.128358\n",
      "Train Epoch: 7 [19840/37519 (53%)]\tLoss: 0.135737\n",
      "Train Epoch: 7 [20480/37519 (55%)]\tLoss: 0.118170\n",
      "Train Epoch: 7 [21120/37519 (56%)]\tLoss: 0.176706\n",
      "Train Epoch: 7 [21760/37519 (58%)]\tLoss: 0.024566\n",
      "Train Epoch: 7 [22400/37519 (60%)]\tLoss: 0.090629\n",
      "Train Epoch: 7 [23040/37519 (61%)]\tLoss: 0.117382\n",
      "Train Epoch: 7 [23680/37519 (63%)]\tLoss: 0.063096\n",
      "Train Epoch: 7 [24320/37519 (65%)]\tLoss: 0.152948\n",
      "Train Epoch: 7 [24960/37519 (66%)]\tLoss: 0.131564\n",
      "Train Epoch: 7 [25600/37519 (68%)]\tLoss: 0.048697\n",
      "Train Epoch: 7 [26240/37519 (70%)]\tLoss: 0.196885\n",
      "Train Epoch: 7 [26880/37519 (72%)]\tLoss: 0.287886\n",
      "Train Epoch: 7 [27520/37519 (73%)]\tLoss: 0.130273\n",
      "Train Epoch: 7 [28160/37519 (75%)]\tLoss: 0.051274\n",
      "Train Epoch: 7 [28800/37519 (77%)]\tLoss: 0.091594\n",
      "Train Epoch: 7 [29440/37519 (78%)]\tLoss: 0.066500\n",
      "Train Epoch: 7 [30080/37519 (80%)]\tLoss: 0.074044\n",
      "Train Epoch: 7 [30720/37519 (82%)]\tLoss: 0.241455\n",
      "Train Epoch: 7 [31360/37519 (83%)]\tLoss: 0.080808\n",
      "Train Epoch: 7 [32000/37519 (85%)]\tLoss: 0.138233\n",
      "Train Epoch: 7 [32640/37519 (87%)]\tLoss: 0.268200\n",
      "Train Epoch: 7 [33280/37519 (89%)]\tLoss: 0.039999\n",
      "Train Epoch: 7 [33920/37519 (90%)]\tLoss: 0.123417\n",
      "Train Epoch: 7 [34560/37519 (92%)]\tLoss: 0.074416\n",
      "Train Epoch: 7 [35200/37519 (94%)]\tLoss: 0.061326\n",
      "Train Epoch: 7 [35840/37519 (95%)]\tLoss: 0.058247\n",
      "Train Epoch: 7 [36480/37519 (97%)]\tLoss: 0.166263\n",
      "Train Epoch: 7 [37120/37519 (99%)]\tLoss: 0.105534\n",
      "Train Epoch: 8 [0/37519 (0%)]\tLoss: 0.258377\n",
      "Train Epoch: 8 [640/37519 (2%)]\tLoss: 0.135094\n",
      "Train Epoch: 8 [1280/37519 (3%)]\tLoss: 0.154402\n",
      "Train Epoch: 8 [1920/37519 (5%)]\tLoss: 0.029966\n",
      "Train Epoch: 8 [2560/37519 (7%)]\tLoss: 0.007824\n",
      "Train Epoch: 8 [3200/37519 (9%)]\tLoss: 0.072529\n",
      "Train Epoch: 8 [3840/37519 (10%)]\tLoss: 0.097572\n",
      "Train Epoch: 8 [4480/37519 (12%)]\tLoss: 0.076573\n",
      "Train Epoch: 8 [5120/37519 (14%)]\tLoss: 0.044616\n",
      "Train Epoch: 8 [5760/37519 (15%)]\tLoss: 0.169101\n",
      "Train Epoch: 8 [6400/37519 (17%)]\tLoss: 0.064175\n",
      "Train Epoch: 8 [7040/37519 (19%)]\tLoss: 0.075143\n",
      "Train Epoch: 8 [7680/37519 (20%)]\tLoss: 0.094928\n",
      "Train Epoch: 8 [8320/37519 (22%)]\tLoss: 0.072902\n",
      "Train Epoch: 8 [8960/37519 (24%)]\tLoss: 0.104510\n",
      "Train Epoch: 8 [9600/37519 (26%)]\tLoss: 0.091261\n",
      "Train Epoch: 8 [10240/37519 (27%)]\tLoss: 0.063345\n",
      "Train Epoch: 8 [10880/37519 (29%)]\tLoss: 0.079314\n",
      "Train Epoch: 8 [11520/37519 (31%)]\tLoss: 0.076071\n",
      "Train Epoch: 8 [12160/37519 (32%)]\tLoss: 0.119001\n",
      "Train Epoch: 8 [12800/37519 (34%)]\tLoss: 0.148840\n",
      "Train Epoch: 8 [13440/37519 (36%)]\tLoss: 0.054445\n",
      "Train Epoch: 8 [14080/37519 (37%)]\tLoss: 0.035191\n",
      "Train Epoch: 8 [14720/37519 (39%)]\tLoss: 0.127463\n",
      "Train Epoch: 8 [15360/37519 (41%)]\tLoss: 0.190942\n",
      "Train Epoch: 8 [16000/37519 (43%)]\tLoss: 0.197897\n",
      "Train Epoch: 8 [16640/37519 (44%)]\tLoss: 0.093343\n",
      "Train Epoch: 8 [17280/37519 (46%)]\tLoss: 0.059923\n",
      "Train Epoch: 8 [17920/37519 (48%)]\tLoss: 0.042954\n",
      "Train Epoch: 8 [18560/37519 (49%)]\tLoss: 0.106253\n",
      "Train Epoch: 8 [19200/37519 (51%)]\tLoss: 0.222738\n",
      "Train Epoch: 8 [19840/37519 (53%)]\tLoss: 0.043481\n",
      "Train Epoch: 8 [20480/37519 (55%)]\tLoss: 0.056427\n",
      "Train Epoch: 8 [21120/37519 (56%)]\tLoss: 0.108101\n",
      "Train Epoch: 8 [21760/37519 (58%)]\tLoss: 0.228010\n",
      "Train Epoch: 8 [22400/37519 (60%)]\tLoss: 0.159059\n",
      "Train Epoch: 8 [23040/37519 (61%)]\tLoss: 0.101934\n",
      "Train Epoch: 8 [23680/37519 (63%)]\tLoss: 0.189176\n",
      "Train Epoch: 8 [24320/37519 (65%)]\tLoss: 0.035577\n",
      "Train Epoch: 8 [24960/37519 (66%)]\tLoss: 0.094806\n",
      "Train Epoch: 8 [25600/37519 (68%)]\tLoss: 0.164422\n",
      "Train Epoch: 8 [26240/37519 (70%)]\tLoss: 0.138056\n",
      "Train Epoch: 8 [26880/37519 (72%)]\tLoss: 0.068953\n",
      "Train Epoch: 8 [27520/37519 (73%)]\tLoss: 0.023005\n",
      "Train Epoch: 8 [28160/37519 (75%)]\tLoss: 0.100053\n",
      "Train Epoch: 8 [28800/37519 (77%)]\tLoss: 0.053159\n",
      "Train Epoch: 8 [29440/37519 (78%)]\tLoss: 0.053624\n",
      "Train Epoch: 8 [30080/37519 (80%)]\tLoss: 0.219316\n",
      "Train Epoch: 8 [30720/37519 (82%)]\tLoss: 0.138430\n",
      "Train Epoch: 8 [31360/37519 (83%)]\tLoss: 0.085066\n",
      "Train Epoch: 8 [32000/37519 (85%)]\tLoss: 0.046097\n",
      "Train Epoch: 8 [32640/37519 (87%)]\tLoss: 0.033114\n",
      "Train Epoch: 8 [33280/37519 (89%)]\tLoss: 0.133931\n",
      "Train Epoch: 8 [33920/37519 (90%)]\tLoss: 0.033899\n",
      "Train Epoch: 8 [34560/37519 (92%)]\tLoss: 0.052664\n",
      "Train Epoch: 8 [35200/37519 (94%)]\tLoss: 0.190805\n",
      "Train Epoch: 8 [35840/37519 (95%)]\tLoss: 0.108488\n",
      "Train Epoch: 8 [36480/37519 (97%)]\tLoss: 0.080537\n",
      "Train Epoch: 8 [37120/37519 (99%)]\tLoss: 0.057339\n",
      "Train Epoch: 9 [0/37519 (0%)]\tLoss: 0.043443\n",
      "Train Epoch: 9 [640/37519 (2%)]\tLoss: 0.101847\n",
      "Train Epoch: 9 [1280/37519 (3%)]\tLoss: 0.067284\n",
      "Train Epoch: 9 [1920/37519 (5%)]\tLoss: 0.064005\n",
      "Train Epoch: 9 [2560/37519 (7%)]\tLoss: 0.117716\n",
      "Train Epoch: 9 [3200/37519 (9%)]\tLoss: 0.019076\n",
      "Train Epoch: 9 [3840/37519 (10%)]\tLoss: 0.086443\n",
      "Train Epoch: 9 [4480/37519 (12%)]\tLoss: 0.037050\n",
      "Train Epoch: 9 [5120/37519 (14%)]\tLoss: 0.134936\n",
      "Train Epoch: 9 [5760/37519 (15%)]\tLoss: 0.093582\n",
      "Train Epoch: 9 [6400/37519 (17%)]\tLoss: 0.068723\n",
      "Train Epoch: 9 [7040/37519 (19%)]\tLoss: 0.195499\n",
      "Train Epoch: 9 [7680/37519 (20%)]\tLoss: 0.138471\n",
      "Train Epoch: 9 [8320/37519 (22%)]\tLoss: 0.201349\n",
      "Train Epoch: 9 [8960/37519 (24%)]\tLoss: 0.159020\n",
      "Train Epoch: 9 [9600/37519 (26%)]\tLoss: 0.023063\n",
      "Train Epoch: 9 [10240/37519 (27%)]\tLoss: 0.108127\n",
      "Train Epoch: 9 [10880/37519 (29%)]\tLoss: 0.058261\n",
      "Train Epoch: 9 [11520/37519 (31%)]\tLoss: 0.117044\n",
      "Train Epoch: 9 [12160/37519 (32%)]\tLoss: 0.060255\n",
      "Train Epoch: 9 [12800/37519 (34%)]\tLoss: 0.013312\n",
      "Train Epoch: 9 [13440/37519 (36%)]\tLoss: 0.219432\n",
      "Train Epoch: 9 [14080/37519 (37%)]\tLoss: 0.087514\n",
      "Train Epoch: 9 [14720/37519 (39%)]\tLoss: 0.076109\n",
      "Train Epoch: 9 [15360/37519 (41%)]\tLoss: 0.037790\n",
      "Train Epoch: 9 [16000/37519 (43%)]\tLoss: 0.085175\n",
      "Train Epoch: 9 [16640/37519 (44%)]\tLoss: 0.138171\n",
      "Train Epoch: 9 [17280/37519 (46%)]\tLoss: 0.105612\n",
      "Train Epoch: 9 [17920/37519 (48%)]\tLoss: 0.030598\n",
      "Train Epoch: 9 [18560/37519 (49%)]\tLoss: 0.043549\n",
      "Train Epoch: 9 [19200/37519 (51%)]\tLoss: 0.110053\n",
      "Train Epoch: 9 [19840/37519 (53%)]\tLoss: 0.109348\n",
      "Train Epoch: 9 [20480/37519 (55%)]\tLoss: 0.042010\n",
      "Train Epoch: 9 [21120/37519 (56%)]\tLoss: 0.072796\n",
      "Train Epoch: 9 [21760/37519 (58%)]\tLoss: 0.024725\n",
      "Train Epoch: 9 [22400/37519 (60%)]\tLoss: 0.216621\n",
      "Train Epoch: 9 [23040/37519 (61%)]\tLoss: 0.145897\n",
      "Train Epoch: 9 [23680/37519 (63%)]\tLoss: 0.083547\n",
      "Train Epoch: 9 [24320/37519 (65%)]\tLoss: 0.076606\n",
      "Train Epoch: 9 [24960/37519 (66%)]\tLoss: 0.066190\n",
      "Train Epoch: 9 [25600/37519 (68%)]\tLoss: 0.075354\n",
      "Train Epoch: 9 [26240/37519 (70%)]\tLoss: 0.091492\n",
      "Train Epoch: 9 [26880/37519 (72%)]\tLoss: 0.090884\n",
      "Train Epoch: 9 [27520/37519 (73%)]\tLoss: 0.059063\n",
      "Train Epoch: 9 [28160/37519 (75%)]\tLoss: 0.033516\n",
      "Train Epoch: 9 [28800/37519 (77%)]\tLoss: 0.118229\n",
      "Train Epoch: 9 [29440/37519 (78%)]\tLoss: 0.079269\n",
      "Train Epoch: 9 [30080/37519 (80%)]\tLoss: 0.154493\n",
      "Train Epoch: 9 [30720/37519 (82%)]\tLoss: 0.063444\n",
      "Train Epoch: 9 [31360/37519 (83%)]\tLoss: 0.217465\n",
      "Train Epoch: 9 [32000/37519 (85%)]\tLoss: 0.152786\n",
      "Train Epoch: 9 [32640/37519 (87%)]\tLoss: 0.051946\n",
      "Train Epoch: 9 [33280/37519 (89%)]\tLoss: 0.181135\n",
      "Train Epoch: 9 [33920/37519 (90%)]\tLoss: 0.085486\n",
      "Train Epoch: 9 [34560/37519 (92%)]\tLoss: 0.062502\n",
      "Train Epoch: 9 [35200/37519 (94%)]\tLoss: 0.219634\n",
      "Train Epoch: 9 [35840/37519 (95%)]\tLoss: 0.095041\n",
      "Train Epoch: 9 [36480/37519 (97%)]\tLoss: 0.150947\n",
      "Train Epoch: 9 [37120/37519 (99%)]\tLoss: 0.021903\n",
      "Train Epoch: 10 [0/37519 (0%)]\tLoss: 0.093707\n",
      "Train Epoch: 10 [640/37519 (2%)]\tLoss: 0.011499\n",
      "Train Epoch: 10 [1280/37519 (3%)]\tLoss: 0.587064\n",
      "Train Epoch: 10 [1920/37519 (5%)]\tLoss: 0.157846\n",
      "Train Epoch: 10 [2560/37519 (7%)]\tLoss: 0.073925\n",
      "Train Epoch: 10 [3200/37519 (9%)]\tLoss: 0.195884\n",
      "Train Epoch: 10 [3840/37519 (10%)]\tLoss: 0.018361\n",
      "Train Epoch: 10 [4480/37519 (12%)]\tLoss: 0.194542\n",
      "Train Epoch: 10 [5120/37519 (14%)]\tLoss: 0.108533\n",
      "Train Epoch: 10 [5760/37519 (15%)]\tLoss: 0.110615\n",
      "Train Epoch: 10 [6400/37519 (17%)]\tLoss: 0.179653\n",
      "Train Epoch: 10 [7040/37519 (19%)]\tLoss: 0.039459\n",
      "Train Epoch: 10 [7680/37519 (20%)]\tLoss: 0.094267\n",
      "Train Epoch: 10 [8320/37519 (22%)]\tLoss: 0.022254\n",
      "Train Epoch: 10 [8960/37519 (24%)]\tLoss: 0.153494\n",
      "Train Epoch: 10 [9600/37519 (26%)]\tLoss: 0.082670\n",
      "Train Epoch: 10 [10240/37519 (27%)]\tLoss: 0.141804\n",
      "Train Epoch: 10 [10880/37519 (29%)]\tLoss: 0.133659\n",
      "Train Epoch: 10 [11520/37519 (31%)]\tLoss: 0.143844\n",
      "Train Epoch: 10 [12160/37519 (32%)]\tLoss: 0.421931\n",
      "Train Epoch: 10 [12800/37519 (34%)]\tLoss: 0.054388\n",
      "Train Epoch: 10 [13440/37519 (36%)]\tLoss: 0.062150\n",
      "Train Epoch: 10 [14080/37519 (37%)]\tLoss: 0.090424\n",
      "Train Epoch: 10 [14720/37519 (39%)]\tLoss: 0.112126\n",
      "Train Epoch: 10 [15360/37519 (41%)]\tLoss: 0.046465\n",
      "Train Epoch: 10 [16000/37519 (43%)]\tLoss: 0.064245\n",
      "Train Epoch: 10 [16640/37519 (44%)]\tLoss: 0.013925\n",
      "Train Epoch: 10 [17280/37519 (46%)]\tLoss: 0.085221\n",
      "Train Epoch: 10 [17920/37519 (48%)]\tLoss: 0.083197\n",
      "Train Epoch: 10 [18560/37519 (49%)]\tLoss: 0.097488\n",
      "Train Epoch: 10 [19200/37519 (51%)]\tLoss: 0.193516\n",
      "Train Epoch: 10 [19840/37519 (53%)]\tLoss: 0.204090\n",
      "Train Epoch: 10 [20480/37519 (55%)]\tLoss: 0.052586\n",
      "Train Epoch: 10 [21120/37519 (56%)]\tLoss: 0.363918\n",
      "Train Epoch: 10 [21760/37519 (58%)]\tLoss: 0.272868\n",
      "Train Epoch: 10 [22400/37519 (60%)]\tLoss: 0.093207\n",
      "Train Epoch: 10 [23040/37519 (61%)]\tLoss: 0.105611\n",
      "Train Epoch: 10 [23680/37519 (63%)]\tLoss: 0.088311\n",
      "Train Epoch: 10 [24320/37519 (65%)]\tLoss: 0.097710\n",
      "Train Epoch: 10 [24960/37519 (66%)]\tLoss: 0.046577\n",
      "Train Epoch: 10 [25600/37519 (68%)]\tLoss: 0.144804\n",
      "Train Epoch: 10 [26240/37519 (70%)]\tLoss: 0.029960\n",
      "Train Epoch: 10 [26880/37519 (72%)]\tLoss: 0.148887\n",
      "Train Epoch: 10 [27520/37519 (73%)]\tLoss: 0.242259\n",
      "Train Epoch: 10 [28160/37519 (75%)]\tLoss: 0.156943\n",
      "Train Epoch: 10 [28800/37519 (77%)]\tLoss: 0.125666\n",
      "Train Epoch: 10 [29440/37519 (78%)]\tLoss: 0.020982\n",
      "Train Epoch: 10 [30080/37519 (80%)]\tLoss: 0.102574\n",
      "Train Epoch: 10 [30720/37519 (82%)]\tLoss: 0.320279\n",
      "Train Epoch: 10 [31360/37519 (83%)]\tLoss: 0.154931\n",
      "Train Epoch: 10 [32000/37519 (85%)]\tLoss: 0.121500\n",
      "Train Epoch: 10 [32640/37519 (87%)]\tLoss: 0.118248\n",
      "Train Epoch: 10 [33280/37519 (89%)]\tLoss: 0.134507\n",
      "Train Epoch: 10 [33920/37519 (90%)]\tLoss: 0.193306\n",
      "Train Epoch: 10 [34560/37519 (92%)]\tLoss: 0.063686\n",
      "Train Epoch: 10 [35200/37519 (94%)]\tLoss: 0.093631\n",
      "Train Epoch: 10 [35840/37519 (95%)]\tLoss: 0.079761\n",
      "Train Epoch: 10 [36480/37519 (97%)]\tLoss: 0.135936\n",
      "Train Epoch: 10 [37120/37519 (99%)]\tLoss: 0.034548\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/22481 (0%)]\tLoss: 0.144213\n",
      "Train Epoch: 1 [640/22481 (3%)]\tLoss: 0.271037\n",
      "Train Epoch: 1 [1280/22481 (6%)]\tLoss: 0.241382\n",
      "Train Epoch: 1 [1920/22481 (9%)]\tLoss: 0.041808\n",
      "Train Epoch: 1 [2560/22481 (11%)]\tLoss: 0.104022\n",
      "Train Epoch: 1 [3200/22481 (14%)]\tLoss: 0.150643\n",
      "Train Epoch: 1 [3840/22481 (17%)]\tLoss: 0.093167\n",
      "Train Epoch: 1 [4480/22481 (20%)]\tLoss: 0.028894\n",
      "Train Epoch: 1 [5120/22481 (23%)]\tLoss: 0.181205\n",
      "Train Epoch: 1 [5760/22481 (26%)]\tLoss: 0.095040\n",
      "Train Epoch: 1 [6400/22481 (28%)]\tLoss: 0.161208\n",
      "Train Epoch: 1 [7040/22481 (31%)]\tLoss: 0.329844\n",
      "Train Epoch: 1 [7680/22481 (34%)]\tLoss: 0.036202\n",
      "Train Epoch: 1 [8320/22481 (37%)]\tLoss: 0.152641\n",
      "Train Epoch: 1 [8960/22481 (40%)]\tLoss: 0.177261\n",
      "Train Epoch: 1 [9600/22481 (43%)]\tLoss: 0.229370\n",
      "Train Epoch: 1 [10240/22481 (45%)]\tLoss: 0.010412\n",
      "Train Epoch: 1 [10880/22481 (48%)]\tLoss: 0.047434\n",
      "Train Epoch: 1 [11520/22481 (51%)]\tLoss: 0.073813\n",
      "Train Epoch: 1 [12160/22481 (54%)]\tLoss: 0.067449\n",
      "Train Epoch: 1 [12800/22481 (57%)]\tLoss: 0.156236\n",
      "Train Epoch: 1 [13440/22481 (60%)]\tLoss: 0.051766\n",
      "Train Epoch: 1 [14080/22481 (62%)]\tLoss: 0.080676\n",
      "Train Epoch: 1 [14720/22481 (65%)]\tLoss: 0.113423\n",
      "Train Epoch: 1 [15360/22481 (68%)]\tLoss: 0.126643\n",
      "Train Epoch: 1 [16000/22481 (71%)]\tLoss: 0.071020\n",
      "Train Epoch: 1 [16640/22481 (74%)]\tLoss: 0.236874\n",
      "Train Epoch: 1 [17280/22481 (77%)]\tLoss: 0.238472\n",
      "Train Epoch: 1 [17920/22481 (80%)]\tLoss: 0.252111\n",
      "Train Epoch: 1 [18560/22481 (82%)]\tLoss: 0.104752\n",
      "Train Epoch: 1 [19200/22481 (85%)]\tLoss: 0.168579\n",
      "Train Epoch: 1 [19840/22481 (88%)]\tLoss: 0.061149\n",
      "Train Epoch: 1 [20480/22481 (91%)]\tLoss: 0.170776\n",
      "Train Epoch: 1 [21120/22481 (94%)]\tLoss: 0.156862\n",
      "Train Epoch: 1 [21760/22481 (97%)]\tLoss: 0.133112\n",
      "Train Epoch: 1 [22400/22481 (99%)]\tLoss: 0.162396\n",
      "Train Epoch: 2 [0/22481 (0%)]\tLoss: 0.069192\n",
      "Train Epoch: 2 [640/22481 (3%)]\tLoss: 0.229870\n",
      "Train Epoch: 2 [1280/22481 (6%)]\tLoss: 0.051375\n",
      "Train Epoch: 2 [1920/22481 (9%)]\tLoss: 0.073105\n",
      "Train Epoch: 2 [2560/22481 (11%)]\tLoss: 0.075760\n",
      "Train Epoch: 2 [3200/22481 (14%)]\tLoss: 0.089434\n",
      "Train Epoch: 2 [3840/22481 (17%)]\tLoss: 0.056487\n",
      "Train Epoch: 2 [4480/22481 (20%)]\tLoss: 0.055726\n",
      "Train Epoch: 2 [5120/22481 (23%)]\tLoss: 0.173330\n",
      "Train Epoch: 2 [5760/22481 (26%)]\tLoss: 0.068720\n",
      "Train Epoch: 2 [6400/22481 (28%)]\tLoss: 0.143516\n",
      "Train Epoch: 2 [7040/22481 (31%)]\tLoss: 0.044854\n",
      "Train Epoch: 2 [7680/22481 (34%)]\tLoss: 0.100827\n",
      "Train Epoch: 2 [8320/22481 (37%)]\tLoss: 0.545567\n",
      "Train Epoch: 2 [8960/22481 (40%)]\tLoss: 0.068035\n",
      "Train Epoch: 2 [9600/22481 (43%)]\tLoss: 0.015758\n",
      "Train Epoch: 2 [10240/22481 (45%)]\tLoss: 0.165805\n",
      "Train Epoch: 2 [10880/22481 (48%)]\tLoss: 0.121919\n",
      "Train Epoch: 2 [11520/22481 (51%)]\tLoss: 0.062386\n",
      "Train Epoch: 2 [12160/22481 (54%)]\tLoss: 0.045233\n",
      "Train Epoch: 2 [12800/22481 (57%)]\tLoss: 0.098754\n",
      "Train Epoch: 2 [13440/22481 (60%)]\tLoss: 0.106384\n",
      "Train Epoch: 2 [14080/22481 (62%)]\tLoss: 0.090383\n",
      "Train Epoch: 2 [14720/22481 (65%)]\tLoss: 0.132207\n",
      "Train Epoch: 2 [15360/22481 (68%)]\tLoss: 0.145659\n",
      "Train Epoch: 2 [16000/22481 (71%)]\tLoss: 0.101718\n",
      "Train Epoch: 2 [16640/22481 (74%)]\tLoss: 0.109641\n",
      "Train Epoch: 2 [17280/22481 (77%)]\tLoss: 0.136227\n",
      "Train Epoch: 2 [17920/22481 (80%)]\tLoss: 0.139060\n",
      "Train Epoch: 2 [18560/22481 (82%)]\tLoss: 0.163142\n",
      "Train Epoch: 2 [19200/22481 (85%)]\tLoss: 0.122843\n",
      "Train Epoch: 2 [19840/22481 (88%)]\tLoss: 0.070112\n",
      "Train Epoch: 2 [20480/22481 (91%)]\tLoss: 0.226962\n",
      "Train Epoch: 2 [21120/22481 (94%)]\tLoss: 0.035536\n",
      "Train Epoch: 2 [21760/22481 (97%)]\tLoss: 0.092625\n",
      "Train Epoch: 2 [22400/22481 (99%)]\tLoss: 0.099330\n",
      "Train Epoch: 3 [0/22481 (0%)]\tLoss: 0.048907\n",
      "Train Epoch: 3 [640/22481 (3%)]\tLoss: 0.310360\n",
      "Train Epoch: 3 [1280/22481 (6%)]\tLoss: 0.176466\n",
      "Train Epoch: 3 [1920/22481 (9%)]\tLoss: 0.104863\n",
      "Train Epoch: 3 [2560/22481 (11%)]\tLoss: 0.099928\n",
      "Train Epoch: 3 [3200/22481 (14%)]\tLoss: 0.150264\n",
      "Train Epoch: 3 [3840/22481 (17%)]\tLoss: 0.072403\n",
      "Train Epoch: 3 [4480/22481 (20%)]\tLoss: 0.202477\n",
      "Train Epoch: 3 [5120/22481 (23%)]\tLoss: 0.130784\n",
      "Train Epoch: 3 [5760/22481 (26%)]\tLoss: 0.031072\n",
      "Train Epoch: 3 [6400/22481 (28%)]\tLoss: 0.035197\n",
      "Train Epoch: 3 [7040/22481 (31%)]\tLoss: 0.125341\n",
      "Train Epoch: 3 [7680/22481 (34%)]\tLoss: 0.061497\n",
      "Train Epoch: 3 [8320/22481 (37%)]\tLoss: 0.178981\n",
      "Train Epoch: 3 [8960/22481 (40%)]\tLoss: 0.031325\n",
      "Train Epoch: 3 [9600/22481 (43%)]\tLoss: 0.124145\n",
      "Train Epoch: 3 [10240/22481 (45%)]\tLoss: 0.141045\n",
      "Train Epoch: 3 [10880/22481 (48%)]\tLoss: 0.198094\n",
      "Train Epoch: 3 [11520/22481 (51%)]\tLoss: 0.114419\n",
      "Train Epoch: 3 [12160/22481 (54%)]\tLoss: 0.203462\n",
      "Train Epoch: 3 [12800/22481 (57%)]\tLoss: 0.148837\n",
      "Train Epoch: 3 [13440/22481 (60%)]\tLoss: 0.279689\n",
      "Train Epoch: 3 [14080/22481 (62%)]\tLoss: 0.149508\n",
      "Train Epoch: 3 [14720/22481 (65%)]\tLoss: 0.057396\n",
      "Train Epoch: 3 [15360/22481 (68%)]\tLoss: 0.213816\n",
      "Train Epoch: 3 [16000/22481 (71%)]\tLoss: 0.125755\n",
      "Train Epoch: 3 [16640/22481 (74%)]\tLoss: 0.087109\n",
      "Train Epoch: 3 [17280/22481 (77%)]\tLoss: 0.083978\n",
      "Train Epoch: 3 [17920/22481 (80%)]\tLoss: 0.265923\n",
      "Train Epoch: 3 [18560/22481 (82%)]\tLoss: 0.052133\n",
      "Train Epoch: 3 [19200/22481 (85%)]\tLoss: 0.080455\n",
      "Train Epoch: 3 [19840/22481 (88%)]\tLoss: 0.089823\n",
      "Train Epoch: 3 [20480/22481 (91%)]\tLoss: 0.107396\n",
      "Train Epoch: 3 [21120/22481 (94%)]\tLoss: 0.095425\n",
      "Train Epoch: 3 [21760/22481 (97%)]\tLoss: 0.168931\n",
      "Train Epoch: 3 [22400/22481 (99%)]\tLoss: 0.027339\n",
      "Train Epoch: 4 [0/22481 (0%)]\tLoss: 0.186410\n",
      "Train Epoch: 4 [640/22481 (3%)]\tLoss: 0.176543\n",
      "Train Epoch: 4 [1280/22481 (6%)]\tLoss: 0.105717\n",
      "Train Epoch: 4 [1920/22481 (9%)]\tLoss: 0.026688\n",
      "Train Epoch: 4 [2560/22481 (11%)]\tLoss: 0.035452\n",
      "Train Epoch: 4 [3200/22481 (14%)]\tLoss: 0.073967\n",
      "Train Epoch: 4 [3840/22481 (17%)]\tLoss: 0.060942\n",
      "Train Epoch: 4 [4480/22481 (20%)]\tLoss: 0.029614\n",
      "Train Epoch: 4 [5120/22481 (23%)]\tLoss: 0.029633\n",
      "Train Epoch: 4 [5760/22481 (26%)]\tLoss: 0.141665\n",
      "Train Epoch: 4 [6400/22481 (28%)]\tLoss: 0.087930\n",
      "Train Epoch: 4 [7040/22481 (31%)]\tLoss: 0.072132\n",
      "Train Epoch: 4 [7680/22481 (34%)]\tLoss: 0.231733\n",
      "Train Epoch: 4 [8320/22481 (37%)]\tLoss: 0.127048\n",
      "Train Epoch: 4 [8960/22481 (40%)]\tLoss: 0.069632\n",
      "Train Epoch: 4 [9600/22481 (43%)]\tLoss: 0.044172\n",
      "Train Epoch: 4 [10240/22481 (45%)]\tLoss: 0.137531\n",
      "Train Epoch: 4 [10880/22481 (48%)]\tLoss: 0.035995\n",
      "Train Epoch: 4 [11520/22481 (51%)]\tLoss: 0.147553\n",
      "Train Epoch: 4 [12160/22481 (54%)]\tLoss: 0.072536\n",
      "Train Epoch: 4 [12800/22481 (57%)]\tLoss: 0.112135\n",
      "Train Epoch: 4 [13440/22481 (60%)]\tLoss: 0.250078\n",
      "Train Epoch: 4 [14080/22481 (62%)]\tLoss: 0.128396\n",
      "Train Epoch: 4 [14720/22481 (65%)]\tLoss: 0.063264\n",
      "Train Epoch: 4 [15360/22481 (68%)]\tLoss: 0.259910\n",
      "Train Epoch: 4 [16000/22481 (71%)]\tLoss: 0.191738\n",
      "Train Epoch: 4 [16640/22481 (74%)]\tLoss: 0.097949\n",
      "Train Epoch: 4 [17280/22481 (77%)]\tLoss: 0.069833\n",
      "Train Epoch: 4 [17920/22481 (80%)]\tLoss: 0.096438\n",
      "Train Epoch: 4 [18560/22481 (82%)]\tLoss: 0.066457\n",
      "Train Epoch: 4 [19200/22481 (85%)]\tLoss: 0.075503\n",
      "Train Epoch: 4 [19840/22481 (88%)]\tLoss: 0.231642\n",
      "Train Epoch: 4 [20480/22481 (91%)]\tLoss: 0.067408\n",
      "Train Epoch: 4 [21120/22481 (94%)]\tLoss: 0.086752\n",
      "Train Epoch: 4 [21760/22481 (97%)]\tLoss: 0.238810\n",
      "Train Epoch: 4 [22400/22481 (99%)]\tLoss: 0.032093\n",
      "Train Epoch: 5 [0/22481 (0%)]\tLoss: 0.159148\n",
      "Train Epoch: 5 [640/22481 (3%)]\tLoss: 0.172034\n",
      "Train Epoch: 5 [1280/22481 (6%)]\tLoss: 0.036827\n",
      "Train Epoch: 5 [1920/22481 (9%)]\tLoss: 0.049197\n",
      "Train Epoch: 5 [2560/22481 (11%)]\tLoss: 0.068234\n",
      "Train Epoch: 5 [3200/22481 (14%)]\tLoss: 0.038388\n",
      "Train Epoch: 5 [3840/22481 (17%)]\tLoss: 0.082029\n",
      "Train Epoch: 5 [4480/22481 (20%)]\tLoss: 0.070932\n",
      "Train Epoch: 5 [5120/22481 (23%)]\tLoss: 0.051428\n",
      "Train Epoch: 5 [5760/22481 (26%)]\tLoss: 0.112501\n",
      "Train Epoch: 5 [6400/22481 (28%)]\tLoss: 0.049451\n",
      "Train Epoch: 5 [7040/22481 (31%)]\tLoss: 0.068328\n",
      "Train Epoch: 5 [7680/22481 (34%)]\tLoss: 0.050042\n",
      "Train Epoch: 5 [8320/22481 (37%)]\tLoss: 0.183013\n",
      "Train Epoch: 5 [8960/22481 (40%)]\tLoss: 0.202489\n",
      "Train Epoch: 5 [9600/22481 (43%)]\tLoss: 0.099410\n",
      "Train Epoch: 5 [10240/22481 (45%)]\tLoss: 0.102640\n",
      "Train Epoch: 5 [10880/22481 (48%)]\tLoss: 0.098188\n",
      "Train Epoch: 5 [11520/22481 (51%)]\tLoss: 0.061714\n",
      "Train Epoch: 5 [12160/22481 (54%)]\tLoss: 0.177078\n",
      "Train Epoch: 5 [12800/22481 (57%)]\tLoss: 0.061380\n",
      "Train Epoch: 5 [13440/22481 (60%)]\tLoss: 0.146644\n",
      "Train Epoch: 5 [14080/22481 (62%)]\tLoss: 0.070282\n",
      "Train Epoch: 5 [14720/22481 (65%)]\tLoss: 0.027249\n",
      "Train Epoch: 5 [15360/22481 (68%)]\tLoss: 0.156160\n",
      "Train Epoch: 5 [16000/22481 (71%)]\tLoss: 0.037107\n",
      "Train Epoch: 5 [16640/22481 (74%)]\tLoss: 0.116261\n",
      "Train Epoch: 5 [17280/22481 (77%)]\tLoss: 0.072244\n",
      "Train Epoch: 5 [17920/22481 (80%)]\tLoss: 0.051888\n",
      "Train Epoch: 5 [18560/22481 (82%)]\tLoss: 0.052771\n",
      "Train Epoch: 5 [19200/22481 (85%)]\tLoss: 0.070563\n",
      "Train Epoch: 5 [19840/22481 (88%)]\tLoss: 0.034328\n",
      "Train Epoch: 5 [20480/22481 (91%)]\tLoss: 0.265755\n",
      "Train Epoch: 5 [21120/22481 (94%)]\tLoss: 0.121477\n",
      "Train Epoch: 5 [21760/22481 (97%)]\tLoss: 0.119055\n",
      "Train Epoch: 5 [22400/22481 (99%)]\tLoss: 0.032307\n",
      "Train Epoch: 6 [0/22481 (0%)]\tLoss: 0.227173\n",
      "Train Epoch: 6 [640/22481 (3%)]\tLoss: 0.016585\n",
      "Train Epoch: 6 [1280/22481 (6%)]\tLoss: 0.117391\n",
      "Train Epoch: 6 [1920/22481 (9%)]\tLoss: 0.060988\n",
      "Train Epoch: 6 [2560/22481 (11%)]\tLoss: 0.063286\n",
      "Train Epoch: 6 [3200/22481 (14%)]\tLoss: 0.116307\n",
      "Train Epoch: 6 [3840/22481 (17%)]\tLoss: 0.088585\n",
      "Train Epoch: 6 [4480/22481 (20%)]\tLoss: 0.027379\n",
      "Train Epoch: 6 [5120/22481 (23%)]\tLoss: 0.059041\n",
      "Train Epoch: 6 [5760/22481 (26%)]\tLoss: 0.079386\n",
      "Train Epoch: 6 [6400/22481 (28%)]\tLoss: 0.141701\n",
      "Train Epoch: 6 [7040/22481 (31%)]\tLoss: 0.085284\n",
      "Train Epoch: 6 [7680/22481 (34%)]\tLoss: 0.136166\n",
      "Train Epoch: 6 [8320/22481 (37%)]\tLoss: 0.039169\n",
      "Train Epoch: 6 [8960/22481 (40%)]\tLoss: 0.139357\n",
      "Train Epoch: 6 [9600/22481 (43%)]\tLoss: 0.069013\n",
      "Train Epoch: 6 [10240/22481 (45%)]\tLoss: 0.046992\n",
      "Train Epoch: 6 [10880/22481 (48%)]\tLoss: 0.068849\n",
      "Train Epoch: 6 [11520/22481 (51%)]\tLoss: 0.253363\n",
      "Train Epoch: 6 [12160/22481 (54%)]\tLoss: 0.254825\n",
      "Train Epoch: 6 [12800/22481 (57%)]\tLoss: 0.152571\n",
      "Train Epoch: 6 [13440/22481 (60%)]\tLoss: 0.175176\n",
      "Train Epoch: 6 [14080/22481 (62%)]\tLoss: 0.073509\n",
      "Train Epoch: 6 [14720/22481 (65%)]\tLoss: 0.246103\n",
      "Train Epoch: 6 [15360/22481 (68%)]\tLoss: 0.136232\n",
      "Train Epoch: 6 [16000/22481 (71%)]\tLoss: 0.113975\n",
      "Train Epoch: 6 [16640/22481 (74%)]\tLoss: 0.058219\n",
      "Train Epoch: 6 [17280/22481 (77%)]\tLoss: 0.101940\n",
      "Train Epoch: 6 [17920/22481 (80%)]\tLoss: 0.090557\n",
      "Train Epoch: 6 [18560/22481 (82%)]\tLoss: 0.212550\n",
      "Train Epoch: 6 [19200/22481 (85%)]\tLoss: 0.192370\n",
      "Train Epoch: 6 [19840/22481 (88%)]\tLoss: 0.050944\n",
      "Train Epoch: 6 [20480/22481 (91%)]\tLoss: 0.100654\n",
      "Train Epoch: 6 [21120/22481 (94%)]\tLoss: 0.083347\n",
      "Train Epoch: 6 [21760/22481 (97%)]\tLoss: 0.112623\n",
      "Train Epoch: 6 [22400/22481 (99%)]\tLoss: 0.113862\n",
      "Train Epoch: 7 [0/22481 (0%)]\tLoss: 0.036998\n",
      "Train Epoch: 7 [640/22481 (3%)]\tLoss: 0.235522\n",
      "Train Epoch: 7 [1280/22481 (6%)]\tLoss: 0.068419\n",
      "Train Epoch: 7 [1920/22481 (9%)]\tLoss: 0.095204\n",
      "Train Epoch: 7 [2560/22481 (11%)]\tLoss: 0.124776\n",
      "Train Epoch: 7 [3200/22481 (14%)]\tLoss: 0.026991\n",
      "Train Epoch: 7 [3840/22481 (17%)]\tLoss: 0.191366\n",
      "Train Epoch: 7 [4480/22481 (20%)]\tLoss: 0.047059\n",
      "Train Epoch: 7 [5120/22481 (23%)]\tLoss: 0.244096\n",
      "Train Epoch: 7 [5760/22481 (26%)]\tLoss: 0.251429\n",
      "Train Epoch: 7 [6400/22481 (28%)]\tLoss: 0.158207\n",
      "Train Epoch: 7 [7040/22481 (31%)]\tLoss: 0.043271\n",
      "Train Epoch: 7 [7680/22481 (34%)]\tLoss: 0.034499\n",
      "Train Epoch: 7 [8320/22481 (37%)]\tLoss: 0.042198\n",
      "Train Epoch: 7 [8960/22481 (40%)]\tLoss: 0.110220\n",
      "Train Epoch: 7 [9600/22481 (43%)]\tLoss: 0.062637\n",
      "Train Epoch: 7 [10240/22481 (45%)]\tLoss: 0.096224\n",
      "Train Epoch: 7 [10880/22481 (48%)]\tLoss: 0.049462\n",
      "Train Epoch: 7 [11520/22481 (51%)]\tLoss: 0.128621\n",
      "Train Epoch: 7 [12160/22481 (54%)]\tLoss: 0.043790\n",
      "Train Epoch: 7 [12800/22481 (57%)]\tLoss: 0.137173\n",
      "Train Epoch: 7 [13440/22481 (60%)]\tLoss: 0.047168\n",
      "Train Epoch: 7 [14080/22481 (62%)]\tLoss: 0.094315\n",
      "Train Epoch: 7 [14720/22481 (65%)]\tLoss: 0.108641\n",
      "Train Epoch: 7 [15360/22481 (68%)]\tLoss: 0.204777\n",
      "Train Epoch: 7 [16000/22481 (71%)]\tLoss: 0.068325\n",
      "Train Epoch: 7 [16640/22481 (74%)]\tLoss: 0.084831\n",
      "Train Epoch: 7 [17280/22481 (77%)]\tLoss: 0.055939\n",
      "Train Epoch: 7 [17920/22481 (80%)]\tLoss: 0.082308\n",
      "Train Epoch: 7 [18560/22481 (82%)]\tLoss: 0.110811\n",
      "Train Epoch: 7 [19200/22481 (85%)]\tLoss: 0.070102\n",
      "Train Epoch: 7 [19840/22481 (88%)]\tLoss: 0.043594\n",
      "Train Epoch: 7 [20480/22481 (91%)]\tLoss: 0.036898\n",
      "Train Epoch: 7 [21120/22481 (94%)]\tLoss: 0.099648\n",
      "Train Epoch: 7 [21760/22481 (97%)]\tLoss: 0.095514\n",
      "Train Epoch: 7 [22400/22481 (99%)]\tLoss: 0.082850\n",
      "Train Epoch: 8 [0/22481 (0%)]\tLoss: 0.062592\n",
      "Train Epoch: 8 [640/22481 (3%)]\tLoss: 0.094109\n",
      "Train Epoch: 8 [1280/22481 (6%)]\tLoss: 0.145819\n",
      "Train Epoch: 8 [1920/22481 (9%)]\tLoss: 0.080544\n",
      "Train Epoch: 8 [2560/22481 (11%)]\tLoss: 0.016146\n",
      "Train Epoch: 8 [3200/22481 (14%)]\tLoss: 0.065079\n",
      "Train Epoch: 8 [3840/22481 (17%)]\tLoss: 0.036560\n",
      "Train Epoch: 8 [4480/22481 (20%)]\tLoss: 0.088785\n",
      "Train Epoch: 8 [5120/22481 (23%)]\tLoss: 0.055839\n",
      "Train Epoch: 8 [5760/22481 (26%)]\tLoss: 0.104084\n",
      "Train Epoch: 8 [6400/22481 (28%)]\tLoss: 0.041545\n",
      "Train Epoch: 8 [7040/22481 (31%)]\tLoss: 0.097426\n",
      "Train Epoch: 8 [7680/22481 (34%)]\tLoss: 0.091746\n",
      "Train Epoch: 8 [8320/22481 (37%)]\tLoss: 0.087479\n",
      "Train Epoch: 8 [8960/22481 (40%)]\tLoss: 0.070551\n",
      "Train Epoch: 8 [9600/22481 (43%)]\tLoss: 0.070224\n",
      "Train Epoch: 8 [10240/22481 (45%)]\tLoss: 0.073117\n",
      "Train Epoch: 8 [10880/22481 (48%)]\tLoss: 0.202566\n",
      "Train Epoch: 8 [11520/22481 (51%)]\tLoss: 0.032892\n",
      "Train Epoch: 8 [12160/22481 (54%)]\tLoss: 0.094766\n",
      "Train Epoch: 8 [12800/22481 (57%)]\tLoss: 0.089870\n",
      "Train Epoch: 8 [13440/22481 (60%)]\tLoss: 0.093095\n",
      "Train Epoch: 8 [14080/22481 (62%)]\tLoss: 0.012099\n",
      "Train Epoch: 8 [14720/22481 (65%)]\tLoss: 0.048184\n",
      "Train Epoch: 8 [15360/22481 (68%)]\tLoss: 0.084533\n",
      "Train Epoch: 8 [16000/22481 (71%)]\tLoss: 0.083308\n",
      "Train Epoch: 8 [16640/22481 (74%)]\tLoss: 0.077967\n",
      "Train Epoch: 8 [17280/22481 (77%)]\tLoss: 0.073185\n",
      "Train Epoch: 8 [17920/22481 (80%)]\tLoss: 0.131030\n",
      "Train Epoch: 8 [18560/22481 (82%)]\tLoss: 0.067827\n",
      "Train Epoch: 8 [19200/22481 (85%)]\tLoss: 0.070805\n",
      "Train Epoch: 8 [19840/22481 (88%)]\tLoss: 0.024919\n",
      "Train Epoch: 8 [20480/22481 (91%)]\tLoss: 0.060550\n",
      "Train Epoch: 8 [21120/22481 (94%)]\tLoss: 0.051415\n",
      "Train Epoch: 8 [21760/22481 (97%)]\tLoss: 0.097861\n",
      "Train Epoch: 8 [22400/22481 (99%)]\tLoss: 0.073023\n",
      "Train Epoch: 9 [0/22481 (0%)]\tLoss: 0.056291\n",
      "Train Epoch: 9 [640/22481 (3%)]\tLoss: 0.089897\n",
      "Train Epoch: 9 [1280/22481 (6%)]\tLoss: 0.081962\n",
      "Train Epoch: 9 [1920/22481 (9%)]\tLoss: 0.018756\n",
      "Train Epoch: 9 [2560/22481 (11%)]\tLoss: 0.123119\n",
      "Train Epoch: 9 [3200/22481 (14%)]\tLoss: 0.019640\n",
      "Train Epoch: 9 [3840/22481 (17%)]\tLoss: 0.023385\n",
      "Train Epoch: 9 [4480/22481 (20%)]\tLoss: 0.052243\n",
      "Train Epoch: 9 [5120/22481 (23%)]\tLoss: 0.108576\n",
      "Train Epoch: 9 [5760/22481 (26%)]\tLoss: 0.095561\n",
      "Train Epoch: 9 [6400/22481 (28%)]\tLoss: 0.141110\n",
      "Train Epoch: 9 [7040/22481 (31%)]\tLoss: 0.215552\n",
      "Train Epoch: 9 [7680/22481 (34%)]\tLoss: 0.084656\n",
      "Train Epoch: 9 [8320/22481 (37%)]\tLoss: 0.089104\n",
      "Train Epoch: 9 [8960/22481 (40%)]\tLoss: 0.170745\n",
      "Train Epoch: 9 [9600/22481 (43%)]\tLoss: 0.069453\n",
      "Train Epoch: 9 [10240/22481 (45%)]\tLoss: 0.140558\n",
      "Train Epoch: 9 [10880/22481 (48%)]\tLoss: 0.110603\n",
      "Train Epoch: 9 [11520/22481 (51%)]\tLoss: 0.157183\n",
      "Train Epoch: 9 [12160/22481 (54%)]\tLoss: 0.109122\n",
      "Train Epoch: 9 [12800/22481 (57%)]\tLoss: 0.120117\n",
      "Train Epoch: 9 [13440/22481 (60%)]\tLoss: 0.085816\n",
      "Train Epoch: 9 [14080/22481 (62%)]\tLoss: 0.121267\n",
      "Train Epoch: 9 [14720/22481 (65%)]\tLoss: 0.056025\n",
      "Train Epoch: 9 [15360/22481 (68%)]\tLoss: 0.057515\n",
      "Train Epoch: 9 [16000/22481 (71%)]\tLoss: 0.076063\n",
      "Train Epoch: 9 [16640/22481 (74%)]\tLoss: 0.044499\n",
      "Train Epoch: 9 [17280/22481 (77%)]\tLoss: 0.025286\n",
      "Train Epoch: 9 [17920/22481 (80%)]\tLoss: 0.092653\n",
      "Train Epoch: 9 [18560/22481 (82%)]\tLoss: 0.121100\n",
      "Train Epoch: 9 [19200/22481 (85%)]\tLoss: 0.031336\n",
      "Train Epoch: 9 [19840/22481 (88%)]\tLoss: 0.120416\n",
      "Train Epoch: 9 [20480/22481 (91%)]\tLoss: 0.209927\n",
      "Train Epoch: 9 [21120/22481 (94%)]\tLoss: 0.025840\n",
      "Train Epoch: 9 [21760/22481 (97%)]\tLoss: 0.117821\n",
      "Train Epoch: 9 [22400/22481 (99%)]\tLoss: 0.053716\n",
      "Train Epoch: 10 [0/22481 (0%)]\tLoss: 0.053945\n",
      "Train Epoch: 10 [640/22481 (3%)]\tLoss: 0.085534\n",
      "Train Epoch: 10 [1280/22481 (6%)]\tLoss: 0.158080\n",
      "Train Epoch: 10 [1920/22481 (9%)]\tLoss: 0.114334\n",
      "Train Epoch: 10 [2560/22481 (11%)]\tLoss: 0.185906\n",
      "Train Epoch: 10 [3200/22481 (14%)]\tLoss: 0.016641\n",
      "Train Epoch: 10 [3840/22481 (17%)]\tLoss: 0.027176\n",
      "Train Epoch: 10 [4480/22481 (20%)]\tLoss: 0.115046\n",
      "Train Epoch: 10 [5120/22481 (23%)]\tLoss: 0.095285\n",
      "Train Epoch: 10 [5760/22481 (26%)]\tLoss: 0.233860\n",
      "Train Epoch: 10 [6400/22481 (28%)]\tLoss: 0.131382\n",
      "Train Epoch: 10 [7040/22481 (31%)]\tLoss: 0.116193\n",
      "Train Epoch: 10 [7680/22481 (34%)]\tLoss: 0.057487\n",
      "Train Epoch: 10 [8320/22481 (37%)]\tLoss: 0.019216\n",
      "Train Epoch: 10 [8960/22481 (40%)]\tLoss: 0.075396\n",
      "Train Epoch: 10 [9600/22481 (43%)]\tLoss: 0.081267\n",
      "Train Epoch: 10 [10240/22481 (45%)]\tLoss: 0.065996\n",
      "Train Epoch: 10 [10880/22481 (48%)]\tLoss: 0.101147\n",
      "Train Epoch: 10 [11520/22481 (51%)]\tLoss: 0.162884\n",
      "Train Epoch: 10 [12160/22481 (54%)]\tLoss: 0.070215\n",
      "Train Epoch: 10 [12800/22481 (57%)]\tLoss: 0.032072\n",
      "Train Epoch: 10 [13440/22481 (60%)]\tLoss: 0.142858\n",
      "Train Epoch: 10 [14080/22481 (62%)]\tLoss: 0.015263\n",
      "Train Epoch: 10 [14720/22481 (65%)]\tLoss: 0.170227\n",
      "Train Epoch: 10 [15360/22481 (68%)]\tLoss: 0.070580\n",
      "Train Epoch: 10 [16000/22481 (71%)]\tLoss: 0.056214\n",
      "Train Epoch: 10 [16640/22481 (74%)]\tLoss: 0.068046\n",
      "Train Epoch: 10 [17280/22481 (77%)]\tLoss: 0.039641\n",
      "Train Epoch: 10 [17920/22481 (80%)]\tLoss: 0.069867\n",
      "Train Epoch: 10 [18560/22481 (82%)]\tLoss: 0.065802\n",
      "Train Epoch: 10 [19200/22481 (85%)]\tLoss: 0.059947\n",
      "Train Epoch: 10 [19840/22481 (88%)]\tLoss: 0.272673\n",
      "Train Epoch: 10 [20480/22481 (91%)]\tLoss: 0.123580\n",
      "Train Epoch: 10 [21120/22481 (94%)]\tLoss: 0.231860\n",
      "Train Epoch: 10 [21760/22481 (97%)]\tLoss: 0.056990\n",
      "Train Epoch: 10 [22400/22481 (99%)]\tLoss: 0.135128\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.2188, Accuracy: 9855/10000 (99%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/37519 (0%)]\tLoss: 0.082179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [640/37519 (2%)]\tLoss: 0.110203\n",
      "Train Epoch: 1 [1280/37519 (3%)]\tLoss: 0.145707\n",
      "Train Epoch: 1 [1920/37519 (5%)]\tLoss: 0.209051\n",
      "Train Epoch: 1 [2560/37519 (7%)]\tLoss: 0.248685\n",
      "Train Epoch: 1 [3200/37519 (9%)]\tLoss: 0.082292\n",
      "Train Epoch: 1 [3840/37519 (10%)]\tLoss: 0.143048\n",
      "Train Epoch: 1 [4480/37519 (12%)]\tLoss: 0.036927\n",
      "Train Epoch: 1 [5120/37519 (14%)]\tLoss: 0.270467\n",
      "Train Epoch: 1 [5760/37519 (15%)]\tLoss: 0.067573\n",
      "Train Epoch: 1 [6400/37519 (17%)]\tLoss: 0.241591\n",
      "Train Epoch: 1 [7040/37519 (19%)]\tLoss: 0.180527\n",
      "Train Epoch: 1 [7680/37519 (20%)]\tLoss: 0.093094\n",
      "Train Epoch: 1 [8320/37519 (22%)]\tLoss: 0.159828\n",
      "Train Epoch: 1 [8960/37519 (24%)]\tLoss: 0.043512\n",
      "Train Epoch: 1 [9600/37519 (26%)]\tLoss: 0.072210\n",
      "Train Epoch: 1 [10240/37519 (27%)]\tLoss: 0.103893\n",
      "Train Epoch: 1 [10880/37519 (29%)]\tLoss: 0.073330\n",
      "Train Epoch: 1 [11520/37519 (31%)]\tLoss: 0.138096\n",
      "Train Epoch: 1 [12160/37519 (32%)]\tLoss: 0.116311\n",
      "Train Epoch: 1 [12800/37519 (34%)]\tLoss: 0.072907\n",
      "Train Epoch: 1 [13440/37519 (36%)]\tLoss: 0.019929\n",
      "Train Epoch: 1 [14080/37519 (37%)]\tLoss: 0.065977\n",
      "Train Epoch: 1 [14720/37519 (39%)]\tLoss: 0.251690\n",
      "Train Epoch: 1 [15360/37519 (41%)]\tLoss: 0.164902\n",
      "Train Epoch: 1 [16000/37519 (43%)]\tLoss: 0.094864\n",
      "Train Epoch: 1 [16640/37519 (44%)]\tLoss: 0.344367\n",
      "Train Epoch: 1 [17280/37519 (46%)]\tLoss: 0.125156\n",
      "Train Epoch: 1 [17920/37519 (48%)]\tLoss: 0.085348\n",
      "Train Epoch: 1 [18560/37519 (49%)]\tLoss: 0.228641\n",
      "Train Epoch: 1 [19200/37519 (51%)]\tLoss: 0.053875\n",
      "Train Epoch: 1 [19840/37519 (53%)]\tLoss: 0.300016\n",
      "Train Epoch: 1 [20480/37519 (55%)]\tLoss: 0.044064\n",
      "Train Epoch: 1 [21120/37519 (56%)]\tLoss: 0.193834\n",
      "Train Epoch: 1 [21760/37519 (58%)]\tLoss: 0.087767\n",
      "Train Epoch: 1 [22400/37519 (60%)]\tLoss: 0.222815\n",
      "Train Epoch: 1 [23040/37519 (61%)]\tLoss: 0.034737\n",
      "Train Epoch: 1 [23680/37519 (63%)]\tLoss: 0.085847\n",
      "Train Epoch: 1 [24320/37519 (65%)]\tLoss: 0.111123\n",
      "Train Epoch: 1 [24960/37519 (66%)]\tLoss: 0.205590\n",
      "Train Epoch: 1 [25600/37519 (68%)]\tLoss: 0.240959\n",
      "Train Epoch: 1 [26240/37519 (70%)]\tLoss: 0.045240\n",
      "Train Epoch: 1 [26880/37519 (72%)]\tLoss: 0.183745\n",
      "Train Epoch: 1 [27520/37519 (73%)]\tLoss: 0.100337\n",
      "Train Epoch: 1 [28160/37519 (75%)]\tLoss: 0.139690\n",
      "Train Epoch: 1 [28800/37519 (77%)]\tLoss: 0.107689\n",
      "Train Epoch: 1 [29440/37519 (78%)]\tLoss: 0.183558\n",
      "Train Epoch: 1 [30080/37519 (80%)]\tLoss: 0.131729\n",
      "Train Epoch: 1 [30720/37519 (82%)]\tLoss: 0.020338\n",
      "Train Epoch: 1 [31360/37519 (83%)]\tLoss: 0.078637\n",
      "Train Epoch: 1 [32000/37519 (85%)]\tLoss: 0.030694\n",
      "Train Epoch: 1 [32640/37519 (87%)]\tLoss: 0.097009\n",
      "Train Epoch: 1 [33280/37519 (89%)]\tLoss: 0.218413\n",
      "Train Epoch: 1 [33920/37519 (90%)]\tLoss: 0.053933\n",
      "Train Epoch: 1 [34560/37519 (92%)]\tLoss: 0.105790\n",
      "Train Epoch: 1 [35200/37519 (94%)]\tLoss: 0.055097\n",
      "Train Epoch: 1 [35840/37519 (95%)]\tLoss: 0.108204\n",
      "Train Epoch: 1 [36480/37519 (97%)]\tLoss: 0.180648\n",
      "Train Epoch: 1 [37120/37519 (99%)]\tLoss: 0.027120\n",
      "Train Epoch: 2 [0/37519 (0%)]\tLoss: 0.045912\n",
      "Train Epoch: 2 [640/37519 (2%)]\tLoss: 0.166310\n",
      "Train Epoch: 2 [1280/37519 (3%)]\tLoss: 0.080901\n",
      "Train Epoch: 2 [1920/37519 (5%)]\tLoss: 0.111830\n",
      "Train Epoch: 2 [2560/37519 (7%)]\tLoss: 0.041074\n",
      "Train Epoch: 2 [3200/37519 (9%)]\tLoss: 0.039384\n",
      "Train Epoch: 2 [3840/37519 (10%)]\tLoss: 0.108405\n",
      "Train Epoch: 2 [4480/37519 (12%)]\tLoss: 0.047455\n",
      "Train Epoch: 2 [5120/37519 (14%)]\tLoss: 0.112682\n",
      "Train Epoch: 2 [5760/37519 (15%)]\tLoss: 0.117422\n",
      "Train Epoch: 2 [6400/37519 (17%)]\tLoss: 0.077600\n",
      "Train Epoch: 2 [7040/37519 (19%)]\tLoss: 0.086463\n",
      "Train Epoch: 2 [7680/37519 (20%)]\tLoss: 0.042250\n",
      "Train Epoch: 2 [8320/37519 (22%)]\tLoss: 0.068494\n",
      "Train Epoch: 2 [8960/37519 (24%)]\tLoss: 0.053996\n",
      "Train Epoch: 2 [9600/37519 (26%)]\tLoss: 0.079925\n",
      "Train Epoch: 2 [10240/37519 (27%)]\tLoss: 0.075188\n",
      "Train Epoch: 2 [10880/37519 (29%)]\tLoss: 0.285212\n",
      "Train Epoch: 2 [11520/37519 (31%)]\tLoss: 0.078824\n",
      "Train Epoch: 2 [12160/37519 (32%)]\tLoss: 0.083262\n",
      "Train Epoch: 2 [12800/37519 (34%)]\tLoss: 0.100293\n",
      "Train Epoch: 2 [13440/37519 (36%)]\tLoss: 0.101441\n",
      "Train Epoch: 2 [14080/37519 (37%)]\tLoss: 0.233282\n",
      "Train Epoch: 2 [14720/37519 (39%)]\tLoss: 0.043256\n",
      "Train Epoch: 2 [15360/37519 (41%)]\tLoss: 0.194671\n",
      "Train Epoch: 2 [16000/37519 (43%)]\tLoss: 0.112821\n",
      "Train Epoch: 2 [16640/37519 (44%)]\tLoss: 0.232507\n",
      "Train Epoch: 2 [17280/37519 (46%)]\tLoss: 0.151027\n",
      "Train Epoch: 2 [17920/37519 (48%)]\tLoss: 0.142312\n",
      "Train Epoch: 2 [18560/37519 (49%)]\tLoss: 0.085997\n",
      "Train Epoch: 2 [19200/37519 (51%)]\tLoss: 0.084209\n",
      "Train Epoch: 2 [19840/37519 (53%)]\tLoss: 0.355642\n",
      "Train Epoch: 2 [20480/37519 (55%)]\tLoss: 0.118259\n",
      "Train Epoch: 2 [21120/37519 (56%)]\tLoss: 0.035947\n",
      "Train Epoch: 2 [21760/37519 (58%)]\tLoss: 0.070415\n",
      "Train Epoch: 2 [22400/37519 (60%)]\tLoss: 0.096031\n",
      "Train Epoch: 2 [23040/37519 (61%)]\tLoss: 0.163270\n",
      "Train Epoch: 2 [23680/37519 (63%)]\tLoss: 0.020330\n",
      "Train Epoch: 2 [24320/37519 (65%)]\tLoss: 0.314208\n",
      "Train Epoch: 2 [24960/37519 (66%)]\tLoss: 0.110914\n",
      "Train Epoch: 2 [25600/37519 (68%)]\tLoss: 0.032161\n",
      "Train Epoch: 2 [26240/37519 (70%)]\tLoss: 0.068648\n",
      "Train Epoch: 2 [26880/37519 (72%)]\tLoss: 0.102807\n",
      "Train Epoch: 2 [27520/37519 (73%)]\tLoss: 0.209676\n",
      "Train Epoch: 2 [28160/37519 (75%)]\tLoss: 0.076997\n",
      "Train Epoch: 2 [28800/37519 (77%)]\tLoss: 0.123504\n",
      "Train Epoch: 2 [29440/37519 (78%)]\tLoss: 0.037680\n",
      "Train Epoch: 2 [30080/37519 (80%)]\tLoss: 0.148318\n",
      "Train Epoch: 2 [30720/37519 (82%)]\tLoss: 0.056260\n",
      "Train Epoch: 2 [31360/37519 (83%)]\tLoss: 0.056307\n",
      "Train Epoch: 2 [32000/37519 (85%)]\tLoss: 0.089461\n",
      "Train Epoch: 2 [32640/37519 (87%)]\tLoss: 0.165775\n",
      "Train Epoch: 2 [33280/37519 (89%)]\tLoss: 0.187387\n",
      "Train Epoch: 2 [33920/37519 (90%)]\tLoss: 0.080905\n",
      "Train Epoch: 2 [34560/37519 (92%)]\tLoss: 0.071736\n",
      "Train Epoch: 2 [35200/37519 (94%)]\tLoss: 0.143586\n",
      "Train Epoch: 2 [35840/37519 (95%)]\tLoss: 0.085530\n",
      "Train Epoch: 2 [36480/37519 (97%)]\tLoss: 0.016249\n",
      "Train Epoch: 2 [37120/37519 (99%)]\tLoss: 0.102685\n",
      "Train Epoch: 3 [0/37519 (0%)]\tLoss: 0.226869\n",
      "Train Epoch: 3 [640/37519 (2%)]\tLoss: 0.144741\n",
      "Train Epoch: 3 [1280/37519 (3%)]\tLoss: 0.284071\n",
      "Train Epoch: 3 [1920/37519 (5%)]\tLoss: 0.117751\n",
      "Train Epoch: 3 [2560/37519 (7%)]\tLoss: 0.117135\n",
      "Train Epoch: 3 [3200/37519 (9%)]\tLoss: 0.029329\n",
      "Train Epoch: 3 [3840/37519 (10%)]\tLoss: 0.184372\n",
      "Train Epoch: 3 [4480/37519 (12%)]\tLoss: 0.060092\n",
      "Train Epoch: 3 [5120/37519 (14%)]\tLoss: 0.116632\n",
      "Train Epoch: 3 [5760/37519 (15%)]\tLoss: 0.114729\n",
      "Train Epoch: 3 [6400/37519 (17%)]\tLoss: 0.088558\n",
      "Train Epoch: 3 [7040/37519 (19%)]\tLoss: 0.066468\n",
      "Train Epoch: 3 [7680/37519 (20%)]\tLoss: 0.040447\n",
      "Train Epoch: 3 [8320/37519 (22%)]\tLoss: 0.186187\n",
      "Train Epoch: 3 [8960/37519 (24%)]\tLoss: 0.101514\n",
      "Train Epoch: 3 [9600/37519 (26%)]\tLoss: 0.127811\n",
      "Train Epoch: 3 [10240/37519 (27%)]\tLoss: 0.172026\n",
      "Train Epoch: 3 [10880/37519 (29%)]\tLoss: 0.079647\n",
      "Train Epoch: 3 [11520/37519 (31%)]\tLoss: 0.045731\n",
      "Train Epoch: 3 [12160/37519 (32%)]\tLoss: 0.155905\n",
      "Train Epoch: 3 [12800/37519 (34%)]\tLoss: 0.039293\n",
      "Train Epoch: 3 [13440/37519 (36%)]\tLoss: 0.006514\n",
      "Train Epoch: 3 [14080/37519 (37%)]\tLoss: 0.035512\n",
      "Train Epoch: 3 [14720/37519 (39%)]\tLoss: 0.057923\n",
      "Train Epoch: 3 [15360/37519 (41%)]\tLoss: 0.023181\n",
      "Train Epoch: 3 [16000/37519 (43%)]\tLoss: 0.127854\n",
      "Train Epoch: 3 [16640/37519 (44%)]\tLoss: 0.059885\n",
      "Train Epoch: 3 [17280/37519 (46%)]\tLoss: 0.145918\n",
      "Train Epoch: 3 [17920/37519 (48%)]\tLoss: 0.025738\n",
      "Train Epoch: 3 [18560/37519 (49%)]\tLoss: 0.087641\n",
      "Train Epoch: 3 [19200/37519 (51%)]\tLoss: 0.151717\n",
      "Train Epoch: 3 [19840/37519 (53%)]\tLoss: 0.193148\n",
      "Train Epoch: 3 [20480/37519 (55%)]\tLoss: 0.021320\n",
      "Train Epoch: 3 [21120/37519 (56%)]\tLoss: 0.039727\n",
      "Train Epoch: 3 [21760/37519 (58%)]\tLoss: 0.033289\n",
      "Train Epoch: 3 [22400/37519 (60%)]\tLoss: 0.144872\n",
      "Train Epoch: 3 [23040/37519 (61%)]\tLoss: 0.127623\n",
      "Train Epoch: 3 [23680/37519 (63%)]\tLoss: 0.101137\n",
      "Train Epoch: 3 [24320/37519 (65%)]\tLoss: 0.098412\n",
      "Train Epoch: 3 [24960/37519 (66%)]\tLoss: 0.199217\n",
      "Train Epoch: 3 [25600/37519 (68%)]\tLoss: 0.080802\n",
      "Train Epoch: 3 [26240/37519 (70%)]\tLoss: 0.048919\n",
      "Train Epoch: 3 [26880/37519 (72%)]\tLoss: 0.109791\n",
      "Train Epoch: 3 [27520/37519 (73%)]\tLoss: 0.118823\n",
      "Train Epoch: 3 [28160/37519 (75%)]\tLoss: 0.043592\n",
      "Train Epoch: 3 [28800/37519 (77%)]\tLoss: 0.008412\n",
      "Train Epoch: 3 [29440/37519 (78%)]\tLoss: 0.099809\n",
      "Train Epoch: 3 [30080/37519 (80%)]\tLoss: 0.176494\n",
      "Train Epoch: 3 [30720/37519 (82%)]\tLoss: 0.085428\n",
      "Train Epoch: 3 [31360/37519 (83%)]\tLoss: 0.165795\n",
      "Train Epoch: 3 [32000/37519 (85%)]\tLoss: 0.131920\n",
      "Train Epoch: 3 [32640/37519 (87%)]\tLoss: 0.205056\n",
      "Train Epoch: 3 [33280/37519 (89%)]\tLoss: 0.041856\n",
      "Train Epoch: 3 [33920/37519 (90%)]\tLoss: 0.086940\n",
      "Train Epoch: 3 [34560/37519 (92%)]\tLoss: 0.075445\n",
      "Train Epoch: 3 [35200/37519 (94%)]\tLoss: 0.148915\n",
      "Train Epoch: 3 [35840/37519 (95%)]\tLoss: 0.063451\n",
      "Train Epoch: 3 [36480/37519 (97%)]\tLoss: 0.212417\n",
      "Train Epoch: 3 [37120/37519 (99%)]\tLoss: 0.043125\n",
      "Train Epoch: 4 [0/37519 (0%)]\tLoss: 0.125041\n",
      "Train Epoch: 4 [640/37519 (2%)]\tLoss: 0.019315\n",
      "Train Epoch: 4 [1280/37519 (3%)]\tLoss: 0.061076\n",
      "Train Epoch: 4 [1920/37519 (5%)]\tLoss: 0.064699\n",
      "Train Epoch: 4 [2560/37519 (7%)]\tLoss: 0.042197\n",
      "Train Epoch: 4 [3200/37519 (9%)]\tLoss: 0.148639\n",
      "Train Epoch: 4 [3840/37519 (10%)]\tLoss: 0.132800\n",
      "Train Epoch: 4 [4480/37519 (12%)]\tLoss: 0.071301\n",
      "Train Epoch: 4 [5120/37519 (14%)]\tLoss: 0.034009\n",
      "Train Epoch: 4 [5760/37519 (15%)]\tLoss: 0.076426\n",
      "Train Epoch: 4 [6400/37519 (17%)]\tLoss: 0.153576\n",
      "Train Epoch: 4 [7040/37519 (19%)]\tLoss: 0.143985\n",
      "Train Epoch: 4 [7680/37519 (20%)]\tLoss: 0.140621\n",
      "Train Epoch: 4 [8320/37519 (22%)]\tLoss: 0.014703\n",
      "Train Epoch: 4 [8960/37519 (24%)]\tLoss: 0.112939\n",
      "Train Epoch: 4 [9600/37519 (26%)]\tLoss: 0.080247\n",
      "Train Epoch: 4 [10240/37519 (27%)]\tLoss: 0.137892\n",
      "Train Epoch: 4 [10880/37519 (29%)]\tLoss: 0.117510\n",
      "Train Epoch: 4 [11520/37519 (31%)]\tLoss: 0.128829\n",
      "Train Epoch: 4 [12160/37519 (32%)]\tLoss: 0.066334\n",
      "Train Epoch: 4 [12800/37519 (34%)]\tLoss: 0.051937\n",
      "Train Epoch: 4 [13440/37519 (36%)]\tLoss: 0.027864\n",
      "Train Epoch: 4 [14080/37519 (37%)]\tLoss: 0.246984\n",
      "Train Epoch: 4 [14720/37519 (39%)]\tLoss: 0.062060\n",
      "Train Epoch: 4 [15360/37519 (41%)]\tLoss: 0.069219\n",
      "Train Epoch: 4 [16000/37519 (43%)]\tLoss: 0.107650\n",
      "Train Epoch: 4 [16640/37519 (44%)]\tLoss: 0.225354\n",
      "Train Epoch: 4 [17280/37519 (46%)]\tLoss: 0.023432\n",
      "Train Epoch: 4 [17920/37519 (48%)]\tLoss: 0.245946\n",
      "Train Epoch: 4 [18560/37519 (49%)]\tLoss: 0.196505\n",
      "Train Epoch: 4 [19200/37519 (51%)]\tLoss: 0.096148\n",
      "Train Epoch: 4 [19840/37519 (53%)]\tLoss: 0.043897\n",
      "Train Epoch: 4 [20480/37519 (55%)]\tLoss: 0.130911\n",
      "Train Epoch: 4 [21120/37519 (56%)]\tLoss: 0.086919\n",
      "Train Epoch: 4 [21760/37519 (58%)]\tLoss: 0.091699\n",
      "Train Epoch: 4 [22400/37519 (60%)]\tLoss: 0.010670\n",
      "Train Epoch: 4 [23040/37519 (61%)]\tLoss: 0.050688\n",
      "Train Epoch: 4 [23680/37519 (63%)]\tLoss: 0.162967\n",
      "Train Epoch: 4 [24320/37519 (65%)]\tLoss: 0.022666\n",
      "Train Epoch: 4 [24960/37519 (66%)]\tLoss: 0.017905\n",
      "Train Epoch: 4 [25600/37519 (68%)]\tLoss: 0.120341\n",
      "Train Epoch: 4 [26240/37519 (70%)]\tLoss: 0.070844\n",
      "Train Epoch: 4 [26880/37519 (72%)]\tLoss: 0.052013\n",
      "Train Epoch: 4 [27520/37519 (73%)]\tLoss: 0.045287\n",
      "Train Epoch: 4 [28160/37519 (75%)]\tLoss: 0.336593\n",
      "Train Epoch: 4 [28800/37519 (77%)]\tLoss: 0.058158\n",
      "Train Epoch: 4 [29440/37519 (78%)]\tLoss: 0.020338\n",
      "Train Epoch: 4 [30080/37519 (80%)]\tLoss: 0.055123\n",
      "Train Epoch: 4 [30720/37519 (82%)]\tLoss: 0.162129\n",
      "Train Epoch: 4 [31360/37519 (83%)]\tLoss: 0.083138\n",
      "Train Epoch: 4 [32000/37519 (85%)]\tLoss: 0.014134\n",
      "Train Epoch: 4 [32640/37519 (87%)]\tLoss: 0.025783\n",
      "Train Epoch: 4 [33280/37519 (89%)]\tLoss: 0.150107\n",
      "Train Epoch: 4 [33920/37519 (90%)]\tLoss: 0.037855\n",
      "Train Epoch: 4 [34560/37519 (92%)]\tLoss: 0.022356\n",
      "Train Epoch: 4 [35200/37519 (94%)]\tLoss: 0.037898\n",
      "Train Epoch: 4 [35840/37519 (95%)]\tLoss: 0.171531\n",
      "Train Epoch: 4 [36480/37519 (97%)]\tLoss: 0.089786\n",
      "Train Epoch: 4 [37120/37519 (99%)]\tLoss: 0.135626\n",
      "Train Epoch: 5 [0/37519 (0%)]\tLoss: 0.045721\n",
      "Train Epoch: 5 [640/37519 (2%)]\tLoss: 0.044327\n",
      "Train Epoch: 5 [1280/37519 (3%)]\tLoss: 0.187384\n",
      "Train Epoch: 5 [1920/37519 (5%)]\tLoss: 0.147434\n",
      "Train Epoch: 5 [2560/37519 (7%)]\tLoss: 0.074470\n",
      "Train Epoch: 5 [3200/37519 (9%)]\tLoss: 0.074241\n",
      "Train Epoch: 5 [3840/37519 (10%)]\tLoss: 0.096138\n",
      "Train Epoch: 5 [4480/37519 (12%)]\tLoss: 0.044715\n",
      "Train Epoch: 5 [5120/37519 (14%)]\tLoss: 0.032549\n",
      "Train Epoch: 5 [5760/37519 (15%)]\tLoss: 0.039153\n",
      "Train Epoch: 5 [6400/37519 (17%)]\tLoss: 0.043408\n",
      "Train Epoch: 5 [7040/37519 (19%)]\tLoss: 0.068103\n",
      "Train Epoch: 5 [7680/37519 (20%)]\tLoss: 0.074100\n",
      "Train Epoch: 5 [8320/37519 (22%)]\tLoss: 0.248271\n",
      "Train Epoch: 5 [8960/37519 (24%)]\tLoss: 0.098398\n",
      "Train Epoch: 5 [9600/37519 (26%)]\tLoss: 0.107194\n",
      "Train Epoch: 5 [10240/37519 (27%)]\tLoss: 0.035711\n",
      "Train Epoch: 5 [10880/37519 (29%)]\tLoss: 0.077081\n",
      "Train Epoch: 5 [11520/37519 (31%)]\tLoss: 0.223855\n",
      "Train Epoch: 5 [12160/37519 (32%)]\tLoss: 0.082723\n",
      "Train Epoch: 5 [12800/37519 (34%)]\tLoss: 0.173811\n",
      "Train Epoch: 5 [13440/37519 (36%)]\tLoss: 0.064129\n",
      "Train Epoch: 5 [14080/37519 (37%)]\tLoss: 0.075663\n",
      "Train Epoch: 5 [14720/37519 (39%)]\tLoss: 0.203097\n",
      "Train Epoch: 5 [15360/37519 (41%)]\tLoss: 0.193618\n",
      "Train Epoch: 5 [16000/37519 (43%)]\tLoss: 0.101843\n",
      "Train Epoch: 5 [16640/37519 (44%)]\tLoss: 0.064308\n",
      "Train Epoch: 5 [17280/37519 (46%)]\tLoss: 0.061755\n",
      "Train Epoch: 5 [17920/37519 (48%)]\tLoss: 0.149237\n",
      "Train Epoch: 5 [18560/37519 (49%)]\tLoss: 0.076752\n",
      "Train Epoch: 5 [19200/37519 (51%)]\tLoss: 0.049517\n",
      "Train Epoch: 5 [19840/37519 (53%)]\tLoss: 0.165473\n",
      "Train Epoch: 5 [20480/37519 (55%)]\tLoss: 0.067704\n",
      "Train Epoch: 5 [21120/37519 (56%)]\tLoss: 0.090511\n",
      "Train Epoch: 5 [21760/37519 (58%)]\tLoss: 0.209051\n",
      "Train Epoch: 5 [22400/37519 (60%)]\tLoss: 0.021737\n",
      "Train Epoch: 5 [23040/37519 (61%)]\tLoss: 0.094737\n",
      "Train Epoch: 5 [23680/37519 (63%)]\tLoss: 0.166450\n",
      "Train Epoch: 5 [24320/37519 (65%)]\tLoss: 0.090053\n",
      "Train Epoch: 5 [24960/37519 (66%)]\tLoss: 0.102657\n",
      "Train Epoch: 5 [25600/37519 (68%)]\tLoss: 0.078525\n",
      "Train Epoch: 5 [26240/37519 (70%)]\tLoss: 0.256425\n",
      "Train Epoch: 5 [26880/37519 (72%)]\tLoss: 0.047320\n",
      "Train Epoch: 5 [27520/37519 (73%)]\tLoss: 0.018116\n",
      "Train Epoch: 5 [28160/37519 (75%)]\tLoss: 0.031793\n",
      "Train Epoch: 5 [28800/37519 (77%)]\tLoss: 0.100547\n",
      "Train Epoch: 5 [29440/37519 (78%)]\tLoss: 0.096435\n",
      "Train Epoch: 5 [30080/37519 (80%)]\tLoss: 0.154367\n",
      "Train Epoch: 5 [30720/37519 (82%)]\tLoss: 0.096231\n",
      "Train Epoch: 5 [31360/37519 (83%)]\tLoss: 0.136635\n",
      "Train Epoch: 5 [32000/37519 (85%)]\tLoss: 0.065957\n",
      "Train Epoch: 5 [32640/37519 (87%)]\tLoss: 0.057791\n",
      "Train Epoch: 5 [33280/37519 (89%)]\tLoss: 0.445165\n",
      "Train Epoch: 5 [33920/37519 (90%)]\tLoss: 0.029413\n",
      "Train Epoch: 5 [34560/37519 (92%)]\tLoss: 0.183088\n",
      "Train Epoch: 5 [35200/37519 (94%)]\tLoss: 0.086229\n",
      "Train Epoch: 5 [35840/37519 (95%)]\tLoss: 0.119979\n",
      "Train Epoch: 5 [36480/37519 (97%)]\tLoss: 0.047009\n",
      "Train Epoch: 5 [37120/37519 (99%)]\tLoss: 0.044612\n",
      "Train Epoch: 6 [0/37519 (0%)]\tLoss: 0.067782\n",
      "Train Epoch: 6 [640/37519 (2%)]\tLoss: 0.250728\n",
      "Train Epoch: 6 [1280/37519 (3%)]\tLoss: 0.190268\n",
      "Train Epoch: 6 [1920/37519 (5%)]\tLoss: 0.060095\n",
      "Train Epoch: 6 [2560/37519 (7%)]\tLoss: 0.108813\n",
      "Train Epoch: 6 [3200/37519 (9%)]\tLoss: 0.049925\n",
      "Train Epoch: 6 [3840/37519 (10%)]\tLoss: 0.080136\n",
      "Train Epoch: 6 [4480/37519 (12%)]\tLoss: 0.009198\n",
      "Train Epoch: 6 [5120/37519 (14%)]\tLoss: 0.061200\n",
      "Train Epoch: 6 [5760/37519 (15%)]\tLoss: 0.110613\n",
      "Train Epoch: 6 [6400/37519 (17%)]\tLoss: 0.041545\n",
      "Train Epoch: 6 [7040/37519 (19%)]\tLoss: 0.098028\n",
      "Train Epoch: 6 [7680/37519 (20%)]\tLoss: 0.019639\n",
      "Train Epoch: 6 [8320/37519 (22%)]\tLoss: 0.043682\n",
      "Train Epoch: 6 [8960/37519 (24%)]\tLoss: 0.179913\n",
      "Train Epoch: 6 [9600/37519 (26%)]\tLoss: 0.091240\n",
      "Train Epoch: 6 [10240/37519 (27%)]\tLoss: 0.034018\n",
      "Train Epoch: 6 [10880/37519 (29%)]\tLoss: 0.127919\n",
      "Train Epoch: 6 [11520/37519 (31%)]\tLoss: 0.105913\n",
      "Train Epoch: 6 [12160/37519 (32%)]\tLoss: 0.129065\n",
      "Train Epoch: 6 [12800/37519 (34%)]\tLoss: 0.062876\n",
      "Train Epoch: 6 [13440/37519 (36%)]\tLoss: 0.107131\n",
      "Train Epoch: 6 [14080/37519 (37%)]\tLoss: 0.121167\n",
      "Train Epoch: 6 [14720/37519 (39%)]\tLoss: 0.120762\n",
      "Train Epoch: 6 [15360/37519 (41%)]\tLoss: 0.079500\n",
      "Train Epoch: 6 [16000/37519 (43%)]\tLoss: 0.218850\n",
      "Train Epoch: 6 [16640/37519 (44%)]\tLoss: 0.048703\n",
      "Train Epoch: 6 [17280/37519 (46%)]\tLoss: 0.191056\n",
      "Train Epoch: 6 [17920/37519 (48%)]\tLoss: 0.159828\n",
      "Train Epoch: 6 [18560/37519 (49%)]\tLoss: 0.160311\n",
      "Train Epoch: 6 [19200/37519 (51%)]\tLoss: 0.126822\n",
      "Train Epoch: 6 [19840/37519 (53%)]\tLoss: 0.087761\n",
      "Train Epoch: 6 [20480/37519 (55%)]\tLoss: 0.040865\n",
      "Train Epoch: 6 [21120/37519 (56%)]\tLoss: 0.444454\n",
      "Train Epoch: 6 [21760/37519 (58%)]\tLoss: 0.135428\n",
      "Train Epoch: 6 [22400/37519 (60%)]\tLoss: 0.116951\n",
      "Train Epoch: 6 [23040/37519 (61%)]\tLoss: 0.080711\n",
      "Train Epoch: 6 [23680/37519 (63%)]\tLoss: 0.131835\n",
      "Train Epoch: 6 [24320/37519 (65%)]\tLoss: 0.038085\n",
      "Train Epoch: 6 [24960/37519 (66%)]\tLoss: 0.033878\n",
      "Train Epoch: 6 [25600/37519 (68%)]\tLoss: 0.187413\n",
      "Train Epoch: 6 [26240/37519 (70%)]\tLoss: 0.025975\n",
      "Train Epoch: 6 [26880/37519 (72%)]\tLoss: 0.332943\n",
      "Train Epoch: 6 [27520/37519 (73%)]\tLoss: 0.027155\n",
      "Train Epoch: 6 [28160/37519 (75%)]\tLoss: 0.093023\n",
      "Train Epoch: 6 [28800/37519 (77%)]\tLoss: 0.071234\n",
      "Train Epoch: 6 [29440/37519 (78%)]\tLoss: 0.141620\n",
      "Train Epoch: 6 [30080/37519 (80%)]\tLoss: 0.090225\n",
      "Train Epoch: 6 [30720/37519 (82%)]\tLoss: 0.081581\n",
      "Train Epoch: 6 [31360/37519 (83%)]\tLoss: 0.086273\n",
      "Train Epoch: 6 [32000/37519 (85%)]\tLoss: 0.179354\n",
      "Train Epoch: 6 [32640/37519 (87%)]\tLoss: 0.149088\n",
      "Train Epoch: 6 [33280/37519 (89%)]\tLoss: 0.055127\n",
      "Train Epoch: 6 [33920/37519 (90%)]\tLoss: 0.079304\n",
      "Train Epoch: 6 [34560/37519 (92%)]\tLoss: 0.016823\n",
      "Train Epoch: 6 [35200/37519 (94%)]\tLoss: 0.066624\n",
      "Train Epoch: 6 [35840/37519 (95%)]\tLoss: 0.062679\n",
      "Train Epoch: 6 [36480/37519 (97%)]\tLoss: 0.044312\n",
      "Train Epoch: 6 [37120/37519 (99%)]\tLoss: 0.151730\n",
      "Train Epoch: 7 [0/37519 (0%)]\tLoss: 0.231224\n",
      "Train Epoch: 7 [640/37519 (2%)]\tLoss: 0.175707\n",
      "Train Epoch: 7 [1280/37519 (3%)]\tLoss: 0.111004\n",
      "Train Epoch: 7 [1920/37519 (5%)]\tLoss: 0.033348\n",
      "Train Epoch: 7 [2560/37519 (7%)]\tLoss: 0.062494\n",
      "Train Epoch: 7 [3200/37519 (9%)]\tLoss: 0.189679\n",
      "Train Epoch: 7 [3840/37519 (10%)]\tLoss: 0.135176\n",
      "Train Epoch: 7 [4480/37519 (12%)]\tLoss: 0.073240\n",
      "Train Epoch: 7 [5120/37519 (14%)]\tLoss: 0.068546\n",
      "Train Epoch: 7 [5760/37519 (15%)]\tLoss: 0.090928\n",
      "Train Epoch: 7 [6400/37519 (17%)]\tLoss: 0.047398\n",
      "Train Epoch: 7 [7040/37519 (19%)]\tLoss: 0.103117\n",
      "Train Epoch: 7 [7680/37519 (20%)]\tLoss: 0.193699\n",
      "Train Epoch: 7 [8320/37519 (22%)]\tLoss: 0.050346\n",
      "Train Epoch: 7 [8960/37519 (24%)]\tLoss: 0.190548\n",
      "Train Epoch: 7 [9600/37519 (26%)]\tLoss: 0.048519\n",
      "Train Epoch: 7 [10240/37519 (27%)]\tLoss: 0.080393\n",
      "Train Epoch: 7 [10880/37519 (29%)]\tLoss: 0.080768\n",
      "Train Epoch: 7 [11520/37519 (31%)]\tLoss: 0.048771\n",
      "Train Epoch: 7 [12160/37519 (32%)]\tLoss: 0.105368\n",
      "Train Epoch: 7 [12800/37519 (34%)]\tLoss: 0.096369\n",
      "Train Epoch: 7 [13440/37519 (36%)]\tLoss: 0.053360\n",
      "Train Epoch: 7 [14080/37519 (37%)]\tLoss: 0.108610\n",
      "Train Epoch: 7 [14720/37519 (39%)]\tLoss: 0.053680\n",
      "Train Epoch: 7 [15360/37519 (41%)]\tLoss: 0.118388\n",
      "Train Epoch: 7 [16000/37519 (43%)]\tLoss: 0.023997\n",
      "Train Epoch: 7 [16640/37519 (44%)]\tLoss: 0.028596\n",
      "Train Epoch: 7 [17280/37519 (46%)]\tLoss: 0.307364\n",
      "Train Epoch: 7 [17920/37519 (48%)]\tLoss: 0.049875\n",
      "Train Epoch: 7 [18560/37519 (49%)]\tLoss: 0.033634\n",
      "Train Epoch: 7 [19200/37519 (51%)]\tLoss: 0.037697\n",
      "Train Epoch: 7 [19840/37519 (53%)]\tLoss: 0.119519\n",
      "Train Epoch: 7 [20480/37519 (55%)]\tLoss: 0.101305\n",
      "Train Epoch: 7 [21120/37519 (56%)]\tLoss: 0.145986\n",
      "Train Epoch: 7 [21760/37519 (58%)]\tLoss: 0.114815\n",
      "Train Epoch: 7 [22400/37519 (60%)]\tLoss: 0.047269\n",
      "Train Epoch: 7 [23040/37519 (61%)]\tLoss: 0.018923\n",
      "Train Epoch: 7 [23680/37519 (63%)]\tLoss: 0.066917\n",
      "Train Epoch: 7 [24320/37519 (65%)]\tLoss: 0.154991\n",
      "Train Epoch: 7 [24960/37519 (66%)]\tLoss: 0.072493\n",
      "Train Epoch: 7 [25600/37519 (68%)]\tLoss: 0.034130\n",
      "Train Epoch: 7 [26240/37519 (70%)]\tLoss: 0.113263\n",
      "Train Epoch: 7 [26880/37519 (72%)]\tLoss: 0.064461\n",
      "Train Epoch: 7 [27520/37519 (73%)]\tLoss: 0.149920\n",
      "Train Epoch: 7 [28160/37519 (75%)]\tLoss: 0.164869\n",
      "Train Epoch: 7 [28800/37519 (77%)]\tLoss: 0.084129\n",
      "Train Epoch: 7 [29440/37519 (78%)]\tLoss: 0.118632\n",
      "Train Epoch: 7 [30080/37519 (80%)]\tLoss: 0.240408\n",
      "Train Epoch: 7 [30720/37519 (82%)]\tLoss: 0.133896\n",
      "Train Epoch: 7 [31360/37519 (83%)]\tLoss: 0.043504\n",
      "Train Epoch: 7 [32000/37519 (85%)]\tLoss: 0.104905\n",
      "Train Epoch: 7 [32640/37519 (87%)]\tLoss: 0.028001\n",
      "Train Epoch: 7 [33280/37519 (89%)]\tLoss: 0.100970\n",
      "Train Epoch: 7 [33920/37519 (90%)]\tLoss: 0.076581\n",
      "Train Epoch: 7 [34560/37519 (92%)]\tLoss: 0.062685\n",
      "Train Epoch: 7 [35200/37519 (94%)]\tLoss: 0.109237\n",
      "Train Epoch: 7 [35840/37519 (95%)]\tLoss: 0.214063\n",
      "Train Epoch: 7 [36480/37519 (97%)]\tLoss: 0.069723\n",
      "Train Epoch: 7 [37120/37519 (99%)]\tLoss: 0.048014\n",
      "Train Epoch: 8 [0/37519 (0%)]\tLoss: 0.144248\n",
      "Train Epoch: 8 [640/37519 (2%)]\tLoss: 0.010387\n",
      "Train Epoch: 8 [1280/37519 (3%)]\tLoss: 0.062230\n",
      "Train Epoch: 8 [1920/37519 (5%)]\tLoss: 0.076253\n",
      "Train Epoch: 8 [2560/37519 (7%)]\tLoss: 0.083563\n",
      "Train Epoch: 8 [3200/37519 (9%)]\tLoss: 0.051062\n",
      "Train Epoch: 8 [3840/37519 (10%)]\tLoss: 0.038105\n",
      "Train Epoch: 8 [4480/37519 (12%)]\tLoss: 0.063393\n",
      "Train Epoch: 8 [5120/37519 (14%)]\tLoss: 0.064176\n",
      "Train Epoch: 8 [5760/37519 (15%)]\tLoss: 0.046930\n",
      "Train Epoch: 8 [6400/37519 (17%)]\tLoss: 0.038886\n",
      "Train Epoch: 8 [7040/37519 (19%)]\tLoss: 0.055483\n",
      "Train Epoch: 8 [7680/37519 (20%)]\tLoss: 0.246630\n",
      "Train Epoch: 8 [8320/37519 (22%)]\tLoss: 0.025863\n",
      "Train Epoch: 8 [8960/37519 (24%)]\tLoss: 0.176098\n",
      "Train Epoch: 8 [9600/37519 (26%)]\tLoss: 0.114996\n",
      "Train Epoch: 8 [10240/37519 (27%)]\tLoss: 0.078322\n",
      "Train Epoch: 8 [10880/37519 (29%)]\tLoss: 0.195194\n",
      "Train Epoch: 8 [11520/37519 (31%)]\tLoss: 0.121214\n",
      "Train Epoch: 8 [12160/37519 (32%)]\tLoss: 0.131248\n",
      "Train Epoch: 8 [12800/37519 (34%)]\tLoss: 0.098622\n",
      "Train Epoch: 8 [13440/37519 (36%)]\tLoss: 0.061155\n",
      "Train Epoch: 8 [14080/37519 (37%)]\tLoss: 0.043905\n",
      "Train Epoch: 8 [14720/37519 (39%)]\tLoss: 0.084240\n",
      "Train Epoch: 8 [15360/37519 (41%)]\tLoss: 0.049353\n",
      "Train Epoch: 8 [16000/37519 (43%)]\tLoss: 0.091396\n",
      "Train Epoch: 8 [16640/37519 (44%)]\tLoss: 0.061731\n",
      "Train Epoch: 8 [17280/37519 (46%)]\tLoss: 0.058828\n",
      "Train Epoch: 8 [17920/37519 (48%)]\tLoss: 0.046378\n",
      "Train Epoch: 8 [18560/37519 (49%)]\tLoss: 0.126761\n",
      "Train Epoch: 8 [19200/37519 (51%)]\tLoss: 0.179903\n",
      "Train Epoch: 8 [19840/37519 (53%)]\tLoss: 0.120514\n",
      "Train Epoch: 8 [20480/37519 (55%)]\tLoss: 0.063759\n",
      "Train Epoch: 8 [21120/37519 (56%)]\tLoss: 0.133444\n",
      "Train Epoch: 8 [21760/37519 (58%)]\tLoss: 0.032561\n",
      "Train Epoch: 8 [22400/37519 (60%)]\tLoss: 0.062910\n",
      "Train Epoch: 8 [23040/37519 (61%)]\tLoss: 0.094732\n",
      "Train Epoch: 8 [23680/37519 (63%)]\tLoss: 0.088237\n",
      "Train Epoch: 8 [24320/37519 (65%)]\tLoss: 0.161414\n",
      "Train Epoch: 8 [24960/37519 (66%)]\tLoss: 0.187621\n",
      "Train Epoch: 8 [25600/37519 (68%)]\tLoss: 0.077221\n",
      "Train Epoch: 8 [26240/37519 (70%)]\tLoss: 0.076103\n",
      "Train Epoch: 8 [26880/37519 (72%)]\tLoss: 0.055931\n",
      "Train Epoch: 8 [27520/37519 (73%)]\tLoss: 0.029641\n",
      "Train Epoch: 8 [28160/37519 (75%)]\tLoss: 0.089137\n",
      "Train Epoch: 8 [28800/37519 (77%)]\tLoss: 0.190098\n",
      "Train Epoch: 8 [29440/37519 (78%)]\tLoss: 0.078544\n",
      "Train Epoch: 8 [30080/37519 (80%)]\tLoss: 0.185475\n",
      "Train Epoch: 8 [30720/37519 (82%)]\tLoss: 0.126042\n",
      "Train Epoch: 8 [31360/37519 (83%)]\tLoss: 0.085842\n",
      "Train Epoch: 8 [32000/37519 (85%)]\tLoss: 0.060754\n",
      "Train Epoch: 8 [32640/37519 (87%)]\tLoss: 0.125508\n",
      "Train Epoch: 8 [33280/37519 (89%)]\tLoss: 0.055759\n",
      "Train Epoch: 8 [33920/37519 (90%)]\tLoss: 0.086978\n",
      "Train Epoch: 8 [34560/37519 (92%)]\tLoss: 0.123302\n",
      "Train Epoch: 8 [35200/37519 (94%)]\tLoss: 0.029583\n",
      "Train Epoch: 8 [35840/37519 (95%)]\tLoss: 0.113886\n",
      "Train Epoch: 8 [36480/37519 (97%)]\tLoss: 0.118016\n",
      "Train Epoch: 8 [37120/37519 (99%)]\tLoss: 0.037856\n",
      "Train Epoch: 9 [0/37519 (0%)]\tLoss: 0.174812\n",
      "Train Epoch: 9 [640/37519 (2%)]\tLoss: 0.323183\n",
      "Train Epoch: 9 [1280/37519 (3%)]\tLoss: 0.179571\n",
      "Train Epoch: 9 [1920/37519 (5%)]\tLoss: 0.045588\n",
      "Train Epoch: 9 [2560/37519 (7%)]\tLoss: 0.085451\n",
      "Train Epoch: 9 [3200/37519 (9%)]\tLoss: 0.109786\n",
      "Train Epoch: 9 [3840/37519 (10%)]\tLoss: 0.145491\n",
      "Train Epoch: 9 [4480/37519 (12%)]\tLoss: 0.114375\n",
      "Train Epoch: 9 [5120/37519 (14%)]\tLoss: 0.081090\n",
      "Train Epoch: 9 [5760/37519 (15%)]\tLoss: 0.092613\n",
      "Train Epoch: 9 [6400/37519 (17%)]\tLoss: 0.082848\n",
      "Train Epoch: 9 [7040/37519 (19%)]\tLoss: 0.161617\n",
      "Train Epoch: 9 [7680/37519 (20%)]\tLoss: 0.047603\n",
      "Train Epoch: 9 [8320/37519 (22%)]\tLoss: 0.061066\n",
      "Train Epoch: 9 [8960/37519 (24%)]\tLoss: 0.061883\n",
      "Train Epoch: 9 [9600/37519 (26%)]\tLoss: 0.176921\n",
      "Train Epoch: 9 [10240/37519 (27%)]\tLoss: 0.143416\n",
      "Train Epoch: 9 [10880/37519 (29%)]\tLoss: 0.090624\n",
      "Train Epoch: 9 [11520/37519 (31%)]\tLoss: 0.162144\n",
      "Train Epoch: 9 [12160/37519 (32%)]\tLoss: 0.046068\n",
      "Train Epoch: 9 [12800/37519 (34%)]\tLoss: 0.073632\n",
      "Train Epoch: 9 [13440/37519 (36%)]\tLoss: 0.086830\n",
      "Train Epoch: 9 [14080/37519 (37%)]\tLoss: 0.026993\n",
      "Train Epoch: 9 [14720/37519 (39%)]\tLoss: 0.067180\n",
      "Train Epoch: 9 [15360/37519 (41%)]\tLoss: 0.048025\n",
      "Train Epoch: 9 [16000/37519 (43%)]\tLoss: 0.096841\n",
      "Train Epoch: 9 [16640/37519 (44%)]\tLoss: 0.029952\n",
      "Train Epoch: 9 [17280/37519 (46%)]\tLoss: 0.136944\n",
      "Train Epoch: 9 [17920/37519 (48%)]\tLoss: 0.029336\n",
      "Train Epoch: 9 [18560/37519 (49%)]\tLoss: 0.024493\n",
      "Train Epoch: 9 [19200/37519 (51%)]\tLoss: 0.022127\n",
      "Train Epoch: 9 [19840/37519 (53%)]\tLoss: 0.138348\n",
      "Train Epoch: 9 [20480/37519 (55%)]\tLoss: 0.016735\n",
      "Train Epoch: 9 [21120/37519 (56%)]\tLoss: 0.242920\n",
      "Train Epoch: 9 [21760/37519 (58%)]\tLoss: 0.124153\n",
      "Train Epoch: 9 [22400/37519 (60%)]\tLoss: 0.041872\n",
      "Train Epoch: 9 [23040/37519 (61%)]\tLoss: 0.110817\n",
      "Train Epoch: 9 [23680/37519 (63%)]\tLoss: 0.046318\n",
      "Train Epoch: 9 [24320/37519 (65%)]\tLoss: 0.027859\n",
      "Train Epoch: 9 [24960/37519 (66%)]\tLoss: 0.054012\n",
      "Train Epoch: 9 [25600/37519 (68%)]\tLoss: 0.050819\n",
      "Train Epoch: 9 [26240/37519 (70%)]\tLoss: 0.183175\n",
      "Train Epoch: 9 [26880/37519 (72%)]\tLoss: 0.030786\n",
      "Train Epoch: 9 [27520/37519 (73%)]\tLoss: 0.021787\n",
      "Train Epoch: 9 [28160/37519 (75%)]\tLoss: 0.186513\n",
      "Train Epoch: 9 [28800/37519 (77%)]\tLoss: 0.053479\n",
      "Train Epoch: 9 [29440/37519 (78%)]\tLoss: 0.325284\n",
      "Train Epoch: 9 [30080/37519 (80%)]\tLoss: 0.150222\n",
      "Train Epoch: 9 [30720/37519 (82%)]\tLoss: 0.112241\n",
      "Train Epoch: 9 [31360/37519 (83%)]\tLoss: 0.050370\n",
      "Train Epoch: 9 [32000/37519 (85%)]\tLoss: 0.098360\n",
      "Train Epoch: 9 [32640/37519 (87%)]\tLoss: 0.177279\n",
      "Train Epoch: 9 [33280/37519 (89%)]\tLoss: 0.199287\n",
      "Train Epoch: 9 [33920/37519 (90%)]\tLoss: 0.083265\n",
      "Train Epoch: 9 [34560/37519 (92%)]\tLoss: 0.063158\n",
      "Train Epoch: 9 [35200/37519 (94%)]\tLoss: 0.142754\n",
      "Train Epoch: 9 [35840/37519 (95%)]\tLoss: 0.152411\n",
      "Train Epoch: 9 [36480/37519 (97%)]\tLoss: 0.224671\n",
      "Train Epoch: 9 [37120/37519 (99%)]\tLoss: 0.265407\n",
      "Train Epoch: 10 [0/37519 (0%)]\tLoss: 0.090539\n",
      "Train Epoch: 10 [640/37519 (2%)]\tLoss: 0.076483\n",
      "Train Epoch: 10 [1280/37519 (3%)]\tLoss: 0.131263\n",
      "Train Epoch: 10 [1920/37519 (5%)]\tLoss: 0.019300\n",
      "Train Epoch: 10 [2560/37519 (7%)]\tLoss: 0.137783\n",
      "Train Epoch: 10 [3200/37519 (9%)]\tLoss: 0.026464\n",
      "Train Epoch: 10 [3840/37519 (10%)]\tLoss: 0.073359\n",
      "Train Epoch: 10 [4480/37519 (12%)]\tLoss: 0.035348\n",
      "Train Epoch: 10 [5120/37519 (14%)]\tLoss: 0.106780\n",
      "Train Epoch: 10 [5760/37519 (15%)]\tLoss: 0.046385\n",
      "Train Epoch: 10 [6400/37519 (17%)]\tLoss: 0.036885\n",
      "Train Epoch: 10 [7040/37519 (19%)]\tLoss: 0.152645\n",
      "Train Epoch: 10 [7680/37519 (20%)]\tLoss: 0.047924\n",
      "Train Epoch: 10 [8320/37519 (22%)]\tLoss: 0.043408\n",
      "Train Epoch: 10 [8960/37519 (24%)]\tLoss: 0.130705\n",
      "Train Epoch: 10 [9600/37519 (26%)]\tLoss: 0.112525\n",
      "Train Epoch: 10 [10240/37519 (27%)]\tLoss: 0.109761\n",
      "Train Epoch: 10 [10880/37519 (29%)]\tLoss: 0.086710\n",
      "Train Epoch: 10 [11520/37519 (31%)]\tLoss: 0.094472\n",
      "Train Epoch: 10 [12160/37519 (32%)]\tLoss: 0.119101\n",
      "Train Epoch: 10 [12800/37519 (34%)]\tLoss: 0.179342\n",
      "Train Epoch: 10 [13440/37519 (36%)]\tLoss: 0.039801\n",
      "Train Epoch: 10 [14080/37519 (37%)]\tLoss: 0.202639\n",
      "Train Epoch: 10 [14720/37519 (39%)]\tLoss: 0.038063\n",
      "Train Epoch: 10 [15360/37519 (41%)]\tLoss: 0.056546\n",
      "Train Epoch: 10 [16000/37519 (43%)]\tLoss: 0.131866\n",
      "Train Epoch: 10 [16640/37519 (44%)]\tLoss: 0.031382\n",
      "Train Epoch: 10 [17280/37519 (46%)]\tLoss: 0.053985\n",
      "Train Epoch: 10 [17920/37519 (48%)]\tLoss: 0.101206\n",
      "Train Epoch: 10 [18560/37519 (49%)]\tLoss: 0.034613\n",
      "Train Epoch: 10 [19200/37519 (51%)]\tLoss: 0.147380\n",
      "Train Epoch: 10 [19840/37519 (53%)]\tLoss: 0.032022\n",
      "Train Epoch: 10 [20480/37519 (55%)]\tLoss: 0.044843\n",
      "Train Epoch: 10 [21120/37519 (56%)]\tLoss: 0.082868\n",
      "Train Epoch: 10 [21760/37519 (58%)]\tLoss: 0.084827\n",
      "Train Epoch: 10 [22400/37519 (60%)]\tLoss: 0.108021\n",
      "Train Epoch: 10 [23040/37519 (61%)]\tLoss: 0.021781\n",
      "Train Epoch: 10 [23680/37519 (63%)]\tLoss: 0.156710\n",
      "Train Epoch: 10 [24320/37519 (65%)]\tLoss: 0.114160\n",
      "Train Epoch: 10 [24960/37519 (66%)]\tLoss: 0.206719\n",
      "Train Epoch: 10 [25600/37519 (68%)]\tLoss: 0.105506\n",
      "Train Epoch: 10 [26240/37519 (70%)]\tLoss: 0.299350\n",
      "Train Epoch: 10 [26880/37519 (72%)]\tLoss: 0.115772\n",
      "Train Epoch: 10 [27520/37519 (73%)]\tLoss: 0.037571\n",
      "Train Epoch: 10 [28160/37519 (75%)]\tLoss: 0.132347\n",
      "Train Epoch: 10 [28800/37519 (77%)]\tLoss: 0.060858\n",
      "Train Epoch: 10 [29440/37519 (78%)]\tLoss: 0.107755\n",
      "Train Epoch: 10 [30080/37519 (80%)]\tLoss: 0.092638\n",
      "Train Epoch: 10 [30720/37519 (82%)]\tLoss: 0.043296\n",
      "Train Epoch: 10 [31360/37519 (83%)]\tLoss: 0.175683\n",
      "Train Epoch: 10 [32000/37519 (85%)]\tLoss: 0.099674\n",
      "Train Epoch: 10 [32640/37519 (87%)]\tLoss: 0.479702\n",
      "Train Epoch: 10 [33280/37519 (89%)]\tLoss: 0.025665\n",
      "Train Epoch: 10 [33920/37519 (90%)]\tLoss: 0.212281\n",
      "Train Epoch: 10 [34560/37519 (92%)]\tLoss: 0.054033\n",
      "Train Epoch: 10 [35200/37519 (94%)]\tLoss: 0.168682\n",
      "Train Epoch: 10 [35840/37519 (95%)]\tLoss: 0.031582\n",
      "Train Epoch: 10 [36480/37519 (97%)]\tLoss: 0.131455\n",
      "Train Epoch: 10 [37120/37519 (99%)]\tLoss: 0.095044\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/22481 (0%)]\tLoss: 0.277337\n",
      "Train Epoch: 1 [640/22481 (3%)]\tLoss: 0.365689\n",
      "Train Epoch: 1 [1280/22481 (6%)]\tLoss: 0.117534\n",
      "Train Epoch: 1 [1920/22481 (9%)]\tLoss: 0.216406\n",
      "Train Epoch: 1 [2560/22481 (11%)]\tLoss: 0.044246\n",
      "Train Epoch: 1 [3200/22481 (14%)]\tLoss: 0.156730\n",
      "Train Epoch: 1 [3840/22481 (17%)]\tLoss: 0.071860\n",
      "Train Epoch: 1 [4480/22481 (20%)]\tLoss: 0.072170\n",
      "Train Epoch: 1 [5120/22481 (23%)]\tLoss: 0.086423\n",
      "Train Epoch: 1 [5760/22481 (26%)]\tLoss: 0.122948\n",
      "Train Epoch: 1 [6400/22481 (28%)]\tLoss: 0.143540\n",
      "Train Epoch: 1 [7040/22481 (31%)]\tLoss: 0.060378\n",
      "Train Epoch: 1 [7680/22481 (34%)]\tLoss: 0.032940\n",
      "Train Epoch: 1 [8320/22481 (37%)]\tLoss: 0.054770\n",
      "Train Epoch: 1 [8960/22481 (40%)]\tLoss: 0.051840\n",
      "Train Epoch: 1 [9600/22481 (43%)]\tLoss: 0.192217\n",
      "Train Epoch: 1 [10240/22481 (45%)]\tLoss: 0.079803\n",
      "Train Epoch: 1 [10880/22481 (48%)]\tLoss: 0.030595\n",
      "Train Epoch: 1 [11520/22481 (51%)]\tLoss: 0.077074\n",
      "Train Epoch: 1 [12160/22481 (54%)]\tLoss: 0.111853\n",
      "Train Epoch: 1 [12800/22481 (57%)]\tLoss: 0.230628\n",
      "Train Epoch: 1 [13440/22481 (60%)]\tLoss: 0.082497\n",
      "Train Epoch: 1 [14080/22481 (62%)]\tLoss: 0.081835\n",
      "Train Epoch: 1 [14720/22481 (65%)]\tLoss: 0.131854\n",
      "Train Epoch: 1 [15360/22481 (68%)]\tLoss: 0.072642\n",
      "Train Epoch: 1 [16000/22481 (71%)]\tLoss: 0.191742\n",
      "Train Epoch: 1 [16640/22481 (74%)]\tLoss: 0.083347\n",
      "Train Epoch: 1 [17280/22481 (77%)]\tLoss: 0.093573\n",
      "Train Epoch: 1 [17920/22481 (80%)]\tLoss: 0.018171\n",
      "Train Epoch: 1 [18560/22481 (82%)]\tLoss: 0.074330\n",
      "Train Epoch: 1 [19200/22481 (85%)]\tLoss: 0.126241\n",
      "Train Epoch: 1 [19840/22481 (88%)]\tLoss: 0.063067\n",
      "Train Epoch: 1 [20480/22481 (91%)]\tLoss: 0.075831\n",
      "Train Epoch: 1 [21120/22481 (94%)]\tLoss: 0.233743\n",
      "Train Epoch: 1 [21760/22481 (97%)]\tLoss: 0.023174\n",
      "Train Epoch: 1 [22400/22481 (99%)]\tLoss: 0.094384\n",
      "Train Epoch: 2 [0/22481 (0%)]\tLoss: 0.108641\n",
      "Train Epoch: 2 [640/22481 (3%)]\tLoss: 0.048702\n",
      "Train Epoch: 2 [1280/22481 (6%)]\tLoss: 0.119657\n",
      "Train Epoch: 2 [1920/22481 (9%)]\tLoss: 0.198158\n",
      "Train Epoch: 2 [2560/22481 (11%)]\tLoss: 0.116873\n",
      "Train Epoch: 2 [3200/22481 (14%)]\tLoss: 0.088937\n",
      "Train Epoch: 2 [3840/22481 (17%)]\tLoss: 0.060151\n",
      "Train Epoch: 2 [4480/22481 (20%)]\tLoss: 0.035560\n",
      "Train Epoch: 2 [5120/22481 (23%)]\tLoss: 0.237003\n",
      "Train Epoch: 2 [5760/22481 (26%)]\tLoss: 0.056675\n",
      "Train Epoch: 2 [6400/22481 (28%)]\tLoss: 0.029680\n",
      "Train Epoch: 2 [7040/22481 (31%)]\tLoss: 0.191814\n",
      "Train Epoch: 2 [7680/22481 (34%)]\tLoss: 0.173075\n",
      "Train Epoch: 2 [8320/22481 (37%)]\tLoss: 0.060451\n",
      "Train Epoch: 2 [8960/22481 (40%)]\tLoss: 0.103674\n",
      "Train Epoch: 2 [9600/22481 (43%)]\tLoss: 0.064790\n",
      "Train Epoch: 2 [10240/22481 (45%)]\tLoss: 0.149741\n",
      "Train Epoch: 2 [10880/22481 (48%)]\tLoss: 0.123025\n",
      "Train Epoch: 2 [11520/22481 (51%)]\tLoss: 0.159458\n",
      "Train Epoch: 2 [12160/22481 (54%)]\tLoss: 0.095995\n",
      "Train Epoch: 2 [12800/22481 (57%)]\tLoss: 0.104454\n",
      "Train Epoch: 2 [13440/22481 (60%)]\tLoss: 0.157116\n",
      "Train Epoch: 2 [14080/22481 (62%)]\tLoss: 0.024512\n",
      "Train Epoch: 2 [14720/22481 (65%)]\tLoss: 0.048228\n",
      "Train Epoch: 2 [15360/22481 (68%)]\tLoss: 0.136830\n",
      "Train Epoch: 2 [16000/22481 (71%)]\tLoss: 0.108853\n",
      "Train Epoch: 2 [16640/22481 (74%)]\tLoss: 0.129933\n",
      "Train Epoch: 2 [17280/22481 (77%)]\tLoss: 0.161668\n",
      "Train Epoch: 2 [17920/22481 (80%)]\tLoss: 0.070317\n",
      "Train Epoch: 2 [18560/22481 (82%)]\tLoss: 0.086093\n",
      "Train Epoch: 2 [19200/22481 (85%)]\tLoss: 0.312301\n",
      "Train Epoch: 2 [19840/22481 (88%)]\tLoss: 0.309672\n",
      "Train Epoch: 2 [20480/22481 (91%)]\tLoss: 0.133892\n",
      "Train Epoch: 2 [21120/22481 (94%)]\tLoss: 0.086059\n",
      "Train Epoch: 2 [21760/22481 (97%)]\tLoss: 0.112630\n",
      "Train Epoch: 2 [22400/22481 (99%)]\tLoss: 0.132468\n",
      "Train Epoch: 3 [0/22481 (0%)]\tLoss: 0.087746\n",
      "Train Epoch: 3 [640/22481 (3%)]\tLoss: 0.076021\n",
      "Train Epoch: 3 [1280/22481 (6%)]\tLoss: 0.060350\n",
      "Train Epoch: 3 [1920/22481 (9%)]\tLoss: 0.179988\n",
      "Train Epoch: 3 [2560/22481 (11%)]\tLoss: 0.084975\n",
      "Train Epoch: 3 [3200/22481 (14%)]\tLoss: 0.043559\n",
      "Train Epoch: 3 [3840/22481 (17%)]\tLoss: 0.114268\n",
      "Train Epoch: 3 [4480/22481 (20%)]\tLoss: 0.058551\n",
      "Train Epoch: 3 [5120/22481 (23%)]\tLoss: 0.056863\n",
      "Train Epoch: 3 [5760/22481 (26%)]\tLoss: 0.149702\n",
      "Train Epoch: 3 [6400/22481 (28%)]\tLoss: 0.091510\n",
      "Train Epoch: 3 [7040/22481 (31%)]\tLoss: 0.199938\n",
      "Train Epoch: 3 [7680/22481 (34%)]\tLoss: 0.108789\n",
      "Train Epoch: 3 [8320/22481 (37%)]\tLoss: 0.087074\n",
      "Train Epoch: 3 [8960/22481 (40%)]\tLoss: 0.020172\n",
      "Train Epoch: 3 [9600/22481 (43%)]\tLoss: 0.068668\n",
      "Train Epoch: 3 [10240/22481 (45%)]\tLoss: 0.097241\n",
      "Train Epoch: 3 [10880/22481 (48%)]\tLoss: 0.194022\n",
      "Train Epoch: 3 [11520/22481 (51%)]\tLoss: 0.089047\n",
      "Train Epoch: 3 [12160/22481 (54%)]\tLoss: 0.021345\n",
      "Train Epoch: 3 [12800/22481 (57%)]\tLoss: 0.086787\n",
      "Train Epoch: 3 [13440/22481 (60%)]\tLoss: 0.132160\n",
      "Train Epoch: 3 [14080/22481 (62%)]\tLoss: 0.092891\n",
      "Train Epoch: 3 [14720/22481 (65%)]\tLoss: 0.072413\n",
      "Train Epoch: 3 [15360/22481 (68%)]\tLoss: 0.201771\n",
      "Train Epoch: 3 [16000/22481 (71%)]\tLoss: 0.145972\n",
      "Train Epoch: 3 [16640/22481 (74%)]\tLoss: 0.071933\n",
      "Train Epoch: 3 [17280/22481 (77%)]\tLoss: 0.094413\n",
      "Train Epoch: 3 [17920/22481 (80%)]\tLoss: 0.019605\n",
      "Train Epoch: 3 [18560/22481 (82%)]\tLoss: 0.072323\n",
      "Train Epoch: 3 [19200/22481 (85%)]\tLoss: 0.072888\n",
      "Train Epoch: 3 [19840/22481 (88%)]\tLoss: 0.035719\n",
      "Train Epoch: 3 [20480/22481 (91%)]\tLoss: 0.025593\n",
      "Train Epoch: 3 [21120/22481 (94%)]\tLoss: 0.087742\n",
      "Train Epoch: 3 [21760/22481 (97%)]\tLoss: 0.117520\n",
      "Train Epoch: 3 [22400/22481 (99%)]\tLoss: 0.121513\n",
      "Train Epoch: 4 [0/22481 (0%)]\tLoss: 0.088333\n",
      "Train Epoch: 4 [640/22481 (3%)]\tLoss: 0.035828\n",
      "Train Epoch: 4 [1280/22481 (6%)]\tLoss: 0.037393\n",
      "Train Epoch: 4 [1920/22481 (9%)]\tLoss: 0.164057\n",
      "Train Epoch: 4 [2560/22481 (11%)]\tLoss: 0.016449\n",
      "Train Epoch: 4 [3200/22481 (14%)]\tLoss: 0.017742\n",
      "Train Epoch: 4 [3840/22481 (17%)]\tLoss: 0.155449\n",
      "Train Epoch: 4 [4480/22481 (20%)]\tLoss: 0.062269\n",
      "Train Epoch: 4 [5120/22481 (23%)]\tLoss: 0.062119\n",
      "Train Epoch: 4 [5760/22481 (26%)]\tLoss: 0.028750\n",
      "Train Epoch: 4 [6400/22481 (28%)]\tLoss: 0.025627\n",
      "Train Epoch: 4 [7040/22481 (31%)]\tLoss: 0.056602\n",
      "Train Epoch: 4 [7680/22481 (34%)]\tLoss: 0.057069\n",
      "Train Epoch: 4 [8320/22481 (37%)]\tLoss: 0.051677\n",
      "Train Epoch: 4 [8960/22481 (40%)]\tLoss: 0.066620\n",
      "Train Epoch: 4 [9600/22481 (43%)]\tLoss: 0.126408\n",
      "Train Epoch: 4 [10240/22481 (45%)]\tLoss: 0.017773\n",
      "Train Epoch: 4 [10880/22481 (48%)]\tLoss: 0.027392\n",
      "Train Epoch: 4 [11520/22481 (51%)]\tLoss: 0.021750\n",
      "Train Epoch: 4 [12160/22481 (54%)]\tLoss: 0.145905\n",
      "Train Epoch: 4 [12800/22481 (57%)]\tLoss: 0.054317\n",
      "Train Epoch: 4 [13440/22481 (60%)]\tLoss: 0.047746\n",
      "Train Epoch: 4 [14080/22481 (62%)]\tLoss: 0.031021\n",
      "Train Epoch: 4 [14720/22481 (65%)]\tLoss: 0.051334\n",
      "Train Epoch: 4 [15360/22481 (68%)]\tLoss: 0.093493\n",
      "Train Epoch: 4 [16000/22481 (71%)]\tLoss: 0.010061\n",
      "Train Epoch: 4 [16640/22481 (74%)]\tLoss: 0.050078\n",
      "Train Epoch: 4 [17280/22481 (77%)]\tLoss: 0.096481\n",
      "Train Epoch: 4 [17920/22481 (80%)]\tLoss: 0.085096\n",
      "Train Epoch: 4 [18560/22481 (82%)]\tLoss: 0.113027\n",
      "Train Epoch: 4 [19200/22481 (85%)]\tLoss: 0.158139\n",
      "Train Epoch: 4 [19840/22481 (88%)]\tLoss: 0.027220\n",
      "Train Epoch: 4 [20480/22481 (91%)]\tLoss: 0.095230\n",
      "Train Epoch: 4 [21120/22481 (94%)]\tLoss: 0.124102\n",
      "Train Epoch: 4 [21760/22481 (97%)]\tLoss: 0.108028\n",
      "Train Epoch: 4 [22400/22481 (99%)]\tLoss: 0.043243\n",
      "Train Epoch: 5 [0/22481 (0%)]\tLoss: 0.119727\n",
      "Train Epoch: 5 [640/22481 (3%)]\tLoss: 0.033808\n",
      "Train Epoch: 5 [1280/22481 (6%)]\tLoss: 0.043870\n",
      "Train Epoch: 5 [1920/22481 (9%)]\tLoss: 0.020458\n",
      "Train Epoch: 5 [2560/22481 (11%)]\tLoss: 0.100629\n",
      "Train Epoch: 5 [3200/22481 (14%)]\tLoss: 0.137486\n",
      "Train Epoch: 5 [3840/22481 (17%)]\tLoss: 0.111847\n",
      "Train Epoch: 5 [4480/22481 (20%)]\tLoss: 0.093377\n",
      "Train Epoch: 5 [5120/22481 (23%)]\tLoss: 0.025418\n",
      "Train Epoch: 5 [5760/22481 (26%)]\tLoss: 0.071643\n",
      "Train Epoch: 5 [6400/22481 (28%)]\tLoss: 0.083566\n",
      "Train Epoch: 5 [7040/22481 (31%)]\tLoss: 0.077973\n",
      "Train Epoch: 5 [7680/22481 (34%)]\tLoss: 0.085424\n",
      "Train Epoch: 5 [8320/22481 (37%)]\tLoss: 0.055079\n",
      "Train Epoch: 5 [8960/22481 (40%)]\tLoss: 0.063953\n",
      "Train Epoch: 5 [9600/22481 (43%)]\tLoss: 0.289707\n",
      "Train Epoch: 5 [10240/22481 (45%)]\tLoss: 0.086738\n",
      "Train Epoch: 5 [10880/22481 (48%)]\tLoss: 0.094624\n",
      "Train Epoch: 5 [11520/22481 (51%)]\tLoss: 0.118552\n",
      "Train Epoch: 5 [12160/22481 (54%)]\tLoss: 0.088238\n",
      "Train Epoch: 5 [12800/22481 (57%)]\tLoss: 0.046631\n",
      "Train Epoch: 5 [13440/22481 (60%)]\tLoss: 0.105019\n",
      "Train Epoch: 5 [14080/22481 (62%)]\tLoss: 0.028491\n",
      "Train Epoch: 5 [14720/22481 (65%)]\tLoss: 0.095715\n",
      "Train Epoch: 5 [15360/22481 (68%)]\tLoss: 0.163968\n",
      "Train Epoch: 5 [16000/22481 (71%)]\tLoss: 0.104948\n",
      "Train Epoch: 5 [16640/22481 (74%)]\tLoss: 0.166067\n",
      "Train Epoch: 5 [17280/22481 (77%)]\tLoss: 0.017044\n",
      "Train Epoch: 5 [17920/22481 (80%)]\tLoss: 0.110131\n",
      "Train Epoch: 5 [18560/22481 (82%)]\tLoss: 0.013833\n",
      "Train Epoch: 5 [19200/22481 (85%)]\tLoss: 0.171009\n",
      "Train Epoch: 5 [19840/22481 (88%)]\tLoss: 0.106289\n",
      "Train Epoch: 5 [20480/22481 (91%)]\tLoss: 0.112010\n",
      "Train Epoch: 5 [21120/22481 (94%)]\tLoss: 0.028170\n",
      "Train Epoch: 5 [21760/22481 (97%)]\tLoss: 0.036436\n",
      "Train Epoch: 5 [22400/22481 (99%)]\tLoss: 0.241640\n",
      "Train Epoch: 6 [0/22481 (0%)]\tLoss: 0.162084\n",
      "Train Epoch: 6 [640/22481 (3%)]\tLoss: 0.040354\n",
      "Train Epoch: 6 [1280/22481 (6%)]\tLoss: 0.054996\n",
      "Train Epoch: 6 [1920/22481 (9%)]\tLoss: 0.039217\n",
      "Train Epoch: 6 [2560/22481 (11%)]\tLoss: 0.123480\n",
      "Train Epoch: 6 [3200/22481 (14%)]\tLoss: 0.112789\n",
      "Train Epoch: 6 [3840/22481 (17%)]\tLoss: 0.032646\n",
      "Train Epoch: 6 [4480/22481 (20%)]\tLoss: 0.102481\n",
      "Train Epoch: 6 [5120/22481 (23%)]\tLoss: 0.176771\n",
      "Train Epoch: 6 [5760/22481 (26%)]\tLoss: 0.088920\n",
      "Train Epoch: 6 [6400/22481 (28%)]\tLoss: 0.064322\n",
      "Train Epoch: 6 [7040/22481 (31%)]\tLoss: 0.028777\n",
      "Train Epoch: 6 [7680/22481 (34%)]\tLoss: 0.014022\n",
      "Train Epoch: 6 [8320/22481 (37%)]\tLoss: 0.106961\n",
      "Train Epoch: 6 [8960/22481 (40%)]\tLoss: 0.053881\n",
      "Train Epoch: 6 [9600/22481 (43%)]\tLoss: 0.303929\n",
      "Train Epoch: 6 [10240/22481 (45%)]\tLoss: 0.083493\n",
      "Train Epoch: 6 [10880/22481 (48%)]\tLoss: 0.128958\n",
      "Train Epoch: 6 [11520/22481 (51%)]\tLoss: 0.029458\n",
      "Train Epoch: 6 [12160/22481 (54%)]\tLoss: 0.080372\n",
      "Train Epoch: 6 [12800/22481 (57%)]\tLoss: 0.126770\n",
      "Train Epoch: 6 [13440/22481 (60%)]\tLoss: 0.019072\n",
      "Train Epoch: 6 [14080/22481 (62%)]\tLoss: 0.084474\n",
      "Train Epoch: 6 [14720/22481 (65%)]\tLoss: 0.065525\n",
      "Train Epoch: 6 [15360/22481 (68%)]\tLoss: 0.079909\n",
      "Train Epoch: 6 [16000/22481 (71%)]\tLoss: 0.116600\n",
      "Train Epoch: 6 [16640/22481 (74%)]\tLoss: 0.053549\n",
      "Train Epoch: 6 [17280/22481 (77%)]\tLoss: 0.117851\n",
      "Train Epoch: 6 [17920/22481 (80%)]\tLoss: 0.133599\n",
      "Train Epoch: 6 [18560/22481 (82%)]\tLoss: 0.126606\n",
      "Train Epoch: 6 [19200/22481 (85%)]\tLoss: 0.117149\n",
      "Train Epoch: 6 [19840/22481 (88%)]\tLoss: 0.144094\n",
      "Train Epoch: 6 [20480/22481 (91%)]\tLoss: 0.214235\n",
      "Train Epoch: 6 [21120/22481 (94%)]\tLoss: 0.035976\n",
      "Train Epoch: 6 [21760/22481 (97%)]\tLoss: 0.080304\n",
      "Train Epoch: 6 [22400/22481 (99%)]\tLoss: 0.027978\n",
      "Train Epoch: 7 [0/22481 (0%)]\tLoss: 0.124132\n",
      "Train Epoch: 7 [640/22481 (3%)]\tLoss: 0.018613\n",
      "Train Epoch: 7 [1280/22481 (6%)]\tLoss: 0.144419\n",
      "Train Epoch: 7 [1920/22481 (9%)]\tLoss: 0.141451\n",
      "Train Epoch: 7 [2560/22481 (11%)]\tLoss: 0.087152\n",
      "Train Epoch: 7 [3200/22481 (14%)]\tLoss: 0.233411\n",
      "Train Epoch: 7 [3840/22481 (17%)]\tLoss: 0.038611\n",
      "Train Epoch: 7 [4480/22481 (20%)]\tLoss: 0.050942\n",
      "Train Epoch: 7 [5120/22481 (23%)]\tLoss: 0.116076\n",
      "Train Epoch: 7 [5760/22481 (26%)]\tLoss: 0.021101\n",
      "Train Epoch: 7 [6400/22481 (28%)]\tLoss: 0.062074\n",
      "Train Epoch: 7 [7040/22481 (31%)]\tLoss: 0.218663\n",
      "Train Epoch: 7 [7680/22481 (34%)]\tLoss: 0.103206\n",
      "Train Epoch: 7 [8320/22481 (37%)]\tLoss: 0.008521\n",
      "Train Epoch: 7 [8960/22481 (40%)]\tLoss: 0.129979\n",
      "Train Epoch: 7 [9600/22481 (43%)]\tLoss: 0.089758\n",
      "Train Epoch: 7 [10240/22481 (45%)]\tLoss: 0.068422\n",
      "Train Epoch: 7 [10880/22481 (48%)]\tLoss: 0.019296\n",
      "Train Epoch: 7 [11520/22481 (51%)]\tLoss: 0.070323\n",
      "Train Epoch: 7 [12160/22481 (54%)]\tLoss: 0.197489\n",
      "Train Epoch: 7 [12800/22481 (57%)]\tLoss: 0.201018\n",
      "Train Epoch: 7 [13440/22481 (60%)]\tLoss: 0.152459\n",
      "Train Epoch: 7 [14080/22481 (62%)]\tLoss: 0.090889\n",
      "Train Epoch: 7 [14720/22481 (65%)]\tLoss: 0.080743\n",
      "Train Epoch: 7 [15360/22481 (68%)]\tLoss: 0.210283\n",
      "Train Epoch: 7 [16000/22481 (71%)]\tLoss: 0.209126\n",
      "Train Epoch: 7 [16640/22481 (74%)]\tLoss: 0.086352\n",
      "Train Epoch: 7 [17280/22481 (77%)]\tLoss: 0.037665\n",
      "Train Epoch: 7 [17920/22481 (80%)]\tLoss: 0.055157\n",
      "Train Epoch: 7 [18560/22481 (82%)]\tLoss: 0.144336\n",
      "Train Epoch: 7 [19200/22481 (85%)]\tLoss: 0.038162\n",
      "Train Epoch: 7 [19840/22481 (88%)]\tLoss: 0.052203\n",
      "Train Epoch: 7 [20480/22481 (91%)]\tLoss: 0.181203\n",
      "Train Epoch: 7 [21120/22481 (94%)]\tLoss: 0.266776\n",
      "Train Epoch: 7 [21760/22481 (97%)]\tLoss: 0.111574\n",
      "Train Epoch: 7 [22400/22481 (99%)]\tLoss: 0.033981\n",
      "Train Epoch: 8 [0/22481 (0%)]\tLoss: 0.044917\n",
      "Train Epoch: 8 [640/22481 (3%)]\tLoss: 0.164554\n",
      "Train Epoch: 8 [1280/22481 (6%)]\tLoss: 0.088891\n",
      "Train Epoch: 8 [1920/22481 (9%)]\tLoss: 0.077949\n",
      "Train Epoch: 8 [2560/22481 (11%)]\tLoss: 0.097810\n",
      "Train Epoch: 8 [3200/22481 (14%)]\tLoss: 0.192539\n",
      "Train Epoch: 8 [3840/22481 (17%)]\tLoss: 0.038757\n",
      "Train Epoch: 8 [4480/22481 (20%)]\tLoss: 0.059949\n",
      "Train Epoch: 8 [5120/22481 (23%)]\tLoss: 0.017813\n",
      "Train Epoch: 8 [5760/22481 (26%)]\tLoss: 0.057754\n",
      "Train Epoch: 8 [6400/22481 (28%)]\tLoss: 0.022481\n",
      "Train Epoch: 8 [7040/22481 (31%)]\tLoss: 0.150867\n",
      "Train Epoch: 8 [7680/22481 (34%)]\tLoss: 0.092313\n",
      "Train Epoch: 8 [8320/22481 (37%)]\tLoss: 0.069021\n",
      "Train Epoch: 8 [8960/22481 (40%)]\tLoss: 0.139639\n",
      "Train Epoch: 8 [9600/22481 (43%)]\tLoss: 0.150758\n",
      "Train Epoch: 8 [10240/22481 (45%)]\tLoss: 0.023215\n",
      "Train Epoch: 8 [10880/22481 (48%)]\tLoss: 0.024232\n",
      "Train Epoch: 8 [11520/22481 (51%)]\tLoss: 0.133718\n",
      "Train Epoch: 8 [12160/22481 (54%)]\tLoss: 0.228392\n",
      "Train Epoch: 8 [12800/22481 (57%)]\tLoss: 0.044824\n",
      "Train Epoch: 8 [13440/22481 (60%)]\tLoss: 0.025977\n",
      "Train Epoch: 8 [14080/22481 (62%)]\tLoss: 0.075486\n",
      "Train Epoch: 8 [14720/22481 (65%)]\tLoss: 0.064694\n",
      "Train Epoch: 8 [15360/22481 (68%)]\tLoss: 0.092535\n",
      "Train Epoch: 8 [16000/22481 (71%)]\tLoss: 0.033063\n",
      "Train Epoch: 8 [16640/22481 (74%)]\tLoss: 0.104846\n",
      "Train Epoch: 8 [17280/22481 (77%)]\tLoss: 0.062421\n",
      "Train Epoch: 8 [17920/22481 (80%)]\tLoss: 0.177179\n",
      "Train Epoch: 8 [18560/22481 (82%)]\tLoss: 0.030254\n",
      "Train Epoch: 8 [19200/22481 (85%)]\tLoss: 0.065392\n",
      "Train Epoch: 8 [19840/22481 (88%)]\tLoss: 0.165485\n",
      "Train Epoch: 8 [20480/22481 (91%)]\tLoss: 0.051251\n",
      "Train Epoch: 8 [21120/22481 (94%)]\tLoss: 0.029060\n",
      "Train Epoch: 8 [21760/22481 (97%)]\tLoss: 0.007524\n",
      "Train Epoch: 8 [22400/22481 (99%)]\tLoss: 0.089192\n",
      "Train Epoch: 9 [0/22481 (0%)]\tLoss: 0.040820\n",
      "Train Epoch: 9 [640/22481 (3%)]\tLoss: 0.017568\n",
      "Train Epoch: 9 [1280/22481 (6%)]\tLoss: 0.048277\n",
      "Train Epoch: 9 [1920/22481 (9%)]\tLoss: 0.050153\n",
      "Train Epoch: 9 [2560/22481 (11%)]\tLoss: 0.047914\n",
      "Train Epoch: 9 [3200/22481 (14%)]\tLoss: 0.070158\n",
      "Train Epoch: 9 [3840/22481 (17%)]\tLoss: 0.170686\n",
      "Train Epoch: 9 [4480/22481 (20%)]\tLoss: 0.062100\n",
      "Train Epoch: 9 [5120/22481 (23%)]\tLoss: 0.066909\n",
      "Train Epoch: 9 [5760/22481 (26%)]\tLoss: 0.078722\n",
      "Train Epoch: 9 [6400/22481 (28%)]\tLoss: 0.099624\n",
      "Train Epoch: 9 [7040/22481 (31%)]\tLoss: 0.035500\n",
      "Train Epoch: 9 [7680/22481 (34%)]\tLoss: 0.053004\n",
      "Train Epoch: 9 [8320/22481 (37%)]\tLoss: 0.069397\n",
      "Train Epoch: 9 [8960/22481 (40%)]\tLoss: 0.042160\n",
      "Train Epoch: 9 [9600/22481 (43%)]\tLoss: 0.085111\n",
      "Train Epoch: 9 [10240/22481 (45%)]\tLoss: 0.030578\n",
      "Train Epoch: 9 [10880/22481 (48%)]\tLoss: 0.072078\n",
      "Train Epoch: 9 [11520/22481 (51%)]\tLoss: 0.045445\n",
      "Train Epoch: 9 [12160/22481 (54%)]\tLoss: 0.049821\n",
      "Train Epoch: 9 [12800/22481 (57%)]\tLoss: 0.072464\n",
      "Train Epoch: 9 [13440/22481 (60%)]\tLoss: 0.011651\n",
      "Train Epoch: 9 [14080/22481 (62%)]\tLoss: 0.055602\n",
      "Train Epoch: 9 [14720/22481 (65%)]\tLoss: 0.076866\n",
      "Train Epoch: 9 [15360/22481 (68%)]\tLoss: 0.048504\n",
      "Train Epoch: 9 [16000/22481 (71%)]\tLoss: 0.123584\n",
      "Train Epoch: 9 [16640/22481 (74%)]\tLoss: 0.062674\n",
      "Train Epoch: 9 [17280/22481 (77%)]\tLoss: 0.059976\n",
      "Train Epoch: 9 [17920/22481 (80%)]\tLoss: 0.084781\n",
      "Train Epoch: 9 [18560/22481 (82%)]\tLoss: 0.032753\n",
      "Train Epoch: 9 [19200/22481 (85%)]\tLoss: 0.230617\n",
      "Train Epoch: 9 [19840/22481 (88%)]\tLoss: 0.064218\n",
      "Train Epoch: 9 [20480/22481 (91%)]\tLoss: 0.040399\n",
      "Train Epoch: 9 [21120/22481 (94%)]\tLoss: 0.063208\n",
      "Train Epoch: 9 [21760/22481 (97%)]\tLoss: 0.025945\n",
      "Train Epoch: 9 [22400/22481 (99%)]\tLoss: 0.045369\n",
      "Train Epoch: 10 [0/22481 (0%)]\tLoss: 0.076583\n",
      "Train Epoch: 10 [640/22481 (3%)]\tLoss: 0.161931\n",
      "Train Epoch: 10 [1280/22481 (6%)]\tLoss: 0.055111\n",
      "Train Epoch: 10 [1920/22481 (9%)]\tLoss: 0.065053\n",
      "Train Epoch: 10 [2560/22481 (11%)]\tLoss: 0.055549\n",
      "Train Epoch: 10 [3200/22481 (14%)]\tLoss: 0.106306\n",
      "Train Epoch: 10 [3840/22481 (17%)]\tLoss: 0.063520\n",
      "Train Epoch: 10 [4480/22481 (20%)]\tLoss: 0.067476\n",
      "Train Epoch: 10 [5120/22481 (23%)]\tLoss: 0.096647\n",
      "Train Epoch: 10 [5760/22481 (26%)]\tLoss: 0.026793\n",
      "Train Epoch: 10 [6400/22481 (28%)]\tLoss: 0.159742\n",
      "Train Epoch: 10 [7040/22481 (31%)]\tLoss: 0.117615\n",
      "Train Epoch: 10 [7680/22481 (34%)]\tLoss: 0.179186\n",
      "Train Epoch: 10 [8320/22481 (37%)]\tLoss: 0.027550\n",
      "Train Epoch: 10 [8960/22481 (40%)]\tLoss: 0.045484\n",
      "Train Epoch: 10 [9600/22481 (43%)]\tLoss: 0.110612\n",
      "Train Epoch: 10 [10240/22481 (45%)]\tLoss: 0.068403\n",
      "Train Epoch: 10 [10880/22481 (48%)]\tLoss: 0.150686\n",
      "Train Epoch: 10 [11520/22481 (51%)]\tLoss: 0.114708\n",
      "Train Epoch: 10 [12160/22481 (54%)]\tLoss: 0.103955\n",
      "Train Epoch: 10 [12800/22481 (57%)]\tLoss: 0.023720\n",
      "Train Epoch: 10 [13440/22481 (60%)]\tLoss: 0.153379\n",
      "Train Epoch: 10 [14080/22481 (62%)]\tLoss: 0.107128\n",
      "Train Epoch: 10 [14720/22481 (65%)]\tLoss: 0.116025\n",
      "Train Epoch: 10 [15360/22481 (68%)]\tLoss: 0.114782\n",
      "Train Epoch: 10 [16000/22481 (71%)]\tLoss: 0.084076\n",
      "Train Epoch: 10 [16640/22481 (74%)]\tLoss: 0.093390\n",
      "Train Epoch: 10 [17280/22481 (77%)]\tLoss: 0.077068\n",
      "Train Epoch: 10 [17920/22481 (80%)]\tLoss: 0.130189\n",
      "Train Epoch: 10 [18560/22481 (82%)]\tLoss: 0.039766\n",
      "Train Epoch: 10 [19200/22481 (85%)]\tLoss: 0.289840\n",
      "Train Epoch: 10 [19840/22481 (88%)]\tLoss: 0.036841\n",
      "Train Epoch: 10 [20480/22481 (91%)]\tLoss: 0.049444\n",
      "Train Epoch: 10 [21120/22481 (94%)]\tLoss: 0.033372\n",
      "Train Epoch: 10 [21760/22481 (97%)]\tLoss: 0.025381\n",
      "Train Epoch: 10 [22400/22481 (99%)]\tLoss: 0.124713\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.1952, Accuracy: 9855/10000 (99%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/18662 (0%)]\tLoss: 0.150311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [640/18662 (3%)]\tLoss: 0.161857\n",
      "Train Epoch: 1 [1280/18662 (7%)]\tLoss: 0.067179\n",
      "Train Epoch: 1 [1920/18662 (10%)]\tLoss: 0.102434\n",
      "Train Epoch: 1 [2560/18662 (14%)]\tLoss: 0.116669\n",
      "Train Epoch: 1 [3200/18662 (17%)]\tLoss: 0.058823\n",
      "Train Epoch: 1 [3840/18662 (21%)]\tLoss: 0.092309\n",
      "Train Epoch: 1 [4480/18662 (24%)]\tLoss: 0.063771\n",
      "Train Epoch: 1 [5120/18662 (27%)]\tLoss: 0.217369\n",
      "Train Epoch: 1 [5760/18662 (31%)]\tLoss: 0.069725\n",
      "Train Epoch: 1 [6400/18662 (34%)]\tLoss: 0.126890\n",
      "Train Epoch: 1 [7040/18662 (38%)]\tLoss: 0.122347\n",
      "Train Epoch: 1 [7680/18662 (41%)]\tLoss: 0.061002\n",
      "Train Epoch: 1 [8320/18662 (45%)]\tLoss: 0.011720\n",
      "Train Epoch: 1 [8960/18662 (48%)]\tLoss: 0.156217\n",
      "Train Epoch: 1 [9600/18662 (51%)]\tLoss: 0.052502\n",
      "Train Epoch: 1 [10240/18662 (55%)]\tLoss: 0.043775\n",
      "Train Epoch: 1 [10880/18662 (58%)]\tLoss: 0.096349\n",
      "Train Epoch: 1 [11520/18662 (62%)]\tLoss: 0.027657\n",
      "Train Epoch: 1 [12160/18662 (65%)]\tLoss: 0.010488\n",
      "Train Epoch: 1 [12800/18662 (68%)]\tLoss: 0.108995\n",
      "Train Epoch: 1 [13440/18662 (72%)]\tLoss: 0.128422\n",
      "Train Epoch: 1 [14080/18662 (75%)]\tLoss: 0.102920\n",
      "Train Epoch: 1 [14720/18662 (79%)]\tLoss: 0.112491\n",
      "Train Epoch: 1 [15360/18662 (82%)]\tLoss: 0.133861\n",
      "Train Epoch: 1 [16000/18662 (86%)]\tLoss: 0.024367\n",
      "Train Epoch: 1 [16640/18662 (89%)]\tLoss: 0.128210\n",
      "Train Epoch: 1 [17280/18662 (92%)]\tLoss: 0.022057\n",
      "Train Epoch: 1 [17920/18662 (96%)]\tLoss: 0.029527\n",
      "Train Epoch: 1 [18560/18662 (99%)]\tLoss: 0.024485\n",
      "Train Epoch: 2 [0/18662 (0%)]\tLoss: 0.024840\n",
      "Train Epoch: 2 [640/18662 (3%)]\tLoss: 0.027454\n",
      "Train Epoch: 2 [1280/18662 (7%)]\tLoss: 0.125953\n",
      "Train Epoch: 2 [1920/18662 (10%)]\tLoss: 0.040467\n",
      "Train Epoch: 2 [2560/18662 (14%)]\tLoss: 0.046862\n",
      "Train Epoch: 2 [3200/18662 (17%)]\tLoss: 0.041784\n",
      "Train Epoch: 2 [3840/18662 (21%)]\tLoss: 0.032642\n",
      "Train Epoch: 2 [4480/18662 (24%)]\tLoss: 0.121357\n",
      "Train Epoch: 2 [5120/18662 (27%)]\tLoss: 0.041578\n",
      "Train Epoch: 2 [5760/18662 (31%)]\tLoss: 0.033485\n",
      "Train Epoch: 2 [6400/18662 (34%)]\tLoss: 0.138408\n",
      "Train Epoch: 2 [7040/18662 (38%)]\tLoss: 0.062059\n",
      "Train Epoch: 2 [7680/18662 (41%)]\tLoss: 0.010334\n",
      "Train Epoch: 2 [8320/18662 (45%)]\tLoss: 0.039439\n",
      "Train Epoch: 2 [8960/18662 (48%)]\tLoss: 0.090614\n",
      "Train Epoch: 2 [9600/18662 (51%)]\tLoss: 0.075847\n",
      "Train Epoch: 2 [10240/18662 (55%)]\tLoss: 0.060515\n",
      "Train Epoch: 2 [10880/18662 (58%)]\tLoss: 0.033946\n",
      "Train Epoch: 2 [11520/18662 (62%)]\tLoss: 0.186976\n",
      "Train Epoch: 2 [12160/18662 (65%)]\tLoss: 0.040846\n",
      "Train Epoch: 2 [12800/18662 (68%)]\tLoss: 0.054695\n",
      "Train Epoch: 2 [13440/18662 (72%)]\tLoss: 0.047844\n",
      "Train Epoch: 2 [14080/18662 (75%)]\tLoss: 0.049065\n",
      "Train Epoch: 2 [14720/18662 (79%)]\tLoss: 0.028749\n",
      "Train Epoch: 2 [15360/18662 (82%)]\tLoss: 0.133736\n",
      "Train Epoch: 2 [16000/18662 (86%)]\tLoss: 0.110191\n",
      "Train Epoch: 2 [16640/18662 (89%)]\tLoss: 0.078724\n",
      "Train Epoch: 2 [17280/18662 (92%)]\tLoss: 0.062823\n",
      "Train Epoch: 2 [17920/18662 (96%)]\tLoss: 0.149248\n",
      "Train Epoch: 2 [18560/18662 (99%)]\tLoss: 0.075247\n",
      "Train Epoch: 3 [0/18662 (0%)]\tLoss: 0.027850\n",
      "Train Epoch: 3 [640/18662 (3%)]\tLoss: 0.152820\n",
      "Train Epoch: 3 [1280/18662 (7%)]\tLoss: 0.051278\n",
      "Train Epoch: 3 [1920/18662 (10%)]\tLoss: 0.028954\n",
      "Train Epoch: 3 [2560/18662 (14%)]\tLoss: 0.139379\n",
      "Train Epoch: 3 [3200/18662 (17%)]\tLoss: 0.006650\n",
      "Train Epoch: 3 [3840/18662 (21%)]\tLoss: 0.027339\n",
      "Train Epoch: 3 [4480/18662 (24%)]\tLoss: 0.037251\n",
      "Train Epoch: 3 [5120/18662 (27%)]\tLoss: 0.076211\n",
      "Train Epoch: 3 [5760/18662 (31%)]\tLoss: 0.045673\n",
      "Train Epoch: 3 [6400/18662 (34%)]\tLoss: 0.018359\n",
      "Train Epoch: 3 [7040/18662 (38%)]\tLoss: 0.276118\n",
      "Train Epoch: 3 [7680/18662 (41%)]\tLoss: 0.129785\n",
      "Train Epoch: 3 [8320/18662 (45%)]\tLoss: 0.122439\n",
      "Train Epoch: 3 [8960/18662 (48%)]\tLoss: 0.140332\n",
      "Train Epoch: 3 [9600/18662 (51%)]\tLoss: 0.076467\n",
      "Train Epoch: 3 [10240/18662 (55%)]\tLoss: 0.033735\n",
      "Train Epoch: 3 [10880/18662 (58%)]\tLoss: 0.033377\n",
      "Train Epoch: 3 [11520/18662 (62%)]\tLoss: 0.037883\n",
      "Train Epoch: 3 [12160/18662 (65%)]\tLoss: 0.034745\n",
      "Train Epoch: 3 [12800/18662 (68%)]\tLoss: 0.027037\n",
      "Train Epoch: 3 [13440/18662 (72%)]\tLoss: 0.023254\n",
      "Train Epoch: 3 [14080/18662 (75%)]\tLoss: 0.060484\n",
      "Train Epoch: 3 [14720/18662 (79%)]\tLoss: 0.074739\n",
      "Train Epoch: 3 [15360/18662 (82%)]\tLoss: 0.087860\n",
      "Train Epoch: 3 [16000/18662 (86%)]\tLoss: 0.123439\n",
      "Train Epoch: 3 [16640/18662 (89%)]\tLoss: 0.027671\n",
      "Train Epoch: 3 [17280/18662 (92%)]\tLoss: 0.020524\n",
      "Train Epoch: 3 [17920/18662 (96%)]\tLoss: 0.166200\n",
      "Train Epoch: 3 [18560/18662 (99%)]\tLoss: 0.059201\n",
      "Train Epoch: 4 [0/18662 (0%)]\tLoss: 0.022144\n",
      "Train Epoch: 4 [640/18662 (3%)]\tLoss: 0.267268\n",
      "Train Epoch: 4 [1280/18662 (7%)]\tLoss: 0.028877\n",
      "Train Epoch: 4 [1920/18662 (10%)]\tLoss: 0.073656\n",
      "Train Epoch: 4 [2560/18662 (14%)]\tLoss: 0.292058\n",
      "Train Epoch: 4 [3200/18662 (17%)]\tLoss: 0.062781\n",
      "Train Epoch: 4 [3840/18662 (21%)]\tLoss: 0.068409\n",
      "Train Epoch: 4 [4480/18662 (24%)]\tLoss: 0.020178\n",
      "Train Epoch: 4 [5120/18662 (27%)]\tLoss: 0.035323\n",
      "Train Epoch: 4 [5760/18662 (31%)]\tLoss: 0.036534\n",
      "Train Epoch: 4 [6400/18662 (34%)]\tLoss: 0.120113\n",
      "Train Epoch: 4 [7040/18662 (38%)]\tLoss: 0.076634\n",
      "Train Epoch: 4 [7680/18662 (41%)]\tLoss: 0.057894\n",
      "Train Epoch: 4 [8320/18662 (45%)]\tLoss: 0.097703\n",
      "Train Epoch: 4 [8960/18662 (48%)]\tLoss: 0.045851\n",
      "Train Epoch: 4 [9600/18662 (51%)]\tLoss: 0.078781\n",
      "Train Epoch: 4 [10240/18662 (55%)]\tLoss: 0.022411\n",
      "Train Epoch: 4 [10880/18662 (58%)]\tLoss: 0.028792\n",
      "Train Epoch: 4 [11520/18662 (62%)]\tLoss: 0.063908\n",
      "Train Epoch: 4 [12160/18662 (65%)]\tLoss: 0.068775\n",
      "Train Epoch: 4 [12800/18662 (68%)]\tLoss: 0.117566\n",
      "Train Epoch: 4 [13440/18662 (72%)]\tLoss: 0.027632\n",
      "Train Epoch: 4 [14080/18662 (75%)]\tLoss: 0.160910\n",
      "Train Epoch: 4 [14720/18662 (79%)]\tLoss: 0.116838\n",
      "Train Epoch: 4 [15360/18662 (82%)]\tLoss: 0.009930\n",
      "Train Epoch: 4 [16000/18662 (86%)]\tLoss: 0.033167\n",
      "Train Epoch: 4 [16640/18662 (89%)]\tLoss: 0.018539\n",
      "Train Epoch: 4 [17280/18662 (92%)]\tLoss: 0.091323\n",
      "Train Epoch: 4 [17920/18662 (96%)]\tLoss: 0.106321\n",
      "Train Epoch: 4 [18560/18662 (99%)]\tLoss: 0.124388\n",
      "Train Epoch: 5 [0/18662 (0%)]\tLoss: 0.068611\n",
      "Train Epoch: 5 [640/18662 (3%)]\tLoss: 0.021549\n",
      "Train Epoch: 5 [1280/18662 (7%)]\tLoss: 0.186811\n",
      "Train Epoch: 5 [1920/18662 (10%)]\tLoss: 0.028382\n",
      "Train Epoch: 5 [2560/18662 (14%)]\tLoss: 0.094356\n",
      "Train Epoch: 5 [3200/18662 (17%)]\tLoss: 0.113137\n",
      "Train Epoch: 5 [3840/18662 (21%)]\tLoss: 0.028847\n",
      "Train Epoch: 5 [4480/18662 (24%)]\tLoss: 0.027050\n",
      "Train Epoch: 5 [5120/18662 (27%)]\tLoss: 0.017112\n",
      "Train Epoch: 5 [5760/18662 (31%)]\tLoss: 0.106296\n",
      "Train Epoch: 5 [6400/18662 (34%)]\tLoss: 0.147790\n",
      "Train Epoch: 5 [7040/18662 (38%)]\tLoss: 0.043587\n",
      "Train Epoch: 5 [7680/18662 (41%)]\tLoss: 0.060310\n",
      "Train Epoch: 5 [8320/18662 (45%)]\tLoss: 0.037043\n",
      "Train Epoch: 5 [8960/18662 (48%)]\tLoss: 0.030074\n",
      "Train Epoch: 5 [9600/18662 (51%)]\tLoss: 0.046211\n",
      "Train Epoch: 5 [10240/18662 (55%)]\tLoss: 0.059616\n",
      "Train Epoch: 5 [10880/18662 (58%)]\tLoss: 0.040661\n",
      "Train Epoch: 5 [11520/18662 (62%)]\tLoss: 0.191779\n",
      "Train Epoch: 5 [12160/18662 (65%)]\tLoss: 0.096572\n",
      "Train Epoch: 5 [12800/18662 (68%)]\tLoss: 0.057715\n",
      "Train Epoch: 5 [13440/18662 (72%)]\tLoss: 0.008759\n",
      "Train Epoch: 5 [14080/18662 (75%)]\tLoss: 0.181034\n",
      "Train Epoch: 5 [14720/18662 (79%)]\tLoss: 0.052105\n",
      "Train Epoch: 5 [15360/18662 (82%)]\tLoss: 0.021576\n",
      "Train Epoch: 5 [16000/18662 (86%)]\tLoss: 0.301211\n",
      "Train Epoch: 5 [16640/18662 (89%)]\tLoss: 0.025896\n",
      "Train Epoch: 5 [17280/18662 (92%)]\tLoss: 0.057637\n",
      "Train Epoch: 5 [17920/18662 (96%)]\tLoss: 0.037658\n",
      "Train Epoch: 5 [18560/18662 (99%)]\tLoss: 0.075694\n",
      "Train Epoch: 6 [0/18662 (0%)]\tLoss: 0.056393\n",
      "Train Epoch: 6 [640/18662 (3%)]\tLoss: 0.060434\n",
      "Train Epoch: 6 [1280/18662 (7%)]\tLoss: 0.151498\n",
      "Train Epoch: 6 [1920/18662 (10%)]\tLoss: 0.165972\n",
      "Train Epoch: 6 [2560/18662 (14%)]\tLoss: 0.121116\n",
      "Train Epoch: 6 [3200/18662 (17%)]\tLoss: 0.008047\n",
      "Train Epoch: 6 [3840/18662 (21%)]\tLoss: 0.030452\n",
      "Train Epoch: 6 [4480/18662 (24%)]\tLoss: 0.100745\n",
      "Train Epoch: 6 [5120/18662 (27%)]\tLoss: 0.024168\n",
      "Train Epoch: 6 [5760/18662 (31%)]\tLoss: 0.163040\n",
      "Train Epoch: 6 [6400/18662 (34%)]\tLoss: 0.173202\n",
      "Train Epoch: 6 [7040/18662 (38%)]\tLoss: 0.133903\n",
      "Train Epoch: 6 [7680/18662 (41%)]\tLoss: 0.084751\n",
      "Train Epoch: 6 [8320/18662 (45%)]\tLoss: 0.136649\n",
      "Train Epoch: 6 [8960/18662 (48%)]\tLoss: 0.016057\n",
      "Train Epoch: 6 [9600/18662 (51%)]\tLoss: 0.049890\n",
      "Train Epoch: 6 [10240/18662 (55%)]\tLoss: 0.065220\n",
      "Train Epoch: 6 [10880/18662 (58%)]\tLoss: 0.112847\n",
      "Train Epoch: 6 [11520/18662 (62%)]\tLoss: 0.026971\n",
      "Train Epoch: 6 [12160/18662 (65%)]\tLoss: 0.013333\n",
      "Train Epoch: 6 [12800/18662 (68%)]\tLoss: 0.026468\n",
      "Train Epoch: 6 [13440/18662 (72%)]\tLoss: 0.027160\n",
      "Train Epoch: 6 [14080/18662 (75%)]\tLoss: 0.052257\n",
      "Train Epoch: 6 [14720/18662 (79%)]\tLoss: 0.111813\n",
      "Train Epoch: 6 [15360/18662 (82%)]\tLoss: 0.116368\n",
      "Train Epoch: 6 [16000/18662 (86%)]\tLoss: 0.067451\n",
      "Train Epoch: 6 [16640/18662 (89%)]\tLoss: 0.056352\n",
      "Train Epoch: 6 [17280/18662 (92%)]\tLoss: 0.049235\n",
      "Train Epoch: 6 [17920/18662 (96%)]\tLoss: 0.033271\n",
      "Train Epoch: 6 [18560/18662 (99%)]\tLoss: 0.027246\n",
      "Train Epoch: 7 [0/18662 (0%)]\tLoss: 0.044942\n",
      "Train Epoch: 7 [640/18662 (3%)]\tLoss: 0.030484\n",
      "Train Epoch: 7 [1280/18662 (7%)]\tLoss: 0.150190\n",
      "Train Epoch: 7 [1920/18662 (10%)]\tLoss: 0.053432\n",
      "Train Epoch: 7 [2560/18662 (14%)]\tLoss: 0.009296\n",
      "Train Epoch: 7 [3200/18662 (17%)]\tLoss: 0.081662\n",
      "Train Epoch: 7 [3840/18662 (21%)]\tLoss: 0.044253\n",
      "Train Epoch: 7 [4480/18662 (24%)]\tLoss: 0.189654\n",
      "Train Epoch: 7 [5120/18662 (27%)]\tLoss: 0.005009\n",
      "Train Epoch: 7 [5760/18662 (31%)]\tLoss: 0.113981\n",
      "Train Epoch: 7 [6400/18662 (34%)]\tLoss: 0.015510\n",
      "Train Epoch: 7 [7040/18662 (38%)]\tLoss: 0.021328\n",
      "Train Epoch: 7 [7680/18662 (41%)]\tLoss: 0.033473\n",
      "Train Epoch: 7 [8320/18662 (45%)]\tLoss: 0.275550\n",
      "Train Epoch: 7 [8960/18662 (48%)]\tLoss: 0.103751\n",
      "Train Epoch: 7 [9600/18662 (51%)]\tLoss: 0.115925\n",
      "Train Epoch: 7 [10240/18662 (55%)]\tLoss: 0.036558\n",
      "Train Epoch: 7 [10880/18662 (58%)]\tLoss: 0.069709\n",
      "Train Epoch: 7 [11520/18662 (62%)]\tLoss: 0.027337\n",
      "Train Epoch: 7 [12160/18662 (65%)]\tLoss: 0.027173\n",
      "Train Epoch: 7 [12800/18662 (68%)]\tLoss: 0.046955\n",
      "Train Epoch: 7 [13440/18662 (72%)]\tLoss: 0.053877\n",
      "Train Epoch: 7 [14080/18662 (75%)]\tLoss: 0.069751\n",
      "Train Epoch: 7 [14720/18662 (79%)]\tLoss: 0.041174\n",
      "Train Epoch: 7 [15360/18662 (82%)]\tLoss: 0.080892\n",
      "Train Epoch: 7 [16000/18662 (86%)]\tLoss: 0.129785\n",
      "Train Epoch: 7 [16640/18662 (89%)]\tLoss: 0.104438\n",
      "Train Epoch: 7 [17280/18662 (92%)]\tLoss: 0.023915\n",
      "Train Epoch: 7 [17920/18662 (96%)]\tLoss: 0.108772\n",
      "Train Epoch: 7 [18560/18662 (99%)]\tLoss: 0.040741\n",
      "Train Epoch: 8 [0/18662 (0%)]\tLoss: 0.006110\n",
      "Train Epoch: 8 [640/18662 (3%)]\tLoss: 0.040298\n",
      "Train Epoch: 8 [1280/18662 (7%)]\tLoss: 0.029343\n",
      "Train Epoch: 8 [1920/18662 (10%)]\tLoss: 0.020495\n",
      "Train Epoch: 8 [2560/18662 (14%)]\tLoss: 0.114049\n",
      "Train Epoch: 8 [3200/18662 (17%)]\tLoss: 0.076713\n",
      "Train Epoch: 8 [3840/18662 (21%)]\tLoss: 0.039163\n",
      "Train Epoch: 8 [4480/18662 (24%)]\tLoss: 0.076883\n",
      "Train Epoch: 8 [5120/18662 (27%)]\tLoss: 0.099516\n",
      "Train Epoch: 8 [5760/18662 (31%)]\tLoss: 0.003309\n",
      "Train Epoch: 8 [6400/18662 (34%)]\tLoss: 0.037993\n",
      "Train Epoch: 8 [7040/18662 (38%)]\tLoss: 0.028696\n",
      "Train Epoch: 8 [7680/18662 (41%)]\tLoss: 0.127911\n",
      "Train Epoch: 8 [8320/18662 (45%)]\tLoss: 0.042477\n",
      "Train Epoch: 8 [8960/18662 (48%)]\tLoss: 0.031580\n",
      "Train Epoch: 8 [9600/18662 (51%)]\tLoss: 0.178442\n",
      "Train Epoch: 8 [10240/18662 (55%)]\tLoss: 0.025455\n",
      "Train Epoch: 8 [10880/18662 (58%)]\tLoss: 0.048674\n",
      "Train Epoch: 8 [11520/18662 (62%)]\tLoss: 0.051017\n",
      "Train Epoch: 8 [12160/18662 (65%)]\tLoss: 0.042301\n",
      "Train Epoch: 8 [12800/18662 (68%)]\tLoss: 0.021336\n",
      "Train Epoch: 8 [13440/18662 (72%)]\tLoss: 0.054946\n",
      "Train Epoch: 8 [14080/18662 (75%)]\tLoss: 0.036976\n",
      "Train Epoch: 8 [14720/18662 (79%)]\tLoss: 0.016333\n",
      "Train Epoch: 8 [15360/18662 (82%)]\tLoss: 0.040647\n",
      "Train Epoch: 8 [16000/18662 (86%)]\tLoss: 0.223179\n",
      "Train Epoch: 8 [16640/18662 (89%)]\tLoss: 0.014756\n",
      "Train Epoch: 8 [17280/18662 (92%)]\tLoss: 0.098797\n",
      "Train Epoch: 8 [17920/18662 (96%)]\tLoss: 0.115961\n",
      "Train Epoch: 8 [18560/18662 (99%)]\tLoss: 0.053718\n",
      "Train Epoch: 9 [0/18662 (0%)]\tLoss: 0.072635\n",
      "Train Epoch: 9 [640/18662 (3%)]\tLoss: 0.093231\n",
      "Train Epoch: 9 [1280/18662 (7%)]\tLoss: 0.070023\n",
      "Train Epoch: 9 [1920/18662 (10%)]\tLoss: 0.138254\n",
      "Train Epoch: 9 [2560/18662 (14%)]\tLoss: 0.012406\n",
      "Train Epoch: 9 [3200/18662 (17%)]\tLoss: 0.041388\n",
      "Train Epoch: 9 [3840/18662 (21%)]\tLoss: 0.006933\n",
      "Train Epoch: 9 [4480/18662 (24%)]\tLoss: 0.087065\n",
      "Train Epoch: 9 [5120/18662 (27%)]\tLoss: 0.069465\n",
      "Train Epoch: 9 [5760/18662 (31%)]\tLoss: 0.052067\n",
      "Train Epoch: 9 [6400/18662 (34%)]\tLoss: 0.013987\n",
      "Train Epoch: 9 [7040/18662 (38%)]\tLoss: 0.077341\n",
      "Train Epoch: 9 [7680/18662 (41%)]\tLoss: 0.037500\n",
      "Train Epoch: 9 [8320/18662 (45%)]\tLoss: 0.061283\n",
      "Train Epoch: 9 [8960/18662 (48%)]\tLoss: 0.042779\n",
      "Train Epoch: 9 [9600/18662 (51%)]\tLoss: 0.014069\n",
      "Train Epoch: 9 [10240/18662 (55%)]\tLoss: 0.206548\n",
      "Train Epoch: 9 [10880/18662 (58%)]\tLoss: 0.100890\n",
      "Train Epoch: 9 [11520/18662 (62%)]\tLoss: 0.011612\n",
      "Train Epoch: 9 [12160/18662 (65%)]\tLoss: 0.140929\n",
      "Train Epoch: 9 [12800/18662 (68%)]\tLoss: 0.039690\n",
      "Train Epoch: 9 [13440/18662 (72%)]\tLoss: 0.021705\n",
      "Train Epoch: 9 [14080/18662 (75%)]\tLoss: 0.008815\n",
      "Train Epoch: 9 [14720/18662 (79%)]\tLoss: 0.040613\n",
      "Train Epoch: 9 [15360/18662 (82%)]\tLoss: 0.083354\n",
      "Train Epoch: 9 [16000/18662 (86%)]\tLoss: 0.001782\n",
      "Train Epoch: 9 [16640/18662 (89%)]\tLoss: 0.119901\n",
      "Train Epoch: 9 [17280/18662 (92%)]\tLoss: 0.097273\n",
      "Train Epoch: 9 [17920/18662 (96%)]\tLoss: 0.009332\n",
      "Train Epoch: 9 [18560/18662 (99%)]\tLoss: 0.017696\n",
      "Train Epoch: 10 [0/18662 (0%)]\tLoss: 0.041165\n",
      "Train Epoch: 10 [640/18662 (3%)]\tLoss: 0.066089\n",
      "Train Epoch: 10 [1280/18662 (7%)]\tLoss: 0.053051\n",
      "Train Epoch: 10 [1920/18662 (10%)]\tLoss: 0.054771\n",
      "Train Epoch: 10 [2560/18662 (14%)]\tLoss: 0.049919\n",
      "Train Epoch: 10 [3200/18662 (17%)]\tLoss: 0.036446\n",
      "Train Epoch: 10 [3840/18662 (21%)]\tLoss: 0.044372\n",
      "Train Epoch: 10 [4480/18662 (24%)]\tLoss: 0.064467\n",
      "Train Epoch: 10 [5120/18662 (27%)]\tLoss: 0.042454\n",
      "Train Epoch: 10 [5760/18662 (31%)]\tLoss: 0.132732\n",
      "Train Epoch: 10 [6400/18662 (34%)]\tLoss: 0.014228\n",
      "Train Epoch: 10 [7040/18662 (38%)]\tLoss: 0.017999\n",
      "Train Epoch: 10 [7680/18662 (41%)]\tLoss: 0.032430\n",
      "Train Epoch: 10 [8320/18662 (45%)]\tLoss: 0.033791\n",
      "Train Epoch: 10 [8960/18662 (48%)]\tLoss: 0.018532\n",
      "Train Epoch: 10 [9600/18662 (51%)]\tLoss: 0.019356\n",
      "Train Epoch: 10 [10240/18662 (55%)]\tLoss: 0.035250\n",
      "Train Epoch: 10 [10880/18662 (58%)]\tLoss: 0.121873\n",
      "Train Epoch: 10 [11520/18662 (62%)]\tLoss: 0.052745\n",
      "Train Epoch: 10 [12160/18662 (65%)]\tLoss: 0.017279\n",
      "Train Epoch: 10 [12800/18662 (68%)]\tLoss: 0.041210\n",
      "Train Epoch: 10 [13440/18662 (72%)]\tLoss: 0.031537\n",
      "Train Epoch: 10 [14080/18662 (75%)]\tLoss: 0.006270\n",
      "Train Epoch: 10 [14720/18662 (79%)]\tLoss: 0.097392\n",
      "Train Epoch: 10 [15360/18662 (82%)]\tLoss: 0.033915\n",
      "Train Epoch: 10 [16000/18662 (86%)]\tLoss: 0.076561\n",
      "Train Epoch: 10 [16640/18662 (89%)]\tLoss: 0.053458\n",
      "Train Epoch: 10 [17280/18662 (92%)]\tLoss: 0.017344\n",
      "Train Epoch: 10 [17920/18662 (96%)]\tLoss: 0.153857\n",
      "Train Epoch: 10 [18560/18662 (99%)]\tLoss: 0.005742\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/10619 (0%)]\tLoss: 0.123648\n",
      "Train Epoch: 1 [640/10619 (6%)]\tLoss: 0.066643\n",
      "Train Epoch: 1 [1280/10619 (12%)]\tLoss: 0.059351\n",
      "Train Epoch: 1 [1920/10619 (18%)]\tLoss: 0.055551\n",
      "Train Epoch: 1 [2560/10619 (24%)]\tLoss: 0.090748\n",
      "Train Epoch: 1 [3200/10619 (30%)]\tLoss: 0.032703\n",
      "Train Epoch: 1 [3840/10619 (36%)]\tLoss: 0.238320\n",
      "Train Epoch: 1 [4480/10619 (42%)]\tLoss: 0.104556\n",
      "Train Epoch: 1 [5120/10619 (48%)]\tLoss: 0.109369\n",
      "Train Epoch: 1 [5760/10619 (54%)]\tLoss: 0.050757\n",
      "Train Epoch: 1 [6400/10619 (60%)]\tLoss: 0.049431\n",
      "Train Epoch: 1 [7040/10619 (66%)]\tLoss: 0.132009\n",
      "Train Epoch: 1 [7680/10619 (72%)]\tLoss: 0.212454\n",
      "Train Epoch: 1 [8320/10619 (78%)]\tLoss: 0.087126\n",
      "Train Epoch: 1 [8960/10619 (84%)]\tLoss: 0.184389\n",
      "Train Epoch: 1 [9600/10619 (90%)]\tLoss: 0.020528\n",
      "Train Epoch: 1 [10240/10619 (96%)]\tLoss: 0.054895\n",
      "Train Epoch: 2 [0/10619 (0%)]\tLoss: 0.273285\n",
      "Train Epoch: 2 [640/10619 (6%)]\tLoss: 0.058613\n",
      "Train Epoch: 2 [1280/10619 (12%)]\tLoss: 0.086243\n",
      "Train Epoch: 2 [1920/10619 (18%)]\tLoss: 0.043001\n",
      "Train Epoch: 2 [2560/10619 (24%)]\tLoss: 0.070002\n",
      "Train Epoch: 2 [3200/10619 (30%)]\tLoss: 0.059642\n",
      "Train Epoch: 2 [3840/10619 (36%)]\tLoss: 0.084585\n",
      "Train Epoch: 2 [4480/10619 (42%)]\tLoss: 0.033565\n",
      "Train Epoch: 2 [5120/10619 (48%)]\tLoss: 0.017152\n",
      "Train Epoch: 2 [5760/10619 (54%)]\tLoss: 0.027396\n",
      "Train Epoch: 2 [6400/10619 (60%)]\tLoss: 0.073398\n",
      "Train Epoch: 2 [7040/10619 (66%)]\tLoss: 0.112255\n",
      "Train Epoch: 2 [7680/10619 (72%)]\tLoss: 0.098571\n",
      "Train Epoch: 2 [8320/10619 (78%)]\tLoss: 0.364099\n",
      "Train Epoch: 2 [8960/10619 (84%)]\tLoss: 0.135806\n",
      "Train Epoch: 2 [9600/10619 (90%)]\tLoss: 0.064876\n",
      "Train Epoch: 2 [10240/10619 (96%)]\tLoss: 0.067886\n",
      "Train Epoch: 3 [0/10619 (0%)]\tLoss: 0.021014\n",
      "Train Epoch: 3 [640/10619 (6%)]\tLoss: 0.114165\n",
      "Train Epoch: 3 [1280/10619 (12%)]\tLoss: 0.159031\n",
      "Train Epoch: 3 [1920/10619 (18%)]\tLoss: 0.126930\n",
      "Train Epoch: 3 [2560/10619 (24%)]\tLoss: 0.053414\n",
      "Train Epoch: 3 [3200/10619 (30%)]\tLoss: 0.072976\n",
      "Train Epoch: 3 [3840/10619 (36%)]\tLoss: 0.072609\n",
      "Train Epoch: 3 [4480/10619 (42%)]\tLoss: 0.043994\n",
      "Train Epoch: 3 [5120/10619 (48%)]\tLoss: 0.106570\n",
      "Train Epoch: 3 [5760/10619 (54%)]\tLoss: 0.065885\n",
      "Train Epoch: 3 [6400/10619 (60%)]\tLoss: 0.128945\n",
      "Train Epoch: 3 [7040/10619 (66%)]\tLoss: 0.041447\n",
      "Train Epoch: 3 [7680/10619 (72%)]\tLoss: 0.037340\n",
      "Train Epoch: 3 [8320/10619 (78%)]\tLoss: 0.079169\n",
      "Train Epoch: 3 [8960/10619 (84%)]\tLoss: 0.045261\n",
      "Train Epoch: 3 [9600/10619 (90%)]\tLoss: 0.016453\n",
      "Train Epoch: 3 [10240/10619 (96%)]\tLoss: 0.137314\n",
      "Train Epoch: 4 [0/10619 (0%)]\tLoss: 0.086766\n",
      "Train Epoch: 4 [640/10619 (6%)]\tLoss: 0.057757\n",
      "Train Epoch: 4 [1280/10619 (12%)]\tLoss: 0.044031\n",
      "Train Epoch: 4 [1920/10619 (18%)]\tLoss: 0.047145\n",
      "Train Epoch: 4 [2560/10619 (24%)]\tLoss: 0.192196\n",
      "Train Epoch: 4 [3200/10619 (30%)]\tLoss: 0.259133\n",
      "Train Epoch: 4 [3840/10619 (36%)]\tLoss: 0.032354\n",
      "Train Epoch: 4 [4480/10619 (42%)]\tLoss: 0.022722\n",
      "Train Epoch: 4 [5120/10619 (48%)]\tLoss: 0.023770\n",
      "Train Epoch: 4 [5760/10619 (54%)]\tLoss: 0.081816\n",
      "Train Epoch: 4 [6400/10619 (60%)]\tLoss: 0.053179\n",
      "Train Epoch: 4 [7040/10619 (66%)]\tLoss: 0.046806\n",
      "Train Epoch: 4 [7680/10619 (72%)]\tLoss: 0.161185\n",
      "Train Epoch: 4 [8320/10619 (78%)]\tLoss: 0.071461\n",
      "Train Epoch: 4 [8960/10619 (84%)]\tLoss: 0.067465\n",
      "Train Epoch: 4 [9600/10619 (90%)]\tLoss: 0.046099\n",
      "Train Epoch: 4 [10240/10619 (96%)]\tLoss: 0.027821\n",
      "Train Epoch: 5 [0/10619 (0%)]\tLoss: 0.019337\n",
      "Train Epoch: 5 [640/10619 (6%)]\tLoss: 0.120559\n",
      "Train Epoch: 5 [1280/10619 (12%)]\tLoss: 0.123615\n",
      "Train Epoch: 5 [1920/10619 (18%)]\tLoss: 0.090947\n",
      "Train Epoch: 5 [2560/10619 (24%)]\tLoss: 0.140962\n",
      "Train Epoch: 5 [3200/10619 (30%)]\tLoss: 0.151645\n",
      "Train Epoch: 5 [3840/10619 (36%)]\tLoss: 0.144736\n",
      "Train Epoch: 5 [4480/10619 (42%)]\tLoss: 0.055785\n",
      "Train Epoch: 5 [5120/10619 (48%)]\tLoss: 0.038225\n",
      "Train Epoch: 5 [5760/10619 (54%)]\tLoss: 0.057562\n",
      "Train Epoch: 5 [6400/10619 (60%)]\tLoss: 0.059878\n",
      "Train Epoch: 5 [7040/10619 (66%)]\tLoss: 0.074349\n",
      "Train Epoch: 5 [7680/10619 (72%)]\tLoss: 0.060394\n",
      "Train Epoch: 5 [8320/10619 (78%)]\tLoss: 0.043830\n",
      "Train Epoch: 5 [8960/10619 (84%)]\tLoss: 0.035288\n",
      "Train Epoch: 5 [9600/10619 (90%)]\tLoss: 0.215587\n",
      "Train Epoch: 5 [10240/10619 (96%)]\tLoss: 0.082420\n",
      "Train Epoch: 6 [0/10619 (0%)]\tLoss: 0.012475\n",
      "Train Epoch: 6 [640/10619 (6%)]\tLoss: 0.068131\n",
      "Train Epoch: 6 [1280/10619 (12%)]\tLoss: 0.061594\n",
      "Train Epoch: 6 [1920/10619 (18%)]\tLoss: 0.246655\n",
      "Train Epoch: 6 [2560/10619 (24%)]\tLoss: 0.105634\n",
      "Train Epoch: 6 [3200/10619 (30%)]\tLoss: 0.146084\n",
      "Train Epoch: 6 [3840/10619 (36%)]\tLoss: 0.073383\n",
      "Train Epoch: 6 [4480/10619 (42%)]\tLoss: 0.093517\n",
      "Train Epoch: 6 [5120/10619 (48%)]\tLoss: 0.025585\n",
      "Train Epoch: 6 [5760/10619 (54%)]\tLoss: 0.024435\n",
      "Train Epoch: 6 [6400/10619 (60%)]\tLoss: 0.032540\n",
      "Train Epoch: 6 [7040/10619 (66%)]\tLoss: 0.067569\n",
      "Train Epoch: 6 [7680/10619 (72%)]\tLoss: 0.023848\n",
      "Train Epoch: 6 [8320/10619 (78%)]\tLoss: 0.133955\n",
      "Train Epoch: 6 [8960/10619 (84%)]\tLoss: 0.033235\n",
      "Train Epoch: 6 [9600/10619 (90%)]\tLoss: 0.050853\n",
      "Train Epoch: 6 [10240/10619 (96%)]\tLoss: 0.162814\n",
      "Train Epoch: 7 [0/10619 (0%)]\tLoss: 0.086036\n",
      "Train Epoch: 7 [640/10619 (6%)]\tLoss: 0.144164\n",
      "Train Epoch: 7 [1280/10619 (12%)]\tLoss: 0.068611\n",
      "Train Epoch: 7 [1920/10619 (18%)]\tLoss: 0.049653\n",
      "Train Epoch: 7 [2560/10619 (24%)]\tLoss: 0.041876\n",
      "Train Epoch: 7 [3200/10619 (30%)]\tLoss: 0.054355\n",
      "Train Epoch: 7 [3840/10619 (36%)]\tLoss: 0.053949\n",
      "Train Epoch: 7 [4480/10619 (42%)]\tLoss: 0.064496\n",
      "Train Epoch: 7 [5120/10619 (48%)]\tLoss: 0.041309\n",
      "Train Epoch: 7 [5760/10619 (54%)]\tLoss: 0.092923\n",
      "Train Epoch: 7 [6400/10619 (60%)]\tLoss: 0.020277\n",
      "Train Epoch: 7 [7040/10619 (66%)]\tLoss: 0.056871\n",
      "Train Epoch: 7 [7680/10619 (72%)]\tLoss: 0.045357\n",
      "Train Epoch: 7 [8320/10619 (78%)]\tLoss: 0.059294\n",
      "Train Epoch: 7 [8960/10619 (84%)]\tLoss: 0.085263\n",
      "Train Epoch: 7 [9600/10619 (90%)]\tLoss: 0.046110\n",
      "Train Epoch: 7 [10240/10619 (96%)]\tLoss: 0.183171\n",
      "Train Epoch: 8 [0/10619 (0%)]\tLoss: 0.170356\n",
      "Train Epoch: 8 [640/10619 (6%)]\tLoss: 0.040931\n",
      "Train Epoch: 8 [1280/10619 (12%)]\tLoss: 0.061730\n",
      "Train Epoch: 8 [1920/10619 (18%)]\tLoss: 0.272588\n",
      "Train Epoch: 8 [2560/10619 (24%)]\tLoss: 0.044374\n",
      "Train Epoch: 8 [3200/10619 (30%)]\tLoss: 0.059570\n",
      "Train Epoch: 8 [3840/10619 (36%)]\tLoss: 0.033569\n",
      "Train Epoch: 8 [4480/10619 (42%)]\tLoss: 0.051732\n",
      "Train Epoch: 8 [5120/10619 (48%)]\tLoss: 0.301919\n",
      "Train Epoch: 8 [5760/10619 (54%)]\tLoss: 0.099489\n",
      "Train Epoch: 8 [6400/10619 (60%)]\tLoss: 0.070734\n",
      "Train Epoch: 8 [7040/10619 (66%)]\tLoss: 0.078173\n",
      "Train Epoch: 8 [7680/10619 (72%)]\tLoss: 0.054691\n",
      "Train Epoch: 8 [8320/10619 (78%)]\tLoss: 0.088897\n",
      "Train Epoch: 8 [8960/10619 (84%)]\tLoss: 0.192902\n",
      "Train Epoch: 8 [9600/10619 (90%)]\tLoss: 0.032653\n",
      "Train Epoch: 8 [10240/10619 (96%)]\tLoss: 0.084214\n",
      "Train Epoch: 9 [0/10619 (0%)]\tLoss: 0.217699\n",
      "Train Epoch: 9 [640/10619 (6%)]\tLoss: 0.126747\n",
      "Train Epoch: 9 [1280/10619 (12%)]\tLoss: 0.040535\n",
      "Train Epoch: 9 [1920/10619 (18%)]\tLoss: 0.163905\n",
      "Train Epoch: 9 [2560/10619 (24%)]\tLoss: 0.109623\n",
      "Train Epoch: 9 [3200/10619 (30%)]\tLoss: 0.033998\n",
      "Train Epoch: 9 [3840/10619 (36%)]\tLoss: 0.047960\n",
      "Train Epoch: 9 [4480/10619 (42%)]\tLoss: 0.103793\n",
      "Train Epoch: 9 [5120/10619 (48%)]\tLoss: 0.076442\n",
      "Train Epoch: 9 [5760/10619 (54%)]\tLoss: 0.020238\n",
      "Train Epoch: 9 [6400/10619 (60%)]\tLoss: 0.174406\n",
      "Train Epoch: 9 [7040/10619 (66%)]\tLoss: 0.059651\n",
      "Train Epoch: 9 [7680/10619 (72%)]\tLoss: 0.116313\n",
      "Train Epoch: 9 [8320/10619 (78%)]\tLoss: 0.283210\n",
      "Train Epoch: 9 [8960/10619 (84%)]\tLoss: 0.038074\n",
      "Train Epoch: 9 [9600/10619 (90%)]\tLoss: 0.109344\n",
      "Train Epoch: 9 [10240/10619 (96%)]\tLoss: 0.020075\n",
      "Train Epoch: 10 [0/10619 (0%)]\tLoss: 0.048869\n",
      "Train Epoch: 10 [640/10619 (6%)]\tLoss: 0.154809\n",
      "Train Epoch: 10 [1280/10619 (12%)]\tLoss: 0.312706\n",
      "Train Epoch: 10 [1920/10619 (18%)]\tLoss: 0.128821\n",
      "Train Epoch: 10 [2560/10619 (24%)]\tLoss: 0.084321\n",
      "Train Epoch: 10 [3200/10619 (30%)]\tLoss: 0.040907\n",
      "Train Epoch: 10 [3840/10619 (36%)]\tLoss: 0.053925\n",
      "Train Epoch: 10 [4480/10619 (42%)]\tLoss: 0.044542\n",
      "Train Epoch: 10 [5120/10619 (48%)]\tLoss: 0.068220\n",
      "Train Epoch: 10 [5760/10619 (54%)]\tLoss: 0.040906\n",
      "Train Epoch: 10 [6400/10619 (60%)]\tLoss: 0.040413\n",
      "Train Epoch: 10 [7040/10619 (66%)]\tLoss: 0.024737\n",
      "Train Epoch: 10 [7680/10619 (72%)]\tLoss: 0.104916\n",
      "Train Epoch: 10 [8320/10619 (78%)]\tLoss: 0.043681\n",
      "Train Epoch: 10 [8960/10619 (84%)]\tLoss: 0.027324\n",
      "Train Epoch: 10 [9600/10619 (90%)]\tLoss: 0.064097\n",
      "Train Epoch: 10 [10240/10619 (96%)]\tLoss: 0.013242\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/15392 (0%)]\tLoss: 0.225108\n",
      "Train Epoch: 1 [640/15392 (4%)]\tLoss: 0.049438\n",
      "Train Epoch: 1 [1280/15392 (8%)]\tLoss: 0.182352\n",
      "Train Epoch: 1 [1920/15392 (12%)]\tLoss: 0.231855\n",
      "Train Epoch: 1 [2560/15392 (17%)]\tLoss: 0.023258\n",
      "Train Epoch: 1 [3200/15392 (21%)]\tLoss: 0.047526\n",
      "Train Epoch: 1 [3840/15392 (25%)]\tLoss: 0.058101\n",
      "Train Epoch: 1 [4480/15392 (29%)]\tLoss: 0.026514\n",
      "Train Epoch: 1 [5120/15392 (33%)]\tLoss: 0.047682\n",
      "Train Epoch: 1 [5760/15392 (37%)]\tLoss: 0.057593\n",
      "Train Epoch: 1 [6400/15392 (41%)]\tLoss: 0.003001\n",
      "Train Epoch: 1 [7040/15392 (46%)]\tLoss: 0.093352\n",
      "Train Epoch: 1 [7680/15392 (50%)]\tLoss: 0.093415\n",
      "Train Epoch: 1 [8320/15392 (54%)]\tLoss: 0.107177\n",
      "Train Epoch: 1 [8960/15392 (58%)]\tLoss: 0.026885\n",
      "Train Epoch: 1 [9600/15392 (62%)]\tLoss: 0.021210\n",
      "Train Epoch: 1 [10240/15392 (66%)]\tLoss: 0.061612\n",
      "Train Epoch: 1 [10880/15392 (71%)]\tLoss: 0.051667\n",
      "Train Epoch: 1 [11520/15392 (75%)]\tLoss: 0.059101\n",
      "Train Epoch: 1 [12160/15392 (79%)]\tLoss: 0.162211\n",
      "Train Epoch: 1 [12800/15392 (83%)]\tLoss: 0.279346\n",
      "Train Epoch: 1 [13440/15392 (87%)]\tLoss: 0.093941\n",
      "Train Epoch: 1 [14080/15392 (91%)]\tLoss: 0.051621\n",
      "Train Epoch: 1 [14720/15392 (95%)]\tLoss: 0.098685\n",
      "Train Epoch: 1 [7680/15392 (100%)]\tLoss: 0.073582\n",
      "Train Epoch: 2 [0/15392 (0%)]\tLoss: 0.079249\n",
      "Train Epoch: 2 [640/15392 (4%)]\tLoss: 0.023360\n",
      "Train Epoch: 2 [1280/15392 (8%)]\tLoss: 0.065802\n",
      "Train Epoch: 2 [1920/15392 (12%)]\tLoss: 0.014737\n",
      "Train Epoch: 2 [2560/15392 (17%)]\tLoss: 0.031479\n",
      "Train Epoch: 2 [3200/15392 (21%)]\tLoss: 0.165134\n",
      "Train Epoch: 2 [3840/15392 (25%)]\tLoss: 0.076176\n",
      "Train Epoch: 2 [4480/15392 (29%)]\tLoss: 0.055017\n",
      "Train Epoch: 2 [5120/15392 (33%)]\tLoss: 0.020605\n",
      "Train Epoch: 2 [5760/15392 (37%)]\tLoss: 0.143347\n",
      "Train Epoch: 2 [6400/15392 (41%)]\tLoss: 0.118772\n",
      "Train Epoch: 2 [7040/15392 (46%)]\tLoss: 0.141294\n",
      "Train Epoch: 2 [7680/15392 (50%)]\tLoss: 0.018625\n",
      "Train Epoch: 2 [8320/15392 (54%)]\tLoss: 0.061113\n",
      "Train Epoch: 2 [8960/15392 (58%)]\tLoss: 0.025096\n",
      "Train Epoch: 2 [9600/15392 (62%)]\tLoss: 0.032305\n",
      "Train Epoch: 2 [10240/15392 (66%)]\tLoss: 0.022318\n",
      "Train Epoch: 2 [10880/15392 (71%)]\tLoss: 0.071599\n",
      "Train Epoch: 2 [11520/15392 (75%)]\tLoss: 0.089761\n",
      "Train Epoch: 2 [12160/15392 (79%)]\tLoss: 0.082457\n",
      "Train Epoch: 2 [12800/15392 (83%)]\tLoss: 0.042684\n",
      "Train Epoch: 2 [13440/15392 (87%)]\tLoss: 0.049521\n",
      "Train Epoch: 2 [14080/15392 (91%)]\tLoss: 0.065724\n",
      "Train Epoch: 2 [14720/15392 (95%)]\tLoss: 0.043813\n",
      "Train Epoch: 2 [7680/15392 (100%)]\tLoss: 0.003826\n",
      "Train Epoch: 3 [0/15392 (0%)]\tLoss: 0.197940\n",
      "Train Epoch: 3 [640/15392 (4%)]\tLoss: 0.024288\n",
      "Train Epoch: 3 [1280/15392 (8%)]\tLoss: 0.037133\n",
      "Train Epoch: 3 [1920/15392 (12%)]\tLoss: 0.168271\n",
      "Train Epoch: 3 [2560/15392 (17%)]\tLoss: 0.034162\n",
      "Train Epoch: 3 [3200/15392 (21%)]\tLoss: 0.162711\n",
      "Train Epoch: 3 [3840/15392 (25%)]\tLoss: 0.085074\n",
      "Train Epoch: 3 [4480/15392 (29%)]\tLoss: 0.196402\n",
      "Train Epoch: 3 [5120/15392 (33%)]\tLoss: 0.074519\n",
      "Train Epoch: 3 [5760/15392 (37%)]\tLoss: 0.021879\n",
      "Train Epoch: 3 [6400/15392 (41%)]\tLoss: 0.007334\n",
      "Train Epoch: 3 [7040/15392 (46%)]\tLoss: 0.130366\n",
      "Train Epoch: 3 [7680/15392 (50%)]\tLoss: 0.087044\n",
      "Train Epoch: 3 [8320/15392 (54%)]\tLoss: 0.051918\n",
      "Train Epoch: 3 [8960/15392 (58%)]\tLoss: 0.080081\n",
      "Train Epoch: 3 [9600/15392 (62%)]\tLoss: 0.064721\n",
      "Train Epoch: 3 [10240/15392 (66%)]\tLoss: 0.117377\n",
      "Train Epoch: 3 [10880/15392 (71%)]\tLoss: 0.024241\n",
      "Train Epoch: 3 [11520/15392 (75%)]\tLoss: 0.075671\n",
      "Train Epoch: 3 [12160/15392 (79%)]\tLoss: 0.176008\n",
      "Train Epoch: 3 [12800/15392 (83%)]\tLoss: 0.534396\n",
      "Train Epoch: 3 [13440/15392 (87%)]\tLoss: 0.022322\n",
      "Train Epoch: 3 [14080/15392 (91%)]\tLoss: 0.061977\n",
      "Train Epoch: 3 [14720/15392 (95%)]\tLoss: 0.033667\n",
      "Train Epoch: 3 [7680/15392 (100%)]\tLoss: 0.057012\n",
      "Train Epoch: 4 [0/15392 (0%)]\tLoss: 0.048559\n",
      "Train Epoch: 4 [640/15392 (4%)]\tLoss: 0.048430\n",
      "Train Epoch: 4 [1280/15392 (8%)]\tLoss: 0.028038\n",
      "Train Epoch: 4 [1920/15392 (12%)]\tLoss: 0.021442\n",
      "Train Epoch: 4 [2560/15392 (17%)]\tLoss: 0.028149\n",
      "Train Epoch: 4 [3200/15392 (21%)]\tLoss: 0.005955\n",
      "Train Epoch: 4 [3840/15392 (25%)]\tLoss: 0.116930\n",
      "Train Epoch: 4 [4480/15392 (29%)]\tLoss: 0.179337\n",
      "Train Epoch: 4 [5120/15392 (33%)]\tLoss: 0.022522\n",
      "Train Epoch: 4 [5760/15392 (37%)]\tLoss: 0.063731\n",
      "Train Epoch: 4 [6400/15392 (41%)]\tLoss: 0.109127\n",
      "Train Epoch: 4 [7040/15392 (46%)]\tLoss: 0.081037\n",
      "Train Epoch: 4 [7680/15392 (50%)]\tLoss: 0.123964\n",
      "Train Epoch: 4 [8320/15392 (54%)]\tLoss: 0.030610\n",
      "Train Epoch: 4 [8960/15392 (58%)]\tLoss: 0.035622\n",
      "Train Epoch: 4 [9600/15392 (62%)]\tLoss: 0.045563\n",
      "Train Epoch: 4 [10240/15392 (66%)]\tLoss: 0.073338\n",
      "Train Epoch: 4 [10880/15392 (71%)]\tLoss: 0.027943\n",
      "Train Epoch: 4 [11520/15392 (75%)]\tLoss: 0.052186\n",
      "Train Epoch: 4 [12160/15392 (79%)]\tLoss: 0.052434\n",
      "Train Epoch: 4 [12800/15392 (83%)]\tLoss: 0.097073\n",
      "Train Epoch: 4 [13440/15392 (87%)]\tLoss: 0.148291\n",
      "Train Epoch: 4 [14080/15392 (91%)]\tLoss: 0.055185\n",
      "Train Epoch: 4 [14720/15392 (95%)]\tLoss: 0.014192\n",
      "Train Epoch: 4 [7680/15392 (100%)]\tLoss: 0.011961\n",
      "Train Epoch: 5 [0/15392 (0%)]\tLoss: 0.028845\n",
      "Train Epoch: 5 [640/15392 (4%)]\tLoss: 0.056173\n",
      "Train Epoch: 5 [1280/15392 (8%)]\tLoss: 0.014723\n",
      "Train Epoch: 5 [1920/15392 (12%)]\tLoss: 0.058133\n",
      "Train Epoch: 5 [2560/15392 (17%)]\tLoss: 0.033915\n",
      "Train Epoch: 5 [3200/15392 (21%)]\tLoss: 0.015404\n",
      "Train Epoch: 5 [3840/15392 (25%)]\tLoss: 0.122997\n",
      "Train Epoch: 5 [4480/15392 (29%)]\tLoss: 0.146573\n",
      "Train Epoch: 5 [5120/15392 (33%)]\tLoss: 0.006081\n",
      "Train Epoch: 5 [5760/15392 (37%)]\tLoss: 0.015422\n",
      "Train Epoch: 5 [6400/15392 (41%)]\tLoss: 0.100167\n",
      "Train Epoch: 5 [7040/15392 (46%)]\tLoss: 0.020077\n",
      "Train Epoch: 5 [7680/15392 (50%)]\tLoss: 0.104324\n",
      "Train Epoch: 5 [8320/15392 (54%)]\tLoss: 0.087568\n",
      "Train Epoch: 5 [8960/15392 (58%)]\tLoss: 0.217469\n",
      "Train Epoch: 5 [9600/15392 (62%)]\tLoss: 0.021408\n",
      "Train Epoch: 5 [10240/15392 (66%)]\tLoss: 0.110902\n",
      "Train Epoch: 5 [10880/15392 (71%)]\tLoss: 0.020875\n",
      "Train Epoch: 5 [11520/15392 (75%)]\tLoss: 0.128330\n",
      "Train Epoch: 5 [12160/15392 (79%)]\tLoss: 0.111291\n",
      "Train Epoch: 5 [12800/15392 (83%)]\tLoss: 0.054918\n",
      "Train Epoch: 5 [13440/15392 (87%)]\tLoss: 0.190087\n",
      "Train Epoch: 5 [14080/15392 (91%)]\tLoss: 0.020673\n",
      "Train Epoch: 5 [14720/15392 (95%)]\tLoss: 0.017442\n",
      "Train Epoch: 5 [7680/15392 (100%)]\tLoss: 0.169332\n",
      "Train Epoch: 6 [0/15392 (0%)]\tLoss: 0.014227\n",
      "Train Epoch: 6 [640/15392 (4%)]\tLoss: 0.019180\n",
      "Train Epoch: 6 [1280/15392 (8%)]\tLoss: 0.147919\n",
      "Train Epoch: 6 [1920/15392 (12%)]\tLoss: 0.072893\n",
      "Train Epoch: 6 [2560/15392 (17%)]\tLoss: 0.018020\n",
      "Train Epoch: 6 [3200/15392 (21%)]\tLoss: 0.020185\n",
      "Train Epoch: 6 [3840/15392 (25%)]\tLoss: 0.015995\n",
      "Train Epoch: 6 [4480/15392 (29%)]\tLoss: 0.037403\n",
      "Train Epoch: 6 [5120/15392 (33%)]\tLoss: 0.078917\n",
      "Train Epoch: 6 [5760/15392 (37%)]\tLoss: 0.062517\n",
      "Train Epoch: 6 [6400/15392 (41%)]\tLoss: 0.028302\n",
      "Train Epoch: 6 [7040/15392 (46%)]\tLoss: 0.070043\n",
      "Train Epoch: 6 [7680/15392 (50%)]\tLoss: 0.099876\n",
      "Train Epoch: 6 [8320/15392 (54%)]\tLoss: 0.178106\n",
      "Train Epoch: 6 [8960/15392 (58%)]\tLoss: 0.079120\n",
      "Train Epoch: 6 [9600/15392 (62%)]\tLoss: 0.057677\n",
      "Train Epoch: 6 [10240/15392 (66%)]\tLoss: 0.155543\n",
      "Train Epoch: 6 [10880/15392 (71%)]\tLoss: 0.040809\n",
      "Train Epoch: 6 [11520/15392 (75%)]\tLoss: 0.140374\n",
      "Train Epoch: 6 [12160/15392 (79%)]\tLoss: 0.095818\n",
      "Train Epoch: 6 [12800/15392 (83%)]\tLoss: 0.033724\n",
      "Train Epoch: 6 [13440/15392 (87%)]\tLoss: 0.051180\n",
      "Train Epoch: 6 [14080/15392 (91%)]\tLoss: 0.075772\n",
      "Train Epoch: 6 [14720/15392 (95%)]\tLoss: 0.079659\n",
      "Train Epoch: 6 [7680/15392 (100%)]\tLoss: 0.068999\n",
      "Train Epoch: 7 [0/15392 (0%)]\tLoss: 0.126409\n",
      "Train Epoch: 7 [640/15392 (4%)]\tLoss: 0.012011\n",
      "Train Epoch: 7 [1280/15392 (8%)]\tLoss: 0.046792\n",
      "Train Epoch: 7 [1920/15392 (12%)]\tLoss: 0.100622\n",
      "Train Epoch: 7 [2560/15392 (17%)]\tLoss: 0.036850\n",
      "Train Epoch: 7 [3200/15392 (21%)]\tLoss: 0.174601\n",
      "Train Epoch: 7 [3840/15392 (25%)]\tLoss: 0.044747\n",
      "Train Epoch: 7 [4480/15392 (29%)]\tLoss: 0.065718\n",
      "Train Epoch: 7 [5120/15392 (33%)]\tLoss: 0.064529\n",
      "Train Epoch: 7 [5760/15392 (37%)]\tLoss: 0.012001\n",
      "Train Epoch: 7 [6400/15392 (41%)]\tLoss: 0.029318\n",
      "Train Epoch: 7 [7040/15392 (46%)]\tLoss: 0.013129\n",
      "Train Epoch: 7 [7680/15392 (50%)]\tLoss: 0.034222\n",
      "Train Epoch: 7 [8320/15392 (54%)]\tLoss: 0.011517\n",
      "Train Epoch: 7 [8960/15392 (58%)]\tLoss: 0.036921\n",
      "Train Epoch: 7 [9600/15392 (62%)]\tLoss: 0.040408\n",
      "Train Epoch: 7 [10240/15392 (66%)]\tLoss: 0.032581\n",
      "Train Epoch: 7 [10880/15392 (71%)]\tLoss: 0.026426\n",
      "Train Epoch: 7 [11520/15392 (75%)]\tLoss: 0.143027\n",
      "Train Epoch: 7 [12160/15392 (79%)]\tLoss: 0.025727\n",
      "Train Epoch: 7 [12800/15392 (83%)]\tLoss: 0.007279\n",
      "Train Epoch: 7 [13440/15392 (87%)]\tLoss: 0.024278\n",
      "Train Epoch: 7 [14080/15392 (91%)]\tLoss: 0.023061\n",
      "Train Epoch: 7 [14720/15392 (95%)]\tLoss: 0.033821\n",
      "Train Epoch: 7 [7680/15392 (100%)]\tLoss: 0.012504\n",
      "Train Epoch: 8 [0/15392 (0%)]\tLoss: 0.071938\n",
      "Train Epoch: 8 [640/15392 (4%)]\tLoss: 0.060585\n",
      "Train Epoch: 8 [1280/15392 (8%)]\tLoss: 0.008314\n",
      "Train Epoch: 8 [1920/15392 (12%)]\tLoss: 0.059701\n",
      "Train Epoch: 8 [2560/15392 (17%)]\tLoss: 0.010319\n",
      "Train Epoch: 8 [3200/15392 (21%)]\tLoss: 0.026029\n",
      "Train Epoch: 8 [3840/15392 (25%)]\tLoss: 0.106829\n",
      "Train Epoch: 8 [4480/15392 (29%)]\tLoss: 0.014719\n",
      "Train Epoch: 8 [5120/15392 (33%)]\tLoss: 0.039857\n",
      "Train Epoch: 8 [5760/15392 (37%)]\tLoss: 0.005737\n",
      "Train Epoch: 8 [6400/15392 (41%)]\tLoss: 0.106619\n",
      "Train Epoch: 8 [7040/15392 (46%)]\tLoss: 0.028111\n",
      "Train Epoch: 8 [7680/15392 (50%)]\tLoss: 0.017425\n",
      "Train Epoch: 8 [8320/15392 (54%)]\tLoss: 0.025937\n",
      "Train Epoch: 8 [8960/15392 (58%)]\tLoss: 0.046987\n",
      "Train Epoch: 8 [9600/15392 (62%)]\tLoss: 0.017996\n",
      "Train Epoch: 8 [10240/15392 (66%)]\tLoss: 0.072304\n",
      "Train Epoch: 8 [10880/15392 (71%)]\tLoss: 0.068772\n",
      "Train Epoch: 8 [11520/15392 (75%)]\tLoss: 0.054259\n",
      "Train Epoch: 8 [12160/15392 (79%)]\tLoss: 0.128354\n",
      "Train Epoch: 8 [12800/15392 (83%)]\tLoss: 0.061157\n",
      "Train Epoch: 8 [13440/15392 (87%)]\tLoss: 0.014779\n",
      "Train Epoch: 8 [14080/15392 (91%)]\tLoss: 0.051018\n",
      "Train Epoch: 8 [14720/15392 (95%)]\tLoss: 0.044814\n",
      "Train Epoch: 8 [7680/15392 (100%)]\tLoss: 0.007019\n",
      "Train Epoch: 9 [0/15392 (0%)]\tLoss: 0.040903\n",
      "Train Epoch: 9 [640/15392 (4%)]\tLoss: 0.022557\n",
      "Train Epoch: 9 [1280/15392 (8%)]\tLoss: 0.090578\n",
      "Train Epoch: 9 [1920/15392 (12%)]\tLoss: 0.052369\n",
      "Train Epoch: 9 [2560/15392 (17%)]\tLoss: 0.012144\n",
      "Train Epoch: 9 [3200/15392 (21%)]\tLoss: 0.086857\n",
      "Train Epoch: 9 [3840/15392 (25%)]\tLoss: 0.124009\n",
      "Train Epoch: 9 [4480/15392 (29%)]\tLoss: 0.036044\n",
      "Train Epoch: 9 [5120/15392 (33%)]\tLoss: 0.027032\n",
      "Train Epoch: 9 [5760/15392 (37%)]\tLoss: 0.015089\n",
      "Train Epoch: 9 [6400/15392 (41%)]\tLoss: 0.112524\n",
      "Train Epoch: 9 [7040/15392 (46%)]\tLoss: 0.069568\n",
      "Train Epoch: 9 [7680/15392 (50%)]\tLoss: 0.029090\n",
      "Train Epoch: 9 [8320/15392 (54%)]\tLoss: 0.086575\n",
      "Train Epoch: 9 [8960/15392 (58%)]\tLoss: 0.035991\n",
      "Train Epoch: 9 [9600/15392 (62%)]\tLoss: 0.043006\n",
      "Train Epoch: 9 [10240/15392 (66%)]\tLoss: 0.068827\n",
      "Train Epoch: 9 [10880/15392 (71%)]\tLoss: 0.021546\n",
      "Train Epoch: 9 [11520/15392 (75%)]\tLoss: 0.020211\n",
      "Train Epoch: 9 [12160/15392 (79%)]\tLoss: 0.008819\n",
      "Train Epoch: 9 [12800/15392 (83%)]\tLoss: 0.089997\n",
      "Train Epoch: 9 [13440/15392 (87%)]\tLoss: 0.024211\n",
      "Train Epoch: 9 [14080/15392 (91%)]\tLoss: 0.168900\n",
      "Train Epoch: 9 [14720/15392 (95%)]\tLoss: 0.023598\n",
      "Train Epoch: 9 [7680/15392 (100%)]\tLoss: 0.007206\n",
      "Train Epoch: 10 [0/15392 (0%)]\tLoss: 0.014926\n",
      "Train Epoch: 10 [640/15392 (4%)]\tLoss: 0.035300\n",
      "Train Epoch: 10 [1280/15392 (8%)]\tLoss: 0.121819\n",
      "Train Epoch: 10 [1920/15392 (12%)]\tLoss: 0.052605\n",
      "Train Epoch: 10 [2560/15392 (17%)]\tLoss: 0.039758\n",
      "Train Epoch: 10 [3200/15392 (21%)]\tLoss: 0.118672\n",
      "Train Epoch: 10 [3840/15392 (25%)]\tLoss: 0.054823\n",
      "Train Epoch: 10 [4480/15392 (29%)]\tLoss: 0.007024\n",
      "Train Epoch: 10 [5120/15392 (33%)]\tLoss: 0.171159\n",
      "Train Epoch: 10 [5760/15392 (37%)]\tLoss: 0.032816\n",
      "Train Epoch: 10 [6400/15392 (41%)]\tLoss: 0.099181\n",
      "Train Epoch: 10 [7040/15392 (46%)]\tLoss: 0.101733\n",
      "Train Epoch: 10 [7680/15392 (50%)]\tLoss: 0.083393\n",
      "Train Epoch: 10 [8320/15392 (54%)]\tLoss: 0.037186\n",
      "Train Epoch: 10 [8960/15392 (58%)]\tLoss: 0.047899\n",
      "Train Epoch: 10 [9600/15392 (62%)]\tLoss: 0.141361\n",
      "Train Epoch: 10 [10240/15392 (66%)]\tLoss: 0.017259\n",
      "Train Epoch: 10 [10880/15392 (71%)]\tLoss: 0.113052\n",
      "Train Epoch: 10 [11520/15392 (75%)]\tLoss: 0.069466\n",
      "Train Epoch: 10 [12160/15392 (79%)]\tLoss: 0.032186\n",
      "Train Epoch: 10 [12800/15392 (83%)]\tLoss: 0.053665\n",
      "Train Epoch: 10 [13440/15392 (87%)]\tLoss: 0.030670\n",
      "Train Epoch: 10 [14080/15392 (91%)]\tLoss: 0.062247\n",
      "Train Epoch: 10 [14720/15392 (95%)]\tLoss: 0.017180\n",
      "Train Epoch: 10 [7680/15392 (100%)]\tLoss: 0.055384\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/15327 (0%)]\tLoss: 0.108891\n",
      "Train Epoch: 1 [640/15327 (4%)]\tLoss: 0.095740\n",
      "Train Epoch: 1 [1280/15327 (8%)]\tLoss: 0.235053\n",
      "Train Epoch: 1 [1920/15327 (12%)]\tLoss: 0.079258\n",
      "Train Epoch: 1 [2560/15327 (17%)]\tLoss: 0.123498\n",
      "Train Epoch: 1 [3200/15327 (21%)]\tLoss: 0.079266\n",
      "Train Epoch: 1 [3840/15327 (25%)]\tLoss: 0.056506\n",
      "Train Epoch: 1 [4480/15327 (29%)]\tLoss: 0.027757\n",
      "Train Epoch: 1 [5120/15327 (33%)]\tLoss: 0.043526\n",
      "Train Epoch: 1 [5760/15327 (38%)]\tLoss: 0.078997\n",
      "Train Epoch: 1 [6400/15327 (42%)]\tLoss: 0.052680\n",
      "Train Epoch: 1 [7040/15327 (46%)]\tLoss: 0.057655\n",
      "Train Epoch: 1 [7680/15327 (50%)]\tLoss: 0.029966\n",
      "Train Epoch: 1 [8320/15327 (54%)]\tLoss: 0.054711\n",
      "Train Epoch: 1 [8960/15327 (58%)]\tLoss: 0.165028\n",
      "Train Epoch: 1 [9600/15327 (62%)]\tLoss: 0.098572\n",
      "Train Epoch: 1 [10240/15327 (67%)]\tLoss: 0.239293\n",
      "Train Epoch: 1 [10880/15327 (71%)]\tLoss: 0.048242\n",
      "Train Epoch: 1 [11520/15327 (75%)]\tLoss: 0.057014\n",
      "Train Epoch: 1 [12160/15327 (79%)]\tLoss: 0.291677\n",
      "Train Epoch: 1 [12800/15327 (83%)]\tLoss: 0.119451\n",
      "Train Epoch: 1 [13440/15327 (88%)]\tLoss: 0.020904\n",
      "Train Epoch: 1 [14080/15327 (92%)]\tLoss: 0.101731\n",
      "Train Epoch: 1 [14720/15327 (96%)]\tLoss: 0.061803\n",
      "Train Epoch: 2 [0/15327 (0%)]\tLoss: 0.136273\n",
      "Train Epoch: 2 [640/15327 (4%)]\tLoss: 0.112107\n",
      "Train Epoch: 2 [1280/15327 (8%)]\tLoss: 0.223680\n",
      "Train Epoch: 2 [1920/15327 (12%)]\tLoss: 0.043790\n",
      "Train Epoch: 2 [2560/15327 (17%)]\tLoss: 0.021112\n",
      "Train Epoch: 2 [3200/15327 (21%)]\tLoss: 0.086041\n",
      "Train Epoch: 2 [3840/15327 (25%)]\tLoss: 0.059424\n",
      "Train Epoch: 2 [4480/15327 (29%)]\tLoss: 0.094464\n",
      "Train Epoch: 2 [5120/15327 (33%)]\tLoss: 0.139586\n",
      "Train Epoch: 2 [5760/15327 (38%)]\tLoss: 0.179811\n",
      "Train Epoch: 2 [6400/15327 (42%)]\tLoss: 0.060186\n",
      "Train Epoch: 2 [7040/15327 (46%)]\tLoss: 0.073868\n",
      "Train Epoch: 2 [7680/15327 (50%)]\tLoss: 0.083091\n",
      "Train Epoch: 2 [8320/15327 (54%)]\tLoss: 0.073654\n",
      "Train Epoch: 2 [8960/15327 (58%)]\tLoss: 0.023918\n",
      "Train Epoch: 2 [9600/15327 (62%)]\tLoss: 0.063687\n",
      "Train Epoch: 2 [10240/15327 (67%)]\tLoss: 0.029797\n",
      "Train Epoch: 2 [10880/15327 (71%)]\tLoss: 0.063596\n",
      "Train Epoch: 2 [11520/15327 (75%)]\tLoss: 0.139047\n",
      "Train Epoch: 2 [12160/15327 (79%)]\tLoss: 0.078160\n",
      "Train Epoch: 2 [12800/15327 (83%)]\tLoss: 0.054325\n",
      "Train Epoch: 2 [13440/15327 (88%)]\tLoss: 0.109590\n",
      "Train Epoch: 2 [14080/15327 (92%)]\tLoss: 0.070068\n",
      "Train Epoch: 2 [14720/15327 (96%)]\tLoss: 0.010070\n",
      "Train Epoch: 3 [0/15327 (0%)]\tLoss: 0.193154\n",
      "Train Epoch: 3 [640/15327 (4%)]\tLoss: 0.015577\n",
      "Train Epoch: 3 [1280/15327 (8%)]\tLoss: 0.172613\n",
      "Train Epoch: 3 [1920/15327 (12%)]\tLoss: 0.015488\n",
      "Train Epoch: 3 [2560/15327 (17%)]\tLoss: 0.082279\n",
      "Train Epoch: 3 [3200/15327 (21%)]\tLoss: 0.044731\n",
      "Train Epoch: 3 [3840/15327 (25%)]\tLoss: 0.009854\n",
      "Train Epoch: 3 [4480/15327 (29%)]\tLoss: 0.078894\n",
      "Train Epoch: 3 [5120/15327 (33%)]\tLoss: 0.103832\n",
      "Train Epoch: 3 [5760/15327 (38%)]\tLoss: 0.062920\n",
      "Train Epoch: 3 [6400/15327 (42%)]\tLoss: 0.034289\n",
      "Train Epoch: 3 [7040/15327 (46%)]\tLoss: 0.126272\n",
      "Train Epoch: 3 [7680/15327 (50%)]\tLoss: 0.054713\n",
      "Train Epoch: 3 [8320/15327 (54%)]\tLoss: 0.038573\n",
      "Train Epoch: 3 [8960/15327 (58%)]\tLoss: 0.122092\n",
      "Train Epoch: 3 [9600/15327 (62%)]\tLoss: 0.047251\n",
      "Train Epoch: 3 [10240/15327 (67%)]\tLoss: 0.119241\n",
      "Train Epoch: 3 [10880/15327 (71%)]\tLoss: 0.050672\n",
      "Train Epoch: 3 [11520/15327 (75%)]\tLoss: 0.086497\n",
      "Train Epoch: 3 [12160/15327 (79%)]\tLoss: 0.025455\n",
      "Train Epoch: 3 [12800/15327 (83%)]\tLoss: 0.036877\n",
      "Train Epoch: 3 [13440/15327 (88%)]\tLoss: 0.269754\n",
      "Train Epoch: 3 [14080/15327 (92%)]\tLoss: 0.023092\n",
      "Train Epoch: 3 [14720/15327 (96%)]\tLoss: 0.024081\n",
      "Train Epoch: 4 [0/15327 (0%)]\tLoss: 0.013227\n",
      "Train Epoch: 4 [640/15327 (4%)]\tLoss: 0.014589\n",
      "Train Epoch: 4 [1280/15327 (8%)]\tLoss: 0.081571\n",
      "Train Epoch: 4 [1920/15327 (12%)]\tLoss: 0.090352\n",
      "Train Epoch: 4 [2560/15327 (17%)]\tLoss: 0.142439\n",
      "Train Epoch: 4 [3200/15327 (21%)]\tLoss: 0.030254\n",
      "Train Epoch: 4 [3840/15327 (25%)]\tLoss: 0.008413\n",
      "Train Epoch: 4 [4480/15327 (29%)]\tLoss: 0.103899\n",
      "Train Epoch: 4 [5120/15327 (33%)]\tLoss: 0.099506\n",
      "Train Epoch: 4 [5760/15327 (38%)]\tLoss: 0.069823\n",
      "Train Epoch: 4 [6400/15327 (42%)]\tLoss: 0.076529\n",
      "Train Epoch: 4 [7040/15327 (46%)]\tLoss: 0.125200\n",
      "Train Epoch: 4 [7680/15327 (50%)]\tLoss: 0.176345\n",
      "Train Epoch: 4 [8320/15327 (54%)]\tLoss: 0.026053\n",
      "Train Epoch: 4 [8960/15327 (58%)]\tLoss: 0.020135\n",
      "Train Epoch: 4 [9600/15327 (62%)]\tLoss: 0.028835\n",
      "Train Epoch: 4 [10240/15327 (67%)]\tLoss: 0.009796\n",
      "Train Epoch: 4 [10880/15327 (71%)]\tLoss: 0.034550\n",
      "Train Epoch: 4 [11520/15327 (75%)]\tLoss: 0.196899\n",
      "Train Epoch: 4 [12160/15327 (79%)]\tLoss: 0.055976\n",
      "Train Epoch: 4 [12800/15327 (83%)]\tLoss: 0.308171\n",
      "Train Epoch: 4 [13440/15327 (88%)]\tLoss: 0.028484\n",
      "Train Epoch: 4 [14080/15327 (92%)]\tLoss: 0.017365\n",
      "Train Epoch: 4 [14720/15327 (96%)]\tLoss: 0.020656\n",
      "Train Epoch: 5 [0/15327 (0%)]\tLoss: 0.086176\n",
      "Train Epoch: 5 [640/15327 (4%)]\tLoss: 0.090240\n",
      "Train Epoch: 5 [1280/15327 (8%)]\tLoss: 0.097612\n",
      "Train Epoch: 5 [1920/15327 (12%)]\tLoss: 0.099988\n",
      "Train Epoch: 5 [2560/15327 (17%)]\tLoss: 0.131378\n",
      "Train Epoch: 5 [3200/15327 (21%)]\tLoss: 0.041759\n",
      "Train Epoch: 5 [3840/15327 (25%)]\tLoss: 0.058224\n",
      "Train Epoch: 5 [4480/15327 (29%)]\tLoss: 0.020019\n",
      "Train Epoch: 5 [5120/15327 (33%)]\tLoss: 0.037210\n",
      "Train Epoch: 5 [5760/15327 (38%)]\tLoss: 0.071489\n",
      "Train Epoch: 5 [6400/15327 (42%)]\tLoss: 0.107565\n",
      "Train Epoch: 5 [7040/15327 (46%)]\tLoss: 0.083057\n",
      "Train Epoch: 5 [7680/15327 (50%)]\tLoss: 0.054562\n",
      "Train Epoch: 5 [8320/15327 (54%)]\tLoss: 0.027078\n",
      "Train Epoch: 5 [8960/15327 (58%)]\tLoss: 0.098992\n",
      "Train Epoch: 5 [9600/15327 (62%)]\tLoss: 0.059658\n",
      "Train Epoch: 5 [10240/15327 (67%)]\tLoss: 0.143199\n",
      "Train Epoch: 5 [10880/15327 (71%)]\tLoss: 0.057668\n",
      "Train Epoch: 5 [11520/15327 (75%)]\tLoss: 0.039314\n",
      "Train Epoch: 5 [12160/15327 (79%)]\tLoss: 0.036400\n",
      "Train Epoch: 5 [12800/15327 (83%)]\tLoss: 0.006963\n",
      "Train Epoch: 5 [13440/15327 (88%)]\tLoss: 0.089007\n",
      "Train Epoch: 5 [14080/15327 (92%)]\tLoss: 0.088760\n",
      "Train Epoch: 5 [14720/15327 (96%)]\tLoss: 0.035086\n",
      "Train Epoch: 6 [0/15327 (0%)]\tLoss: 0.055050\n",
      "Train Epoch: 6 [640/15327 (4%)]\tLoss: 0.044829\n",
      "Train Epoch: 6 [1280/15327 (8%)]\tLoss: 0.104096\n",
      "Train Epoch: 6 [1920/15327 (12%)]\tLoss: 0.059717\n",
      "Train Epoch: 6 [2560/15327 (17%)]\tLoss: 0.010999\n",
      "Train Epoch: 6 [3200/15327 (21%)]\tLoss: 0.076741\n",
      "Train Epoch: 6 [3840/15327 (25%)]\tLoss: 0.051160\n",
      "Train Epoch: 6 [4480/15327 (29%)]\tLoss: 0.061809\n",
      "Train Epoch: 6 [5120/15327 (33%)]\tLoss: 0.052605\n",
      "Train Epoch: 6 [5760/15327 (38%)]\tLoss: 0.061909\n",
      "Train Epoch: 6 [6400/15327 (42%)]\tLoss: 0.069155\n",
      "Train Epoch: 6 [7040/15327 (46%)]\tLoss: 0.045355\n",
      "Train Epoch: 6 [7680/15327 (50%)]\tLoss: 0.085657\n",
      "Train Epoch: 6 [8320/15327 (54%)]\tLoss: 0.091357\n",
      "Train Epoch: 6 [8960/15327 (58%)]\tLoss: 0.056533\n",
      "Train Epoch: 6 [9600/15327 (62%)]\tLoss: 0.140250\n",
      "Train Epoch: 6 [10240/15327 (67%)]\tLoss: 0.057462\n",
      "Train Epoch: 6 [10880/15327 (71%)]\tLoss: 0.018321\n",
      "Train Epoch: 6 [11520/15327 (75%)]\tLoss: 0.055102\n",
      "Train Epoch: 6 [12160/15327 (79%)]\tLoss: 0.003660\n",
      "Train Epoch: 6 [12800/15327 (83%)]\tLoss: 0.094851\n",
      "Train Epoch: 6 [13440/15327 (88%)]\tLoss: 0.171736\n",
      "Train Epoch: 6 [14080/15327 (92%)]\tLoss: 0.035405\n",
      "Train Epoch: 6 [14720/15327 (96%)]\tLoss: 0.053811\n",
      "Train Epoch: 7 [0/15327 (0%)]\tLoss: 0.047650\n",
      "Train Epoch: 7 [640/15327 (4%)]\tLoss: 0.084797\n",
      "Train Epoch: 7 [1280/15327 (8%)]\tLoss: 0.013038\n",
      "Train Epoch: 7 [1920/15327 (12%)]\tLoss: 0.082654\n",
      "Train Epoch: 7 [2560/15327 (17%)]\tLoss: 0.031219\n",
      "Train Epoch: 7 [3200/15327 (21%)]\tLoss: 0.029991\n",
      "Train Epoch: 7 [3840/15327 (25%)]\tLoss: 0.103439\n",
      "Train Epoch: 7 [4480/15327 (29%)]\tLoss: 0.035984\n",
      "Train Epoch: 7 [5120/15327 (33%)]\tLoss: 0.103112\n",
      "Train Epoch: 7 [5760/15327 (38%)]\tLoss: 0.065609\n",
      "Train Epoch: 7 [6400/15327 (42%)]\tLoss: 0.075651\n",
      "Train Epoch: 7 [7040/15327 (46%)]\tLoss: 0.121549\n",
      "Train Epoch: 7 [7680/15327 (50%)]\tLoss: 0.030942\n",
      "Train Epoch: 7 [8320/15327 (54%)]\tLoss: 0.116208\n",
      "Train Epoch: 7 [8960/15327 (58%)]\tLoss: 0.039865\n",
      "Train Epoch: 7 [9600/15327 (62%)]\tLoss: 0.070805\n",
      "Train Epoch: 7 [10240/15327 (67%)]\tLoss: 0.025529\n",
      "Train Epoch: 7 [10880/15327 (71%)]\tLoss: 0.108928\n",
      "Train Epoch: 7 [11520/15327 (75%)]\tLoss: 0.060832\n",
      "Train Epoch: 7 [12160/15327 (79%)]\tLoss: 0.067704\n",
      "Train Epoch: 7 [12800/15327 (83%)]\tLoss: 0.276625\n",
      "Train Epoch: 7 [13440/15327 (88%)]\tLoss: 0.039478\n",
      "Train Epoch: 7 [14080/15327 (92%)]\tLoss: 0.032073\n",
      "Train Epoch: 7 [14720/15327 (96%)]\tLoss: 0.110678\n",
      "Train Epoch: 8 [0/15327 (0%)]\tLoss: 0.019514\n",
      "Train Epoch: 8 [640/15327 (4%)]\tLoss: 0.009775\n",
      "Train Epoch: 8 [1280/15327 (8%)]\tLoss: 0.001451\n",
      "Train Epoch: 8 [1920/15327 (12%)]\tLoss: 0.047060\n",
      "Train Epoch: 8 [2560/15327 (17%)]\tLoss: 0.026121\n",
      "Train Epoch: 8 [3200/15327 (21%)]\tLoss: 0.108265\n",
      "Train Epoch: 8 [3840/15327 (25%)]\tLoss: 0.120803\n",
      "Train Epoch: 8 [4480/15327 (29%)]\tLoss: 0.009508\n",
      "Train Epoch: 8 [5120/15327 (33%)]\tLoss: 0.217559\n",
      "Train Epoch: 8 [5760/15327 (38%)]\tLoss: 0.016901\n",
      "Train Epoch: 8 [6400/15327 (42%)]\tLoss: 0.145755\n",
      "Train Epoch: 8 [7040/15327 (46%)]\tLoss: 0.040062\n",
      "Train Epoch: 8 [7680/15327 (50%)]\tLoss: 0.121786\n",
      "Train Epoch: 8 [8320/15327 (54%)]\tLoss: 0.053313\n",
      "Train Epoch: 8 [8960/15327 (58%)]\tLoss: 0.036881\n",
      "Train Epoch: 8 [9600/15327 (62%)]\tLoss: 0.071348\n",
      "Train Epoch: 8 [10240/15327 (67%)]\tLoss: 0.141503\n",
      "Train Epoch: 8 [10880/15327 (71%)]\tLoss: 0.044411\n",
      "Train Epoch: 8 [11520/15327 (75%)]\tLoss: 0.124066\n",
      "Train Epoch: 8 [12160/15327 (79%)]\tLoss: 0.024224\n",
      "Train Epoch: 8 [12800/15327 (83%)]\tLoss: 0.053110\n",
      "Train Epoch: 8 [13440/15327 (88%)]\tLoss: 0.050509\n",
      "Train Epoch: 8 [14080/15327 (92%)]\tLoss: 0.026385\n",
      "Train Epoch: 8 [14720/15327 (96%)]\tLoss: 0.072165\n",
      "Train Epoch: 9 [0/15327 (0%)]\tLoss: 0.029823\n",
      "Train Epoch: 9 [640/15327 (4%)]\tLoss: 0.031865\n",
      "Train Epoch: 9 [1280/15327 (8%)]\tLoss: 0.132795\n",
      "Train Epoch: 9 [1920/15327 (12%)]\tLoss: 0.007596\n",
      "Train Epoch: 9 [2560/15327 (17%)]\tLoss: 0.047941\n",
      "Train Epoch: 9 [3200/15327 (21%)]\tLoss: 0.071640\n",
      "Train Epoch: 9 [3840/15327 (25%)]\tLoss: 0.025433\n",
      "Train Epoch: 9 [4480/15327 (29%)]\tLoss: 0.052006\n",
      "Train Epoch: 9 [5120/15327 (33%)]\tLoss: 0.021322\n",
      "Train Epoch: 9 [5760/15327 (38%)]\tLoss: 0.020217\n",
      "Train Epoch: 9 [6400/15327 (42%)]\tLoss: 0.135698\n",
      "Train Epoch: 9 [7040/15327 (46%)]\tLoss: 0.186125\n",
      "Train Epoch: 9 [7680/15327 (50%)]\tLoss: 0.170468\n",
      "Train Epoch: 9 [8320/15327 (54%)]\tLoss: 0.019699\n",
      "Train Epoch: 9 [8960/15327 (58%)]\tLoss: 0.136675\n",
      "Train Epoch: 9 [9600/15327 (62%)]\tLoss: 0.038811\n",
      "Train Epoch: 9 [10240/15327 (67%)]\tLoss: 0.041073\n",
      "Train Epoch: 9 [10880/15327 (71%)]\tLoss: 0.109914\n",
      "Train Epoch: 9 [11520/15327 (75%)]\tLoss: 0.083130\n",
      "Train Epoch: 9 [12160/15327 (79%)]\tLoss: 0.099762\n",
      "Train Epoch: 9 [12800/15327 (83%)]\tLoss: 0.104568\n",
      "Train Epoch: 9 [13440/15327 (88%)]\tLoss: 0.079202\n",
      "Train Epoch: 9 [14080/15327 (92%)]\tLoss: 0.021349\n",
      "Train Epoch: 9 [14720/15327 (96%)]\tLoss: 0.076807\n",
      "Train Epoch: 10 [0/15327 (0%)]\tLoss: 0.042741\n",
      "Train Epoch: 10 [640/15327 (4%)]\tLoss: 0.037564\n",
      "Train Epoch: 10 [1280/15327 (8%)]\tLoss: 0.038304\n",
      "Train Epoch: 10 [1920/15327 (12%)]\tLoss: 0.024107\n",
      "Train Epoch: 10 [2560/15327 (17%)]\tLoss: 0.027404\n",
      "Train Epoch: 10 [3200/15327 (21%)]\tLoss: 0.090183\n",
      "Train Epoch: 10 [3840/15327 (25%)]\tLoss: 0.006928\n",
      "Train Epoch: 10 [4480/15327 (29%)]\tLoss: 0.066307\n",
      "Train Epoch: 10 [5120/15327 (33%)]\tLoss: 0.036211\n",
      "Train Epoch: 10 [5760/15327 (38%)]\tLoss: 0.012192\n",
      "Train Epoch: 10 [6400/15327 (42%)]\tLoss: 0.020460\n",
      "Train Epoch: 10 [7040/15327 (46%)]\tLoss: 0.066181\n",
      "Train Epoch: 10 [7680/15327 (50%)]\tLoss: 0.040569\n",
      "Train Epoch: 10 [8320/15327 (54%)]\tLoss: 0.127416\n",
      "Train Epoch: 10 [8960/15327 (58%)]\tLoss: 0.048080\n",
      "Train Epoch: 10 [9600/15327 (62%)]\tLoss: 0.061160\n",
      "Train Epoch: 10 [10240/15327 (67%)]\tLoss: 0.082859\n",
      "Train Epoch: 10 [10880/15327 (71%)]\tLoss: 0.047861\n",
      "Train Epoch: 10 [11520/15327 (75%)]\tLoss: 0.050029\n",
      "Train Epoch: 10 [12160/15327 (79%)]\tLoss: 0.049947\n",
      "Train Epoch: 10 [12800/15327 (83%)]\tLoss: 0.050160\n",
      "Train Epoch: 10 [13440/15327 (88%)]\tLoss: 0.035749\n",
      "Train Epoch: 10 [14080/15327 (92%)]\tLoss: 0.064867\n",
      "Train Epoch: 10 [14720/15327 (96%)]\tLoss: 0.029083\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.1755, Accuracy: 9866/10000 (99%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/18662 (0%)]\tLoss: 0.029370\n",
      "Train Epoch: 1 [640/18662 (3%)]\tLoss: 0.028509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1280/18662 (7%)]\tLoss: 0.063748\n",
      "Train Epoch: 1 [1920/18662 (10%)]\tLoss: 0.182488\n",
      "Train Epoch: 1 [2560/18662 (14%)]\tLoss: 0.051980\n",
      "Train Epoch: 1 [3200/18662 (17%)]\tLoss: 0.139318\n",
      "Train Epoch: 1 [3840/18662 (21%)]\tLoss: 0.104834\n",
      "Train Epoch: 1 [4480/18662 (24%)]\tLoss: 0.040354\n",
      "Train Epoch: 1 [5120/18662 (27%)]\tLoss: 0.068964\n",
      "Train Epoch: 1 [5760/18662 (31%)]\tLoss: 0.029298\n",
      "Train Epoch: 1 [6400/18662 (34%)]\tLoss: 0.079106\n",
      "Train Epoch: 1 [7040/18662 (38%)]\tLoss: 0.091678\n",
      "Train Epoch: 1 [7680/18662 (41%)]\tLoss: 0.040233\n",
      "Train Epoch: 1 [8320/18662 (45%)]\tLoss: 0.019249\n",
      "Train Epoch: 1 [8960/18662 (48%)]\tLoss: 0.052733\n",
      "Train Epoch: 1 [9600/18662 (51%)]\tLoss: 0.066595\n",
      "Train Epoch: 1 [10240/18662 (55%)]\tLoss: 0.065710\n",
      "Train Epoch: 1 [10880/18662 (58%)]\tLoss: 0.048437\n",
      "Train Epoch: 1 [11520/18662 (62%)]\tLoss: 0.025629\n",
      "Train Epoch: 1 [12160/18662 (65%)]\tLoss: 0.036823\n",
      "Train Epoch: 1 [12800/18662 (68%)]\tLoss: 0.078549\n",
      "Train Epoch: 1 [13440/18662 (72%)]\tLoss: 0.135101\n",
      "Train Epoch: 1 [14080/18662 (75%)]\tLoss: 0.021069\n",
      "Train Epoch: 1 [14720/18662 (79%)]\tLoss: 0.148284\n",
      "Train Epoch: 1 [15360/18662 (82%)]\tLoss: 0.010088\n",
      "Train Epoch: 1 [16000/18662 (86%)]\tLoss: 0.098794\n",
      "Train Epoch: 1 [16640/18662 (89%)]\tLoss: 0.021146\n",
      "Train Epoch: 1 [17280/18662 (92%)]\tLoss: 0.037699\n",
      "Train Epoch: 1 [17920/18662 (96%)]\tLoss: 0.051854\n",
      "Train Epoch: 1 [18560/18662 (99%)]\tLoss: 0.031580\n",
      "Train Epoch: 2 [0/18662 (0%)]\tLoss: 0.021004\n",
      "Train Epoch: 2 [640/18662 (3%)]\tLoss: 0.083108\n",
      "Train Epoch: 2 [1280/18662 (7%)]\tLoss: 0.109054\n",
      "Train Epoch: 2 [1920/18662 (10%)]\tLoss: 0.173696\n",
      "Train Epoch: 2 [2560/18662 (14%)]\tLoss: 0.038655\n",
      "Train Epoch: 2 [3200/18662 (17%)]\tLoss: 0.050361\n",
      "Train Epoch: 2 [3840/18662 (21%)]\tLoss: 0.103026\n",
      "Train Epoch: 2 [4480/18662 (24%)]\tLoss: 0.063588\n",
      "Train Epoch: 2 [5120/18662 (27%)]\tLoss: 0.077884\n",
      "Train Epoch: 2 [5760/18662 (31%)]\tLoss: 0.095522\n",
      "Train Epoch: 2 [6400/18662 (34%)]\tLoss: 0.025697\n",
      "Train Epoch: 2 [7040/18662 (38%)]\tLoss: 0.065011\n",
      "Train Epoch: 2 [7680/18662 (41%)]\tLoss: 0.152421\n",
      "Train Epoch: 2 [8320/18662 (45%)]\tLoss: 0.055435\n",
      "Train Epoch: 2 [8960/18662 (48%)]\tLoss: 0.015860\n",
      "Train Epoch: 2 [9600/18662 (51%)]\tLoss: 0.032426\n",
      "Train Epoch: 2 [10240/18662 (55%)]\tLoss: 0.254948\n",
      "Train Epoch: 2 [10880/18662 (58%)]\tLoss: 0.021966\n",
      "Train Epoch: 2 [11520/18662 (62%)]\tLoss: 0.114911\n",
      "Train Epoch: 2 [12160/18662 (65%)]\tLoss: 0.070975\n",
      "Train Epoch: 2 [12800/18662 (68%)]\tLoss: 0.054449\n",
      "Train Epoch: 2 [13440/18662 (72%)]\tLoss: 0.020217\n",
      "Train Epoch: 2 [14080/18662 (75%)]\tLoss: 0.173296\n",
      "Train Epoch: 2 [14720/18662 (79%)]\tLoss: 0.046414\n",
      "Train Epoch: 2 [15360/18662 (82%)]\tLoss: 0.056491\n",
      "Train Epoch: 2 [16000/18662 (86%)]\tLoss: 0.034357\n",
      "Train Epoch: 2 [16640/18662 (89%)]\tLoss: 0.025761\n",
      "Train Epoch: 2 [17280/18662 (92%)]\tLoss: 0.010654\n",
      "Train Epoch: 2 [17920/18662 (96%)]\tLoss: 0.085862\n",
      "Train Epoch: 2 [18560/18662 (99%)]\tLoss: 0.004656\n",
      "Train Epoch: 3 [0/18662 (0%)]\tLoss: 0.019784\n",
      "Train Epoch: 3 [640/18662 (3%)]\tLoss: 0.028126\n",
      "Train Epoch: 3 [1280/18662 (7%)]\tLoss: 0.002442\n",
      "Train Epoch: 3 [1920/18662 (10%)]\tLoss: 0.045867\n",
      "Train Epoch: 3 [2560/18662 (14%)]\tLoss: 0.020387\n",
      "Train Epoch: 3 [3200/18662 (17%)]\tLoss: 0.069216\n",
      "Train Epoch: 3 [3840/18662 (21%)]\tLoss: 0.231989\n",
      "Train Epoch: 3 [4480/18662 (24%)]\tLoss: 0.015871\n",
      "Train Epoch: 3 [5120/18662 (27%)]\tLoss: 0.022003\n",
      "Train Epoch: 3 [5760/18662 (31%)]\tLoss: 0.105614\n",
      "Train Epoch: 3 [6400/18662 (34%)]\tLoss: 0.058789\n",
      "Train Epoch: 3 [7040/18662 (38%)]\tLoss: 0.010955\n",
      "Train Epoch: 3 [7680/18662 (41%)]\tLoss: 0.019796\n",
      "Train Epoch: 3 [8320/18662 (45%)]\tLoss: 0.010045\n",
      "Train Epoch: 3 [8960/18662 (48%)]\tLoss: 0.079865\n",
      "Train Epoch: 3 [9600/18662 (51%)]\tLoss: 0.043350\n",
      "Train Epoch: 3 [10240/18662 (55%)]\tLoss: 0.019087\n",
      "Train Epoch: 3 [10880/18662 (58%)]\tLoss: 0.009708\n",
      "Train Epoch: 3 [11520/18662 (62%)]\tLoss: 0.102646\n",
      "Train Epoch: 3 [12160/18662 (65%)]\tLoss: 0.170254\n",
      "Train Epoch: 3 [12800/18662 (68%)]\tLoss: 0.029120\n",
      "Train Epoch: 3 [13440/18662 (72%)]\tLoss: 0.107725\n",
      "Train Epoch: 3 [14080/18662 (75%)]\tLoss: 0.035729\n",
      "Train Epoch: 3 [14720/18662 (79%)]\tLoss: 0.199299\n",
      "Train Epoch: 3 [15360/18662 (82%)]\tLoss: 0.010781\n",
      "Train Epoch: 3 [16000/18662 (86%)]\tLoss: 0.043059\n",
      "Train Epoch: 3 [16640/18662 (89%)]\tLoss: 0.147434\n",
      "Train Epoch: 3 [17280/18662 (92%)]\tLoss: 0.049902\n",
      "Train Epoch: 3 [17920/18662 (96%)]\tLoss: 0.047643\n",
      "Train Epoch: 3 [18560/18662 (99%)]\tLoss: 0.067714\n",
      "Train Epoch: 4 [0/18662 (0%)]\tLoss: 0.321605\n",
      "Train Epoch: 4 [640/18662 (3%)]\tLoss: 0.107648\n",
      "Train Epoch: 4 [1280/18662 (7%)]\tLoss: 0.065247\n",
      "Train Epoch: 4 [1920/18662 (10%)]\tLoss: 0.014495\n",
      "Train Epoch: 4 [2560/18662 (14%)]\tLoss: 0.038293\n",
      "Train Epoch: 4 [3200/18662 (17%)]\tLoss: 0.063064\n",
      "Train Epoch: 4 [3840/18662 (21%)]\tLoss: 0.009527\n",
      "Train Epoch: 4 [4480/18662 (24%)]\tLoss: 0.094371\n",
      "Train Epoch: 4 [5120/18662 (27%)]\tLoss: 0.070113\n",
      "Train Epoch: 4 [5760/18662 (31%)]\tLoss: 0.049757\n",
      "Train Epoch: 4 [6400/18662 (34%)]\tLoss: 0.064516\n",
      "Train Epoch: 4 [7040/18662 (38%)]\tLoss: 0.043221\n",
      "Train Epoch: 4 [7680/18662 (41%)]\tLoss: 0.037247\n",
      "Train Epoch: 4 [8320/18662 (45%)]\tLoss: 0.034285\n",
      "Train Epoch: 4 [8960/18662 (48%)]\tLoss: 0.015216\n",
      "Train Epoch: 4 [9600/18662 (51%)]\tLoss: 0.028823\n",
      "Train Epoch: 4 [10240/18662 (55%)]\tLoss: 0.012180\n",
      "Train Epoch: 4 [10880/18662 (58%)]\tLoss: 0.052472\n",
      "Train Epoch: 4 [11520/18662 (62%)]\tLoss: 0.007672\n",
      "Train Epoch: 4 [12160/18662 (65%)]\tLoss: 0.078376\n",
      "Train Epoch: 4 [12800/18662 (68%)]\tLoss: 0.047801\n",
      "Train Epoch: 4 [13440/18662 (72%)]\tLoss: 0.052240\n",
      "Train Epoch: 4 [14080/18662 (75%)]\tLoss: 0.043253\n",
      "Train Epoch: 4 [14720/18662 (79%)]\tLoss: 0.017004\n",
      "Train Epoch: 4 [15360/18662 (82%)]\tLoss: 0.040111\n",
      "Train Epoch: 4 [16000/18662 (86%)]\tLoss: 0.057727\n",
      "Train Epoch: 4 [16640/18662 (89%)]\tLoss: 0.103644\n",
      "Train Epoch: 4 [17280/18662 (92%)]\tLoss: 0.083627\n",
      "Train Epoch: 4 [17920/18662 (96%)]\tLoss: 0.020206\n",
      "Train Epoch: 4 [18560/18662 (99%)]\tLoss: 0.053493\n",
      "Train Epoch: 5 [0/18662 (0%)]\tLoss: 0.052950\n",
      "Train Epoch: 5 [640/18662 (3%)]\tLoss: 0.051158\n",
      "Train Epoch: 5 [1280/18662 (7%)]\tLoss: 0.063871\n",
      "Train Epoch: 5 [1920/18662 (10%)]\tLoss: 0.037215\n",
      "Train Epoch: 5 [2560/18662 (14%)]\tLoss: 0.255585\n",
      "Train Epoch: 5 [3200/18662 (17%)]\tLoss: 0.067826\n",
      "Train Epoch: 5 [3840/18662 (21%)]\tLoss: 0.060417\n",
      "Train Epoch: 5 [4480/18662 (24%)]\tLoss: 0.021388\n",
      "Train Epoch: 5 [5120/18662 (27%)]\tLoss: 0.041697\n",
      "Train Epoch: 5 [5760/18662 (31%)]\tLoss: 0.025980\n",
      "Train Epoch: 5 [6400/18662 (34%)]\tLoss: 0.083839\n",
      "Train Epoch: 5 [7040/18662 (38%)]\tLoss: 0.019497\n",
      "Train Epoch: 5 [7680/18662 (41%)]\tLoss: 0.005793\n",
      "Train Epoch: 5 [8320/18662 (45%)]\tLoss: 0.035125\n",
      "Train Epoch: 5 [8960/18662 (48%)]\tLoss: 0.213077\n",
      "Train Epoch: 5 [9600/18662 (51%)]\tLoss: 0.016975\n",
      "Train Epoch: 5 [10240/18662 (55%)]\tLoss: 0.078326\n",
      "Train Epoch: 5 [10880/18662 (58%)]\tLoss: 0.041396\n",
      "Train Epoch: 5 [11520/18662 (62%)]\tLoss: 0.033665\n",
      "Train Epoch: 5 [12160/18662 (65%)]\tLoss: 0.035019\n",
      "Train Epoch: 5 [12800/18662 (68%)]\tLoss: 0.042093\n",
      "Train Epoch: 5 [13440/18662 (72%)]\tLoss: 0.066999\n",
      "Train Epoch: 5 [14080/18662 (75%)]\tLoss: 0.007666\n",
      "Train Epoch: 5 [14720/18662 (79%)]\tLoss: 0.022729\n",
      "Train Epoch: 5 [15360/18662 (82%)]\tLoss: 0.058188\n",
      "Train Epoch: 5 [16000/18662 (86%)]\tLoss: 0.096000\n",
      "Train Epoch: 5 [16640/18662 (89%)]\tLoss: 0.007281\n",
      "Train Epoch: 5 [17280/18662 (92%)]\tLoss: 0.150813\n",
      "Train Epoch: 5 [17920/18662 (96%)]\tLoss: 0.028708\n",
      "Train Epoch: 5 [18560/18662 (99%)]\tLoss: 0.090849\n",
      "Train Epoch: 6 [0/18662 (0%)]\tLoss: 0.010797\n",
      "Train Epoch: 6 [640/18662 (3%)]\tLoss: 0.021721\n",
      "Train Epoch: 6 [1280/18662 (7%)]\tLoss: 0.180178\n",
      "Train Epoch: 6 [1920/18662 (10%)]\tLoss: 0.080156\n",
      "Train Epoch: 6 [2560/18662 (14%)]\tLoss: 0.013306\n",
      "Train Epoch: 6 [3200/18662 (17%)]\tLoss: 0.107403\n",
      "Train Epoch: 6 [3840/18662 (21%)]\tLoss: 0.186994\n",
      "Train Epoch: 6 [4480/18662 (24%)]\tLoss: 0.140702\n",
      "Train Epoch: 6 [5120/18662 (27%)]\tLoss: 0.030070\n",
      "Train Epoch: 6 [5760/18662 (31%)]\tLoss: 0.085590\n",
      "Train Epoch: 6 [6400/18662 (34%)]\tLoss: 0.047842\n",
      "Train Epoch: 6 [7040/18662 (38%)]\tLoss: 0.061164\n",
      "Train Epoch: 6 [7680/18662 (41%)]\tLoss: 0.015089\n",
      "Train Epoch: 6 [8320/18662 (45%)]\tLoss: 0.162770\n",
      "Train Epoch: 6 [8960/18662 (48%)]\tLoss: 0.027529\n",
      "Train Epoch: 6 [9600/18662 (51%)]\tLoss: 0.050294\n",
      "Train Epoch: 6 [10240/18662 (55%)]\tLoss: 0.063525\n",
      "Train Epoch: 6 [10880/18662 (58%)]\tLoss: 0.025998\n",
      "Train Epoch: 6 [11520/18662 (62%)]\tLoss: 0.009000\n",
      "Train Epoch: 6 [12160/18662 (65%)]\tLoss: 0.035554\n",
      "Train Epoch: 6 [12800/18662 (68%)]\tLoss: 0.065429\n",
      "Train Epoch: 6 [13440/18662 (72%)]\tLoss: 0.012377\n",
      "Train Epoch: 6 [14080/18662 (75%)]\tLoss: 0.023549\n",
      "Train Epoch: 6 [14720/18662 (79%)]\tLoss: 0.070370\n",
      "Train Epoch: 6 [15360/18662 (82%)]\tLoss: 0.170476\n",
      "Train Epoch: 6 [16000/18662 (86%)]\tLoss: 0.019941\n",
      "Train Epoch: 6 [16640/18662 (89%)]\tLoss: 0.009810\n",
      "Train Epoch: 6 [17280/18662 (92%)]\tLoss: 0.052713\n",
      "Train Epoch: 6 [17920/18662 (96%)]\tLoss: 0.020919\n",
      "Train Epoch: 6 [18560/18662 (99%)]\tLoss: 0.020891\n",
      "Train Epoch: 7 [0/18662 (0%)]\tLoss: 0.036198\n",
      "Train Epoch: 7 [640/18662 (3%)]\tLoss: 0.125319\n",
      "Train Epoch: 7 [1280/18662 (7%)]\tLoss: 0.032099\n",
      "Train Epoch: 7 [1920/18662 (10%)]\tLoss: 0.123506\n",
      "Train Epoch: 7 [2560/18662 (14%)]\tLoss: 0.046937\n",
      "Train Epoch: 7 [3200/18662 (17%)]\tLoss: 0.042657\n",
      "Train Epoch: 7 [3840/18662 (21%)]\tLoss: 0.065310\n",
      "Train Epoch: 7 [4480/18662 (24%)]\tLoss: 0.183924\n",
      "Train Epoch: 7 [5120/18662 (27%)]\tLoss: 0.015057\n",
      "Train Epoch: 7 [5760/18662 (31%)]\tLoss: 0.087934\n",
      "Train Epoch: 7 [6400/18662 (34%)]\tLoss: 0.038165\n",
      "Train Epoch: 7 [7040/18662 (38%)]\tLoss: 0.060883\n",
      "Train Epoch: 7 [7680/18662 (41%)]\tLoss: 0.127750\n",
      "Train Epoch: 7 [8320/18662 (45%)]\tLoss: 0.045447\n",
      "Train Epoch: 7 [8960/18662 (48%)]\tLoss: 0.017265\n",
      "Train Epoch: 7 [9600/18662 (51%)]\tLoss: 0.044876\n",
      "Train Epoch: 7 [10240/18662 (55%)]\tLoss: 0.067502\n",
      "Train Epoch: 7 [10880/18662 (58%)]\tLoss: 0.192706\n",
      "Train Epoch: 7 [11520/18662 (62%)]\tLoss: 0.022225\n",
      "Train Epoch: 7 [12160/18662 (65%)]\tLoss: 0.064406\n",
      "Train Epoch: 7 [12800/18662 (68%)]\tLoss: 0.074045\n",
      "Train Epoch: 7 [13440/18662 (72%)]\tLoss: 0.115007\n",
      "Train Epoch: 7 [14080/18662 (75%)]\tLoss: 0.050010\n",
      "Train Epoch: 7 [14720/18662 (79%)]\tLoss: 0.011574\n",
      "Train Epoch: 7 [15360/18662 (82%)]\tLoss: 0.025481\n",
      "Train Epoch: 7 [16000/18662 (86%)]\tLoss: 0.062159\n",
      "Train Epoch: 7 [16640/18662 (89%)]\tLoss: 0.125194\n",
      "Train Epoch: 7 [17280/18662 (92%)]\tLoss: 0.050228\n",
      "Train Epoch: 7 [17920/18662 (96%)]\tLoss: 0.021627\n",
      "Train Epoch: 7 [18560/18662 (99%)]\tLoss: 0.061688\n",
      "Train Epoch: 8 [0/18662 (0%)]\tLoss: 0.052303\n",
      "Train Epoch: 8 [640/18662 (3%)]\tLoss: 0.013355\n",
      "Train Epoch: 8 [1280/18662 (7%)]\tLoss: 0.147160\n",
      "Train Epoch: 8 [1920/18662 (10%)]\tLoss: 0.022215\n",
      "Train Epoch: 8 [2560/18662 (14%)]\tLoss: 0.036645\n",
      "Train Epoch: 8 [3200/18662 (17%)]\tLoss: 0.035345\n",
      "Train Epoch: 8 [3840/18662 (21%)]\tLoss: 0.087600\n",
      "Train Epoch: 8 [4480/18662 (24%)]\tLoss: 0.055681\n",
      "Train Epoch: 8 [5120/18662 (27%)]\tLoss: 0.039758\n",
      "Train Epoch: 8 [5760/18662 (31%)]\tLoss: 0.067518\n",
      "Train Epoch: 8 [6400/18662 (34%)]\tLoss: 0.083245\n",
      "Train Epoch: 8 [7040/18662 (38%)]\tLoss: 0.026335\n",
      "Train Epoch: 8 [7680/18662 (41%)]\tLoss: 0.016842\n",
      "Train Epoch: 8 [8320/18662 (45%)]\tLoss: 0.013682\n",
      "Train Epoch: 8 [8960/18662 (48%)]\tLoss: 0.062117\n",
      "Train Epoch: 8 [9600/18662 (51%)]\tLoss: 0.035146\n",
      "Train Epoch: 8 [10240/18662 (55%)]\tLoss: 0.048273\n",
      "Train Epoch: 8 [10880/18662 (58%)]\tLoss: 0.032434\n",
      "Train Epoch: 8 [11520/18662 (62%)]\tLoss: 0.165272\n",
      "Train Epoch: 8 [12160/18662 (65%)]\tLoss: 0.055907\n",
      "Train Epoch: 8 [12800/18662 (68%)]\tLoss: 0.031661\n",
      "Train Epoch: 8 [13440/18662 (72%)]\tLoss: 0.076158\n",
      "Train Epoch: 8 [14080/18662 (75%)]\tLoss: 0.033634\n",
      "Train Epoch: 8 [14720/18662 (79%)]\tLoss: 0.087778\n",
      "Train Epoch: 8 [15360/18662 (82%)]\tLoss: 0.036539\n",
      "Train Epoch: 8 [16000/18662 (86%)]\tLoss: 0.067994\n",
      "Train Epoch: 8 [16640/18662 (89%)]\tLoss: 0.025301\n",
      "Train Epoch: 8 [17280/18662 (92%)]\tLoss: 0.024497\n",
      "Train Epoch: 8 [17920/18662 (96%)]\tLoss: 0.066399\n",
      "Train Epoch: 8 [18560/18662 (99%)]\tLoss: 0.017689\n",
      "Train Epoch: 9 [0/18662 (0%)]\tLoss: 0.016265\n",
      "Train Epoch: 9 [640/18662 (3%)]\tLoss: 0.044200\n",
      "Train Epoch: 9 [1280/18662 (7%)]\tLoss: 0.118825\n",
      "Train Epoch: 9 [1920/18662 (10%)]\tLoss: 0.152613\n",
      "Train Epoch: 9 [2560/18662 (14%)]\tLoss: 0.047266\n",
      "Train Epoch: 9 [3200/18662 (17%)]\tLoss: 0.007977\n",
      "Train Epoch: 9 [3840/18662 (21%)]\tLoss: 0.026594\n",
      "Train Epoch: 9 [4480/18662 (24%)]\tLoss: 0.064451\n",
      "Train Epoch: 9 [5120/18662 (27%)]\tLoss: 0.065063\n",
      "Train Epoch: 9 [5760/18662 (31%)]\tLoss: 0.071035\n",
      "Train Epoch: 9 [6400/18662 (34%)]\tLoss: 0.046878\n",
      "Train Epoch: 9 [7040/18662 (38%)]\tLoss: 0.180805\n",
      "Train Epoch: 9 [7680/18662 (41%)]\tLoss: 0.042485\n",
      "Train Epoch: 9 [8320/18662 (45%)]\tLoss: 0.009297\n",
      "Train Epoch: 9 [8960/18662 (48%)]\tLoss: 0.037125\n",
      "Train Epoch: 9 [9600/18662 (51%)]\tLoss: 0.003973\n",
      "Train Epoch: 9 [10240/18662 (55%)]\tLoss: 0.352636\n",
      "Train Epoch: 9 [10880/18662 (58%)]\tLoss: 0.016083\n",
      "Train Epoch: 9 [11520/18662 (62%)]\tLoss: 0.027553\n",
      "Train Epoch: 9 [12160/18662 (65%)]\tLoss: 0.010173\n",
      "Train Epoch: 9 [12800/18662 (68%)]\tLoss: 0.093119\n",
      "Train Epoch: 9 [13440/18662 (72%)]\tLoss: 0.041850\n",
      "Train Epoch: 9 [14080/18662 (75%)]\tLoss: 0.003584\n",
      "Train Epoch: 9 [14720/18662 (79%)]\tLoss: 0.072793\n",
      "Train Epoch: 9 [15360/18662 (82%)]\tLoss: 0.024904\n",
      "Train Epoch: 9 [16000/18662 (86%)]\tLoss: 0.032139\n",
      "Train Epoch: 9 [16640/18662 (89%)]\tLoss: 0.211624\n",
      "Train Epoch: 9 [17280/18662 (92%)]\tLoss: 0.064326\n",
      "Train Epoch: 9 [17920/18662 (96%)]\tLoss: 0.012806\n",
      "Train Epoch: 9 [18560/18662 (99%)]\tLoss: 0.052528\n",
      "Train Epoch: 10 [0/18662 (0%)]\tLoss: 0.068651\n",
      "Train Epoch: 10 [640/18662 (3%)]\tLoss: 0.091731\n",
      "Train Epoch: 10 [1280/18662 (7%)]\tLoss: 0.094744\n",
      "Train Epoch: 10 [1920/18662 (10%)]\tLoss: 0.039665\n",
      "Train Epoch: 10 [2560/18662 (14%)]\tLoss: 0.052683\n",
      "Train Epoch: 10 [3200/18662 (17%)]\tLoss: 0.193112\n",
      "Train Epoch: 10 [3840/18662 (21%)]\tLoss: 0.037747\n",
      "Train Epoch: 10 [4480/18662 (24%)]\tLoss: 0.060080\n",
      "Train Epoch: 10 [5120/18662 (27%)]\tLoss: 0.234100\n",
      "Train Epoch: 10 [5760/18662 (31%)]\tLoss: 0.063082\n",
      "Train Epoch: 10 [6400/18662 (34%)]\tLoss: 0.043036\n",
      "Train Epoch: 10 [7040/18662 (38%)]\tLoss: 0.040415\n",
      "Train Epoch: 10 [7680/18662 (41%)]\tLoss: 0.085971\n",
      "Train Epoch: 10 [8320/18662 (45%)]\tLoss: 0.030835\n",
      "Train Epoch: 10 [8960/18662 (48%)]\tLoss: 0.008478\n",
      "Train Epoch: 10 [9600/18662 (51%)]\tLoss: 0.097644\n",
      "Train Epoch: 10 [10240/18662 (55%)]\tLoss: 0.008193\n",
      "Train Epoch: 10 [10880/18662 (58%)]\tLoss: 0.012789\n",
      "Train Epoch: 10 [11520/18662 (62%)]\tLoss: 0.075641\n",
      "Train Epoch: 10 [12160/18662 (65%)]\tLoss: 0.055038\n",
      "Train Epoch: 10 [12800/18662 (68%)]\tLoss: 0.011816\n",
      "Train Epoch: 10 [13440/18662 (72%)]\tLoss: 0.039958\n",
      "Train Epoch: 10 [14080/18662 (75%)]\tLoss: 0.086989\n",
      "Train Epoch: 10 [14720/18662 (79%)]\tLoss: 0.025801\n",
      "Train Epoch: 10 [15360/18662 (82%)]\tLoss: 0.086861\n",
      "Train Epoch: 10 [16000/18662 (86%)]\tLoss: 0.128817\n",
      "Train Epoch: 10 [16640/18662 (89%)]\tLoss: 0.018817\n",
      "Train Epoch: 10 [17280/18662 (92%)]\tLoss: 0.107424\n",
      "Train Epoch: 10 [17920/18662 (96%)]\tLoss: 0.154195\n",
      "Train Epoch: 10 [18560/18662 (99%)]\tLoss: 0.133861\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/10619 (0%)]\tLoss: 0.299926\n",
      "Train Epoch: 1 [640/10619 (6%)]\tLoss: 0.050813\n",
      "Train Epoch: 1 [1280/10619 (12%)]\tLoss: 0.142658\n",
      "Train Epoch: 1 [1920/10619 (18%)]\tLoss: 0.051076\n",
      "Train Epoch: 1 [2560/10619 (24%)]\tLoss: 0.120560\n",
      "Train Epoch: 1 [3200/10619 (30%)]\tLoss: 0.087919\n",
      "Train Epoch: 1 [3840/10619 (36%)]\tLoss: 0.074997\n",
      "Train Epoch: 1 [4480/10619 (42%)]\tLoss: 0.047165\n",
      "Train Epoch: 1 [5120/10619 (48%)]\tLoss: 0.041496\n",
      "Train Epoch: 1 [5760/10619 (54%)]\tLoss: 0.088265\n",
      "Train Epoch: 1 [6400/10619 (60%)]\tLoss: 0.023074\n",
      "Train Epoch: 1 [7040/10619 (66%)]\tLoss: 0.022387\n",
      "Train Epoch: 1 [7680/10619 (72%)]\tLoss: 0.141543\n",
      "Train Epoch: 1 [8320/10619 (78%)]\tLoss: 0.088378\n",
      "Train Epoch: 1 [8960/10619 (84%)]\tLoss: 0.019894\n",
      "Train Epoch: 1 [9600/10619 (90%)]\tLoss: 0.042297\n",
      "Train Epoch: 1 [10240/10619 (96%)]\tLoss: 0.125163\n",
      "Train Epoch: 2 [0/10619 (0%)]\tLoss: 0.049586\n",
      "Train Epoch: 2 [640/10619 (6%)]\tLoss: 0.036620\n",
      "Train Epoch: 2 [1280/10619 (12%)]\tLoss: 0.022775\n",
      "Train Epoch: 2 [1920/10619 (18%)]\tLoss: 0.046856\n",
      "Train Epoch: 2 [2560/10619 (24%)]\tLoss: 0.166222\n",
      "Train Epoch: 2 [3200/10619 (30%)]\tLoss: 0.113491\n",
      "Train Epoch: 2 [3840/10619 (36%)]\tLoss: 0.149522\n",
      "Train Epoch: 2 [4480/10619 (42%)]\tLoss: 0.054855\n",
      "Train Epoch: 2 [5120/10619 (48%)]\tLoss: 0.094370\n",
      "Train Epoch: 2 [5760/10619 (54%)]\tLoss: 0.098598\n",
      "Train Epoch: 2 [6400/10619 (60%)]\tLoss: 0.083460\n",
      "Train Epoch: 2 [7040/10619 (66%)]\tLoss: 0.099097\n",
      "Train Epoch: 2 [7680/10619 (72%)]\tLoss: 0.135550\n",
      "Train Epoch: 2 [8320/10619 (78%)]\tLoss: 0.096304\n",
      "Train Epoch: 2 [8960/10619 (84%)]\tLoss: 0.097736\n",
      "Train Epoch: 2 [9600/10619 (90%)]\tLoss: 0.122206\n",
      "Train Epoch: 2 [10240/10619 (96%)]\tLoss: 0.296381\n",
      "Train Epoch: 3 [0/10619 (0%)]\tLoss: 0.032438\n",
      "Train Epoch: 3 [640/10619 (6%)]\tLoss: 0.056274\n",
      "Train Epoch: 3 [1280/10619 (12%)]\tLoss: 0.041033\n",
      "Train Epoch: 3 [1920/10619 (18%)]\tLoss: 0.152602\n",
      "Train Epoch: 3 [2560/10619 (24%)]\tLoss: 0.066052\n",
      "Train Epoch: 3 [3200/10619 (30%)]\tLoss: 0.188014\n",
      "Train Epoch: 3 [3840/10619 (36%)]\tLoss: 0.016017\n",
      "Train Epoch: 3 [4480/10619 (42%)]\tLoss: 0.028131\n",
      "Train Epoch: 3 [5120/10619 (48%)]\tLoss: 0.061581\n",
      "Train Epoch: 3 [5760/10619 (54%)]\tLoss: 0.152691\n",
      "Train Epoch: 3 [6400/10619 (60%)]\tLoss: 0.121785\n",
      "Train Epoch: 3 [7040/10619 (66%)]\tLoss: 0.046654\n",
      "Train Epoch: 3 [7680/10619 (72%)]\tLoss: 0.070558\n",
      "Train Epoch: 3 [8320/10619 (78%)]\tLoss: 0.104600\n",
      "Train Epoch: 3 [8960/10619 (84%)]\tLoss: 0.070279\n",
      "Train Epoch: 3 [9600/10619 (90%)]\tLoss: 0.066446\n",
      "Train Epoch: 3 [10240/10619 (96%)]\tLoss: 0.032668\n",
      "Train Epoch: 4 [0/10619 (0%)]\tLoss: 0.159054\n",
      "Train Epoch: 4 [640/10619 (6%)]\tLoss: 0.131519\n",
      "Train Epoch: 4 [1280/10619 (12%)]\tLoss: 0.019720\n",
      "Train Epoch: 4 [1920/10619 (18%)]\tLoss: 0.057561\n",
      "Train Epoch: 4 [2560/10619 (24%)]\tLoss: 0.075303\n",
      "Train Epoch: 4 [3200/10619 (30%)]\tLoss: 0.062462\n",
      "Train Epoch: 4 [3840/10619 (36%)]\tLoss: 0.026105\n",
      "Train Epoch: 4 [4480/10619 (42%)]\tLoss: 0.182361\n",
      "Train Epoch: 4 [5120/10619 (48%)]\tLoss: 0.178498\n",
      "Train Epoch: 4 [5760/10619 (54%)]\tLoss: 0.113619\n",
      "Train Epoch: 4 [6400/10619 (60%)]\tLoss: 0.024948\n",
      "Train Epoch: 4 [7040/10619 (66%)]\tLoss: 0.032119\n",
      "Train Epoch: 4 [7680/10619 (72%)]\tLoss: 0.061594\n",
      "Train Epoch: 4 [8320/10619 (78%)]\tLoss: 0.113033\n",
      "Train Epoch: 4 [8960/10619 (84%)]\tLoss: 0.042387\n",
      "Train Epoch: 4 [9600/10619 (90%)]\tLoss: 0.119459\n",
      "Train Epoch: 4 [10240/10619 (96%)]\tLoss: 0.032085\n",
      "Train Epoch: 5 [0/10619 (0%)]\tLoss: 0.048536\n",
      "Train Epoch: 5 [640/10619 (6%)]\tLoss: 0.049915\n",
      "Train Epoch: 5 [1280/10619 (12%)]\tLoss: 0.035293\n",
      "Train Epoch: 5 [1920/10619 (18%)]\tLoss: 0.018188\n",
      "Train Epoch: 5 [2560/10619 (24%)]\tLoss: 0.087325\n",
      "Train Epoch: 5 [3200/10619 (30%)]\tLoss: 0.093201\n",
      "Train Epoch: 5 [3840/10619 (36%)]\tLoss: 0.011363\n",
      "Train Epoch: 5 [4480/10619 (42%)]\tLoss: 0.116780\n",
      "Train Epoch: 5 [5120/10619 (48%)]\tLoss: 0.058579\n",
      "Train Epoch: 5 [5760/10619 (54%)]\tLoss: 0.248924\n",
      "Train Epoch: 5 [6400/10619 (60%)]\tLoss: 0.040986\n",
      "Train Epoch: 5 [7040/10619 (66%)]\tLoss: 0.020106\n",
      "Train Epoch: 5 [7680/10619 (72%)]\tLoss: 0.036404\n",
      "Train Epoch: 5 [8320/10619 (78%)]\tLoss: 0.186186\n",
      "Train Epoch: 5 [8960/10619 (84%)]\tLoss: 0.061099\n",
      "Train Epoch: 5 [9600/10619 (90%)]\tLoss: 0.127295\n",
      "Train Epoch: 5 [10240/10619 (96%)]\tLoss: 0.129798\n",
      "Train Epoch: 6 [0/10619 (0%)]\tLoss: 0.054320\n",
      "Train Epoch: 6 [640/10619 (6%)]\tLoss: 0.016114\n",
      "Train Epoch: 6 [1280/10619 (12%)]\tLoss: 0.061583\n",
      "Train Epoch: 6 [1920/10619 (18%)]\tLoss: 0.059836\n",
      "Train Epoch: 6 [2560/10619 (24%)]\tLoss: 0.067868\n",
      "Train Epoch: 6 [3200/10619 (30%)]\tLoss: 0.050421\n",
      "Train Epoch: 6 [3840/10619 (36%)]\tLoss: 0.023183\n",
      "Train Epoch: 6 [4480/10619 (42%)]\tLoss: 0.091599\n",
      "Train Epoch: 6 [5120/10619 (48%)]\tLoss: 0.075527\n",
      "Train Epoch: 6 [5760/10619 (54%)]\tLoss: 0.154034\n",
      "Train Epoch: 6 [6400/10619 (60%)]\tLoss: 0.086102\n",
      "Train Epoch: 6 [7040/10619 (66%)]\tLoss: 0.080162\n",
      "Train Epoch: 6 [7680/10619 (72%)]\tLoss: 0.061626\n",
      "Train Epoch: 6 [8320/10619 (78%)]\tLoss: 0.058531\n",
      "Train Epoch: 6 [8960/10619 (84%)]\tLoss: 0.105660\n",
      "Train Epoch: 6 [9600/10619 (90%)]\tLoss: 0.230498\n",
      "Train Epoch: 6 [10240/10619 (96%)]\tLoss: 0.028328\n",
      "Train Epoch: 7 [0/10619 (0%)]\tLoss: 0.069761\n",
      "Train Epoch: 7 [640/10619 (6%)]\tLoss: 0.022444\n",
      "Train Epoch: 7 [1280/10619 (12%)]\tLoss: 0.144164\n",
      "Train Epoch: 7 [1920/10619 (18%)]\tLoss: 0.046573\n",
      "Train Epoch: 7 [2560/10619 (24%)]\tLoss: 0.085395\n",
      "Train Epoch: 7 [3200/10619 (30%)]\tLoss: 0.070464\n",
      "Train Epoch: 7 [3840/10619 (36%)]\tLoss: 0.131150\n",
      "Train Epoch: 7 [4480/10619 (42%)]\tLoss: 0.061594\n",
      "Train Epoch: 7 [5120/10619 (48%)]\tLoss: 0.027739\n",
      "Train Epoch: 7 [5760/10619 (54%)]\tLoss: 0.085325\n",
      "Train Epoch: 7 [6400/10619 (60%)]\tLoss: 0.047306\n",
      "Train Epoch: 7 [7040/10619 (66%)]\tLoss: 0.061425\n",
      "Train Epoch: 7 [7680/10619 (72%)]\tLoss: 0.024858\n",
      "Train Epoch: 7 [8320/10619 (78%)]\tLoss: 0.124844\n",
      "Train Epoch: 7 [8960/10619 (84%)]\tLoss: 0.006180\n",
      "Train Epoch: 7 [9600/10619 (90%)]\tLoss: 0.027654\n",
      "Train Epoch: 7 [10240/10619 (96%)]\tLoss: 0.030136\n",
      "Train Epoch: 8 [0/10619 (0%)]\tLoss: 0.078966\n",
      "Train Epoch: 8 [640/10619 (6%)]\tLoss: 0.104804\n",
      "Train Epoch: 8 [1280/10619 (12%)]\tLoss: 0.117998\n",
      "Train Epoch: 8 [1920/10619 (18%)]\tLoss: 0.166372\n",
      "Train Epoch: 8 [2560/10619 (24%)]\tLoss: 0.148924\n",
      "Train Epoch: 8 [3200/10619 (30%)]\tLoss: 0.033666\n",
      "Train Epoch: 8 [3840/10619 (36%)]\tLoss: 0.037090\n",
      "Train Epoch: 8 [4480/10619 (42%)]\tLoss: 0.053317\n",
      "Train Epoch: 8 [5120/10619 (48%)]\tLoss: 0.080929\n",
      "Train Epoch: 8 [5760/10619 (54%)]\tLoss: 0.083689\n",
      "Train Epoch: 8 [6400/10619 (60%)]\tLoss: 0.022628\n",
      "Train Epoch: 8 [7040/10619 (66%)]\tLoss: 0.055878\n",
      "Train Epoch: 8 [7680/10619 (72%)]\tLoss: 0.057700\n",
      "Train Epoch: 8 [8320/10619 (78%)]\tLoss: 0.019552\n",
      "Train Epoch: 8 [8960/10619 (84%)]\tLoss: 0.192662\n",
      "Train Epoch: 8 [9600/10619 (90%)]\tLoss: 0.012294\n",
      "Train Epoch: 8 [10240/10619 (96%)]\tLoss: 0.118599\n",
      "Train Epoch: 9 [0/10619 (0%)]\tLoss: 0.075189\n",
      "Train Epoch: 9 [640/10619 (6%)]\tLoss: 0.022226\n",
      "Train Epoch: 9 [1280/10619 (12%)]\tLoss: 0.041214\n",
      "Train Epoch: 9 [1920/10619 (18%)]\tLoss: 0.038070\n",
      "Train Epoch: 9 [2560/10619 (24%)]\tLoss: 0.052058\n",
      "Train Epoch: 9 [3200/10619 (30%)]\tLoss: 0.026143\n",
      "Train Epoch: 9 [3840/10619 (36%)]\tLoss: 0.047594\n",
      "Train Epoch: 9 [4480/10619 (42%)]\tLoss: 0.019651\n",
      "Train Epoch: 9 [5120/10619 (48%)]\tLoss: 0.028559\n",
      "Train Epoch: 9 [5760/10619 (54%)]\tLoss: 0.029299\n",
      "Train Epoch: 9 [6400/10619 (60%)]\tLoss: 0.036666\n",
      "Train Epoch: 9 [7040/10619 (66%)]\tLoss: 0.143097\n",
      "Train Epoch: 9 [7680/10619 (72%)]\tLoss: 0.071796\n",
      "Train Epoch: 9 [8320/10619 (78%)]\tLoss: 0.015511\n",
      "Train Epoch: 9 [8960/10619 (84%)]\tLoss: 0.048565\n",
      "Train Epoch: 9 [9600/10619 (90%)]\tLoss: 0.063821\n",
      "Train Epoch: 9 [10240/10619 (96%)]\tLoss: 0.062968\n",
      "Train Epoch: 10 [0/10619 (0%)]\tLoss: 0.073623\n",
      "Train Epoch: 10 [640/10619 (6%)]\tLoss: 0.109812\n",
      "Train Epoch: 10 [1280/10619 (12%)]\tLoss: 0.157320\n",
      "Train Epoch: 10 [1920/10619 (18%)]\tLoss: 0.094165\n",
      "Train Epoch: 10 [2560/10619 (24%)]\tLoss: 0.045206\n",
      "Train Epoch: 10 [3200/10619 (30%)]\tLoss: 0.025243\n",
      "Train Epoch: 10 [3840/10619 (36%)]\tLoss: 0.051398\n",
      "Train Epoch: 10 [4480/10619 (42%)]\tLoss: 0.150116\n",
      "Train Epoch: 10 [5120/10619 (48%)]\tLoss: 0.018408\n",
      "Train Epoch: 10 [5760/10619 (54%)]\tLoss: 0.137181\n",
      "Train Epoch: 10 [6400/10619 (60%)]\tLoss: 0.094218\n",
      "Train Epoch: 10 [7040/10619 (66%)]\tLoss: 0.029461\n",
      "Train Epoch: 10 [7680/10619 (72%)]\tLoss: 0.053471\n",
      "Train Epoch: 10 [8320/10619 (78%)]\tLoss: 0.203026\n",
      "Train Epoch: 10 [8960/10619 (84%)]\tLoss: 0.073947\n",
      "Train Epoch: 10 [9600/10619 (90%)]\tLoss: 0.035306\n",
      "Train Epoch: 10 [10240/10619 (96%)]\tLoss: 0.067317\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/15392 (0%)]\tLoss: 0.044949\n",
      "Train Epoch: 1 [640/15392 (4%)]\tLoss: 0.095148\n",
      "Train Epoch: 1 [1280/15392 (8%)]\tLoss: 0.033408\n",
      "Train Epoch: 1 [1920/15392 (12%)]\tLoss: 0.254131\n",
      "Train Epoch: 1 [2560/15392 (17%)]\tLoss: 0.171427\n",
      "Train Epoch: 1 [3200/15392 (21%)]\tLoss: 0.096210\n",
      "Train Epoch: 1 [3840/15392 (25%)]\tLoss: 0.045044\n",
      "Train Epoch: 1 [4480/15392 (29%)]\tLoss: 0.124837\n",
      "Train Epoch: 1 [5120/15392 (33%)]\tLoss: 0.142778\n",
      "Train Epoch: 1 [5760/15392 (37%)]\tLoss: 0.030617\n",
      "Train Epoch: 1 [6400/15392 (41%)]\tLoss: 0.029003\n",
      "Train Epoch: 1 [7040/15392 (46%)]\tLoss: 0.061362\n",
      "Train Epoch: 1 [7680/15392 (50%)]\tLoss: 0.052041\n",
      "Train Epoch: 1 [8320/15392 (54%)]\tLoss: 0.105183\n",
      "Train Epoch: 1 [8960/15392 (58%)]\tLoss: 0.078171\n",
      "Train Epoch: 1 [9600/15392 (62%)]\tLoss: 0.043941\n",
      "Train Epoch: 1 [10240/15392 (66%)]\tLoss: 0.173615\n",
      "Train Epoch: 1 [10880/15392 (71%)]\tLoss: 0.033093\n",
      "Train Epoch: 1 [11520/15392 (75%)]\tLoss: 0.077208\n",
      "Train Epoch: 1 [12160/15392 (79%)]\tLoss: 0.091917\n",
      "Train Epoch: 1 [12800/15392 (83%)]\tLoss: 0.171525\n",
      "Train Epoch: 1 [13440/15392 (87%)]\tLoss: 0.114390\n",
      "Train Epoch: 1 [14080/15392 (91%)]\tLoss: 0.015063\n",
      "Train Epoch: 1 [14720/15392 (95%)]\tLoss: 0.014172\n",
      "Train Epoch: 1 [7680/15392 (100%)]\tLoss: 0.072472\n",
      "Train Epoch: 2 [0/15392 (0%)]\tLoss: 0.030487\n",
      "Train Epoch: 2 [640/15392 (4%)]\tLoss: 0.077217\n",
      "Train Epoch: 2 [1280/15392 (8%)]\tLoss: 0.037451\n",
      "Train Epoch: 2 [1920/15392 (12%)]\tLoss: 0.021322\n",
      "Train Epoch: 2 [2560/15392 (17%)]\tLoss: 0.008823\n",
      "Train Epoch: 2 [3200/15392 (21%)]\tLoss: 0.096461\n",
      "Train Epoch: 2 [3840/15392 (25%)]\tLoss: 0.095638\n",
      "Train Epoch: 2 [4480/15392 (29%)]\tLoss: 0.040771\n",
      "Train Epoch: 2 [5120/15392 (33%)]\tLoss: 0.042122\n",
      "Train Epoch: 2 [5760/15392 (37%)]\tLoss: 0.071557\n",
      "Train Epoch: 2 [6400/15392 (41%)]\tLoss: 0.035817\n",
      "Train Epoch: 2 [7040/15392 (46%)]\tLoss: 0.077049\n",
      "Train Epoch: 2 [7680/15392 (50%)]\tLoss: 0.044525\n",
      "Train Epoch: 2 [8320/15392 (54%)]\tLoss: 0.024967\n",
      "Train Epoch: 2 [8960/15392 (58%)]\tLoss: 0.007981\n",
      "Train Epoch: 2 [9600/15392 (62%)]\tLoss: 0.139899\n",
      "Train Epoch: 2 [10240/15392 (66%)]\tLoss: 0.151941\n",
      "Train Epoch: 2 [10880/15392 (71%)]\tLoss: 0.026722\n",
      "Train Epoch: 2 [11520/15392 (75%)]\tLoss: 0.065564\n",
      "Train Epoch: 2 [12160/15392 (79%)]\tLoss: 0.029398\n",
      "Train Epoch: 2 [12800/15392 (83%)]\tLoss: 0.103348\n",
      "Train Epoch: 2 [13440/15392 (87%)]\tLoss: 0.080018\n",
      "Train Epoch: 2 [14080/15392 (91%)]\tLoss: 0.062207\n",
      "Train Epoch: 2 [14720/15392 (95%)]\tLoss: 0.103213\n",
      "Train Epoch: 2 [7680/15392 (100%)]\tLoss: 0.073594\n",
      "Train Epoch: 3 [0/15392 (0%)]\tLoss: 0.035803\n",
      "Train Epoch: 3 [640/15392 (4%)]\tLoss: 0.035159\n",
      "Train Epoch: 3 [1280/15392 (8%)]\tLoss: 0.035794\n",
      "Train Epoch: 3 [1920/15392 (12%)]\tLoss: 0.006755\n",
      "Train Epoch: 3 [2560/15392 (17%)]\tLoss: 0.049588\n",
      "Train Epoch: 3 [3200/15392 (21%)]\tLoss: 0.187453\n",
      "Train Epoch: 3 [3840/15392 (25%)]\tLoss: 0.080895\n",
      "Train Epoch: 3 [4480/15392 (29%)]\tLoss: 0.067379\n",
      "Train Epoch: 3 [5120/15392 (33%)]\tLoss: 0.098695\n",
      "Train Epoch: 3 [5760/15392 (37%)]\tLoss: 0.101135\n",
      "Train Epoch: 3 [6400/15392 (41%)]\tLoss: 0.025232\n",
      "Train Epoch: 3 [7040/15392 (46%)]\tLoss: 0.004307\n",
      "Train Epoch: 3 [7680/15392 (50%)]\tLoss: 0.052100\n",
      "Train Epoch: 3 [8320/15392 (54%)]\tLoss: 0.013193\n",
      "Train Epoch: 3 [8960/15392 (58%)]\tLoss: 0.146913\n",
      "Train Epoch: 3 [9600/15392 (62%)]\tLoss: 0.024228\n",
      "Train Epoch: 3 [10240/15392 (66%)]\tLoss: 0.013824\n",
      "Train Epoch: 3 [10880/15392 (71%)]\tLoss: 0.064085\n",
      "Train Epoch: 3 [11520/15392 (75%)]\tLoss: 0.093861\n",
      "Train Epoch: 3 [12160/15392 (79%)]\tLoss: 0.009180\n",
      "Train Epoch: 3 [12800/15392 (83%)]\tLoss: 0.108402\n",
      "Train Epoch: 3 [13440/15392 (87%)]\tLoss: 0.007498\n",
      "Train Epoch: 3 [14080/15392 (91%)]\tLoss: 0.038038\n",
      "Train Epoch: 3 [14720/15392 (95%)]\tLoss: 0.036737\n",
      "Train Epoch: 3 [7680/15392 (100%)]\tLoss: 0.050768\n",
      "Train Epoch: 4 [0/15392 (0%)]\tLoss: 0.022627\n",
      "Train Epoch: 4 [640/15392 (4%)]\tLoss: 0.029286\n",
      "Train Epoch: 4 [1280/15392 (8%)]\tLoss: 0.129698\n",
      "Train Epoch: 4 [1920/15392 (12%)]\tLoss: 0.041555\n",
      "Train Epoch: 4 [2560/15392 (17%)]\tLoss: 0.048822\n",
      "Train Epoch: 4 [3200/15392 (21%)]\tLoss: 0.024010\n",
      "Train Epoch: 4 [3840/15392 (25%)]\tLoss: 0.079667\n",
      "Train Epoch: 4 [4480/15392 (29%)]\tLoss: 0.020869\n",
      "Train Epoch: 4 [5120/15392 (33%)]\tLoss: 0.084371\n",
      "Train Epoch: 4 [5760/15392 (37%)]\tLoss: 0.085327\n",
      "Train Epoch: 4 [6400/15392 (41%)]\tLoss: 0.023337\n",
      "Train Epoch: 4 [7040/15392 (46%)]\tLoss: 0.029257\n",
      "Train Epoch: 4 [7680/15392 (50%)]\tLoss: 0.098040\n",
      "Train Epoch: 4 [8320/15392 (54%)]\tLoss: 0.042016\n",
      "Train Epoch: 4 [8960/15392 (58%)]\tLoss: 0.007626\n",
      "Train Epoch: 4 [9600/15392 (62%)]\tLoss: 0.028833\n",
      "Train Epoch: 4 [10240/15392 (66%)]\tLoss: 0.011383\n",
      "Train Epoch: 4 [10880/15392 (71%)]\tLoss: 0.030385\n",
      "Train Epoch: 4 [11520/15392 (75%)]\tLoss: 0.071166\n",
      "Train Epoch: 4 [12160/15392 (79%)]\tLoss: 0.114749\n",
      "Train Epoch: 4 [12800/15392 (83%)]\tLoss: 0.018903\n",
      "Train Epoch: 4 [13440/15392 (87%)]\tLoss: 0.068407\n",
      "Train Epoch: 4 [14080/15392 (91%)]\tLoss: 0.057906\n",
      "Train Epoch: 4 [14720/15392 (95%)]\tLoss: 0.153697\n",
      "Train Epoch: 4 [7680/15392 (100%)]\tLoss: 0.037380\n",
      "Train Epoch: 5 [0/15392 (0%)]\tLoss: 0.008298\n",
      "Train Epoch: 5 [640/15392 (4%)]\tLoss: 0.016405\n",
      "Train Epoch: 5 [1280/15392 (8%)]\tLoss: 0.054981\n",
      "Train Epoch: 5 [1920/15392 (12%)]\tLoss: 0.007467\n",
      "Train Epoch: 5 [2560/15392 (17%)]\tLoss: 0.083916\n",
      "Train Epoch: 5 [3200/15392 (21%)]\tLoss: 0.079449\n",
      "Train Epoch: 5 [3840/15392 (25%)]\tLoss: 0.005314\n",
      "Train Epoch: 5 [4480/15392 (29%)]\tLoss: 0.024526\n",
      "Train Epoch: 5 [5120/15392 (33%)]\tLoss: 0.052177\n",
      "Train Epoch: 5 [5760/15392 (37%)]\tLoss: 0.015588\n",
      "Train Epoch: 5 [6400/15392 (41%)]\tLoss: 0.042901\n",
      "Train Epoch: 5 [7040/15392 (46%)]\tLoss: 0.051033\n",
      "Train Epoch: 5 [7680/15392 (50%)]\tLoss: 0.042549\n",
      "Train Epoch: 5 [8320/15392 (54%)]\tLoss: 0.116279\n",
      "Train Epoch: 5 [8960/15392 (58%)]\tLoss: 0.012946\n",
      "Train Epoch: 5 [9600/15392 (62%)]\tLoss: 0.002842\n",
      "Train Epoch: 5 [10240/15392 (66%)]\tLoss: 0.072094\n",
      "Train Epoch: 5 [10880/15392 (71%)]\tLoss: 0.010894\n",
      "Train Epoch: 5 [11520/15392 (75%)]\tLoss: 0.138578\n",
      "Train Epoch: 5 [12160/15392 (79%)]\tLoss: 0.026163\n",
      "Train Epoch: 5 [12800/15392 (83%)]\tLoss: 0.043625\n",
      "Train Epoch: 5 [13440/15392 (87%)]\tLoss: 0.028950\n",
      "Train Epoch: 5 [14080/15392 (91%)]\tLoss: 0.317106\n",
      "Train Epoch: 5 [14720/15392 (95%)]\tLoss: 0.016127\n",
      "Train Epoch: 5 [7680/15392 (100%)]\tLoss: 0.083652\n",
      "Train Epoch: 6 [0/15392 (0%)]\tLoss: 0.029346\n",
      "Train Epoch: 6 [640/15392 (4%)]\tLoss: 0.032580\n",
      "Train Epoch: 6 [1280/15392 (8%)]\tLoss: 0.090085\n",
      "Train Epoch: 6 [1920/15392 (12%)]\tLoss: 0.249358\n",
      "Train Epoch: 6 [2560/15392 (17%)]\tLoss: 0.027790\n",
      "Train Epoch: 6 [3200/15392 (21%)]\tLoss: 0.024834\n",
      "Train Epoch: 6 [3840/15392 (25%)]\tLoss: 0.076410\n",
      "Train Epoch: 6 [4480/15392 (29%)]\tLoss: 0.262678\n",
      "Train Epoch: 6 [5120/15392 (33%)]\tLoss: 0.018184\n",
      "Train Epoch: 6 [5760/15392 (37%)]\tLoss: 0.057202\n",
      "Train Epoch: 6 [6400/15392 (41%)]\tLoss: 0.095350\n",
      "Train Epoch: 6 [7040/15392 (46%)]\tLoss: 0.056664\n",
      "Train Epoch: 6 [7680/15392 (50%)]\tLoss: 0.045200\n",
      "Train Epoch: 6 [8320/15392 (54%)]\tLoss: 0.160531\n",
      "Train Epoch: 6 [8960/15392 (58%)]\tLoss: 0.134306\n",
      "Train Epoch: 6 [9600/15392 (62%)]\tLoss: 0.014377\n",
      "Train Epoch: 6 [10240/15392 (66%)]\tLoss: 0.034881\n",
      "Train Epoch: 6 [10880/15392 (71%)]\tLoss: 0.066629\n",
      "Train Epoch: 6 [11520/15392 (75%)]\tLoss: 0.027875\n",
      "Train Epoch: 6 [12160/15392 (79%)]\tLoss: 0.012484\n",
      "Train Epoch: 6 [12800/15392 (83%)]\tLoss: 0.041884\n",
      "Train Epoch: 6 [13440/15392 (87%)]\tLoss: 0.005199\n",
      "Train Epoch: 6 [14080/15392 (91%)]\tLoss: 0.148833\n",
      "Train Epoch: 6 [14720/15392 (95%)]\tLoss: 0.095054\n",
      "Train Epoch: 6 [7680/15392 (100%)]\tLoss: 0.070632\n",
      "Train Epoch: 7 [0/15392 (0%)]\tLoss: 0.030452\n",
      "Train Epoch: 7 [640/15392 (4%)]\tLoss: 0.076557\n",
      "Train Epoch: 7 [1280/15392 (8%)]\tLoss: 0.019634\n",
      "Train Epoch: 7 [1920/15392 (12%)]\tLoss: 0.010445\n",
      "Train Epoch: 7 [2560/15392 (17%)]\tLoss: 0.081745\n",
      "Train Epoch: 7 [3200/15392 (21%)]\tLoss: 0.070655\n",
      "Train Epoch: 7 [3840/15392 (25%)]\tLoss: 0.066662\n",
      "Train Epoch: 7 [4480/15392 (29%)]\tLoss: 0.162776\n",
      "Train Epoch: 7 [5120/15392 (33%)]\tLoss: 0.067609\n",
      "Train Epoch: 7 [5760/15392 (37%)]\tLoss: 0.031903\n",
      "Train Epoch: 7 [6400/15392 (41%)]\tLoss: 0.067578\n",
      "Train Epoch: 7 [7040/15392 (46%)]\tLoss: 0.003031\n",
      "Train Epoch: 7 [7680/15392 (50%)]\tLoss: 0.076252\n",
      "Train Epoch: 7 [8320/15392 (54%)]\tLoss: 0.045812\n",
      "Train Epoch: 7 [8960/15392 (58%)]\tLoss: 0.091874\n",
      "Train Epoch: 7 [9600/15392 (62%)]\tLoss: 0.045031\n",
      "Train Epoch: 7 [10240/15392 (66%)]\tLoss: 0.023500\n",
      "Train Epoch: 7 [10880/15392 (71%)]\tLoss: 0.086966\n",
      "Train Epoch: 7 [11520/15392 (75%)]\tLoss: 0.041495\n",
      "Train Epoch: 7 [12160/15392 (79%)]\tLoss: 0.082516\n",
      "Train Epoch: 7 [12800/15392 (83%)]\tLoss: 0.002934\n",
      "Train Epoch: 7 [13440/15392 (87%)]\tLoss: 0.117478\n",
      "Train Epoch: 7 [14080/15392 (91%)]\tLoss: 0.026503\n",
      "Train Epoch: 7 [14720/15392 (95%)]\tLoss: 0.026975\n",
      "Train Epoch: 7 [7680/15392 (100%)]\tLoss: 0.079947\n",
      "Train Epoch: 8 [0/15392 (0%)]\tLoss: 0.002474\n",
      "Train Epoch: 8 [640/15392 (4%)]\tLoss: 0.031898\n",
      "Train Epoch: 8 [1280/15392 (8%)]\tLoss: 0.064987\n",
      "Train Epoch: 8 [1920/15392 (12%)]\tLoss: 0.036434\n",
      "Train Epoch: 8 [2560/15392 (17%)]\tLoss: 0.167130\n",
      "Train Epoch: 8 [3200/15392 (21%)]\tLoss: 0.035795\n",
      "Train Epoch: 8 [3840/15392 (25%)]\tLoss: 0.133869\n",
      "Train Epoch: 8 [4480/15392 (29%)]\tLoss: 0.016043\n",
      "Train Epoch: 8 [5120/15392 (33%)]\tLoss: 0.214267\n",
      "Train Epoch: 8 [5760/15392 (37%)]\tLoss: 0.020004\n",
      "Train Epoch: 8 [6400/15392 (41%)]\tLoss: 0.101640\n",
      "Train Epoch: 8 [7040/15392 (46%)]\tLoss: 0.025309\n",
      "Train Epoch: 8 [7680/15392 (50%)]\tLoss: 0.051417\n",
      "Train Epoch: 8 [8320/15392 (54%)]\tLoss: 0.017646\n",
      "Train Epoch: 8 [8960/15392 (58%)]\tLoss: 0.051217\n",
      "Train Epoch: 8 [9600/15392 (62%)]\tLoss: 0.012093\n",
      "Train Epoch: 8 [10240/15392 (66%)]\tLoss: 0.021018\n",
      "Train Epoch: 8 [10880/15392 (71%)]\tLoss: 0.181661\n",
      "Train Epoch: 8 [11520/15392 (75%)]\tLoss: 0.021243\n",
      "Train Epoch: 8 [12160/15392 (79%)]\tLoss: 0.024706\n",
      "Train Epoch: 8 [12800/15392 (83%)]\tLoss: 0.026764\n",
      "Train Epoch: 8 [13440/15392 (87%)]\tLoss: 0.181279\n",
      "Train Epoch: 8 [14080/15392 (91%)]\tLoss: 0.029332\n",
      "Train Epoch: 8 [14720/15392 (95%)]\tLoss: 0.038953\n",
      "Train Epoch: 8 [7680/15392 (100%)]\tLoss: 0.004433\n",
      "Train Epoch: 9 [0/15392 (0%)]\tLoss: 0.018714\n",
      "Train Epoch: 9 [640/15392 (4%)]\tLoss: 0.045856\n",
      "Train Epoch: 9 [1280/15392 (8%)]\tLoss: 0.049146\n",
      "Train Epoch: 9 [1920/15392 (12%)]\tLoss: 0.039805\n",
      "Train Epoch: 9 [2560/15392 (17%)]\tLoss: 0.005348\n",
      "Train Epoch: 9 [3200/15392 (21%)]\tLoss: 0.041289\n",
      "Train Epoch: 9 [3840/15392 (25%)]\tLoss: 0.057419\n",
      "Train Epoch: 9 [4480/15392 (29%)]\tLoss: 0.255954\n",
      "Train Epoch: 9 [5120/15392 (33%)]\tLoss: 0.070296\n",
      "Train Epoch: 9 [5760/15392 (37%)]\tLoss: 0.020516\n",
      "Train Epoch: 9 [6400/15392 (41%)]\tLoss: 0.118481\n",
      "Train Epoch: 9 [7040/15392 (46%)]\tLoss: 0.044467\n",
      "Train Epoch: 9 [7680/15392 (50%)]\tLoss: 0.108117\n",
      "Train Epoch: 9 [8320/15392 (54%)]\tLoss: 0.034216\n",
      "Train Epoch: 9 [8960/15392 (58%)]\tLoss: 0.030107\n",
      "Train Epoch: 9 [9600/15392 (62%)]\tLoss: 0.187547\n",
      "Train Epoch: 9 [10240/15392 (66%)]\tLoss: 0.016292\n",
      "Train Epoch: 9 [10880/15392 (71%)]\tLoss: 0.015812\n",
      "Train Epoch: 9 [11520/15392 (75%)]\tLoss: 0.032134\n",
      "Train Epoch: 9 [12160/15392 (79%)]\tLoss: 0.030652\n",
      "Train Epoch: 9 [12800/15392 (83%)]\tLoss: 0.030964\n",
      "Train Epoch: 9 [13440/15392 (87%)]\tLoss: 0.090199\n",
      "Train Epoch: 9 [14080/15392 (91%)]\tLoss: 0.025918\n",
      "Train Epoch: 9 [14720/15392 (95%)]\tLoss: 0.033299\n",
      "Train Epoch: 9 [7680/15392 (100%)]\tLoss: 0.009902\n",
      "Train Epoch: 10 [0/15392 (0%)]\tLoss: 0.043725\n",
      "Train Epoch: 10 [640/15392 (4%)]\tLoss: 0.009259\n",
      "Train Epoch: 10 [1280/15392 (8%)]\tLoss: 0.001100\n",
      "Train Epoch: 10 [1920/15392 (12%)]\tLoss: 0.056099\n",
      "Train Epoch: 10 [2560/15392 (17%)]\tLoss: 0.012516\n",
      "Train Epoch: 10 [3200/15392 (21%)]\tLoss: 0.058714\n",
      "Train Epoch: 10 [3840/15392 (25%)]\tLoss: 0.018937\n",
      "Train Epoch: 10 [4480/15392 (29%)]\tLoss: 0.116242\n",
      "Train Epoch: 10 [5120/15392 (33%)]\tLoss: 0.049426\n",
      "Train Epoch: 10 [5760/15392 (37%)]\tLoss: 0.060649\n",
      "Train Epoch: 10 [6400/15392 (41%)]\tLoss: 0.009996\n",
      "Train Epoch: 10 [7040/15392 (46%)]\tLoss: 0.027249\n",
      "Train Epoch: 10 [7680/15392 (50%)]\tLoss: 0.069712\n",
      "Train Epoch: 10 [8320/15392 (54%)]\tLoss: 0.060086\n",
      "Train Epoch: 10 [8960/15392 (58%)]\tLoss: 0.042319\n",
      "Train Epoch: 10 [9600/15392 (62%)]\tLoss: 0.032682\n",
      "Train Epoch: 10 [10240/15392 (66%)]\tLoss: 0.023707\n",
      "Train Epoch: 10 [10880/15392 (71%)]\tLoss: 0.053946\n",
      "Train Epoch: 10 [11520/15392 (75%)]\tLoss: 0.123164\n",
      "Train Epoch: 10 [12160/15392 (79%)]\tLoss: 0.025276\n",
      "Train Epoch: 10 [12800/15392 (83%)]\tLoss: 0.089553\n",
      "Train Epoch: 10 [13440/15392 (87%)]\tLoss: 0.040885\n",
      "Train Epoch: 10 [14080/15392 (91%)]\tLoss: 0.064156\n",
      "Train Epoch: 10 [14720/15392 (95%)]\tLoss: 0.055612\n",
      "Train Epoch: 10 [7680/15392 (100%)]\tLoss: 0.023524\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/15327 (0%)]\tLoss: 0.174340\n",
      "Train Epoch: 1 [640/15327 (4%)]\tLoss: 0.130052\n",
      "Train Epoch: 1 [1280/15327 (8%)]\tLoss: 0.121853\n",
      "Train Epoch: 1 [1920/15327 (12%)]\tLoss: 0.162326\n",
      "Train Epoch: 1 [2560/15327 (17%)]\tLoss: 0.055547\n",
      "Train Epoch: 1 [3200/15327 (21%)]\tLoss: 0.016074\n",
      "Train Epoch: 1 [3840/15327 (25%)]\tLoss: 0.042497\n",
      "Train Epoch: 1 [4480/15327 (29%)]\tLoss: 0.071548\n",
      "Train Epoch: 1 [5120/15327 (33%)]\tLoss: 0.266157\n",
      "Train Epoch: 1 [5760/15327 (38%)]\tLoss: 0.040496\n",
      "Train Epoch: 1 [6400/15327 (42%)]\tLoss: 0.141484\n",
      "Train Epoch: 1 [7040/15327 (46%)]\tLoss: 0.152304\n",
      "Train Epoch: 1 [7680/15327 (50%)]\tLoss: 0.220972\n",
      "Train Epoch: 1 [8320/15327 (54%)]\tLoss: 0.057313\n",
      "Train Epoch: 1 [8960/15327 (58%)]\tLoss: 0.042367\n",
      "Train Epoch: 1 [9600/15327 (62%)]\tLoss: 0.054963\n",
      "Train Epoch: 1 [10240/15327 (67%)]\tLoss: 0.021711\n",
      "Train Epoch: 1 [10880/15327 (71%)]\tLoss: 0.042485\n",
      "Train Epoch: 1 [11520/15327 (75%)]\tLoss: 0.021581\n",
      "Train Epoch: 1 [12160/15327 (79%)]\tLoss: 0.043842\n",
      "Train Epoch: 1 [12800/15327 (83%)]\tLoss: 0.044213\n",
      "Train Epoch: 1 [13440/15327 (88%)]\tLoss: 0.151190\n",
      "Train Epoch: 1 [14080/15327 (92%)]\tLoss: 0.136897\n",
      "Train Epoch: 1 [14720/15327 (96%)]\tLoss: 0.139162\n",
      "Train Epoch: 2 [0/15327 (0%)]\tLoss: 0.086145\n",
      "Train Epoch: 2 [640/15327 (4%)]\tLoss: 0.050938\n",
      "Train Epoch: 2 [1280/15327 (8%)]\tLoss: 0.052776\n",
      "Train Epoch: 2 [1920/15327 (12%)]\tLoss: 0.018156\n",
      "Train Epoch: 2 [2560/15327 (17%)]\tLoss: 0.087215\n",
      "Train Epoch: 2 [3200/15327 (21%)]\tLoss: 0.109746\n",
      "Train Epoch: 2 [3840/15327 (25%)]\tLoss: 0.043155\n",
      "Train Epoch: 2 [4480/15327 (29%)]\tLoss: 0.060986\n",
      "Train Epoch: 2 [5120/15327 (33%)]\tLoss: 0.022709\n",
      "Train Epoch: 2 [5760/15327 (38%)]\tLoss: 0.056463\n",
      "Train Epoch: 2 [6400/15327 (42%)]\tLoss: 0.073345\n",
      "Train Epoch: 2 [7040/15327 (46%)]\tLoss: 0.036986\n",
      "Train Epoch: 2 [7680/15327 (50%)]\tLoss: 0.066871\n",
      "Train Epoch: 2 [8320/15327 (54%)]\tLoss: 0.031813\n",
      "Train Epoch: 2 [8960/15327 (58%)]\tLoss: 0.064745\n",
      "Train Epoch: 2 [9600/15327 (62%)]\tLoss: 0.026618\n",
      "Train Epoch: 2 [10240/15327 (67%)]\tLoss: 0.092223\n",
      "Train Epoch: 2 [10880/15327 (71%)]\tLoss: 0.026601\n",
      "Train Epoch: 2 [11520/15327 (75%)]\tLoss: 0.028919\n",
      "Train Epoch: 2 [12160/15327 (79%)]\tLoss: 0.110134\n",
      "Train Epoch: 2 [12800/15327 (83%)]\tLoss: 0.069666\n",
      "Train Epoch: 2 [13440/15327 (88%)]\tLoss: 0.075775\n",
      "Train Epoch: 2 [14080/15327 (92%)]\tLoss: 0.070004\n",
      "Train Epoch: 2 [14720/15327 (96%)]\tLoss: 0.211452\n",
      "Train Epoch: 3 [0/15327 (0%)]\tLoss: 0.180172\n",
      "Train Epoch: 3 [640/15327 (4%)]\tLoss: 0.074544\n",
      "Train Epoch: 3 [1280/15327 (8%)]\tLoss: 0.101084\n",
      "Train Epoch: 3 [1920/15327 (12%)]\tLoss: 0.093676\n",
      "Train Epoch: 3 [2560/15327 (17%)]\tLoss: 0.052022\n",
      "Train Epoch: 3 [3200/15327 (21%)]\tLoss: 0.084009\n",
      "Train Epoch: 3 [3840/15327 (25%)]\tLoss: 0.043321\n",
      "Train Epoch: 3 [4480/15327 (29%)]\tLoss: 0.079304\n",
      "Train Epoch: 3 [5120/15327 (33%)]\tLoss: 0.070270\n",
      "Train Epoch: 3 [5760/15327 (38%)]\tLoss: 0.035343\n",
      "Train Epoch: 3 [6400/15327 (42%)]\tLoss: 0.088242\n",
      "Train Epoch: 3 [7040/15327 (46%)]\tLoss: 0.068905\n",
      "Train Epoch: 3 [7680/15327 (50%)]\tLoss: 0.050510\n",
      "Train Epoch: 3 [8320/15327 (54%)]\tLoss: 0.069402\n",
      "Train Epoch: 3 [8960/15327 (58%)]\tLoss: 0.023942\n",
      "Train Epoch: 3 [9600/15327 (62%)]\tLoss: 0.019759\n",
      "Train Epoch: 3 [10240/15327 (67%)]\tLoss: 0.087534\n",
      "Train Epoch: 3 [10880/15327 (71%)]\tLoss: 0.183098\n",
      "Train Epoch: 3 [11520/15327 (75%)]\tLoss: 0.027356\n",
      "Train Epoch: 3 [12160/15327 (79%)]\tLoss: 0.034342\n",
      "Train Epoch: 3 [12800/15327 (83%)]\tLoss: 0.421966\n",
      "Train Epoch: 3 [13440/15327 (88%)]\tLoss: 0.011368\n",
      "Train Epoch: 3 [14080/15327 (92%)]\tLoss: 0.153697\n",
      "Train Epoch: 3 [14720/15327 (96%)]\tLoss: 0.122632\n",
      "Train Epoch: 4 [0/15327 (0%)]\tLoss: 0.053106\n",
      "Train Epoch: 4 [640/15327 (4%)]\tLoss: 0.135781\n",
      "Train Epoch: 4 [1280/15327 (8%)]\tLoss: 0.091864\n",
      "Train Epoch: 4 [1920/15327 (12%)]\tLoss: 0.027536\n",
      "Train Epoch: 4 [2560/15327 (17%)]\tLoss: 0.051220\n",
      "Train Epoch: 4 [3200/15327 (21%)]\tLoss: 0.072377\n",
      "Train Epoch: 4 [3840/15327 (25%)]\tLoss: 0.100948\n",
      "Train Epoch: 4 [4480/15327 (29%)]\tLoss: 0.061292\n",
      "Train Epoch: 4 [5120/15327 (33%)]\tLoss: 0.031372\n",
      "Train Epoch: 4 [5760/15327 (38%)]\tLoss: 0.108740\n",
      "Train Epoch: 4 [6400/15327 (42%)]\tLoss: 0.103826\n",
      "Train Epoch: 4 [7040/15327 (46%)]\tLoss: 0.082489\n",
      "Train Epoch: 4 [7680/15327 (50%)]\tLoss: 0.053113\n",
      "Train Epoch: 4 [8320/15327 (54%)]\tLoss: 0.023954\n",
      "Train Epoch: 4 [8960/15327 (58%)]\tLoss: 0.040076\n",
      "Train Epoch: 4 [9600/15327 (62%)]\tLoss: 0.035283\n",
      "Train Epoch: 4 [10240/15327 (67%)]\tLoss: 0.017457\n",
      "Train Epoch: 4 [10880/15327 (71%)]\tLoss: 0.009527\n",
      "Train Epoch: 4 [11520/15327 (75%)]\tLoss: 0.019636\n",
      "Train Epoch: 4 [12160/15327 (79%)]\tLoss: 0.073564\n",
      "Train Epoch: 4 [12800/15327 (83%)]\tLoss: 0.021824\n",
      "Train Epoch: 4 [13440/15327 (88%)]\tLoss: 0.010180\n",
      "Train Epoch: 4 [14080/15327 (92%)]\tLoss: 0.054537\n",
      "Train Epoch: 4 [14720/15327 (96%)]\tLoss: 0.027390\n",
      "Train Epoch: 5 [0/15327 (0%)]\tLoss: 0.039977\n",
      "Train Epoch: 5 [640/15327 (4%)]\tLoss: 0.026123\n",
      "Train Epoch: 5 [1280/15327 (8%)]\tLoss: 0.137904\n",
      "Train Epoch: 5 [1920/15327 (12%)]\tLoss: 0.016529\n",
      "Train Epoch: 5 [2560/15327 (17%)]\tLoss: 0.071290\n",
      "Train Epoch: 5 [3200/15327 (21%)]\tLoss: 0.030497\n",
      "Train Epoch: 5 [3840/15327 (25%)]\tLoss: 0.035534\n",
      "Train Epoch: 5 [4480/15327 (29%)]\tLoss: 0.042888\n",
      "Train Epoch: 5 [5120/15327 (33%)]\tLoss: 0.091770\n",
      "Train Epoch: 5 [5760/15327 (38%)]\tLoss: 0.020439\n",
      "Train Epoch: 5 [6400/15327 (42%)]\tLoss: 0.102845\n",
      "Train Epoch: 5 [7040/15327 (46%)]\tLoss: 0.060527\n",
      "Train Epoch: 5 [7680/15327 (50%)]\tLoss: 0.022067\n",
      "Train Epoch: 5 [8320/15327 (54%)]\tLoss: 0.028428\n",
      "Train Epoch: 5 [8960/15327 (58%)]\tLoss: 0.026784\n",
      "Train Epoch: 5 [9600/15327 (62%)]\tLoss: 0.054436\n",
      "Train Epoch: 5 [10240/15327 (67%)]\tLoss: 0.013058\n",
      "Train Epoch: 5 [10880/15327 (71%)]\tLoss: 0.124160\n",
      "Train Epoch: 5 [11520/15327 (75%)]\tLoss: 0.106148\n",
      "Train Epoch: 5 [12160/15327 (79%)]\tLoss: 0.061733\n",
      "Train Epoch: 5 [12800/15327 (83%)]\tLoss: 0.112468\n",
      "Train Epoch: 5 [13440/15327 (88%)]\tLoss: 0.152211\n",
      "Train Epoch: 5 [14080/15327 (92%)]\tLoss: 0.047403\n",
      "Train Epoch: 5 [14720/15327 (96%)]\tLoss: 0.178253\n",
      "Train Epoch: 6 [0/15327 (0%)]\tLoss: 0.076798\n",
      "Train Epoch: 6 [640/15327 (4%)]\tLoss: 0.082300\n",
      "Train Epoch: 6 [1280/15327 (8%)]\tLoss: 0.015306\n",
      "Train Epoch: 6 [1920/15327 (12%)]\tLoss: 0.046592\n",
      "Train Epoch: 6 [2560/15327 (17%)]\tLoss: 0.021843\n",
      "Train Epoch: 6 [3200/15327 (21%)]\tLoss: 0.035998\n",
      "Train Epoch: 6 [3840/15327 (25%)]\tLoss: 0.043026\n",
      "Train Epoch: 6 [4480/15327 (29%)]\tLoss: 0.020522\n",
      "Train Epoch: 6 [5120/15327 (33%)]\tLoss: 0.020585\n",
      "Train Epoch: 6 [5760/15327 (38%)]\tLoss: 0.044008\n",
      "Train Epoch: 6 [6400/15327 (42%)]\tLoss: 0.043615\n",
      "Train Epoch: 6 [7040/15327 (46%)]\tLoss: 0.048254\n",
      "Train Epoch: 6 [7680/15327 (50%)]\tLoss: 0.038814\n",
      "Train Epoch: 6 [8320/15327 (54%)]\tLoss: 0.269342\n",
      "Train Epoch: 6 [8960/15327 (58%)]\tLoss: 0.308798\n",
      "Train Epoch: 6 [9600/15327 (62%)]\tLoss: 0.137986\n",
      "Train Epoch: 6 [10240/15327 (67%)]\tLoss: 0.027746\n",
      "Train Epoch: 6 [10880/15327 (71%)]\tLoss: 0.068408\n",
      "Train Epoch: 6 [11520/15327 (75%)]\tLoss: 0.010119\n",
      "Train Epoch: 6 [12160/15327 (79%)]\tLoss: 0.013983\n",
      "Train Epoch: 6 [12800/15327 (83%)]\tLoss: 0.070401\n",
      "Train Epoch: 6 [13440/15327 (88%)]\tLoss: 0.049857\n",
      "Train Epoch: 6 [14080/15327 (92%)]\tLoss: 0.027367\n",
      "Train Epoch: 6 [14720/15327 (96%)]\tLoss: 0.110168\n",
      "Train Epoch: 7 [0/15327 (0%)]\tLoss: 0.034427\n",
      "Train Epoch: 7 [640/15327 (4%)]\tLoss: 0.104394\n",
      "Train Epoch: 7 [1280/15327 (8%)]\tLoss: 0.039623\n",
      "Train Epoch: 7 [1920/15327 (12%)]\tLoss: 0.072395\n",
      "Train Epoch: 7 [2560/15327 (17%)]\tLoss: 0.231264\n",
      "Train Epoch: 7 [3200/15327 (21%)]\tLoss: 0.085437\n",
      "Train Epoch: 7 [3840/15327 (25%)]\tLoss: 0.130975\n",
      "Train Epoch: 7 [4480/15327 (29%)]\tLoss: 0.039022\n",
      "Train Epoch: 7 [5120/15327 (33%)]\tLoss: 0.129027\n",
      "Train Epoch: 7 [5760/15327 (38%)]\tLoss: 0.071127\n",
      "Train Epoch: 7 [6400/15327 (42%)]\tLoss: 0.067126\n",
      "Train Epoch: 7 [7040/15327 (46%)]\tLoss: 0.037202\n",
      "Train Epoch: 7 [7680/15327 (50%)]\tLoss: 0.039629\n",
      "Train Epoch: 7 [8320/15327 (54%)]\tLoss: 0.112545\n",
      "Train Epoch: 7 [8960/15327 (58%)]\tLoss: 0.159723\n",
      "Train Epoch: 7 [9600/15327 (62%)]\tLoss: 0.040809\n",
      "Train Epoch: 7 [10240/15327 (67%)]\tLoss: 0.194805\n",
      "Train Epoch: 7 [10880/15327 (71%)]\tLoss: 0.061990\n",
      "Train Epoch: 7 [11520/15327 (75%)]\tLoss: 0.051333\n",
      "Train Epoch: 7 [12160/15327 (79%)]\tLoss: 0.098581\n",
      "Train Epoch: 7 [12800/15327 (83%)]\tLoss: 0.023105\n",
      "Train Epoch: 7 [13440/15327 (88%)]\tLoss: 0.039824\n",
      "Train Epoch: 7 [14080/15327 (92%)]\tLoss: 0.081332\n",
      "Train Epoch: 7 [14720/15327 (96%)]\tLoss: 0.038192\n",
      "Train Epoch: 8 [0/15327 (0%)]\tLoss: 0.033831\n",
      "Train Epoch: 8 [640/15327 (4%)]\tLoss: 0.062246\n",
      "Train Epoch: 8 [1280/15327 (8%)]\tLoss: 0.002207\n",
      "Train Epoch: 8 [1920/15327 (12%)]\tLoss: 0.096899\n",
      "Train Epoch: 8 [2560/15327 (17%)]\tLoss: 0.066467\n",
      "Train Epoch: 8 [3200/15327 (21%)]\tLoss: 0.165690\n",
      "Train Epoch: 8 [3840/15327 (25%)]\tLoss: 0.130974\n",
      "Train Epoch: 8 [4480/15327 (29%)]\tLoss: 0.028741\n",
      "Train Epoch: 8 [5120/15327 (33%)]\tLoss: 0.050907\n",
      "Train Epoch: 8 [5760/15327 (38%)]\tLoss: 0.029392\n",
      "Train Epoch: 8 [6400/15327 (42%)]\tLoss: 0.017803\n",
      "Train Epoch: 8 [7040/15327 (46%)]\tLoss: 0.119575\n",
      "Train Epoch: 8 [7680/15327 (50%)]\tLoss: 0.033427\n",
      "Train Epoch: 8 [8320/15327 (54%)]\tLoss: 0.019238\n",
      "Train Epoch: 8 [8960/15327 (58%)]\tLoss: 0.034821\n",
      "Train Epoch: 8 [9600/15327 (62%)]\tLoss: 0.035073\n",
      "Train Epoch: 8 [10240/15327 (67%)]\tLoss: 0.039302\n",
      "Train Epoch: 8 [10880/15327 (71%)]\tLoss: 0.031859\n",
      "Train Epoch: 8 [11520/15327 (75%)]\tLoss: 0.086066\n",
      "Train Epoch: 8 [12160/15327 (79%)]\tLoss: 0.027126\n",
      "Train Epoch: 8 [12800/15327 (83%)]\tLoss: 0.037794\n",
      "Train Epoch: 8 [13440/15327 (88%)]\tLoss: 0.030274\n",
      "Train Epoch: 8 [14080/15327 (92%)]\tLoss: 0.079092\n",
      "Train Epoch: 8 [14720/15327 (96%)]\tLoss: 0.011841\n",
      "Train Epoch: 9 [0/15327 (0%)]\tLoss: 0.185871\n",
      "Train Epoch: 9 [640/15327 (4%)]\tLoss: 0.012236\n",
      "Train Epoch: 9 [1280/15327 (8%)]\tLoss: 0.117911\n",
      "Train Epoch: 9 [1920/15327 (12%)]\tLoss: 0.009157\n",
      "Train Epoch: 9 [2560/15327 (17%)]\tLoss: 0.016978\n",
      "Train Epoch: 9 [3200/15327 (21%)]\tLoss: 0.010497\n",
      "Train Epoch: 9 [3840/15327 (25%)]\tLoss: 0.021234\n",
      "Train Epoch: 9 [4480/15327 (29%)]\tLoss: 0.028312\n",
      "Train Epoch: 9 [5120/15327 (33%)]\tLoss: 0.048055\n",
      "Train Epoch: 9 [5760/15327 (38%)]\tLoss: 0.107904\n",
      "Train Epoch: 9 [6400/15327 (42%)]\tLoss: 0.060279\n",
      "Train Epoch: 9 [7040/15327 (46%)]\tLoss: 0.024824\n",
      "Train Epoch: 9 [7680/15327 (50%)]\tLoss: 0.109411\n",
      "Train Epoch: 9 [8320/15327 (54%)]\tLoss: 0.078684\n",
      "Train Epoch: 9 [8960/15327 (58%)]\tLoss: 0.050762\n",
      "Train Epoch: 9 [9600/15327 (62%)]\tLoss: 0.125770\n",
      "Train Epoch: 9 [10240/15327 (67%)]\tLoss: 0.199041\n",
      "Train Epoch: 9 [10880/15327 (71%)]\tLoss: 0.011240\n",
      "Train Epoch: 9 [11520/15327 (75%)]\tLoss: 0.375015\n",
      "Train Epoch: 9 [12160/15327 (79%)]\tLoss: 0.041443\n",
      "Train Epoch: 9 [12800/15327 (83%)]\tLoss: 0.017292\n",
      "Train Epoch: 9 [13440/15327 (88%)]\tLoss: 0.038852\n",
      "Train Epoch: 9 [14080/15327 (92%)]\tLoss: 0.120921\n",
      "Train Epoch: 9 [14720/15327 (96%)]\tLoss: 0.025231\n",
      "Train Epoch: 10 [0/15327 (0%)]\tLoss: 0.117528\n",
      "Train Epoch: 10 [640/15327 (4%)]\tLoss: 0.037028\n",
      "Train Epoch: 10 [1280/15327 (8%)]\tLoss: 0.076304\n",
      "Train Epoch: 10 [1920/15327 (12%)]\tLoss: 0.064728\n",
      "Train Epoch: 10 [2560/15327 (17%)]\tLoss: 0.037949\n",
      "Train Epoch: 10 [3200/15327 (21%)]\tLoss: 0.066732\n",
      "Train Epoch: 10 [3840/15327 (25%)]\tLoss: 0.049883\n",
      "Train Epoch: 10 [4480/15327 (29%)]\tLoss: 0.043954\n",
      "Train Epoch: 10 [5120/15327 (33%)]\tLoss: 0.144559\n",
      "Train Epoch: 10 [5760/15327 (38%)]\tLoss: 0.049166\n",
      "Train Epoch: 10 [6400/15327 (42%)]\tLoss: 0.015121\n",
      "Train Epoch: 10 [7040/15327 (46%)]\tLoss: 0.027983\n",
      "Train Epoch: 10 [7680/15327 (50%)]\tLoss: 0.019037\n",
      "Train Epoch: 10 [8320/15327 (54%)]\tLoss: 0.075919\n",
      "Train Epoch: 10 [8960/15327 (58%)]\tLoss: 0.158143\n",
      "Train Epoch: 10 [9600/15327 (62%)]\tLoss: 0.054166\n",
      "Train Epoch: 10 [10240/15327 (67%)]\tLoss: 0.067802\n",
      "Train Epoch: 10 [10880/15327 (71%)]\tLoss: 0.106033\n",
      "Train Epoch: 10 [11520/15327 (75%)]\tLoss: 0.053869\n",
      "Train Epoch: 10 [12160/15327 (79%)]\tLoss: 0.037648\n",
      "Train Epoch: 10 [12800/15327 (83%)]\tLoss: 0.009537\n",
      "Train Epoch: 10 [13440/15327 (88%)]\tLoss: 0.012463\n",
      "Train Epoch: 10 [14080/15327 (92%)]\tLoss: 0.067608\n",
      "Train Epoch: 10 [14720/15327 (96%)]\tLoss: 0.037299\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.1764, Accuracy: 9857/10000 (99%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/18662 (0%)]\tLoss: 0.171393\n",
      "Train Epoch: 1 [640/18662 (3%)]\tLoss: 0.198522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1280/18662 (7%)]\tLoss: 0.137397\n",
      "Train Epoch: 1 [1920/18662 (10%)]\tLoss: 0.073083\n",
      "Train Epoch: 1 [2560/18662 (14%)]\tLoss: 0.121603\n",
      "Train Epoch: 1 [3200/18662 (17%)]\tLoss: 0.034028\n",
      "Train Epoch: 1 [3840/18662 (21%)]\tLoss: 0.118060\n",
      "Train Epoch: 1 [4480/18662 (24%)]\tLoss: 0.064586\n",
      "Train Epoch: 1 [5120/18662 (27%)]\tLoss: 0.054659\n",
      "Train Epoch: 1 [5760/18662 (31%)]\tLoss: 0.025283\n",
      "Train Epoch: 1 [6400/18662 (34%)]\tLoss: 0.035822\n",
      "Train Epoch: 1 [7040/18662 (38%)]\tLoss: 0.089777\n",
      "Train Epoch: 1 [7680/18662 (41%)]\tLoss: 0.244468\n",
      "Train Epoch: 1 [8320/18662 (45%)]\tLoss: 0.027226\n",
      "Train Epoch: 1 [8960/18662 (48%)]\tLoss: 0.144441\n",
      "Train Epoch: 1 [9600/18662 (51%)]\tLoss: 0.211318\n",
      "Train Epoch: 1 [10240/18662 (55%)]\tLoss: 0.029701\n",
      "Train Epoch: 1 [10880/18662 (58%)]\tLoss: 0.086649\n",
      "Train Epoch: 1 [11520/18662 (62%)]\tLoss: 0.011015\n",
      "Train Epoch: 1 [12160/18662 (65%)]\tLoss: 0.014943\n",
      "Train Epoch: 1 [12800/18662 (68%)]\tLoss: 0.014854\n",
      "Train Epoch: 1 [13440/18662 (72%)]\tLoss: 0.017824\n",
      "Train Epoch: 1 [14080/18662 (75%)]\tLoss: 0.082202\n",
      "Train Epoch: 1 [14720/18662 (79%)]\tLoss: 0.100662\n",
      "Train Epoch: 1 [15360/18662 (82%)]\tLoss: 0.013746\n",
      "Train Epoch: 1 [16000/18662 (86%)]\tLoss: 0.027694\n",
      "Train Epoch: 1 [16640/18662 (89%)]\tLoss: 0.088473\n",
      "Train Epoch: 1 [17280/18662 (92%)]\tLoss: 0.047934\n",
      "Train Epoch: 1 [17920/18662 (96%)]\tLoss: 0.106798\n",
      "Train Epoch: 1 [18560/18662 (99%)]\tLoss: 0.050810\n",
      "Train Epoch: 2 [0/18662 (0%)]\tLoss: 0.027433\n",
      "Train Epoch: 2 [640/18662 (3%)]\tLoss: 0.038162\n",
      "Train Epoch: 2 [1280/18662 (7%)]\tLoss: 0.150171\n",
      "Train Epoch: 2 [1920/18662 (10%)]\tLoss: 0.039581\n",
      "Train Epoch: 2 [2560/18662 (14%)]\tLoss: 0.095249\n",
      "Train Epoch: 2 [3200/18662 (17%)]\tLoss: 0.025080\n",
      "Train Epoch: 2 [3840/18662 (21%)]\tLoss: 0.057716\n",
      "Train Epoch: 2 [4480/18662 (24%)]\tLoss: 0.024373\n",
      "Train Epoch: 2 [5120/18662 (27%)]\tLoss: 0.144770\n",
      "Train Epoch: 2 [5760/18662 (31%)]\tLoss: 0.026397\n",
      "Train Epoch: 2 [6400/18662 (34%)]\tLoss: 0.114726\n",
      "Train Epoch: 2 [7040/18662 (38%)]\tLoss: 0.272769\n",
      "Train Epoch: 2 [7680/18662 (41%)]\tLoss: 0.183045\n",
      "Train Epoch: 2 [8320/18662 (45%)]\tLoss: 0.006456\n",
      "Train Epoch: 2 [8960/18662 (48%)]\tLoss: 0.110569\n",
      "Train Epoch: 2 [9600/18662 (51%)]\tLoss: 0.032321\n",
      "Train Epoch: 2 [10240/18662 (55%)]\tLoss: 0.117031\n",
      "Train Epoch: 2 [10880/18662 (58%)]\tLoss: 0.038445\n",
      "Train Epoch: 2 [11520/18662 (62%)]\tLoss: 0.018787\n",
      "Train Epoch: 2 [12160/18662 (65%)]\tLoss: 0.114348\n",
      "Train Epoch: 2 [12800/18662 (68%)]\tLoss: 0.028445\n",
      "Train Epoch: 2 [13440/18662 (72%)]\tLoss: 0.085813\n",
      "Train Epoch: 2 [14080/18662 (75%)]\tLoss: 0.192491\n",
      "Train Epoch: 2 [14720/18662 (79%)]\tLoss: 0.031128\n",
      "Train Epoch: 2 [15360/18662 (82%)]\tLoss: 0.015989\n",
      "Train Epoch: 2 [16000/18662 (86%)]\tLoss: 0.029817\n",
      "Train Epoch: 2 [16640/18662 (89%)]\tLoss: 0.021676\n",
      "Train Epoch: 2 [17280/18662 (92%)]\tLoss: 0.087267\n",
      "Train Epoch: 2 [17920/18662 (96%)]\tLoss: 0.241189\n",
      "Train Epoch: 2 [18560/18662 (99%)]\tLoss: 0.045193\n",
      "Train Epoch: 3 [0/18662 (0%)]\tLoss: 0.073694\n",
      "Train Epoch: 3 [640/18662 (3%)]\tLoss: 0.076868\n",
      "Train Epoch: 3 [1280/18662 (7%)]\tLoss: 0.043661\n",
      "Train Epoch: 3 [1920/18662 (10%)]\tLoss: 0.181332\n",
      "Train Epoch: 3 [2560/18662 (14%)]\tLoss: 0.013144\n",
      "Train Epoch: 3 [3200/18662 (17%)]\tLoss: 0.217668\n",
      "Train Epoch: 3 [3840/18662 (21%)]\tLoss: 0.070205\n",
      "Train Epoch: 3 [4480/18662 (24%)]\tLoss: 0.029773\n",
      "Train Epoch: 3 [5120/18662 (27%)]\tLoss: 0.026015\n",
      "Train Epoch: 3 [5760/18662 (31%)]\tLoss: 0.061213\n",
      "Train Epoch: 3 [6400/18662 (34%)]\tLoss: 0.011371\n",
      "Train Epoch: 3 [7040/18662 (38%)]\tLoss: 0.058533\n",
      "Train Epoch: 3 [7680/18662 (41%)]\tLoss: 0.020966\n",
      "Train Epoch: 3 [8320/18662 (45%)]\tLoss: 0.086306\n",
      "Train Epoch: 3 [8960/18662 (48%)]\tLoss: 0.250319\n",
      "Train Epoch: 3 [9600/18662 (51%)]\tLoss: 0.051582\n",
      "Train Epoch: 3 [10240/18662 (55%)]\tLoss: 0.020393\n",
      "Train Epoch: 3 [10880/18662 (58%)]\tLoss: 0.018760\n",
      "Train Epoch: 3 [11520/18662 (62%)]\tLoss: 0.138401\n",
      "Train Epoch: 3 [12160/18662 (65%)]\tLoss: 0.014581\n",
      "Train Epoch: 3 [12800/18662 (68%)]\tLoss: 0.061008\n",
      "Train Epoch: 3 [13440/18662 (72%)]\tLoss: 0.008875\n",
      "Train Epoch: 3 [14080/18662 (75%)]\tLoss: 0.014270\n",
      "Train Epoch: 3 [14720/18662 (79%)]\tLoss: 0.187827\n",
      "Train Epoch: 3 [15360/18662 (82%)]\tLoss: 0.033616\n",
      "Train Epoch: 3 [16000/18662 (86%)]\tLoss: 0.036135\n",
      "Train Epoch: 3 [16640/18662 (89%)]\tLoss: 0.029212\n",
      "Train Epoch: 3 [17280/18662 (92%)]\tLoss: 0.021711\n",
      "Train Epoch: 3 [17920/18662 (96%)]\tLoss: 0.038089\n",
      "Train Epoch: 3 [18560/18662 (99%)]\tLoss: 0.233989\n",
      "Train Epoch: 4 [0/18662 (0%)]\tLoss: 0.034140\n",
      "Train Epoch: 4 [640/18662 (3%)]\tLoss: 0.004512\n",
      "Train Epoch: 4 [1280/18662 (7%)]\tLoss: 0.279285\n",
      "Train Epoch: 4 [1920/18662 (10%)]\tLoss: 0.021404\n",
      "Train Epoch: 4 [2560/18662 (14%)]\tLoss: 0.114026\n",
      "Train Epoch: 4 [3200/18662 (17%)]\tLoss: 0.014124\n",
      "Train Epoch: 4 [3840/18662 (21%)]\tLoss: 0.014805\n",
      "Train Epoch: 4 [4480/18662 (24%)]\tLoss: 0.046969\n",
      "Train Epoch: 4 [5120/18662 (27%)]\tLoss: 0.086667\n",
      "Train Epoch: 4 [5760/18662 (31%)]\tLoss: 0.097950\n",
      "Train Epoch: 4 [6400/18662 (34%)]\tLoss: 0.022354\n",
      "Train Epoch: 4 [7040/18662 (38%)]\tLoss: 0.028417\n",
      "Train Epoch: 4 [7680/18662 (41%)]\tLoss: 0.088389\n",
      "Train Epoch: 4 [8320/18662 (45%)]\tLoss: 0.054086\n",
      "Train Epoch: 4 [8960/18662 (48%)]\tLoss: 0.060901\n",
      "Train Epoch: 4 [9600/18662 (51%)]\tLoss: 0.018215\n",
      "Train Epoch: 4 [10240/18662 (55%)]\tLoss: 0.085603\n",
      "Train Epoch: 4 [10880/18662 (58%)]\tLoss: 0.031489\n",
      "Train Epoch: 4 [11520/18662 (62%)]\tLoss: 0.048193\n",
      "Train Epoch: 4 [12160/18662 (65%)]\tLoss: 0.059938\n",
      "Train Epoch: 4 [12800/18662 (68%)]\tLoss: 0.023339\n",
      "Train Epoch: 4 [13440/18662 (72%)]\tLoss: 0.118075\n",
      "Train Epoch: 4 [14080/18662 (75%)]\tLoss: 0.023177\n",
      "Train Epoch: 4 [14720/18662 (79%)]\tLoss: 0.060422\n",
      "Train Epoch: 4 [15360/18662 (82%)]\tLoss: 0.015113\n",
      "Train Epoch: 4 [16000/18662 (86%)]\tLoss: 0.070448\n",
      "Train Epoch: 4 [16640/18662 (89%)]\tLoss: 0.010272\n",
      "Train Epoch: 4 [17280/18662 (92%)]\tLoss: 0.170223\n",
      "Train Epoch: 4 [17920/18662 (96%)]\tLoss: 0.034049\n",
      "Train Epoch: 4 [18560/18662 (99%)]\tLoss: 0.027417\n",
      "Train Epoch: 5 [0/18662 (0%)]\tLoss: 0.026192\n",
      "Train Epoch: 5 [640/18662 (3%)]\tLoss: 0.082559\n",
      "Train Epoch: 5 [1280/18662 (7%)]\tLoss: 0.067288\n",
      "Train Epoch: 5 [1920/18662 (10%)]\tLoss: 0.054478\n",
      "Train Epoch: 5 [2560/18662 (14%)]\tLoss: 0.041313\n",
      "Train Epoch: 5 [3200/18662 (17%)]\tLoss: 0.021913\n",
      "Train Epoch: 5 [3840/18662 (21%)]\tLoss: 0.034801\n",
      "Train Epoch: 5 [4480/18662 (24%)]\tLoss: 0.015209\n",
      "Train Epoch: 5 [5120/18662 (27%)]\tLoss: 0.039090\n",
      "Train Epoch: 5 [5760/18662 (31%)]\tLoss: 0.126011\n",
      "Train Epoch: 5 [6400/18662 (34%)]\tLoss: 0.024564\n",
      "Train Epoch: 5 [7040/18662 (38%)]\tLoss: 0.011820\n",
      "Train Epoch: 5 [7680/18662 (41%)]\tLoss: 0.165827\n",
      "Train Epoch: 5 [8320/18662 (45%)]\tLoss: 0.045356\n",
      "Train Epoch: 5 [8960/18662 (48%)]\tLoss: 0.169850\n",
      "Train Epoch: 5 [9600/18662 (51%)]\tLoss: 0.149796\n",
      "Train Epoch: 5 [10240/18662 (55%)]\tLoss: 0.046329\n",
      "Train Epoch: 5 [10880/18662 (58%)]\tLoss: 0.007442\n",
      "Train Epoch: 5 [11520/18662 (62%)]\tLoss: 0.043414\n",
      "Train Epoch: 5 [12160/18662 (65%)]\tLoss: 0.024527\n",
      "Train Epoch: 5 [12800/18662 (68%)]\tLoss: 0.035106\n",
      "Train Epoch: 5 [13440/18662 (72%)]\tLoss: 0.071480\n",
      "Train Epoch: 5 [14080/18662 (75%)]\tLoss: 0.098681\n",
      "Train Epoch: 5 [14720/18662 (79%)]\tLoss: 0.117727\n",
      "Train Epoch: 5 [15360/18662 (82%)]\tLoss: 0.113550\n",
      "Train Epoch: 5 [16000/18662 (86%)]\tLoss: 0.013398\n",
      "Train Epoch: 5 [16640/18662 (89%)]\tLoss: 0.155051\n",
      "Train Epoch: 5 [17280/18662 (92%)]\tLoss: 0.030623\n",
      "Train Epoch: 5 [17920/18662 (96%)]\tLoss: 0.057663\n",
      "Train Epoch: 5 [18560/18662 (99%)]\tLoss: 0.041837\n",
      "Train Epoch: 6 [0/18662 (0%)]\tLoss: 0.018802\n",
      "Train Epoch: 6 [640/18662 (3%)]\tLoss: 0.020990\n",
      "Train Epoch: 6 [1280/18662 (7%)]\tLoss: 0.114704\n",
      "Train Epoch: 6 [1920/18662 (10%)]\tLoss: 0.045268\n",
      "Train Epoch: 6 [2560/18662 (14%)]\tLoss: 0.128843\n",
      "Train Epoch: 6 [3200/18662 (17%)]\tLoss: 0.026591\n",
      "Train Epoch: 6 [3840/18662 (21%)]\tLoss: 0.115178\n",
      "Train Epoch: 6 [4480/18662 (24%)]\tLoss: 0.053099\n",
      "Train Epoch: 6 [5120/18662 (27%)]\tLoss: 0.029515\n",
      "Train Epoch: 6 [5760/18662 (31%)]\tLoss: 0.037239\n",
      "Train Epoch: 6 [6400/18662 (34%)]\tLoss: 0.135304\n",
      "Train Epoch: 6 [7040/18662 (38%)]\tLoss: 0.028882\n",
      "Train Epoch: 6 [7680/18662 (41%)]\tLoss: 0.083244\n",
      "Train Epoch: 6 [8320/18662 (45%)]\tLoss: 0.025488\n",
      "Train Epoch: 6 [8960/18662 (48%)]\tLoss: 0.029466\n",
      "Train Epoch: 6 [9600/18662 (51%)]\tLoss: 0.115102\n",
      "Train Epoch: 6 [10240/18662 (55%)]\tLoss: 0.169820\n",
      "Train Epoch: 6 [10880/18662 (58%)]\tLoss: 0.024266\n",
      "Train Epoch: 6 [11520/18662 (62%)]\tLoss: 0.022836\n",
      "Train Epoch: 6 [12160/18662 (65%)]\tLoss: 0.018030\n",
      "Train Epoch: 6 [12800/18662 (68%)]\tLoss: 0.003164\n",
      "Train Epoch: 6 [13440/18662 (72%)]\tLoss: 0.058669\n",
      "Train Epoch: 6 [14080/18662 (75%)]\tLoss: 0.100443\n",
      "Train Epoch: 6 [14720/18662 (79%)]\tLoss: 0.076075\n",
      "Train Epoch: 6 [15360/18662 (82%)]\tLoss: 0.080631\n",
      "Train Epoch: 6 [16000/18662 (86%)]\tLoss: 0.041989\n",
      "Train Epoch: 6 [16640/18662 (89%)]\tLoss: 0.030615\n",
      "Train Epoch: 6 [17280/18662 (92%)]\tLoss: 0.043303\n",
      "Train Epoch: 6 [17920/18662 (96%)]\tLoss: 0.024813\n",
      "Train Epoch: 6 [18560/18662 (99%)]\tLoss: 0.030133\n",
      "Train Epoch: 7 [0/18662 (0%)]\tLoss: 0.035133\n",
      "Train Epoch: 7 [640/18662 (3%)]\tLoss: 0.084518\n",
      "Train Epoch: 7 [1280/18662 (7%)]\tLoss: 0.039967\n",
      "Train Epoch: 7 [1920/18662 (10%)]\tLoss: 0.072470\n",
      "Train Epoch: 7 [2560/18662 (14%)]\tLoss: 0.027366\n",
      "Train Epoch: 7 [3200/18662 (17%)]\tLoss: 0.049814\n",
      "Train Epoch: 7 [3840/18662 (21%)]\tLoss: 0.022875\n",
      "Train Epoch: 7 [4480/18662 (24%)]\tLoss: 0.047657\n",
      "Train Epoch: 7 [5120/18662 (27%)]\tLoss: 0.014401\n",
      "Train Epoch: 7 [5760/18662 (31%)]\tLoss: 0.048278\n",
      "Train Epoch: 7 [6400/18662 (34%)]\tLoss: 0.004712\n",
      "Train Epoch: 7 [7040/18662 (38%)]\tLoss: 0.159394\n",
      "Train Epoch: 7 [7680/18662 (41%)]\tLoss: 0.040751\n",
      "Train Epoch: 7 [8320/18662 (45%)]\tLoss: 0.069645\n",
      "Train Epoch: 7 [8960/18662 (48%)]\tLoss: 0.098783\n",
      "Train Epoch: 7 [9600/18662 (51%)]\tLoss: 0.050694\n",
      "Train Epoch: 7 [10240/18662 (55%)]\tLoss: 0.161829\n",
      "Train Epoch: 7 [10880/18662 (58%)]\tLoss: 0.119656\n",
      "Train Epoch: 7 [11520/18662 (62%)]\tLoss: 0.055415\n",
      "Train Epoch: 7 [12160/18662 (65%)]\tLoss: 0.030967\n",
      "Train Epoch: 7 [12800/18662 (68%)]\tLoss: 0.026967\n",
      "Train Epoch: 7 [13440/18662 (72%)]\tLoss: 0.052795\n",
      "Train Epoch: 7 [14080/18662 (75%)]\tLoss: 0.153417\n",
      "Train Epoch: 7 [14720/18662 (79%)]\tLoss: 0.039074\n",
      "Train Epoch: 7 [15360/18662 (82%)]\tLoss: 0.019293\n",
      "Train Epoch: 7 [16000/18662 (86%)]\tLoss: 0.069635\n",
      "Train Epoch: 7 [16640/18662 (89%)]\tLoss: 0.245415\n",
      "Train Epoch: 7 [17280/18662 (92%)]\tLoss: 0.051833\n",
      "Train Epoch: 7 [17920/18662 (96%)]\tLoss: 0.160984\n",
      "Train Epoch: 7 [18560/18662 (99%)]\tLoss: 0.019226\n",
      "Train Epoch: 8 [0/18662 (0%)]\tLoss: 0.012305\n",
      "Train Epoch: 8 [640/18662 (3%)]\tLoss: 0.145117\n",
      "Train Epoch: 8 [1280/18662 (7%)]\tLoss: 0.115429\n",
      "Train Epoch: 8 [1920/18662 (10%)]\tLoss: 0.032622\n",
      "Train Epoch: 8 [2560/18662 (14%)]\tLoss: 0.036854\n",
      "Train Epoch: 8 [3200/18662 (17%)]\tLoss: 0.035713\n",
      "Train Epoch: 8 [3840/18662 (21%)]\tLoss: 0.013332\n",
      "Train Epoch: 8 [4480/18662 (24%)]\tLoss: 0.105796\n",
      "Train Epoch: 8 [5120/18662 (27%)]\tLoss: 0.008598\n",
      "Train Epoch: 8 [5760/18662 (31%)]\tLoss: 0.015210\n",
      "Train Epoch: 8 [6400/18662 (34%)]\tLoss: 0.051482\n",
      "Train Epoch: 8 [7040/18662 (38%)]\tLoss: 0.060376\n",
      "Train Epoch: 8 [7680/18662 (41%)]\tLoss: 0.095676\n",
      "Train Epoch: 8 [8320/18662 (45%)]\tLoss: 0.127198\n",
      "Train Epoch: 8 [8960/18662 (48%)]\tLoss: 0.034259\n",
      "Train Epoch: 8 [9600/18662 (51%)]\tLoss: 0.244197\n",
      "Train Epoch: 8 [10240/18662 (55%)]\tLoss: 0.074272\n",
      "Train Epoch: 8 [10880/18662 (58%)]\tLoss: 0.054243\n",
      "Train Epoch: 8 [11520/18662 (62%)]\tLoss: 0.085195\n",
      "Train Epoch: 8 [12160/18662 (65%)]\tLoss: 0.046965\n",
      "Train Epoch: 8 [12800/18662 (68%)]\tLoss: 0.144314\n",
      "Train Epoch: 8 [13440/18662 (72%)]\tLoss: 0.261044\n",
      "Train Epoch: 8 [14080/18662 (75%)]\tLoss: 0.078692\n",
      "Train Epoch: 8 [14720/18662 (79%)]\tLoss: 0.112054\n",
      "Train Epoch: 8 [15360/18662 (82%)]\tLoss: 0.018640\n",
      "Train Epoch: 8 [16000/18662 (86%)]\tLoss: 0.008656\n",
      "Train Epoch: 8 [16640/18662 (89%)]\tLoss: 0.049949\n",
      "Train Epoch: 8 [17280/18662 (92%)]\tLoss: 0.007313\n",
      "Train Epoch: 8 [17920/18662 (96%)]\tLoss: 0.050595\n",
      "Train Epoch: 8 [18560/18662 (99%)]\tLoss: 0.052258\n",
      "Train Epoch: 9 [0/18662 (0%)]\tLoss: 0.019653\n",
      "Train Epoch: 9 [640/18662 (3%)]\tLoss: 0.034763\n",
      "Train Epoch: 9 [1280/18662 (7%)]\tLoss: 0.017156\n",
      "Train Epoch: 9 [1920/18662 (10%)]\tLoss: 0.154650\n",
      "Train Epoch: 9 [2560/18662 (14%)]\tLoss: 0.037342\n",
      "Train Epoch: 9 [3200/18662 (17%)]\tLoss: 0.033461\n",
      "Train Epoch: 9 [3840/18662 (21%)]\tLoss: 0.038488\n",
      "Train Epoch: 9 [4480/18662 (24%)]\tLoss: 0.020589\n",
      "Train Epoch: 9 [5120/18662 (27%)]\tLoss: 0.015705\n",
      "Train Epoch: 9 [5760/18662 (31%)]\tLoss: 0.026848\n",
      "Train Epoch: 9 [6400/18662 (34%)]\tLoss: 0.120713\n",
      "Train Epoch: 9 [7040/18662 (38%)]\tLoss: 0.032075\n",
      "Train Epoch: 9 [7680/18662 (41%)]\tLoss: 0.108842\n",
      "Train Epoch: 9 [8320/18662 (45%)]\tLoss: 0.006101\n",
      "Train Epoch: 9 [8960/18662 (48%)]\tLoss: 0.138417\n",
      "Train Epoch: 9 [9600/18662 (51%)]\tLoss: 0.069880\n",
      "Train Epoch: 9 [10240/18662 (55%)]\tLoss: 0.025695\n",
      "Train Epoch: 9 [10880/18662 (58%)]\tLoss: 0.016997\n",
      "Train Epoch: 9 [11520/18662 (62%)]\tLoss: 0.010749\n",
      "Train Epoch: 9 [12160/18662 (65%)]\tLoss: 0.017039\n",
      "Train Epoch: 9 [12800/18662 (68%)]\tLoss: 0.024643\n",
      "Train Epoch: 9 [13440/18662 (72%)]\tLoss: 0.090317\n",
      "Train Epoch: 9 [14080/18662 (75%)]\tLoss: 0.024352\n",
      "Train Epoch: 9 [14720/18662 (79%)]\tLoss: 0.084949\n",
      "Train Epoch: 9 [15360/18662 (82%)]\tLoss: 0.071406\n",
      "Train Epoch: 9 [16000/18662 (86%)]\tLoss: 0.016395\n",
      "Train Epoch: 9 [16640/18662 (89%)]\tLoss: 0.008612\n",
      "Train Epoch: 9 [17280/18662 (92%)]\tLoss: 0.031164\n",
      "Train Epoch: 9 [17920/18662 (96%)]\tLoss: 0.035549\n",
      "Train Epoch: 9 [18560/18662 (99%)]\tLoss: 0.036959\n",
      "Train Epoch: 10 [0/18662 (0%)]\tLoss: 0.019713\n",
      "Train Epoch: 10 [640/18662 (3%)]\tLoss: 0.033838\n",
      "Train Epoch: 10 [1280/18662 (7%)]\tLoss: 0.030711\n",
      "Train Epoch: 10 [1920/18662 (10%)]\tLoss: 0.021154\n",
      "Train Epoch: 10 [2560/18662 (14%)]\tLoss: 0.004842\n",
      "Train Epoch: 10 [3200/18662 (17%)]\tLoss: 0.021271\n",
      "Train Epoch: 10 [3840/18662 (21%)]\tLoss: 0.119461\n",
      "Train Epoch: 10 [4480/18662 (24%)]\tLoss: 0.245610\n",
      "Train Epoch: 10 [5120/18662 (27%)]\tLoss: 0.022132\n",
      "Train Epoch: 10 [5760/18662 (31%)]\tLoss: 0.036384\n",
      "Train Epoch: 10 [6400/18662 (34%)]\tLoss: 0.005797\n",
      "Train Epoch: 10 [7040/18662 (38%)]\tLoss: 0.027643\n",
      "Train Epoch: 10 [7680/18662 (41%)]\tLoss: 0.036332\n",
      "Train Epoch: 10 [8320/18662 (45%)]\tLoss: 0.009343\n",
      "Train Epoch: 10 [8960/18662 (48%)]\tLoss: 0.009124\n",
      "Train Epoch: 10 [9600/18662 (51%)]\tLoss: 0.015340\n",
      "Train Epoch: 10 [10240/18662 (55%)]\tLoss: 0.117055\n",
      "Train Epoch: 10 [10880/18662 (58%)]\tLoss: 0.030439\n",
      "Train Epoch: 10 [11520/18662 (62%)]\tLoss: 0.016982\n",
      "Train Epoch: 10 [12160/18662 (65%)]\tLoss: 0.054129\n",
      "Train Epoch: 10 [12800/18662 (68%)]\tLoss: 0.029759\n",
      "Train Epoch: 10 [13440/18662 (72%)]\tLoss: 0.034288\n",
      "Train Epoch: 10 [14080/18662 (75%)]\tLoss: 0.037703\n",
      "Train Epoch: 10 [14720/18662 (79%)]\tLoss: 0.054024\n",
      "Train Epoch: 10 [15360/18662 (82%)]\tLoss: 0.049438\n",
      "Train Epoch: 10 [16000/18662 (86%)]\tLoss: 0.005971\n",
      "Train Epoch: 10 [16640/18662 (89%)]\tLoss: 0.023760\n",
      "Train Epoch: 10 [17280/18662 (92%)]\tLoss: 0.108820\n",
      "Train Epoch: 10 [17920/18662 (96%)]\tLoss: 0.052685\n",
      "Train Epoch: 10 [18560/18662 (99%)]\tLoss: 0.063071\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/10619 (0%)]\tLoss: 0.172242\n",
      "Train Epoch: 1 [640/10619 (6%)]\tLoss: 0.393495\n",
      "Train Epoch: 1 [1280/10619 (12%)]\tLoss: 0.080842\n",
      "Train Epoch: 1 [1920/10619 (18%)]\tLoss: 0.207434\n",
      "Train Epoch: 1 [2560/10619 (24%)]\tLoss: 0.065842\n",
      "Train Epoch: 1 [3200/10619 (30%)]\tLoss: 0.058925\n",
      "Train Epoch: 1 [3840/10619 (36%)]\tLoss: 0.127883\n",
      "Train Epoch: 1 [4480/10619 (42%)]\tLoss: 0.112516\n",
      "Train Epoch: 1 [5120/10619 (48%)]\tLoss: 0.100851\n",
      "Train Epoch: 1 [5760/10619 (54%)]\tLoss: 0.094048\n",
      "Train Epoch: 1 [6400/10619 (60%)]\tLoss: 0.107841\n",
      "Train Epoch: 1 [7040/10619 (66%)]\tLoss: 0.020798\n",
      "Train Epoch: 1 [7680/10619 (72%)]\tLoss: 0.099132\n",
      "Train Epoch: 1 [8320/10619 (78%)]\tLoss: 0.109388\n",
      "Train Epoch: 1 [8960/10619 (84%)]\tLoss: 0.041272\n",
      "Train Epoch: 1 [9600/10619 (90%)]\tLoss: 0.179449\n",
      "Train Epoch: 1 [10240/10619 (96%)]\tLoss: 0.078333\n",
      "Train Epoch: 2 [0/10619 (0%)]\tLoss: 0.068291\n",
      "Train Epoch: 2 [640/10619 (6%)]\tLoss: 0.039655\n",
      "Train Epoch: 2 [1280/10619 (12%)]\tLoss: 0.115140\n",
      "Train Epoch: 2 [1920/10619 (18%)]\tLoss: 0.017184\n",
      "Train Epoch: 2 [2560/10619 (24%)]\tLoss: 0.186079\n",
      "Train Epoch: 2 [3200/10619 (30%)]\tLoss: 0.069317\n",
      "Train Epoch: 2 [3840/10619 (36%)]\tLoss: 0.128123\n",
      "Train Epoch: 2 [4480/10619 (42%)]\tLoss: 0.042084\n",
      "Train Epoch: 2 [5120/10619 (48%)]\tLoss: 0.114083\n",
      "Train Epoch: 2 [5760/10619 (54%)]\tLoss: 0.048610\n",
      "Train Epoch: 2 [6400/10619 (60%)]\tLoss: 0.016876\n",
      "Train Epoch: 2 [7040/10619 (66%)]\tLoss: 0.066830\n",
      "Train Epoch: 2 [7680/10619 (72%)]\tLoss: 0.092804\n",
      "Train Epoch: 2 [8320/10619 (78%)]\tLoss: 0.096115\n",
      "Train Epoch: 2 [8960/10619 (84%)]\tLoss: 0.169052\n",
      "Train Epoch: 2 [9600/10619 (90%)]\tLoss: 0.052004\n",
      "Train Epoch: 2 [10240/10619 (96%)]\tLoss: 0.046571\n",
      "Train Epoch: 3 [0/10619 (0%)]\tLoss: 0.013039\n",
      "Train Epoch: 3 [640/10619 (6%)]\tLoss: 0.079138\n",
      "Train Epoch: 3 [1280/10619 (12%)]\tLoss: 0.040857\n",
      "Train Epoch: 3 [1920/10619 (18%)]\tLoss: 0.105523\n",
      "Train Epoch: 3 [2560/10619 (24%)]\tLoss: 0.158996\n",
      "Train Epoch: 3 [3200/10619 (30%)]\tLoss: 0.022856\n",
      "Train Epoch: 3 [3840/10619 (36%)]\tLoss: 0.114446\n",
      "Train Epoch: 3 [4480/10619 (42%)]\tLoss: 0.038218\n",
      "Train Epoch: 3 [5120/10619 (48%)]\tLoss: 0.053523\n",
      "Train Epoch: 3 [5760/10619 (54%)]\tLoss: 0.018698\n",
      "Train Epoch: 3 [6400/10619 (60%)]\tLoss: 0.125815\n",
      "Train Epoch: 3 [7040/10619 (66%)]\tLoss: 0.076195\n",
      "Train Epoch: 3 [7680/10619 (72%)]\tLoss: 0.081478\n",
      "Train Epoch: 3 [8320/10619 (78%)]\tLoss: 0.140718\n",
      "Train Epoch: 3 [8960/10619 (84%)]\tLoss: 0.072284\n",
      "Train Epoch: 3 [9600/10619 (90%)]\tLoss: 0.076449\n",
      "Train Epoch: 3 [10240/10619 (96%)]\tLoss: 0.212703\n",
      "Train Epoch: 4 [0/10619 (0%)]\tLoss: 0.085544\n",
      "Train Epoch: 4 [640/10619 (6%)]\tLoss: 0.062728\n",
      "Train Epoch: 4 [1280/10619 (12%)]\tLoss: 0.094642\n",
      "Train Epoch: 4 [1920/10619 (18%)]\tLoss: 0.091770\n",
      "Train Epoch: 4 [2560/10619 (24%)]\tLoss: 0.021393\n",
      "Train Epoch: 4 [3200/10619 (30%)]\tLoss: 0.151115\n",
      "Train Epoch: 4 [3840/10619 (36%)]\tLoss: 0.155378\n",
      "Train Epoch: 4 [4480/10619 (42%)]\tLoss: 0.046873\n",
      "Train Epoch: 4 [5120/10619 (48%)]\tLoss: 0.090202\n",
      "Train Epoch: 4 [5760/10619 (54%)]\tLoss: 0.025643\n",
      "Train Epoch: 4 [6400/10619 (60%)]\tLoss: 0.042440\n",
      "Train Epoch: 4 [7040/10619 (66%)]\tLoss: 0.100763\n",
      "Train Epoch: 4 [7680/10619 (72%)]\tLoss: 0.266764\n",
      "Train Epoch: 4 [8320/10619 (78%)]\tLoss: 0.014475\n",
      "Train Epoch: 4 [8960/10619 (84%)]\tLoss: 0.032769\n",
      "Train Epoch: 4 [9600/10619 (90%)]\tLoss: 0.150273\n",
      "Train Epoch: 4 [10240/10619 (96%)]\tLoss: 0.024900\n",
      "Train Epoch: 5 [0/10619 (0%)]\tLoss: 0.222970\n",
      "Train Epoch: 5 [640/10619 (6%)]\tLoss: 0.045880\n",
      "Train Epoch: 5 [1280/10619 (12%)]\tLoss: 0.033727\n",
      "Train Epoch: 5 [1920/10619 (18%)]\tLoss: 0.067758\n",
      "Train Epoch: 5 [2560/10619 (24%)]\tLoss: 0.034033\n",
      "Train Epoch: 5 [3200/10619 (30%)]\tLoss: 0.086646\n",
      "Train Epoch: 5 [3840/10619 (36%)]\tLoss: 0.038568\n",
      "Train Epoch: 5 [4480/10619 (42%)]\tLoss: 0.055656\n",
      "Train Epoch: 5 [5120/10619 (48%)]\tLoss: 0.173186\n",
      "Train Epoch: 5 [5760/10619 (54%)]\tLoss: 0.081829\n",
      "Train Epoch: 5 [6400/10619 (60%)]\tLoss: 0.099357\n",
      "Train Epoch: 5 [7040/10619 (66%)]\tLoss: 0.034449\n",
      "Train Epoch: 5 [7680/10619 (72%)]\tLoss: 0.041514\n",
      "Train Epoch: 5 [8320/10619 (78%)]\tLoss: 0.100921\n",
      "Train Epoch: 5 [8960/10619 (84%)]\tLoss: 0.028933\n",
      "Train Epoch: 5 [9600/10619 (90%)]\tLoss: 0.015177\n",
      "Train Epoch: 5 [10240/10619 (96%)]\tLoss: 0.167319\n",
      "Train Epoch: 6 [0/10619 (0%)]\tLoss: 0.075122\n",
      "Train Epoch: 6 [640/10619 (6%)]\tLoss: 0.047428\n",
      "Train Epoch: 6 [1280/10619 (12%)]\tLoss: 0.035721\n",
      "Train Epoch: 6 [1920/10619 (18%)]\tLoss: 0.082010\n",
      "Train Epoch: 6 [2560/10619 (24%)]\tLoss: 0.045498\n",
      "Train Epoch: 6 [3200/10619 (30%)]\tLoss: 0.096987\n",
      "Train Epoch: 6 [3840/10619 (36%)]\tLoss: 0.101215\n",
      "Train Epoch: 6 [4480/10619 (42%)]\tLoss: 0.026472\n",
      "Train Epoch: 6 [5120/10619 (48%)]\tLoss: 0.063090\n",
      "Train Epoch: 6 [5760/10619 (54%)]\tLoss: 0.026866\n",
      "Train Epoch: 6 [6400/10619 (60%)]\tLoss: 0.032926\n",
      "Train Epoch: 6 [7040/10619 (66%)]\tLoss: 0.104163\n",
      "Train Epoch: 6 [7680/10619 (72%)]\tLoss: 0.108437\n",
      "Train Epoch: 6 [8320/10619 (78%)]\tLoss: 0.047573\n",
      "Train Epoch: 6 [8960/10619 (84%)]\tLoss: 0.186495\n",
      "Train Epoch: 6 [9600/10619 (90%)]\tLoss: 0.063469\n",
      "Train Epoch: 6 [10240/10619 (96%)]\tLoss: 0.021093\n",
      "Train Epoch: 7 [0/10619 (0%)]\tLoss: 0.068082\n",
      "Train Epoch: 7 [640/10619 (6%)]\tLoss: 0.080535\n",
      "Train Epoch: 7 [1280/10619 (12%)]\tLoss: 0.175808\n",
      "Train Epoch: 7 [1920/10619 (18%)]\tLoss: 0.099659\n",
      "Train Epoch: 7 [2560/10619 (24%)]\tLoss: 0.021692\n",
      "Train Epoch: 7 [3200/10619 (30%)]\tLoss: 0.093943\n",
      "Train Epoch: 7 [3840/10619 (36%)]\tLoss: 0.229210\n",
      "Train Epoch: 7 [4480/10619 (42%)]\tLoss: 0.013411\n",
      "Train Epoch: 7 [5120/10619 (48%)]\tLoss: 0.189626\n",
      "Train Epoch: 7 [5760/10619 (54%)]\tLoss: 0.027345\n",
      "Train Epoch: 7 [6400/10619 (60%)]\tLoss: 0.072738\n",
      "Train Epoch: 7 [7040/10619 (66%)]\tLoss: 0.053820\n",
      "Train Epoch: 7 [7680/10619 (72%)]\tLoss: 0.086199\n",
      "Train Epoch: 7 [8320/10619 (78%)]\tLoss: 0.062984\n",
      "Train Epoch: 7 [8960/10619 (84%)]\tLoss: 0.060682\n",
      "Train Epoch: 7 [9600/10619 (90%)]\tLoss: 0.155832\n",
      "Train Epoch: 7 [10240/10619 (96%)]\tLoss: 0.190964\n",
      "Train Epoch: 8 [0/10619 (0%)]\tLoss: 0.119082\n",
      "Train Epoch: 8 [640/10619 (6%)]\tLoss: 0.036320\n",
      "Train Epoch: 8 [1280/10619 (12%)]\tLoss: 0.121089\n",
      "Train Epoch: 8 [1920/10619 (18%)]\tLoss: 0.038168\n",
      "Train Epoch: 8 [2560/10619 (24%)]\tLoss: 0.229318\n",
      "Train Epoch: 8 [3200/10619 (30%)]\tLoss: 0.060120\n",
      "Train Epoch: 8 [3840/10619 (36%)]\tLoss: 0.153153\n",
      "Train Epoch: 8 [4480/10619 (42%)]\tLoss: 0.054542\n",
      "Train Epoch: 8 [5120/10619 (48%)]\tLoss: 0.079173\n",
      "Train Epoch: 8 [5760/10619 (54%)]\tLoss: 0.116041\n",
      "Train Epoch: 8 [6400/10619 (60%)]\tLoss: 0.024008\n",
      "Train Epoch: 8 [7040/10619 (66%)]\tLoss: 0.074137\n",
      "Train Epoch: 8 [7680/10619 (72%)]\tLoss: 0.135243\n",
      "Train Epoch: 8 [8320/10619 (78%)]\tLoss: 0.080830\n",
      "Train Epoch: 8 [8960/10619 (84%)]\tLoss: 0.025121\n",
      "Train Epoch: 8 [9600/10619 (90%)]\tLoss: 0.040893\n",
      "Train Epoch: 8 [10240/10619 (96%)]\tLoss: 0.070216\n",
      "Train Epoch: 9 [0/10619 (0%)]\tLoss: 0.006935\n",
      "Train Epoch: 9 [640/10619 (6%)]\tLoss: 0.025098\n",
      "Train Epoch: 9 [1280/10619 (12%)]\tLoss: 0.073039\n",
      "Train Epoch: 9 [1920/10619 (18%)]\tLoss: 0.027252\n",
      "Train Epoch: 9 [2560/10619 (24%)]\tLoss: 0.025270\n",
      "Train Epoch: 9 [3200/10619 (30%)]\tLoss: 0.078846\n",
      "Train Epoch: 9 [3840/10619 (36%)]\tLoss: 0.059809\n",
      "Train Epoch: 9 [4480/10619 (42%)]\tLoss: 0.069302\n",
      "Train Epoch: 9 [5120/10619 (48%)]\tLoss: 0.016472\n",
      "Train Epoch: 9 [5760/10619 (54%)]\tLoss: 0.102504\n",
      "Train Epoch: 9 [6400/10619 (60%)]\tLoss: 0.149512\n",
      "Train Epoch: 9 [7040/10619 (66%)]\tLoss: 0.193568\n",
      "Train Epoch: 9 [7680/10619 (72%)]\tLoss: 0.089848\n",
      "Train Epoch: 9 [8320/10619 (78%)]\tLoss: 0.058634\n",
      "Train Epoch: 9 [8960/10619 (84%)]\tLoss: 0.023070\n",
      "Train Epoch: 9 [9600/10619 (90%)]\tLoss: 0.004232\n",
      "Train Epoch: 9 [10240/10619 (96%)]\tLoss: 0.115652\n",
      "Train Epoch: 10 [0/10619 (0%)]\tLoss: 0.039956\n",
      "Train Epoch: 10 [640/10619 (6%)]\tLoss: 0.020637\n",
      "Train Epoch: 10 [1280/10619 (12%)]\tLoss: 0.055309\n",
      "Train Epoch: 10 [1920/10619 (18%)]\tLoss: 0.057495\n",
      "Train Epoch: 10 [2560/10619 (24%)]\tLoss: 0.056788\n",
      "Train Epoch: 10 [3200/10619 (30%)]\tLoss: 0.025850\n",
      "Train Epoch: 10 [3840/10619 (36%)]\tLoss: 0.021336\n",
      "Train Epoch: 10 [4480/10619 (42%)]\tLoss: 0.101469\n",
      "Train Epoch: 10 [5120/10619 (48%)]\tLoss: 0.089201\n",
      "Train Epoch: 10 [5760/10619 (54%)]\tLoss: 0.054877\n",
      "Train Epoch: 10 [6400/10619 (60%)]\tLoss: 0.116669\n",
      "Train Epoch: 10 [7040/10619 (66%)]\tLoss: 0.024834\n",
      "Train Epoch: 10 [7680/10619 (72%)]\tLoss: 0.072893\n",
      "Train Epoch: 10 [8320/10619 (78%)]\tLoss: 0.165974\n",
      "Train Epoch: 10 [8960/10619 (84%)]\tLoss: 0.059857\n",
      "Train Epoch: 10 [9600/10619 (90%)]\tLoss: 0.039834\n",
      "Train Epoch: 10 [10240/10619 (96%)]\tLoss: 0.054746\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/15392 (0%)]\tLoss: 0.065894\n",
      "Train Epoch: 1 [640/15392 (4%)]\tLoss: 0.112899\n",
      "Train Epoch: 1 [1280/15392 (8%)]\tLoss: 0.052692\n",
      "Train Epoch: 1 [1920/15392 (12%)]\tLoss: 0.055957\n",
      "Train Epoch: 1 [2560/15392 (17%)]\tLoss: 0.082603\n",
      "Train Epoch: 1 [3200/15392 (21%)]\tLoss: 0.034032\n",
      "Train Epoch: 1 [3840/15392 (25%)]\tLoss: 0.051956\n",
      "Train Epoch: 1 [4480/15392 (29%)]\tLoss: 0.034411\n",
      "Train Epoch: 1 [5120/15392 (33%)]\tLoss: 0.017587\n",
      "Train Epoch: 1 [5760/15392 (37%)]\tLoss: 0.037048\n",
      "Train Epoch: 1 [6400/15392 (41%)]\tLoss: 0.029233\n",
      "Train Epoch: 1 [7040/15392 (46%)]\tLoss: 0.099384\n",
      "Train Epoch: 1 [7680/15392 (50%)]\tLoss: 0.065168\n",
      "Train Epoch: 1 [8320/15392 (54%)]\tLoss: 0.192657\n",
      "Train Epoch: 1 [8960/15392 (58%)]\tLoss: 0.039913\n",
      "Train Epoch: 1 [9600/15392 (62%)]\tLoss: 0.002652\n",
      "Train Epoch: 1 [10240/15392 (66%)]\tLoss: 0.055874\n",
      "Train Epoch: 1 [10880/15392 (71%)]\tLoss: 0.036301\n",
      "Train Epoch: 1 [11520/15392 (75%)]\tLoss: 0.169250\n",
      "Train Epoch: 1 [12160/15392 (79%)]\tLoss: 0.093038\n",
      "Train Epoch: 1 [12800/15392 (83%)]\tLoss: 0.177648\n",
      "Train Epoch: 1 [13440/15392 (87%)]\tLoss: 0.019685\n",
      "Train Epoch: 1 [14080/15392 (91%)]\tLoss: 0.081332\n",
      "Train Epoch: 1 [14720/15392 (95%)]\tLoss: 0.035923\n",
      "Train Epoch: 1 [7680/15392 (100%)]\tLoss: 0.012274\n",
      "Train Epoch: 2 [0/15392 (0%)]\tLoss: 0.206045\n",
      "Train Epoch: 2 [640/15392 (4%)]\tLoss: 0.043675\n",
      "Train Epoch: 2 [1280/15392 (8%)]\tLoss: 0.028929\n",
      "Train Epoch: 2 [1920/15392 (12%)]\tLoss: 0.186360\n",
      "Train Epoch: 2 [2560/15392 (17%)]\tLoss: 0.011920\n",
      "Train Epoch: 2 [3200/15392 (21%)]\tLoss: 0.060388\n",
      "Train Epoch: 2 [3840/15392 (25%)]\tLoss: 0.041084\n",
      "Train Epoch: 2 [4480/15392 (29%)]\tLoss: 0.107375\n",
      "Train Epoch: 2 [5120/15392 (33%)]\tLoss: 0.014808\n",
      "Train Epoch: 2 [5760/15392 (37%)]\tLoss: 0.107389\n",
      "Train Epoch: 2 [6400/15392 (41%)]\tLoss: 0.032411\n",
      "Train Epoch: 2 [7040/15392 (46%)]\tLoss: 0.106940\n",
      "Train Epoch: 2 [7680/15392 (50%)]\tLoss: 0.223906\n",
      "Train Epoch: 2 [8320/15392 (54%)]\tLoss: 0.116155\n",
      "Train Epoch: 2 [8960/15392 (58%)]\tLoss: 0.053305\n",
      "Train Epoch: 2 [9600/15392 (62%)]\tLoss: 0.044896\n",
      "Train Epoch: 2 [10240/15392 (66%)]\tLoss: 0.135005\n",
      "Train Epoch: 2 [10880/15392 (71%)]\tLoss: 0.023243\n",
      "Train Epoch: 2 [11520/15392 (75%)]\tLoss: 0.060159\n",
      "Train Epoch: 2 [12160/15392 (79%)]\tLoss: 0.026807\n",
      "Train Epoch: 2 [12800/15392 (83%)]\tLoss: 0.035824\n",
      "Train Epoch: 2 [13440/15392 (87%)]\tLoss: 0.116568\n",
      "Train Epoch: 2 [14080/15392 (91%)]\tLoss: 0.097392\n",
      "Train Epoch: 2 [14720/15392 (95%)]\tLoss: 0.101457\n",
      "Train Epoch: 2 [7680/15392 (100%)]\tLoss: 0.131679\n",
      "Train Epoch: 3 [0/15392 (0%)]\tLoss: 0.014587\n",
      "Train Epoch: 3 [640/15392 (4%)]\tLoss: 0.023289\n",
      "Train Epoch: 3 [1280/15392 (8%)]\tLoss: 0.071058\n",
      "Train Epoch: 3 [1920/15392 (12%)]\tLoss: 0.011387\n",
      "Train Epoch: 3 [2560/15392 (17%)]\tLoss: 0.012391\n",
      "Train Epoch: 3 [3200/15392 (21%)]\tLoss: 0.073636\n",
      "Train Epoch: 3 [3840/15392 (25%)]\tLoss: 0.116913\n",
      "Train Epoch: 3 [4480/15392 (29%)]\tLoss: 0.050948\n",
      "Train Epoch: 3 [5120/15392 (33%)]\tLoss: 0.040708\n",
      "Train Epoch: 3 [5760/15392 (37%)]\tLoss: 0.023976\n",
      "Train Epoch: 3 [6400/15392 (41%)]\tLoss: 0.039523\n",
      "Train Epoch: 3 [7040/15392 (46%)]\tLoss: 0.072837\n",
      "Train Epoch: 3 [7680/15392 (50%)]\tLoss: 0.032002\n",
      "Train Epoch: 3 [8320/15392 (54%)]\tLoss: 0.112190\n",
      "Train Epoch: 3 [8960/15392 (58%)]\tLoss: 0.011284\n",
      "Train Epoch: 3 [9600/15392 (62%)]\tLoss: 0.037923\n",
      "Train Epoch: 3 [10240/15392 (66%)]\tLoss: 0.023249\n",
      "Train Epoch: 3 [10880/15392 (71%)]\tLoss: 0.034267\n",
      "Train Epoch: 3 [11520/15392 (75%)]\tLoss: 0.078468\n",
      "Train Epoch: 3 [12160/15392 (79%)]\tLoss: 0.046757\n",
      "Train Epoch: 3 [12800/15392 (83%)]\tLoss: 0.049516\n",
      "Train Epoch: 3 [13440/15392 (87%)]\tLoss: 0.051775\n",
      "Train Epoch: 3 [14080/15392 (91%)]\tLoss: 0.068181\n",
      "Train Epoch: 3 [14720/15392 (95%)]\tLoss: 0.020795\n",
      "Train Epoch: 3 [7680/15392 (100%)]\tLoss: 0.274011\n",
      "Train Epoch: 4 [0/15392 (0%)]\tLoss: 0.017342\n",
      "Train Epoch: 4 [640/15392 (4%)]\tLoss: 0.048155\n",
      "Train Epoch: 4 [1280/15392 (8%)]\tLoss: 0.050641\n",
      "Train Epoch: 4 [1920/15392 (12%)]\tLoss: 0.018577\n",
      "Train Epoch: 4 [2560/15392 (17%)]\tLoss: 0.023466\n",
      "Train Epoch: 4 [3200/15392 (21%)]\tLoss: 0.040217\n",
      "Train Epoch: 4 [3840/15392 (25%)]\tLoss: 0.023045\n",
      "Train Epoch: 4 [4480/15392 (29%)]\tLoss: 0.024646\n",
      "Train Epoch: 4 [5120/15392 (33%)]\tLoss: 0.014555\n",
      "Train Epoch: 4 [5760/15392 (37%)]\tLoss: 0.102442\n",
      "Train Epoch: 4 [6400/15392 (41%)]\tLoss: 0.041225\n",
      "Train Epoch: 4 [7040/15392 (46%)]\tLoss: 0.031190\n",
      "Train Epoch: 4 [7680/15392 (50%)]\tLoss: 0.007058\n",
      "Train Epoch: 4 [8320/15392 (54%)]\tLoss: 0.022841\n",
      "Train Epoch: 4 [8960/15392 (58%)]\tLoss: 0.035105\n",
      "Train Epoch: 4 [9600/15392 (62%)]\tLoss: 0.049437\n",
      "Train Epoch: 4 [10240/15392 (66%)]\tLoss: 0.047660\n",
      "Train Epoch: 4 [10880/15392 (71%)]\tLoss: 0.033974\n",
      "Train Epoch: 4 [11520/15392 (75%)]\tLoss: 0.039094\n",
      "Train Epoch: 4 [12160/15392 (79%)]\tLoss: 0.015946\n",
      "Train Epoch: 4 [12800/15392 (83%)]\tLoss: 0.083277\n",
      "Train Epoch: 4 [13440/15392 (87%)]\tLoss: 0.032039\n",
      "Train Epoch: 4 [14080/15392 (91%)]\tLoss: 0.125794\n",
      "Train Epoch: 4 [14720/15392 (95%)]\tLoss: 0.024969\n",
      "Train Epoch: 4 [7680/15392 (100%)]\tLoss: 0.040080\n",
      "Train Epoch: 5 [0/15392 (0%)]\tLoss: 0.045224\n",
      "Train Epoch: 5 [640/15392 (4%)]\tLoss: 0.277111\n",
      "Train Epoch: 5 [1280/15392 (8%)]\tLoss: 0.089767\n",
      "Train Epoch: 5 [1920/15392 (12%)]\tLoss: 0.022201\n",
      "Train Epoch: 5 [2560/15392 (17%)]\tLoss: 0.136347\n",
      "Train Epoch: 5 [3200/15392 (21%)]\tLoss: 0.089655\n",
      "Train Epoch: 5 [3840/15392 (25%)]\tLoss: 0.032966\n",
      "Train Epoch: 5 [4480/15392 (29%)]\tLoss: 0.006678\n",
      "Train Epoch: 5 [5120/15392 (33%)]\tLoss: 0.083710\n",
      "Train Epoch: 5 [5760/15392 (37%)]\tLoss: 0.044954\n",
      "Train Epoch: 5 [6400/15392 (41%)]\tLoss: 0.025539\n",
      "Train Epoch: 5 [7040/15392 (46%)]\tLoss: 0.118833\n",
      "Train Epoch: 5 [7680/15392 (50%)]\tLoss: 0.031236\n",
      "Train Epoch: 5 [8320/15392 (54%)]\tLoss: 0.048834\n",
      "Train Epoch: 5 [8960/15392 (58%)]\tLoss: 0.045630\n",
      "Train Epoch: 5 [9600/15392 (62%)]\tLoss: 0.009384\n",
      "Train Epoch: 5 [10240/15392 (66%)]\tLoss: 0.004111\n",
      "Train Epoch: 5 [10880/15392 (71%)]\tLoss: 0.028835\n",
      "Train Epoch: 5 [11520/15392 (75%)]\tLoss: 0.015489\n",
      "Train Epoch: 5 [12160/15392 (79%)]\tLoss: 0.093730\n",
      "Train Epoch: 5 [12800/15392 (83%)]\tLoss: 0.025715\n",
      "Train Epoch: 5 [13440/15392 (87%)]\tLoss: 0.055870\n",
      "Train Epoch: 5 [14080/15392 (91%)]\tLoss: 0.038592\n",
      "Train Epoch: 5 [14720/15392 (95%)]\tLoss: 0.068873\n",
      "Train Epoch: 5 [7680/15392 (100%)]\tLoss: 0.030506\n",
      "Train Epoch: 6 [0/15392 (0%)]\tLoss: 0.015828\n",
      "Train Epoch: 6 [640/15392 (4%)]\tLoss: 0.033317\n",
      "Train Epoch: 6 [1280/15392 (8%)]\tLoss: 0.106771\n",
      "Train Epoch: 6 [1920/15392 (12%)]\tLoss: 0.103032\n",
      "Train Epoch: 6 [2560/15392 (17%)]\tLoss: 0.134650\n",
      "Train Epoch: 6 [3200/15392 (21%)]\tLoss: 0.029218\n",
      "Train Epoch: 6 [3840/15392 (25%)]\tLoss: 0.066911\n",
      "Train Epoch: 6 [4480/15392 (29%)]\tLoss: 0.104435\n",
      "Train Epoch: 6 [5120/15392 (33%)]\tLoss: 0.079729\n",
      "Train Epoch: 6 [5760/15392 (37%)]\tLoss: 0.040297\n",
      "Train Epoch: 6 [6400/15392 (41%)]\tLoss: 0.020034\n",
      "Train Epoch: 6 [7040/15392 (46%)]\tLoss: 0.052997\n",
      "Train Epoch: 6 [7680/15392 (50%)]\tLoss: 0.042091\n",
      "Train Epoch: 6 [8320/15392 (54%)]\tLoss: 0.080425\n",
      "Train Epoch: 6 [8960/15392 (58%)]\tLoss: 0.038632\n",
      "Train Epoch: 6 [9600/15392 (62%)]\tLoss: 0.076643\n",
      "Train Epoch: 6 [10240/15392 (66%)]\tLoss: 0.027897\n",
      "Train Epoch: 6 [10880/15392 (71%)]\tLoss: 0.054887\n",
      "Train Epoch: 6 [11520/15392 (75%)]\tLoss: 0.008009\n",
      "Train Epoch: 6 [12160/15392 (79%)]\tLoss: 0.029671\n",
      "Train Epoch: 6 [12800/15392 (83%)]\tLoss: 0.006712\n",
      "Train Epoch: 6 [13440/15392 (87%)]\tLoss: 0.054780\n",
      "Train Epoch: 6 [14080/15392 (91%)]\tLoss: 0.069183\n",
      "Train Epoch: 6 [14720/15392 (95%)]\tLoss: 0.019604\n",
      "Train Epoch: 6 [7680/15392 (100%)]\tLoss: 0.094788\n",
      "Train Epoch: 7 [0/15392 (0%)]\tLoss: 0.262189\n",
      "Train Epoch: 7 [640/15392 (4%)]\tLoss: 0.007482\n",
      "Train Epoch: 7 [1280/15392 (8%)]\tLoss: 0.147624\n",
      "Train Epoch: 7 [1920/15392 (12%)]\tLoss: 0.085908\n",
      "Train Epoch: 7 [2560/15392 (17%)]\tLoss: 0.119673\n",
      "Train Epoch: 7 [3200/15392 (21%)]\tLoss: 0.030206\n",
      "Train Epoch: 7 [3840/15392 (25%)]\tLoss: 0.054257\n",
      "Train Epoch: 7 [4480/15392 (29%)]\tLoss: 0.043439\n",
      "Train Epoch: 7 [5120/15392 (33%)]\tLoss: 0.107962\n",
      "Train Epoch: 7 [5760/15392 (37%)]\tLoss: 0.015719\n",
      "Train Epoch: 7 [6400/15392 (41%)]\tLoss: 0.045682\n",
      "Train Epoch: 7 [7040/15392 (46%)]\tLoss: 0.008849\n",
      "Train Epoch: 7 [7680/15392 (50%)]\tLoss: 0.010507\n",
      "Train Epoch: 7 [8320/15392 (54%)]\tLoss: 0.153963\n",
      "Train Epoch: 7 [8960/15392 (58%)]\tLoss: 0.014319\n",
      "Train Epoch: 7 [9600/15392 (62%)]\tLoss: 0.139919\n",
      "Train Epoch: 7 [10240/15392 (66%)]\tLoss: 0.065348\n",
      "Train Epoch: 7 [10880/15392 (71%)]\tLoss: 0.038583\n",
      "Train Epoch: 7 [11520/15392 (75%)]\tLoss: 0.037230\n",
      "Train Epoch: 7 [12160/15392 (79%)]\tLoss: 0.026681\n",
      "Train Epoch: 7 [12800/15392 (83%)]\tLoss: 0.026324\n",
      "Train Epoch: 7 [13440/15392 (87%)]\tLoss: 0.013352\n",
      "Train Epoch: 7 [14080/15392 (91%)]\tLoss: 0.123768\n",
      "Train Epoch: 7 [14720/15392 (95%)]\tLoss: 0.094513\n",
      "Train Epoch: 7 [7680/15392 (100%)]\tLoss: 0.034303\n",
      "Train Epoch: 8 [0/15392 (0%)]\tLoss: 0.018726\n",
      "Train Epoch: 8 [640/15392 (4%)]\tLoss: 0.123370\n",
      "Train Epoch: 8 [1280/15392 (8%)]\tLoss: 0.092004\n",
      "Train Epoch: 8 [1920/15392 (12%)]\tLoss: 0.102356\n",
      "Train Epoch: 8 [2560/15392 (17%)]\tLoss: 0.058827\n",
      "Train Epoch: 8 [3200/15392 (21%)]\tLoss: 0.037010\n",
      "Train Epoch: 8 [3840/15392 (25%)]\tLoss: 0.037574\n",
      "Train Epoch: 8 [4480/15392 (29%)]\tLoss: 0.037714\n",
      "Train Epoch: 8 [5120/15392 (33%)]\tLoss: 0.008915\n",
      "Train Epoch: 8 [5760/15392 (37%)]\tLoss: 0.064179\n",
      "Train Epoch: 8 [6400/15392 (41%)]\tLoss: 0.047899\n",
      "Train Epoch: 8 [7040/15392 (46%)]\tLoss: 0.039744\n",
      "Train Epoch: 8 [7680/15392 (50%)]\tLoss: 0.092486\n",
      "Train Epoch: 8 [8320/15392 (54%)]\tLoss: 0.019208\n",
      "Train Epoch: 8 [8960/15392 (58%)]\tLoss: 0.004407\n",
      "Train Epoch: 8 [9600/15392 (62%)]\tLoss: 0.009968\n",
      "Train Epoch: 8 [10240/15392 (66%)]\tLoss: 0.019133\n",
      "Train Epoch: 8 [10880/15392 (71%)]\tLoss: 0.071220\n",
      "Train Epoch: 8 [11520/15392 (75%)]\tLoss: 0.067490\n",
      "Train Epoch: 8 [12160/15392 (79%)]\tLoss: 0.023127\n",
      "Train Epoch: 8 [12800/15392 (83%)]\tLoss: 0.080053\n",
      "Train Epoch: 8 [13440/15392 (87%)]\tLoss: 0.008263\n",
      "Train Epoch: 8 [14080/15392 (91%)]\tLoss: 0.117938\n",
      "Train Epoch: 8 [14720/15392 (95%)]\tLoss: 0.009967\n",
      "Train Epoch: 8 [7680/15392 (100%)]\tLoss: 0.186229\n",
      "Train Epoch: 9 [0/15392 (0%)]\tLoss: 0.048339\n",
      "Train Epoch: 9 [640/15392 (4%)]\tLoss: 0.046774\n",
      "Train Epoch: 9 [1280/15392 (8%)]\tLoss: 0.049508\n",
      "Train Epoch: 9 [1920/15392 (12%)]\tLoss: 0.266195\n",
      "Train Epoch: 9 [2560/15392 (17%)]\tLoss: 0.014944\n",
      "Train Epoch: 9 [3200/15392 (21%)]\tLoss: 0.131871\n",
      "Train Epoch: 9 [3840/15392 (25%)]\tLoss: 0.068905\n",
      "Train Epoch: 9 [4480/15392 (29%)]\tLoss: 0.082337\n",
      "Train Epoch: 9 [5120/15392 (33%)]\tLoss: 0.010203\n",
      "Train Epoch: 9 [5760/15392 (37%)]\tLoss: 0.066093\n",
      "Train Epoch: 9 [6400/15392 (41%)]\tLoss: 0.019584\n",
      "Train Epoch: 9 [7040/15392 (46%)]\tLoss: 0.042517\n",
      "Train Epoch: 9 [7680/15392 (50%)]\tLoss: 0.050703\n",
      "Train Epoch: 9 [8320/15392 (54%)]\tLoss: 0.007367\n",
      "Train Epoch: 9 [8960/15392 (58%)]\tLoss: 0.026427\n",
      "Train Epoch: 9 [9600/15392 (62%)]\tLoss: 0.074317\n",
      "Train Epoch: 9 [10240/15392 (66%)]\tLoss: 0.063761\n",
      "Train Epoch: 9 [10880/15392 (71%)]\tLoss: 0.046913\n",
      "Train Epoch: 9 [11520/15392 (75%)]\tLoss: 0.104002\n",
      "Train Epoch: 9 [12160/15392 (79%)]\tLoss: 0.088606\n",
      "Train Epoch: 9 [12800/15392 (83%)]\tLoss: 0.031265\n",
      "Train Epoch: 9 [13440/15392 (87%)]\tLoss: 0.097824\n",
      "Train Epoch: 9 [14080/15392 (91%)]\tLoss: 0.047838\n",
      "Train Epoch: 9 [14720/15392 (95%)]\tLoss: 0.028307\n",
      "Train Epoch: 9 [7680/15392 (100%)]\tLoss: 0.057145\n",
      "Train Epoch: 10 [0/15392 (0%)]\tLoss: 0.072869\n",
      "Train Epoch: 10 [640/15392 (4%)]\tLoss: 0.014033\n",
      "Train Epoch: 10 [1280/15392 (8%)]\tLoss: 0.013186\n",
      "Train Epoch: 10 [1920/15392 (12%)]\tLoss: 0.049154\n",
      "Train Epoch: 10 [2560/15392 (17%)]\tLoss: 0.014699\n",
      "Train Epoch: 10 [3200/15392 (21%)]\tLoss: 0.044168\n",
      "Train Epoch: 10 [3840/15392 (25%)]\tLoss: 0.133724\n",
      "Train Epoch: 10 [4480/15392 (29%)]\tLoss: 0.066814\n",
      "Train Epoch: 10 [5120/15392 (33%)]\tLoss: 0.089049\n",
      "Train Epoch: 10 [5760/15392 (37%)]\tLoss: 0.024337\n",
      "Train Epoch: 10 [6400/15392 (41%)]\tLoss: 0.057205\n",
      "Train Epoch: 10 [7040/15392 (46%)]\tLoss: 0.099070\n",
      "Train Epoch: 10 [7680/15392 (50%)]\tLoss: 0.071394\n",
      "Train Epoch: 10 [8320/15392 (54%)]\tLoss: 0.069740\n",
      "Train Epoch: 10 [8960/15392 (58%)]\tLoss: 0.162762\n",
      "Train Epoch: 10 [9600/15392 (62%)]\tLoss: 0.029671\n",
      "Train Epoch: 10 [10240/15392 (66%)]\tLoss: 0.018728\n",
      "Train Epoch: 10 [10880/15392 (71%)]\tLoss: 0.118239\n",
      "Train Epoch: 10 [11520/15392 (75%)]\tLoss: 0.023776\n",
      "Train Epoch: 10 [12160/15392 (79%)]\tLoss: 0.040864\n",
      "Train Epoch: 10 [12800/15392 (83%)]\tLoss: 0.078118\n",
      "Train Epoch: 10 [13440/15392 (87%)]\tLoss: 0.020678\n",
      "Train Epoch: 10 [14080/15392 (91%)]\tLoss: 0.003748\n",
      "Train Epoch: 10 [14720/15392 (95%)]\tLoss: 0.120516\n",
      "Train Epoch: 10 [7680/15392 (100%)]\tLoss: 0.038246\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/15327 (0%)]\tLoss: 0.117497\n",
      "Train Epoch: 1 [640/15327 (4%)]\tLoss: 0.033534\n",
      "Train Epoch: 1 [1280/15327 (8%)]\tLoss: 0.029957\n",
      "Train Epoch: 1 [1920/15327 (12%)]\tLoss: 0.104031\n",
      "Train Epoch: 1 [2560/15327 (17%)]\tLoss: 0.080523\n",
      "Train Epoch: 1 [3200/15327 (21%)]\tLoss: 0.057116\n",
      "Train Epoch: 1 [3840/15327 (25%)]\tLoss: 0.084363\n",
      "Train Epoch: 1 [4480/15327 (29%)]\tLoss: 0.135130\n",
      "Train Epoch: 1 [5120/15327 (33%)]\tLoss: 0.123809\n",
      "Train Epoch: 1 [5760/15327 (38%)]\tLoss: 0.022209\n",
      "Train Epoch: 1 [6400/15327 (42%)]\tLoss: 0.045731\n",
      "Train Epoch: 1 [7040/15327 (46%)]\tLoss: 0.030223\n",
      "Train Epoch: 1 [7680/15327 (50%)]\tLoss: 0.073619\n",
      "Train Epoch: 1 [8320/15327 (54%)]\tLoss: 0.172607\n",
      "Train Epoch: 1 [8960/15327 (58%)]\tLoss: 0.036900\n",
      "Train Epoch: 1 [9600/15327 (62%)]\tLoss: 0.130851\n",
      "Train Epoch: 1 [10240/15327 (67%)]\tLoss: 0.141404\n",
      "Train Epoch: 1 [10880/15327 (71%)]\tLoss: 0.184652\n",
      "Train Epoch: 1 [11520/15327 (75%)]\tLoss: 0.091842\n",
      "Train Epoch: 1 [12160/15327 (79%)]\tLoss: 0.034989\n",
      "Train Epoch: 1 [12800/15327 (83%)]\tLoss: 0.103455\n",
      "Train Epoch: 1 [13440/15327 (88%)]\tLoss: 0.046757\n",
      "Train Epoch: 1 [14080/15327 (92%)]\tLoss: 0.058747\n",
      "Train Epoch: 1 [14720/15327 (96%)]\tLoss: 0.115717\n",
      "Train Epoch: 2 [0/15327 (0%)]\tLoss: 0.014158\n",
      "Train Epoch: 2 [640/15327 (4%)]\tLoss: 0.023825\n",
      "Train Epoch: 2 [1280/15327 (8%)]\tLoss: 0.013423\n",
      "Train Epoch: 2 [1920/15327 (12%)]\tLoss: 0.074305\n",
      "Train Epoch: 2 [2560/15327 (17%)]\tLoss: 0.035129\n",
      "Train Epoch: 2 [3200/15327 (21%)]\tLoss: 0.081150\n",
      "Train Epoch: 2 [3840/15327 (25%)]\tLoss: 0.062570\n",
      "Train Epoch: 2 [4480/15327 (29%)]\tLoss: 0.082211\n",
      "Train Epoch: 2 [5120/15327 (33%)]\tLoss: 0.028555\n",
      "Train Epoch: 2 [5760/15327 (38%)]\tLoss: 0.035874\n",
      "Train Epoch: 2 [6400/15327 (42%)]\tLoss: 0.089560\n",
      "Train Epoch: 2 [7040/15327 (46%)]\tLoss: 0.070265\n",
      "Train Epoch: 2 [7680/15327 (50%)]\tLoss: 0.043963\n",
      "Train Epoch: 2 [8320/15327 (54%)]\tLoss: 0.065299\n",
      "Train Epoch: 2 [8960/15327 (58%)]\tLoss: 0.026830\n",
      "Train Epoch: 2 [9600/15327 (62%)]\tLoss: 0.063479\n",
      "Train Epoch: 2 [10240/15327 (67%)]\tLoss: 0.034510\n",
      "Train Epoch: 2 [10880/15327 (71%)]\tLoss: 0.009729\n",
      "Train Epoch: 2 [11520/15327 (75%)]\tLoss: 0.073284\n",
      "Train Epoch: 2 [12160/15327 (79%)]\tLoss: 0.042307\n",
      "Train Epoch: 2 [12800/15327 (83%)]\tLoss: 0.036423\n",
      "Train Epoch: 2 [13440/15327 (88%)]\tLoss: 0.066836\n",
      "Train Epoch: 2 [14080/15327 (92%)]\tLoss: 0.020890\n",
      "Train Epoch: 2 [14720/15327 (96%)]\tLoss: 0.081675\n",
      "Train Epoch: 3 [0/15327 (0%)]\tLoss: 0.119518\n",
      "Train Epoch: 3 [640/15327 (4%)]\tLoss: 0.059303\n",
      "Train Epoch: 3 [1280/15327 (8%)]\tLoss: 0.014631\n",
      "Train Epoch: 3 [1920/15327 (12%)]\tLoss: 0.065840\n",
      "Train Epoch: 3 [2560/15327 (17%)]\tLoss: 0.060000\n",
      "Train Epoch: 3 [3200/15327 (21%)]\tLoss: 0.142257\n",
      "Train Epoch: 3 [3840/15327 (25%)]\tLoss: 0.023937\n",
      "Train Epoch: 3 [4480/15327 (29%)]\tLoss: 0.040369\n",
      "Train Epoch: 3 [5120/15327 (33%)]\tLoss: 0.023858\n",
      "Train Epoch: 3 [5760/15327 (38%)]\tLoss: 0.121487\n",
      "Train Epoch: 3 [6400/15327 (42%)]\tLoss: 0.173421\n",
      "Train Epoch: 3 [7040/15327 (46%)]\tLoss: 0.047950\n",
      "Train Epoch: 3 [7680/15327 (50%)]\tLoss: 0.049131\n",
      "Train Epoch: 3 [8320/15327 (54%)]\tLoss: 0.012112\n",
      "Train Epoch: 3 [8960/15327 (58%)]\tLoss: 0.126609\n",
      "Train Epoch: 3 [9600/15327 (62%)]\tLoss: 0.011582\n",
      "Train Epoch: 3 [10240/15327 (67%)]\tLoss: 0.042818\n",
      "Train Epoch: 3 [10880/15327 (71%)]\tLoss: 0.072094\n",
      "Train Epoch: 3 [11520/15327 (75%)]\tLoss: 0.043939\n",
      "Train Epoch: 3 [12160/15327 (79%)]\tLoss: 0.118844\n",
      "Train Epoch: 3 [12800/15327 (83%)]\tLoss: 0.068902\n",
      "Train Epoch: 3 [13440/15327 (88%)]\tLoss: 0.053499\n",
      "Train Epoch: 3 [14080/15327 (92%)]\tLoss: 0.107120\n",
      "Train Epoch: 3 [14720/15327 (96%)]\tLoss: 0.043829\n",
      "Train Epoch: 4 [0/15327 (0%)]\tLoss: 0.035864\n",
      "Train Epoch: 4 [640/15327 (4%)]\tLoss: 0.021225\n",
      "Train Epoch: 4 [1280/15327 (8%)]\tLoss: 0.102976\n",
      "Train Epoch: 4 [1920/15327 (12%)]\tLoss: 0.075840\n",
      "Train Epoch: 4 [2560/15327 (17%)]\tLoss: 0.043375\n",
      "Train Epoch: 4 [3200/15327 (21%)]\tLoss: 0.054609\n",
      "Train Epoch: 4 [3840/15327 (25%)]\tLoss: 0.053643\n",
      "Train Epoch: 4 [4480/15327 (29%)]\tLoss: 0.025569\n",
      "Train Epoch: 4 [5120/15327 (33%)]\tLoss: 0.119238\n",
      "Train Epoch: 4 [5760/15327 (38%)]\tLoss: 0.013214\n",
      "Train Epoch: 4 [6400/15327 (42%)]\tLoss: 0.186319\n",
      "Train Epoch: 4 [7040/15327 (46%)]\tLoss: 0.052760\n",
      "Train Epoch: 4 [7680/15327 (50%)]\tLoss: 0.089869\n",
      "Train Epoch: 4 [8320/15327 (54%)]\tLoss: 0.022480\n",
      "Train Epoch: 4 [8960/15327 (58%)]\tLoss: 0.068073\n",
      "Train Epoch: 4 [9600/15327 (62%)]\tLoss: 0.084363\n",
      "Train Epoch: 4 [10240/15327 (67%)]\tLoss: 0.040676\n",
      "Train Epoch: 4 [10880/15327 (71%)]\tLoss: 0.088125\n",
      "Train Epoch: 4 [11520/15327 (75%)]\tLoss: 0.047326\n",
      "Train Epoch: 4 [12160/15327 (79%)]\tLoss: 0.046658\n",
      "Train Epoch: 4 [12800/15327 (83%)]\tLoss: 0.040161\n",
      "Train Epoch: 4 [13440/15327 (88%)]\tLoss: 0.091306\n",
      "Train Epoch: 4 [14080/15327 (92%)]\tLoss: 0.159338\n",
      "Train Epoch: 4 [14720/15327 (96%)]\tLoss: 0.031630\n",
      "Train Epoch: 5 [0/15327 (0%)]\tLoss: 0.036943\n",
      "Train Epoch: 5 [640/15327 (4%)]\tLoss: 0.050435\n",
      "Train Epoch: 5 [1280/15327 (8%)]\tLoss: 0.048335\n",
      "Train Epoch: 5 [1920/15327 (12%)]\tLoss: 0.038468\n",
      "Train Epoch: 5 [2560/15327 (17%)]\tLoss: 0.080489\n",
      "Train Epoch: 5 [3200/15327 (21%)]\tLoss: 0.013890\n",
      "Train Epoch: 5 [3840/15327 (25%)]\tLoss: 0.033008\n",
      "Train Epoch: 5 [4480/15327 (29%)]\tLoss: 0.038202\n",
      "Train Epoch: 5 [5120/15327 (33%)]\tLoss: 0.007080\n",
      "Train Epoch: 5 [5760/15327 (38%)]\tLoss: 0.059616\n",
      "Train Epoch: 5 [6400/15327 (42%)]\tLoss: 0.061794\n",
      "Train Epoch: 5 [7040/15327 (46%)]\tLoss: 0.112754\n",
      "Train Epoch: 5 [7680/15327 (50%)]\tLoss: 0.024900\n",
      "Train Epoch: 5 [8320/15327 (54%)]\tLoss: 0.036530\n",
      "Train Epoch: 5 [8960/15327 (58%)]\tLoss: 0.075750\n",
      "Train Epoch: 5 [9600/15327 (62%)]\tLoss: 0.207349\n",
      "Train Epoch: 5 [10240/15327 (67%)]\tLoss: 0.003757\n",
      "Train Epoch: 5 [10880/15327 (71%)]\tLoss: 0.076550\n",
      "Train Epoch: 5 [11520/15327 (75%)]\tLoss: 0.329466\n",
      "Train Epoch: 5 [12160/15327 (79%)]\tLoss: 0.064276\n",
      "Train Epoch: 5 [12800/15327 (83%)]\tLoss: 0.019893\n",
      "Train Epoch: 5 [13440/15327 (88%)]\tLoss: 0.090117\n",
      "Train Epoch: 5 [14080/15327 (92%)]\tLoss: 0.099115\n",
      "Train Epoch: 5 [14720/15327 (96%)]\tLoss: 0.034507\n",
      "Train Epoch: 6 [0/15327 (0%)]\tLoss: 0.071267\n",
      "Train Epoch: 6 [640/15327 (4%)]\tLoss: 0.175945\n",
      "Train Epoch: 6 [1280/15327 (8%)]\tLoss: 0.122490\n",
      "Train Epoch: 6 [1920/15327 (12%)]\tLoss: 0.106468\n",
      "Train Epoch: 6 [2560/15327 (17%)]\tLoss: 0.145433\n",
      "Train Epoch: 6 [3200/15327 (21%)]\tLoss: 0.023214\n",
      "Train Epoch: 6 [3840/15327 (25%)]\tLoss: 0.040924\n",
      "Train Epoch: 6 [4480/15327 (29%)]\tLoss: 0.022094\n",
      "Train Epoch: 6 [5120/15327 (33%)]\tLoss: 0.035539\n",
      "Train Epoch: 6 [5760/15327 (38%)]\tLoss: 0.168144\n",
      "Train Epoch: 6 [6400/15327 (42%)]\tLoss: 0.020214\n",
      "Train Epoch: 6 [7040/15327 (46%)]\tLoss: 0.059188\n",
      "Train Epoch: 6 [7680/15327 (50%)]\tLoss: 0.019312\n",
      "Train Epoch: 6 [8320/15327 (54%)]\tLoss: 0.012067\n",
      "Train Epoch: 6 [8960/15327 (58%)]\tLoss: 0.280959\n",
      "Train Epoch: 6 [9600/15327 (62%)]\tLoss: 0.019448\n",
      "Train Epoch: 6 [10240/15327 (67%)]\tLoss: 0.026437\n",
      "Train Epoch: 6 [10880/15327 (71%)]\tLoss: 0.054068\n",
      "Train Epoch: 6 [11520/15327 (75%)]\tLoss: 0.020716\n",
      "Train Epoch: 6 [12160/15327 (79%)]\tLoss: 0.054085\n",
      "Train Epoch: 6 [12800/15327 (83%)]\tLoss: 0.121140\n",
      "Train Epoch: 6 [13440/15327 (88%)]\tLoss: 0.094226\n",
      "Train Epoch: 6 [14080/15327 (92%)]\tLoss: 0.043363\n",
      "Train Epoch: 6 [14720/15327 (96%)]\tLoss: 0.062213\n",
      "Train Epoch: 7 [0/15327 (0%)]\tLoss: 0.048884\n",
      "Train Epoch: 7 [640/15327 (4%)]\tLoss: 0.011962\n",
      "Train Epoch: 7 [1280/15327 (8%)]\tLoss: 0.033588\n",
      "Train Epoch: 7 [1920/15327 (12%)]\tLoss: 0.030826\n",
      "Train Epoch: 7 [2560/15327 (17%)]\tLoss: 0.064050\n",
      "Train Epoch: 7 [3200/15327 (21%)]\tLoss: 0.040225\n",
      "Train Epoch: 7 [3840/15327 (25%)]\tLoss: 0.132370\n",
      "Train Epoch: 7 [4480/15327 (29%)]\tLoss: 0.036821\n",
      "Train Epoch: 7 [5120/15327 (33%)]\tLoss: 0.047284\n",
      "Train Epoch: 7 [5760/15327 (38%)]\tLoss: 0.021844\n",
      "Train Epoch: 7 [6400/15327 (42%)]\tLoss: 0.068906\n",
      "Train Epoch: 7 [7040/15327 (46%)]\tLoss: 0.014781\n",
      "Train Epoch: 7 [7680/15327 (50%)]\tLoss: 0.094513\n",
      "Train Epoch: 7 [8320/15327 (54%)]\tLoss: 0.116304\n",
      "Train Epoch: 7 [8960/15327 (58%)]\tLoss: 0.080349\n",
      "Train Epoch: 7 [9600/15327 (62%)]\tLoss: 0.099578\n",
      "Train Epoch: 7 [10240/15327 (67%)]\tLoss: 0.021023\n",
      "Train Epoch: 7 [10880/15327 (71%)]\tLoss: 0.023776\n",
      "Train Epoch: 7 [11520/15327 (75%)]\tLoss: 0.058256\n",
      "Train Epoch: 7 [12160/15327 (79%)]\tLoss: 0.016869\n",
      "Train Epoch: 7 [12800/15327 (83%)]\tLoss: 0.159057\n",
      "Train Epoch: 7 [13440/15327 (88%)]\tLoss: 0.059746\n",
      "Train Epoch: 7 [14080/15327 (92%)]\tLoss: 0.055053\n",
      "Train Epoch: 7 [14720/15327 (96%)]\tLoss: 0.010844\n",
      "Train Epoch: 8 [0/15327 (0%)]\tLoss: 0.012577\n",
      "Train Epoch: 8 [640/15327 (4%)]\tLoss: 0.024842\n",
      "Train Epoch: 8 [1280/15327 (8%)]\tLoss: 0.048493\n",
      "Train Epoch: 8 [1920/15327 (12%)]\tLoss: 0.026247\n",
      "Train Epoch: 8 [2560/15327 (17%)]\tLoss: 0.045392\n",
      "Train Epoch: 8 [3200/15327 (21%)]\tLoss: 0.023725\n",
      "Train Epoch: 8 [3840/15327 (25%)]\tLoss: 0.050551\n",
      "Train Epoch: 8 [4480/15327 (29%)]\tLoss: 0.176155\n",
      "Train Epoch: 8 [5120/15327 (33%)]\tLoss: 0.067436\n",
      "Train Epoch: 8 [5760/15327 (38%)]\tLoss: 0.054049\n",
      "Train Epoch: 8 [6400/15327 (42%)]\tLoss: 0.036621\n",
      "Train Epoch: 8 [7040/15327 (46%)]\tLoss: 0.062792\n",
      "Train Epoch: 8 [7680/15327 (50%)]\tLoss: 0.018400\n",
      "Train Epoch: 8 [8320/15327 (54%)]\tLoss: 0.070834\n",
      "Train Epoch: 8 [8960/15327 (58%)]\tLoss: 0.026279\n",
      "Train Epoch: 8 [9600/15327 (62%)]\tLoss: 0.017744\n",
      "Train Epoch: 8 [10240/15327 (67%)]\tLoss: 0.115926\n",
      "Train Epoch: 8 [10880/15327 (71%)]\tLoss: 0.035087\n",
      "Train Epoch: 8 [11520/15327 (75%)]\tLoss: 0.009400\n",
      "Train Epoch: 8 [12160/15327 (79%)]\tLoss: 0.256243\n",
      "Train Epoch: 8 [12800/15327 (83%)]\tLoss: 0.025048\n",
      "Train Epoch: 8 [13440/15327 (88%)]\tLoss: 0.066699\n",
      "Train Epoch: 8 [14080/15327 (92%)]\tLoss: 0.025434\n",
      "Train Epoch: 8 [14720/15327 (96%)]\tLoss: 0.021566\n",
      "Train Epoch: 9 [0/15327 (0%)]\tLoss: 0.083729\n",
      "Train Epoch: 9 [640/15327 (4%)]\tLoss: 0.017379\n",
      "Train Epoch: 9 [1280/15327 (8%)]\tLoss: 0.038790\n",
      "Train Epoch: 9 [1920/15327 (12%)]\tLoss: 0.035594\n",
      "Train Epoch: 9 [2560/15327 (17%)]\tLoss: 0.029309\n",
      "Train Epoch: 9 [3200/15327 (21%)]\tLoss: 0.025122\n",
      "Train Epoch: 9 [3840/15327 (25%)]\tLoss: 0.030335\n",
      "Train Epoch: 9 [4480/15327 (29%)]\tLoss: 0.042195\n",
      "Train Epoch: 9 [5120/15327 (33%)]\tLoss: 0.141035\n",
      "Train Epoch: 9 [5760/15327 (38%)]\tLoss: 0.049341\n",
      "Train Epoch: 9 [6400/15327 (42%)]\tLoss: 0.096970\n",
      "Train Epoch: 9 [7040/15327 (46%)]\tLoss: 0.115219\n",
      "Train Epoch: 9 [7680/15327 (50%)]\tLoss: 0.058904\n",
      "Train Epoch: 9 [8320/15327 (54%)]\tLoss: 0.086277\n",
      "Train Epoch: 9 [8960/15327 (58%)]\tLoss: 0.023581\n",
      "Train Epoch: 9 [9600/15327 (62%)]\tLoss: 0.023599\n",
      "Train Epoch: 9 [10240/15327 (67%)]\tLoss: 0.089684\n",
      "Train Epoch: 9 [10880/15327 (71%)]\tLoss: 0.057974\n",
      "Train Epoch: 9 [11520/15327 (75%)]\tLoss: 0.067324\n",
      "Train Epoch: 9 [12160/15327 (79%)]\tLoss: 0.029946\n",
      "Train Epoch: 9 [12800/15327 (83%)]\tLoss: 0.015609\n",
      "Train Epoch: 9 [13440/15327 (88%)]\tLoss: 0.014735\n",
      "Train Epoch: 9 [14080/15327 (92%)]\tLoss: 0.126930\n",
      "Train Epoch: 9 [14720/15327 (96%)]\tLoss: 0.085387\n",
      "Train Epoch: 10 [0/15327 (0%)]\tLoss: 0.025455\n",
      "Train Epoch: 10 [640/15327 (4%)]\tLoss: 0.014859\n",
      "Train Epoch: 10 [1280/15327 (8%)]\tLoss: 0.075396\n",
      "Train Epoch: 10 [1920/15327 (12%)]\tLoss: 0.091821\n",
      "Train Epoch: 10 [2560/15327 (17%)]\tLoss: 0.069545\n",
      "Train Epoch: 10 [3200/15327 (21%)]\tLoss: 0.029941\n",
      "Train Epoch: 10 [3840/15327 (25%)]\tLoss: 0.133908\n",
      "Train Epoch: 10 [4480/15327 (29%)]\tLoss: 0.100592\n",
      "Train Epoch: 10 [5120/15327 (33%)]\tLoss: 0.116754\n",
      "Train Epoch: 10 [5760/15327 (38%)]\tLoss: 0.018526\n",
      "Train Epoch: 10 [6400/15327 (42%)]\tLoss: 0.057487\n",
      "Train Epoch: 10 [7040/15327 (46%)]\tLoss: 0.019011\n",
      "Train Epoch: 10 [7680/15327 (50%)]\tLoss: 0.083216\n",
      "Train Epoch: 10 [8320/15327 (54%)]\tLoss: 0.098533\n",
      "Train Epoch: 10 [8960/15327 (58%)]\tLoss: 0.015108\n",
      "Train Epoch: 10 [9600/15327 (62%)]\tLoss: 0.058470\n",
      "Train Epoch: 10 [10240/15327 (67%)]\tLoss: 0.010837\n",
      "Train Epoch: 10 [10880/15327 (71%)]\tLoss: 0.054754\n",
      "Train Epoch: 10 [11520/15327 (75%)]\tLoss: 0.100356\n",
      "Train Epoch: 10 [12160/15327 (79%)]\tLoss: 0.037153\n",
      "Train Epoch: 10 [12800/15327 (83%)]\tLoss: 0.028762\n",
      "Train Epoch: 10 [13440/15327 (88%)]\tLoss: 0.144365\n",
      "Train Epoch: 10 [14080/15327 (92%)]\tLoss: 0.016603\n",
      "Train Epoch: 10 [14720/15327 (96%)]\tLoss: 0.044649\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.1685, Accuracy: 9868/10000 (99%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/18662 (0%)]\tLoss: 0.054692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [640/18662 (3%)]\tLoss: 0.099334\n",
      "Train Epoch: 1 [1280/18662 (7%)]\tLoss: 0.115376\n",
      "Train Epoch: 1 [1920/18662 (10%)]\tLoss: 0.046257\n",
      "Train Epoch: 1 [2560/18662 (14%)]\tLoss: 0.029092\n",
      "Train Epoch: 1 [3200/18662 (17%)]\tLoss: 0.047639\n",
      "Train Epoch: 1 [3840/18662 (21%)]\tLoss: 0.025450\n",
      "Train Epoch: 1 [4480/18662 (24%)]\tLoss: 0.157845\n",
      "Train Epoch: 1 [5120/18662 (27%)]\tLoss: 0.090637\n",
      "Train Epoch: 1 [5760/18662 (31%)]\tLoss: 0.032706\n",
      "Train Epoch: 1 [6400/18662 (34%)]\tLoss: 0.064011\n",
      "Train Epoch: 1 [7040/18662 (38%)]\tLoss: 0.070859\n",
      "Train Epoch: 1 [7680/18662 (41%)]\tLoss: 0.235565\n",
      "Train Epoch: 1 [8320/18662 (45%)]\tLoss: 0.102281\n",
      "Train Epoch: 1 [8960/18662 (48%)]\tLoss: 0.050707\n",
      "Train Epoch: 1 [9600/18662 (51%)]\tLoss: 0.071050\n",
      "Train Epoch: 1 [10240/18662 (55%)]\tLoss: 0.004932\n",
      "Train Epoch: 1 [10880/18662 (58%)]\tLoss: 0.023674\n",
      "Train Epoch: 1 [11520/18662 (62%)]\tLoss: 0.022883\n",
      "Train Epoch: 1 [12160/18662 (65%)]\tLoss: 0.152059\n",
      "Train Epoch: 1 [12800/18662 (68%)]\tLoss: 0.067748\n",
      "Train Epoch: 1 [13440/18662 (72%)]\tLoss: 0.060299\n",
      "Train Epoch: 1 [14080/18662 (75%)]\tLoss: 0.016892\n",
      "Train Epoch: 1 [14720/18662 (79%)]\tLoss: 0.059324\n",
      "Train Epoch: 1 [15360/18662 (82%)]\tLoss: 0.055406\n",
      "Train Epoch: 1 [16000/18662 (86%)]\tLoss: 0.012492\n",
      "Train Epoch: 1 [16640/18662 (89%)]\tLoss: 0.025136\n",
      "Train Epoch: 1 [17280/18662 (92%)]\tLoss: 0.049252\n",
      "Train Epoch: 1 [17920/18662 (96%)]\tLoss: 0.041320\n",
      "Train Epoch: 1 [18560/18662 (99%)]\tLoss: 0.045818\n",
      "Train Epoch: 2 [0/18662 (0%)]\tLoss: 0.034430\n",
      "Train Epoch: 2 [640/18662 (3%)]\tLoss: 0.039273\n",
      "Train Epoch: 2 [1280/18662 (7%)]\tLoss: 0.037042\n",
      "Train Epoch: 2 [1920/18662 (10%)]\tLoss: 0.151192\n",
      "Train Epoch: 2 [2560/18662 (14%)]\tLoss: 0.119844\n",
      "Train Epoch: 2 [3200/18662 (17%)]\tLoss: 0.016955\n",
      "Train Epoch: 2 [3840/18662 (21%)]\tLoss: 0.087158\n",
      "Train Epoch: 2 [4480/18662 (24%)]\tLoss: 0.019532\n",
      "Train Epoch: 2 [5120/18662 (27%)]\tLoss: 0.055996\n",
      "Train Epoch: 2 [5760/18662 (31%)]\tLoss: 0.040650\n",
      "Train Epoch: 2 [6400/18662 (34%)]\tLoss: 0.082423\n",
      "Train Epoch: 2 [7040/18662 (38%)]\tLoss: 0.025821\n",
      "Train Epoch: 2 [7680/18662 (41%)]\tLoss: 0.048729\n",
      "Train Epoch: 2 [8320/18662 (45%)]\tLoss: 0.093924\n",
      "Train Epoch: 2 [8960/18662 (48%)]\tLoss: 0.164410\n",
      "Train Epoch: 2 [9600/18662 (51%)]\tLoss: 0.028967\n",
      "Train Epoch: 2 [10240/18662 (55%)]\tLoss: 0.029099\n",
      "Train Epoch: 2 [10880/18662 (58%)]\tLoss: 0.071502\n",
      "Train Epoch: 2 [11520/18662 (62%)]\tLoss: 0.014274\n",
      "Train Epoch: 2 [12160/18662 (65%)]\tLoss: 0.040161\n",
      "Train Epoch: 2 [12800/18662 (68%)]\tLoss: 0.082504\n",
      "Train Epoch: 2 [13440/18662 (72%)]\tLoss: 0.093181\n",
      "Train Epoch: 2 [14080/18662 (75%)]\tLoss: 0.040107\n",
      "Train Epoch: 2 [14720/18662 (79%)]\tLoss: 0.335829\n",
      "Train Epoch: 2 [15360/18662 (82%)]\tLoss: 0.054248\n",
      "Train Epoch: 2 [16000/18662 (86%)]\tLoss: 0.035161\n",
      "Train Epoch: 2 [16640/18662 (89%)]\tLoss: 0.211359\n",
      "Train Epoch: 2 [17280/18662 (92%)]\tLoss: 0.105870\n",
      "Train Epoch: 2 [17920/18662 (96%)]\tLoss: 0.020143\n",
      "Train Epoch: 2 [18560/18662 (99%)]\tLoss: 0.074642\n",
      "Train Epoch: 3 [0/18662 (0%)]\tLoss: 0.105358\n",
      "Train Epoch: 3 [640/18662 (3%)]\tLoss: 0.071308\n",
      "Train Epoch: 3 [1280/18662 (7%)]\tLoss: 0.025912\n",
      "Train Epoch: 3 [1920/18662 (10%)]\tLoss: 0.018194\n",
      "Train Epoch: 3 [2560/18662 (14%)]\tLoss: 0.038555\n",
      "Train Epoch: 3 [3200/18662 (17%)]\tLoss: 0.116213\n",
      "Train Epoch: 3 [3840/18662 (21%)]\tLoss: 0.096506\n",
      "Train Epoch: 3 [4480/18662 (24%)]\tLoss: 0.035121\n",
      "Train Epoch: 3 [5120/18662 (27%)]\tLoss: 0.064165\n",
      "Train Epoch: 3 [5760/18662 (31%)]\tLoss: 0.024053\n",
      "Train Epoch: 3 [6400/18662 (34%)]\tLoss: 0.156405\n",
      "Train Epoch: 3 [7040/18662 (38%)]\tLoss: 0.058011\n",
      "Train Epoch: 3 [7680/18662 (41%)]\tLoss: 0.010705\n",
      "Train Epoch: 3 [8320/18662 (45%)]\tLoss: 0.017134\n",
      "Train Epoch: 3 [8960/18662 (48%)]\tLoss: 0.003676\n",
      "Train Epoch: 3 [9600/18662 (51%)]\tLoss: 0.094193\n",
      "Train Epoch: 3 [10240/18662 (55%)]\tLoss: 0.080560\n",
      "Train Epoch: 3 [10880/18662 (58%)]\tLoss: 0.012836\n",
      "Train Epoch: 3 [11520/18662 (62%)]\tLoss: 0.057078\n",
      "Train Epoch: 3 [12160/18662 (65%)]\tLoss: 0.047913\n",
      "Train Epoch: 3 [12800/18662 (68%)]\tLoss: 0.036145\n",
      "Train Epoch: 3 [13440/18662 (72%)]\tLoss: 0.012340\n",
      "Train Epoch: 3 [14080/18662 (75%)]\tLoss: 0.100517\n",
      "Train Epoch: 3 [14720/18662 (79%)]\tLoss: 0.042297\n",
      "Train Epoch: 3 [15360/18662 (82%)]\tLoss: 0.023786\n",
      "Train Epoch: 3 [16000/18662 (86%)]\tLoss: 0.017679\n",
      "Train Epoch: 3 [16640/18662 (89%)]\tLoss: 0.028666\n",
      "Train Epoch: 3 [17280/18662 (92%)]\tLoss: 0.025768\n",
      "Train Epoch: 3 [17920/18662 (96%)]\tLoss: 0.044327\n",
      "Train Epoch: 3 [18560/18662 (99%)]\tLoss: 0.010553\n",
      "Train Epoch: 4 [0/18662 (0%)]\tLoss: 0.036854\n",
      "Train Epoch: 4 [640/18662 (3%)]\tLoss: 0.026183\n",
      "Train Epoch: 4 [1280/18662 (7%)]\tLoss: 0.056544\n",
      "Train Epoch: 4 [1920/18662 (10%)]\tLoss: 0.030026\n",
      "Train Epoch: 4 [2560/18662 (14%)]\tLoss: 0.093618\n",
      "Train Epoch: 4 [3200/18662 (17%)]\tLoss: 0.070537\n",
      "Train Epoch: 4 [3840/18662 (21%)]\tLoss: 0.024025\n",
      "Train Epoch: 4 [4480/18662 (24%)]\tLoss: 0.045668\n",
      "Train Epoch: 4 [5120/18662 (27%)]\tLoss: 0.018558\n",
      "Train Epoch: 4 [5760/18662 (31%)]\tLoss: 0.013813\n",
      "Train Epoch: 4 [6400/18662 (34%)]\tLoss: 0.037931\n",
      "Train Epoch: 4 [7040/18662 (38%)]\tLoss: 0.061590\n",
      "Train Epoch: 4 [7680/18662 (41%)]\tLoss: 0.011603\n",
      "Train Epoch: 4 [8320/18662 (45%)]\tLoss: 0.110521\n",
      "Train Epoch: 4 [8960/18662 (48%)]\tLoss: 0.010783\n",
      "Train Epoch: 4 [9600/18662 (51%)]\tLoss: 0.040324\n",
      "Train Epoch: 4 [10240/18662 (55%)]\tLoss: 0.264692\n",
      "Train Epoch: 4 [10880/18662 (58%)]\tLoss: 0.059070\n",
      "Train Epoch: 4 [11520/18662 (62%)]\tLoss: 0.038785\n",
      "Train Epoch: 4 [12160/18662 (65%)]\tLoss: 0.153461\n",
      "Train Epoch: 4 [12800/18662 (68%)]\tLoss: 0.146525\n",
      "Train Epoch: 4 [13440/18662 (72%)]\tLoss: 0.114754\n",
      "Train Epoch: 4 [14080/18662 (75%)]\tLoss: 0.029036\n",
      "Train Epoch: 4 [14720/18662 (79%)]\tLoss: 0.050889\n",
      "Train Epoch: 4 [15360/18662 (82%)]\tLoss: 0.022917\n",
      "Train Epoch: 4 [16000/18662 (86%)]\tLoss: 0.059751\n",
      "Train Epoch: 4 [16640/18662 (89%)]\tLoss: 0.011734\n",
      "Train Epoch: 4 [17280/18662 (92%)]\tLoss: 0.012023\n",
      "Train Epoch: 4 [17920/18662 (96%)]\tLoss: 0.028363\n",
      "Train Epoch: 4 [18560/18662 (99%)]\tLoss: 0.011204\n",
      "Train Epoch: 5 [0/18662 (0%)]\tLoss: 0.079442\n",
      "Train Epoch: 5 [640/18662 (3%)]\tLoss: 0.070347\n",
      "Train Epoch: 5 [1280/18662 (7%)]\tLoss: 0.030586\n",
      "Train Epoch: 5 [1920/18662 (10%)]\tLoss: 0.183030\n",
      "Train Epoch: 5 [2560/18662 (14%)]\tLoss: 0.019467\n",
      "Train Epoch: 5 [3200/18662 (17%)]\tLoss: 0.067058\n",
      "Train Epoch: 5 [3840/18662 (21%)]\tLoss: 0.020605\n",
      "Train Epoch: 5 [4480/18662 (24%)]\tLoss: 0.051866\n",
      "Train Epoch: 5 [5120/18662 (27%)]\tLoss: 0.035764\n",
      "Train Epoch: 5 [5760/18662 (31%)]\tLoss: 0.066160\n",
      "Train Epoch: 5 [6400/18662 (34%)]\tLoss: 0.025378\n",
      "Train Epoch: 5 [7040/18662 (38%)]\tLoss: 0.015485\n",
      "Train Epoch: 5 [7680/18662 (41%)]\tLoss: 0.132654\n",
      "Train Epoch: 5 [8320/18662 (45%)]\tLoss: 0.134639\n",
      "Train Epoch: 5 [8960/18662 (48%)]\tLoss: 0.083604\n",
      "Train Epoch: 5 [9600/18662 (51%)]\tLoss: 0.026196\n",
      "Train Epoch: 5 [10240/18662 (55%)]\tLoss: 0.036382\n",
      "Train Epoch: 5 [10880/18662 (58%)]\tLoss: 0.154536\n",
      "Train Epoch: 5 [11520/18662 (62%)]\tLoss: 0.034563\n",
      "Train Epoch: 5 [12160/18662 (65%)]\tLoss: 0.068957\n",
      "Train Epoch: 5 [12800/18662 (68%)]\tLoss: 0.020379\n",
      "Train Epoch: 5 [13440/18662 (72%)]\tLoss: 0.033193\n",
      "Train Epoch: 5 [14080/18662 (75%)]\tLoss: 0.089084\n",
      "Train Epoch: 5 [14720/18662 (79%)]\tLoss: 0.018478\n",
      "Train Epoch: 5 [15360/18662 (82%)]\tLoss: 0.019198\n",
      "Train Epoch: 5 [16000/18662 (86%)]\tLoss: 0.043341\n",
      "Train Epoch: 5 [16640/18662 (89%)]\tLoss: 0.039255\n",
      "Train Epoch: 5 [17280/18662 (92%)]\tLoss: 0.042994\n",
      "Train Epoch: 5 [17920/18662 (96%)]\tLoss: 0.013942\n",
      "Train Epoch: 5 [18560/18662 (99%)]\tLoss: 0.022515\n",
      "Train Epoch: 6 [0/18662 (0%)]\tLoss: 0.011498\n",
      "Train Epoch: 6 [640/18662 (3%)]\tLoss: 0.162349\n",
      "Train Epoch: 6 [1280/18662 (7%)]\tLoss: 0.034925\n",
      "Train Epoch: 6 [1920/18662 (10%)]\tLoss: 0.152868\n",
      "Train Epoch: 6 [2560/18662 (14%)]\tLoss: 0.065031\n",
      "Train Epoch: 6 [3200/18662 (17%)]\tLoss: 0.007221\n",
      "Train Epoch: 6 [3840/18662 (21%)]\tLoss: 0.051006\n",
      "Train Epoch: 6 [4480/18662 (24%)]\tLoss: 0.007475\n",
      "Train Epoch: 6 [5120/18662 (27%)]\tLoss: 0.019297\n",
      "Train Epoch: 6 [5760/18662 (31%)]\tLoss: 0.149366\n",
      "Train Epoch: 6 [6400/18662 (34%)]\tLoss: 0.007912\n",
      "Train Epoch: 6 [7040/18662 (38%)]\tLoss: 0.023617\n",
      "Train Epoch: 6 [7680/18662 (41%)]\tLoss: 0.049725\n",
      "Train Epoch: 6 [8320/18662 (45%)]\tLoss: 0.042222\n",
      "Train Epoch: 6 [8960/18662 (48%)]\tLoss: 0.052037\n",
      "Train Epoch: 6 [9600/18662 (51%)]\tLoss: 0.013143\n",
      "Train Epoch: 6 [10240/18662 (55%)]\tLoss: 0.006759\n",
      "Train Epoch: 6 [10880/18662 (58%)]\tLoss: 0.116076\n",
      "Train Epoch: 6 [11520/18662 (62%)]\tLoss: 0.129685\n",
      "Train Epoch: 6 [12160/18662 (65%)]\tLoss: 0.026018\n",
      "Train Epoch: 6 [12800/18662 (68%)]\tLoss: 0.022877\n",
      "Train Epoch: 6 [13440/18662 (72%)]\tLoss: 0.037049\n",
      "Train Epoch: 6 [14080/18662 (75%)]\tLoss: 0.113314\n",
      "Train Epoch: 6 [14720/18662 (79%)]\tLoss: 0.052069\n",
      "Train Epoch: 6 [15360/18662 (82%)]\tLoss: 0.056683\n",
      "Train Epoch: 6 [16000/18662 (86%)]\tLoss: 0.031733\n",
      "Train Epoch: 6 [16640/18662 (89%)]\tLoss: 0.055875\n",
      "Train Epoch: 6 [17280/18662 (92%)]\tLoss: 0.009196\n",
      "Train Epoch: 6 [17920/18662 (96%)]\tLoss: 0.050892\n",
      "Train Epoch: 6 [18560/18662 (99%)]\tLoss: 0.080335\n",
      "Train Epoch: 7 [0/18662 (0%)]\tLoss: 0.027410\n",
      "Train Epoch: 7 [640/18662 (3%)]\tLoss: 0.041529\n",
      "Train Epoch: 7 [1280/18662 (7%)]\tLoss: 0.137123\n",
      "Train Epoch: 7 [1920/18662 (10%)]\tLoss: 0.134814\n",
      "Train Epoch: 7 [2560/18662 (14%)]\tLoss: 0.030011\n",
      "Train Epoch: 7 [3200/18662 (17%)]\tLoss: 0.021670\n",
      "Train Epoch: 7 [3840/18662 (21%)]\tLoss: 0.056895\n",
      "Train Epoch: 7 [4480/18662 (24%)]\tLoss: 0.055429\n",
      "Train Epoch: 7 [5120/18662 (27%)]\tLoss: 0.133898\n",
      "Train Epoch: 7 [5760/18662 (31%)]\tLoss: 0.008280\n",
      "Train Epoch: 7 [6400/18662 (34%)]\tLoss: 0.058709\n",
      "Train Epoch: 7 [7040/18662 (38%)]\tLoss: 0.095680\n",
      "Train Epoch: 7 [7680/18662 (41%)]\tLoss: 0.020259\n",
      "Train Epoch: 7 [8320/18662 (45%)]\tLoss: 0.005236\n",
      "Train Epoch: 7 [8960/18662 (48%)]\tLoss: 0.077440\n",
      "Train Epoch: 7 [9600/18662 (51%)]\tLoss: 0.041348\n",
      "Train Epoch: 7 [10240/18662 (55%)]\tLoss: 0.009304\n",
      "Train Epoch: 7 [10880/18662 (58%)]\tLoss: 0.012624\n",
      "Train Epoch: 7 [11520/18662 (62%)]\tLoss: 0.027006\n",
      "Train Epoch: 7 [12160/18662 (65%)]\tLoss: 0.200812\n",
      "Train Epoch: 7 [12800/18662 (68%)]\tLoss: 0.037000\n",
      "Train Epoch: 7 [13440/18662 (72%)]\tLoss: 0.008868\n",
      "Train Epoch: 7 [14080/18662 (75%)]\tLoss: 0.269724\n",
      "Train Epoch: 7 [14720/18662 (79%)]\tLoss: 0.018631\n",
      "Train Epoch: 7 [15360/18662 (82%)]\tLoss: 0.073552\n",
      "Train Epoch: 7 [16000/18662 (86%)]\tLoss: 0.011301\n",
      "Train Epoch: 7 [16640/18662 (89%)]\tLoss: 0.069619\n",
      "Train Epoch: 7 [17280/18662 (92%)]\tLoss: 0.042273\n",
      "Train Epoch: 7 [17920/18662 (96%)]\tLoss: 0.033187\n",
      "Train Epoch: 7 [18560/18662 (99%)]\tLoss: 0.129688\n",
      "Train Epoch: 8 [0/18662 (0%)]\tLoss: 0.016734\n",
      "Train Epoch: 8 [640/18662 (3%)]\tLoss: 0.009031\n",
      "Train Epoch: 8 [1280/18662 (7%)]\tLoss: 0.026226\n",
      "Train Epoch: 8 [1920/18662 (10%)]\tLoss: 0.032783\n",
      "Train Epoch: 8 [2560/18662 (14%)]\tLoss: 0.038375\n",
      "Train Epoch: 8 [3200/18662 (17%)]\tLoss: 0.009391\n",
      "Train Epoch: 8 [3840/18662 (21%)]\tLoss: 0.057352\n",
      "Train Epoch: 8 [4480/18662 (24%)]\tLoss: 0.028964\n",
      "Train Epoch: 8 [5120/18662 (27%)]\tLoss: 0.016905\n",
      "Train Epoch: 8 [5760/18662 (31%)]\tLoss: 0.015731\n",
      "Train Epoch: 8 [6400/18662 (34%)]\tLoss: 0.042944\n",
      "Train Epoch: 8 [7040/18662 (38%)]\tLoss: 0.119119\n",
      "Train Epoch: 8 [7680/18662 (41%)]\tLoss: 0.017039\n",
      "Train Epoch: 8 [8320/18662 (45%)]\tLoss: 0.097427\n",
      "Train Epoch: 8 [8960/18662 (48%)]\tLoss: 0.118166\n",
      "Train Epoch: 8 [9600/18662 (51%)]\tLoss: 0.093514\n",
      "Train Epoch: 8 [10240/18662 (55%)]\tLoss: 0.037563\n",
      "Train Epoch: 8 [10880/18662 (58%)]\tLoss: 0.008241\n",
      "Train Epoch: 8 [11520/18662 (62%)]\tLoss: 0.324440\n",
      "Train Epoch: 8 [12160/18662 (65%)]\tLoss: 0.037616\n",
      "Train Epoch: 8 [12800/18662 (68%)]\tLoss: 0.001841\n",
      "Train Epoch: 8 [13440/18662 (72%)]\tLoss: 0.026648\n",
      "Train Epoch: 8 [14080/18662 (75%)]\tLoss: 0.135082\n",
      "Train Epoch: 8 [14720/18662 (79%)]\tLoss: 0.037859\n",
      "Train Epoch: 8 [15360/18662 (82%)]\tLoss: 0.184920\n",
      "Train Epoch: 8 [16000/18662 (86%)]\tLoss: 0.009368\n",
      "Train Epoch: 8 [16640/18662 (89%)]\tLoss: 0.070402\n",
      "Train Epoch: 8 [17280/18662 (92%)]\tLoss: 0.012435\n",
      "Train Epoch: 8 [17920/18662 (96%)]\tLoss: 0.111986\n",
      "Train Epoch: 8 [18560/18662 (99%)]\tLoss: 0.031597\n",
      "Train Epoch: 9 [0/18662 (0%)]\tLoss: 0.043002\n",
      "Train Epoch: 9 [640/18662 (3%)]\tLoss: 0.008342\n",
      "Train Epoch: 9 [1280/18662 (7%)]\tLoss: 0.085576\n",
      "Train Epoch: 9 [1920/18662 (10%)]\tLoss: 0.027558\n",
      "Train Epoch: 9 [2560/18662 (14%)]\tLoss: 0.102895\n",
      "Train Epoch: 9 [3200/18662 (17%)]\tLoss: 0.077390\n",
      "Train Epoch: 9 [3840/18662 (21%)]\tLoss: 0.020951\n",
      "Train Epoch: 9 [4480/18662 (24%)]\tLoss: 0.079153\n",
      "Train Epoch: 9 [5120/18662 (27%)]\tLoss: 0.075918\n",
      "Train Epoch: 9 [5760/18662 (31%)]\tLoss: 0.037359\n",
      "Train Epoch: 9 [6400/18662 (34%)]\tLoss: 0.019072\n",
      "Train Epoch: 9 [7040/18662 (38%)]\tLoss: 0.027792\n",
      "Train Epoch: 9 [7680/18662 (41%)]\tLoss: 0.017279\n",
      "Train Epoch: 9 [8320/18662 (45%)]\tLoss: 0.050675\n",
      "Train Epoch: 9 [8960/18662 (48%)]\tLoss: 0.092657\n",
      "Train Epoch: 9 [9600/18662 (51%)]\tLoss: 0.029129\n",
      "Train Epoch: 9 [10240/18662 (55%)]\tLoss: 0.083363\n",
      "Train Epoch: 9 [10880/18662 (58%)]\tLoss: 0.161798\n",
      "Train Epoch: 9 [11520/18662 (62%)]\tLoss: 0.081669\n",
      "Train Epoch: 9 [12160/18662 (65%)]\tLoss: 0.066015\n",
      "Train Epoch: 9 [12800/18662 (68%)]\tLoss: 0.043387\n",
      "Train Epoch: 9 [13440/18662 (72%)]\tLoss: 0.058689\n",
      "Train Epoch: 9 [14080/18662 (75%)]\tLoss: 0.021303\n",
      "Train Epoch: 9 [14720/18662 (79%)]\tLoss: 0.028754\n",
      "Train Epoch: 9 [15360/18662 (82%)]\tLoss: 0.097123\n",
      "Train Epoch: 9 [16000/18662 (86%)]\tLoss: 0.038694\n",
      "Train Epoch: 9 [16640/18662 (89%)]\tLoss: 0.065592\n",
      "Train Epoch: 9 [17280/18662 (92%)]\tLoss: 0.062484\n",
      "Train Epoch: 9 [17920/18662 (96%)]\tLoss: 0.003371\n",
      "Train Epoch: 9 [18560/18662 (99%)]\tLoss: 0.011363\n",
      "Train Epoch: 10 [0/18662 (0%)]\tLoss: 0.149955\n",
      "Train Epoch: 10 [640/18662 (3%)]\tLoss: 0.007832\n",
      "Train Epoch: 10 [1280/18662 (7%)]\tLoss: 0.030303\n",
      "Train Epoch: 10 [1920/18662 (10%)]\tLoss: 0.043823\n",
      "Train Epoch: 10 [2560/18662 (14%)]\tLoss: 0.022233\n",
      "Train Epoch: 10 [3200/18662 (17%)]\tLoss: 0.071520\n",
      "Train Epoch: 10 [3840/18662 (21%)]\tLoss: 0.027696\n",
      "Train Epoch: 10 [4480/18662 (24%)]\tLoss: 0.059282\n",
      "Train Epoch: 10 [5120/18662 (27%)]\tLoss: 0.032535\n",
      "Train Epoch: 10 [5760/18662 (31%)]\tLoss: 0.016542\n",
      "Train Epoch: 10 [6400/18662 (34%)]\tLoss: 0.010646\n",
      "Train Epoch: 10 [7040/18662 (38%)]\tLoss: 0.035033\n",
      "Train Epoch: 10 [7680/18662 (41%)]\tLoss: 0.015553\n",
      "Train Epoch: 10 [8320/18662 (45%)]\tLoss: 0.084805\n",
      "Train Epoch: 10 [8960/18662 (48%)]\tLoss: 0.030433\n",
      "Train Epoch: 10 [9600/18662 (51%)]\tLoss: 0.050055\n",
      "Train Epoch: 10 [10240/18662 (55%)]\tLoss: 0.081830\n",
      "Train Epoch: 10 [10880/18662 (58%)]\tLoss: 0.028466\n",
      "Train Epoch: 10 [11520/18662 (62%)]\tLoss: 0.108685\n",
      "Train Epoch: 10 [12160/18662 (65%)]\tLoss: 0.007269\n",
      "Train Epoch: 10 [12800/18662 (68%)]\tLoss: 0.022884\n",
      "Train Epoch: 10 [13440/18662 (72%)]\tLoss: 0.010413\n",
      "Train Epoch: 10 [14080/18662 (75%)]\tLoss: 0.059050\n",
      "Train Epoch: 10 [14720/18662 (79%)]\tLoss: 0.060420\n",
      "Train Epoch: 10 [15360/18662 (82%)]\tLoss: 0.027603\n",
      "Train Epoch: 10 [16000/18662 (86%)]\tLoss: 0.076133\n",
      "Train Epoch: 10 [16640/18662 (89%)]\tLoss: 0.130382\n",
      "Train Epoch: 10 [17280/18662 (92%)]\tLoss: 0.015764\n",
      "Train Epoch: 10 [17920/18662 (96%)]\tLoss: 0.018023\n",
      "Train Epoch: 10 [18560/18662 (99%)]\tLoss: 0.129294\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/10619 (0%)]\tLoss: 0.163741\n",
      "Train Epoch: 1 [640/10619 (6%)]\tLoss: 0.065737\n",
      "Train Epoch: 1 [1280/10619 (12%)]\tLoss: 0.257688\n",
      "Train Epoch: 1 [1920/10619 (18%)]\tLoss: 0.057399\n",
      "Train Epoch: 1 [2560/10619 (24%)]\tLoss: 0.054967\n",
      "Train Epoch: 1 [3200/10619 (30%)]\tLoss: 0.029512\n",
      "Train Epoch: 1 [3840/10619 (36%)]\tLoss: 0.142737\n",
      "Train Epoch: 1 [4480/10619 (42%)]\tLoss: 0.030012\n",
      "Train Epoch: 1 [5120/10619 (48%)]\tLoss: 0.044318\n",
      "Train Epoch: 1 [5760/10619 (54%)]\tLoss: 0.041121\n",
      "Train Epoch: 1 [6400/10619 (60%)]\tLoss: 0.093579\n",
      "Train Epoch: 1 [7040/10619 (66%)]\tLoss: 0.063222\n",
      "Train Epoch: 1 [7680/10619 (72%)]\tLoss: 0.030461\n",
      "Train Epoch: 1 [8320/10619 (78%)]\tLoss: 0.019811\n",
      "Train Epoch: 1 [8960/10619 (84%)]\tLoss: 0.116604\n",
      "Train Epoch: 1 [9600/10619 (90%)]\tLoss: 0.069350\n",
      "Train Epoch: 1 [10240/10619 (96%)]\tLoss: 0.094207\n",
      "Train Epoch: 2 [0/10619 (0%)]\tLoss: 0.035908\n",
      "Train Epoch: 2 [640/10619 (6%)]\tLoss: 0.030486\n",
      "Train Epoch: 2 [1280/10619 (12%)]\tLoss: 0.105761\n",
      "Train Epoch: 2 [1920/10619 (18%)]\tLoss: 0.109574\n",
      "Train Epoch: 2 [2560/10619 (24%)]\tLoss: 0.075548\n",
      "Train Epoch: 2 [3200/10619 (30%)]\tLoss: 0.292845\n",
      "Train Epoch: 2 [3840/10619 (36%)]\tLoss: 0.058352\n",
      "Train Epoch: 2 [4480/10619 (42%)]\tLoss: 0.040865\n",
      "Train Epoch: 2 [5120/10619 (48%)]\tLoss: 0.105902\n",
      "Train Epoch: 2 [5760/10619 (54%)]\tLoss: 0.015869\n",
      "Train Epoch: 2 [6400/10619 (60%)]\tLoss: 0.128509\n",
      "Train Epoch: 2 [7040/10619 (66%)]\tLoss: 0.065959\n",
      "Train Epoch: 2 [7680/10619 (72%)]\tLoss: 0.034476\n",
      "Train Epoch: 2 [8320/10619 (78%)]\tLoss: 0.027997\n",
      "Train Epoch: 2 [8960/10619 (84%)]\tLoss: 0.019827\n",
      "Train Epoch: 2 [9600/10619 (90%)]\tLoss: 0.139359\n",
      "Train Epoch: 2 [10240/10619 (96%)]\tLoss: 0.087226\n",
      "Train Epoch: 3 [0/10619 (0%)]\tLoss: 0.016144\n",
      "Train Epoch: 3 [640/10619 (6%)]\tLoss: 0.065694\n",
      "Train Epoch: 3 [1280/10619 (12%)]\tLoss: 0.088192\n",
      "Train Epoch: 3 [1920/10619 (18%)]\tLoss: 0.025348\n",
      "Train Epoch: 3 [2560/10619 (24%)]\tLoss: 0.062934\n",
      "Train Epoch: 3 [3200/10619 (30%)]\tLoss: 0.094199\n",
      "Train Epoch: 3 [3840/10619 (36%)]\tLoss: 0.033421\n",
      "Train Epoch: 3 [4480/10619 (42%)]\tLoss: 0.183795\n",
      "Train Epoch: 3 [5120/10619 (48%)]\tLoss: 0.179139\n",
      "Train Epoch: 3 [5760/10619 (54%)]\tLoss: 0.015914\n",
      "Train Epoch: 3 [6400/10619 (60%)]\tLoss: 0.091637\n",
      "Train Epoch: 3 [7040/10619 (66%)]\tLoss: 0.062749\n",
      "Train Epoch: 3 [7680/10619 (72%)]\tLoss: 0.025692\n",
      "Train Epoch: 3 [8320/10619 (78%)]\tLoss: 0.152687\n",
      "Train Epoch: 3 [8960/10619 (84%)]\tLoss: 0.062531\n",
      "Train Epoch: 3 [9600/10619 (90%)]\tLoss: 0.256793\n",
      "Train Epoch: 3 [10240/10619 (96%)]\tLoss: 0.092267\n",
      "Train Epoch: 4 [0/10619 (0%)]\tLoss: 0.195109\n",
      "Train Epoch: 4 [640/10619 (6%)]\tLoss: 0.062387\n",
      "Train Epoch: 4 [1280/10619 (12%)]\tLoss: 0.150173\n",
      "Train Epoch: 4 [1920/10619 (18%)]\tLoss: 0.098588\n",
      "Train Epoch: 4 [2560/10619 (24%)]\tLoss: 0.047341\n",
      "Train Epoch: 4 [3200/10619 (30%)]\tLoss: 0.028544\n",
      "Train Epoch: 4 [3840/10619 (36%)]\tLoss: 0.065730\n",
      "Train Epoch: 4 [4480/10619 (42%)]\tLoss: 0.076138\n",
      "Train Epoch: 4 [5120/10619 (48%)]\tLoss: 0.104442\n",
      "Train Epoch: 4 [5760/10619 (54%)]\tLoss: 0.039857\n",
      "Train Epoch: 4 [6400/10619 (60%)]\tLoss: 0.076286\n",
      "Train Epoch: 4 [7040/10619 (66%)]\tLoss: 0.049406\n",
      "Train Epoch: 4 [7680/10619 (72%)]\tLoss: 0.117115\n",
      "Train Epoch: 4 [8320/10619 (78%)]\tLoss: 0.106999\n",
      "Train Epoch: 4 [8960/10619 (84%)]\tLoss: 0.088120\n",
      "Train Epoch: 4 [9600/10619 (90%)]\tLoss: 0.094014\n",
      "Train Epoch: 4 [10240/10619 (96%)]\tLoss: 0.178499\n",
      "Train Epoch: 5 [0/10619 (0%)]\tLoss: 0.108627\n",
      "Train Epoch: 5 [640/10619 (6%)]\tLoss: 0.207583\n",
      "Train Epoch: 5 [1280/10619 (12%)]\tLoss: 0.061359\n",
      "Train Epoch: 5 [1920/10619 (18%)]\tLoss: 0.030877\n",
      "Train Epoch: 5 [2560/10619 (24%)]\tLoss: 0.039764\n",
      "Train Epoch: 5 [3200/10619 (30%)]\tLoss: 0.104327\n",
      "Train Epoch: 5 [3840/10619 (36%)]\tLoss: 0.026431\n",
      "Train Epoch: 5 [4480/10619 (42%)]\tLoss: 0.072350\n",
      "Train Epoch: 5 [5120/10619 (48%)]\tLoss: 0.227885\n",
      "Train Epoch: 5 [5760/10619 (54%)]\tLoss: 0.040596\n",
      "Train Epoch: 5 [6400/10619 (60%)]\tLoss: 0.053282\n",
      "Train Epoch: 5 [7040/10619 (66%)]\tLoss: 0.039365\n",
      "Train Epoch: 5 [7680/10619 (72%)]\tLoss: 0.055420\n",
      "Train Epoch: 5 [8320/10619 (78%)]\tLoss: 0.062920\n",
      "Train Epoch: 5 [8960/10619 (84%)]\tLoss: 0.049448\n",
      "Train Epoch: 5 [9600/10619 (90%)]\tLoss: 0.112654\n",
      "Train Epoch: 5 [10240/10619 (96%)]\tLoss: 0.058729\n",
      "Train Epoch: 6 [0/10619 (0%)]\tLoss: 0.039483\n",
      "Train Epoch: 6 [640/10619 (6%)]\tLoss: 0.015629\n",
      "Train Epoch: 6 [1280/10619 (12%)]\tLoss: 0.089578\n",
      "Train Epoch: 6 [1920/10619 (18%)]\tLoss: 0.024606\n",
      "Train Epoch: 6 [2560/10619 (24%)]\tLoss: 0.049315\n",
      "Train Epoch: 6 [3200/10619 (30%)]\tLoss: 0.099419\n",
      "Train Epoch: 6 [3840/10619 (36%)]\tLoss: 0.066660\n",
      "Train Epoch: 6 [4480/10619 (42%)]\tLoss: 0.033716\n",
      "Train Epoch: 6 [5120/10619 (48%)]\tLoss: 0.024167\n",
      "Train Epoch: 6 [5760/10619 (54%)]\tLoss: 0.013899\n",
      "Train Epoch: 6 [6400/10619 (60%)]\tLoss: 0.122823\n",
      "Train Epoch: 6 [7040/10619 (66%)]\tLoss: 0.104522\n",
      "Train Epoch: 6 [7680/10619 (72%)]\tLoss: 0.027746\n",
      "Train Epoch: 6 [8320/10619 (78%)]\tLoss: 0.014239\n",
      "Train Epoch: 6 [8960/10619 (84%)]\tLoss: 0.089283\n",
      "Train Epoch: 6 [9600/10619 (90%)]\tLoss: 0.056427\n",
      "Train Epoch: 6 [10240/10619 (96%)]\tLoss: 0.079034\n",
      "Train Epoch: 7 [0/10619 (0%)]\tLoss: 0.049964\n",
      "Train Epoch: 7 [640/10619 (6%)]\tLoss: 0.069124\n",
      "Train Epoch: 7 [1280/10619 (12%)]\tLoss: 0.079633\n",
      "Train Epoch: 7 [1920/10619 (18%)]\tLoss: 0.176881\n",
      "Train Epoch: 7 [2560/10619 (24%)]\tLoss: 0.085014\n",
      "Train Epoch: 7 [3200/10619 (30%)]\tLoss: 0.096972\n",
      "Train Epoch: 7 [3840/10619 (36%)]\tLoss: 0.072931\n",
      "Train Epoch: 7 [4480/10619 (42%)]\tLoss: 0.007908\n",
      "Train Epoch: 7 [5120/10619 (48%)]\tLoss: 0.179987\n",
      "Train Epoch: 7 [5760/10619 (54%)]\tLoss: 0.084510\n",
      "Train Epoch: 7 [6400/10619 (60%)]\tLoss: 0.111006\n",
      "Train Epoch: 7 [7040/10619 (66%)]\tLoss: 0.042796\n",
      "Train Epoch: 7 [7680/10619 (72%)]\tLoss: 0.092547\n",
      "Train Epoch: 7 [8320/10619 (78%)]\tLoss: 0.175355\n",
      "Train Epoch: 7 [8960/10619 (84%)]\tLoss: 0.054313\n",
      "Train Epoch: 7 [9600/10619 (90%)]\tLoss: 0.101752\n",
      "Train Epoch: 7 [10240/10619 (96%)]\tLoss: 0.021353\n",
      "Train Epoch: 8 [0/10619 (0%)]\tLoss: 0.102805\n",
      "Train Epoch: 8 [640/10619 (6%)]\tLoss: 0.161627\n",
      "Train Epoch: 8 [1280/10619 (12%)]\tLoss: 0.021187\n",
      "Train Epoch: 8 [1920/10619 (18%)]\tLoss: 0.099839\n",
      "Train Epoch: 8 [2560/10619 (24%)]\tLoss: 0.049159\n",
      "Train Epoch: 8 [3200/10619 (30%)]\tLoss: 0.136449\n",
      "Train Epoch: 8 [3840/10619 (36%)]\tLoss: 0.106606\n",
      "Train Epoch: 8 [4480/10619 (42%)]\tLoss: 0.057025\n",
      "Train Epoch: 8 [5120/10619 (48%)]\tLoss: 0.121661\n",
      "Train Epoch: 8 [5760/10619 (54%)]\tLoss: 0.060773\n",
      "Train Epoch: 8 [6400/10619 (60%)]\tLoss: 0.074074\n",
      "Train Epoch: 8 [7040/10619 (66%)]\tLoss: 0.018178\n",
      "Train Epoch: 8 [7680/10619 (72%)]\tLoss: 0.018066\n",
      "Train Epoch: 8 [8320/10619 (78%)]\tLoss: 0.044147\n",
      "Train Epoch: 8 [8960/10619 (84%)]\tLoss: 0.084280\n",
      "Train Epoch: 8 [9600/10619 (90%)]\tLoss: 0.073905\n",
      "Train Epoch: 8 [10240/10619 (96%)]\tLoss: 0.029189\n",
      "Train Epoch: 9 [0/10619 (0%)]\tLoss: 0.048164\n",
      "Train Epoch: 9 [640/10619 (6%)]\tLoss: 0.029829\n",
      "Train Epoch: 9 [1280/10619 (12%)]\tLoss: 0.032334\n",
      "Train Epoch: 9 [1920/10619 (18%)]\tLoss: 0.110688\n",
      "Train Epoch: 9 [2560/10619 (24%)]\tLoss: 0.035297\n",
      "Train Epoch: 9 [3200/10619 (30%)]\tLoss: 0.069083\n",
      "Train Epoch: 9 [3840/10619 (36%)]\tLoss: 0.087869\n",
      "Train Epoch: 9 [4480/10619 (42%)]\tLoss: 0.062983\n",
      "Train Epoch: 9 [5120/10619 (48%)]\tLoss: 0.038570\n",
      "Train Epoch: 9 [5760/10619 (54%)]\tLoss: 0.056981\n",
      "Train Epoch: 9 [6400/10619 (60%)]\tLoss: 0.101259\n",
      "Train Epoch: 9 [7040/10619 (66%)]\tLoss: 0.069197\n",
      "Train Epoch: 9 [7680/10619 (72%)]\tLoss: 0.129092\n",
      "Train Epoch: 9 [8320/10619 (78%)]\tLoss: 0.039753\n",
      "Train Epoch: 9 [8960/10619 (84%)]\tLoss: 0.092910\n",
      "Train Epoch: 9 [9600/10619 (90%)]\tLoss: 0.036798\n",
      "Train Epoch: 9 [10240/10619 (96%)]\tLoss: 0.056177\n",
      "Train Epoch: 10 [0/10619 (0%)]\tLoss: 0.049757\n",
      "Train Epoch: 10 [640/10619 (6%)]\tLoss: 0.039470\n",
      "Train Epoch: 10 [1280/10619 (12%)]\tLoss: 0.049804\n",
      "Train Epoch: 10 [1920/10619 (18%)]\tLoss: 0.032775\n",
      "Train Epoch: 10 [2560/10619 (24%)]\tLoss: 0.055876\n",
      "Train Epoch: 10 [3200/10619 (30%)]\tLoss: 0.024914\n",
      "Train Epoch: 10 [3840/10619 (36%)]\tLoss: 0.035516\n",
      "Train Epoch: 10 [4480/10619 (42%)]\tLoss: 0.092404\n",
      "Train Epoch: 10 [5120/10619 (48%)]\tLoss: 0.046300\n",
      "Train Epoch: 10 [5760/10619 (54%)]\tLoss: 0.077719\n",
      "Train Epoch: 10 [6400/10619 (60%)]\tLoss: 0.111152\n",
      "Train Epoch: 10 [7040/10619 (66%)]\tLoss: 0.133182\n",
      "Train Epoch: 10 [7680/10619 (72%)]\tLoss: 0.151743\n",
      "Train Epoch: 10 [8320/10619 (78%)]\tLoss: 0.072892\n",
      "Train Epoch: 10 [8960/10619 (84%)]\tLoss: 0.022861\n",
      "Train Epoch: 10 [9600/10619 (90%)]\tLoss: 0.057277\n",
      "Train Epoch: 10 [10240/10619 (96%)]\tLoss: 0.065716\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/15392 (0%)]\tLoss: 0.061500\n",
      "Train Epoch: 1 [640/15392 (4%)]\tLoss: 0.082515\n",
      "Train Epoch: 1 [1280/15392 (8%)]\tLoss: 0.064912\n",
      "Train Epoch: 1 [1920/15392 (12%)]\tLoss: 0.007696\n",
      "Train Epoch: 1 [2560/15392 (17%)]\tLoss: 0.228601\n",
      "Train Epoch: 1 [3200/15392 (21%)]\tLoss: 0.072447\n",
      "Train Epoch: 1 [3840/15392 (25%)]\tLoss: 0.172272\n",
      "Train Epoch: 1 [4480/15392 (29%)]\tLoss: 0.064563\n",
      "Train Epoch: 1 [5120/15392 (33%)]\tLoss: 0.011432\n",
      "Train Epoch: 1 [5760/15392 (37%)]\tLoss: 0.069798\n",
      "Train Epoch: 1 [6400/15392 (41%)]\tLoss: 0.280786\n",
      "Train Epoch: 1 [7040/15392 (46%)]\tLoss: 0.006482\n",
      "Train Epoch: 1 [7680/15392 (50%)]\tLoss: 0.083859\n",
      "Train Epoch: 1 [8320/15392 (54%)]\tLoss: 0.077687\n",
      "Train Epoch: 1 [8960/15392 (58%)]\tLoss: 0.055124\n",
      "Train Epoch: 1 [9600/15392 (62%)]\tLoss: 0.011592\n",
      "Train Epoch: 1 [10240/15392 (66%)]\tLoss: 0.125483\n",
      "Train Epoch: 1 [10880/15392 (71%)]\tLoss: 0.027276\n",
      "Train Epoch: 1 [11520/15392 (75%)]\tLoss: 0.080476\n",
      "Train Epoch: 1 [12160/15392 (79%)]\tLoss: 0.038366\n",
      "Train Epoch: 1 [12800/15392 (83%)]\tLoss: 0.018617\n",
      "Train Epoch: 1 [13440/15392 (87%)]\tLoss: 0.025920\n",
      "Train Epoch: 1 [14080/15392 (91%)]\tLoss: 0.026777\n",
      "Train Epoch: 1 [14720/15392 (95%)]\tLoss: 0.046149\n",
      "Train Epoch: 1 [7680/15392 (100%)]\tLoss: 0.133203\n",
      "Train Epoch: 2 [0/15392 (0%)]\tLoss: 0.105016\n",
      "Train Epoch: 2 [640/15392 (4%)]\tLoss: 0.043266\n",
      "Train Epoch: 2 [1280/15392 (8%)]\tLoss: 0.013258\n",
      "Train Epoch: 2 [1920/15392 (12%)]\tLoss: 0.013456\n",
      "Train Epoch: 2 [2560/15392 (17%)]\tLoss: 0.031871\n",
      "Train Epoch: 2 [3200/15392 (21%)]\tLoss: 0.016055\n",
      "Train Epoch: 2 [3840/15392 (25%)]\tLoss: 0.052733\n",
      "Train Epoch: 2 [4480/15392 (29%)]\tLoss: 0.031721\n",
      "Train Epoch: 2 [5120/15392 (33%)]\tLoss: 0.037492\n",
      "Train Epoch: 2 [5760/15392 (37%)]\tLoss: 0.045972\n",
      "Train Epoch: 2 [6400/15392 (41%)]\tLoss: 0.049516\n",
      "Train Epoch: 2 [7040/15392 (46%)]\tLoss: 0.071364\n",
      "Train Epoch: 2 [7680/15392 (50%)]\tLoss: 0.025463\n",
      "Train Epoch: 2 [8320/15392 (54%)]\tLoss: 0.042353\n",
      "Train Epoch: 2 [8960/15392 (58%)]\tLoss: 0.104949\n",
      "Train Epoch: 2 [9600/15392 (62%)]\tLoss: 0.092839\n",
      "Train Epoch: 2 [10240/15392 (66%)]\tLoss: 0.111437\n",
      "Train Epoch: 2 [10880/15392 (71%)]\tLoss: 0.119226\n",
      "Train Epoch: 2 [11520/15392 (75%)]\tLoss: 0.022712\n",
      "Train Epoch: 2 [12160/15392 (79%)]\tLoss: 0.082537\n",
      "Train Epoch: 2 [12800/15392 (83%)]\tLoss: 0.007776\n",
      "Train Epoch: 2 [13440/15392 (87%)]\tLoss: 0.088418\n",
      "Train Epoch: 2 [14080/15392 (91%)]\tLoss: 0.033835\n",
      "Train Epoch: 2 [14720/15392 (95%)]\tLoss: 0.123213\n",
      "Train Epoch: 2 [7680/15392 (100%)]\tLoss: 0.022911\n",
      "Train Epoch: 3 [0/15392 (0%)]\tLoss: 0.016026\n",
      "Train Epoch: 3 [640/15392 (4%)]\tLoss: 0.045247\n",
      "Train Epoch: 3 [1280/15392 (8%)]\tLoss: 0.008896\n",
      "Train Epoch: 3 [1920/15392 (12%)]\tLoss: 0.074188\n",
      "Train Epoch: 3 [2560/15392 (17%)]\tLoss: 0.053066\n",
      "Train Epoch: 3 [3200/15392 (21%)]\tLoss: 0.060432\n",
      "Train Epoch: 3 [3840/15392 (25%)]\tLoss: 0.059714\n",
      "Train Epoch: 3 [4480/15392 (29%)]\tLoss: 0.011841\n",
      "Train Epoch: 3 [5120/15392 (33%)]\tLoss: 0.060055\n",
      "Train Epoch: 3 [5760/15392 (37%)]\tLoss: 0.103233\n",
      "Train Epoch: 3 [6400/15392 (41%)]\tLoss: 0.093078\n",
      "Train Epoch: 3 [7040/15392 (46%)]\tLoss: 0.164455\n",
      "Train Epoch: 3 [7680/15392 (50%)]\tLoss: 0.035339\n",
      "Train Epoch: 3 [8320/15392 (54%)]\tLoss: 0.051363\n",
      "Train Epoch: 3 [8960/15392 (58%)]\tLoss: 0.006438\n",
      "Train Epoch: 3 [9600/15392 (62%)]\tLoss: 0.154571\n",
      "Train Epoch: 3 [10240/15392 (66%)]\tLoss: 0.124659\n",
      "Train Epoch: 3 [10880/15392 (71%)]\tLoss: 0.167714\n",
      "Train Epoch: 3 [11520/15392 (75%)]\tLoss: 0.007112\n",
      "Train Epoch: 3 [12160/15392 (79%)]\tLoss: 0.038599\n",
      "Train Epoch: 3 [12800/15392 (83%)]\tLoss: 0.099090\n",
      "Train Epoch: 3 [13440/15392 (87%)]\tLoss: 0.019551\n",
      "Train Epoch: 3 [14080/15392 (91%)]\tLoss: 0.073846\n",
      "Train Epoch: 3 [14720/15392 (95%)]\tLoss: 0.034794\n",
      "Train Epoch: 3 [7680/15392 (100%)]\tLoss: 0.220910\n",
      "Train Epoch: 4 [0/15392 (0%)]\tLoss: 0.197237\n",
      "Train Epoch: 4 [640/15392 (4%)]\tLoss: 0.045495\n",
      "Train Epoch: 4 [1280/15392 (8%)]\tLoss: 0.092754\n",
      "Train Epoch: 4 [1920/15392 (12%)]\tLoss: 0.014215\n",
      "Train Epoch: 4 [2560/15392 (17%)]\tLoss: 0.018270\n",
      "Train Epoch: 4 [3200/15392 (21%)]\tLoss: 0.029238\n",
      "Train Epoch: 4 [3840/15392 (25%)]\tLoss: 0.016002\n",
      "Train Epoch: 4 [4480/15392 (29%)]\tLoss: 0.012456\n",
      "Train Epoch: 4 [5120/15392 (33%)]\tLoss: 0.050429\n",
      "Train Epoch: 4 [5760/15392 (37%)]\tLoss: 0.211226\n",
      "Train Epoch: 4 [6400/15392 (41%)]\tLoss: 0.053804\n",
      "Train Epoch: 4 [7040/15392 (46%)]\tLoss: 0.097947\n",
      "Train Epoch: 4 [7680/15392 (50%)]\tLoss: 0.096503\n",
      "Train Epoch: 4 [8320/15392 (54%)]\tLoss: 0.066985\n",
      "Train Epoch: 4 [8960/15392 (58%)]\tLoss: 0.062491\n",
      "Train Epoch: 4 [9600/15392 (62%)]\tLoss: 0.026813\n",
      "Train Epoch: 4 [10240/15392 (66%)]\tLoss: 0.017097\n",
      "Train Epoch: 4 [10880/15392 (71%)]\tLoss: 0.010253\n",
      "Train Epoch: 4 [11520/15392 (75%)]\tLoss: 0.161657\n",
      "Train Epoch: 4 [12160/15392 (79%)]\tLoss: 0.134655\n",
      "Train Epoch: 4 [12800/15392 (83%)]\tLoss: 0.030452\n",
      "Train Epoch: 4 [13440/15392 (87%)]\tLoss: 0.043526\n",
      "Train Epoch: 4 [14080/15392 (91%)]\tLoss: 0.019044\n",
      "Train Epoch: 4 [14720/15392 (95%)]\tLoss: 0.046558\n",
      "Train Epoch: 4 [7680/15392 (100%)]\tLoss: 0.011909\n",
      "Train Epoch: 5 [0/15392 (0%)]\tLoss: 0.049778\n",
      "Train Epoch: 5 [640/15392 (4%)]\tLoss: 0.090829\n",
      "Train Epoch: 5 [1280/15392 (8%)]\tLoss: 0.040107\n",
      "Train Epoch: 5 [1920/15392 (12%)]\tLoss: 0.022081\n",
      "Train Epoch: 5 [2560/15392 (17%)]\tLoss: 0.061592\n",
      "Train Epoch: 5 [3200/15392 (21%)]\tLoss: 0.031097\n",
      "Train Epoch: 5 [3840/15392 (25%)]\tLoss: 0.050567\n",
      "Train Epoch: 5 [4480/15392 (29%)]\tLoss: 0.055221\n",
      "Train Epoch: 5 [5120/15392 (33%)]\tLoss: 0.041054\n",
      "Train Epoch: 5 [5760/15392 (37%)]\tLoss: 0.020796\n",
      "Train Epoch: 5 [6400/15392 (41%)]\tLoss: 0.025865\n",
      "Train Epoch: 5 [7040/15392 (46%)]\tLoss: 0.053885\n",
      "Train Epoch: 5 [7680/15392 (50%)]\tLoss: 0.213012\n",
      "Train Epoch: 5 [8320/15392 (54%)]\tLoss: 0.022459\n",
      "Train Epoch: 5 [8960/15392 (58%)]\tLoss: 0.057803\n",
      "Train Epoch: 5 [9600/15392 (62%)]\tLoss: 0.060515\n",
      "Train Epoch: 5 [10240/15392 (66%)]\tLoss: 0.021400\n",
      "Train Epoch: 5 [10880/15392 (71%)]\tLoss: 0.024129\n",
      "Train Epoch: 5 [11520/15392 (75%)]\tLoss: 0.013445\n",
      "Train Epoch: 5 [12160/15392 (79%)]\tLoss: 0.087753\n",
      "Train Epoch: 5 [12800/15392 (83%)]\tLoss: 0.010796\n",
      "Train Epoch: 5 [13440/15392 (87%)]\tLoss: 0.060841\n",
      "Train Epoch: 5 [14080/15392 (91%)]\tLoss: 0.082747\n",
      "Train Epoch: 5 [14720/15392 (95%)]\tLoss: 0.094056\n",
      "Train Epoch: 5 [7680/15392 (100%)]\tLoss: 0.035114\n",
      "Train Epoch: 6 [0/15392 (0%)]\tLoss: 0.030954\n",
      "Train Epoch: 6 [640/15392 (4%)]\tLoss: 0.071985\n",
      "Train Epoch: 6 [1280/15392 (8%)]\tLoss: 0.030910\n",
      "Train Epoch: 6 [1920/15392 (12%)]\tLoss: 0.005163\n",
      "Train Epoch: 6 [2560/15392 (17%)]\tLoss: 0.086201\n",
      "Train Epoch: 6 [3200/15392 (21%)]\tLoss: 0.018998\n",
      "Train Epoch: 6 [3840/15392 (25%)]\tLoss: 0.008884\n",
      "Train Epoch: 6 [4480/15392 (29%)]\tLoss: 0.041819\n",
      "Train Epoch: 6 [5120/15392 (33%)]\tLoss: 0.122419\n",
      "Train Epoch: 6 [5760/15392 (37%)]\tLoss: 0.160373\n",
      "Train Epoch: 6 [6400/15392 (41%)]\tLoss: 0.174576\n",
      "Train Epoch: 6 [7040/15392 (46%)]\tLoss: 0.026146\n",
      "Train Epoch: 6 [7680/15392 (50%)]\tLoss: 0.027590\n",
      "Train Epoch: 6 [8320/15392 (54%)]\tLoss: 0.008995\n",
      "Train Epoch: 6 [8960/15392 (58%)]\tLoss: 0.037784\n",
      "Train Epoch: 6 [9600/15392 (62%)]\tLoss: 0.023590\n",
      "Train Epoch: 6 [10240/15392 (66%)]\tLoss: 0.015899\n",
      "Train Epoch: 6 [10880/15392 (71%)]\tLoss: 0.031613\n",
      "Train Epoch: 6 [11520/15392 (75%)]\tLoss: 0.098889\n",
      "Train Epoch: 6 [12160/15392 (79%)]\tLoss: 0.008466\n",
      "Train Epoch: 6 [12800/15392 (83%)]\tLoss: 0.033941\n",
      "Train Epoch: 6 [13440/15392 (87%)]\tLoss: 0.037027\n",
      "Train Epoch: 6 [14080/15392 (91%)]\tLoss: 0.007268\n",
      "Train Epoch: 6 [14720/15392 (95%)]\tLoss: 0.089337\n",
      "Train Epoch: 6 [7680/15392 (100%)]\tLoss: 0.006502\n",
      "Train Epoch: 7 [0/15392 (0%)]\tLoss: 0.066184\n",
      "Train Epoch: 7 [640/15392 (4%)]\tLoss: 0.027608\n",
      "Train Epoch: 7 [1280/15392 (8%)]\tLoss: 0.082906\n",
      "Train Epoch: 7 [1920/15392 (12%)]\tLoss: 0.018247\n",
      "Train Epoch: 7 [2560/15392 (17%)]\tLoss: 0.100021\n",
      "Train Epoch: 7 [3200/15392 (21%)]\tLoss: 0.023592\n",
      "Train Epoch: 7 [3840/15392 (25%)]\tLoss: 0.021874\n",
      "Train Epoch: 7 [4480/15392 (29%)]\tLoss: 0.018872\n",
      "Train Epoch: 7 [5120/15392 (33%)]\tLoss: 0.054650\n",
      "Train Epoch: 7 [5760/15392 (37%)]\tLoss: 0.033412\n",
      "Train Epoch: 7 [6400/15392 (41%)]\tLoss: 0.013567\n",
      "Train Epoch: 7 [7040/15392 (46%)]\tLoss: 0.057192\n",
      "Train Epoch: 7 [7680/15392 (50%)]\tLoss: 0.139318\n",
      "Train Epoch: 7 [8320/15392 (54%)]\tLoss: 0.029869\n",
      "Train Epoch: 7 [8960/15392 (58%)]\tLoss: 0.007475\n",
      "Train Epoch: 7 [9600/15392 (62%)]\tLoss: 0.131117\n",
      "Train Epoch: 7 [10240/15392 (66%)]\tLoss: 0.094924\n",
      "Train Epoch: 7 [10880/15392 (71%)]\tLoss: 0.064695\n",
      "Train Epoch: 7 [11520/15392 (75%)]\tLoss: 0.004053\n",
      "Train Epoch: 7 [12160/15392 (79%)]\tLoss: 0.109169\n",
      "Train Epoch: 7 [12800/15392 (83%)]\tLoss: 0.044377\n",
      "Train Epoch: 7 [13440/15392 (87%)]\tLoss: 0.041768\n",
      "Train Epoch: 7 [14080/15392 (91%)]\tLoss: 0.151738\n",
      "Train Epoch: 7 [14720/15392 (95%)]\tLoss: 0.005772\n",
      "Train Epoch: 7 [7680/15392 (100%)]\tLoss: 0.050161\n",
      "Train Epoch: 8 [0/15392 (0%)]\tLoss: 0.055069\n",
      "Train Epoch: 8 [640/15392 (4%)]\tLoss: 0.047192\n",
      "Train Epoch: 8 [1280/15392 (8%)]\tLoss: 0.003914\n",
      "Train Epoch: 8 [1920/15392 (12%)]\tLoss: 0.014316\n",
      "Train Epoch: 8 [2560/15392 (17%)]\tLoss: 0.024543\n",
      "Train Epoch: 8 [3200/15392 (21%)]\tLoss: 0.140847\n",
      "Train Epoch: 8 [3840/15392 (25%)]\tLoss: 0.033265\n",
      "Train Epoch: 8 [4480/15392 (29%)]\tLoss: 0.068209\n",
      "Train Epoch: 8 [5120/15392 (33%)]\tLoss: 0.130190\n",
      "Train Epoch: 8 [5760/15392 (37%)]\tLoss: 0.024480\n",
      "Train Epoch: 8 [6400/15392 (41%)]\tLoss: 0.026369\n",
      "Train Epoch: 8 [7040/15392 (46%)]\tLoss: 0.025984\n",
      "Train Epoch: 8 [7680/15392 (50%)]\tLoss: 0.014151\n",
      "Train Epoch: 8 [8320/15392 (54%)]\tLoss: 0.043123\n",
      "Train Epoch: 8 [8960/15392 (58%)]\tLoss: 0.030733\n",
      "Train Epoch: 8 [9600/15392 (62%)]\tLoss: 0.080295\n",
      "Train Epoch: 8 [10240/15392 (66%)]\tLoss: 0.080962\n",
      "Train Epoch: 8 [10880/15392 (71%)]\tLoss: 0.008398\n",
      "Train Epoch: 8 [11520/15392 (75%)]\tLoss: 0.031851\n",
      "Train Epoch: 8 [12160/15392 (79%)]\tLoss: 0.104724\n",
      "Train Epoch: 8 [12800/15392 (83%)]\tLoss: 0.006530\n",
      "Train Epoch: 8 [13440/15392 (87%)]\tLoss: 0.014612\n",
      "Train Epoch: 8 [14080/15392 (91%)]\tLoss: 0.103159\n",
      "Train Epoch: 8 [14720/15392 (95%)]\tLoss: 0.061985\n",
      "Train Epoch: 8 [7680/15392 (100%)]\tLoss: 0.016319\n",
      "Train Epoch: 9 [0/15392 (0%)]\tLoss: 0.013848\n",
      "Train Epoch: 9 [640/15392 (4%)]\tLoss: 0.008209\n",
      "Train Epoch: 9 [1280/15392 (8%)]\tLoss: 0.076389\n",
      "Train Epoch: 9 [1920/15392 (12%)]\tLoss: 0.067044\n",
      "Train Epoch: 9 [2560/15392 (17%)]\tLoss: 0.045465\n",
      "Train Epoch: 9 [3200/15392 (21%)]\tLoss: 0.029002\n",
      "Train Epoch: 9 [3840/15392 (25%)]\tLoss: 0.018035\n",
      "Train Epoch: 9 [4480/15392 (29%)]\tLoss: 0.019096\n",
      "Train Epoch: 9 [5120/15392 (33%)]\tLoss: 0.026147\n",
      "Train Epoch: 9 [5760/15392 (37%)]\tLoss: 0.016003\n",
      "Train Epoch: 9 [6400/15392 (41%)]\tLoss: 0.074111\n",
      "Train Epoch: 9 [7040/15392 (46%)]\tLoss: 0.164758\n",
      "Train Epoch: 9 [7680/15392 (50%)]\tLoss: 0.018239\n",
      "Train Epoch: 9 [8320/15392 (54%)]\tLoss: 0.007862\n",
      "Train Epoch: 9 [8960/15392 (58%)]\tLoss: 0.041937\n",
      "Train Epoch: 9 [9600/15392 (62%)]\tLoss: 0.044570\n",
      "Train Epoch: 9 [10240/15392 (66%)]\tLoss: 0.156268\n",
      "Train Epoch: 9 [10880/15392 (71%)]\tLoss: 0.026699\n",
      "Train Epoch: 9 [11520/15392 (75%)]\tLoss: 0.005279\n",
      "Train Epoch: 9 [12160/15392 (79%)]\tLoss: 0.022836\n",
      "Train Epoch: 9 [12800/15392 (83%)]\tLoss: 0.035479\n",
      "Train Epoch: 9 [13440/15392 (87%)]\tLoss: 0.074543\n",
      "Train Epoch: 9 [14080/15392 (91%)]\tLoss: 0.055345\n",
      "Train Epoch: 9 [14720/15392 (95%)]\tLoss: 0.022707\n",
      "Train Epoch: 9 [7680/15392 (100%)]\tLoss: 0.108068\n",
      "Train Epoch: 10 [0/15392 (0%)]\tLoss: 0.036096\n",
      "Train Epoch: 10 [640/15392 (4%)]\tLoss: 0.017355\n",
      "Train Epoch: 10 [1280/15392 (8%)]\tLoss: 0.045329\n",
      "Train Epoch: 10 [1920/15392 (12%)]\tLoss: 0.030249\n",
      "Train Epoch: 10 [2560/15392 (17%)]\tLoss: 0.073947\n",
      "Train Epoch: 10 [3200/15392 (21%)]\tLoss: 0.012938\n",
      "Train Epoch: 10 [3840/15392 (25%)]\tLoss: 0.016551\n",
      "Train Epoch: 10 [4480/15392 (29%)]\tLoss: 0.067869\n",
      "Train Epoch: 10 [5120/15392 (33%)]\tLoss: 0.020867\n",
      "Train Epoch: 10 [5760/15392 (37%)]\tLoss: 0.055776\n",
      "Train Epoch: 10 [6400/15392 (41%)]\tLoss: 0.038960\n",
      "Train Epoch: 10 [7040/15392 (46%)]\tLoss: 0.025234\n",
      "Train Epoch: 10 [7680/15392 (50%)]\tLoss: 0.036077\n",
      "Train Epoch: 10 [8320/15392 (54%)]\tLoss: 0.050005\n",
      "Train Epoch: 10 [8960/15392 (58%)]\tLoss: 0.036415\n",
      "Train Epoch: 10 [9600/15392 (62%)]\tLoss: 0.009887\n",
      "Train Epoch: 10 [10240/15392 (66%)]\tLoss: 0.127852\n",
      "Train Epoch: 10 [10880/15392 (71%)]\tLoss: 0.070200\n",
      "Train Epoch: 10 [11520/15392 (75%)]\tLoss: 0.016755\n",
      "Train Epoch: 10 [12160/15392 (79%)]\tLoss: 0.134193\n",
      "Train Epoch: 10 [12800/15392 (83%)]\tLoss: 0.043864\n",
      "Train Epoch: 10 [13440/15392 (87%)]\tLoss: 0.194829\n",
      "Train Epoch: 10 [14080/15392 (91%)]\tLoss: 0.007788\n",
      "Train Epoch: 10 [14720/15392 (95%)]\tLoss: 0.016287\n",
      "Train Epoch: 10 [7680/15392 (100%)]\tLoss: 0.164049\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/15327 (0%)]\tLoss: 0.049081\n",
      "Train Epoch: 1 [640/15327 (4%)]\tLoss: 0.037210\n",
      "Train Epoch: 1 [1280/15327 (8%)]\tLoss: 0.044341\n",
      "Train Epoch: 1 [1920/15327 (12%)]\tLoss: 0.066777\n",
      "Train Epoch: 1 [2560/15327 (17%)]\tLoss: 0.164834\n",
      "Train Epoch: 1 [3200/15327 (21%)]\tLoss: 0.132526\n",
      "Train Epoch: 1 [3840/15327 (25%)]\tLoss: 0.031867\n",
      "Train Epoch: 1 [4480/15327 (29%)]\tLoss: 0.032722\n",
      "Train Epoch: 1 [5120/15327 (33%)]\tLoss: 0.191080\n",
      "Train Epoch: 1 [5760/15327 (38%)]\tLoss: 0.034215\n",
      "Train Epoch: 1 [6400/15327 (42%)]\tLoss: 0.133033\n",
      "Train Epoch: 1 [7040/15327 (46%)]\tLoss: 0.049368\n",
      "Train Epoch: 1 [7680/15327 (50%)]\tLoss: 0.063290\n",
      "Train Epoch: 1 [8320/15327 (54%)]\tLoss: 0.126318\n",
      "Train Epoch: 1 [8960/15327 (58%)]\tLoss: 0.040902\n",
      "Train Epoch: 1 [9600/15327 (62%)]\tLoss: 0.020652\n",
      "Train Epoch: 1 [10240/15327 (67%)]\tLoss: 0.057981\n",
      "Train Epoch: 1 [10880/15327 (71%)]\tLoss: 0.043599\n",
      "Train Epoch: 1 [11520/15327 (75%)]\tLoss: 0.038800\n",
      "Train Epoch: 1 [12160/15327 (79%)]\tLoss: 0.044660\n",
      "Train Epoch: 1 [12800/15327 (83%)]\tLoss: 0.052989\n",
      "Train Epoch: 1 [13440/15327 (88%)]\tLoss: 0.037240\n",
      "Train Epoch: 1 [14080/15327 (92%)]\tLoss: 0.085404\n",
      "Train Epoch: 1 [14720/15327 (96%)]\tLoss: 0.109176\n",
      "Train Epoch: 2 [0/15327 (0%)]\tLoss: 0.044875\n",
      "Train Epoch: 2 [640/15327 (4%)]\tLoss: 0.056238\n",
      "Train Epoch: 2 [1280/15327 (8%)]\tLoss: 0.020188\n",
      "Train Epoch: 2 [1920/15327 (12%)]\tLoss: 0.019830\n",
      "Train Epoch: 2 [2560/15327 (17%)]\tLoss: 0.179157\n",
      "Train Epoch: 2 [3200/15327 (21%)]\tLoss: 0.108268\n",
      "Train Epoch: 2 [3840/15327 (25%)]\tLoss: 0.083798\n",
      "Train Epoch: 2 [4480/15327 (29%)]\tLoss: 0.053921\n",
      "Train Epoch: 2 [5120/15327 (33%)]\tLoss: 0.024861\n",
      "Train Epoch: 2 [5760/15327 (38%)]\tLoss: 0.115676\n",
      "Train Epoch: 2 [6400/15327 (42%)]\tLoss: 0.100523\n",
      "Train Epoch: 2 [7040/15327 (46%)]\tLoss: 0.090377\n",
      "Train Epoch: 2 [7680/15327 (50%)]\tLoss: 0.026589\n",
      "Train Epoch: 2 [8320/15327 (54%)]\tLoss: 0.092449\n",
      "Train Epoch: 2 [8960/15327 (58%)]\tLoss: 0.040461\n",
      "Train Epoch: 2 [9600/15327 (62%)]\tLoss: 0.063944\n",
      "Train Epoch: 2 [10240/15327 (67%)]\tLoss: 0.029720\n",
      "Train Epoch: 2 [10880/15327 (71%)]\tLoss: 0.012224\n",
      "Train Epoch: 2 [11520/15327 (75%)]\tLoss: 0.112902\n",
      "Train Epoch: 2 [12160/15327 (79%)]\tLoss: 0.068761\n",
      "Train Epoch: 2 [12800/15327 (83%)]\tLoss: 0.036695\n",
      "Train Epoch: 2 [13440/15327 (88%)]\tLoss: 0.182982\n",
      "Train Epoch: 2 [14080/15327 (92%)]\tLoss: 0.050686\n",
      "Train Epoch: 2 [14720/15327 (96%)]\tLoss: 0.088892\n",
      "Train Epoch: 3 [0/15327 (0%)]\tLoss: 0.158896\n",
      "Train Epoch: 3 [640/15327 (4%)]\tLoss: 0.026703\n",
      "Train Epoch: 3 [1280/15327 (8%)]\tLoss: 0.089356\n",
      "Train Epoch: 3 [1920/15327 (12%)]\tLoss: 0.086840\n",
      "Train Epoch: 3 [2560/15327 (17%)]\tLoss: 0.006209\n",
      "Train Epoch: 3 [3200/15327 (21%)]\tLoss: 0.165789\n",
      "Train Epoch: 3 [3840/15327 (25%)]\tLoss: 0.163613\n",
      "Train Epoch: 3 [4480/15327 (29%)]\tLoss: 0.026752\n",
      "Train Epoch: 3 [5120/15327 (33%)]\tLoss: 0.037550\n",
      "Train Epoch: 3 [5760/15327 (38%)]\tLoss: 0.050647\n",
      "Train Epoch: 3 [6400/15327 (42%)]\tLoss: 0.041920\n",
      "Train Epoch: 3 [7040/15327 (46%)]\tLoss: 0.017053\n",
      "Train Epoch: 3 [7680/15327 (50%)]\tLoss: 0.087946\n",
      "Train Epoch: 3 [8320/15327 (54%)]\tLoss: 0.195787\n",
      "Train Epoch: 3 [8960/15327 (58%)]\tLoss: 0.078916\n",
      "Train Epoch: 3 [9600/15327 (62%)]\tLoss: 0.046172\n",
      "Train Epoch: 3 [10240/15327 (67%)]\tLoss: 0.006205\n",
      "Train Epoch: 3 [10880/15327 (71%)]\tLoss: 0.085374\n",
      "Train Epoch: 3 [11520/15327 (75%)]\tLoss: 0.123917\n",
      "Train Epoch: 3 [12160/15327 (79%)]\tLoss: 0.042223\n",
      "Train Epoch: 3 [12800/15327 (83%)]\tLoss: 0.033462\n",
      "Train Epoch: 3 [13440/15327 (88%)]\tLoss: 0.043652\n",
      "Train Epoch: 3 [14080/15327 (92%)]\tLoss: 0.099034\n",
      "Train Epoch: 3 [14720/15327 (96%)]\tLoss: 0.079531\n",
      "Train Epoch: 4 [0/15327 (0%)]\tLoss: 0.059684\n",
      "Train Epoch: 4 [640/15327 (4%)]\tLoss: 0.062105\n",
      "Train Epoch: 4 [1280/15327 (8%)]\tLoss: 0.071799\n",
      "Train Epoch: 4 [1920/15327 (12%)]\tLoss: 0.017194\n",
      "Train Epoch: 4 [2560/15327 (17%)]\tLoss: 0.071511\n",
      "Train Epoch: 4 [3200/15327 (21%)]\tLoss: 0.049243\n",
      "Train Epoch: 4 [3840/15327 (25%)]\tLoss: 0.020304\n",
      "Train Epoch: 4 [4480/15327 (29%)]\tLoss: 0.070533\n",
      "Train Epoch: 4 [5120/15327 (33%)]\tLoss: 0.032970\n",
      "Train Epoch: 4 [5760/15327 (38%)]\tLoss: 0.165604\n",
      "Train Epoch: 4 [6400/15327 (42%)]\tLoss: 0.025523\n",
      "Train Epoch: 4 [7040/15327 (46%)]\tLoss: 0.189960\n",
      "Train Epoch: 4 [7680/15327 (50%)]\tLoss: 0.089972\n",
      "Train Epoch: 4 [8320/15327 (54%)]\tLoss: 0.052914\n",
      "Train Epoch: 4 [8960/15327 (58%)]\tLoss: 0.105857\n",
      "Train Epoch: 4 [9600/15327 (62%)]\tLoss: 0.063612\n",
      "Train Epoch: 4 [10240/15327 (67%)]\tLoss: 0.013864\n",
      "Train Epoch: 4 [10880/15327 (71%)]\tLoss: 0.077823\n",
      "Train Epoch: 4 [11520/15327 (75%)]\tLoss: 0.106252\n",
      "Train Epoch: 4 [12160/15327 (79%)]\tLoss: 0.060401\n",
      "Train Epoch: 4 [12800/15327 (83%)]\tLoss: 0.049523\n",
      "Train Epoch: 4 [13440/15327 (88%)]\tLoss: 0.050978\n",
      "Train Epoch: 4 [14080/15327 (92%)]\tLoss: 0.025490\n",
      "Train Epoch: 4 [14720/15327 (96%)]\tLoss: 0.193912\n",
      "Train Epoch: 5 [0/15327 (0%)]\tLoss: 0.062445\n",
      "Train Epoch: 5 [640/15327 (4%)]\tLoss: 0.103371\n",
      "Train Epoch: 5 [1280/15327 (8%)]\tLoss: 0.126417\n",
      "Train Epoch: 5 [1920/15327 (12%)]\tLoss: 0.039698\n",
      "Train Epoch: 5 [2560/15327 (17%)]\tLoss: 0.079372\n",
      "Train Epoch: 5 [3200/15327 (21%)]\tLoss: 0.079258\n",
      "Train Epoch: 5 [3840/15327 (25%)]\tLoss: 0.101866\n",
      "Train Epoch: 5 [4480/15327 (29%)]\tLoss: 0.112265\n",
      "Train Epoch: 5 [5120/15327 (33%)]\tLoss: 0.017664\n",
      "Train Epoch: 5 [5760/15327 (38%)]\tLoss: 0.014356\n",
      "Train Epoch: 5 [6400/15327 (42%)]\tLoss: 0.011817\n",
      "Train Epoch: 5 [7040/15327 (46%)]\tLoss: 0.036001\n",
      "Train Epoch: 5 [7680/15327 (50%)]\tLoss: 0.032251\n",
      "Train Epoch: 5 [8320/15327 (54%)]\tLoss: 0.013785\n",
      "Train Epoch: 5 [8960/15327 (58%)]\tLoss: 0.047602\n",
      "Train Epoch: 5 [9600/15327 (62%)]\tLoss: 0.090202\n",
      "Train Epoch: 5 [10240/15327 (67%)]\tLoss: 0.020802\n",
      "Train Epoch: 5 [10880/15327 (71%)]\tLoss: 0.059128\n",
      "Train Epoch: 5 [11520/15327 (75%)]\tLoss: 0.058339\n",
      "Train Epoch: 5 [12160/15327 (79%)]\tLoss: 0.035071\n",
      "Train Epoch: 5 [12800/15327 (83%)]\tLoss: 0.017229\n",
      "Train Epoch: 5 [13440/15327 (88%)]\tLoss: 0.085670\n",
      "Train Epoch: 5 [14080/15327 (92%)]\tLoss: 0.052446\n",
      "Train Epoch: 5 [14720/15327 (96%)]\tLoss: 0.104793\n",
      "Train Epoch: 6 [0/15327 (0%)]\tLoss: 0.122642\n",
      "Train Epoch: 6 [640/15327 (4%)]\tLoss: 0.096482\n",
      "Train Epoch: 6 [1280/15327 (8%)]\tLoss: 0.031433\n",
      "Train Epoch: 6 [1920/15327 (12%)]\tLoss: 0.116020\n",
      "Train Epoch: 6 [2560/15327 (17%)]\tLoss: 0.081224\n",
      "Train Epoch: 6 [3200/15327 (21%)]\tLoss: 0.052721\n",
      "Train Epoch: 6 [3840/15327 (25%)]\tLoss: 0.102976\n",
      "Train Epoch: 6 [4480/15327 (29%)]\tLoss: 0.083399\n",
      "Train Epoch: 6 [5120/15327 (33%)]\tLoss: 0.089142\n",
      "Train Epoch: 6 [5760/15327 (38%)]\tLoss: 0.065859\n",
      "Train Epoch: 6 [6400/15327 (42%)]\tLoss: 0.109403\n",
      "Train Epoch: 6 [7040/15327 (46%)]\tLoss: 0.039671\n",
      "Train Epoch: 6 [7680/15327 (50%)]\tLoss: 0.089108\n",
      "Train Epoch: 6 [8320/15327 (54%)]\tLoss: 0.039274\n",
      "Train Epoch: 6 [8960/15327 (58%)]\tLoss: 0.061302\n",
      "Train Epoch: 6 [9600/15327 (62%)]\tLoss: 0.104904\n",
      "Train Epoch: 6 [10240/15327 (67%)]\tLoss: 0.142028\n",
      "Train Epoch: 6 [10880/15327 (71%)]\tLoss: 0.053092\n",
      "Train Epoch: 6 [11520/15327 (75%)]\tLoss: 0.108576\n",
      "Train Epoch: 6 [12160/15327 (79%)]\tLoss: 0.011095\n",
      "Train Epoch: 6 [12800/15327 (83%)]\tLoss: 0.018566\n",
      "Train Epoch: 6 [13440/15327 (88%)]\tLoss: 0.011232\n",
      "Train Epoch: 6 [14080/15327 (92%)]\tLoss: 0.026833\n",
      "Train Epoch: 6 [14720/15327 (96%)]\tLoss: 0.042213\n",
      "Train Epoch: 7 [0/15327 (0%)]\tLoss: 0.081527\n",
      "Train Epoch: 7 [640/15327 (4%)]\tLoss: 0.093851\n",
      "Train Epoch: 7 [1280/15327 (8%)]\tLoss: 0.019604\n",
      "Train Epoch: 7 [1920/15327 (12%)]\tLoss: 0.012125\n",
      "Train Epoch: 7 [2560/15327 (17%)]\tLoss: 0.083326\n",
      "Train Epoch: 7 [3200/15327 (21%)]\tLoss: 0.041607\n",
      "Train Epoch: 7 [3840/15327 (25%)]\tLoss: 0.168133\n",
      "Train Epoch: 7 [4480/15327 (29%)]\tLoss: 0.028331\n",
      "Train Epoch: 7 [5120/15327 (33%)]\tLoss: 0.027050\n",
      "Train Epoch: 7 [5760/15327 (38%)]\tLoss: 0.053744\n",
      "Train Epoch: 7 [6400/15327 (42%)]\tLoss: 0.006507\n",
      "Train Epoch: 7 [7040/15327 (46%)]\tLoss: 0.088125\n",
      "Train Epoch: 7 [7680/15327 (50%)]\tLoss: 0.078287\n",
      "Train Epoch: 7 [8320/15327 (54%)]\tLoss: 0.113869\n",
      "Train Epoch: 7 [8960/15327 (58%)]\tLoss: 0.071111\n",
      "Train Epoch: 7 [9600/15327 (62%)]\tLoss: 0.019167\n",
      "Train Epoch: 7 [10240/15327 (67%)]\tLoss: 0.008403\n",
      "Train Epoch: 7 [10880/15327 (71%)]\tLoss: 0.030409\n",
      "Train Epoch: 7 [11520/15327 (75%)]\tLoss: 0.178762\n",
      "Train Epoch: 7 [12160/15327 (79%)]\tLoss: 0.013892\n",
      "Train Epoch: 7 [12800/15327 (83%)]\tLoss: 0.068329\n",
      "Train Epoch: 7 [13440/15327 (88%)]\tLoss: 0.025177\n",
      "Train Epoch: 7 [14080/15327 (92%)]\tLoss: 0.035575\n",
      "Train Epoch: 7 [14720/15327 (96%)]\tLoss: 0.040264\n",
      "Train Epoch: 8 [0/15327 (0%)]\tLoss: 0.042243\n",
      "Train Epoch: 8 [640/15327 (4%)]\tLoss: 0.049522\n",
      "Train Epoch: 8 [1280/15327 (8%)]\tLoss: 0.022080\n",
      "Train Epoch: 8 [1920/15327 (12%)]\tLoss: 0.121250\n",
      "Train Epoch: 8 [2560/15327 (17%)]\tLoss: 0.068493\n",
      "Train Epoch: 8 [3200/15327 (21%)]\tLoss: 0.044037\n",
      "Train Epoch: 8 [3840/15327 (25%)]\tLoss: 0.016987\n",
      "Train Epoch: 8 [4480/15327 (29%)]\tLoss: 0.008666\n",
      "Train Epoch: 8 [5120/15327 (33%)]\tLoss: 0.006380\n",
      "Train Epoch: 8 [5760/15327 (38%)]\tLoss: 0.219303\n",
      "Train Epoch: 8 [6400/15327 (42%)]\tLoss: 0.065159\n",
      "Train Epoch: 8 [7040/15327 (46%)]\tLoss: 0.014148\n",
      "Train Epoch: 8 [7680/15327 (50%)]\tLoss: 0.031943\n",
      "Train Epoch: 8 [8320/15327 (54%)]\tLoss: 0.025555\n",
      "Train Epoch: 8 [8960/15327 (58%)]\tLoss: 0.101285\n",
      "Train Epoch: 8 [9600/15327 (62%)]\tLoss: 0.015644\n",
      "Train Epoch: 8 [10240/15327 (67%)]\tLoss: 0.017364\n",
      "Train Epoch: 8 [10880/15327 (71%)]\tLoss: 0.079683\n",
      "Train Epoch: 8 [11520/15327 (75%)]\tLoss: 0.050583\n",
      "Train Epoch: 8 [12160/15327 (79%)]\tLoss: 0.037946\n",
      "Train Epoch: 8 [12800/15327 (83%)]\tLoss: 0.059441\n",
      "Train Epoch: 8 [13440/15327 (88%)]\tLoss: 0.026458\n",
      "Train Epoch: 8 [14080/15327 (92%)]\tLoss: 0.174880\n",
      "Train Epoch: 8 [14720/15327 (96%)]\tLoss: 0.055368\n",
      "Train Epoch: 9 [0/15327 (0%)]\tLoss: 0.071935\n",
      "Train Epoch: 9 [640/15327 (4%)]\tLoss: 0.036272\n",
      "Train Epoch: 9 [1280/15327 (8%)]\tLoss: 0.055063\n",
      "Train Epoch: 9 [1920/15327 (12%)]\tLoss: 0.157050\n",
      "Train Epoch: 9 [2560/15327 (17%)]\tLoss: 0.007770\n",
      "Train Epoch: 9 [3200/15327 (21%)]\tLoss: 0.059313\n",
      "Train Epoch: 9 [3840/15327 (25%)]\tLoss: 0.154293\n",
      "Train Epoch: 9 [4480/15327 (29%)]\tLoss: 0.041223\n",
      "Train Epoch: 9 [5120/15327 (33%)]\tLoss: 0.022303\n",
      "Train Epoch: 9 [5760/15327 (38%)]\tLoss: 0.109447\n",
      "Train Epoch: 9 [6400/15327 (42%)]\tLoss: 0.100715\n",
      "Train Epoch: 9 [7040/15327 (46%)]\tLoss: 0.052919\n",
      "Train Epoch: 9 [7680/15327 (50%)]\tLoss: 0.044356\n",
      "Train Epoch: 9 [8320/15327 (54%)]\tLoss: 0.070964\n",
      "Train Epoch: 9 [8960/15327 (58%)]\tLoss: 0.016463\n",
      "Train Epoch: 9 [9600/15327 (62%)]\tLoss: 0.038016\n",
      "Train Epoch: 9 [10240/15327 (67%)]\tLoss: 0.182016\n",
      "Train Epoch: 9 [10880/15327 (71%)]\tLoss: 0.157328\n",
      "Train Epoch: 9 [11520/15327 (75%)]\tLoss: 0.287397\n",
      "Train Epoch: 9 [12160/15327 (79%)]\tLoss: 0.107945\n",
      "Train Epoch: 9 [12800/15327 (83%)]\tLoss: 0.008556\n",
      "Train Epoch: 9 [13440/15327 (88%)]\tLoss: 0.048258\n",
      "Train Epoch: 9 [14080/15327 (92%)]\tLoss: 0.036957\n",
      "Train Epoch: 9 [14720/15327 (96%)]\tLoss: 0.069745\n",
      "Train Epoch: 10 [0/15327 (0%)]\tLoss: 0.017552\n",
      "Train Epoch: 10 [640/15327 (4%)]\tLoss: 0.108333\n",
      "Train Epoch: 10 [1280/15327 (8%)]\tLoss: 0.018711\n",
      "Train Epoch: 10 [1920/15327 (12%)]\tLoss: 0.030513\n",
      "Train Epoch: 10 [2560/15327 (17%)]\tLoss: 0.035140\n",
      "Train Epoch: 10 [3200/15327 (21%)]\tLoss: 0.045995\n",
      "Train Epoch: 10 [3840/15327 (25%)]\tLoss: 0.073202\n",
      "Train Epoch: 10 [4480/15327 (29%)]\tLoss: 0.069027\n",
      "Train Epoch: 10 [5120/15327 (33%)]\tLoss: 0.088828\n",
      "Train Epoch: 10 [5760/15327 (38%)]\tLoss: 0.075288\n",
      "Train Epoch: 10 [6400/15327 (42%)]\tLoss: 0.049674\n",
      "Train Epoch: 10 [7040/15327 (46%)]\tLoss: 0.029560\n",
      "Train Epoch: 10 [7680/15327 (50%)]\tLoss: 0.076659\n",
      "Train Epoch: 10 [8320/15327 (54%)]\tLoss: 0.062211\n",
      "Train Epoch: 10 [8960/15327 (58%)]\tLoss: 0.134197\n",
      "Train Epoch: 10 [9600/15327 (62%)]\tLoss: 0.001132\n",
      "Train Epoch: 10 [10240/15327 (67%)]\tLoss: 0.026075\n",
      "Train Epoch: 10 [10880/15327 (71%)]\tLoss: 0.076235\n",
      "Train Epoch: 10 [11520/15327 (75%)]\tLoss: 0.039349\n",
      "Train Epoch: 10 [12160/15327 (79%)]\tLoss: 0.171001\n",
      "Train Epoch: 10 [12800/15327 (83%)]\tLoss: 0.013296\n",
      "Train Epoch: 10 [13440/15327 (88%)]\tLoss: 0.156354\n",
      "Train Epoch: 10 [14080/15327 (92%)]\tLoss: 0.062485\n",
      "Train Epoch: 10 [14720/15327 (96%)]\tLoss: 0.030485\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.1623, Accuracy: 9872/10000 (99%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 0.081470\n",
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 0.116759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 0.043662\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 0.139474\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 0.090123\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 0.029040\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 0.024319\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 0.081914\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 0.050873\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 0.097477\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 0.059498\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 0.018390\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 0.047026\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 0.040113\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 0.273691\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 0.014002\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 0.079057\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 0.011802\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 0.020637\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 0.014299\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.086523\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 0.096115\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 0.011969\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.012070\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.012991\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 0.062182\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.051868\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 0.027678\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.148756\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.038563\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.029136\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.025235\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.027920\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.093657\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.014468\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.159549\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.083586\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.051492\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.065423\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.103194\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.030681\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.016657\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.027127\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.042039\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.060778\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.074020\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.041621\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.002088\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.036295\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.051453\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.010354\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.125116\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.107084\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.054115\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.128798\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.025810\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.020672\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.007210\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.074010\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.113729\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.050775\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.023598\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.143015\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.084589\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.028831\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.052491\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.068936\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.015376\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.052841\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.071942\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.029137\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.078145\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.078170\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.064412\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.053601\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.143286\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.029306\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.090491\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.013941\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.004526\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.009729\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.012522\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.022346\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.136902\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.030507\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.012969\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.040471\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.094676\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.118919\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.091386\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.016648\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.064281\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.024342\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.127854\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.139994\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.014895\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.017320\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.125417\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.051504\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.191575\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.263616\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.134504\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.088519\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.028255\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.039353\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.033842\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.085515\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.108600\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 0.050114\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.050042\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.151208\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.038086\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.098428\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.052104\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.109670\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.006998\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.009134\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.063371\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.017679\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.070561\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.032645\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.061865\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.102854\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.116252\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.042128\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.004388\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.006741\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.055975\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.089476\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.106494\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.015515\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.025245\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.027453\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.023126\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.056611\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.211612\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.036974\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.223262\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.043732\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.052609\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.067683\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.069665\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.022662\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.011675\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.091885\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.041586\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.004210\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.027430\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.054384\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.054201\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.072427\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.211477\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.011051\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.021863\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.018270\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.008889\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.019198\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.206900\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.034424\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.037360\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.005577\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.030629\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.016499\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.056076\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.066903\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.009093\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.048405\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.059524\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.066775\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.061846\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.059959\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.074467\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.027195\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.006026\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.016973\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.035310\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.123776\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.017348\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.025531\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.052451\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/13906 (0%)]\tLoss: 0.070328\n",
      "Train Epoch: 1 [640/13906 (5%)]\tLoss: 0.109550\n",
      "Train Epoch: 1 [1280/13906 (9%)]\tLoss: 0.018197\n",
      "Train Epoch: 1 [1920/13906 (14%)]\tLoss: 0.149990\n",
      "Train Epoch: 1 [2560/13906 (18%)]\tLoss: 0.044850\n",
      "Train Epoch: 1 [3200/13906 (23%)]\tLoss: 0.037535\n",
      "Train Epoch: 1 [3840/13906 (28%)]\tLoss: 0.074200\n",
      "Train Epoch: 1 [4480/13906 (32%)]\tLoss: 0.133629\n",
      "Train Epoch: 1 [5120/13906 (37%)]\tLoss: 0.015587\n",
      "Train Epoch: 1 [5760/13906 (41%)]\tLoss: 0.036254\n",
      "Train Epoch: 1 [6400/13906 (46%)]\tLoss: 0.041533\n",
      "Train Epoch: 1 [7040/13906 (50%)]\tLoss: 0.033635\n",
      "Train Epoch: 1 [7680/13906 (55%)]\tLoss: 0.098165\n",
      "Train Epoch: 1 [8320/13906 (60%)]\tLoss: 0.115331\n",
      "Train Epoch: 1 [8960/13906 (64%)]\tLoss: 0.033459\n",
      "Train Epoch: 1 [9600/13906 (69%)]\tLoss: 0.073246\n",
      "Train Epoch: 1 [10240/13906 (73%)]\tLoss: 0.041397\n",
      "Train Epoch: 1 [10880/13906 (78%)]\tLoss: 0.226453\n",
      "Train Epoch: 1 [11520/13906 (83%)]\tLoss: 0.017669\n",
      "Train Epoch: 1 [12160/13906 (87%)]\tLoss: 0.031291\n",
      "Train Epoch: 1 [12800/13906 (92%)]\tLoss: 0.019937\n",
      "Train Epoch: 1 [13440/13906 (96%)]\tLoss: 0.077049\n",
      "Train Epoch: 2 [0/13906 (0%)]\tLoss: 0.166156\n",
      "Train Epoch: 2 [640/13906 (5%)]\tLoss: 0.074814\n",
      "Train Epoch: 2 [1280/13906 (9%)]\tLoss: 0.073729\n",
      "Train Epoch: 2 [1920/13906 (14%)]\tLoss: 0.046331\n",
      "Train Epoch: 2 [2560/13906 (18%)]\tLoss: 0.046080\n",
      "Train Epoch: 2 [3200/13906 (23%)]\tLoss: 0.040939\n",
      "Train Epoch: 2 [3840/13906 (28%)]\tLoss: 0.021634\n",
      "Train Epoch: 2 [4480/13906 (32%)]\tLoss: 0.039762\n",
      "Train Epoch: 2 [5120/13906 (37%)]\tLoss: 0.072016\n",
      "Train Epoch: 2 [5760/13906 (41%)]\tLoss: 0.199232\n",
      "Train Epoch: 2 [6400/13906 (46%)]\tLoss: 0.101835\n",
      "Train Epoch: 2 [7040/13906 (50%)]\tLoss: 0.137818\n",
      "Train Epoch: 2 [7680/13906 (55%)]\tLoss: 0.071029\n",
      "Train Epoch: 2 [8320/13906 (60%)]\tLoss: 0.184896\n",
      "Train Epoch: 2 [8960/13906 (64%)]\tLoss: 0.150192\n",
      "Train Epoch: 2 [9600/13906 (69%)]\tLoss: 0.031502\n",
      "Train Epoch: 2 [10240/13906 (73%)]\tLoss: 0.035060\n",
      "Train Epoch: 2 [10880/13906 (78%)]\tLoss: 0.037405\n",
      "Train Epoch: 2 [11520/13906 (83%)]\tLoss: 0.034671\n",
      "Train Epoch: 2 [12160/13906 (87%)]\tLoss: 0.019703\n",
      "Train Epoch: 2 [12800/13906 (92%)]\tLoss: 0.009130\n",
      "Train Epoch: 2 [13440/13906 (96%)]\tLoss: 0.043665\n",
      "Train Epoch: 3 [0/13906 (0%)]\tLoss: 0.055984\n",
      "Train Epoch: 3 [640/13906 (5%)]\tLoss: 0.079395\n",
      "Train Epoch: 3 [1280/13906 (9%)]\tLoss: 0.045914\n",
      "Train Epoch: 3 [1920/13906 (14%)]\tLoss: 0.048768\n",
      "Train Epoch: 3 [2560/13906 (18%)]\tLoss: 0.011646\n",
      "Train Epoch: 3 [3200/13906 (23%)]\tLoss: 0.073589\n",
      "Train Epoch: 3 [3840/13906 (28%)]\tLoss: 0.237945\n",
      "Train Epoch: 3 [4480/13906 (32%)]\tLoss: 0.058721\n",
      "Train Epoch: 3 [5120/13906 (37%)]\tLoss: 0.017455\n",
      "Train Epoch: 3 [5760/13906 (41%)]\tLoss: 0.037538\n",
      "Train Epoch: 3 [6400/13906 (46%)]\tLoss: 0.042221\n",
      "Train Epoch: 3 [7040/13906 (50%)]\tLoss: 0.036030\n",
      "Train Epoch: 3 [7680/13906 (55%)]\tLoss: 0.049651\n",
      "Train Epoch: 3 [8320/13906 (60%)]\tLoss: 0.035601\n",
      "Train Epoch: 3 [8960/13906 (64%)]\tLoss: 0.104660\n",
      "Train Epoch: 3 [9600/13906 (69%)]\tLoss: 0.089772\n",
      "Train Epoch: 3 [10240/13906 (73%)]\tLoss: 0.120497\n",
      "Train Epoch: 3 [10880/13906 (78%)]\tLoss: 0.040795\n",
      "Train Epoch: 3 [11520/13906 (83%)]\tLoss: 0.095586\n",
      "Train Epoch: 3 [12160/13906 (87%)]\tLoss: 0.043973\n",
      "Train Epoch: 3 [12800/13906 (92%)]\tLoss: 0.087042\n",
      "Train Epoch: 3 [13440/13906 (96%)]\tLoss: 0.045607\n",
      "Train Epoch: 4 [0/13906 (0%)]\tLoss: 0.192348\n",
      "Train Epoch: 4 [640/13906 (5%)]\tLoss: 0.009125\n",
      "Train Epoch: 4 [1280/13906 (9%)]\tLoss: 0.025196\n",
      "Train Epoch: 4 [1920/13906 (14%)]\tLoss: 0.015468\n",
      "Train Epoch: 4 [2560/13906 (18%)]\tLoss: 0.043730\n",
      "Train Epoch: 4 [3200/13906 (23%)]\tLoss: 0.123813\n",
      "Train Epoch: 4 [3840/13906 (28%)]\tLoss: 0.078615\n",
      "Train Epoch: 4 [4480/13906 (32%)]\tLoss: 0.058453\n",
      "Train Epoch: 4 [5120/13906 (37%)]\tLoss: 0.037418\n",
      "Train Epoch: 4 [5760/13906 (41%)]\tLoss: 0.013716\n",
      "Train Epoch: 4 [6400/13906 (46%)]\tLoss: 0.029701\n",
      "Train Epoch: 4 [7040/13906 (50%)]\tLoss: 0.063950\n",
      "Train Epoch: 4 [7680/13906 (55%)]\tLoss: 0.100950\n",
      "Train Epoch: 4 [8320/13906 (60%)]\tLoss: 0.018152\n",
      "Train Epoch: 4 [8960/13906 (64%)]\tLoss: 0.258230\n",
      "Train Epoch: 4 [9600/13906 (69%)]\tLoss: 0.005061\n",
      "Train Epoch: 4 [10240/13906 (73%)]\tLoss: 0.040403\n",
      "Train Epoch: 4 [10880/13906 (78%)]\tLoss: 0.093761\n",
      "Train Epoch: 4 [11520/13906 (83%)]\tLoss: 0.044014\n",
      "Train Epoch: 4 [12160/13906 (87%)]\tLoss: 0.028557\n",
      "Train Epoch: 4 [12800/13906 (92%)]\tLoss: 0.019987\n",
      "Train Epoch: 4 [13440/13906 (96%)]\tLoss: 0.030020\n",
      "Train Epoch: 5 [0/13906 (0%)]\tLoss: 0.036619\n",
      "Train Epoch: 5 [640/13906 (5%)]\tLoss: 0.097394\n",
      "Train Epoch: 5 [1280/13906 (9%)]\tLoss: 0.022659\n",
      "Train Epoch: 5 [1920/13906 (14%)]\tLoss: 0.058339\n",
      "Train Epoch: 5 [2560/13906 (18%)]\tLoss: 0.035618\n",
      "Train Epoch: 5 [3200/13906 (23%)]\tLoss: 0.014647\n",
      "Train Epoch: 5 [3840/13906 (28%)]\tLoss: 0.057107\n",
      "Train Epoch: 5 [4480/13906 (32%)]\tLoss: 0.035663\n",
      "Train Epoch: 5 [5120/13906 (37%)]\tLoss: 0.017900\n",
      "Train Epoch: 5 [5760/13906 (41%)]\tLoss: 0.090192\n",
      "Train Epoch: 5 [6400/13906 (46%)]\tLoss: 0.048836\n",
      "Train Epoch: 5 [7040/13906 (50%)]\tLoss: 0.106284\n",
      "Train Epoch: 5 [7680/13906 (55%)]\tLoss: 0.067040\n",
      "Train Epoch: 5 [8320/13906 (60%)]\tLoss: 0.027030\n",
      "Train Epoch: 5 [8960/13906 (64%)]\tLoss: 0.055885\n",
      "Train Epoch: 5 [9600/13906 (69%)]\tLoss: 0.064334\n",
      "Train Epoch: 5 [10240/13906 (73%)]\tLoss: 0.014485\n",
      "Train Epoch: 5 [10880/13906 (78%)]\tLoss: 0.054559\n",
      "Train Epoch: 5 [11520/13906 (83%)]\tLoss: 0.009316\n",
      "Train Epoch: 5 [12160/13906 (87%)]\tLoss: 0.005473\n",
      "Train Epoch: 5 [12800/13906 (92%)]\tLoss: 0.091609\n",
      "Train Epoch: 5 [13440/13906 (96%)]\tLoss: 0.139835\n",
      "Train Epoch: 6 [0/13906 (0%)]\tLoss: 0.011457\n",
      "Train Epoch: 6 [640/13906 (5%)]\tLoss: 0.071727\n",
      "Train Epoch: 6 [1280/13906 (9%)]\tLoss: 0.048756\n",
      "Train Epoch: 6 [1920/13906 (14%)]\tLoss: 0.078057\n",
      "Train Epoch: 6 [2560/13906 (18%)]\tLoss: 0.018269\n",
      "Train Epoch: 6 [3200/13906 (23%)]\tLoss: 0.069089\n",
      "Train Epoch: 6 [3840/13906 (28%)]\tLoss: 0.058064\n",
      "Train Epoch: 6 [4480/13906 (32%)]\tLoss: 0.072863\n",
      "Train Epoch: 6 [5120/13906 (37%)]\tLoss: 0.013678\n",
      "Train Epoch: 6 [5760/13906 (41%)]\tLoss: 0.085359\n",
      "Train Epoch: 6 [6400/13906 (46%)]\tLoss: 0.017456\n",
      "Train Epoch: 6 [7040/13906 (50%)]\tLoss: 0.070145\n",
      "Train Epoch: 6 [7680/13906 (55%)]\tLoss: 0.026679\n",
      "Train Epoch: 6 [8320/13906 (60%)]\tLoss: 0.041098\n",
      "Train Epoch: 6 [8960/13906 (64%)]\tLoss: 0.038869\n",
      "Train Epoch: 6 [9600/13906 (69%)]\tLoss: 0.106441\n",
      "Train Epoch: 6 [10240/13906 (73%)]\tLoss: 0.011476\n",
      "Train Epoch: 6 [10880/13906 (78%)]\tLoss: 0.042038\n",
      "Train Epoch: 6 [11520/13906 (83%)]\tLoss: 0.006843\n",
      "Train Epoch: 6 [12160/13906 (87%)]\tLoss: 0.007491\n",
      "Train Epoch: 6 [12800/13906 (92%)]\tLoss: 0.040559\n",
      "Train Epoch: 6 [13440/13906 (96%)]\tLoss: 0.031194\n",
      "Train Epoch: 7 [0/13906 (0%)]\tLoss: 0.027612\n",
      "Train Epoch: 7 [640/13906 (5%)]\tLoss: 0.157337\n",
      "Train Epoch: 7 [1280/13906 (9%)]\tLoss: 0.027213\n",
      "Train Epoch: 7 [1920/13906 (14%)]\tLoss: 0.018874\n",
      "Train Epoch: 7 [2560/13906 (18%)]\tLoss: 0.037977\n",
      "Train Epoch: 7 [3200/13906 (23%)]\tLoss: 0.115489\n",
      "Train Epoch: 7 [3840/13906 (28%)]\tLoss: 0.050115\n",
      "Train Epoch: 7 [4480/13906 (32%)]\tLoss: 0.034767\n",
      "Train Epoch: 7 [5120/13906 (37%)]\tLoss: 0.151312\n",
      "Train Epoch: 7 [5760/13906 (41%)]\tLoss: 0.032143\n",
      "Train Epoch: 7 [6400/13906 (46%)]\tLoss: 0.023730\n",
      "Train Epoch: 7 [7040/13906 (50%)]\tLoss: 0.031839\n",
      "Train Epoch: 7 [7680/13906 (55%)]\tLoss: 0.029301\n",
      "Train Epoch: 7 [8320/13906 (60%)]\tLoss: 0.102779\n",
      "Train Epoch: 7 [8960/13906 (64%)]\tLoss: 0.218720\n",
      "Train Epoch: 7 [9600/13906 (69%)]\tLoss: 0.029125\n",
      "Train Epoch: 7 [10240/13906 (73%)]\tLoss: 0.070234\n",
      "Train Epoch: 7 [10880/13906 (78%)]\tLoss: 0.091978\n",
      "Train Epoch: 7 [11520/13906 (83%)]\tLoss: 0.022841\n",
      "Train Epoch: 7 [12160/13906 (87%)]\tLoss: 0.059689\n",
      "Train Epoch: 7 [12800/13906 (92%)]\tLoss: 0.198895\n",
      "Train Epoch: 7 [13440/13906 (96%)]\tLoss: 0.027626\n",
      "Train Epoch: 8 [0/13906 (0%)]\tLoss: 0.010800\n",
      "Train Epoch: 8 [640/13906 (5%)]\tLoss: 0.213786\n",
      "Train Epoch: 8 [1280/13906 (9%)]\tLoss: 0.063722\n",
      "Train Epoch: 8 [1920/13906 (14%)]\tLoss: 0.046178\n",
      "Train Epoch: 8 [2560/13906 (18%)]\tLoss: 0.077497\n",
      "Train Epoch: 8 [3200/13906 (23%)]\tLoss: 0.032923\n",
      "Train Epoch: 8 [3840/13906 (28%)]\tLoss: 0.092258\n",
      "Train Epoch: 8 [4480/13906 (32%)]\tLoss: 0.022748\n",
      "Train Epoch: 8 [5120/13906 (37%)]\tLoss: 0.129626\n",
      "Train Epoch: 8 [5760/13906 (41%)]\tLoss: 0.008611\n",
      "Train Epoch: 8 [6400/13906 (46%)]\tLoss: 0.006973\n",
      "Train Epoch: 8 [7040/13906 (50%)]\tLoss: 0.018217\n",
      "Train Epoch: 8 [7680/13906 (55%)]\tLoss: 0.307751\n",
      "Train Epoch: 8 [8320/13906 (60%)]\tLoss: 0.092415\n",
      "Train Epoch: 8 [8960/13906 (64%)]\tLoss: 0.015438\n",
      "Train Epoch: 8 [9600/13906 (69%)]\tLoss: 0.017400\n",
      "Train Epoch: 8 [10240/13906 (73%)]\tLoss: 0.069214\n",
      "Train Epoch: 8 [10880/13906 (78%)]\tLoss: 0.014460\n",
      "Train Epoch: 8 [11520/13906 (83%)]\tLoss: 0.093216\n",
      "Train Epoch: 8 [12160/13906 (87%)]\tLoss: 0.025528\n",
      "Train Epoch: 8 [12800/13906 (92%)]\tLoss: 0.013127\n",
      "Train Epoch: 8 [13440/13906 (96%)]\tLoss: 0.061846\n",
      "Train Epoch: 9 [0/13906 (0%)]\tLoss: 0.097531\n",
      "Train Epoch: 9 [640/13906 (5%)]\tLoss: 0.076560\n",
      "Train Epoch: 9 [1280/13906 (9%)]\tLoss: 0.131157\n",
      "Train Epoch: 9 [1920/13906 (14%)]\tLoss: 0.052834\n",
      "Train Epoch: 9 [2560/13906 (18%)]\tLoss: 0.146678\n",
      "Train Epoch: 9 [3200/13906 (23%)]\tLoss: 0.008577\n",
      "Train Epoch: 9 [3840/13906 (28%)]\tLoss: 0.042104\n",
      "Train Epoch: 9 [4480/13906 (32%)]\tLoss: 0.006170\n",
      "Train Epoch: 9 [5120/13906 (37%)]\tLoss: 0.041751\n",
      "Train Epoch: 9 [5760/13906 (41%)]\tLoss: 0.105104\n",
      "Train Epoch: 9 [6400/13906 (46%)]\tLoss: 0.099406\n",
      "Train Epoch: 9 [7040/13906 (50%)]\tLoss: 0.104089\n",
      "Train Epoch: 9 [7680/13906 (55%)]\tLoss: 0.109965\n",
      "Train Epoch: 9 [8320/13906 (60%)]\tLoss: 0.293496\n",
      "Train Epoch: 9 [8960/13906 (64%)]\tLoss: 0.039567\n",
      "Train Epoch: 9 [9600/13906 (69%)]\tLoss: 0.023732\n",
      "Train Epoch: 9 [10240/13906 (73%)]\tLoss: 0.037435\n",
      "Train Epoch: 9 [10880/13906 (78%)]\tLoss: 0.125072\n",
      "Train Epoch: 9 [11520/13906 (83%)]\tLoss: 0.197065\n",
      "Train Epoch: 9 [12160/13906 (87%)]\tLoss: 0.055450\n",
      "Train Epoch: 9 [12800/13906 (92%)]\tLoss: 0.022162\n",
      "Train Epoch: 9 [13440/13906 (96%)]\tLoss: 0.053083\n",
      "Train Epoch: 10 [0/13906 (0%)]\tLoss: 0.006577\n",
      "Train Epoch: 10 [640/13906 (5%)]\tLoss: 0.103101\n",
      "Train Epoch: 10 [1280/13906 (9%)]\tLoss: 0.057599\n",
      "Train Epoch: 10 [1920/13906 (14%)]\tLoss: 0.008909\n",
      "Train Epoch: 10 [2560/13906 (18%)]\tLoss: 0.051272\n",
      "Train Epoch: 10 [3200/13906 (23%)]\tLoss: 0.138934\n",
      "Train Epoch: 10 [3840/13906 (28%)]\tLoss: 0.080957\n",
      "Train Epoch: 10 [4480/13906 (32%)]\tLoss: 0.020709\n",
      "Train Epoch: 10 [5120/13906 (37%)]\tLoss: 0.037248\n",
      "Train Epoch: 10 [5760/13906 (41%)]\tLoss: 0.063985\n",
      "Train Epoch: 10 [6400/13906 (46%)]\tLoss: 0.051026\n",
      "Train Epoch: 10 [7040/13906 (50%)]\tLoss: 0.027759\n",
      "Train Epoch: 10 [7680/13906 (55%)]\tLoss: 0.060394\n",
      "Train Epoch: 10 [8320/13906 (60%)]\tLoss: 0.021600\n",
      "Train Epoch: 10 [8960/13906 (64%)]\tLoss: 0.029515\n",
      "Train Epoch: 10 [9600/13906 (69%)]\tLoss: 0.048795\n",
      "Train Epoch: 10 [10240/13906 (73%)]\tLoss: 0.015425\n",
      "Train Epoch: 10 [10880/13906 (78%)]\tLoss: 0.078087\n",
      "Train Epoch: 10 [11520/13906 (83%)]\tLoss: 0.021689\n",
      "Train Epoch: 10 [12160/13906 (87%)]\tLoss: 0.046234\n",
      "Train Epoch: 10 [12800/13906 (92%)]\tLoss: 0.019554\n",
      "Train Epoch: 10 [13440/13906 (96%)]\tLoss: 0.004555\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/11862 (0%)]\tLoss: 0.244682\n",
      "Train Epoch: 1 [640/11862 (5%)]\tLoss: 0.047852\n",
      "Train Epoch: 1 [1280/11862 (11%)]\tLoss: 0.082853\n",
      "Train Epoch: 1 [1920/11862 (16%)]\tLoss: 0.049910\n",
      "Train Epoch: 1 [2560/11862 (22%)]\tLoss: 0.022126\n",
      "Train Epoch: 1 [3200/11862 (27%)]\tLoss: 0.012171\n",
      "Train Epoch: 1 [3840/11862 (32%)]\tLoss: 0.040650\n",
      "Train Epoch: 1 [4480/11862 (38%)]\tLoss: 0.016578\n",
      "Train Epoch: 1 [5120/11862 (43%)]\tLoss: 0.047884\n",
      "Train Epoch: 1 [5760/11862 (48%)]\tLoss: 0.001115\n",
      "Train Epoch: 1 [6400/11862 (54%)]\tLoss: 0.028858\n",
      "Train Epoch: 1 [7040/11862 (59%)]\tLoss: 0.045549\n",
      "Train Epoch: 1 [7680/11862 (65%)]\tLoss: 0.013087\n",
      "Train Epoch: 1 [8320/11862 (70%)]\tLoss: 0.019187\n",
      "Train Epoch: 1 [8960/11862 (75%)]\tLoss: 0.012900\n",
      "Train Epoch: 1 [9600/11862 (81%)]\tLoss: 0.006568\n",
      "Train Epoch: 1 [10240/11862 (86%)]\tLoss: 0.004444\n",
      "Train Epoch: 1 [10880/11862 (91%)]\tLoss: 0.067603\n",
      "Train Epoch: 1 [11520/11862 (97%)]\tLoss: 0.118159\n",
      "Train Epoch: 2 [0/11862 (0%)]\tLoss: 0.029936\n",
      "Train Epoch: 2 [640/11862 (5%)]\tLoss: 0.125832\n",
      "Train Epoch: 2 [1280/11862 (11%)]\tLoss: 0.130034\n",
      "Train Epoch: 2 [1920/11862 (16%)]\tLoss: 0.014537\n",
      "Train Epoch: 2 [2560/11862 (22%)]\tLoss: 0.058355\n",
      "Train Epoch: 2 [3200/11862 (27%)]\tLoss: 0.063525\n",
      "Train Epoch: 2 [3840/11862 (32%)]\tLoss: 0.066525\n",
      "Train Epoch: 2 [4480/11862 (38%)]\tLoss: 0.003206\n",
      "Train Epoch: 2 [5120/11862 (43%)]\tLoss: 0.014397\n",
      "Train Epoch: 2 [5760/11862 (48%)]\tLoss: 0.230206\n",
      "Train Epoch: 2 [6400/11862 (54%)]\tLoss: 0.054959\n",
      "Train Epoch: 2 [7040/11862 (59%)]\tLoss: 0.083289\n",
      "Train Epoch: 2 [7680/11862 (65%)]\tLoss: 0.017287\n",
      "Train Epoch: 2 [8320/11862 (70%)]\tLoss: 0.041886\n",
      "Train Epoch: 2 [8960/11862 (75%)]\tLoss: 0.081884\n",
      "Train Epoch: 2 [9600/11862 (81%)]\tLoss: 0.151551\n",
      "Train Epoch: 2 [10240/11862 (86%)]\tLoss: 0.022074\n",
      "Train Epoch: 2 [10880/11862 (91%)]\tLoss: 0.052667\n",
      "Train Epoch: 2 [11520/11862 (97%)]\tLoss: 0.038635\n",
      "Train Epoch: 3 [0/11862 (0%)]\tLoss: 0.086769\n",
      "Train Epoch: 3 [640/11862 (5%)]\tLoss: 0.031166\n",
      "Train Epoch: 3 [1280/11862 (11%)]\tLoss: 0.211822\n",
      "Train Epoch: 3 [1920/11862 (16%)]\tLoss: 0.085822\n",
      "Train Epoch: 3 [2560/11862 (22%)]\tLoss: 0.059804\n",
      "Train Epoch: 3 [3200/11862 (27%)]\tLoss: 0.100153\n",
      "Train Epoch: 3 [3840/11862 (32%)]\tLoss: 0.023553\n",
      "Train Epoch: 3 [4480/11862 (38%)]\tLoss: 0.029336\n",
      "Train Epoch: 3 [5120/11862 (43%)]\tLoss: 0.021552\n",
      "Train Epoch: 3 [5760/11862 (48%)]\tLoss: 0.050297\n",
      "Train Epoch: 3 [6400/11862 (54%)]\tLoss: 0.046702\n",
      "Train Epoch: 3 [7040/11862 (59%)]\tLoss: 0.012581\n",
      "Train Epoch: 3 [7680/11862 (65%)]\tLoss: 0.032209\n",
      "Train Epoch: 3 [8320/11862 (70%)]\tLoss: 0.075457\n",
      "Train Epoch: 3 [8960/11862 (75%)]\tLoss: 0.117062\n",
      "Train Epoch: 3 [9600/11862 (81%)]\tLoss: 0.011512\n",
      "Train Epoch: 3 [10240/11862 (86%)]\tLoss: 0.044656\n",
      "Train Epoch: 3 [10880/11862 (91%)]\tLoss: 0.044268\n",
      "Train Epoch: 3 [11520/11862 (97%)]\tLoss: 0.030172\n",
      "Train Epoch: 4 [0/11862 (0%)]\tLoss: 0.037021\n",
      "Train Epoch: 4 [640/11862 (5%)]\tLoss: 0.009969\n",
      "Train Epoch: 4 [1280/11862 (11%)]\tLoss: 0.108640\n",
      "Train Epoch: 4 [1920/11862 (16%)]\tLoss: 0.035671\n",
      "Train Epoch: 4 [2560/11862 (22%)]\tLoss: 0.026833\n",
      "Train Epoch: 4 [3200/11862 (27%)]\tLoss: 0.026567\n",
      "Train Epoch: 4 [3840/11862 (32%)]\tLoss: 0.009250\n",
      "Train Epoch: 4 [4480/11862 (38%)]\tLoss: 0.056161\n",
      "Train Epoch: 4 [5120/11862 (43%)]\tLoss: 0.018229\n",
      "Train Epoch: 4 [5760/11862 (48%)]\tLoss: 0.015593\n",
      "Train Epoch: 4 [6400/11862 (54%)]\tLoss: 0.059336\n",
      "Train Epoch: 4 [7040/11862 (59%)]\tLoss: 0.002410\n",
      "Train Epoch: 4 [7680/11862 (65%)]\tLoss: 0.026158\n",
      "Train Epoch: 4 [8320/11862 (70%)]\tLoss: 0.128712\n",
      "Train Epoch: 4 [8960/11862 (75%)]\tLoss: 0.298075\n",
      "Train Epoch: 4 [9600/11862 (81%)]\tLoss: 0.058608\n",
      "Train Epoch: 4 [10240/11862 (86%)]\tLoss: 0.014691\n",
      "Train Epoch: 4 [10880/11862 (91%)]\tLoss: 0.096992\n",
      "Train Epoch: 4 [11520/11862 (97%)]\tLoss: 0.034690\n",
      "Train Epoch: 5 [0/11862 (0%)]\tLoss: 0.054089\n",
      "Train Epoch: 5 [640/11862 (5%)]\tLoss: 0.040681\n",
      "Train Epoch: 5 [1280/11862 (11%)]\tLoss: 0.152142\n",
      "Train Epoch: 5 [1920/11862 (16%)]\tLoss: 0.000452\n",
      "Train Epoch: 5 [2560/11862 (22%)]\tLoss: 0.248603\n",
      "Train Epoch: 5 [3200/11862 (27%)]\tLoss: 0.007759\n",
      "Train Epoch: 5 [3840/11862 (32%)]\tLoss: 0.078569\n",
      "Train Epoch: 5 [4480/11862 (38%)]\tLoss: 0.024921\n",
      "Train Epoch: 5 [5120/11862 (43%)]\tLoss: 0.021762\n",
      "Train Epoch: 5 [5760/11862 (48%)]\tLoss: 0.031986\n",
      "Train Epoch: 5 [6400/11862 (54%)]\tLoss: 0.015109\n",
      "Train Epoch: 5 [7040/11862 (59%)]\tLoss: 0.061236\n",
      "Train Epoch: 5 [7680/11862 (65%)]\tLoss: 0.050772\n",
      "Train Epoch: 5 [8320/11862 (70%)]\tLoss: 0.024800\n",
      "Train Epoch: 5 [8960/11862 (75%)]\tLoss: 0.058815\n",
      "Train Epoch: 5 [9600/11862 (81%)]\tLoss: 0.036999\n",
      "Train Epoch: 5 [10240/11862 (86%)]\tLoss: 0.068947\n",
      "Train Epoch: 5 [10880/11862 (91%)]\tLoss: 0.011634\n",
      "Train Epoch: 5 [11520/11862 (97%)]\tLoss: 0.039366\n",
      "Train Epoch: 6 [0/11862 (0%)]\tLoss: 0.117890\n",
      "Train Epoch: 6 [640/11862 (5%)]\tLoss: 0.082416\n",
      "Train Epoch: 6 [1280/11862 (11%)]\tLoss: 0.004297\n",
      "Train Epoch: 6 [1920/11862 (16%)]\tLoss: 0.015166\n",
      "Train Epoch: 6 [2560/11862 (22%)]\tLoss: 0.012313\n",
      "Train Epoch: 6 [3200/11862 (27%)]\tLoss: 0.021971\n",
      "Train Epoch: 6 [3840/11862 (32%)]\tLoss: 0.008443\n",
      "Train Epoch: 6 [4480/11862 (38%)]\tLoss: 0.006885\n",
      "Train Epoch: 6 [5120/11862 (43%)]\tLoss: 0.009363\n",
      "Train Epoch: 6 [5760/11862 (48%)]\tLoss: 0.178779\n",
      "Train Epoch: 6 [6400/11862 (54%)]\tLoss: 0.071838\n",
      "Train Epoch: 6 [7040/11862 (59%)]\tLoss: 0.000556\n",
      "Train Epoch: 6 [7680/11862 (65%)]\tLoss: 0.025198\n",
      "Train Epoch: 6 [8320/11862 (70%)]\tLoss: 0.024574\n",
      "Train Epoch: 6 [8960/11862 (75%)]\tLoss: 0.107276\n",
      "Train Epoch: 6 [9600/11862 (81%)]\tLoss: 0.014573\n",
      "Train Epoch: 6 [10240/11862 (86%)]\tLoss: 0.022984\n",
      "Train Epoch: 6 [10880/11862 (91%)]\tLoss: 0.092465\n",
      "Train Epoch: 6 [11520/11862 (97%)]\tLoss: 0.111244\n",
      "Train Epoch: 7 [0/11862 (0%)]\tLoss: 0.011268\n",
      "Train Epoch: 7 [640/11862 (5%)]\tLoss: 0.013629\n",
      "Train Epoch: 7 [1280/11862 (11%)]\tLoss: 0.017241\n",
      "Train Epoch: 7 [1920/11862 (16%)]\tLoss: 0.027920\n",
      "Train Epoch: 7 [2560/11862 (22%)]\tLoss: 0.031856\n",
      "Train Epoch: 7 [3200/11862 (27%)]\tLoss: 0.022938\n",
      "Train Epoch: 7 [3840/11862 (32%)]\tLoss: 0.075076\n",
      "Train Epoch: 7 [4480/11862 (38%)]\tLoss: 0.158006\n",
      "Train Epoch: 7 [5120/11862 (43%)]\tLoss: 0.024450\n",
      "Train Epoch: 7 [5760/11862 (48%)]\tLoss: 0.010460\n",
      "Train Epoch: 7 [6400/11862 (54%)]\tLoss: 0.037155\n",
      "Train Epoch: 7 [7040/11862 (59%)]\tLoss: 0.128832\n",
      "Train Epoch: 7 [7680/11862 (65%)]\tLoss: 0.005614\n",
      "Train Epoch: 7 [8320/11862 (70%)]\tLoss: 0.053161\n",
      "Train Epoch: 7 [8960/11862 (75%)]\tLoss: 0.116623\n",
      "Train Epoch: 7 [9600/11862 (81%)]\tLoss: 0.143966\n",
      "Train Epoch: 7 [10240/11862 (86%)]\tLoss: 0.013588\n",
      "Train Epoch: 7 [10880/11862 (91%)]\tLoss: 0.045700\n",
      "Train Epoch: 7 [11520/11862 (97%)]\tLoss: 0.008620\n",
      "Train Epoch: 8 [0/11862 (0%)]\tLoss: 0.033960\n",
      "Train Epoch: 8 [640/11862 (5%)]\tLoss: 0.049954\n",
      "Train Epoch: 8 [1280/11862 (11%)]\tLoss: 0.004928\n",
      "Train Epoch: 8 [1920/11862 (16%)]\tLoss: 0.061757\n",
      "Train Epoch: 8 [2560/11862 (22%)]\tLoss: 0.035690\n",
      "Train Epoch: 8 [3200/11862 (27%)]\tLoss: 0.082037\n",
      "Train Epoch: 8 [3840/11862 (32%)]\tLoss: 0.019833\n",
      "Train Epoch: 8 [4480/11862 (38%)]\tLoss: 0.016150\n",
      "Train Epoch: 8 [5120/11862 (43%)]\tLoss: 0.084530\n",
      "Train Epoch: 8 [5760/11862 (48%)]\tLoss: 0.012690\n",
      "Train Epoch: 8 [6400/11862 (54%)]\tLoss: 0.048816\n",
      "Train Epoch: 8 [7040/11862 (59%)]\tLoss: 0.026438\n",
      "Train Epoch: 8 [7680/11862 (65%)]\tLoss: 0.079274\n",
      "Train Epoch: 8 [8320/11862 (70%)]\tLoss: 0.080293\n",
      "Train Epoch: 8 [8960/11862 (75%)]\tLoss: 0.052459\n",
      "Train Epoch: 8 [9600/11862 (81%)]\tLoss: 0.059474\n",
      "Train Epoch: 8 [10240/11862 (86%)]\tLoss: 0.009897\n",
      "Train Epoch: 8 [10880/11862 (91%)]\tLoss: 0.065709\n",
      "Train Epoch: 8 [11520/11862 (97%)]\tLoss: 0.030788\n",
      "Train Epoch: 9 [0/11862 (0%)]\tLoss: 0.027161\n",
      "Train Epoch: 9 [640/11862 (5%)]\tLoss: 0.019151\n",
      "Train Epoch: 9 [1280/11862 (11%)]\tLoss: 0.053221\n",
      "Train Epoch: 9 [1920/11862 (16%)]\tLoss: 0.070095\n",
      "Train Epoch: 9 [2560/11862 (22%)]\tLoss: 0.049345\n",
      "Train Epoch: 9 [3200/11862 (27%)]\tLoss: 0.072556\n",
      "Train Epoch: 9 [3840/11862 (32%)]\tLoss: 0.007272\n",
      "Train Epoch: 9 [4480/11862 (38%)]\tLoss: 0.020722\n",
      "Train Epoch: 9 [5120/11862 (43%)]\tLoss: 0.166907\n",
      "Train Epoch: 9 [5760/11862 (48%)]\tLoss: 0.055840\n",
      "Train Epoch: 9 [6400/11862 (54%)]\tLoss: 0.018950\n",
      "Train Epoch: 9 [7040/11862 (59%)]\tLoss: 0.074213\n",
      "Train Epoch: 9 [7680/11862 (65%)]\tLoss: 0.045346\n",
      "Train Epoch: 9 [8320/11862 (70%)]\tLoss: 0.049918\n",
      "Train Epoch: 9 [8960/11862 (75%)]\tLoss: 0.007266\n",
      "Train Epoch: 9 [9600/11862 (81%)]\tLoss: 0.003012\n",
      "Train Epoch: 9 [10240/11862 (86%)]\tLoss: 0.128844\n",
      "Train Epoch: 9 [10880/11862 (91%)]\tLoss: 0.004150\n",
      "Train Epoch: 9 [11520/11862 (97%)]\tLoss: 0.059086\n",
      "Train Epoch: 10 [0/11862 (0%)]\tLoss: 0.086039\n",
      "Train Epoch: 10 [640/11862 (5%)]\tLoss: 0.026346\n",
      "Train Epoch: 10 [1280/11862 (11%)]\tLoss: 0.037660\n",
      "Train Epoch: 10 [1920/11862 (16%)]\tLoss: 0.034861\n",
      "Train Epoch: 10 [2560/11862 (22%)]\tLoss: 0.003935\n",
      "Train Epoch: 10 [3200/11862 (27%)]\tLoss: 0.016060\n",
      "Train Epoch: 10 [3840/11862 (32%)]\tLoss: 0.029577\n",
      "Train Epoch: 10 [4480/11862 (38%)]\tLoss: 0.013056\n",
      "Train Epoch: 10 [5120/11862 (43%)]\tLoss: 0.076447\n",
      "Train Epoch: 10 [5760/11862 (48%)]\tLoss: 0.050888\n",
      "Train Epoch: 10 [6400/11862 (54%)]\tLoss: 0.011765\n",
      "Train Epoch: 10 [7040/11862 (59%)]\tLoss: 0.011492\n",
      "Train Epoch: 10 [7680/11862 (65%)]\tLoss: 0.054799\n",
      "Train Epoch: 10 [8320/11862 (70%)]\tLoss: 0.066447\n",
      "Train Epoch: 10 [8960/11862 (75%)]\tLoss: 0.018391\n",
      "Train Epoch: 10 [9600/11862 (81%)]\tLoss: 0.147060\n",
      "Train Epoch: 10 [10240/11862 (86%)]\tLoss: 0.045233\n",
      "Train Epoch: 10 [10880/11862 (91%)]\tLoss: 0.084998\n",
      "Train Epoch: 10 [11520/11862 (97%)]\tLoss: 0.033252\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 0.068809\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 0.159592\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 0.036514\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 0.021039\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 0.071476\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 0.006650\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 0.045323\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 0.103504\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 0.027638\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 0.044886\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 0.007417\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 0.025974\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 0.044484\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 0.051856\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 0.031049\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 0.015379\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 0.023326\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.125863\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.079909\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.018070\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.090086\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.072045\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.046587\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.021818\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.048253\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.075817\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.025629\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.028548\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.059275\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.079249\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.093977\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.046044\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.053346\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.015528\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.035242\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.015642\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.032271\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.068107\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.030948\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.054637\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.038835\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.089184\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.106117\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.044260\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.029285\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.023928\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.037983\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.063227\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.012789\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.011295\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.036111\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.014983\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.022899\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.015905\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.034713\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.051055\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.061941\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.097490\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.246374\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.084969\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.012191\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.056710\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.170312\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.003914\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.027234\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.006456\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.061340\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.076095\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.105921\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.048352\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.045397\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.068400\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.023558\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.072244\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.087376\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.084360\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.018564\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.021230\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.024999\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.048498\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.024299\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.036269\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.008869\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.008552\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.016783\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.067957\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.030652\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.041044\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.016740\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.040499\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.048786\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.037702\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.015854\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.060577\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.108510\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.010262\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.046411\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.034047\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.033207\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.027923\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.092771\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.017347\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.004565\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.021609\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.047542\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.036167\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.027819\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.005058\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.052887\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.007602\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.008391\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.021921\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.014481\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.022492\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.016931\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.032461\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.153968\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.034199\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.020438\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.016140\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.003094\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.138677\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.093418\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.022896\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.078353\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.022906\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.091693\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.029472\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.084169\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.100470\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.005988\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.012327\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.006018\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.056970\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.011585\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.086404\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.081921\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.006939\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.014309\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.010229\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.019424\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.083338\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.014436\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.074755\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.024105\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.145125\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.025286\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.014446\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.383302\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.032235\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.068116\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.052140\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.180579\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.021545\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.048060\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.073334\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.089850\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.029103\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.006630\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.015401\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5509 (0%)]\tLoss: 0.217614\n",
      "Train Epoch: 1 [640/5509 (11%)]\tLoss: 0.018829\n",
      "Train Epoch: 1 [1280/5509 (23%)]\tLoss: 0.041082\n",
      "Train Epoch: 1 [1920/5509 (34%)]\tLoss: 0.031217\n",
      "Train Epoch: 1 [2560/5509 (46%)]\tLoss: 0.092483\n",
      "Train Epoch: 1 [3200/5509 (57%)]\tLoss: 0.013292\n",
      "Train Epoch: 1 [3840/5509 (69%)]\tLoss: 0.049604\n",
      "Train Epoch: 1 [4480/5509 (80%)]\tLoss: 0.094178\n",
      "Train Epoch: 1 [5120/5509 (92%)]\tLoss: 0.052136\n",
      "Train Epoch: 2 [0/5509 (0%)]\tLoss: 0.035136\n",
      "Train Epoch: 2 [640/5509 (11%)]\tLoss: 0.064356\n",
      "Train Epoch: 2 [1280/5509 (23%)]\tLoss: 0.042480\n",
      "Train Epoch: 2 [1920/5509 (34%)]\tLoss: 0.037523\n",
      "Train Epoch: 2 [2560/5509 (46%)]\tLoss: 0.103931\n",
      "Train Epoch: 2 [3200/5509 (57%)]\tLoss: 0.024067\n",
      "Train Epoch: 2 [3840/5509 (69%)]\tLoss: 0.053430\n",
      "Train Epoch: 2 [4480/5509 (80%)]\tLoss: 0.072787\n",
      "Train Epoch: 2 [5120/5509 (92%)]\tLoss: 0.032670\n",
      "Train Epoch: 3 [0/5509 (0%)]\tLoss: 0.031912\n",
      "Train Epoch: 3 [640/5509 (11%)]\tLoss: 0.052130\n",
      "Train Epoch: 3 [1280/5509 (23%)]\tLoss: 0.040190\n",
      "Train Epoch: 3 [1920/5509 (34%)]\tLoss: 0.074445\n",
      "Train Epoch: 3 [2560/5509 (46%)]\tLoss: 0.056431\n",
      "Train Epoch: 3 [3200/5509 (57%)]\tLoss: 0.082790\n",
      "Train Epoch: 3 [3840/5509 (69%)]\tLoss: 0.066392\n",
      "Train Epoch: 3 [4480/5509 (80%)]\tLoss: 0.022338\n",
      "Train Epoch: 3 [5120/5509 (92%)]\tLoss: 0.052596\n",
      "Train Epoch: 4 [0/5509 (0%)]\tLoss: 0.074494\n",
      "Train Epoch: 4 [640/5509 (11%)]\tLoss: 0.004445\n",
      "Train Epoch: 4 [1280/5509 (23%)]\tLoss: 0.113078\n",
      "Train Epoch: 4 [1920/5509 (34%)]\tLoss: 0.054752\n",
      "Train Epoch: 4 [2560/5509 (46%)]\tLoss: 0.125162\n",
      "Train Epoch: 4 [3200/5509 (57%)]\tLoss: 0.029237\n",
      "Train Epoch: 4 [3840/5509 (69%)]\tLoss: 0.320912\n",
      "Train Epoch: 4 [4480/5509 (80%)]\tLoss: 0.033243\n",
      "Train Epoch: 4 [5120/5509 (92%)]\tLoss: 0.115992\n",
      "Train Epoch: 5 [0/5509 (0%)]\tLoss: 0.116590\n",
      "Train Epoch: 5 [640/5509 (11%)]\tLoss: 0.061577\n",
      "Train Epoch: 5 [1280/5509 (23%)]\tLoss: 0.139625\n",
      "Train Epoch: 5 [1920/5509 (34%)]\tLoss: 0.086576\n",
      "Train Epoch: 5 [2560/5509 (46%)]\tLoss: 0.057614\n",
      "Train Epoch: 5 [3200/5509 (57%)]\tLoss: 0.011200\n",
      "Train Epoch: 5 [3840/5509 (69%)]\tLoss: 0.019336\n",
      "Train Epoch: 5 [4480/5509 (80%)]\tLoss: 0.049864\n",
      "Train Epoch: 5 [5120/5509 (92%)]\tLoss: 0.107257\n",
      "Train Epoch: 6 [0/5509 (0%)]\tLoss: 0.033843\n",
      "Train Epoch: 6 [640/5509 (11%)]\tLoss: 0.081816\n",
      "Train Epoch: 6 [1280/5509 (23%)]\tLoss: 0.047984\n",
      "Train Epoch: 6 [1920/5509 (34%)]\tLoss: 0.017039\n",
      "Train Epoch: 6 [2560/5509 (46%)]\tLoss: 0.144337\n",
      "Train Epoch: 6 [3200/5509 (57%)]\tLoss: 0.019815\n",
      "Train Epoch: 6 [3840/5509 (69%)]\tLoss: 0.079827\n",
      "Train Epoch: 6 [4480/5509 (80%)]\tLoss: 0.070504\n",
      "Train Epoch: 6 [5120/5509 (92%)]\tLoss: 0.095075\n",
      "Train Epoch: 7 [0/5509 (0%)]\tLoss: 0.185839\n",
      "Train Epoch: 7 [640/5509 (11%)]\tLoss: 0.050767\n",
      "Train Epoch: 7 [1280/5509 (23%)]\tLoss: 0.076306\n",
      "Train Epoch: 7 [1920/5509 (34%)]\tLoss: 0.053956\n",
      "Train Epoch: 7 [2560/5509 (46%)]\tLoss: 0.066068\n",
      "Train Epoch: 7 [3200/5509 (57%)]\tLoss: 0.356932\n",
      "Train Epoch: 7 [3840/5509 (69%)]\tLoss: 0.088489\n",
      "Train Epoch: 7 [4480/5509 (80%)]\tLoss: 0.037670\n",
      "Train Epoch: 7 [5120/5509 (92%)]\tLoss: 0.037379\n",
      "Train Epoch: 8 [0/5509 (0%)]\tLoss: 0.116168\n",
      "Train Epoch: 8 [640/5509 (11%)]\tLoss: 0.075859\n",
      "Train Epoch: 8 [1280/5509 (23%)]\tLoss: 0.112071\n",
      "Train Epoch: 8 [1920/5509 (34%)]\tLoss: 0.038291\n",
      "Train Epoch: 8 [2560/5509 (46%)]\tLoss: 0.140967\n",
      "Train Epoch: 8 [3200/5509 (57%)]\tLoss: 0.012785\n",
      "Train Epoch: 8 [3840/5509 (69%)]\tLoss: 0.051115\n",
      "Train Epoch: 8 [4480/5509 (80%)]\tLoss: 0.083711\n",
      "Train Epoch: 8 [5120/5509 (92%)]\tLoss: 0.077418\n",
      "Train Epoch: 9 [0/5509 (0%)]\tLoss: 0.009842\n",
      "Train Epoch: 9 [640/5509 (11%)]\tLoss: 0.042285\n",
      "Train Epoch: 9 [1280/5509 (23%)]\tLoss: 0.094969\n",
      "Train Epoch: 9 [1920/5509 (34%)]\tLoss: 0.064863\n",
      "Train Epoch: 9 [2560/5509 (46%)]\tLoss: 0.042914\n",
      "Train Epoch: 9 [3200/5509 (57%)]\tLoss: 0.138071\n",
      "Train Epoch: 9 [3840/5509 (69%)]\tLoss: 0.088415\n",
      "Train Epoch: 9 [4480/5509 (80%)]\tLoss: 0.100849\n",
      "Train Epoch: 9 [5120/5509 (92%)]\tLoss: 0.131348\n",
      "Train Epoch: 10 [0/5509 (0%)]\tLoss: 0.032560\n",
      "Train Epoch: 10 [640/5509 (11%)]\tLoss: 0.082404\n",
      "Train Epoch: 10 [1280/5509 (23%)]\tLoss: 0.011956\n",
      "Train Epoch: 10 [1920/5509 (34%)]\tLoss: 0.038096\n",
      "Train Epoch: 10 [2560/5509 (46%)]\tLoss: 0.089168\n",
      "Train Epoch: 10 [3200/5509 (57%)]\tLoss: 0.042690\n",
      "Train Epoch: 10 [3840/5509 (69%)]\tLoss: 0.144035\n",
      "Train Epoch: 10 [4480/5509 (80%)]\tLoss: 0.231797\n",
      "Train Epoch: 10 [5120/5509 (92%)]\tLoss: 0.059442\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 0.117017\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 0.080039\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 0.047539\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 0.017200\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 0.048570\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 0.105219\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 0.012171\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 0.010647\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 0.017092\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 0.018786\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.023819\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.027208\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 0.026659\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 0.018110\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 0.116662\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.003491\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.077200\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.087861\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.109816\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.007392\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.087319\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.082098\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.047911\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.048217\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.032926\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.057944\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.041772\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.111903\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.060932\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.001340\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.018544\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.002577\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.017951\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.056558\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.007399\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.044438\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.124903\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.099913\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.034032\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.034046\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.044670\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.032061\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.007731\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.015722\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.020076\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.035198\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.164284\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.032092\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.035844\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.022936\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.003845\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.017688\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.001060\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.005053\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.015668\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.002525\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.020846\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.014743\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.099627\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.007797\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.051154\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.012855\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.001276\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.021430\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.024984\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.004126\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.017281\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.006117\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.027543\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.117557\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.032229\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.108532\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.043102\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.033502\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.015169\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.019710\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.047995\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.052078\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.006196\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.025208\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.006637\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.007113\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.007539\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.055087\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.110969\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.016515\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.000878\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.042674\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.097373\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.008211\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.008865\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.011466\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.027595\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.005480\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.055891\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.002731\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.020252\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.076208\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.020480\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.031971\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.025081\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.008858\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.015176\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.023032\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.108259\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.008347\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.026684\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.046238\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.012041\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.015589\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.009419\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.006010\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.007892\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.024650\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.006455\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.007526\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.004326\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.003007\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.058720\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.038582\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.1539, Accuracy: 9880/10000 (99%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 0.036885\n",
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 0.050756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 0.034995\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 0.021208\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 0.055494\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 0.179239\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 0.031430\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 0.009780\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 0.089391\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 0.026662\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 0.255975\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 0.066690\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 0.066335\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 0.017546\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 0.025956\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 0.080420\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 0.035765\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 0.101390\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 0.037908\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 0.084257\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.199404\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 0.028334\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 0.004728\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.002602\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.070128\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 0.085795\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.058600\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 0.073086\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.101778\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.042199\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.175828\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.446706\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.050720\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.033387\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.059570\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.010880\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.008310\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.048673\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.026202\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.099807\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.053378\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.079634\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.003239\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.105241\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.161750\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.057464\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.008832\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.014330\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.094697\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.072714\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.072008\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.058388\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.035678\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.123767\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.108149\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.114639\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.117908\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.118522\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.063687\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.127337\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.042337\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.062049\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.067356\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.025213\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.079184\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.035703\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.050811\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.043136\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.153606\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.007004\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.064719\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.075779\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.161501\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.045570\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.020893\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.020089\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.038156\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.006304\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.055140\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.196965\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.008680\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.064150\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.012746\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.005971\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.074767\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.037388\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.061757\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.033756\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.187218\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.020167\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.032681\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.007370\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.085457\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.030214\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.041040\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.018570\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.069477\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.042245\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.030023\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.042193\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.021020\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.150860\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.031094\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.018071\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.107235\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.079648\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.038481\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.234945\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 0.021148\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.013004\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.009473\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.050622\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.016409\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.046600\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.047126\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.121144\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.084020\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.021745\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.064025\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.024163\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.049042\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.010326\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.126367\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.039219\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.037119\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.115019\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.083654\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.007824\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.095518\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.115857\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.106628\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.012055\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.052923\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.014468\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.015239\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.014743\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.082915\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.013684\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.006586\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.030120\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.015712\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.037010\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.030128\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.161799\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.321314\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.029748\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.019447\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.007946\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.017175\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.077854\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.022840\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.030603\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.154227\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.102439\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.029625\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.015493\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.065063\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.086727\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.171581\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.080362\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.047352\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.051299\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.008789\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.071717\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.118846\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.070602\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.032612\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.104701\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.023062\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.009843\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.114159\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.003888\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.022025\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.027243\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.015363\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.006719\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.031626\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.034186\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.026126\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.072584\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/13906 (0%)]\tLoss: 0.210034\n",
      "Train Epoch: 1 [640/13906 (5%)]\tLoss: 0.046540\n",
      "Train Epoch: 1 [1280/13906 (9%)]\tLoss: 0.023305\n",
      "Train Epoch: 1 [1920/13906 (14%)]\tLoss: 0.155863\n",
      "Train Epoch: 1 [2560/13906 (18%)]\tLoss: 0.100982\n",
      "Train Epoch: 1 [3200/13906 (23%)]\tLoss: 0.048894\n",
      "Train Epoch: 1 [3840/13906 (28%)]\tLoss: 0.128280\n",
      "Train Epoch: 1 [4480/13906 (32%)]\tLoss: 0.151118\n",
      "Train Epoch: 1 [5120/13906 (37%)]\tLoss: 0.056092\n",
      "Train Epoch: 1 [5760/13906 (41%)]\tLoss: 0.049098\n",
      "Train Epoch: 1 [6400/13906 (46%)]\tLoss: 0.018519\n",
      "Train Epoch: 1 [7040/13906 (50%)]\tLoss: 0.063594\n",
      "Train Epoch: 1 [7680/13906 (55%)]\tLoss: 0.039737\n",
      "Train Epoch: 1 [8320/13906 (60%)]\tLoss: 0.019790\n",
      "Train Epoch: 1 [8960/13906 (64%)]\tLoss: 0.032765\n",
      "Train Epoch: 1 [9600/13906 (69%)]\tLoss: 0.121223\n",
      "Train Epoch: 1 [10240/13906 (73%)]\tLoss: 0.087986\n",
      "Train Epoch: 1 [10880/13906 (78%)]\tLoss: 0.089069\n",
      "Train Epoch: 1 [11520/13906 (83%)]\tLoss: 0.117840\n",
      "Train Epoch: 1 [12160/13906 (87%)]\tLoss: 0.075960\n",
      "Train Epoch: 1 [12800/13906 (92%)]\tLoss: 0.031466\n",
      "Train Epoch: 1 [13440/13906 (96%)]\tLoss: 0.104148\n",
      "Train Epoch: 2 [0/13906 (0%)]\tLoss: 0.061687\n",
      "Train Epoch: 2 [640/13906 (5%)]\tLoss: 0.030772\n",
      "Train Epoch: 2 [1280/13906 (9%)]\tLoss: 0.071905\n",
      "Train Epoch: 2 [1920/13906 (14%)]\tLoss: 0.020496\n",
      "Train Epoch: 2 [2560/13906 (18%)]\tLoss: 0.058503\n",
      "Train Epoch: 2 [3200/13906 (23%)]\tLoss: 0.019729\n",
      "Train Epoch: 2 [3840/13906 (28%)]\tLoss: 0.089634\n",
      "Train Epoch: 2 [4480/13906 (32%)]\tLoss: 0.188869\n",
      "Train Epoch: 2 [5120/13906 (37%)]\tLoss: 0.091643\n",
      "Train Epoch: 2 [5760/13906 (41%)]\tLoss: 0.133219\n",
      "Train Epoch: 2 [6400/13906 (46%)]\tLoss: 0.040564\n",
      "Train Epoch: 2 [7040/13906 (50%)]\tLoss: 0.055584\n",
      "Train Epoch: 2 [7680/13906 (55%)]\tLoss: 0.043287\n",
      "Train Epoch: 2 [8320/13906 (60%)]\tLoss: 0.010019\n",
      "Train Epoch: 2 [8960/13906 (64%)]\tLoss: 0.061638\n",
      "Train Epoch: 2 [9600/13906 (69%)]\tLoss: 0.050389\n",
      "Train Epoch: 2 [10240/13906 (73%)]\tLoss: 0.030270\n",
      "Train Epoch: 2 [10880/13906 (78%)]\tLoss: 0.019518\n",
      "Train Epoch: 2 [11520/13906 (83%)]\tLoss: 0.081975\n",
      "Train Epoch: 2 [12160/13906 (87%)]\tLoss: 0.011248\n",
      "Train Epoch: 2 [12800/13906 (92%)]\tLoss: 0.041254\n",
      "Train Epoch: 2 [13440/13906 (96%)]\tLoss: 0.019786\n",
      "Train Epoch: 3 [0/13906 (0%)]\tLoss: 0.060408\n",
      "Train Epoch: 3 [640/13906 (5%)]\tLoss: 0.026837\n",
      "Train Epoch: 3 [1280/13906 (9%)]\tLoss: 0.311519\n",
      "Train Epoch: 3 [1920/13906 (14%)]\tLoss: 0.029072\n",
      "Train Epoch: 3 [2560/13906 (18%)]\tLoss: 0.055172\n",
      "Train Epoch: 3 [3200/13906 (23%)]\tLoss: 0.061491\n",
      "Train Epoch: 3 [3840/13906 (28%)]\tLoss: 0.035198\n",
      "Train Epoch: 3 [4480/13906 (32%)]\tLoss: 0.092558\n",
      "Train Epoch: 3 [5120/13906 (37%)]\tLoss: 0.023308\n",
      "Train Epoch: 3 [5760/13906 (41%)]\tLoss: 0.064867\n",
      "Train Epoch: 3 [6400/13906 (46%)]\tLoss: 0.077301\n",
      "Train Epoch: 3 [7040/13906 (50%)]\tLoss: 0.048980\n",
      "Train Epoch: 3 [7680/13906 (55%)]\tLoss: 0.096932\n",
      "Train Epoch: 3 [8320/13906 (60%)]\tLoss: 0.039262\n",
      "Train Epoch: 3 [8960/13906 (64%)]\tLoss: 0.036080\n",
      "Train Epoch: 3 [9600/13906 (69%)]\tLoss: 0.029989\n",
      "Train Epoch: 3 [10240/13906 (73%)]\tLoss: 0.124846\n",
      "Train Epoch: 3 [10880/13906 (78%)]\tLoss: 0.181686\n",
      "Train Epoch: 3 [11520/13906 (83%)]\tLoss: 0.075273\n",
      "Train Epoch: 3 [12160/13906 (87%)]\tLoss: 0.016604\n",
      "Train Epoch: 3 [12800/13906 (92%)]\tLoss: 0.050688\n",
      "Train Epoch: 3 [13440/13906 (96%)]\tLoss: 0.051509\n",
      "Train Epoch: 4 [0/13906 (0%)]\tLoss: 0.120443\n",
      "Train Epoch: 4 [640/13906 (5%)]\tLoss: 0.057387\n",
      "Train Epoch: 4 [1280/13906 (9%)]\tLoss: 0.125853\n",
      "Train Epoch: 4 [1920/13906 (14%)]\tLoss: 0.069868\n",
      "Train Epoch: 4 [2560/13906 (18%)]\tLoss: 0.005158\n",
      "Train Epoch: 4 [3200/13906 (23%)]\tLoss: 0.023305\n",
      "Train Epoch: 4 [3840/13906 (28%)]\tLoss: 0.116477\n",
      "Train Epoch: 4 [4480/13906 (32%)]\tLoss: 0.027909\n",
      "Train Epoch: 4 [5120/13906 (37%)]\tLoss: 0.044241\n",
      "Train Epoch: 4 [5760/13906 (41%)]\tLoss: 0.108318\n",
      "Train Epoch: 4 [6400/13906 (46%)]\tLoss: 0.045691\n",
      "Train Epoch: 4 [7040/13906 (50%)]\tLoss: 0.079039\n",
      "Train Epoch: 4 [7680/13906 (55%)]\tLoss: 0.050483\n",
      "Train Epoch: 4 [8320/13906 (60%)]\tLoss: 0.215732\n",
      "Train Epoch: 4 [8960/13906 (64%)]\tLoss: 0.033567\n",
      "Train Epoch: 4 [9600/13906 (69%)]\tLoss: 0.052232\n",
      "Train Epoch: 4 [10240/13906 (73%)]\tLoss: 0.187520\n",
      "Train Epoch: 4 [10880/13906 (78%)]\tLoss: 0.026786\n",
      "Train Epoch: 4 [11520/13906 (83%)]\tLoss: 0.024298\n",
      "Train Epoch: 4 [12160/13906 (87%)]\tLoss: 0.108269\n",
      "Train Epoch: 4 [12800/13906 (92%)]\tLoss: 0.106762\n",
      "Train Epoch: 4 [13440/13906 (96%)]\tLoss: 0.023679\n",
      "Train Epoch: 5 [0/13906 (0%)]\tLoss: 0.005847\n",
      "Train Epoch: 5 [640/13906 (5%)]\tLoss: 0.051663\n",
      "Train Epoch: 5 [1280/13906 (9%)]\tLoss: 0.025153\n",
      "Train Epoch: 5 [1920/13906 (14%)]\tLoss: 0.056961\n",
      "Train Epoch: 5 [2560/13906 (18%)]\tLoss: 0.370275\n",
      "Train Epoch: 5 [3200/13906 (23%)]\tLoss: 0.072063\n",
      "Train Epoch: 5 [3840/13906 (28%)]\tLoss: 0.014518\n",
      "Train Epoch: 5 [4480/13906 (32%)]\tLoss: 0.050591\n",
      "Train Epoch: 5 [5120/13906 (37%)]\tLoss: 0.057166\n",
      "Train Epoch: 5 [5760/13906 (41%)]\tLoss: 0.055833\n",
      "Train Epoch: 5 [6400/13906 (46%)]\tLoss: 0.134579\n",
      "Train Epoch: 5 [7040/13906 (50%)]\tLoss: 0.060651\n",
      "Train Epoch: 5 [7680/13906 (55%)]\tLoss: 0.005421\n",
      "Train Epoch: 5 [8320/13906 (60%)]\tLoss: 0.076154\n",
      "Train Epoch: 5 [8960/13906 (64%)]\tLoss: 0.059127\n",
      "Train Epoch: 5 [9600/13906 (69%)]\tLoss: 0.024932\n",
      "Train Epoch: 5 [10240/13906 (73%)]\tLoss: 0.111856\n",
      "Train Epoch: 5 [10880/13906 (78%)]\tLoss: 0.057026\n",
      "Train Epoch: 5 [11520/13906 (83%)]\tLoss: 0.100869\n",
      "Train Epoch: 5 [12160/13906 (87%)]\tLoss: 0.005312\n",
      "Train Epoch: 5 [12800/13906 (92%)]\tLoss: 0.058357\n",
      "Train Epoch: 5 [13440/13906 (96%)]\tLoss: 0.011168\n",
      "Train Epoch: 6 [0/13906 (0%)]\tLoss: 0.021913\n",
      "Train Epoch: 6 [640/13906 (5%)]\tLoss: 0.053557\n",
      "Train Epoch: 6 [1280/13906 (9%)]\tLoss: 0.045009\n",
      "Train Epoch: 6 [1920/13906 (14%)]\tLoss: 0.104734\n",
      "Train Epoch: 6 [2560/13906 (18%)]\tLoss: 0.112408\n",
      "Train Epoch: 6 [3200/13906 (23%)]\tLoss: 0.039355\n",
      "Train Epoch: 6 [3840/13906 (28%)]\tLoss: 0.078430\n",
      "Train Epoch: 6 [4480/13906 (32%)]\tLoss: 0.065405\n",
      "Train Epoch: 6 [5120/13906 (37%)]\tLoss: 0.078352\n",
      "Train Epoch: 6 [5760/13906 (41%)]\tLoss: 0.083994\n",
      "Train Epoch: 6 [6400/13906 (46%)]\tLoss: 0.006258\n",
      "Train Epoch: 6 [7040/13906 (50%)]\tLoss: 0.059271\n",
      "Train Epoch: 6 [7680/13906 (55%)]\tLoss: 0.023202\n",
      "Train Epoch: 6 [8320/13906 (60%)]\tLoss: 0.036998\n",
      "Train Epoch: 6 [8960/13906 (64%)]\tLoss: 0.059285\n",
      "Train Epoch: 6 [9600/13906 (69%)]\tLoss: 0.045818\n",
      "Train Epoch: 6 [10240/13906 (73%)]\tLoss: 0.094148\n",
      "Train Epoch: 6 [10880/13906 (78%)]\tLoss: 0.006489\n",
      "Train Epoch: 6 [11520/13906 (83%)]\tLoss: 0.058296\n",
      "Train Epoch: 6 [12160/13906 (87%)]\tLoss: 0.007802\n",
      "Train Epoch: 6 [12800/13906 (92%)]\tLoss: 0.031408\n",
      "Train Epoch: 6 [13440/13906 (96%)]\tLoss: 0.026476\n",
      "Train Epoch: 7 [0/13906 (0%)]\tLoss: 0.033996\n",
      "Train Epoch: 7 [640/13906 (5%)]\tLoss: 0.038365\n",
      "Train Epoch: 7 [1280/13906 (9%)]\tLoss: 0.062768\n",
      "Train Epoch: 7 [1920/13906 (14%)]\tLoss: 0.040255\n",
      "Train Epoch: 7 [2560/13906 (18%)]\tLoss: 0.052153\n",
      "Train Epoch: 7 [3200/13906 (23%)]\tLoss: 0.090876\n",
      "Train Epoch: 7 [3840/13906 (28%)]\tLoss: 0.126701\n",
      "Train Epoch: 7 [4480/13906 (32%)]\tLoss: 0.065444\n",
      "Train Epoch: 7 [5120/13906 (37%)]\tLoss: 0.060096\n",
      "Train Epoch: 7 [5760/13906 (41%)]\tLoss: 0.204599\n",
      "Train Epoch: 7 [6400/13906 (46%)]\tLoss: 0.020345\n",
      "Train Epoch: 7 [7040/13906 (50%)]\tLoss: 0.033385\n",
      "Train Epoch: 7 [7680/13906 (55%)]\tLoss: 0.106762\n",
      "Train Epoch: 7 [8320/13906 (60%)]\tLoss: 0.012552\n",
      "Train Epoch: 7 [8960/13906 (64%)]\tLoss: 0.126444\n",
      "Train Epoch: 7 [9600/13906 (69%)]\tLoss: 0.020088\n",
      "Train Epoch: 7 [10240/13906 (73%)]\tLoss: 0.040845\n",
      "Train Epoch: 7 [10880/13906 (78%)]\tLoss: 0.022138\n",
      "Train Epoch: 7 [11520/13906 (83%)]\tLoss: 0.201712\n",
      "Train Epoch: 7 [12160/13906 (87%)]\tLoss: 0.018569\n",
      "Train Epoch: 7 [12800/13906 (92%)]\tLoss: 0.034561\n",
      "Train Epoch: 7 [13440/13906 (96%)]\tLoss: 0.046928\n",
      "Train Epoch: 8 [0/13906 (0%)]\tLoss: 0.022412\n",
      "Train Epoch: 8 [640/13906 (5%)]\tLoss: 0.061257\n",
      "Train Epoch: 8 [1280/13906 (9%)]\tLoss: 0.077751\n",
      "Train Epoch: 8 [1920/13906 (14%)]\tLoss: 0.126634\n",
      "Train Epoch: 8 [2560/13906 (18%)]\tLoss: 0.101678\n",
      "Train Epoch: 8 [3200/13906 (23%)]\tLoss: 0.059066\n",
      "Train Epoch: 8 [3840/13906 (28%)]\tLoss: 0.052718\n",
      "Train Epoch: 8 [4480/13906 (32%)]\tLoss: 0.008317\n",
      "Train Epoch: 8 [5120/13906 (37%)]\tLoss: 0.024854\n",
      "Train Epoch: 8 [5760/13906 (41%)]\tLoss: 0.019233\n",
      "Train Epoch: 8 [6400/13906 (46%)]\tLoss: 0.020325\n",
      "Train Epoch: 8 [7040/13906 (50%)]\tLoss: 0.049304\n",
      "Train Epoch: 8 [7680/13906 (55%)]\tLoss: 0.081354\n",
      "Train Epoch: 8 [8320/13906 (60%)]\tLoss: 0.028443\n",
      "Train Epoch: 8 [8960/13906 (64%)]\tLoss: 0.076887\n",
      "Train Epoch: 8 [9600/13906 (69%)]\tLoss: 0.019763\n",
      "Train Epoch: 8 [10240/13906 (73%)]\tLoss: 0.021021\n",
      "Train Epoch: 8 [10880/13906 (78%)]\tLoss: 0.035515\n",
      "Train Epoch: 8 [11520/13906 (83%)]\tLoss: 0.144859\n",
      "Train Epoch: 8 [12160/13906 (87%)]\tLoss: 0.475014\n",
      "Train Epoch: 8 [12800/13906 (92%)]\tLoss: 0.042756\n",
      "Train Epoch: 8 [13440/13906 (96%)]\tLoss: 0.022700\n",
      "Train Epoch: 9 [0/13906 (0%)]\tLoss: 0.057286\n",
      "Train Epoch: 9 [640/13906 (5%)]\tLoss: 0.111148\n",
      "Train Epoch: 9 [1280/13906 (9%)]\tLoss: 0.093881\n",
      "Train Epoch: 9 [1920/13906 (14%)]\tLoss: 0.034461\n",
      "Train Epoch: 9 [2560/13906 (18%)]\tLoss: 0.051864\n",
      "Train Epoch: 9 [3200/13906 (23%)]\tLoss: 0.042381\n",
      "Train Epoch: 9 [3840/13906 (28%)]\tLoss: 0.087133\n",
      "Train Epoch: 9 [4480/13906 (32%)]\tLoss: 0.016996\n",
      "Train Epoch: 9 [5120/13906 (37%)]\tLoss: 0.032549\n",
      "Train Epoch: 9 [5760/13906 (41%)]\tLoss: 0.009205\n",
      "Train Epoch: 9 [6400/13906 (46%)]\tLoss: 0.066275\n",
      "Train Epoch: 9 [7040/13906 (50%)]\tLoss: 0.057118\n",
      "Train Epoch: 9 [7680/13906 (55%)]\tLoss: 0.034744\n",
      "Train Epoch: 9 [8320/13906 (60%)]\tLoss: 0.046495\n",
      "Train Epoch: 9 [8960/13906 (64%)]\tLoss: 0.023266\n",
      "Train Epoch: 9 [9600/13906 (69%)]\tLoss: 0.068877\n",
      "Train Epoch: 9 [10240/13906 (73%)]\tLoss: 0.186287\n",
      "Train Epoch: 9 [10880/13906 (78%)]\tLoss: 0.062582\n",
      "Train Epoch: 9 [11520/13906 (83%)]\tLoss: 0.088202\n",
      "Train Epoch: 9 [12160/13906 (87%)]\tLoss: 0.059065\n",
      "Train Epoch: 9 [12800/13906 (92%)]\tLoss: 0.010935\n",
      "Train Epoch: 9 [13440/13906 (96%)]\tLoss: 0.010710\n",
      "Train Epoch: 10 [0/13906 (0%)]\tLoss: 0.003303\n",
      "Train Epoch: 10 [640/13906 (5%)]\tLoss: 0.067405\n",
      "Train Epoch: 10 [1280/13906 (9%)]\tLoss: 0.029044\n",
      "Train Epoch: 10 [1920/13906 (14%)]\tLoss: 0.113418\n",
      "Train Epoch: 10 [2560/13906 (18%)]\tLoss: 0.088037\n",
      "Train Epoch: 10 [3200/13906 (23%)]\tLoss: 0.053852\n",
      "Train Epoch: 10 [3840/13906 (28%)]\tLoss: 0.095711\n",
      "Train Epoch: 10 [4480/13906 (32%)]\tLoss: 0.064763\n",
      "Train Epoch: 10 [5120/13906 (37%)]\tLoss: 0.021586\n",
      "Train Epoch: 10 [5760/13906 (41%)]\tLoss: 0.016246\n",
      "Train Epoch: 10 [6400/13906 (46%)]\tLoss: 0.016787\n",
      "Train Epoch: 10 [7040/13906 (50%)]\tLoss: 0.007976\n",
      "Train Epoch: 10 [7680/13906 (55%)]\tLoss: 0.147862\n",
      "Train Epoch: 10 [8320/13906 (60%)]\tLoss: 0.026397\n",
      "Train Epoch: 10 [8960/13906 (64%)]\tLoss: 0.044958\n",
      "Train Epoch: 10 [9600/13906 (69%)]\tLoss: 0.280323\n",
      "Train Epoch: 10 [10240/13906 (73%)]\tLoss: 0.023428\n",
      "Train Epoch: 10 [10880/13906 (78%)]\tLoss: 0.010654\n",
      "Train Epoch: 10 [11520/13906 (83%)]\tLoss: 0.222034\n",
      "Train Epoch: 10 [12160/13906 (87%)]\tLoss: 0.067868\n",
      "Train Epoch: 10 [12800/13906 (92%)]\tLoss: 0.015583\n",
      "Train Epoch: 10 [13440/13906 (96%)]\tLoss: 0.037431\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/11862 (0%)]\tLoss: 0.073650\n",
      "Train Epoch: 1 [640/11862 (5%)]\tLoss: 0.050161\n",
      "Train Epoch: 1 [1280/11862 (11%)]\tLoss: 0.028256\n",
      "Train Epoch: 1 [1920/11862 (16%)]\tLoss: 0.076027\n",
      "Train Epoch: 1 [2560/11862 (22%)]\tLoss: 0.058963\n",
      "Train Epoch: 1 [3200/11862 (27%)]\tLoss: 0.089241\n",
      "Train Epoch: 1 [3840/11862 (32%)]\tLoss: 0.073497\n",
      "Train Epoch: 1 [4480/11862 (38%)]\tLoss: 0.030273\n",
      "Train Epoch: 1 [5120/11862 (43%)]\tLoss: 0.082023\n",
      "Train Epoch: 1 [5760/11862 (48%)]\tLoss: 0.033005\n",
      "Train Epoch: 1 [6400/11862 (54%)]\tLoss: 0.020538\n",
      "Train Epoch: 1 [7040/11862 (59%)]\tLoss: 0.007993\n",
      "Train Epoch: 1 [7680/11862 (65%)]\tLoss: 0.044908\n",
      "Train Epoch: 1 [8320/11862 (70%)]\tLoss: 0.081147\n",
      "Train Epoch: 1 [8960/11862 (75%)]\tLoss: 0.069166\n",
      "Train Epoch: 1 [9600/11862 (81%)]\tLoss: 0.174292\n",
      "Train Epoch: 1 [10240/11862 (86%)]\tLoss: 0.025647\n",
      "Train Epoch: 1 [10880/11862 (91%)]\tLoss: 0.187936\n",
      "Train Epoch: 1 [11520/11862 (97%)]\tLoss: 0.020204\n",
      "Train Epoch: 2 [0/11862 (0%)]\tLoss: 0.092249\n",
      "Train Epoch: 2 [640/11862 (5%)]\tLoss: 0.217874\n",
      "Train Epoch: 2 [1280/11862 (11%)]\tLoss: 0.047308\n",
      "Train Epoch: 2 [1920/11862 (16%)]\tLoss: 0.029855\n",
      "Train Epoch: 2 [2560/11862 (22%)]\tLoss: 0.010912\n",
      "Train Epoch: 2 [3200/11862 (27%)]\tLoss: 0.095608\n",
      "Train Epoch: 2 [3840/11862 (32%)]\tLoss: 0.017430\n",
      "Train Epoch: 2 [4480/11862 (38%)]\tLoss: 0.136688\n",
      "Train Epoch: 2 [5120/11862 (43%)]\tLoss: 0.084450\n",
      "Train Epoch: 2 [5760/11862 (48%)]\tLoss: 0.037875\n",
      "Train Epoch: 2 [6400/11862 (54%)]\tLoss: 0.019633\n",
      "Train Epoch: 2 [7040/11862 (59%)]\tLoss: 0.117807\n",
      "Train Epoch: 2 [7680/11862 (65%)]\tLoss: 0.091906\n",
      "Train Epoch: 2 [8320/11862 (70%)]\tLoss: 0.011862\n",
      "Train Epoch: 2 [8960/11862 (75%)]\tLoss: 0.037775\n",
      "Train Epoch: 2 [9600/11862 (81%)]\tLoss: 0.043095\n",
      "Train Epoch: 2 [10240/11862 (86%)]\tLoss: 0.045084\n",
      "Train Epoch: 2 [10880/11862 (91%)]\tLoss: 0.071772\n",
      "Train Epoch: 2 [11520/11862 (97%)]\tLoss: 0.119603\n",
      "Train Epoch: 3 [0/11862 (0%)]\tLoss: 0.024278\n",
      "Train Epoch: 3 [640/11862 (5%)]\tLoss: 0.039375\n",
      "Train Epoch: 3 [1280/11862 (11%)]\tLoss: 0.011824\n",
      "Train Epoch: 3 [1920/11862 (16%)]\tLoss: 0.020123\n",
      "Train Epoch: 3 [2560/11862 (22%)]\tLoss: 0.007034\n",
      "Train Epoch: 3 [3200/11862 (27%)]\tLoss: 0.027988\n",
      "Train Epoch: 3 [3840/11862 (32%)]\tLoss: 0.063168\n",
      "Train Epoch: 3 [4480/11862 (38%)]\tLoss: 0.219329\n",
      "Train Epoch: 3 [5120/11862 (43%)]\tLoss: 0.121934\n",
      "Train Epoch: 3 [5760/11862 (48%)]\tLoss: 0.101206\n",
      "Train Epoch: 3 [6400/11862 (54%)]\tLoss: 0.031446\n",
      "Train Epoch: 3 [7040/11862 (59%)]\tLoss: 0.086970\n",
      "Train Epoch: 3 [7680/11862 (65%)]\tLoss: 0.050628\n",
      "Train Epoch: 3 [8320/11862 (70%)]\tLoss: 0.019217\n",
      "Train Epoch: 3 [8960/11862 (75%)]\tLoss: 0.050845\n",
      "Train Epoch: 3 [9600/11862 (81%)]\tLoss: 0.002332\n",
      "Train Epoch: 3 [10240/11862 (86%)]\tLoss: 0.051020\n",
      "Train Epoch: 3 [10880/11862 (91%)]\tLoss: 0.013275\n",
      "Train Epoch: 3 [11520/11862 (97%)]\tLoss: 0.161428\n",
      "Train Epoch: 4 [0/11862 (0%)]\tLoss: 0.007121\n",
      "Train Epoch: 4 [640/11862 (5%)]\tLoss: 0.017156\n",
      "Train Epoch: 4 [1280/11862 (11%)]\tLoss: 0.030250\n",
      "Train Epoch: 4 [1920/11862 (16%)]\tLoss: 0.045390\n",
      "Train Epoch: 4 [2560/11862 (22%)]\tLoss: 0.074281\n",
      "Train Epoch: 4 [3200/11862 (27%)]\tLoss: 0.025718\n",
      "Train Epoch: 4 [3840/11862 (32%)]\tLoss: 0.003524\n",
      "Train Epoch: 4 [4480/11862 (38%)]\tLoss: 0.008773\n",
      "Train Epoch: 4 [5120/11862 (43%)]\tLoss: 0.073887\n",
      "Train Epoch: 4 [5760/11862 (48%)]\tLoss: 0.011847\n",
      "Train Epoch: 4 [6400/11862 (54%)]\tLoss: 0.038535\n",
      "Train Epoch: 4 [7040/11862 (59%)]\tLoss: 0.023327\n",
      "Train Epoch: 4 [7680/11862 (65%)]\tLoss: 0.217845\n",
      "Train Epoch: 4 [8320/11862 (70%)]\tLoss: 0.010585\n",
      "Train Epoch: 4 [8960/11862 (75%)]\tLoss: 0.023409\n",
      "Train Epoch: 4 [9600/11862 (81%)]\tLoss: 0.030956\n",
      "Train Epoch: 4 [10240/11862 (86%)]\tLoss: 0.009400\n",
      "Train Epoch: 4 [10880/11862 (91%)]\tLoss: 0.083874\n",
      "Train Epoch: 4 [11520/11862 (97%)]\tLoss: 0.151238\n",
      "Train Epoch: 5 [0/11862 (0%)]\tLoss: 0.025051\n",
      "Train Epoch: 5 [640/11862 (5%)]\tLoss: 0.011451\n",
      "Train Epoch: 5 [1280/11862 (11%)]\tLoss: 0.003224\n",
      "Train Epoch: 5 [1920/11862 (16%)]\tLoss: 0.018989\n",
      "Train Epoch: 5 [2560/11862 (22%)]\tLoss: 0.054212\n",
      "Train Epoch: 5 [3200/11862 (27%)]\tLoss: 0.035364\n",
      "Train Epoch: 5 [3840/11862 (32%)]\tLoss: 0.104531\n",
      "Train Epoch: 5 [4480/11862 (38%)]\tLoss: 0.020218\n",
      "Train Epoch: 5 [5120/11862 (43%)]\tLoss: 0.015064\n",
      "Train Epoch: 5 [5760/11862 (48%)]\tLoss: 0.121492\n",
      "Train Epoch: 5 [6400/11862 (54%)]\tLoss: 0.016322\n",
      "Train Epoch: 5 [7040/11862 (59%)]\tLoss: 0.015931\n",
      "Train Epoch: 5 [7680/11862 (65%)]\tLoss: 0.023089\n",
      "Train Epoch: 5 [8320/11862 (70%)]\tLoss: 0.173724\n",
      "Train Epoch: 5 [8960/11862 (75%)]\tLoss: 0.015709\n",
      "Train Epoch: 5 [9600/11862 (81%)]\tLoss: 0.016944\n",
      "Train Epoch: 5 [10240/11862 (86%)]\tLoss: 0.006012\n",
      "Train Epoch: 5 [10880/11862 (91%)]\tLoss: 0.038202\n",
      "Train Epoch: 5 [11520/11862 (97%)]\tLoss: 0.021949\n",
      "Train Epoch: 6 [0/11862 (0%)]\tLoss: 0.034396\n",
      "Train Epoch: 6 [640/11862 (5%)]\tLoss: 0.062867\n",
      "Train Epoch: 6 [1280/11862 (11%)]\tLoss: 0.031668\n",
      "Train Epoch: 6 [1920/11862 (16%)]\tLoss: 0.019540\n",
      "Train Epoch: 6 [2560/11862 (22%)]\tLoss: 0.057798\n",
      "Train Epoch: 6 [3200/11862 (27%)]\tLoss: 0.082692\n",
      "Train Epoch: 6 [3840/11862 (32%)]\tLoss: 0.022649\n",
      "Train Epoch: 6 [4480/11862 (38%)]\tLoss: 0.069159\n",
      "Train Epoch: 6 [5120/11862 (43%)]\tLoss: 0.028214\n",
      "Train Epoch: 6 [5760/11862 (48%)]\tLoss: 0.087948\n",
      "Train Epoch: 6 [6400/11862 (54%)]\tLoss: 0.056636\n",
      "Train Epoch: 6 [7040/11862 (59%)]\tLoss: 0.004415\n",
      "Train Epoch: 6 [7680/11862 (65%)]\tLoss: 0.034326\n",
      "Train Epoch: 6 [8320/11862 (70%)]\tLoss: 0.017794\n",
      "Train Epoch: 6 [8960/11862 (75%)]\tLoss: 0.051768\n",
      "Train Epoch: 6 [9600/11862 (81%)]\tLoss: 0.031014\n",
      "Train Epoch: 6 [10240/11862 (86%)]\tLoss: 0.023542\n",
      "Train Epoch: 6 [10880/11862 (91%)]\tLoss: 0.018921\n",
      "Train Epoch: 6 [11520/11862 (97%)]\tLoss: 0.045739\n",
      "Train Epoch: 7 [0/11862 (0%)]\tLoss: 0.028985\n",
      "Train Epoch: 7 [640/11862 (5%)]\tLoss: 0.054792\n",
      "Train Epoch: 7 [1280/11862 (11%)]\tLoss: 0.055909\n",
      "Train Epoch: 7 [1920/11862 (16%)]\tLoss: 0.022159\n",
      "Train Epoch: 7 [2560/11862 (22%)]\tLoss: 0.015029\n",
      "Train Epoch: 7 [3200/11862 (27%)]\tLoss: 0.040563\n",
      "Train Epoch: 7 [3840/11862 (32%)]\tLoss: 0.029291\n",
      "Train Epoch: 7 [4480/11862 (38%)]\tLoss: 0.004783\n",
      "Train Epoch: 7 [5120/11862 (43%)]\tLoss: 0.046314\n",
      "Train Epoch: 7 [5760/11862 (48%)]\tLoss: 0.010971\n",
      "Train Epoch: 7 [6400/11862 (54%)]\tLoss: 0.010746\n",
      "Train Epoch: 7 [7040/11862 (59%)]\tLoss: 0.023706\n",
      "Train Epoch: 7 [7680/11862 (65%)]\tLoss: 0.026718\n",
      "Train Epoch: 7 [8320/11862 (70%)]\tLoss: 0.010903\n",
      "Train Epoch: 7 [8960/11862 (75%)]\tLoss: 0.112500\n",
      "Train Epoch: 7 [9600/11862 (81%)]\tLoss: 0.045253\n",
      "Train Epoch: 7 [10240/11862 (86%)]\tLoss: 0.019554\n",
      "Train Epoch: 7 [10880/11862 (91%)]\tLoss: 0.050369\n",
      "Train Epoch: 7 [11520/11862 (97%)]\tLoss: 0.023494\n",
      "Train Epoch: 8 [0/11862 (0%)]\tLoss: 0.002360\n",
      "Train Epoch: 8 [640/11862 (5%)]\tLoss: 0.048727\n",
      "Train Epoch: 8 [1280/11862 (11%)]\tLoss: 0.023421\n",
      "Train Epoch: 8 [1920/11862 (16%)]\tLoss: 0.011837\n",
      "Train Epoch: 8 [2560/11862 (22%)]\tLoss: 0.013407\n",
      "Train Epoch: 8 [3200/11862 (27%)]\tLoss: 0.005729\n",
      "Train Epoch: 8 [3840/11862 (32%)]\tLoss: 0.011907\n",
      "Train Epoch: 8 [4480/11862 (38%)]\tLoss: 0.063414\n",
      "Train Epoch: 8 [5120/11862 (43%)]\tLoss: 0.079566\n",
      "Train Epoch: 8 [5760/11862 (48%)]\tLoss: 0.049458\n",
      "Train Epoch: 8 [6400/11862 (54%)]\tLoss: 0.087718\n",
      "Train Epoch: 8 [7040/11862 (59%)]\tLoss: 0.042711\n",
      "Train Epoch: 8 [7680/11862 (65%)]\tLoss: 0.025436\n",
      "Train Epoch: 8 [8320/11862 (70%)]\tLoss: 0.055682\n",
      "Train Epoch: 8 [8960/11862 (75%)]\tLoss: 0.011892\n",
      "Train Epoch: 8 [9600/11862 (81%)]\tLoss: 0.002098\n",
      "Train Epoch: 8 [10240/11862 (86%)]\tLoss: 0.018392\n",
      "Train Epoch: 8 [10880/11862 (91%)]\tLoss: 0.020156\n",
      "Train Epoch: 8 [11520/11862 (97%)]\tLoss: 0.002186\n",
      "Train Epoch: 9 [0/11862 (0%)]\tLoss: 0.058952\n",
      "Train Epoch: 9 [640/11862 (5%)]\tLoss: 0.055316\n",
      "Train Epoch: 9 [1280/11862 (11%)]\tLoss: 0.033188\n",
      "Train Epoch: 9 [1920/11862 (16%)]\tLoss: 0.074368\n",
      "Train Epoch: 9 [2560/11862 (22%)]\tLoss: 0.032197\n",
      "Train Epoch: 9 [3200/11862 (27%)]\tLoss: 0.020885\n",
      "Train Epoch: 9 [3840/11862 (32%)]\tLoss: 0.053653\n",
      "Train Epoch: 9 [4480/11862 (38%)]\tLoss: 0.012172\n",
      "Train Epoch: 9 [5120/11862 (43%)]\tLoss: 0.007138\n",
      "Train Epoch: 9 [5760/11862 (48%)]\tLoss: 0.026154\n",
      "Train Epoch: 9 [6400/11862 (54%)]\tLoss: 0.053967\n",
      "Train Epoch: 9 [7040/11862 (59%)]\tLoss: 0.056154\n",
      "Train Epoch: 9 [7680/11862 (65%)]\tLoss: 0.017316\n",
      "Train Epoch: 9 [8320/11862 (70%)]\tLoss: 0.008523\n",
      "Train Epoch: 9 [8960/11862 (75%)]\tLoss: 0.055267\n",
      "Train Epoch: 9 [9600/11862 (81%)]\tLoss: 0.079304\n",
      "Train Epoch: 9 [10240/11862 (86%)]\tLoss: 0.036332\n",
      "Train Epoch: 9 [10880/11862 (91%)]\tLoss: 0.007879\n",
      "Train Epoch: 9 [11520/11862 (97%)]\tLoss: 0.077819\n",
      "Train Epoch: 10 [0/11862 (0%)]\tLoss: 0.019511\n",
      "Train Epoch: 10 [640/11862 (5%)]\tLoss: 0.068542\n",
      "Train Epoch: 10 [1280/11862 (11%)]\tLoss: 0.032781\n",
      "Train Epoch: 10 [1920/11862 (16%)]\tLoss: 0.004418\n",
      "Train Epoch: 10 [2560/11862 (22%)]\tLoss: 0.043782\n",
      "Train Epoch: 10 [3200/11862 (27%)]\tLoss: 0.002311\n",
      "Train Epoch: 10 [3840/11862 (32%)]\tLoss: 0.043363\n",
      "Train Epoch: 10 [4480/11862 (38%)]\tLoss: 0.020675\n",
      "Train Epoch: 10 [5120/11862 (43%)]\tLoss: 0.005665\n",
      "Train Epoch: 10 [5760/11862 (48%)]\tLoss: 0.017290\n",
      "Train Epoch: 10 [6400/11862 (54%)]\tLoss: 0.021381\n",
      "Train Epoch: 10 [7040/11862 (59%)]\tLoss: 0.034363\n",
      "Train Epoch: 10 [7680/11862 (65%)]\tLoss: 0.065776\n",
      "Train Epoch: 10 [8320/11862 (70%)]\tLoss: 0.055804\n",
      "Train Epoch: 10 [8960/11862 (75%)]\tLoss: 0.031095\n",
      "Train Epoch: 10 [9600/11862 (81%)]\tLoss: 0.043917\n",
      "Train Epoch: 10 [10240/11862 (86%)]\tLoss: 0.012540\n",
      "Train Epoch: 10 [10880/11862 (91%)]\tLoss: 0.014719\n",
      "Train Epoch: 10 [11520/11862 (97%)]\tLoss: 0.116198\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 0.036635\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 0.044976\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 0.071972\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 0.012499\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 0.219612\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 0.018215\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 0.091319\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 0.105941\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 0.040548\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 0.056509\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 0.045060\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 0.020306\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 0.047602\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 0.058459\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 0.073362\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 0.013297\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 0.015818\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.042376\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.005111\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.029522\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.121108\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.022591\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.098977\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.024924\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.019615\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.046000\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.009090\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.117127\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.008892\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.035199\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.023373\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.063977\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.045020\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.168443\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.044272\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.089580\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.027092\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.042228\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.017885\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.041022\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.039051\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.011963\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.128914\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.009450\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.050720\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.014512\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.057942\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.016593\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.074817\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.048043\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.083684\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.131539\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.077754\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.062039\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.070794\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.082337\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.037996\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.071390\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.008373\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.010070\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.047554\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.084612\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.048388\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.025354\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.021375\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.011664\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.191469\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.024483\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.114782\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.032516\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.036275\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.049225\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.058707\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.131346\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.021351\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.063894\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.014398\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.042693\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.008590\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.007963\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.047254\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.018060\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.011938\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.018559\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.021250\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.037733\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.087847\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.021554\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.029973\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.008650\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.050343\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.043672\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.016282\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.008987\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.031325\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.007667\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.030729\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.019141\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.024097\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.021068\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.131335\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.024363\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.108705\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.032911\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.007590\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.043948\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.012950\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.037229\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.004346\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.045200\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.023027\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.051946\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.012776\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.008734\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.007781\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.004315\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.024695\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.018255\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.010851\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.010162\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.025099\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.004851\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.010626\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.022204\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.016201\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.003587\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.176886\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.050379\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.069173\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.046878\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.019246\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.004593\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.009857\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.006422\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.036098\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.041162\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.029978\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.088778\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.001440\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.012762\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.062410\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.002417\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.124574\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.065539\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.004702\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.023549\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.051820\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.016955\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.011568\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.013823\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.021579\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.013913\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.038977\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.162847\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.053190\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.033707\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.099592\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.001240\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.044632\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.043851\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5509 (0%)]\tLoss: 0.422151\n",
      "Train Epoch: 1 [640/5509 (11%)]\tLoss: 0.057781\n",
      "Train Epoch: 1 [1280/5509 (23%)]\tLoss: 0.147395\n",
      "Train Epoch: 1 [1920/5509 (34%)]\tLoss: 0.035936\n",
      "Train Epoch: 1 [2560/5509 (46%)]\tLoss: 0.114633\n",
      "Train Epoch: 1 [3200/5509 (57%)]\tLoss: 0.013511\n",
      "Train Epoch: 1 [3840/5509 (69%)]\tLoss: 0.036528\n",
      "Train Epoch: 1 [4480/5509 (80%)]\tLoss: 0.302501\n",
      "Train Epoch: 1 [5120/5509 (92%)]\tLoss: 0.116276\n",
      "Train Epoch: 2 [0/5509 (0%)]\tLoss: 0.064857\n",
      "Train Epoch: 2 [640/5509 (11%)]\tLoss: 0.042143\n",
      "Train Epoch: 2 [1280/5509 (23%)]\tLoss: 0.034449\n",
      "Train Epoch: 2 [1920/5509 (34%)]\tLoss: 0.060148\n",
      "Train Epoch: 2 [2560/5509 (46%)]\tLoss: 0.036540\n",
      "Train Epoch: 2 [3200/5509 (57%)]\tLoss: 0.121224\n",
      "Train Epoch: 2 [3840/5509 (69%)]\tLoss: 0.087918\n",
      "Train Epoch: 2 [4480/5509 (80%)]\tLoss: 0.031106\n",
      "Train Epoch: 2 [5120/5509 (92%)]\tLoss: 0.032225\n",
      "Train Epoch: 3 [0/5509 (0%)]\tLoss: 0.064593\n",
      "Train Epoch: 3 [640/5509 (11%)]\tLoss: 0.064702\n",
      "Train Epoch: 3 [1280/5509 (23%)]\tLoss: 0.151631\n",
      "Train Epoch: 3 [1920/5509 (34%)]\tLoss: 0.063321\n",
      "Train Epoch: 3 [2560/5509 (46%)]\tLoss: 0.028781\n",
      "Train Epoch: 3 [3200/5509 (57%)]\tLoss: 0.061231\n",
      "Train Epoch: 3 [3840/5509 (69%)]\tLoss: 0.012905\n",
      "Train Epoch: 3 [4480/5509 (80%)]\tLoss: 0.065141\n",
      "Train Epoch: 3 [5120/5509 (92%)]\tLoss: 0.095848\n",
      "Train Epoch: 4 [0/5509 (0%)]\tLoss: 0.129185\n",
      "Train Epoch: 4 [640/5509 (11%)]\tLoss: 0.042140\n",
      "Train Epoch: 4 [1280/5509 (23%)]\tLoss: 0.029938\n",
      "Train Epoch: 4 [1920/5509 (34%)]\tLoss: 0.061267\n",
      "Train Epoch: 4 [2560/5509 (46%)]\tLoss: 0.041075\n",
      "Train Epoch: 4 [3200/5509 (57%)]\tLoss: 0.022587\n",
      "Train Epoch: 4 [3840/5509 (69%)]\tLoss: 0.013410\n",
      "Train Epoch: 4 [4480/5509 (80%)]\tLoss: 0.024477\n",
      "Train Epoch: 4 [5120/5509 (92%)]\tLoss: 0.063439\n",
      "Train Epoch: 5 [0/5509 (0%)]\tLoss: 0.135010\n",
      "Train Epoch: 5 [640/5509 (11%)]\tLoss: 0.016024\n",
      "Train Epoch: 5 [1280/5509 (23%)]\tLoss: 0.032581\n",
      "Train Epoch: 5 [1920/5509 (34%)]\tLoss: 0.039053\n",
      "Train Epoch: 5 [2560/5509 (46%)]\tLoss: 0.151711\n",
      "Train Epoch: 5 [3200/5509 (57%)]\tLoss: 0.016059\n",
      "Train Epoch: 5 [3840/5509 (69%)]\tLoss: 0.133220\n",
      "Train Epoch: 5 [4480/5509 (80%)]\tLoss: 0.078954\n",
      "Train Epoch: 5 [5120/5509 (92%)]\tLoss: 0.025569\n",
      "Train Epoch: 6 [0/5509 (0%)]\tLoss: 0.027447\n",
      "Train Epoch: 6 [640/5509 (11%)]\tLoss: 0.007811\n",
      "Train Epoch: 6 [1280/5509 (23%)]\tLoss: 0.029910\n",
      "Train Epoch: 6 [1920/5509 (34%)]\tLoss: 0.033484\n",
      "Train Epoch: 6 [2560/5509 (46%)]\tLoss: 0.046836\n",
      "Train Epoch: 6 [3200/5509 (57%)]\tLoss: 0.027455\n",
      "Train Epoch: 6 [3840/5509 (69%)]\tLoss: 0.110054\n",
      "Train Epoch: 6 [4480/5509 (80%)]\tLoss: 0.042481\n",
      "Train Epoch: 6 [5120/5509 (92%)]\tLoss: 0.054021\n",
      "Train Epoch: 7 [0/5509 (0%)]\tLoss: 0.006563\n",
      "Train Epoch: 7 [640/5509 (11%)]\tLoss: 0.027535\n",
      "Train Epoch: 7 [1280/5509 (23%)]\tLoss: 0.129882\n",
      "Train Epoch: 7 [1920/5509 (34%)]\tLoss: 0.006519\n",
      "Train Epoch: 7 [2560/5509 (46%)]\tLoss: 0.050758\n",
      "Train Epoch: 7 [3200/5509 (57%)]\tLoss: 0.034964\n",
      "Train Epoch: 7 [3840/5509 (69%)]\tLoss: 0.011791\n",
      "Train Epoch: 7 [4480/5509 (80%)]\tLoss: 0.044282\n",
      "Train Epoch: 7 [5120/5509 (92%)]\tLoss: 0.082409\n",
      "Train Epoch: 8 [0/5509 (0%)]\tLoss: 0.017226\n",
      "Train Epoch: 8 [640/5509 (11%)]\tLoss: 0.024790\n",
      "Train Epoch: 8 [1280/5509 (23%)]\tLoss: 0.054544\n",
      "Train Epoch: 8 [1920/5509 (34%)]\tLoss: 0.014464\n",
      "Train Epoch: 8 [2560/5509 (46%)]\tLoss: 0.101720\n",
      "Train Epoch: 8 [3200/5509 (57%)]\tLoss: 0.046350\n",
      "Train Epoch: 8 [3840/5509 (69%)]\tLoss: 0.052279\n",
      "Train Epoch: 8 [4480/5509 (80%)]\tLoss: 0.010812\n",
      "Train Epoch: 8 [5120/5509 (92%)]\tLoss: 0.071532\n",
      "Train Epoch: 9 [0/5509 (0%)]\tLoss: 0.041455\n",
      "Train Epoch: 9 [640/5509 (11%)]\tLoss: 0.018436\n",
      "Train Epoch: 9 [1280/5509 (23%)]\tLoss: 0.039183\n",
      "Train Epoch: 9 [1920/5509 (34%)]\tLoss: 0.032750\n",
      "Train Epoch: 9 [2560/5509 (46%)]\tLoss: 0.021300\n",
      "Train Epoch: 9 [3200/5509 (57%)]\tLoss: 0.045757\n",
      "Train Epoch: 9 [3840/5509 (69%)]\tLoss: 0.055404\n",
      "Train Epoch: 9 [4480/5509 (80%)]\tLoss: 0.012257\n",
      "Train Epoch: 9 [5120/5509 (92%)]\tLoss: 0.045723\n",
      "Train Epoch: 10 [0/5509 (0%)]\tLoss: 0.118920\n",
      "Train Epoch: 10 [640/5509 (11%)]\tLoss: 0.005135\n",
      "Train Epoch: 10 [1280/5509 (23%)]\tLoss: 0.005010\n",
      "Train Epoch: 10 [1920/5509 (34%)]\tLoss: 0.039629\n",
      "Train Epoch: 10 [2560/5509 (46%)]\tLoss: 0.015942\n",
      "Train Epoch: 10 [3200/5509 (57%)]\tLoss: 0.004795\n",
      "Train Epoch: 10 [3840/5509 (69%)]\tLoss: 0.071358\n",
      "Train Epoch: 10 [4480/5509 (80%)]\tLoss: 0.154876\n",
      "Train Epoch: 10 [5120/5509 (92%)]\tLoss: 0.058878\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 0.053348\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 0.019384\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 0.055928\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 0.027700\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 0.070531\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 0.003516\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 0.003711\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 0.002374\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 0.048640\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 0.034070\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.052392\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.017797\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 0.054388\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 0.004670\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 0.011787\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.058674\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.022941\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.003207\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.116687\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.042811\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.104803\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.010623\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.014456\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.050191\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.029483\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.071091\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.002708\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.009531\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.008450\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.011205\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.003530\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.005908\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.051100\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.035190\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.022907\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.014237\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.088063\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.096367\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.004578\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.075820\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.106343\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.101348\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.010479\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.064051\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.004166\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.017753\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.011158\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.005160\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.058361\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.010579\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.094341\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.013257\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.006810\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.004310\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.019998\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.002541\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.026504\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.009791\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.028739\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.006107\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.003140\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.006563\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.064560\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.007263\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.063656\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.024696\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.169229\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.005190\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.021097\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.073712\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.012238\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.010274\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.041582\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.044071\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.018769\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.069276\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.032870\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.082682\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.000948\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.028816\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.033656\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.003732\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.043870\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.005029\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.072107\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.013926\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.009972\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.046525\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.022418\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.033757\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.066519\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.061362\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.035456\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.004204\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.012130\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.073462\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.043804\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.002858\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.042416\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.007337\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.012315\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.014322\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.005501\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.024371\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.006930\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.002449\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.010416\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.002338\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.010070\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.061723\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.019564\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.002771\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.149855\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.042572\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.003790\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.049757\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.043367\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.000255\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.076273\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.009279\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.1540, Accuracy: 9875/10000 (99%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 0.128962\n",
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 0.148974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 0.117140\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 0.117541\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 0.035849\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 0.020828\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 0.057751\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 0.029131\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 0.103792\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 0.062201\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 0.109070\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 0.065039\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 0.047607\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 0.104576\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 0.122266\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 0.205155\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 0.020636\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 0.063928\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 0.036132\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 0.035289\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.113691\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 0.040468\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 0.021318\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.043103\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.013164\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 0.163985\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.068959\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 0.023413\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.028409\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.034532\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.027454\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.059484\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.015279\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.107411\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.026781\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.013826\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.073030\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.040013\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.057234\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.017665\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.042799\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.020930\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.041981\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.064408\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.091788\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.024185\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.081267\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.006050\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.024088\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.116333\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.042276\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.024037\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.118209\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.024094\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.016611\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.029379\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.020265\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.050494\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.048547\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.024547\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.021752\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.064717\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.062440\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.065644\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.036977\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.037197\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.061558\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.042020\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.013380\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.032769\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.044384\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.146532\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.015533\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.010460\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.018734\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.007587\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.003719\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.034058\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.011646\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.057673\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.273981\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.045159\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.148542\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.061003\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.005309\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.258778\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.083261\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.139025\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.010985\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.064793\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.055625\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.012903\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.004872\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.002701\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.015580\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.013125\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.010260\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.027697\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.035551\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.004908\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.043617\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.042364\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.117566\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.022089\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.018859\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.135223\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.015937\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.053463\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 0.410942\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.336249\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.026088\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.064828\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.105361\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.449564\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.085522\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.157632\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.030892\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.040780\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.070104\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.117269\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.078377\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.036631\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.014791\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.055685\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.132379\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.007269\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.018081\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.032355\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.024228\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.050589\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.032926\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.114984\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.020315\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.274469\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.093983\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.111819\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.060040\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.036203\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.080814\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.338372\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.020908\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.064964\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.079682\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.067472\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.107876\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.086627\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.051347\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.108241\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.085570\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.065312\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.018402\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.051474\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.100643\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.046351\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.014566\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.006768\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.011733\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.108533\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.033855\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.003944\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.066404\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.069449\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.022699\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.134623\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.087919\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.009560\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.039672\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.108700\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.071574\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.012288\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.190386\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.122409\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.019330\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.076531\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.059548\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.075881\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.108795\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.057949\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.059358\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.065960\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/13906 (0%)]\tLoss: 0.185397\n",
      "Train Epoch: 1 [640/13906 (5%)]\tLoss: 0.151958\n",
      "Train Epoch: 1 [1280/13906 (9%)]\tLoss: 0.086217\n",
      "Train Epoch: 1 [1920/13906 (14%)]\tLoss: 0.048625\n",
      "Train Epoch: 1 [2560/13906 (18%)]\tLoss: 0.112970\n",
      "Train Epoch: 1 [3200/13906 (23%)]\tLoss: 0.075530\n",
      "Train Epoch: 1 [3840/13906 (28%)]\tLoss: 0.139622\n",
      "Train Epoch: 1 [4480/13906 (32%)]\tLoss: 0.032546\n",
      "Train Epoch: 1 [5120/13906 (37%)]\tLoss: 0.092573\n",
      "Train Epoch: 1 [5760/13906 (41%)]\tLoss: 0.053608\n",
      "Train Epoch: 1 [6400/13906 (46%)]\tLoss: 0.032635\n",
      "Train Epoch: 1 [7040/13906 (50%)]\tLoss: 0.067874\n",
      "Train Epoch: 1 [7680/13906 (55%)]\tLoss: 0.026841\n",
      "Train Epoch: 1 [8320/13906 (60%)]\tLoss: 0.035912\n",
      "Train Epoch: 1 [8960/13906 (64%)]\tLoss: 0.068847\n",
      "Train Epoch: 1 [9600/13906 (69%)]\tLoss: 0.017002\n",
      "Train Epoch: 1 [10240/13906 (73%)]\tLoss: 0.108589\n",
      "Train Epoch: 1 [10880/13906 (78%)]\tLoss: 0.023396\n",
      "Train Epoch: 1 [11520/13906 (83%)]\tLoss: 0.043130\n",
      "Train Epoch: 1 [12160/13906 (87%)]\tLoss: 0.126602\n",
      "Train Epoch: 1 [12800/13906 (92%)]\tLoss: 0.062724\n",
      "Train Epoch: 1 [13440/13906 (96%)]\tLoss: 0.014415\n",
      "Train Epoch: 2 [0/13906 (0%)]\tLoss: 0.066467\n",
      "Train Epoch: 2 [640/13906 (5%)]\tLoss: 0.045708\n",
      "Train Epoch: 2 [1280/13906 (9%)]\tLoss: 0.160959\n",
      "Train Epoch: 2 [1920/13906 (14%)]\tLoss: 0.025054\n",
      "Train Epoch: 2 [2560/13906 (18%)]\tLoss: 0.099225\n",
      "Train Epoch: 2 [3200/13906 (23%)]\tLoss: 0.078810\n",
      "Train Epoch: 2 [3840/13906 (28%)]\tLoss: 0.009380\n",
      "Train Epoch: 2 [4480/13906 (32%)]\tLoss: 0.075341\n",
      "Train Epoch: 2 [5120/13906 (37%)]\tLoss: 0.038094\n",
      "Train Epoch: 2 [5760/13906 (41%)]\tLoss: 0.054942\n",
      "Train Epoch: 2 [6400/13906 (46%)]\tLoss: 0.070687\n",
      "Train Epoch: 2 [7040/13906 (50%)]\tLoss: 0.050705\n",
      "Train Epoch: 2 [7680/13906 (55%)]\tLoss: 0.096711\n",
      "Train Epoch: 2 [8320/13906 (60%)]\tLoss: 0.075055\n",
      "Train Epoch: 2 [8960/13906 (64%)]\tLoss: 0.082289\n",
      "Train Epoch: 2 [9600/13906 (69%)]\tLoss: 0.046415\n",
      "Train Epoch: 2 [10240/13906 (73%)]\tLoss: 0.137981\n",
      "Train Epoch: 2 [10880/13906 (78%)]\tLoss: 0.058865\n",
      "Train Epoch: 2 [11520/13906 (83%)]\tLoss: 0.033777\n",
      "Train Epoch: 2 [12160/13906 (87%)]\tLoss: 0.091167\n",
      "Train Epoch: 2 [12800/13906 (92%)]\tLoss: 0.059192\n",
      "Train Epoch: 2 [13440/13906 (96%)]\tLoss: 0.003207\n",
      "Train Epoch: 3 [0/13906 (0%)]\tLoss: 0.119729\n",
      "Train Epoch: 3 [640/13906 (5%)]\tLoss: 0.218285\n",
      "Train Epoch: 3 [1280/13906 (9%)]\tLoss: 0.018800\n",
      "Train Epoch: 3 [1920/13906 (14%)]\tLoss: 0.024504\n",
      "Train Epoch: 3 [2560/13906 (18%)]\tLoss: 0.037158\n",
      "Train Epoch: 3 [3200/13906 (23%)]\tLoss: 0.046082\n",
      "Train Epoch: 3 [3840/13906 (28%)]\tLoss: 0.021727\n",
      "Train Epoch: 3 [4480/13906 (32%)]\tLoss: 0.035104\n",
      "Train Epoch: 3 [5120/13906 (37%)]\tLoss: 0.200998\n",
      "Train Epoch: 3 [5760/13906 (41%)]\tLoss: 0.049527\n",
      "Train Epoch: 3 [6400/13906 (46%)]\tLoss: 0.094665\n",
      "Train Epoch: 3 [7040/13906 (50%)]\tLoss: 0.027612\n",
      "Train Epoch: 3 [7680/13906 (55%)]\tLoss: 0.045837\n",
      "Train Epoch: 3 [8320/13906 (60%)]\tLoss: 0.028050\n",
      "Train Epoch: 3 [8960/13906 (64%)]\tLoss: 0.117517\n",
      "Train Epoch: 3 [9600/13906 (69%)]\tLoss: 0.093859\n",
      "Train Epoch: 3 [10240/13906 (73%)]\tLoss: 0.029700\n",
      "Train Epoch: 3 [10880/13906 (78%)]\tLoss: 0.100170\n",
      "Train Epoch: 3 [11520/13906 (83%)]\tLoss: 0.064779\n",
      "Train Epoch: 3 [12160/13906 (87%)]\tLoss: 0.045114\n",
      "Train Epoch: 3 [12800/13906 (92%)]\tLoss: 0.045340\n",
      "Train Epoch: 3 [13440/13906 (96%)]\tLoss: 0.059813\n",
      "Train Epoch: 4 [0/13906 (0%)]\tLoss: 0.050388\n",
      "Train Epoch: 4 [640/13906 (5%)]\tLoss: 0.013644\n",
      "Train Epoch: 4 [1280/13906 (9%)]\tLoss: 0.119673\n",
      "Train Epoch: 4 [1920/13906 (14%)]\tLoss: 0.037191\n",
      "Train Epoch: 4 [2560/13906 (18%)]\tLoss: 0.064209\n",
      "Train Epoch: 4 [3200/13906 (23%)]\tLoss: 0.138273\n",
      "Train Epoch: 4 [3840/13906 (28%)]\tLoss: 0.028637\n",
      "Train Epoch: 4 [4480/13906 (32%)]\tLoss: 0.055466\n",
      "Train Epoch: 4 [5120/13906 (37%)]\tLoss: 0.101092\n",
      "Train Epoch: 4 [5760/13906 (41%)]\tLoss: 0.050398\n",
      "Train Epoch: 4 [6400/13906 (46%)]\tLoss: 0.079618\n",
      "Train Epoch: 4 [7040/13906 (50%)]\tLoss: 0.016553\n",
      "Train Epoch: 4 [7680/13906 (55%)]\tLoss: 0.024659\n",
      "Train Epoch: 4 [8320/13906 (60%)]\tLoss: 0.053718\n",
      "Train Epoch: 4 [8960/13906 (64%)]\tLoss: 0.129598\n",
      "Train Epoch: 4 [9600/13906 (69%)]\tLoss: 0.123374\n",
      "Train Epoch: 4 [10240/13906 (73%)]\tLoss: 0.017382\n",
      "Train Epoch: 4 [10880/13906 (78%)]\tLoss: 0.099364\n",
      "Train Epoch: 4 [11520/13906 (83%)]\tLoss: 0.066908\n",
      "Train Epoch: 4 [12160/13906 (87%)]\tLoss: 0.056495\n",
      "Train Epoch: 4 [12800/13906 (92%)]\tLoss: 0.078794\n",
      "Train Epoch: 4 [13440/13906 (96%)]\tLoss: 0.013316\n",
      "Train Epoch: 5 [0/13906 (0%)]\tLoss: 0.042783\n",
      "Train Epoch: 5 [640/13906 (5%)]\tLoss: 0.142013\n",
      "Train Epoch: 5 [1280/13906 (9%)]\tLoss: 0.014899\n",
      "Train Epoch: 5 [1920/13906 (14%)]\tLoss: 0.099393\n",
      "Train Epoch: 5 [2560/13906 (18%)]\tLoss: 0.095451\n",
      "Train Epoch: 5 [3200/13906 (23%)]\tLoss: 0.112801\n",
      "Train Epoch: 5 [3840/13906 (28%)]\tLoss: 0.038283\n",
      "Train Epoch: 5 [4480/13906 (32%)]\tLoss: 0.043859\n",
      "Train Epoch: 5 [5120/13906 (37%)]\tLoss: 0.105903\n",
      "Train Epoch: 5 [5760/13906 (41%)]\tLoss: 0.079586\n",
      "Train Epoch: 5 [6400/13906 (46%)]\tLoss: 0.116941\n",
      "Train Epoch: 5 [7040/13906 (50%)]\tLoss: 0.030110\n",
      "Train Epoch: 5 [7680/13906 (55%)]\tLoss: 0.113855\n",
      "Train Epoch: 5 [8320/13906 (60%)]\tLoss: 0.022134\n",
      "Train Epoch: 5 [8960/13906 (64%)]\tLoss: 0.008916\n",
      "Train Epoch: 5 [9600/13906 (69%)]\tLoss: 0.075153\n",
      "Train Epoch: 5 [10240/13906 (73%)]\tLoss: 0.011418\n",
      "Train Epoch: 5 [10880/13906 (78%)]\tLoss: 0.109364\n",
      "Train Epoch: 5 [11520/13906 (83%)]\tLoss: 0.080394\n",
      "Train Epoch: 5 [12160/13906 (87%)]\tLoss: 0.013317\n",
      "Train Epoch: 5 [12800/13906 (92%)]\tLoss: 0.105833\n",
      "Train Epoch: 5 [13440/13906 (96%)]\tLoss: 0.065469\n",
      "Train Epoch: 6 [0/13906 (0%)]\tLoss: 0.040132\n",
      "Train Epoch: 6 [640/13906 (5%)]\tLoss: 0.030469\n",
      "Train Epoch: 6 [1280/13906 (9%)]\tLoss: 0.010962\n",
      "Train Epoch: 6 [1920/13906 (14%)]\tLoss: 0.046524\n",
      "Train Epoch: 6 [2560/13906 (18%)]\tLoss: 0.145194\n",
      "Train Epoch: 6 [3200/13906 (23%)]\tLoss: 0.012673\n",
      "Train Epoch: 6 [3840/13906 (28%)]\tLoss: 0.212887\n",
      "Train Epoch: 6 [4480/13906 (32%)]\tLoss: 0.101560\n",
      "Train Epoch: 6 [5120/13906 (37%)]\tLoss: 0.026702\n",
      "Train Epoch: 6 [5760/13906 (41%)]\tLoss: 0.134100\n",
      "Train Epoch: 6 [6400/13906 (46%)]\tLoss: 0.036374\n",
      "Train Epoch: 6 [7040/13906 (50%)]\tLoss: 0.064034\n",
      "Train Epoch: 6 [7680/13906 (55%)]\tLoss: 0.042108\n",
      "Train Epoch: 6 [8320/13906 (60%)]\tLoss: 0.352898\n",
      "Train Epoch: 6 [8960/13906 (64%)]\tLoss: 0.254004\n",
      "Train Epoch: 6 [9600/13906 (69%)]\tLoss: 0.063447\n",
      "Train Epoch: 6 [10240/13906 (73%)]\tLoss: 0.050451\n",
      "Train Epoch: 6 [10880/13906 (78%)]\tLoss: 0.073399\n",
      "Train Epoch: 6 [11520/13906 (83%)]\tLoss: 0.042432\n",
      "Train Epoch: 6 [12160/13906 (87%)]\tLoss: 0.025514\n",
      "Train Epoch: 6 [12800/13906 (92%)]\tLoss: 0.011807\n",
      "Train Epoch: 6 [13440/13906 (96%)]\tLoss: 0.144825\n",
      "Train Epoch: 7 [0/13906 (0%)]\tLoss: 0.027594\n",
      "Train Epoch: 7 [640/13906 (5%)]\tLoss: 0.049964\n",
      "Train Epoch: 7 [1280/13906 (9%)]\tLoss: 0.003428\n",
      "Train Epoch: 7 [1920/13906 (14%)]\tLoss: 0.012276\n",
      "Train Epoch: 7 [2560/13906 (18%)]\tLoss: 0.019716\n",
      "Train Epoch: 7 [3200/13906 (23%)]\tLoss: 0.034987\n",
      "Train Epoch: 7 [3840/13906 (28%)]\tLoss: 0.005307\n",
      "Train Epoch: 7 [4480/13906 (32%)]\tLoss: 0.027354\n",
      "Train Epoch: 7 [5120/13906 (37%)]\tLoss: 0.047909\n",
      "Train Epoch: 7 [5760/13906 (41%)]\tLoss: 0.031598\n",
      "Train Epoch: 7 [6400/13906 (46%)]\tLoss: 0.082852\n",
      "Train Epoch: 7 [7040/13906 (50%)]\tLoss: 0.050744\n",
      "Train Epoch: 7 [7680/13906 (55%)]\tLoss: 0.034810\n",
      "Train Epoch: 7 [8320/13906 (60%)]\tLoss: 0.013387\n",
      "Train Epoch: 7 [8960/13906 (64%)]\tLoss: 0.028990\n",
      "Train Epoch: 7 [9600/13906 (69%)]\tLoss: 0.043291\n",
      "Train Epoch: 7 [10240/13906 (73%)]\tLoss: 0.065883\n",
      "Train Epoch: 7 [10880/13906 (78%)]\tLoss: 0.009119\n",
      "Train Epoch: 7 [11520/13906 (83%)]\tLoss: 0.037889\n",
      "Train Epoch: 7 [12160/13906 (87%)]\tLoss: 0.054241\n",
      "Train Epoch: 7 [12800/13906 (92%)]\tLoss: 0.058066\n",
      "Train Epoch: 7 [13440/13906 (96%)]\tLoss: 0.085941\n",
      "Train Epoch: 8 [0/13906 (0%)]\tLoss: 0.096464\n",
      "Train Epoch: 8 [640/13906 (5%)]\tLoss: 0.030219\n",
      "Train Epoch: 8 [1280/13906 (9%)]\tLoss: 0.078676\n",
      "Train Epoch: 8 [1920/13906 (14%)]\tLoss: 0.087640\n",
      "Train Epoch: 8 [2560/13906 (18%)]\tLoss: 0.028830\n",
      "Train Epoch: 8 [3200/13906 (23%)]\tLoss: 0.053663\n",
      "Train Epoch: 8 [3840/13906 (28%)]\tLoss: 0.030987\n",
      "Train Epoch: 8 [4480/13906 (32%)]\tLoss: 0.005465\n",
      "Train Epoch: 8 [5120/13906 (37%)]\tLoss: 0.014606\n",
      "Train Epoch: 8 [5760/13906 (41%)]\tLoss: 0.005692\n",
      "Train Epoch: 8 [6400/13906 (46%)]\tLoss: 0.005047\n",
      "Train Epoch: 8 [7040/13906 (50%)]\tLoss: 0.004647\n",
      "Train Epoch: 8 [7680/13906 (55%)]\tLoss: 0.040102\n",
      "Train Epoch: 8 [8320/13906 (60%)]\tLoss: 0.008443\n",
      "Train Epoch: 8 [8960/13906 (64%)]\tLoss: 0.024475\n",
      "Train Epoch: 8 [9600/13906 (69%)]\tLoss: 0.060907\n",
      "Train Epoch: 8 [10240/13906 (73%)]\tLoss: 0.086753\n",
      "Train Epoch: 8 [10880/13906 (78%)]\tLoss: 0.035259\n",
      "Train Epoch: 8 [11520/13906 (83%)]\tLoss: 0.019461\n",
      "Train Epoch: 8 [12160/13906 (87%)]\tLoss: 0.083583\n",
      "Train Epoch: 8 [12800/13906 (92%)]\tLoss: 0.078166\n",
      "Train Epoch: 8 [13440/13906 (96%)]\tLoss: 0.026802\n",
      "Train Epoch: 9 [0/13906 (0%)]\tLoss: 0.106941\n",
      "Train Epoch: 9 [640/13906 (5%)]\tLoss: 0.081846\n",
      "Train Epoch: 9 [1280/13906 (9%)]\tLoss: 0.128779\n",
      "Train Epoch: 9 [1920/13906 (14%)]\tLoss: 0.083116\n",
      "Train Epoch: 9 [2560/13906 (18%)]\tLoss: 0.050250\n",
      "Train Epoch: 9 [3200/13906 (23%)]\tLoss: 0.027526\n",
      "Train Epoch: 9 [3840/13906 (28%)]\tLoss: 0.070017\n",
      "Train Epoch: 9 [4480/13906 (32%)]\tLoss: 0.079613\n",
      "Train Epoch: 9 [5120/13906 (37%)]\tLoss: 0.080021\n",
      "Train Epoch: 9 [5760/13906 (41%)]\tLoss: 0.031733\n",
      "Train Epoch: 9 [6400/13906 (46%)]\tLoss: 0.049238\n",
      "Train Epoch: 9 [7040/13906 (50%)]\tLoss: 0.026120\n",
      "Train Epoch: 9 [7680/13906 (55%)]\tLoss: 0.057936\n",
      "Train Epoch: 9 [8320/13906 (60%)]\tLoss: 0.011446\n",
      "Train Epoch: 9 [8960/13906 (64%)]\tLoss: 0.016931\n",
      "Train Epoch: 9 [9600/13906 (69%)]\tLoss: 0.071618\n",
      "Train Epoch: 9 [10240/13906 (73%)]\tLoss: 0.006426\n",
      "Train Epoch: 9 [10880/13906 (78%)]\tLoss: 0.092691\n",
      "Train Epoch: 9 [11520/13906 (83%)]\tLoss: 0.029123\n",
      "Train Epoch: 9 [12160/13906 (87%)]\tLoss: 0.128512\n",
      "Train Epoch: 9 [12800/13906 (92%)]\tLoss: 0.006106\n",
      "Train Epoch: 9 [13440/13906 (96%)]\tLoss: 0.091195\n",
      "Train Epoch: 10 [0/13906 (0%)]\tLoss: 0.039231\n",
      "Train Epoch: 10 [640/13906 (5%)]\tLoss: 0.095308\n",
      "Train Epoch: 10 [1280/13906 (9%)]\tLoss: 0.026799\n",
      "Train Epoch: 10 [1920/13906 (14%)]\tLoss: 0.098887\n",
      "Train Epoch: 10 [2560/13906 (18%)]\tLoss: 0.002662\n",
      "Train Epoch: 10 [3200/13906 (23%)]\tLoss: 0.016057\n",
      "Train Epoch: 10 [3840/13906 (28%)]\tLoss: 0.052994\n",
      "Train Epoch: 10 [4480/13906 (32%)]\tLoss: 0.081922\n",
      "Train Epoch: 10 [5120/13906 (37%)]\tLoss: 0.101336\n",
      "Train Epoch: 10 [5760/13906 (41%)]\tLoss: 0.169958\n",
      "Train Epoch: 10 [6400/13906 (46%)]\tLoss: 0.038387\n",
      "Train Epoch: 10 [7040/13906 (50%)]\tLoss: 0.160549\n",
      "Train Epoch: 10 [7680/13906 (55%)]\tLoss: 0.006476\n",
      "Train Epoch: 10 [8320/13906 (60%)]\tLoss: 0.149567\n",
      "Train Epoch: 10 [8960/13906 (64%)]\tLoss: 0.140489\n",
      "Train Epoch: 10 [9600/13906 (69%)]\tLoss: 0.031896\n",
      "Train Epoch: 10 [10240/13906 (73%)]\tLoss: 0.006132\n",
      "Train Epoch: 10 [10880/13906 (78%)]\tLoss: 0.141341\n",
      "Train Epoch: 10 [11520/13906 (83%)]\tLoss: 0.024956\n",
      "Train Epoch: 10 [12160/13906 (87%)]\tLoss: 0.161432\n",
      "Train Epoch: 10 [12800/13906 (92%)]\tLoss: 0.100486\n",
      "Train Epoch: 10 [13440/13906 (96%)]\tLoss: 0.078204\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/11862 (0%)]\tLoss: 0.090243\n",
      "Train Epoch: 1 [640/11862 (5%)]\tLoss: 0.060019\n",
      "Train Epoch: 1 [1280/11862 (11%)]\tLoss: 0.110781\n",
      "Train Epoch: 1 [1920/11862 (16%)]\tLoss: 0.102274\n",
      "Train Epoch: 1 [2560/11862 (22%)]\tLoss: 0.014772\n",
      "Train Epoch: 1 [3200/11862 (27%)]\tLoss: 0.005436\n",
      "Train Epoch: 1 [3840/11862 (32%)]\tLoss: 0.020213\n",
      "Train Epoch: 1 [4480/11862 (38%)]\tLoss: 0.218612\n",
      "Train Epoch: 1 [5120/11862 (43%)]\tLoss: 0.040787\n",
      "Train Epoch: 1 [5760/11862 (48%)]\tLoss: 0.033762\n",
      "Train Epoch: 1 [6400/11862 (54%)]\tLoss: 0.038618\n",
      "Train Epoch: 1 [7040/11862 (59%)]\tLoss: 0.126166\n",
      "Train Epoch: 1 [7680/11862 (65%)]\tLoss: 0.206928\n",
      "Train Epoch: 1 [8320/11862 (70%)]\tLoss: 0.037841\n",
      "Train Epoch: 1 [8960/11862 (75%)]\tLoss: 0.011838\n",
      "Train Epoch: 1 [9600/11862 (81%)]\tLoss: 0.091992\n",
      "Train Epoch: 1 [10240/11862 (86%)]\tLoss: 0.008909\n",
      "Train Epoch: 1 [10880/11862 (91%)]\tLoss: 0.040301\n",
      "Train Epoch: 1 [11520/11862 (97%)]\tLoss: 0.040332\n",
      "Train Epoch: 2 [0/11862 (0%)]\tLoss: 0.034063\n",
      "Train Epoch: 2 [640/11862 (5%)]\tLoss: 0.014862\n",
      "Train Epoch: 2 [1280/11862 (11%)]\tLoss: 0.110708\n",
      "Train Epoch: 2 [1920/11862 (16%)]\tLoss: 0.084770\n",
      "Train Epoch: 2 [2560/11862 (22%)]\tLoss: 0.009256\n",
      "Train Epoch: 2 [3200/11862 (27%)]\tLoss: 0.006520\n",
      "Train Epoch: 2 [3840/11862 (32%)]\tLoss: 0.087489\n",
      "Train Epoch: 2 [4480/11862 (38%)]\tLoss: 0.012501\n",
      "Train Epoch: 2 [5120/11862 (43%)]\tLoss: 0.047294\n",
      "Train Epoch: 2 [5760/11862 (48%)]\tLoss: 0.070400\n",
      "Train Epoch: 2 [6400/11862 (54%)]\tLoss: 0.173767\n",
      "Train Epoch: 2 [7040/11862 (59%)]\tLoss: 0.004905\n",
      "Train Epoch: 2 [7680/11862 (65%)]\tLoss: 0.150111\n",
      "Train Epoch: 2 [8320/11862 (70%)]\tLoss: 0.014480\n",
      "Train Epoch: 2 [8960/11862 (75%)]\tLoss: 0.014199\n",
      "Train Epoch: 2 [9600/11862 (81%)]\tLoss: 0.052271\n",
      "Train Epoch: 2 [10240/11862 (86%)]\tLoss: 0.003785\n",
      "Train Epoch: 2 [10880/11862 (91%)]\tLoss: 0.004684\n",
      "Train Epoch: 2 [11520/11862 (97%)]\tLoss: 0.074216\n",
      "Train Epoch: 3 [0/11862 (0%)]\tLoss: 0.006264\n",
      "Train Epoch: 3 [640/11862 (5%)]\tLoss: 0.004221\n",
      "Train Epoch: 3 [1280/11862 (11%)]\tLoss: 0.004150\n",
      "Train Epoch: 3 [1920/11862 (16%)]\tLoss: 0.066410\n",
      "Train Epoch: 3 [2560/11862 (22%)]\tLoss: 0.001074\n",
      "Train Epoch: 3 [3200/11862 (27%)]\tLoss: 0.005158\n",
      "Train Epoch: 3 [3840/11862 (32%)]\tLoss: 0.098159\n",
      "Train Epoch: 3 [4480/11862 (38%)]\tLoss: 0.005833\n",
      "Train Epoch: 3 [5120/11862 (43%)]\tLoss: 0.018683\n",
      "Train Epoch: 3 [5760/11862 (48%)]\tLoss: 0.012339\n",
      "Train Epoch: 3 [6400/11862 (54%)]\tLoss: 0.022177\n",
      "Train Epoch: 3 [7040/11862 (59%)]\tLoss: 0.161954\n",
      "Train Epoch: 3 [7680/11862 (65%)]\tLoss: 0.040417\n",
      "Train Epoch: 3 [8320/11862 (70%)]\tLoss: 0.084613\n",
      "Train Epoch: 3 [8960/11862 (75%)]\tLoss: 0.029389\n",
      "Train Epoch: 3 [9600/11862 (81%)]\tLoss: 0.033279\n",
      "Train Epoch: 3 [10240/11862 (86%)]\tLoss: 0.038426\n",
      "Train Epoch: 3 [10880/11862 (91%)]\tLoss: 0.042046\n",
      "Train Epoch: 3 [11520/11862 (97%)]\tLoss: 0.092574\n",
      "Train Epoch: 4 [0/11862 (0%)]\tLoss: 0.009148\n",
      "Train Epoch: 4 [640/11862 (5%)]\tLoss: 0.057673\n",
      "Train Epoch: 4 [1280/11862 (11%)]\tLoss: 0.007134\n",
      "Train Epoch: 4 [1920/11862 (16%)]\tLoss: 0.020656\n",
      "Train Epoch: 4 [2560/11862 (22%)]\tLoss: 0.014229\n",
      "Train Epoch: 4 [3200/11862 (27%)]\tLoss: 0.012652\n",
      "Train Epoch: 4 [3840/11862 (32%)]\tLoss: 0.012332\n",
      "Train Epoch: 4 [4480/11862 (38%)]\tLoss: 0.135868\n",
      "Train Epoch: 4 [5120/11862 (43%)]\tLoss: 0.006135\n",
      "Train Epoch: 4 [5760/11862 (48%)]\tLoss: 0.022730\n",
      "Train Epoch: 4 [6400/11862 (54%)]\tLoss: 0.019587\n",
      "Train Epoch: 4 [7040/11862 (59%)]\tLoss: 0.047118\n",
      "Train Epoch: 4 [7680/11862 (65%)]\tLoss: 0.124876\n",
      "Train Epoch: 4 [8320/11862 (70%)]\tLoss: 0.009335\n",
      "Train Epoch: 4 [8960/11862 (75%)]\tLoss: 0.048949\n",
      "Train Epoch: 4 [9600/11862 (81%)]\tLoss: 0.082708\n",
      "Train Epoch: 4 [10240/11862 (86%)]\tLoss: 0.056831\n",
      "Train Epoch: 4 [10880/11862 (91%)]\tLoss: 0.024046\n",
      "Train Epoch: 4 [11520/11862 (97%)]\tLoss: 0.080722\n",
      "Train Epoch: 5 [0/11862 (0%)]\tLoss: 0.018712\n",
      "Train Epoch: 5 [640/11862 (5%)]\tLoss: 0.017247\n",
      "Train Epoch: 5 [1280/11862 (11%)]\tLoss: 0.001613\n",
      "Train Epoch: 5 [1920/11862 (16%)]\tLoss: 0.036481\n",
      "Train Epoch: 5 [2560/11862 (22%)]\tLoss: 0.018246\n",
      "Train Epoch: 5 [3200/11862 (27%)]\tLoss: 0.023734\n",
      "Train Epoch: 5 [3840/11862 (32%)]\tLoss: 0.028784\n",
      "Train Epoch: 5 [4480/11862 (38%)]\tLoss: 0.010036\n",
      "Train Epoch: 5 [5120/11862 (43%)]\tLoss: 0.041830\n",
      "Train Epoch: 5 [5760/11862 (48%)]\tLoss: 0.145469\n",
      "Train Epoch: 5 [6400/11862 (54%)]\tLoss: 0.090814\n",
      "Train Epoch: 5 [7040/11862 (59%)]\tLoss: 0.224855\n",
      "Train Epoch: 5 [7680/11862 (65%)]\tLoss: 0.008664\n",
      "Train Epoch: 5 [8320/11862 (70%)]\tLoss: 0.039258\n",
      "Train Epoch: 5 [8960/11862 (75%)]\tLoss: 0.044859\n",
      "Train Epoch: 5 [9600/11862 (81%)]\tLoss: 0.111846\n",
      "Train Epoch: 5 [10240/11862 (86%)]\tLoss: 0.020318\n",
      "Train Epoch: 5 [10880/11862 (91%)]\tLoss: 0.003847\n",
      "Train Epoch: 5 [11520/11862 (97%)]\tLoss: 0.044613\n",
      "Train Epoch: 6 [0/11862 (0%)]\tLoss: 0.080711\n",
      "Train Epoch: 6 [640/11862 (5%)]\tLoss: 0.031201\n",
      "Train Epoch: 6 [1280/11862 (11%)]\tLoss: 0.001172\n",
      "Train Epoch: 6 [1920/11862 (16%)]\tLoss: 0.029273\n",
      "Train Epoch: 6 [2560/11862 (22%)]\tLoss: 0.060041\n",
      "Train Epoch: 6 [3200/11862 (27%)]\tLoss: 0.004091\n",
      "Train Epoch: 6 [3840/11862 (32%)]\tLoss: 0.045925\n",
      "Train Epoch: 6 [4480/11862 (38%)]\tLoss: 0.029933\n",
      "Train Epoch: 6 [5120/11862 (43%)]\tLoss: 0.010741\n",
      "Train Epoch: 6 [5760/11862 (48%)]\tLoss: 0.009173\n",
      "Train Epoch: 6 [6400/11862 (54%)]\tLoss: 0.087980\n",
      "Train Epoch: 6 [7040/11862 (59%)]\tLoss: 0.067897\n",
      "Train Epoch: 6 [7680/11862 (65%)]\tLoss: 0.008943\n",
      "Train Epoch: 6 [8320/11862 (70%)]\tLoss: 0.023501\n",
      "Train Epoch: 6 [8960/11862 (75%)]\tLoss: 0.005154\n",
      "Train Epoch: 6 [9600/11862 (81%)]\tLoss: 0.004645\n",
      "Train Epoch: 6 [10240/11862 (86%)]\tLoss: 0.016865\n",
      "Train Epoch: 6 [10880/11862 (91%)]\tLoss: 0.008290\n",
      "Train Epoch: 6 [11520/11862 (97%)]\tLoss: 0.058875\n",
      "Train Epoch: 7 [0/11862 (0%)]\tLoss: 0.004694\n",
      "Train Epoch: 7 [640/11862 (5%)]\tLoss: 0.053311\n",
      "Train Epoch: 7 [1280/11862 (11%)]\tLoss: 0.212167\n",
      "Train Epoch: 7 [1920/11862 (16%)]\tLoss: 0.025458\n",
      "Train Epoch: 7 [2560/11862 (22%)]\tLoss: 0.037492\n",
      "Train Epoch: 7 [3200/11862 (27%)]\tLoss: 0.030177\n",
      "Train Epoch: 7 [3840/11862 (32%)]\tLoss: 0.115708\n",
      "Train Epoch: 7 [4480/11862 (38%)]\tLoss: 0.020790\n",
      "Train Epoch: 7 [5120/11862 (43%)]\tLoss: 0.032795\n",
      "Train Epoch: 7 [5760/11862 (48%)]\tLoss: 0.102903\n",
      "Train Epoch: 7 [6400/11862 (54%)]\tLoss: 0.032333\n",
      "Train Epoch: 7 [7040/11862 (59%)]\tLoss: 0.018212\n",
      "Train Epoch: 7 [7680/11862 (65%)]\tLoss: 0.041992\n",
      "Train Epoch: 7 [8320/11862 (70%)]\tLoss: 0.024906\n",
      "Train Epoch: 7 [8960/11862 (75%)]\tLoss: 0.208678\n",
      "Train Epoch: 7 [9600/11862 (81%)]\tLoss: 0.083841\n",
      "Train Epoch: 7 [10240/11862 (86%)]\tLoss: 0.027756\n",
      "Train Epoch: 7 [10880/11862 (91%)]\tLoss: 0.008569\n",
      "Train Epoch: 7 [11520/11862 (97%)]\tLoss: 0.007131\n",
      "Train Epoch: 8 [0/11862 (0%)]\tLoss: 0.115587\n",
      "Train Epoch: 8 [640/11862 (5%)]\tLoss: 0.025767\n",
      "Train Epoch: 8 [1280/11862 (11%)]\tLoss: 0.016419\n",
      "Train Epoch: 8 [1920/11862 (16%)]\tLoss: 0.052810\n",
      "Train Epoch: 8 [2560/11862 (22%)]\tLoss: 0.035384\n",
      "Train Epoch: 8 [3200/11862 (27%)]\tLoss: 0.067692\n",
      "Train Epoch: 8 [3840/11862 (32%)]\tLoss: 0.032732\n",
      "Train Epoch: 8 [4480/11862 (38%)]\tLoss: 0.110232\n",
      "Train Epoch: 8 [5120/11862 (43%)]\tLoss: 0.049831\n",
      "Train Epoch: 8 [5760/11862 (48%)]\tLoss: 0.008551\n",
      "Train Epoch: 8 [6400/11862 (54%)]\tLoss: 0.021851\n",
      "Train Epoch: 8 [7040/11862 (59%)]\tLoss: 0.050368\n",
      "Train Epoch: 8 [7680/11862 (65%)]\tLoss: 0.013768\n",
      "Train Epoch: 8 [8320/11862 (70%)]\tLoss: 0.055199\n",
      "Train Epoch: 8 [8960/11862 (75%)]\tLoss: 0.170195\n",
      "Train Epoch: 8 [9600/11862 (81%)]\tLoss: 0.052300\n",
      "Train Epoch: 8 [10240/11862 (86%)]\tLoss: 0.009373\n",
      "Train Epoch: 8 [10880/11862 (91%)]\tLoss: 0.051866\n",
      "Train Epoch: 8 [11520/11862 (97%)]\tLoss: 0.017578\n",
      "Train Epoch: 9 [0/11862 (0%)]\tLoss: 0.212018\n",
      "Train Epoch: 9 [640/11862 (5%)]\tLoss: 0.056004\n",
      "Train Epoch: 9 [1280/11862 (11%)]\tLoss: 0.059693\n",
      "Train Epoch: 9 [1920/11862 (16%)]\tLoss: 0.016279\n",
      "Train Epoch: 9 [2560/11862 (22%)]\tLoss: 0.026226\n",
      "Train Epoch: 9 [3200/11862 (27%)]\tLoss: 0.002907\n",
      "Train Epoch: 9 [3840/11862 (32%)]\tLoss: 0.006186\n",
      "Train Epoch: 9 [4480/11862 (38%)]\tLoss: 0.089161\n",
      "Train Epoch: 9 [5120/11862 (43%)]\tLoss: 0.059629\n",
      "Train Epoch: 9 [5760/11862 (48%)]\tLoss: 0.019491\n",
      "Train Epoch: 9 [6400/11862 (54%)]\tLoss: 0.040064\n",
      "Train Epoch: 9 [7040/11862 (59%)]\tLoss: 0.070021\n",
      "Train Epoch: 9 [7680/11862 (65%)]\tLoss: 0.004234\n",
      "Train Epoch: 9 [8320/11862 (70%)]\tLoss: 0.064923\n",
      "Train Epoch: 9 [8960/11862 (75%)]\tLoss: 0.051911\n",
      "Train Epoch: 9 [9600/11862 (81%)]\tLoss: 0.006115\n",
      "Train Epoch: 9 [10240/11862 (86%)]\tLoss: 0.036394\n",
      "Train Epoch: 9 [10880/11862 (91%)]\tLoss: 0.008043\n",
      "Train Epoch: 9 [11520/11862 (97%)]\tLoss: 0.162978\n",
      "Train Epoch: 10 [0/11862 (0%)]\tLoss: 0.003341\n",
      "Train Epoch: 10 [640/11862 (5%)]\tLoss: 0.053589\n",
      "Train Epoch: 10 [1280/11862 (11%)]\tLoss: 0.025271\n",
      "Train Epoch: 10 [1920/11862 (16%)]\tLoss: 0.015193\n",
      "Train Epoch: 10 [2560/11862 (22%)]\tLoss: 0.034892\n",
      "Train Epoch: 10 [3200/11862 (27%)]\tLoss: 0.007033\n",
      "Train Epoch: 10 [3840/11862 (32%)]\tLoss: 0.041491\n",
      "Train Epoch: 10 [4480/11862 (38%)]\tLoss: 0.006759\n",
      "Train Epoch: 10 [5120/11862 (43%)]\tLoss: 0.020983\n",
      "Train Epoch: 10 [5760/11862 (48%)]\tLoss: 0.125510\n",
      "Train Epoch: 10 [6400/11862 (54%)]\tLoss: 0.067570\n",
      "Train Epoch: 10 [7040/11862 (59%)]\tLoss: 0.008186\n",
      "Train Epoch: 10 [7680/11862 (65%)]\tLoss: 0.024955\n",
      "Train Epoch: 10 [8320/11862 (70%)]\tLoss: 0.007399\n",
      "Train Epoch: 10 [8960/11862 (75%)]\tLoss: 0.039434\n",
      "Train Epoch: 10 [9600/11862 (81%)]\tLoss: 0.008326\n",
      "Train Epoch: 10 [10240/11862 (86%)]\tLoss: 0.045278\n",
      "Train Epoch: 10 [10880/11862 (91%)]\tLoss: 0.066323\n",
      "Train Epoch: 10 [11520/11862 (97%)]\tLoss: 0.034583\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 0.053680\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 0.011263\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 0.013185\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 0.042054\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 0.051038\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 0.059326\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 0.047539\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 0.009482\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 0.056560\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 0.035152\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 0.028063\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 0.170832\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 0.137698\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 0.187041\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 0.036760\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 0.054698\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 0.005618\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.050634\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.054364\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.093496\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.005388\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.041325\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.040441\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.033577\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.023077\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.024337\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.011783\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.017500\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.008805\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.091942\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.012112\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.006823\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.009860\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.048272\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.081476\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.029818\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.015453\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.014450\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.158343\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.052844\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.102218\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.044896\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.480656\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.037778\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.098268\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.009788\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.024513\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.061186\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.064864\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.062611\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.050595\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.047510\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.096131\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.025067\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.044628\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.006631\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.019530\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.073051\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.066027\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.063168\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.002130\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.088082\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.017288\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.035905\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.037399\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.084894\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.021817\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.009540\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.018335\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.077619\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.047202\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.024230\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.006661\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.068442\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.081959\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.108631\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.004296\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.025867\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.102930\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.032222\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.015909\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.116704\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.016515\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.030105\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.056194\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.021869\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.043535\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.018851\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.002328\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.011490\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.042644\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.061617\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.083982\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.249085\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.028753\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.037175\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.006839\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.054983\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.009804\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.007863\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.005528\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.014128\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.038319\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.098911\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.029917\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.013938\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.006454\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.045471\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.021836\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.062069\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.006822\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.016077\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.005083\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.027514\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.009823\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.006659\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.017121\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.064092\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.026957\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.023040\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.011595\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.013779\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.004123\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.055834\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.007982\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.113466\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.015439\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.032913\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.024657\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.010200\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.017476\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.037294\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.002218\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.021382\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.065261\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.207681\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.006347\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.005581\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.079281\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.095622\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.161753\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.036058\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.010252\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.013383\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.009132\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.010073\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.097713\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.046551\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.011338\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.049722\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.055251\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.025166\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.050938\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.024150\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.027454\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.049193\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.014874\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.052686\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.032662\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.071035\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5509 (0%)]\tLoss: 0.057931\n",
      "Train Epoch: 1 [640/5509 (11%)]\tLoss: 0.065848\n",
      "Train Epoch: 1 [1280/5509 (23%)]\tLoss: 0.077290\n",
      "Train Epoch: 1 [1920/5509 (34%)]\tLoss: 0.050610\n",
      "Train Epoch: 1 [2560/5509 (46%)]\tLoss: 0.137839\n",
      "Train Epoch: 1 [3200/5509 (57%)]\tLoss: 0.028823\n",
      "Train Epoch: 1 [3840/5509 (69%)]\tLoss: 0.025784\n",
      "Train Epoch: 1 [4480/5509 (80%)]\tLoss: 0.013088\n",
      "Train Epoch: 1 [5120/5509 (92%)]\tLoss: 0.076091\n",
      "Train Epoch: 2 [0/5509 (0%)]\tLoss: 0.074755\n",
      "Train Epoch: 2 [640/5509 (11%)]\tLoss: 0.100003\n",
      "Train Epoch: 2 [1280/5509 (23%)]\tLoss: 0.112126\n",
      "Train Epoch: 2 [1920/5509 (34%)]\tLoss: 0.123785\n",
      "Train Epoch: 2 [2560/5509 (46%)]\tLoss: 0.019380\n",
      "Train Epoch: 2 [3200/5509 (57%)]\tLoss: 0.089207\n",
      "Train Epoch: 2 [3840/5509 (69%)]\tLoss: 0.065202\n",
      "Train Epoch: 2 [4480/5509 (80%)]\tLoss: 0.016703\n",
      "Train Epoch: 2 [5120/5509 (92%)]\tLoss: 0.092314\n",
      "Train Epoch: 3 [0/5509 (0%)]\tLoss: 0.078246\n",
      "Train Epoch: 3 [640/5509 (11%)]\tLoss: 0.063006\n",
      "Train Epoch: 3 [1280/5509 (23%)]\tLoss: 0.026137\n",
      "Train Epoch: 3 [1920/5509 (34%)]\tLoss: 0.074810\n",
      "Train Epoch: 3 [2560/5509 (46%)]\tLoss: 0.016499\n",
      "Train Epoch: 3 [3200/5509 (57%)]\tLoss: 0.020603\n",
      "Train Epoch: 3 [3840/5509 (69%)]\tLoss: 0.086769\n",
      "Train Epoch: 3 [4480/5509 (80%)]\tLoss: 0.047495\n",
      "Train Epoch: 3 [5120/5509 (92%)]\tLoss: 0.154133\n",
      "Train Epoch: 4 [0/5509 (0%)]\tLoss: 0.135761\n",
      "Train Epoch: 4 [640/5509 (11%)]\tLoss: 0.057754\n",
      "Train Epoch: 4 [1280/5509 (23%)]\tLoss: 0.041956\n",
      "Train Epoch: 4 [1920/5509 (34%)]\tLoss: 0.087801\n",
      "Train Epoch: 4 [2560/5509 (46%)]\tLoss: 0.091892\n",
      "Train Epoch: 4 [3200/5509 (57%)]\tLoss: 0.051269\n",
      "Train Epoch: 4 [3840/5509 (69%)]\tLoss: 0.100794\n",
      "Train Epoch: 4 [4480/5509 (80%)]\tLoss: 0.206233\n",
      "Train Epoch: 4 [5120/5509 (92%)]\tLoss: 0.035821\n",
      "Train Epoch: 5 [0/5509 (0%)]\tLoss: 0.223803\n",
      "Train Epoch: 5 [640/5509 (11%)]\tLoss: 0.020175\n",
      "Train Epoch: 5 [1280/5509 (23%)]\tLoss: 0.061604\n",
      "Train Epoch: 5 [1920/5509 (34%)]\tLoss: 0.030309\n",
      "Train Epoch: 5 [2560/5509 (46%)]\tLoss: 0.027762\n",
      "Train Epoch: 5 [3200/5509 (57%)]\tLoss: 0.071729\n",
      "Train Epoch: 5 [3840/5509 (69%)]\tLoss: 0.017621\n",
      "Train Epoch: 5 [4480/5509 (80%)]\tLoss: 0.031876\n",
      "Train Epoch: 5 [5120/5509 (92%)]\tLoss: 0.048113\n",
      "Train Epoch: 6 [0/5509 (0%)]\tLoss: 0.027131\n",
      "Train Epoch: 6 [640/5509 (11%)]\tLoss: 0.013703\n",
      "Train Epoch: 6 [1280/5509 (23%)]\tLoss: 0.021868\n",
      "Train Epoch: 6 [1920/5509 (34%)]\tLoss: 0.010355\n",
      "Train Epoch: 6 [2560/5509 (46%)]\tLoss: 0.033555\n",
      "Train Epoch: 6 [3200/5509 (57%)]\tLoss: 0.019404\n",
      "Train Epoch: 6 [3840/5509 (69%)]\tLoss: 0.028609\n",
      "Train Epoch: 6 [4480/5509 (80%)]\tLoss: 0.010243\n",
      "Train Epoch: 6 [5120/5509 (92%)]\tLoss: 0.032180\n",
      "Train Epoch: 7 [0/5509 (0%)]\tLoss: 0.143610\n",
      "Train Epoch: 7 [640/5509 (11%)]\tLoss: 0.033831\n",
      "Train Epoch: 7 [1280/5509 (23%)]\tLoss: 0.063796\n",
      "Train Epoch: 7 [1920/5509 (34%)]\tLoss: 0.055663\n",
      "Train Epoch: 7 [2560/5509 (46%)]\tLoss: 0.108894\n",
      "Train Epoch: 7 [3200/5509 (57%)]\tLoss: 0.103518\n",
      "Train Epoch: 7 [3840/5509 (69%)]\tLoss: 0.071462\n",
      "Train Epoch: 7 [4480/5509 (80%)]\tLoss: 0.010010\n",
      "Train Epoch: 7 [5120/5509 (92%)]\tLoss: 0.124541\n",
      "Train Epoch: 8 [0/5509 (0%)]\tLoss: 0.139698\n",
      "Train Epoch: 8 [640/5509 (11%)]\tLoss: 0.004051\n",
      "Train Epoch: 8 [1280/5509 (23%)]\tLoss: 0.086061\n",
      "Train Epoch: 8 [1920/5509 (34%)]\tLoss: 0.072924\n",
      "Train Epoch: 8 [2560/5509 (46%)]\tLoss: 0.115187\n",
      "Train Epoch: 8 [3200/5509 (57%)]\tLoss: 0.094012\n",
      "Train Epoch: 8 [3840/5509 (69%)]\tLoss: 0.051543\n",
      "Train Epoch: 8 [4480/5509 (80%)]\tLoss: 0.156672\n",
      "Train Epoch: 8 [5120/5509 (92%)]\tLoss: 0.046288\n",
      "Train Epoch: 9 [0/5509 (0%)]\tLoss: 0.069719\n",
      "Train Epoch: 9 [640/5509 (11%)]\tLoss: 0.066330\n",
      "Train Epoch: 9 [1280/5509 (23%)]\tLoss: 0.051054\n",
      "Train Epoch: 9 [1920/5509 (34%)]\tLoss: 0.136781\n",
      "Train Epoch: 9 [2560/5509 (46%)]\tLoss: 0.121557\n",
      "Train Epoch: 9 [3200/5509 (57%)]\tLoss: 0.008834\n",
      "Train Epoch: 9 [3840/5509 (69%)]\tLoss: 0.020023\n",
      "Train Epoch: 9 [4480/5509 (80%)]\tLoss: 0.013042\n",
      "Train Epoch: 9 [5120/5509 (92%)]\tLoss: 0.044467\n",
      "Train Epoch: 10 [0/5509 (0%)]\tLoss: 0.011229\n",
      "Train Epoch: 10 [640/5509 (11%)]\tLoss: 0.093828\n",
      "Train Epoch: 10 [1280/5509 (23%)]\tLoss: 0.041543\n",
      "Train Epoch: 10 [1920/5509 (34%)]\tLoss: 0.013703\n",
      "Train Epoch: 10 [2560/5509 (46%)]\tLoss: 0.051114\n",
      "Train Epoch: 10 [3200/5509 (57%)]\tLoss: 0.050809\n",
      "Train Epoch: 10 [3840/5509 (69%)]\tLoss: 0.034719\n",
      "Train Epoch: 10 [4480/5509 (80%)]\tLoss: 0.014409\n",
      "Train Epoch: 10 [5120/5509 (92%)]\tLoss: 0.089285\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 0.100483\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 0.047646\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 0.024775\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 0.101531\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 0.123555\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 0.078558\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 0.026271\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 0.009535\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 0.047095\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 0.056774\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.056793\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.091378\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 0.028474\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 0.103624\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 0.064659\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.013587\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.045051\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.023787\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.002034\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.012106\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.017337\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.010872\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.010181\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.053619\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.015483\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.030622\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.027661\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.204396\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.071749\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.018571\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.002278\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.018648\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.040112\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.043946\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.180821\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.012032\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.034132\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.006239\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.095566\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.024523\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.030164\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.006277\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.006114\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.010960\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.027346\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.014719\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.004687\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.020258\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.077698\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.013087\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.061194\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.032538\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.007088\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.152509\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.012492\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.027615\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.025358\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.010277\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.020458\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.028417\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.012386\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.005850\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.005376\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.033891\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.004066\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.009749\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.003666\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.020595\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.010838\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.119439\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.005678\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.008482\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.024232\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.044980\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.114851\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.008302\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.065426\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.034980\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.086539\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.003807\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.048537\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.052286\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.082346\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.037571\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.017058\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.057733\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.024861\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.008457\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.064257\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.004623\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.023745\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.027213\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.008480\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.014294\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.014442\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.011212\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.011435\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.006675\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.010993\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.054739\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.115888\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.047675\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.003796\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.032087\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.007961\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.014142\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.023051\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.101010\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.034205\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.001568\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.051151\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.013244\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.039358\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.023362\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.005811\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.053583\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.033373\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.007873\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.041956\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.005565\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.1580, Accuracy: 9869/10000 (99%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 0.081039\n",
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 0.017673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 0.008140\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 0.027879\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 0.098237\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 0.033189\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 0.083709\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 0.023136\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 0.043720\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 0.108128\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 0.086262\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 0.017333\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 0.027463\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 0.126487\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 0.131162\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 0.004749\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 0.013333\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 0.032987\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 0.046289\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 0.058358\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.038811\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 0.047734\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 0.031728\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.054364\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.072966\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 0.012019\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.171018\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 0.014929\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.033386\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.011926\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.014908\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.048472\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.047258\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.100921\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.199768\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.044678\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.070738\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.058473\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.091862\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.015261\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.013803\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.094080\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.032377\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.019362\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.043197\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.069473\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.028996\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.050034\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.123601\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.028786\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.234115\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.035650\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.089781\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.099423\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.052689\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.148638\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.023284\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.102319\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.074311\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.017943\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.004871\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.029467\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.032369\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.020693\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.034696\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.055235\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.017118\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.163012\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.062372\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.156370\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.072830\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.046760\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.055183\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.038899\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.007013\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.033609\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.101544\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.021828\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.079705\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.012356\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.058453\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.009577\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.039181\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.026401\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.063745\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.127811\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.008364\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.191872\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.032319\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.007407\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.046074\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.017157\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.008653\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.012738\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.070862\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.037593\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.015866\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.019968\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.040162\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.007916\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.046355\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.015780\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.099971\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.096548\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.197504\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.122275\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.081331\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.060034\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 0.007093\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.047761\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.028554\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.016729\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.031965\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.017388\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.128627\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.080149\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.089327\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.164536\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.061032\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.059688\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.032434\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.118601\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.050655\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.015937\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.069183\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.032818\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.049735\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.033772\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.013066\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.015090\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.006503\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.120375\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.079652\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.066832\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.003715\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.059671\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.080792\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.048680\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.019548\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.007245\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.041206\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.033090\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.071520\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.014560\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.118195\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.003919\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.020228\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.020941\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.016080\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.061825\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.022751\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.012485\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.008633\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.006785\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.153102\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.089498\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.064650\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.012407\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.021406\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.015884\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.002446\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.035827\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.030146\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.076218\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.016549\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.108487\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.043697\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.033070\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.058976\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.028468\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.020517\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.009370\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.039812\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.044709\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.040340\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.069776\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.007740\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.032800\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.043140\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.016948\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/13906 (0%)]\tLoss: 0.098971\n",
      "Train Epoch: 1 [640/13906 (5%)]\tLoss: 0.039416\n",
      "Train Epoch: 1 [1280/13906 (9%)]\tLoss: 0.095794\n",
      "Train Epoch: 1 [1920/13906 (14%)]\tLoss: 0.054594\n",
      "Train Epoch: 1 [2560/13906 (18%)]\tLoss: 0.024886\n",
      "Train Epoch: 1 [3200/13906 (23%)]\tLoss: 0.073282\n",
      "Train Epoch: 1 [3840/13906 (28%)]\tLoss: 0.015573\n",
      "Train Epoch: 1 [4480/13906 (32%)]\tLoss: 0.095596\n",
      "Train Epoch: 1 [5120/13906 (37%)]\tLoss: 0.108304\n",
      "Train Epoch: 1 [5760/13906 (41%)]\tLoss: 0.013975\n",
      "Train Epoch: 1 [6400/13906 (46%)]\tLoss: 0.113343\n",
      "Train Epoch: 1 [7040/13906 (50%)]\tLoss: 0.051256\n",
      "Train Epoch: 1 [7680/13906 (55%)]\tLoss: 0.035459\n",
      "Train Epoch: 1 [8320/13906 (60%)]\tLoss: 0.073594\n",
      "Train Epoch: 1 [8960/13906 (64%)]\tLoss: 0.140650\n",
      "Train Epoch: 1 [9600/13906 (69%)]\tLoss: 0.167859\n",
      "Train Epoch: 1 [10240/13906 (73%)]\tLoss: 0.238931\n",
      "Train Epoch: 1 [10880/13906 (78%)]\tLoss: 0.033169\n",
      "Train Epoch: 1 [11520/13906 (83%)]\tLoss: 0.014446\n",
      "Train Epoch: 1 [12160/13906 (87%)]\tLoss: 0.018968\n",
      "Train Epoch: 1 [12800/13906 (92%)]\tLoss: 0.112592\n",
      "Train Epoch: 1 [13440/13906 (96%)]\tLoss: 0.009604\n",
      "Train Epoch: 2 [0/13906 (0%)]\tLoss: 0.061255\n",
      "Train Epoch: 2 [640/13906 (5%)]\tLoss: 0.049427\n",
      "Train Epoch: 2 [1280/13906 (9%)]\tLoss: 0.013159\n",
      "Train Epoch: 2 [1920/13906 (14%)]\tLoss: 0.058900\n",
      "Train Epoch: 2 [2560/13906 (18%)]\tLoss: 0.037543\n",
      "Train Epoch: 2 [3200/13906 (23%)]\tLoss: 0.054770\n",
      "Train Epoch: 2 [3840/13906 (28%)]\tLoss: 0.088276\n",
      "Train Epoch: 2 [4480/13906 (32%)]\tLoss: 0.029253\n",
      "Train Epoch: 2 [5120/13906 (37%)]\tLoss: 0.031270\n",
      "Train Epoch: 2 [5760/13906 (41%)]\tLoss: 0.016284\n",
      "Train Epoch: 2 [6400/13906 (46%)]\tLoss: 0.189528\n",
      "Train Epoch: 2 [7040/13906 (50%)]\tLoss: 0.012618\n",
      "Train Epoch: 2 [7680/13906 (55%)]\tLoss: 0.023727\n",
      "Train Epoch: 2 [8320/13906 (60%)]\tLoss: 0.147470\n",
      "Train Epoch: 2 [8960/13906 (64%)]\tLoss: 0.143831\n",
      "Train Epoch: 2 [9600/13906 (69%)]\tLoss: 0.135891\n",
      "Train Epoch: 2 [10240/13906 (73%)]\tLoss: 0.072374\n",
      "Train Epoch: 2 [10880/13906 (78%)]\tLoss: 0.043522\n",
      "Train Epoch: 2 [11520/13906 (83%)]\tLoss: 0.033616\n",
      "Train Epoch: 2 [12160/13906 (87%)]\tLoss: 0.109832\n",
      "Train Epoch: 2 [12800/13906 (92%)]\tLoss: 0.097955\n",
      "Train Epoch: 2 [13440/13906 (96%)]\tLoss: 0.129256\n",
      "Train Epoch: 3 [0/13906 (0%)]\tLoss: 0.019719\n",
      "Train Epoch: 3 [640/13906 (5%)]\tLoss: 0.048980\n",
      "Train Epoch: 3 [1280/13906 (9%)]\tLoss: 0.121826\n",
      "Train Epoch: 3 [1920/13906 (14%)]\tLoss: 0.060417\n",
      "Train Epoch: 3 [2560/13906 (18%)]\tLoss: 0.002119\n",
      "Train Epoch: 3 [3200/13906 (23%)]\tLoss: 0.115521\n",
      "Train Epoch: 3 [3840/13906 (28%)]\tLoss: 0.056931\n",
      "Train Epoch: 3 [4480/13906 (32%)]\tLoss: 0.045732\n",
      "Train Epoch: 3 [5120/13906 (37%)]\tLoss: 0.046867\n",
      "Train Epoch: 3 [5760/13906 (41%)]\tLoss: 0.031243\n",
      "Train Epoch: 3 [6400/13906 (46%)]\tLoss: 0.040698\n",
      "Train Epoch: 3 [7040/13906 (50%)]\tLoss: 0.051365\n",
      "Train Epoch: 3 [7680/13906 (55%)]\tLoss: 0.043981\n",
      "Train Epoch: 3 [8320/13906 (60%)]\tLoss: 0.026116\n",
      "Train Epoch: 3 [8960/13906 (64%)]\tLoss: 0.035869\n",
      "Train Epoch: 3 [9600/13906 (69%)]\tLoss: 0.001323\n",
      "Train Epoch: 3 [10240/13906 (73%)]\tLoss: 0.020465\n",
      "Train Epoch: 3 [10880/13906 (78%)]\tLoss: 0.102436\n",
      "Train Epoch: 3 [11520/13906 (83%)]\tLoss: 0.039736\n",
      "Train Epoch: 3 [12160/13906 (87%)]\tLoss: 0.121804\n",
      "Train Epoch: 3 [12800/13906 (92%)]\tLoss: 0.051088\n",
      "Train Epoch: 3 [13440/13906 (96%)]\tLoss: 0.042024\n",
      "Train Epoch: 4 [0/13906 (0%)]\tLoss: 0.062907\n",
      "Train Epoch: 4 [640/13906 (5%)]\tLoss: 0.098583\n",
      "Train Epoch: 4 [1280/13906 (9%)]\tLoss: 0.065220\n",
      "Train Epoch: 4 [1920/13906 (14%)]\tLoss: 0.058914\n",
      "Train Epoch: 4 [2560/13906 (18%)]\tLoss: 0.003809\n",
      "Train Epoch: 4 [3200/13906 (23%)]\tLoss: 0.024819\n",
      "Train Epoch: 4 [3840/13906 (28%)]\tLoss: 0.136374\n",
      "Train Epoch: 4 [4480/13906 (32%)]\tLoss: 0.050960\n",
      "Train Epoch: 4 [5120/13906 (37%)]\tLoss: 0.090305\n",
      "Train Epoch: 4 [5760/13906 (41%)]\tLoss: 0.073760\n",
      "Train Epoch: 4 [6400/13906 (46%)]\tLoss: 0.022383\n",
      "Train Epoch: 4 [7040/13906 (50%)]\tLoss: 0.009853\n",
      "Train Epoch: 4 [7680/13906 (55%)]\tLoss: 0.149804\n",
      "Train Epoch: 4 [8320/13906 (60%)]\tLoss: 0.054415\n",
      "Train Epoch: 4 [8960/13906 (64%)]\tLoss: 0.057444\n",
      "Train Epoch: 4 [9600/13906 (69%)]\tLoss: 0.044296\n",
      "Train Epoch: 4 [10240/13906 (73%)]\tLoss: 0.030447\n",
      "Train Epoch: 4 [10880/13906 (78%)]\tLoss: 0.028513\n",
      "Train Epoch: 4 [11520/13906 (83%)]\tLoss: 0.043813\n",
      "Train Epoch: 4 [12160/13906 (87%)]\tLoss: 0.009906\n",
      "Train Epoch: 4 [12800/13906 (92%)]\tLoss: 0.083972\n",
      "Train Epoch: 4 [13440/13906 (96%)]\tLoss: 0.218219\n",
      "Train Epoch: 5 [0/13906 (0%)]\tLoss: 0.063505\n",
      "Train Epoch: 5 [640/13906 (5%)]\tLoss: 0.118762\n",
      "Train Epoch: 5 [1280/13906 (9%)]\tLoss: 0.083272\n",
      "Train Epoch: 5 [1920/13906 (14%)]\tLoss: 0.027648\n",
      "Train Epoch: 5 [2560/13906 (18%)]\tLoss: 0.051311\n",
      "Train Epoch: 5 [3200/13906 (23%)]\tLoss: 0.025107\n",
      "Train Epoch: 5 [3840/13906 (28%)]\tLoss: 0.006666\n",
      "Train Epoch: 5 [4480/13906 (32%)]\tLoss: 0.020247\n",
      "Train Epoch: 5 [5120/13906 (37%)]\tLoss: 0.069906\n",
      "Train Epoch: 5 [5760/13906 (41%)]\tLoss: 0.116502\n",
      "Train Epoch: 5 [6400/13906 (46%)]\tLoss: 0.060022\n",
      "Train Epoch: 5 [7040/13906 (50%)]\tLoss: 0.015572\n",
      "Train Epoch: 5 [7680/13906 (55%)]\tLoss: 0.211915\n",
      "Train Epoch: 5 [8320/13906 (60%)]\tLoss: 0.123114\n",
      "Train Epoch: 5 [8960/13906 (64%)]\tLoss: 0.081845\n",
      "Train Epoch: 5 [9600/13906 (69%)]\tLoss: 0.018234\n",
      "Train Epoch: 5 [10240/13906 (73%)]\tLoss: 0.051348\n",
      "Train Epoch: 5 [10880/13906 (78%)]\tLoss: 0.016789\n",
      "Train Epoch: 5 [11520/13906 (83%)]\tLoss: 0.089537\n",
      "Train Epoch: 5 [12160/13906 (87%)]\tLoss: 0.052431\n",
      "Train Epoch: 5 [12800/13906 (92%)]\tLoss: 0.082091\n",
      "Train Epoch: 5 [13440/13906 (96%)]\tLoss: 0.013472\n",
      "Train Epoch: 6 [0/13906 (0%)]\tLoss: 0.035855\n",
      "Train Epoch: 6 [640/13906 (5%)]\tLoss: 0.026000\n",
      "Train Epoch: 6 [1280/13906 (9%)]\tLoss: 0.047525\n",
      "Train Epoch: 6 [1920/13906 (14%)]\tLoss: 0.184277\n",
      "Train Epoch: 6 [2560/13906 (18%)]\tLoss: 0.097841\n",
      "Train Epoch: 6 [3200/13906 (23%)]\tLoss: 0.047807\n",
      "Train Epoch: 6 [3840/13906 (28%)]\tLoss: 0.083427\n",
      "Train Epoch: 6 [4480/13906 (32%)]\tLoss: 0.011223\n",
      "Train Epoch: 6 [5120/13906 (37%)]\tLoss: 0.019646\n",
      "Train Epoch: 6 [5760/13906 (41%)]\tLoss: 0.101337\n",
      "Train Epoch: 6 [6400/13906 (46%)]\tLoss: 0.036353\n",
      "Train Epoch: 6 [7040/13906 (50%)]\tLoss: 0.156183\n",
      "Train Epoch: 6 [7680/13906 (55%)]\tLoss: 0.040896\n",
      "Train Epoch: 6 [8320/13906 (60%)]\tLoss: 0.100092\n",
      "Train Epoch: 6 [8960/13906 (64%)]\tLoss: 0.026287\n",
      "Train Epoch: 6 [9600/13906 (69%)]\tLoss: 0.023117\n",
      "Train Epoch: 6 [10240/13906 (73%)]\tLoss: 0.067666\n",
      "Train Epoch: 6 [10880/13906 (78%)]\tLoss: 0.029844\n",
      "Train Epoch: 6 [11520/13906 (83%)]\tLoss: 0.033804\n",
      "Train Epoch: 6 [12160/13906 (87%)]\tLoss: 0.015968\n",
      "Train Epoch: 6 [12800/13906 (92%)]\tLoss: 0.039094\n",
      "Train Epoch: 6 [13440/13906 (96%)]\tLoss: 0.103581\n",
      "Train Epoch: 7 [0/13906 (0%)]\tLoss: 0.013526\n",
      "Train Epoch: 7 [640/13906 (5%)]\tLoss: 0.032815\n",
      "Train Epoch: 7 [1280/13906 (9%)]\tLoss: 0.013437\n",
      "Train Epoch: 7 [1920/13906 (14%)]\tLoss: 0.055097\n",
      "Train Epoch: 7 [2560/13906 (18%)]\tLoss: 0.041437\n",
      "Train Epoch: 7 [3200/13906 (23%)]\tLoss: 0.099854\n",
      "Train Epoch: 7 [3840/13906 (28%)]\tLoss: 0.020872\n",
      "Train Epoch: 7 [4480/13906 (32%)]\tLoss: 0.027044\n",
      "Train Epoch: 7 [5120/13906 (37%)]\tLoss: 0.156934\n",
      "Train Epoch: 7 [5760/13906 (41%)]\tLoss: 0.015611\n",
      "Train Epoch: 7 [6400/13906 (46%)]\tLoss: 0.059857\n",
      "Train Epoch: 7 [7040/13906 (50%)]\tLoss: 0.004670\n",
      "Train Epoch: 7 [7680/13906 (55%)]\tLoss: 0.034502\n",
      "Train Epoch: 7 [8320/13906 (60%)]\tLoss: 0.053794\n",
      "Train Epoch: 7 [8960/13906 (64%)]\tLoss: 0.057631\n",
      "Train Epoch: 7 [9600/13906 (69%)]\tLoss: 0.038787\n",
      "Train Epoch: 7 [10240/13906 (73%)]\tLoss: 0.073796\n",
      "Train Epoch: 7 [10880/13906 (78%)]\tLoss: 0.021183\n",
      "Train Epoch: 7 [11520/13906 (83%)]\tLoss: 0.053595\n",
      "Train Epoch: 7 [12160/13906 (87%)]\tLoss: 0.106881\n",
      "Train Epoch: 7 [12800/13906 (92%)]\tLoss: 0.067582\n",
      "Train Epoch: 7 [13440/13906 (96%)]\tLoss: 0.028227\n",
      "Train Epoch: 8 [0/13906 (0%)]\tLoss: 0.087249\n",
      "Train Epoch: 8 [640/13906 (5%)]\tLoss: 0.011627\n",
      "Train Epoch: 8 [1280/13906 (9%)]\tLoss: 0.078915\n",
      "Train Epoch: 8 [1920/13906 (14%)]\tLoss: 0.088530\n",
      "Train Epoch: 8 [2560/13906 (18%)]\tLoss: 0.100574\n",
      "Train Epoch: 8 [3200/13906 (23%)]\tLoss: 0.029779\n",
      "Train Epoch: 8 [3840/13906 (28%)]\tLoss: 0.003200\n",
      "Train Epoch: 8 [4480/13906 (32%)]\tLoss: 0.029789\n",
      "Train Epoch: 8 [5120/13906 (37%)]\tLoss: 0.061733\n",
      "Train Epoch: 8 [5760/13906 (41%)]\tLoss: 0.037767\n",
      "Train Epoch: 8 [6400/13906 (46%)]\tLoss: 0.045274\n",
      "Train Epoch: 8 [7040/13906 (50%)]\tLoss: 0.067951\n",
      "Train Epoch: 8 [7680/13906 (55%)]\tLoss: 0.086584\n",
      "Train Epoch: 8 [8320/13906 (60%)]\tLoss: 0.024214\n",
      "Train Epoch: 8 [8960/13906 (64%)]\tLoss: 0.013634\n",
      "Train Epoch: 8 [9600/13906 (69%)]\tLoss: 0.036773\n",
      "Train Epoch: 8 [10240/13906 (73%)]\tLoss: 0.043046\n",
      "Train Epoch: 8 [10880/13906 (78%)]\tLoss: 0.017698\n",
      "Train Epoch: 8 [11520/13906 (83%)]\tLoss: 0.073472\n",
      "Train Epoch: 8 [12160/13906 (87%)]\tLoss: 0.140392\n",
      "Train Epoch: 8 [12800/13906 (92%)]\tLoss: 0.058130\n",
      "Train Epoch: 8 [13440/13906 (96%)]\tLoss: 0.147377\n",
      "Train Epoch: 9 [0/13906 (0%)]\tLoss: 0.208635\n",
      "Train Epoch: 9 [640/13906 (5%)]\tLoss: 0.027346\n",
      "Train Epoch: 9 [1280/13906 (9%)]\tLoss: 0.024131\n",
      "Train Epoch: 9 [1920/13906 (14%)]\tLoss: 0.049552\n",
      "Train Epoch: 9 [2560/13906 (18%)]\tLoss: 0.050251\n",
      "Train Epoch: 9 [3200/13906 (23%)]\tLoss: 0.136785\n",
      "Train Epoch: 9 [3840/13906 (28%)]\tLoss: 0.089564\n",
      "Train Epoch: 9 [4480/13906 (32%)]\tLoss: 0.144920\n",
      "Train Epoch: 9 [5120/13906 (37%)]\tLoss: 0.077540\n",
      "Train Epoch: 9 [5760/13906 (41%)]\tLoss: 0.070803\n",
      "Train Epoch: 9 [6400/13906 (46%)]\tLoss: 0.056706\n",
      "Train Epoch: 9 [7040/13906 (50%)]\tLoss: 0.020786\n",
      "Train Epoch: 9 [7680/13906 (55%)]\tLoss: 0.060798\n",
      "Train Epoch: 9 [8320/13906 (60%)]\tLoss: 0.074312\n",
      "Train Epoch: 9 [8960/13906 (64%)]\tLoss: 0.039556\n",
      "Train Epoch: 9 [9600/13906 (69%)]\tLoss: 0.052492\n",
      "Train Epoch: 9 [10240/13906 (73%)]\tLoss: 0.093548\n",
      "Train Epoch: 9 [10880/13906 (78%)]\tLoss: 0.077783\n",
      "Train Epoch: 9 [11520/13906 (83%)]\tLoss: 0.036331\n",
      "Train Epoch: 9 [12160/13906 (87%)]\tLoss: 0.076782\n",
      "Train Epoch: 9 [12800/13906 (92%)]\tLoss: 0.010043\n",
      "Train Epoch: 9 [13440/13906 (96%)]\tLoss: 0.077633\n",
      "Train Epoch: 10 [0/13906 (0%)]\tLoss: 0.006651\n",
      "Train Epoch: 10 [640/13906 (5%)]\tLoss: 0.009456\n",
      "Train Epoch: 10 [1280/13906 (9%)]\tLoss: 0.063007\n",
      "Train Epoch: 10 [1920/13906 (14%)]\tLoss: 0.066660\n",
      "Train Epoch: 10 [2560/13906 (18%)]\tLoss: 0.130016\n",
      "Train Epoch: 10 [3200/13906 (23%)]\tLoss: 0.084214\n",
      "Train Epoch: 10 [3840/13906 (28%)]\tLoss: 0.058522\n",
      "Train Epoch: 10 [4480/13906 (32%)]\tLoss: 0.033022\n",
      "Train Epoch: 10 [5120/13906 (37%)]\tLoss: 0.117703\n",
      "Train Epoch: 10 [5760/13906 (41%)]\tLoss: 0.174444\n",
      "Train Epoch: 10 [6400/13906 (46%)]\tLoss: 0.043627\n",
      "Train Epoch: 10 [7040/13906 (50%)]\tLoss: 0.186025\n",
      "Train Epoch: 10 [7680/13906 (55%)]\tLoss: 0.055260\n",
      "Train Epoch: 10 [8320/13906 (60%)]\tLoss: 0.049545\n",
      "Train Epoch: 10 [8960/13906 (64%)]\tLoss: 0.009257\n",
      "Train Epoch: 10 [9600/13906 (69%)]\tLoss: 0.048375\n",
      "Train Epoch: 10 [10240/13906 (73%)]\tLoss: 0.064599\n",
      "Train Epoch: 10 [10880/13906 (78%)]\tLoss: 0.116374\n",
      "Train Epoch: 10 [11520/13906 (83%)]\tLoss: 0.001810\n",
      "Train Epoch: 10 [12160/13906 (87%)]\tLoss: 0.019864\n",
      "Train Epoch: 10 [12800/13906 (92%)]\tLoss: 0.020983\n",
      "Train Epoch: 10 [13440/13906 (96%)]\tLoss: 0.016466\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/11862 (0%)]\tLoss: 0.123122\n",
      "Train Epoch: 1 [640/11862 (5%)]\tLoss: 0.066438\n",
      "Train Epoch: 1 [1280/11862 (11%)]\tLoss: 0.033808\n",
      "Train Epoch: 1 [1920/11862 (16%)]\tLoss: 0.016691\n",
      "Train Epoch: 1 [2560/11862 (22%)]\tLoss: 0.061090\n",
      "Train Epoch: 1 [3200/11862 (27%)]\tLoss: 0.043879\n",
      "Train Epoch: 1 [3840/11862 (32%)]\tLoss: 0.038220\n",
      "Train Epoch: 1 [4480/11862 (38%)]\tLoss: 0.089495\n",
      "Train Epoch: 1 [5120/11862 (43%)]\tLoss: 0.105011\n",
      "Train Epoch: 1 [5760/11862 (48%)]\tLoss: 0.015145\n",
      "Train Epoch: 1 [6400/11862 (54%)]\tLoss: 0.061328\n",
      "Train Epoch: 1 [7040/11862 (59%)]\tLoss: 0.008477\n",
      "Train Epoch: 1 [7680/11862 (65%)]\tLoss: 0.173808\n",
      "Train Epoch: 1 [8320/11862 (70%)]\tLoss: 0.016203\n",
      "Train Epoch: 1 [8960/11862 (75%)]\tLoss: 0.023768\n",
      "Train Epoch: 1 [9600/11862 (81%)]\tLoss: 0.027553\n",
      "Train Epoch: 1 [10240/11862 (86%)]\tLoss: 0.031708\n",
      "Train Epoch: 1 [10880/11862 (91%)]\tLoss: 0.012937\n",
      "Train Epoch: 1 [11520/11862 (97%)]\tLoss: 0.008453\n",
      "Train Epoch: 2 [0/11862 (0%)]\tLoss: 0.092138\n",
      "Train Epoch: 2 [640/11862 (5%)]\tLoss: 0.085643\n",
      "Train Epoch: 2 [1280/11862 (11%)]\tLoss: 0.012593\n",
      "Train Epoch: 2 [1920/11862 (16%)]\tLoss: 0.003293\n",
      "Train Epoch: 2 [2560/11862 (22%)]\tLoss: 0.017328\n",
      "Train Epoch: 2 [3200/11862 (27%)]\tLoss: 0.008361\n",
      "Train Epoch: 2 [3840/11862 (32%)]\tLoss: 0.059738\n",
      "Train Epoch: 2 [4480/11862 (38%)]\tLoss: 0.028107\n",
      "Train Epoch: 2 [5120/11862 (43%)]\tLoss: 0.012833\n",
      "Train Epoch: 2 [5760/11862 (48%)]\tLoss: 0.018367\n",
      "Train Epoch: 2 [6400/11862 (54%)]\tLoss: 0.063453\n",
      "Train Epoch: 2 [7040/11862 (59%)]\tLoss: 0.110692\n",
      "Train Epoch: 2 [7680/11862 (65%)]\tLoss: 0.018632\n",
      "Train Epoch: 2 [8320/11862 (70%)]\tLoss: 0.092115\n",
      "Train Epoch: 2 [8960/11862 (75%)]\tLoss: 0.116549\n",
      "Train Epoch: 2 [9600/11862 (81%)]\tLoss: 0.057228\n",
      "Train Epoch: 2 [10240/11862 (86%)]\tLoss: 0.216389\n",
      "Train Epoch: 2 [10880/11862 (91%)]\tLoss: 0.088495\n",
      "Train Epoch: 2 [11520/11862 (97%)]\tLoss: 0.062406\n",
      "Train Epoch: 3 [0/11862 (0%)]\tLoss: 0.024744\n",
      "Train Epoch: 3 [640/11862 (5%)]\tLoss: 0.020528\n",
      "Train Epoch: 3 [1280/11862 (11%)]\tLoss: 0.068082\n",
      "Train Epoch: 3 [1920/11862 (16%)]\tLoss: 0.015232\n",
      "Train Epoch: 3 [2560/11862 (22%)]\tLoss: 0.117235\n",
      "Train Epoch: 3 [3200/11862 (27%)]\tLoss: 0.054811\n",
      "Train Epoch: 3 [3840/11862 (32%)]\tLoss: 0.083911\n",
      "Train Epoch: 3 [4480/11862 (38%)]\tLoss: 0.123346\n",
      "Train Epoch: 3 [5120/11862 (43%)]\tLoss: 0.009000\n",
      "Train Epoch: 3 [5760/11862 (48%)]\tLoss: 0.039731\n",
      "Train Epoch: 3 [6400/11862 (54%)]\tLoss: 0.044332\n",
      "Train Epoch: 3 [7040/11862 (59%)]\tLoss: 0.040741\n",
      "Train Epoch: 3 [7680/11862 (65%)]\tLoss: 0.032356\n",
      "Train Epoch: 3 [8320/11862 (70%)]\tLoss: 0.021896\n",
      "Train Epoch: 3 [8960/11862 (75%)]\tLoss: 0.040663\n",
      "Train Epoch: 3 [9600/11862 (81%)]\tLoss: 0.034425\n",
      "Train Epoch: 3 [10240/11862 (86%)]\tLoss: 0.040585\n",
      "Train Epoch: 3 [10880/11862 (91%)]\tLoss: 0.110999\n",
      "Train Epoch: 3 [11520/11862 (97%)]\tLoss: 0.129205\n",
      "Train Epoch: 4 [0/11862 (0%)]\tLoss: 0.005009\n",
      "Train Epoch: 4 [640/11862 (5%)]\tLoss: 0.149365\n",
      "Train Epoch: 4 [1280/11862 (11%)]\tLoss: 0.029025\n",
      "Train Epoch: 4 [1920/11862 (16%)]\tLoss: 0.067053\n",
      "Train Epoch: 4 [2560/11862 (22%)]\tLoss: 0.018060\n",
      "Train Epoch: 4 [3200/11862 (27%)]\tLoss: 0.031598\n",
      "Train Epoch: 4 [3840/11862 (32%)]\tLoss: 0.007573\n",
      "Train Epoch: 4 [4480/11862 (38%)]\tLoss: 0.025644\n",
      "Train Epoch: 4 [5120/11862 (43%)]\tLoss: 0.004289\n",
      "Train Epoch: 4 [5760/11862 (48%)]\tLoss: 0.101590\n",
      "Train Epoch: 4 [6400/11862 (54%)]\tLoss: 0.007138\n",
      "Train Epoch: 4 [7040/11862 (59%)]\tLoss: 0.010159\n",
      "Train Epoch: 4 [7680/11862 (65%)]\tLoss: 0.028952\n",
      "Train Epoch: 4 [8320/11862 (70%)]\tLoss: 0.013710\n",
      "Train Epoch: 4 [8960/11862 (75%)]\tLoss: 0.047021\n",
      "Train Epoch: 4 [9600/11862 (81%)]\tLoss: 0.041778\n",
      "Train Epoch: 4 [10240/11862 (86%)]\tLoss: 0.025091\n",
      "Train Epoch: 4 [10880/11862 (91%)]\tLoss: 0.011383\n",
      "Train Epoch: 4 [11520/11862 (97%)]\tLoss: 0.033923\n",
      "Train Epoch: 5 [0/11862 (0%)]\tLoss: 0.101621\n",
      "Train Epoch: 5 [640/11862 (5%)]\tLoss: 0.083455\n",
      "Train Epoch: 5 [1280/11862 (11%)]\tLoss: 0.029513\n",
      "Train Epoch: 5 [1920/11862 (16%)]\tLoss: 0.053646\n",
      "Train Epoch: 5 [2560/11862 (22%)]\tLoss: 0.019479\n",
      "Train Epoch: 5 [3200/11862 (27%)]\tLoss: 0.038782\n",
      "Train Epoch: 5 [3840/11862 (32%)]\tLoss: 0.041968\n",
      "Train Epoch: 5 [4480/11862 (38%)]\tLoss: 0.013726\n",
      "Train Epoch: 5 [5120/11862 (43%)]\tLoss: 0.011808\n",
      "Train Epoch: 5 [5760/11862 (48%)]\tLoss: 0.066571\n",
      "Train Epoch: 5 [6400/11862 (54%)]\tLoss: 0.008800\n",
      "Train Epoch: 5 [7040/11862 (59%)]\tLoss: 0.014523\n",
      "Train Epoch: 5 [7680/11862 (65%)]\tLoss: 0.163377\n",
      "Train Epoch: 5 [8320/11862 (70%)]\tLoss: 0.034138\n",
      "Train Epoch: 5 [8960/11862 (75%)]\tLoss: 0.022429\n",
      "Train Epoch: 5 [9600/11862 (81%)]\tLoss: 0.057014\n",
      "Train Epoch: 5 [10240/11862 (86%)]\tLoss: 0.049914\n",
      "Train Epoch: 5 [10880/11862 (91%)]\tLoss: 0.090936\n",
      "Train Epoch: 5 [11520/11862 (97%)]\tLoss: 0.068890\n",
      "Train Epoch: 6 [0/11862 (0%)]\tLoss: 0.012905\n",
      "Train Epoch: 6 [640/11862 (5%)]\tLoss: 0.046159\n",
      "Train Epoch: 6 [1280/11862 (11%)]\tLoss: 0.013249\n",
      "Train Epoch: 6 [1920/11862 (16%)]\tLoss: 0.084515\n",
      "Train Epoch: 6 [2560/11862 (22%)]\tLoss: 0.045480\n",
      "Train Epoch: 6 [3200/11862 (27%)]\tLoss: 0.043506\n",
      "Train Epoch: 6 [3840/11862 (32%)]\tLoss: 0.018442\n",
      "Train Epoch: 6 [4480/11862 (38%)]\tLoss: 0.065837\n",
      "Train Epoch: 6 [5120/11862 (43%)]\tLoss: 0.007224\n",
      "Train Epoch: 6 [5760/11862 (48%)]\tLoss: 0.021922\n",
      "Train Epoch: 6 [6400/11862 (54%)]\tLoss: 0.018158\n",
      "Train Epoch: 6 [7040/11862 (59%)]\tLoss: 0.040610\n",
      "Train Epoch: 6 [7680/11862 (65%)]\tLoss: 0.012851\n",
      "Train Epoch: 6 [8320/11862 (70%)]\tLoss: 0.021822\n",
      "Train Epoch: 6 [8960/11862 (75%)]\tLoss: 0.001534\n",
      "Train Epoch: 6 [9600/11862 (81%)]\tLoss: 0.075255\n",
      "Train Epoch: 6 [10240/11862 (86%)]\tLoss: 0.020610\n",
      "Train Epoch: 6 [10880/11862 (91%)]\tLoss: 0.097206\n",
      "Train Epoch: 6 [11520/11862 (97%)]\tLoss: 0.008431\n",
      "Train Epoch: 7 [0/11862 (0%)]\tLoss: 0.011130\n",
      "Train Epoch: 7 [640/11862 (5%)]\tLoss: 0.097159\n",
      "Train Epoch: 7 [1280/11862 (11%)]\tLoss: 0.005081\n",
      "Train Epoch: 7 [1920/11862 (16%)]\tLoss: 0.032918\n",
      "Train Epoch: 7 [2560/11862 (22%)]\tLoss: 0.020551\n",
      "Train Epoch: 7 [3200/11862 (27%)]\tLoss: 0.032066\n",
      "Train Epoch: 7 [3840/11862 (32%)]\tLoss: 0.011615\n",
      "Train Epoch: 7 [4480/11862 (38%)]\tLoss: 0.073127\n",
      "Train Epoch: 7 [5120/11862 (43%)]\tLoss: 0.065814\n",
      "Train Epoch: 7 [5760/11862 (48%)]\tLoss: 0.004464\n",
      "Train Epoch: 7 [6400/11862 (54%)]\tLoss: 0.032660\n",
      "Train Epoch: 7 [7040/11862 (59%)]\tLoss: 0.018085\n",
      "Train Epoch: 7 [7680/11862 (65%)]\tLoss: 0.036891\n",
      "Train Epoch: 7 [8320/11862 (70%)]\tLoss: 0.015201\n",
      "Train Epoch: 7 [8960/11862 (75%)]\tLoss: 0.064915\n",
      "Train Epoch: 7 [9600/11862 (81%)]\tLoss: 0.100377\n",
      "Train Epoch: 7 [10240/11862 (86%)]\tLoss: 0.085524\n",
      "Train Epoch: 7 [10880/11862 (91%)]\tLoss: 0.041480\n",
      "Train Epoch: 7 [11520/11862 (97%)]\tLoss: 0.036892\n",
      "Train Epoch: 8 [0/11862 (0%)]\tLoss: 0.016509\n",
      "Train Epoch: 8 [640/11862 (5%)]\tLoss: 0.030707\n",
      "Train Epoch: 8 [1280/11862 (11%)]\tLoss: 0.051537\n",
      "Train Epoch: 8 [1920/11862 (16%)]\tLoss: 0.008916\n",
      "Train Epoch: 8 [2560/11862 (22%)]\tLoss: 0.048254\n",
      "Train Epoch: 8 [3200/11862 (27%)]\tLoss: 0.048189\n",
      "Train Epoch: 8 [3840/11862 (32%)]\tLoss: 0.017554\n",
      "Train Epoch: 8 [4480/11862 (38%)]\tLoss: 0.058316\n",
      "Train Epoch: 8 [5120/11862 (43%)]\tLoss: 0.022051\n",
      "Train Epoch: 8 [5760/11862 (48%)]\tLoss: 0.042212\n",
      "Train Epoch: 8 [6400/11862 (54%)]\tLoss: 0.165279\n",
      "Train Epoch: 8 [7040/11862 (59%)]\tLoss: 0.016547\n",
      "Train Epoch: 8 [7680/11862 (65%)]\tLoss: 0.011421\n",
      "Train Epoch: 8 [8320/11862 (70%)]\tLoss: 0.036707\n",
      "Train Epoch: 8 [8960/11862 (75%)]\tLoss: 0.070214\n",
      "Train Epoch: 8 [9600/11862 (81%)]\tLoss: 0.009572\n",
      "Train Epoch: 8 [10240/11862 (86%)]\tLoss: 0.011888\n",
      "Train Epoch: 8 [10880/11862 (91%)]\tLoss: 0.002136\n",
      "Train Epoch: 8 [11520/11862 (97%)]\tLoss: 0.039977\n",
      "Train Epoch: 9 [0/11862 (0%)]\tLoss: 0.040403\n",
      "Train Epoch: 9 [640/11862 (5%)]\tLoss: 0.057605\n",
      "Train Epoch: 9 [1280/11862 (11%)]\tLoss: 0.022182\n",
      "Train Epoch: 9 [1920/11862 (16%)]\tLoss: 0.015883\n",
      "Train Epoch: 9 [2560/11862 (22%)]\tLoss: 0.043974\n",
      "Train Epoch: 9 [3200/11862 (27%)]\tLoss: 0.094240\n",
      "Train Epoch: 9 [3840/11862 (32%)]\tLoss: 0.101909\n",
      "Train Epoch: 9 [4480/11862 (38%)]\tLoss: 0.029016\n",
      "Train Epoch: 9 [5120/11862 (43%)]\tLoss: 0.035767\n",
      "Train Epoch: 9 [5760/11862 (48%)]\tLoss: 0.113009\n",
      "Train Epoch: 9 [6400/11862 (54%)]\tLoss: 0.039873\n",
      "Train Epoch: 9 [7040/11862 (59%)]\tLoss: 0.059325\n",
      "Train Epoch: 9 [7680/11862 (65%)]\tLoss: 0.029319\n",
      "Train Epoch: 9 [8320/11862 (70%)]\tLoss: 0.034818\n",
      "Train Epoch: 9 [8960/11862 (75%)]\tLoss: 0.028580\n",
      "Train Epoch: 9 [9600/11862 (81%)]\tLoss: 0.025972\n",
      "Train Epoch: 9 [10240/11862 (86%)]\tLoss: 0.193732\n",
      "Train Epoch: 9 [10880/11862 (91%)]\tLoss: 0.024326\n",
      "Train Epoch: 9 [11520/11862 (97%)]\tLoss: 0.072285\n",
      "Train Epoch: 10 [0/11862 (0%)]\tLoss: 0.004016\n",
      "Train Epoch: 10 [640/11862 (5%)]\tLoss: 0.000836\n",
      "Train Epoch: 10 [1280/11862 (11%)]\tLoss: 0.015936\n",
      "Train Epoch: 10 [1920/11862 (16%)]\tLoss: 0.010508\n",
      "Train Epoch: 10 [2560/11862 (22%)]\tLoss: 0.096948\n",
      "Train Epoch: 10 [3200/11862 (27%)]\tLoss: 0.069035\n",
      "Train Epoch: 10 [3840/11862 (32%)]\tLoss: 0.096463\n",
      "Train Epoch: 10 [4480/11862 (38%)]\tLoss: 0.013987\n",
      "Train Epoch: 10 [5120/11862 (43%)]\tLoss: 0.023381\n",
      "Train Epoch: 10 [5760/11862 (48%)]\tLoss: 0.019036\n",
      "Train Epoch: 10 [6400/11862 (54%)]\tLoss: 0.014540\n",
      "Train Epoch: 10 [7040/11862 (59%)]\tLoss: 0.096117\n",
      "Train Epoch: 10 [7680/11862 (65%)]\tLoss: 0.004095\n",
      "Train Epoch: 10 [8320/11862 (70%)]\tLoss: 0.068251\n",
      "Train Epoch: 10 [8960/11862 (75%)]\tLoss: 0.158572\n",
      "Train Epoch: 10 [9600/11862 (81%)]\tLoss: 0.095113\n",
      "Train Epoch: 10 [10240/11862 (86%)]\tLoss: 0.071663\n",
      "Train Epoch: 10 [10880/11862 (91%)]\tLoss: 0.002381\n",
      "Train Epoch: 10 [11520/11862 (97%)]\tLoss: 0.021106\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 0.035874\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 0.045838\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 0.077508\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 0.078150\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 0.021791\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 0.096577\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 0.049804\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 0.092625\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 0.033395\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 0.010423\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 0.016325\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 0.056537\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 0.057500\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 0.039188\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 0.024694\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 0.014670\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 0.031194\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.024827\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.145363\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.101864\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.023452\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.011213\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.036363\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.030430\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.037559\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.076447\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.050780\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.009672\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.035905\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.042335\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.049749\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.078434\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.020312\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.012249\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.025300\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.059224\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.037259\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.017497\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.097149\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.068483\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.027263\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.066986\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.091353\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.014341\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.028851\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.160412\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.006462\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.038662\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.004978\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.001117\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.177707\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.016843\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.016223\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.043533\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.011824\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.014626\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.006462\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.052671\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.060493\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.107798\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.033980\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.061854\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.019113\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.007425\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.005806\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.018671\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.111489\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.032899\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.059454\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.072478\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.063024\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.048599\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.022714\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.131272\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.008494\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.017327\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.164473\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.171413\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.120496\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.011434\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.050639\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.076725\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.072016\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.075658\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.077346\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.022872\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.009356\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.009016\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.002561\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.097384\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.010844\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.020346\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.143704\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.011284\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.134172\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.005166\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.031020\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.023265\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.008917\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.028131\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.067942\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.003176\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.030717\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.011869\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.013770\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.057216\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.006289\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.020257\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.035366\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.045020\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.036104\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.015198\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.041040\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.012895\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.044947\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.008794\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.011714\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.102966\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.013250\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.003770\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.015122\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.039624\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.004493\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.056987\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.008120\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.182538\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.067387\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.020941\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.070848\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.092978\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.032435\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.055972\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.047322\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.038318\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.016234\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.010679\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.019690\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.022299\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.005369\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.008231\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.012443\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.008268\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.090278\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.029851\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.135408\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.022277\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.057171\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.019270\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.005766\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.081036\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.032994\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.002579\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.021841\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.048625\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.113054\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.007407\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.030734\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.005255\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.077108\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.004724\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5509 (0%)]\tLoss: 0.263589\n",
      "Train Epoch: 1 [640/5509 (11%)]\tLoss: 0.419345\n",
      "Train Epoch: 1 [1280/5509 (23%)]\tLoss: 0.121774\n",
      "Train Epoch: 1 [1920/5509 (34%)]\tLoss: 0.086218\n",
      "Train Epoch: 1 [2560/5509 (46%)]\tLoss: 0.070469\n",
      "Train Epoch: 1 [3200/5509 (57%)]\tLoss: 0.061170\n",
      "Train Epoch: 1 [3840/5509 (69%)]\tLoss: 0.073294\n",
      "Train Epoch: 1 [4480/5509 (80%)]\tLoss: 0.055563\n",
      "Train Epoch: 1 [5120/5509 (92%)]\tLoss: 0.320341\n",
      "Train Epoch: 2 [0/5509 (0%)]\tLoss: 0.016416\n",
      "Train Epoch: 2 [640/5509 (11%)]\tLoss: 0.019882\n",
      "Train Epoch: 2 [1280/5509 (23%)]\tLoss: 0.025720\n",
      "Train Epoch: 2 [1920/5509 (34%)]\tLoss: 0.066464\n",
      "Train Epoch: 2 [2560/5509 (46%)]\tLoss: 0.044173\n",
      "Train Epoch: 2 [3200/5509 (57%)]\tLoss: 0.048640\n",
      "Train Epoch: 2 [3840/5509 (69%)]\tLoss: 0.202533\n",
      "Train Epoch: 2 [4480/5509 (80%)]\tLoss: 0.069889\n",
      "Train Epoch: 2 [5120/5509 (92%)]\tLoss: 0.017422\n",
      "Train Epoch: 3 [0/5509 (0%)]\tLoss: 0.059833\n",
      "Train Epoch: 3 [640/5509 (11%)]\tLoss: 0.012058\n",
      "Train Epoch: 3 [1280/5509 (23%)]\tLoss: 0.010308\n",
      "Train Epoch: 3 [1920/5509 (34%)]\tLoss: 0.077090\n",
      "Train Epoch: 3 [2560/5509 (46%)]\tLoss: 0.116599\n",
      "Train Epoch: 3 [3200/5509 (57%)]\tLoss: 0.042057\n",
      "Train Epoch: 3 [3840/5509 (69%)]\tLoss: 0.035607\n",
      "Train Epoch: 3 [4480/5509 (80%)]\tLoss: 0.015496\n",
      "Train Epoch: 3 [5120/5509 (92%)]\tLoss: 0.064335\n",
      "Train Epoch: 4 [0/5509 (0%)]\tLoss: 0.027239\n",
      "Train Epoch: 4 [640/5509 (11%)]\tLoss: 0.019743\n",
      "Train Epoch: 4 [1280/5509 (23%)]\tLoss: 0.058841\n",
      "Train Epoch: 4 [1920/5509 (34%)]\tLoss: 0.091101\n",
      "Train Epoch: 4 [2560/5509 (46%)]\tLoss: 0.072599\n",
      "Train Epoch: 4 [3200/5509 (57%)]\tLoss: 0.061429\n",
      "Train Epoch: 4 [3840/5509 (69%)]\tLoss: 0.068210\n",
      "Train Epoch: 4 [4480/5509 (80%)]\tLoss: 0.092838\n",
      "Train Epoch: 4 [5120/5509 (92%)]\tLoss: 0.050594\n",
      "Train Epoch: 5 [0/5509 (0%)]\tLoss: 0.012875\n",
      "Train Epoch: 5 [640/5509 (11%)]\tLoss: 0.117028\n",
      "Train Epoch: 5 [1280/5509 (23%)]\tLoss: 0.126539\n",
      "Train Epoch: 5 [1920/5509 (34%)]\tLoss: 0.020259\n",
      "Train Epoch: 5 [2560/5509 (46%)]\tLoss: 0.098269\n",
      "Train Epoch: 5 [3200/5509 (57%)]\tLoss: 0.101783\n",
      "Train Epoch: 5 [3840/5509 (69%)]\tLoss: 0.140766\n",
      "Train Epoch: 5 [4480/5509 (80%)]\tLoss: 0.061383\n",
      "Train Epoch: 5 [5120/5509 (92%)]\tLoss: 0.044654\n",
      "Train Epoch: 6 [0/5509 (0%)]\tLoss: 0.070273\n",
      "Train Epoch: 6 [640/5509 (11%)]\tLoss: 0.029465\n",
      "Train Epoch: 6 [1280/5509 (23%)]\tLoss: 0.204728\n",
      "Train Epoch: 6 [1920/5509 (34%)]\tLoss: 0.036667\n",
      "Train Epoch: 6 [2560/5509 (46%)]\tLoss: 0.033897\n",
      "Train Epoch: 6 [3200/5509 (57%)]\tLoss: 0.042093\n",
      "Train Epoch: 6 [3840/5509 (69%)]\tLoss: 0.046727\n",
      "Train Epoch: 6 [4480/5509 (80%)]\tLoss: 0.101893\n",
      "Train Epoch: 6 [5120/5509 (92%)]\tLoss: 0.071922\n",
      "Train Epoch: 7 [0/5509 (0%)]\tLoss: 0.033786\n",
      "Train Epoch: 7 [640/5509 (11%)]\tLoss: 0.047893\n",
      "Train Epoch: 7 [1280/5509 (23%)]\tLoss: 0.021042\n",
      "Train Epoch: 7 [1920/5509 (34%)]\tLoss: 0.183794\n",
      "Train Epoch: 7 [2560/5509 (46%)]\tLoss: 0.070770\n",
      "Train Epoch: 7 [3200/5509 (57%)]\tLoss: 0.017971\n",
      "Train Epoch: 7 [3840/5509 (69%)]\tLoss: 0.143034\n",
      "Train Epoch: 7 [4480/5509 (80%)]\tLoss: 0.079278\n",
      "Train Epoch: 7 [5120/5509 (92%)]\tLoss: 0.007748\n",
      "Train Epoch: 8 [0/5509 (0%)]\tLoss: 0.038187\n",
      "Train Epoch: 8 [640/5509 (11%)]\tLoss: 0.030348\n",
      "Train Epoch: 8 [1280/5509 (23%)]\tLoss: 0.111877\n",
      "Train Epoch: 8 [1920/5509 (34%)]\tLoss: 0.056682\n",
      "Train Epoch: 8 [2560/5509 (46%)]\tLoss: 0.103434\n",
      "Train Epoch: 8 [3200/5509 (57%)]\tLoss: 0.009009\n",
      "Train Epoch: 8 [3840/5509 (69%)]\tLoss: 0.023582\n",
      "Train Epoch: 8 [4480/5509 (80%)]\tLoss: 0.277611\n",
      "Train Epoch: 8 [5120/5509 (92%)]\tLoss: 0.054700\n",
      "Train Epoch: 9 [0/5509 (0%)]\tLoss: 0.049175\n",
      "Train Epoch: 9 [640/5509 (11%)]\tLoss: 0.052270\n",
      "Train Epoch: 9 [1280/5509 (23%)]\tLoss: 0.063000\n",
      "Train Epoch: 9 [1920/5509 (34%)]\tLoss: 0.047967\n",
      "Train Epoch: 9 [2560/5509 (46%)]\tLoss: 0.087878\n",
      "Train Epoch: 9 [3200/5509 (57%)]\tLoss: 0.005527\n",
      "Train Epoch: 9 [3840/5509 (69%)]\tLoss: 0.070612\n",
      "Train Epoch: 9 [4480/5509 (80%)]\tLoss: 0.010241\n",
      "Train Epoch: 9 [5120/5509 (92%)]\tLoss: 0.171005\n",
      "Train Epoch: 10 [0/5509 (0%)]\tLoss: 0.016066\n",
      "Train Epoch: 10 [640/5509 (11%)]\tLoss: 0.015395\n",
      "Train Epoch: 10 [1280/5509 (23%)]\tLoss: 0.014072\n",
      "Train Epoch: 10 [1920/5509 (34%)]\tLoss: 0.054732\n",
      "Train Epoch: 10 [2560/5509 (46%)]\tLoss: 0.045661\n",
      "Train Epoch: 10 [3200/5509 (57%)]\tLoss: 0.021240\n",
      "Train Epoch: 10 [3840/5509 (69%)]\tLoss: 0.029095\n",
      "Train Epoch: 10 [4480/5509 (80%)]\tLoss: 0.010761\n",
      "Train Epoch: 10 [5120/5509 (92%)]\tLoss: 0.028766\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 0.156273\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 0.049742\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 0.013295\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 0.034539\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 0.027451\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 0.017768\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 0.088559\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 0.006667\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 0.052180\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 0.047538\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.039313\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.023254\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 0.175371\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 0.009397\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 0.010648\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.012454\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.007017\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.411919\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.131055\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.010939\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.109955\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.006210\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.005359\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.004183\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.007627\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.010539\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.116741\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.023543\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.008018\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.017229\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.020987\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.004158\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.015772\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.006509\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.020368\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.117486\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.025320\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.003795\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.017574\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.009288\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.008471\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.019640\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.090219\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.008866\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.081418\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.029195\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.031932\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.003639\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.013225\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.017985\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.002302\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.058174\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.023618\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.006260\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.002898\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.009473\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.177741\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.012016\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.005644\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.117942\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.046884\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.025854\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.037746\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.042972\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.059233\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.001449\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.001755\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.002851\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.002597\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.001505\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.080874\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.084076\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.009096\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.013979\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.002930\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.012301\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.013708\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.002794\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.017936\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.019244\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.000811\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.008426\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.030894\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.012703\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.093519\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.052858\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.046675\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.012358\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.015017\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.089320\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.004865\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.002359\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.019119\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.001789\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.005029\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.021740\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.010679\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.065773\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.019091\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.008145\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.021795\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.025546\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.001474\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.139846\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.015600\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.027561\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.002897\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.012060\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.031690\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.081896\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.030765\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.006916\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.009500\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.007956\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.020521\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.039912\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.002744\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.010464\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.006355\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.010461\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.1462, Accuracy: 9878/10000 (99%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 0.078793\n",
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 0.021067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 0.071962\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 0.056075\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 0.045934\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 0.038349\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 0.006009\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 0.027952\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 0.048920\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 0.053895\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 0.045908\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 0.028416\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 0.033237\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 0.021984\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 0.018023\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 0.072257\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 0.046160\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 0.083182\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 0.019286\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 0.025472\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.018072\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 0.072708\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 0.174892\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.016495\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.022401\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 0.068222\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.031106\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 0.102100\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.011521\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.098588\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.037502\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.016550\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.037775\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.031956\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.252701\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.052482\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.009842\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.048748\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.089007\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.013582\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.114326\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.023261\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.044017\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.070955\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.006573\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.081335\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.189478\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.017908\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.025247\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.004325\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.096664\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.044090\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.009635\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.133257\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.036487\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.124606\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.210546\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.081274\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.021892\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.110201\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.040641\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.023089\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.048103\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.042197\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.037989\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.125779\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.020008\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.018673\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.057301\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.017712\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.055892\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.030103\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.064482\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.039295\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.043447\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.119290\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.097580\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.081227\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.037855\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.059612\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.066217\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.002432\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.016985\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.010570\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.016092\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.013714\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.017623\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.003542\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.016854\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.035951\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.071570\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.045669\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.011831\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.017503\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.009220\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.046574\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.120163\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.012627\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.009062\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.005991\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.028737\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.036499\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.042365\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.042848\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.096937\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.052335\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.032300\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.035157\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 0.052940\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.040567\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.097549\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.044350\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.022854\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.001595\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.034435\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.039989\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.067684\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.044730\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.109912\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.053438\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.011192\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.072521\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.005182\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.056921\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.005850\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.006770\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.006558\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.076880\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.037806\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.024673\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.056435\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.028354\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.050362\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.047546\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.099834\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.051447\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.008438\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.030402\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.140088\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.013483\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.008109\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.140635\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.009302\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.071474\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.013862\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.038946\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.030181\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.042210\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.156632\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.176367\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.089259\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.111408\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.057861\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.021848\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.042822\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.012875\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.021926\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.012296\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.038942\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.041261\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.114457\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.028365\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.002350\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.024645\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.012510\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.072893\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.061489\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.004131\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.076403\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.117782\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.003960\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.012603\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.062595\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.023059\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.038479\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.019575\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.067847\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.037968\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.181203\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.024211\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/5110 (0%)]\tLoss: 0.100683\n",
      "Train Epoch: 1 [640/5110 (12%)]\tLoss: 0.123227\n",
      "Train Epoch: 1 [1280/5110 (25%)]\tLoss: 0.014833\n",
      "Train Epoch: 1 [1920/5110 (38%)]\tLoss: 0.070303\n",
      "Train Epoch: 1 [2560/5110 (50%)]\tLoss: 0.056550\n",
      "Train Epoch: 1 [3200/5110 (62%)]\tLoss: 0.076417\n",
      "Train Epoch: 1 [3840/5110 (75%)]\tLoss: 0.102073\n",
      "Train Epoch: 1 [4480/5110 (88%)]\tLoss: 0.014709\n",
      "Train Epoch: 2 [0/5110 (0%)]\tLoss: 0.031382\n",
      "Train Epoch: 2 [640/5110 (12%)]\tLoss: 0.026436\n",
      "Train Epoch: 2 [1280/5110 (25%)]\tLoss: 0.007163\n",
      "Train Epoch: 2 [1920/5110 (38%)]\tLoss: 0.037212\n",
      "Train Epoch: 2 [2560/5110 (50%)]\tLoss: 0.001735\n",
      "Train Epoch: 2 [3200/5110 (62%)]\tLoss: 0.017768\n",
      "Train Epoch: 2 [3840/5110 (75%)]\tLoss: 0.019304\n",
      "Train Epoch: 2 [4480/5110 (88%)]\tLoss: 0.179227\n",
      "Train Epoch: 3 [0/5110 (0%)]\tLoss: 0.025927\n",
      "Train Epoch: 3 [640/5110 (12%)]\tLoss: 0.021546\n",
      "Train Epoch: 3 [1280/5110 (25%)]\tLoss: 0.110354\n",
      "Train Epoch: 3 [1920/5110 (38%)]\tLoss: 0.032649\n",
      "Train Epoch: 3 [2560/5110 (50%)]\tLoss: 0.132106\n",
      "Train Epoch: 3 [3200/5110 (62%)]\tLoss: 0.155319\n",
      "Train Epoch: 3 [3840/5110 (75%)]\tLoss: 0.026786\n",
      "Train Epoch: 3 [4480/5110 (88%)]\tLoss: 0.002768\n",
      "Train Epoch: 4 [0/5110 (0%)]\tLoss: 0.122882\n",
      "Train Epoch: 4 [640/5110 (12%)]\tLoss: 0.017377\n",
      "Train Epoch: 4 [1280/5110 (25%)]\tLoss: 0.046799\n",
      "Train Epoch: 4 [1920/5110 (38%)]\tLoss: 0.028186\n",
      "Train Epoch: 4 [2560/5110 (50%)]\tLoss: 0.033755\n",
      "Train Epoch: 4 [3200/5110 (62%)]\tLoss: 0.133032\n",
      "Train Epoch: 4 [3840/5110 (75%)]\tLoss: 0.116854\n",
      "Train Epoch: 4 [4480/5110 (88%)]\tLoss: 0.019648\n",
      "Train Epoch: 5 [0/5110 (0%)]\tLoss: 0.236084\n",
      "Train Epoch: 5 [640/5110 (12%)]\tLoss: 0.093309\n",
      "Train Epoch: 5 [1280/5110 (25%)]\tLoss: 0.005391\n",
      "Train Epoch: 5 [1920/5110 (38%)]\tLoss: 0.003066\n",
      "Train Epoch: 5 [2560/5110 (50%)]\tLoss: 0.016018\n",
      "Train Epoch: 5 [3200/5110 (62%)]\tLoss: 0.011605\n",
      "Train Epoch: 5 [3840/5110 (75%)]\tLoss: 0.070181\n",
      "Train Epoch: 5 [4480/5110 (88%)]\tLoss: 0.056717\n",
      "Train Epoch: 6 [0/5110 (0%)]\tLoss: 0.056289\n",
      "Train Epoch: 6 [640/5110 (12%)]\tLoss: 0.100783\n",
      "Train Epoch: 6 [1280/5110 (25%)]\tLoss: 0.098860\n",
      "Train Epoch: 6 [1920/5110 (38%)]\tLoss: 0.016399\n",
      "Train Epoch: 6 [2560/5110 (50%)]\tLoss: 0.034101\n",
      "Train Epoch: 6 [3200/5110 (62%)]\tLoss: 0.022351\n",
      "Train Epoch: 6 [3840/5110 (75%)]\tLoss: 0.108581\n",
      "Train Epoch: 6 [4480/5110 (88%)]\tLoss: 0.004022\n",
      "Train Epoch: 7 [0/5110 (0%)]\tLoss: 0.065075\n",
      "Train Epoch: 7 [640/5110 (12%)]\tLoss: 0.021919\n",
      "Train Epoch: 7 [1280/5110 (25%)]\tLoss: 0.066065\n",
      "Train Epoch: 7 [1920/5110 (38%)]\tLoss: 0.006504\n",
      "Train Epoch: 7 [2560/5110 (50%)]\tLoss: 0.020237\n",
      "Train Epoch: 7 [3200/5110 (62%)]\tLoss: 0.043960\n",
      "Train Epoch: 7 [3840/5110 (75%)]\tLoss: 0.023208\n",
      "Train Epoch: 7 [4480/5110 (88%)]\tLoss: 0.145889\n",
      "Train Epoch: 8 [0/5110 (0%)]\tLoss: 0.064737\n",
      "Train Epoch: 8 [640/5110 (12%)]\tLoss: 0.012383\n",
      "Train Epoch: 8 [1280/5110 (25%)]\tLoss: 0.016361\n",
      "Train Epoch: 8 [1920/5110 (38%)]\tLoss: 0.002384\n",
      "Train Epoch: 8 [2560/5110 (50%)]\tLoss: 0.009848\n",
      "Train Epoch: 8 [3200/5110 (62%)]\tLoss: 0.040558\n",
      "Train Epoch: 8 [3840/5110 (75%)]\tLoss: 0.037471\n",
      "Train Epoch: 8 [4480/5110 (88%)]\tLoss: 0.025409\n",
      "Train Epoch: 9 [0/5110 (0%)]\tLoss: 0.039224\n",
      "Train Epoch: 9 [640/5110 (12%)]\tLoss: 0.003247\n",
      "Train Epoch: 9 [1280/5110 (25%)]\tLoss: 0.003314\n",
      "Train Epoch: 9 [1920/5110 (38%)]\tLoss: 0.002731\n",
      "Train Epoch: 9 [2560/5110 (50%)]\tLoss: 0.042670\n",
      "Train Epoch: 9 [3200/5110 (62%)]\tLoss: 0.036306\n",
      "Train Epoch: 9 [3840/5110 (75%)]\tLoss: 0.005568\n",
      "Train Epoch: 9 [4480/5110 (88%)]\tLoss: 0.076855\n",
      "Train Epoch: 10 [0/5110 (0%)]\tLoss: 0.009069\n",
      "Train Epoch: 10 [640/5110 (12%)]\tLoss: 0.047369\n",
      "Train Epoch: 10 [1280/5110 (25%)]\tLoss: 0.022735\n",
      "Train Epoch: 10 [1920/5110 (38%)]\tLoss: 0.004144\n",
      "Train Epoch: 10 [2560/5110 (50%)]\tLoss: 0.052412\n",
      "Train Epoch: 10 [3200/5110 (62%)]\tLoss: 0.122232\n",
      "Train Epoch: 10 [3840/5110 (75%)]\tLoss: 0.010991\n",
      "Train Epoch: 10 [4480/5110 (88%)]\tLoss: 0.032745\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/10296 (0%)]\tLoss: 0.115944\n",
      "Train Epoch: 1 [640/10296 (6%)]\tLoss: 0.038543\n",
      "Train Epoch: 1 [1280/10296 (12%)]\tLoss: 0.008924\n",
      "Train Epoch: 1 [1920/10296 (19%)]\tLoss: 0.146403\n",
      "Train Epoch: 1 [2560/10296 (25%)]\tLoss: 0.083077\n",
      "Train Epoch: 1 [3200/10296 (31%)]\tLoss: 0.008155\n",
      "Train Epoch: 1 [3840/10296 (37%)]\tLoss: 0.045119\n",
      "Train Epoch: 1 [4480/10296 (43%)]\tLoss: 0.028243\n",
      "Train Epoch: 1 [5120/10296 (50%)]\tLoss: 0.040547\n",
      "Train Epoch: 1 [5760/10296 (56%)]\tLoss: 0.077739\n",
      "Train Epoch: 1 [6400/10296 (62%)]\tLoss: 0.106433\n",
      "Train Epoch: 1 [7040/10296 (68%)]\tLoss: 0.179080\n",
      "Train Epoch: 1 [7680/10296 (75%)]\tLoss: 0.092978\n",
      "Train Epoch: 1 [8320/10296 (81%)]\tLoss: 0.073726\n",
      "Train Epoch: 1 [8960/10296 (87%)]\tLoss: 0.087418\n",
      "Train Epoch: 1 [9600/10296 (93%)]\tLoss: 0.137536\n",
      "Train Epoch: 1 [8960/10296 (99%)]\tLoss: 0.108214\n",
      "Train Epoch: 2 [0/10296 (0%)]\tLoss: 0.007517\n",
      "Train Epoch: 2 [640/10296 (6%)]\tLoss: 0.018727\n",
      "Train Epoch: 2 [1280/10296 (12%)]\tLoss: 0.092002\n",
      "Train Epoch: 2 [1920/10296 (19%)]\tLoss: 0.016507\n",
      "Train Epoch: 2 [2560/10296 (25%)]\tLoss: 0.031359\n",
      "Train Epoch: 2 [3200/10296 (31%)]\tLoss: 0.035461\n",
      "Train Epoch: 2 [3840/10296 (37%)]\tLoss: 0.016730\n",
      "Train Epoch: 2 [4480/10296 (43%)]\tLoss: 0.122071\n",
      "Train Epoch: 2 [5120/10296 (50%)]\tLoss: 0.011658\n",
      "Train Epoch: 2 [5760/10296 (56%)]\tLoss: 0.011669\n",
      "Train Epoch: 2 [6400/10296 (62%)]\tLoss: 0.112788\n",
      "Train Epoch: 2 [7040/10296 (68%)]\tLoss: 0.032473\n",
      "Train Epoch: 2 [7680/10296 (75%)]\tLoss: 0.002169\n",
      "Train Epoch: 2 [8320/10296 (81%)]\tLoss: 0.043494\n",
      "Train Epoch: 2 [8960/10296 (87%)]\tLoss: 0.035210\n",
      "Train Epoch: 2 [9600/10296 (93%)]\tLoss: 0.069742\n",
      "Train Epoch: 2 [8960/10296 (99%)]\tLoss: 0.132149\n",
      "Train Epoch: 3 [0/10296 (0%)]\tLoss: 0.032648\n",
      "Train Epoch: 3 [640/10296 (6%)]\tLoss: 0.010976\n",
      "Train Epoch: 3 [1280/10296 (12%)]\tLoss: 0.104446\n",
      "Train Epoch: 3 [1920/10296 (19%)]\tLoss: 0.008363\n",
      "Train Epoch: 3 [2560/10296 (25%)]\tLoss: 0.011895\n",
      "Train Epoch: 3 [3200/10296 (31%)]\tLoss: 0.155959\n",
      "Train Epoch: 3 [3840/10296 (37%)]\tLoss: 0.059162\n",
      "Train Epoch: 3 [4480/10296 (43%)]\tLoss: 0.038803\n",
      "Train Epoch: 3 [5120/10296 (50%)]\tLoss: 0.012512\n",
      "Train Epoch: 3 [5760/10296 (56%)]\tLoss: 0.067643\n",
      "Train Epoch: 3 [6400/10296 (62%)]\tLoss: 0.145670\n",
      "Train Epoch: 3 [7040/10296 (68%)]\tLoss: 0.050287\n",
      "Train Epoch: 3 [7680/10296 (75%)]\tLoss: 0.009155\n",
      "Train Epoch: 3 [8320/10296 (81%)]\tLoss: 0.021017\n",
      "Train Epoch: 3 [8960/10296 (87%)]\tLoss: 0.010079\n",
      "Train Epoch: 3 [9600/10296 (93%)]\tLoss: 0.183789\n",
      "Train Epoch: 3 [8960/10296 (99%)]\tLoss: 0.044592\n",
      "Train Epoch: 4 [0/10296 (0%)]\tLoss: 0.068564\n",
      "Train Epoch: 4 [640/10296 (6%)]\tLoss: 0.044343\n",
      "Train Epoch: 4 [1280/10296 (12%)]\tLoss: 0.019901\n",
      "Train Epoch: 4 [1920/10296 (19%)]\tLoss: 0.021697\n",
      "Train Epoch: 4 [2560/10296 (25%)]\tLoss: 0.021350\n",
      "Train Epoch: 4 [3200/10296 (31%)]\tLoss: 0.012467\n",
      "Train Epoch: 4 [3840/10296 (37%)]\tLoss: 0.035616\n",
      "Train Epoch: 4 [4480/10296 (43%)]\tLoss: 0.040020\n",
      "Train Epoch: 4 [5120/10296 (50%)]\tLoss: 0.051102\n",
      "Train Epoch: 4 [5760/10296 (56%)]\tLoss: 0.106880\n",
      "Train Epoch: 4 [6400/10296 (62%)]\tLoss: 0.018908\n",
      "Train Epoch: 4 [7040/10296 (68%)]\tLoss: 0.020087\n",
      "Train Epoch: 4 [7680/10296 (75%)]\tLoss: 0.014188\n",
      "Train Epoch: 4 [8320/10296 (81%)]\tLoss: 0.125525\n",
      "Train Epoch: 4 [8960/10296 (87%)]\tLoss: 0.084402\n",
      "Train Epoch: 4 [9600/10296 (93%)]\tLoss: 0.045678\n",
      "Train Epoch: 4 [8960/10296 (99%)]\tLoss: 0.086834\n",
      "Train Epoch: 5 [0/10296 (0%)]\tLoss: 0.031219\n",
      "Train Epoch: 5 [640/10296 (6%)]\tLoss: 0.097430\n",
      "Train Epoch: 5 [1280/10296 (12%)]\tLoss: 0.007538\n",
      "Train Epoch: 5 [1920/10296 (19%)]\tLoss: 0.053487\n",
      "Train Epoch: 5 [2560/10296 (25%)]\tLoss: 0.005946\n",
      "Train Epoch: 5 [3200/10296 (31%)]\tLoss: 0.080240\n",
      "Train Epoch: 5 [3840/10296 (37%)]\tLoss: 0.108861\n",
      "Train Epoch: 5 [4480/10296 (43%)]\tLoss: 0.038744\n",
      "Train Epoch: 5 [5120/10296 (50%)]\tLoss: 0.024629\n",
      "Train Epoch: 5 [5760/10296 (56%)]\tLoss: 0.040177\n",
      "Train Epoch: 5 [6400/10296 (62%)]\tLoss: 0.004927\n",
      "Train Epoch: 5 [7040/10296 (68%)]\tLoss: 0.037892\n",
      "Train Epoch: 5 [7680/10296 (75%)]\tLoss: 0.262155\n",
      "Train Epoch: 5 [8320/10296 (81%)]\tLoss: 0.068896\n",
      "Train Epoch: 5 [8960/10296 (87%)]\tLoss: 0.069316\n",
      "Train Epoch: 5 [9600/10296 (93%)]\tLoss: 0.005668\n",
      "Train Epoch: 5 [8960/10296 (99%)]\tLoss: 0.008905\n",
      "Train Epoch: 6 [0/10296 (0%)]\tLoss: 0.047299\n",
      "Train Epoch: 6 [640/10296 (6%)]\tLoss: 0.126363\n",
      "Train Epoch: 6 [1280/10296 (12%)]\tLoss: 0.019180\n",
      "Train Epoch: 6 [1920/10296 (19%)]\tLoss: 0.030044\n",
      "Train Epoch: 6 [2560/10296 (25%)]\tLoss: 0.069182\n",
      "Train Epoch: 6 [3200/10296 (31%)]\tLoss: 0.006384\n",
      "Train Epoch: 6 [3840/10296 (37%)]\tLoss: 0.061993\n",
      "Train Epoch: 6 [4480/10296 (43%)]\tLoss: 0.019646\n",
      "Train Epoch: 6 [5120/10296 (50%)]\tLoss: 0.006660\n",
      "Train Epoch: 6 [5760/10296 (56%)]\tLoss: 0.031239\n",
      "Train Epoch: 6 [6400/10296 (62%)]\tLoss: 0.075871\n",
      "Train Epoch: 6 [7040/10296 (68%)]\tLoss: 0.021223\n",
      "Train Epoch: 6 [7680/10296 (75%)]\tLoss: 0.062454\n",
      "Train Epoch: 6 [8320/10296 (81%)]\tLoss: 0.101858\n",
      "Train Epoch: 6 [8960/10296 (87%)]\tLoss: 0.079000\n",
      "Train Epoch: 6 [9600/10296 (93%)]\tLoss: 0.008130\n",
      "Train Epoch: 6 [8960/10296 (99%)]\tLoss: 0.066351\n",
      "Train Epoch: 7 [0/10296 (0%)]\tLoss: 0.071564\n",
      "Train Epoch: 7 [640/10296 (6%)]\tLoss: 0.037990\n",
      "Train Epoch: 7 [1280/10296 (12%)]\tLoss: 0.008367\n",
      "Train Epoch: 7 [1920/10296 (19%)]\tLoss: 0.057820\n",
      "Train Epoch: 7 [2560/10296 (25%)]\tLoss: 0.015831\n",
      "Train Epoch: 7 [3200/10296 (31%)]\tLoss: 0.050997\n",
      "Train Epoch: 7 [3840/10296 (37%)]\tLoss: 0.040128\n",
      "Train Epoch: 7 [4480/10296 (43%)]\tLoss: 0.142533\n",
      "Train Epoch: 7 [5120/10296 (50%)]\tLoss: 0.007354\n",
      "Train Epoch: 7 [5760/10296 (56%)]\tLoss: 0.025657\n",
      "Train Epoch: 7 [6400/10296 (62%)]\tLoss: 0.014755\n",
      "Train Epoch: 7 [7040/10296 (68%)]\tLoss: 0.021865\n",
      "Train Epoch: 7 [7680/10296 (75%)]\tLoss: 0.026357\n",
      "Train Epoch: 7 [8320/10296 (81%)]\tLoss: 0.036246\n",
      "Train Epoch: 7 [8960/10296 (87%)]\tLoss: 0.070555\n",
      "Train Epoch: 7 [9600/10296 (93%)]\tLoss: 0.014215\n",
      "Train Epoch: 7 [8960/10296 (99%)]\tLoss: 0.124256\n",
      "Train Epoch: 8 [0/10296 (0%)]\tLoss: 0.038021\n",
      "Train Epoch: 8 [640/10296 (6%)]\tLoss: 0.062176\n",
      "Train Epoch: 8 [1280/10296 (12%)]\tLoss: 0.006523\n",
      "Train Epoch: 8 [1920/10296 (19%)]\tLoss: 0.054946\n",
      "Train Epoch: 8 [2560/10296 (25%)]\tLoss: 0.009164\n",
      "Train Epoch: 8 [3200/10296 (31%)]\tLoss: 0.050696\n",
      "Train Epoch: 8 [3840/10296 (37%)]\tLoss: 0.100056\n",
      "Train Epoch: 8 [4480/10296 (43%)]\tLoss: 0.044862\n",
      "Train Epoch: 8 [5120/10296 (50%)]\tLoss: 0.014320\n",
      "Train Epoch: 8 [5760/10296 (56%)]\tLoss: 0.032237\n",
      "Train Epoch: 8 [6400/10296 (62%)]\tLoss: 0.092964\n",
      "Train Epoch: 8 [7040/10296 (68%)]\tLoss: 0.104062\n",
      "Train Epoch: 8 [7680/10296 (75%)]\tLoss: 0.035906\n",
      "Train Epoch: 8 [8320/10296 (81%)]\tLoss: 0.041548\n",
      "Train Epoch: 8 [8960/10296 (87%)]\tLoss: 0.051229\n",
      "Train Epoch: 8 [9600/10296 (93%)]\tLoss: 0.044925\n",
      "Train Epoch: 8 [8960/10296 (99%)]\tLoss: 0.075869\n",
      "Train Epoch: 9 [0/10296 (0%)]\tLoss: 0.078698\n",
      "Train Epoch: 9 [640/10296 (6%)]\tLoss: 0.039721\n",
      "Train Epoch: 9 [1280/10296 (12%)]\tLoss: 0.047692\n",
      "Train Epoch: 9 [1920/10296 (19%)]\tLoss: 0.009407\n",
      "Train Epoch: 9 [2560/10296 (25%)]\tLoss: 0.060340\n",
      "Train Epoch: 9 [3200/10296 (31%)]\tLoss: 0.044501\n",
      "Train Epoch: 9 [3840/10296 (37%)]\tLoss: 0.053408\n",
      "Train Epoch: 9 [4480/10296 (43%)]\tLoss: 0.094247\n",
      "Train Epoch: 9 [5120/10296 (50%)]\tLoss: 0.047670\n",
      "Train Epoch: 9 [5760/10296 (56%)]\tLoss: 0.035766\n",
      "Train Epoch: 9 [6400/10296 (62%)]\tLoss: 0.055715\n",
      "Train Epoch: 9 [7040/10296 (68%)]\tLoss: 0.114865\n",
      "Train Epoch: 9 [7680/10296 (75%)]\tLoss: 0.011769\n",
      "Train Epoch: 9 [8320/10296 (81%)]\tLoss: 0.160697\n",
      "Train Epoch: 9 [8960/10296 (87%)]\tLoss: 0.019675\n",
      "Train Epoch: 9 [9600/10296 (93%)]\tLoss: 0.017477\n",
      "Train Epoch: 9 [8960/10296 (99%)]\tLoss: 0.005504\n",
      "Train Epoch: 10 [0/10296 (0%)]\tLoss: 0.126128\n",
      "Train Epoch: 10 [640/10296 (6%)]\tLoss: 0.031925\n",
      "Train Epoch: 10 [1280/10296 (12%)]\tLoss: 0.091967\n",
      "Train Epoch: 10 [1920/10296 (19%)]\tLoss: 0.083413\n",
      "Train Epoch: 10 [2560/10296 (25%)]\tLoss: 0.033036\n",
      "Train Epoch: 10 [3200/10296 (31%)]\tLoss: 0.030096\n",
      "Train Epoch: 10 [3840/10296 (37%)]\tLoss: 0.054811\n",
      "Train Epoch: 10 [4480/10296 (43%)]\tLoss: 0.011309\n",
      "Train Epoch: 10 [5120/10296 (50%)]\tLoss: 0.023916\n",
      "Train Epoch: 10 [5760/10296 (56%)]\tLoss: 0.018866\n",
      "Train Epoch: 10 [6400/10296 (62%)]\tLoss: 0.091987\n",
      "Train Epoch: 10 [7040/10296 (68%)]\tLoss: 0.033467\n",
      "Train Epoch: 10 [7680/10296 (75%)]\tLoss: 0.030071\n",
      "Train Epoch: 10 [8320/10296 (81%)]\tLoss: 0.015100\n",
      "Train Epoch: 10 [8960/10296 (87%)]\tLoss: 0.087490\n",
      "Train Epoch: 10 [9600/10296 (93%)]\tLoss: 0.071619\n",
      "Train Epoch: 10 [8960/10296 (99%)]\tLoss: 0.025626\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 0.069329\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 0.040261\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 0.018503\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 0.090983\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 0.030256\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 0.043216\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 0.078694\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 0.021938\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 0.037554\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 0.052120\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 0.054569\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 0.018191\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 0.074336\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 0.017411\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 0.013693\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 0.075773\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 0.050949\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.036322\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.010077\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.101455\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.024239\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.005896\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.049656\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.022295\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.125232\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.070108\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.084672\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.072755\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.017802\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.032110\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.012097\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.042851\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.223950\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.005062\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.057716\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.007499\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.050663\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.008697\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.045757\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.059017\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.004964\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.045797\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.028932\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.049905\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.058457\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.015034\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.015313\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.056354\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.182643\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.025229\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.031697\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.024130\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.037007\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.069603\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.012390\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.036134\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.043325\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.128989\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.007218\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.058764\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.016067\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.005560\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.012110\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.025571\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.146038\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.089791\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.015841\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.012478\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.033408\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.004199\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.089658\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.006443\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.007707\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.042282\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.086074\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.034429\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.064817\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.012545\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.013011\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.046526\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.036159\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.042825\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.190822\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.017692\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.049799\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.030793\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.023878\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.096506\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.054123\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.041961\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.090304\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.007062\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.027809\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.120719\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.035081\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.001959\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.044539\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.011953\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.020453\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.012007\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.021056\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.016208\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.042796\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.007647\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.022236\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.041770\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.002550\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.017602\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.055099\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.017741\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.007694\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.018362\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.018282\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.105287\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.001850\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.063291\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.046764\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.006275\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.002891\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.029071\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.088883\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.021859\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.039469\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.056894\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.039835\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.005500\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.145939\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.049021\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.061144\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.107703\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.034477\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.023537\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.024433\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.046793\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.009417\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.050137\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.025115\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.020515\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.002147\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.015375\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.035425\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.014388\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.031085\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.070376\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.046087\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.024720\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.053192\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.115742\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.065821\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.053347\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.013613\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.002326\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.034955\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.015046\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.004912\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.038693\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.056595\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.037166\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.030997\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.023589\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/3910 (0%)]\tLoss: 0.137067\n",
      "Train Epoch: 1 [640/3910 (16%)]\tLoss: 0.048015\n",
      "Train Epoch: 1 [1280/3910 (32%)]\tLoss: 0.020781\n",
      "Train Epoch: 1 [1920/3910 (48%)]\tLoss: 0.007067\n",
      "Train Epoch: 1 [2560/3910 (65%)]\tLoss: 0.019819\n",
      "Train Epoch: 1 [3200/3910 (81%)]\tLoss: 0.017157\n",
      "Train Epoch: 1 [3840/3910 (97%)]\tLoss: 0.014401\n",
      "Train Epoch: 2 [0/3910 (0%)]\tLoss: 0.100157\n",
      "Train Epoch: 2 [640/3910 (16%)]\tLoss: 0.063873\n",
      "Train Epoch: 2 [1280/3910 (32%)]\tLoss: 0.280434\n",
      "Train Epoch: 2 [1920/3910 (48%)]\tLoss: 0.034800\n",
      "Train Epoch: 2 [2560/3910 (65%)]\tLoss: 0.087559\n",
      "Train Epoch: 2 [3200/3910 (81%)]\tLoss: 0.074973\n",
      "Train Epoch: 2 [3840/3910 (97%)]\tLoss: 0.051771\n",
      "Train Epoch: 3 [0/3910 (0%)]\tLoss: 0.004377\n",
      "Train Epoch: 3 [640/3910 (16%)]\tLoss: 0.119556\n",
      "Train Epoch: 3 [1280/3910 (32%)]\tLoss: 0.037840\n",
      "Train Epoch: 3 [1920/3910 (48%)]\tLoss: 0.244184\n",
      "Train Epoch: 3 [2560/3910 (65%)]\tLoss: 0.051173\n",
      "Train Epoch: 3 [3200/3910 (81%)]\tLoss: 0.019063\n",
      "Train Epoch: 3 [3840/3910 (97%)]\tLoss: 0.260810\n",
      "Train Epoch: 4 [0/3910 (0%)]\tLoss: 0.009269\n",
      "Train Epoch: 4 [640/3910 (16%)]\tLoss: 0.026895\n",
      "Train Epoch: 4 [1280/3910 (32%)]\tLoss: 0.211632\n",
      "Train Epoch: 4 [1920/3910 (48%)]\tLoss: 0.009897\n",
      "Train Epoch: 4 [2560/3910 (65%)]\tLoss: 0.110944\n",
      "Train Epoch: 4 [3200/3910 (81%)]\tLoss: 0.013961\n",
      "Train Epoch: 4 [3840/3910 (97%)]\tLoss: 0.043621\n",
      "Train Epoch: 5 [0/3910 (0%)]\tLoss: 0.032517\n",
      "Train Epoch: 5 [640/3910 (16%)]\tLoss: 0.109863\n",
      "Train Epoch: 5 [1280/3910 (32%)]\tLoss: 0.028254\n",
      "Train Epoch: 5 [1920/3910 (48%)]\tLoss: 0.029054\n",
      "Train Epoch: 5 [2560/3910 (65%)]\tLoss: 0.104338\n",
      "Train Epoch: 5 [3200/3910 (81%)]\tLoss: 0.027010\n",
      "Train Epoch: 5 [3840/3910 (97%)]\tLoss: 0.078151\n",
      "Train Epoch: 6 [0/3910 (0%)]\tLoss: 0.096288\n",
      "Train Epoch: 6 [640/3910 (16%)]\tLoss: 0.015349\n",
      "Train Epoch: 6 [1280/3910 (32%)]\tLoss: 0.019851\n",
      "Train Epoch: 6 [1920/3910 (48%)]\tLoss: 0.033764\n",
      "Train Epoch: 6 [2560/3910 (65%)]\tLoss: 0.130246\n",
      "Train Epoch: 6 [3200/3910 (81%)]\tLoss: 0.095349\n",
      "Train Epoch: 6 [3840/3910 (97%)]\tLoss: 0.017878\n",
      "Train Epoch: 7 [0/3910 (0%)]\tLoss: 0.024804\n",
      "Train Epoch: 7 [640/3910 (16%)]\tLoss: 0.017497\n",
      "Train Epoch: 7 [1280/3910 (32%)]\tLoss: 0.015663\n",
      "Train Epoch: 7 [1920/3910 (48%)]\tLoss: 0.026822\n",
      "Train Epoch: 7 [2560/3910 (65%)]\tLoss: 0.013440\n",
      "Train Epoch: 7 [3200/3910 (81%)]\tLoss: 0.092152\n",
      "Train Epoch: 7 [3840/3910 (97%)]\tLoss: 0.040815\n",
      "Train Epoch: 8 [0/3910 (0%)]\tLoss: 0.047114\n",
      "Train Epoch: 8 [640/3910 (16%)]\tLoss: 0.065878\n",
      "Train Epoch: 8 [1280/3910 (32%)]\tLoss: 0.058325\n",
      "Train Epoch: 8 [1920/3910 (48%)]\tLoss: 0.102478\n",
      "Train Epoch: 8 [2560/3910 (65%)]\tLoss: 0.047297\n",
      "Train Epoch: 8 [3200/3910 (81%)]\tLoss: 0.046423\n",
      "Train Epoch: 8 [3840/3910 (97%)]\tLoss: 0.088133\n",
      "Train Epoch: 9 [0/3910 (0%)]\tLoss: 0.044839\n",
      "Train Epoch: 9 [640/3910 (16%)]\tLoss: 0.057739\n",
      "Train Epoch: 9 [1280/3910 (32%)]\tLoss: 0.020876\n",
      "Train Epoch: 9 [1920/3910 (48%)]\tLoss: 0.026694\n",
      "Train Epoch: 9 [2560/3910 (65%)]\tLoss: 0.047179\n",
      "Train Epoch: 9 [3200/3910 (81%)]\tLoss: 0.093003\n",
      "Train Epoch: 9 [3840/3910 (97%)]\tLoss: 0.012165\n",
      "Train Epoch: 10 [0/3910 (0%)]\tLoss: 0.001686\n",
      "Train Epoch: 10 [640/3910 (16%)]\tLoss: 0.067219\n",
      "Train Epoch: 10 [1280/3910 (32%)]\tLoss: 0.080699\n",
      "Train Epoch: 10 [1920/3910 (48%)]\tLoss: 0.114138\n",
      "Train Epoch: 10 [2560/3910 (65%)]\tLoss: 0.007677\n",
      "Train Epoch: 10 [3200/3910 (81%)]\tLoss: 0.095319\n",
      "Train Epoch: 10 [3840/3910 (97%)]\tLoss: 0.063997\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 0.104342\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 0.039232\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 0.071840\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 0.017861\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 0.063995\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 0.011714\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 0.055968\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 0.172476\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 0.116549\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 0.053185\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.083944\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.049030\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 0.017217\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 0.020174\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 0.002184\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.007428\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.113852\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.007514\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.029116\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.048675\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.116466\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.047928\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.008209\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.005116\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.003277\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.020567\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.059907\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.044956\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.062288\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.001319\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.006911\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.026066\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.004688\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.027879\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.001553\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.007122\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.030553\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.117561\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.011182\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.001926\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.045804\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.026086\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.069630\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.005914\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.000833\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.006633\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.007500\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.014902\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.020313\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.007527\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.004056\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.019856\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.006273\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.023038\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.063662\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.031775\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.006519\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.073007\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.091908\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.130890\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.102178\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.033042\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.029412\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.022052\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.006223\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.014021\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.015152\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.052867\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.017808\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.001754\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.051151\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.001502\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.015432\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.009746\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.013912\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.015852\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.001806\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.009031\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.028963\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.002181\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.053521\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.058954\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.042891\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.003742\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.089822\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.003588\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.011556\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.027299\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.034253\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.018838\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.011816\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.130888\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.096615\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.016440\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.147709\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.037224\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.015323\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.032314\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.053849\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.107887\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.001531\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.053887\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.003796\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.032216\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.016199\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.036684\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.011389\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.002150\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.013664\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.011259\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.000893\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.020782\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.007429\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.018162\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.001448\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.044311\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.053567\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.035522\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.001862\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.006560\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/5096 (0%)]\tLoss: 0.196879\n",
      "Train Epoch: 1 [640/5096 (12%)]\tLoss: 0.042223\n",
      "Train Epoch: 1 [1280/5096 (25%)]\tLoss: 0.036073\n",
      "Train Epoch: 1 [1920/5096 (38%)]\tLoss: 0.082653\n",
      "Train Epoch: 1 [2560/5096 (50%)]\tLoss: 0.024984\n",
      "Train Epoch: 1 [3200/5096 (62%)]\tLoss: 0.050870\n",
      "Train Epoch: 1 [3840/5096 (75%)]\tLoss: 0.008411\n",
      "Train Epoch: 1 [4480/5096 (88%)]\tLoss: 0.022933\n",
      "Train Epoch: 2 [0/5096 (0%)]\tLoss: 0.069538\n",
      "Train Epoch: 2 [640/5096 (12%)]\tLoss: 0.058657\n",
      "Train Epoch: 2 [1280/5096 (25%)]\tLoss: 0.009756\n",
      "Train Epoch: 2 [1920/5096 (38%)]\tLoss: 0.085321\n",
      "Train Epoch: 2 [2560/5096 (50%)]\tLoss: 0.005342\n",
      "Train Epoch: 2 [3200/5096 (62%)]\tLoss: 0.003750\n",
      "Train Epoch: 2 [3840/5096 (75%)]\tLoss: 0.009239\n",
      "Train Epoch: 2 [4480/5096 (88%)]\tLoss: 0.075021\n",
      "Train Epoch: 3 [0/5096 (0%)]\tLoss: 0.010564\n",
      "Train Epoch: 3 [640/5096 (12%)]\tLoss: 0.003464\n",
      "Train Epoch: 3 [1280/5096 (25%)]\tLoss: 0.001171\n",
      "Train Epoch: 3 [1920/5096 (38%)]\tLoss: 0.003219\n",
      "Train Epoch: 3 [2560/5096 (50%)]\tLoss: 0.016290\n",
      "Train Epoch: 3 [3200/5096 (62%)]\tLoss: 0.022747\n",
      "Train Epoch: 3 [3840/5096 (75%)]\tLoss: 0.041277\n",
      "Train Epoch: 3 [4480/5096 (88%)]\tLoss: 0.035715\n",
      "Train Epoch: 4 [0/5096 (0%)]\tLoss: 0.031118\n",
      "Train Epoch: 4 [640/5096 (12%)]\tLoss: 0.025728\n",
      "Train Epoch: 4 [1280/5096 (25%)]\tLoss: 0.010179\n",
      "Train Epoch: 4 [1920/5096 (38%)]\tLoss: 0.030632\n",
      "Train Epoch: 4 [2560/5096 (50%)]\tLoss: 0.006106\n",
      "Train Epoch: 4 [3200/5096 (62%)]\tLoss: 0.061699\n",
      "Train Epoch: 4 [3840/5096 (75%)]\tLoss: 0.139825\n",
      "Train Epoch: 4 [4480/5096 (88%)]\tLoss: 0.004771\n",
      "Train Epoch: 5 [0/5096 (0%)]\tLoss: 0.017612\n",
      "Train Epoch: 5 [640/5096 (12%)]\tLoss: 0.102953\n",
      "Train Epoch: 5 [1280/5096 (25%)]\tLoss: 0.016906\n",
      "Train Epoch: 5 [1920/5096 (38%)]\tLoss: 0.050025\n",
      "Train Epoch: 5 [2560/5096 (50%)]\tLoss: 0.001602\n",
      "Train Epoch: 5 [3200/5096 (62%)]\tLoss: 0.048661\n",
      "Train Epoch: 5 [3840/5096 (75%)]\tLoss: 0.019380\n",
      "Train Epoch: 5 [4480/5096 (88%)]\tLoss: 0.038875\n",
      "Train Epoch: 6 [0/5096 (0%)]\tLoss: 0.042331\n",
      "Train Epoch: 6 [640/5096 (12%)]\tLoss: 0.011549\n",
      "Train Epoch: 6 [1280/5096 (25%)]\tLoss: 0.033556\n",
      "Train Epoch: 6 [1920/5096 (38%)]\tLoss: 0.047012\n",
      "Train Epoch: 6 [2560/5096 (50%)]\tLoss: 0.015058\n",
      "Train Epoch: 6 [3200/5096 (62%)]\tLoss: 0.068853\n",
      "Train Epoch: 6 [3840/5096 (75%)]\tLoss: 0.001615\n",
      "Train Epoch: 6 [4480/5096 (88%)]\tLoss: 0.005458\n",
      "Train Epoch: 7 [0/5096 (0%)]\tLoss: 0.004249\n",
      "Train Epoch: 7 [640/5096 (12%)]\tLoss: 0.002113\n",
      "Train Epoch: 7 [1280/5096 (25%)]\tLoss: 0.001487\n",
      "Train Epoch: 7 [1920/5096 (38%)]\tLoss: 0.020670\n",
      "Train Epoch: 7 [2560/5096 (50%)]\tLoss: 0.006281\n",
      "Train Epoch: 7 [3200/5096 (62%)]\tLoss: 0.014256\n",
      "Train Epoch: 7 [3840/5096 (75%)]\tLoss: 0.024128\n",
      "Train Epoch: 7 [4480/5096 (88%)]\tLoss: 0.059985\n",
      "Train Epoch: 8 [0/5096 (0%)]\tLoss: 0.099991\n",
      "Train Epoch: 8 [640/5096 (12%)]\tLoss: 0.013528\n",
      "Train Epoch: 8 [1280/5096 (25%)]\tLoss: 0.027637\n",
      "Train Epoch: 8 [1920/5096 (38%)]\tLoss: 0.027593\n",
      "Train Epoch: 8 [2560/5096 (50%)]\tLoss: 0.003161\n",
      "Train Epoch: 8 [3200/5096 (62%)]\tLoss: 0.010785\n",
      "Train Epoch: 8 [3840/5096 (75%)]\tLoss: 0.013353\n",
      "Train Epoch: 8 [4480/5096 (88%)]\tLoss: 0.007064\n",
      "Train Epoch: 9 [0/5096 (0%)]\tLoss: 0.055839\n",
      "Train Epoch: 9 [640/5096 (12%)]\tLoss: 0.183783\n",
      "Train Epoch: 9 [1280/5096 (25%)]\tLoss: 0.021757\n",
      "Train Epoch: 9 [1920/5096 (38%)]\tLoss: 0.044668\n",
      "Train Epoch: 9 [2560/5096 (50%)]\tLoss: 0.006243\n",
      "Train Epoch: 9 [3200/5096 (62%)]\tLoss: 0.000369\n",
      "Train Epoch: 9 [3840/5096 (75%)]\tLoss: 0.009288\n",
      "Train Epoch: 9 [4480/5096 (88%)]\tLoss: 0.009395\n",
      "Train Epoch: 10 [0/5096 (0%)]\tLoss: 0.027679\n",
      "Train Epoch: 10 [640/5096 (12%)]\tLoss: 0.010034\n",
      "Train Epoch: 10 [1280/5096 (25%)]\tLoss: 0.001396\n",
      "Train Epoch: 10 [1920/5096 (38%)]\tLoss: 0.049628\n",
      "Train Epoch: 10 [2560/5096 (50%)]\tLoss: 0.046452\n",
      "Train Epoch: 10 [3200/5096 (62%)]\tLoss: 0.020098\n",
      "Train Epoch: 10 [3840/5096 (75%)]\tLoss: 0.006327\n",
      "Train Epoch: 10 [4480/5096 (88%)]\tLoss: 0.013174\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6865 (0%)]\tLoss: 0.159077\n",
      "Train Epoch: 1 [640/6865 (9%)]\tLoss: 0.022144\n",
      "Train Epoch: 1 [1280/6865 (19%)]\tLoss: 0.050505\n",
      "Train Epoch: 1 [1920/6865 (28%)]\tLoss: 0.030284\n",
      "Train Epoch: 1 [2560/6865 (37%)]\tLoss: 0.117100\n",
      "Train Epoch: 1 [3200/6865 (46%)]\tLoss: 0.039702\n",
      "Train Epoch: 1 [3840/6865 (56%)]\tLoss: 0.037889\n",
      "Train Epoch: 1 [4480/6865 (65%)]\tLoss: 0.009780\n",
      "Train Epoch: 1 [5120/6865 (74%)]\tLoss: 0.013227\n",
      "Train Epoch: 1 [5760/6865 (83%)]\tLoss: 0.054894\n",
      "Train Epoch: 1 [6400/6865 (93%)]\tLoss: 0.017152\n",
      "Train Epoch: 2 [0/6865 (0%)]\tLoss: 0.122599\n",
      "Train Epoch: 2 [640/6865 (9%)]\tLoss: 0.108872\n",
      "Train Epoch: 2 [1280/6865 (19%)]\tLoss: 0.074276\n",
      "Train Epoch: 2 [1920/6865 (28%)]\tLoss: 0.021984\n",
      "Train Epoch: 2 [2560/6865 (37%)]\tLoss: 0.006364\n",
      "Train Epoch: 2 [3200/6865 (46%)]\tLoss: 0.057066\n",
      "Train Epoch: 2 [3840/6865 (56%)]\tLoss: 0.012571\n",
      "Train Epoch: 2 [4480/6865 (65%)]\tLoss: 0.000414\n",
      "Train Epoch: 2 [5120/6865 (74%)]\tLoss: 0.023992\n",
      "Train Epoch: 2 [5760/6865 (83%)]\tLoss: 0.002736\n",
      "Train Epoch: 2 [6400/6865 (93%)]\tLoss: 0.032306\n",
      "Train Epoch: 3 [0/6865 (0%)]\tLoss: 0.012522\n",
      "Train Epoch: 3 [640/6865 (9%)]\tLoss: 0.010186\n",
      "Train Epoch: 3 [1280/6865 (19%)]\tLoss: 0.021802\n",
      "Train Epoch: 3 [1920/6865 (28%)]\tLoss: 0.101444\n",
      "Train Epoch: 3 [2560/6865 (37%)]\tLoss: 0.075580\n",
      "Train Epoch: 3 [3200/6865 (46%)]\tLoss: 0.055179\n",
      "Train Epoch: 3 [3840/6865 (56%)]\tLoss: 0.032241\n",
      "Train Epoch: 3 [4480/6865 (65%)]\tLoss: 0.023787\n",
      "Train Epoch: 3 [5120/6865 (74%)]\tLoss: 0.012369\n",
      "Train Epoch: 3 [5760/6865 (83%)]\tLoss: 0.050428\n",
      "Train Epoch: 3 [6400/6865 (93%)]\tLoss: 0.022087\n",
      "Train Epoch: 4 [0/6865 (0%)]\tLoss: 0.025478\n",
      "Train Epoch: 4 [640/6865 (9%)]\tLoss: 0.124822\n",
      "Train Epoch: 4 [1280/6865 (19%)]\tLoss: 0.042717\n",
      "Train Epoch: 4 [1920/6865 (28%)]\tLoss: 0.004371\n",
      "Train Epoch: 4 [2560/6865 (37%)]\tLoss: 0.013318\n",
      "Train Epoch: 4 [3200/6865 (46%)]\tLoss: 0.002000\n",
      "Train Epoch: 4 [3840/6865 (56%)]\tLoss: 0.077758\n",
      "Train Epoch: 4 [4480/6865 (65%)]\tLoss: 0.020650\n",
      "Train Epoch: 4 [5120/6865 (74%)]\tLoss: 0.005772\n",
      "Train Epoch: 4 [5760/6865 (83%)]\tLoss: 0.040246\n",
      "Train Epoch: 4 [6400/6865 (93%)]\tLoss: 0.013615\n",
      "Train Epoch: 5 [0/6865 (0%)]\tLoss: 0.004653\n",
      "Train Epoch: 5 [640/6865 (9%)]\tLoss: 0.007914\n",
      "Train Epoch: 5 [1280/6865 (19%)]\tLoss: 0.048275\n",
      "Train Epoch: 5 [1920/6865 (28%)]\tLoss: 0.001539\n",
      "Train Epoch: 5 [2560/6865 (37%)]\tLoss: 0.010000\n",
      "Train Epoch: 5 [3200/6865 (46%)]\tLoss: 0.012495\n",
      "Train Epoch: 5 [3840/6865 (56%)]\tLoss: 0.084975\n",
      "Train Epoch: 5 [4480/6865 (65%)]\tLoss: 0.003558\n",
      "Train Epoch: 5 [5120/6865 (74%)]\tLoss: 0.049821\n",
      "Train Epoch: 5 [5760/6865 (83%)]\tLoss: 0.043935\n",
      "Train Epoch: 5 [6400/6865 (93%)]\tLoss: 0.015734\n",
      "Train Epoch: 6 [0/6865 (0%)]\tLoss: 0.062257\n",
      "Train Epoch: 6 [640/6865 (9%)]\tLoss: 0.018917\n",
      "Train Epoch: 6 [1280/6865 (19%)]\tLoss: 0.019641\n",
      "Train Epoch: 6 [1920/6865 (28%)]\tLoss: 0.033441\n",
      "Train Epoch: 6 [2560/6865 (37%)]\tLoss: 0.009094\n",
      "Train Epoch: 6 [3200/6865 (46%)]\tLoss: 0.038418\n",
      "Train Epoch: 6 [3840/6865 (56%)]\tLoss: 0.001499\n",
      "Train Epoch: 6 [4480/6865 (65%)]\tLoss: 0.051329\n",
      "Train Epoch: 6 [5120/6865 (74%)]\tLoss: 0.089904\n",
      "Train Epoch: 6 [5760/6865 (83%)]\tLoss: 0.058916\n",
      "Train Epoch: 6 [6400/6865 (93%)]\tLoss: 0.022115\n",
      "Train Epoch: 7 [0/6865 (0%)]\tLoss: 0.006765\n",
      "Train Epoch: 7 [640/6865 (9%)]\tLoss: 0.029932\n",
      "Train Epoch: 7 [1280/6865 (19%)]\tLoss: 0.027046\n",
      "Train Epoch: 7 [1920/6865 (28%)]\tLoss: 0.025089\n",
      "Train Epoch: 7 [2560/6865 (37%)]\tLoss: 0.027560\n",
      "Train Epoch: 7 [3200/6865 (46%)]\tLoss: 0.014747\n",
      "Train Epoch: 7 [3840/6865 (56%)]\tLoss: 0.054839\n",
      "Train Epoch: 7 [4480/6865 (65%)]\tLoss: 0.062931\n",
      "Train Epoch: 7 [5120/6865 (74%)]\tLoss: 0.066841\n",
      "Train Epoch: 7 [5760/6865 (83%)]\tLoss: 0.066320\n",
      "Train Epoch: 7 [6400/6865 (93%)]\tLoss: 0.025786\n",
      "Train Epoch: 8 [0/6865 (0%)]\tLoss: 0.009007\n",
      "Train Epoch: 8 [640/6865 (9%)]\tLoss: 0.007631\n",
      "Train Epoch: 8 [1280/6865 (19%)]\tLoss: 0.204368\n",
      "Train Epoch: 8 [1920/6865 (28%)]\tLoss: 0.040476\n",
      "Train Epoch: 8 [2560/6865 (37%)]\tLoss: 0.056927\n",
      "Train Epoch: 8 [3200/6865 (46%)]\tLoss: 0.084051\n",
      "Train Epoch: 8 [3840/6865 (56%)]\tLoss: 0.009747\n",
      "Train Epoch: 8 [4480/6865 (65%)]\tLoss: 0.053953\n",
      "Train Epoch: 8 [5120/6865 (74%)]\tLoss: 0.040671\n",
      "Train Epoch: 8 [5760/6865 (83%)]\tLoss: 0.044502\n",
      "Train Epoch: 8 [6400/6865 (93%)]\tLoss: 0.043587\n",
      "Train Epoch: 9 [0/6865 (0%)]\tLoss: 0.024882\n",
      "Train Epoch: 9 [640/6865 (9%)]\tLoss: 0.017934\n",
      "Train Epoch: 9 [1280/6865 (19%)]\tLoss: 0.016215\n",
      "Train Epoch: 9 [1920/6865 (28%)]\tLoss: 0.002963\n",
      "Train Epoch: 9 [2560/6865 (37%)]\tLoss: 0.009227\n",
      "Train Epoch: 9 [3200/6865 (46%)]\tLoss: 0.001341\n",
      "Train Epoch: 9 [3840/6865 (56%)]\tLoss: 0.156671\n",
      "Train Epoch: 9 [4480/6865 (65%)]\tLoss: 0.014064\n",
      "Train Epoch: 9 [5120/6865 (74%)]\tLoss: 0.030662\n",
      "Train Epoch: 9 [5760/6865 (83%)]\tLoss: 0.034980\n",
      "Train Epoch: 9 [6400/6865 (93%)]\tLoss: 0.030417\n",
      "Train Epoch: 10 [0/6865 (0%)]\tLoss: 0.063238\n",
      "Train Epoch: 10 [640/6865 (9%)]\tLoss: 0.052040\n",
      "Train Epoch: 10 [1280/6865 (19%)]\tLoss: 0.035592\n",
      "Train Epoch: 10 [1920/6865 (28%)]\tLoss: 0.007877\n",
      "Train Epoch: 10 [2560/6865 (37%)]\tLoss: 0.006795\n",
      "Train Epoch: 10 [3200/6865 (46%)]\tLoss: 0.019514\n",
      "Train Epoch: 10 [3840/6865 (56%)]\tLoss: 0.008693\n",
      "Train Epoch: 10 [4480/6865 (65%)]\tLoss: 0.013318\n",
      "Train Epoch: 10 [5120/6865 (74%)]\tLoss: 0.008651\n",
      "Train Epoch: 10 [5760/6865 (83%)]\tLoss: 0.059033\n",
      "Train Epoch: 10 [6400/6865 (93%)]\tLoss: 0.017215\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.1389, Accuracy: 9891/10000 (99%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 0.028041\n",
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 0.014399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 0.010085\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 0.200433\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 0.053122\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 0.140060\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 0.035570\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 0.050347\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 0.036408\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 0.118870\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 0.076099\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 0.057573\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 0.005378\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 0.013614\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 0.060815\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 0.020633\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 0.022696\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 0.039331\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 0.018150\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 0.055588\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.068031\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 0.005294\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 0.052689\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.094452\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.150798\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 0.049963\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.009680\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 0.058187\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.031475\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.038252\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.056273\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.027829\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.011335\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.049861\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.021933\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.033204\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.100533\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.015027\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.158180\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.073229\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.010854\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.020739\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.052537\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.113086\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.137801\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.138977\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.059590\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.060932\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.118475\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.028499\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.047271\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.078316\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.023588\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.059313\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.065026\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.141273\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.012759\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.059765\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.015100\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.070310\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.035206\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.147031\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.023000\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.061333\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.080333\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.022377\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.065641\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.041914\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.032796\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.047436\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.166487\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.194385\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.053847\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.012526\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.009905\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.061096\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.009896\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.174779\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.069617\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.012714\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.164232\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.020071\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.013759\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.030477\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.110291\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.011849\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.120921\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.080447\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.012658\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.167838\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.054950\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.006955\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.038715\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.008303\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.009729\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.004710\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.165043\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.019884\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.006258\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.098875\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.003391\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.022789\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.034325\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.018936\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.006272\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.029683\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.027770\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.046367\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 0.067176\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.016063\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.023211\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.036342\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.010870\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.022728\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.018048\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.033010\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.046280\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.045810\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.040148\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.278386\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.036810\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.004507\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.018104\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.059528\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.027117\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.066919\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.005486\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.100119\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.009323\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.106344\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.049502\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.046763\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.054426\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.055581\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.011099\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.103258\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.011265\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.098059\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.015218\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.064855\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.097046\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.018535\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.011000\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.010975\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.015957\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.027498\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.039137\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.044274\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.136172\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.009358\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.097071\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.069461\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.017106\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.014735\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.061232\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.071002\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.255254\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.053048\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.062991\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.013325\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.038509\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.086592\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.091563\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.029261\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.101360\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.053380\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.019243\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.065676\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.013797\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.196814\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.005202\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.063046\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.013415\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.020601\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.029733\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.121709\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.054128\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.002540\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.102864\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.138082\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/5110 (0%)]\tLoss: 0.242667\n",
      "Train Epoch: 1 [640/5110 (12%)]\tLoss: 0.213563\n",
      "Train Epoch: 1 [1280/5110 (25%)]\tLoss: 0.027080\n",
      "Train Epoch: 1 [1920/5110 (38%)]\tLoss: 0.004316\n",
      "Train Epoch: 1 [2560/5110 (50%)]\tLoss: 0.052702\n",
      "Train Epoch: 1 [3200/5110 (62%)]\tLoss: 0.073509\n",
      "Train Epoch: 1 [3840/5110 (75%)]\tLoss: 0.076123\n",
      "Train Epoch: 1 [4480/5110 (88%)]\tLoss: 0.049966\n",
      "Train Epoch: 2 [0/5110 (0%)]\tLoss: 0.018193\n",
      "Train Epoch: 2 [640/5110 (12%)]\tLoss: 0.029666\n",
      "Train Epoch: 2 [1280/5110 (25%)]\tLoss: 0.027961\n",
      "Train Epoch: 2 [1920/5110 (38%)]\tLoss: 0.014524\n",
      "Train Epoch: 2 [2560/5110 (50%)]\tLoss: 0.033280\n",
      "Train Epoch: 2 [3200/5110 (62%)]\tLoss: 0.059862\n",
      "Train Epoch: 2 [3840/5110 (75%)]\tLoss: 0.023424\n",
      "Train Epoch: 2 [4480/5110 (88%)]\tLoss: 0.077569\n",
      "Train Epoch: 3 [0/5110 (0%)]\tLoss: 0.018672\n",
      "Train Epoch: 3 [640/5110 (12%)]\tLoss: 0.084142\n",
      "Train Epoch: 3 [1280/5110 (25%)]\tLoss: 0.104240\n",
      "Train Epoch: 3 [1920/5110 (38%)]\tLoss: 0.016265\n",
      "Train Epoch: 3 [2560/5110 (50%)]\tLoss: 0.011293\n",
      "Train Epoch: 3 [3200/5110 (62%)]\tLoss: 0.028429\n",
      "Train Epoch: 3 [3840/5110 (75%)]\tLoss: 0.026853\n",
      "Train Epoch: 3 [4480/5110 (88%)]\tLoss: 0.080725\n",
      "Train Epoch: 4 [0/5110 (0%)]\tLoss: 0.041926\n",
      "Train Epoch: 4 [640/5110 (12%)]\tLoss: 0.008703\n",
      "Train Epoch: 4 [1280/5110 (25%)]\tLoss: 0.060559\n",
      "Train Epoch: 4 [1920/5110 (38%)]\tLoss: 0.011343\n",
      "Train Epoch: 4 [2560/5110 (50%)]\tLoss: 0.037148\n",
      "Train Epoch: 4 [3200/5110 (62%)]\tLoss: 0.114403\n",
      "Train Epoch: 4 [3840/5110 (75%)]\tLoss: 0.044960\n",
      "Train Epoch: 4 [4480/5110 (88%)]\tLoss: 0.011575\n",
      "Train Epoch: 5 [0/5110 (0%)]\tLoss: 0.072952\n",
      "Train Epoch: 5 [640/5110 (12%)]\tLoss: 0.041384\n",
      "Train Epoch: 5 [1280/5110 (25%)]\tLoss: 0.181955\n",
      "Train Epoch: 5 [1920/5110 (38%)]\tLoss: 0.096444\n",
      "Train Epoch: 5 [2560/5110 (50%)]\tLoss: 0.017469\n",
      "Train Epoch: 5 [3200/5110 (62%)]\tLoss: 0.022852\n",
      "Train Epoch: 5 [3840/5110 (75%)]\tLoss: 0.068013\n",
      "Train Epoch: 5 [4480/5110 (88%)]\tLoss: 0.023398\n",
      "Train Epoch: 6 [0/5110 (0%)]\tLoss: 0.015664\n",
      "Train Epoch: 6 [640/5110 (12%)]\tLoss: 0.015478\n",
      "Train Epoch: 6 [1280/5110 (25%)]\tLoss: 0.013612\n",
      "Train Epoch: 6 [1920/5110 (38%)]\tLoss: 0.105402\n",
      "Train Epoch: 6 [2560/5110 (50%)]\tLoss: 0.065555\n",
      "Train Epoch: 6 [3200/5110 (62%)]\tLoss: 0.050892\n",
      "Train Epoch: 6 [3840/5110 (75%)]\tLoss: 0.048226\n",
      "Train Epoch: 6 [4480/5110 (88%)]\tLoss: 0.024922\n",
      "Train Epoch: 7 [0/5110 (0%)]\tLoss: 0.030081\n",
      "Train Epoch: 7 [640/5110 (12%)]\tLoss: 0.032710\n",
      "Train Epoch: 7 [1280/5110 (25%)]\tLoss: 0.003568\n",
      "Train Epoch: 7 [1920/5110 (38%)]\tLoss: 0.038408\n",
      "Train Epoch: 7 [2560/5110 (50%)]\tLoss: 0.028483\n",
      "Train Epoch: 7 [3200/5110 (62%)]\tLoss: 0.080978\n",
      "Train Epoch: 7 [3840/5110 (75%)]\tLoss: 0.059398\n",
      "Train Epoch: 7 [4480/5110 (88%)]\tLoss: 0.037059\n",
      "Train Epoch: 8 [0/5110 (0%)]\tLoss: 0.024475\n",
      "Train Epoch: 8 [640/5110 (12%)]\tLoss: 0.030998\n",
      "Train Epoch: 8 [1280/5110 (25%)]\tLoss: 0.126644\n",
      "Train Epoch: 8 [1920/5110 (38%)]\tLoss: 0.050823\n",
      "Train Epoch: 8 [2560/5110 (50%)]\tLoss: 0.007249\n",
      "Train Epoch: 8 [3200/5110 (62%)]\tLoss: 0.013498\n",
      "Train Epoch: 8 [3840/5110 (75%)]\tLoss: 0.297684\n",
      "Train Epoch: 8 [4480/5110 (88%)]\tLoss: 0.007733\n",
      "Train Epoch: 9 [0/5110 (0%)]\tLoss: 0.057207\n",
      "Train Epoch: 9 [640/5110 (12%)]\tLoss: 0.008943\n",
      "Train Epoch: 9 [1280/5110 (25%)]\tLoss: 0.010903\n",
      "Train Epoch: 9 [1920/5110 (38%)]\tLoss: 0.040315\n",
      "Train Epoch: 9 [2560/5110 (50%)]\tLoss: 0.051312\n",
      "Train Epoch: 9 [3200/5110 (62%)]\tLoss: 0.009293\n",
      "Train Epoch: 9 [3840/5110 (75%)]\tLoss: 0.070538\n",
      "Train Epoch: 9 [4480/5110 (88%)]\tLoss: 0.037577\n",
      "Train Epoch: 10 [0/5110 (0%)]\tLoss: 0.007151\n",
      "Train Epoch: 10 [640/5110 (12%)]\tLoss: 0.129923\n",
      "Train Epoch: 10 [1280/5110 (25%)]\tLoss: 0.112414\n",
      "Train Epoch: 10 [1920/5110 (38%)]\tLoss: 0.127176\n",
      "Train Epoch: 10 [2560/5110 (50%)]\tLoss: 0.023561\n",
      "Train Epoch: 10 [3200/5110 (62%)]\tLoss: 0.028834\n",
      "Train Epoch: 10 [3840/5110 (75%)]\tLoss: 0.015998\n",
      "Train Epoch: 10 [4480/5110 (88%)]\tLoss: 0.026249\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/10296 (0%)]\tLoss: 0.132593\n",
      "Train Epoch: 1 [640/10296 (6%)]\tLoss: 0.033948\n",
      "Train Epoch: 1 [1280/10296 (12%)]\tLoss: 0.209066\n",
      "Train Epoch: 1 [1920/10296 (19%)]\tLoss: 0.034509\n",
      "Train Epoch: 1 [2560/10296 (25%)]\tLoss: 0.101811\n",
      "Train Epoch: 1 [3200/10296 (31%)]\tLoss: 0.047559\n",
      "Train Epoch: 1 [3840/10296 (37%)]\tLoss: 0.058206\n",
      "Train Epoch: 1 [4480/10296 (43%)]\tLoss: 0.109592\n",
      "Train Epoch: 1 [5120/10296 (50%)]\tLoss: 0.021329\n",
      "Train Epoch: 1 [5760/10296 (56%)]\tLoss: 0.011533\n",
      "Train Epoch: 1 [6400/10296 (62%)]\tLoss: 0.013680\n",
      "Train Epoch: 1 [7040/10296 (68%)]\tLoss: 0.037209\n",
      "Train Epoch: 1 [7680/10296 (75%)]\tLoss: 0.036736\n",
      "Train Epoch: 1 [8320/10296 (81%)]\tLoss: 0.046608\n",
      "Train Epoch: 1 [8960/10296 (87%)]\tLoss: 0.083261\n",
      "Train Epoch: 1 [9600/10296 (93%)]\tLoss: 0.009468\n",
      "Train Epoch: 1 [8960/10296 (99%)]\tLoss: 0.035296\n",
      "Train Epoch: 2 [0/10296 (0%)]\tLoss: 0.067822\n",
      "Train Epoch: 2 [640/10296 (6%)]\tLoss: 0.091820\n",
      "Train Epoch: 2 [1280/10296 (12%)]\tLoss: 0.076517\n",
      "Train Epoch: 2 [1920/10296 (19%)]\tLoss: 0.162397\n",
      "Train Epoch: 2 [2560/10296 (25%)]\tLoss: 0.050391\n",
      "Train Epoch: 2 [3200/10296 (31%)]\tLoss: 0.037917\n",
      "Train Epoch: 2 [3840/10296 (37%)]\tLoss: 0.028795\n",
      "Train Epoch: 2 [4480/10296 (43%)]\tLoss: 0.005832\n",
      "Train Epoch: 2 [5120/10296 (50%)]\tLoss: 0.023009\n",
      "Train Epoch: 2 [5760/10296 (56%)]\tLoss: 0.220904\n",
      "Train Epoch: 2 [6400/10296 (62%)]\tLoss: 0.095601\n",
      "Train Epoch: 2 [7040/10296 (68%)]\tLoss: 0.042033\n",
      "Train Epoch: 2 [7680/10296 (75%)]\tLoss: 0.087070\n",
      "Train Epoch: 2 [8320/10296 (81%)]\tLoss: 0.055906\n",
      "Train Epoch: 2 [8960/10296 (87%)]\tLoss: 0.064628\n",
      "Train Epoch: 2 [9600/10296 (93%)]\tLoss: 0.067362\n",
      "Train Epoch: 2 [8960/10296 (99%)]\tLoss: 0.039159\n",
      "Train Epoch: 3 [0/10296 (0%)]\tLoss: 0.077633\n",
      "Train Epoch: 3 [640/10296 (6%)]\tLoss: 0.073492\n",
      "Train Epoch: 3 [1280/10296 (12%)]\tLoss: 0.151332\n",
      "Train Epoch: 3 [1920/10296 (19%)]\tLoss: 0.012991\n",
      "Train Epoch: 3 [2560/10296 (25%)]\tLoss: 0.014415\n",
      "Train Epoch: 3 [3200/10296 (31%)]\tLoss: 0.099283\n",
      "Train Epoch: 3 [3840/10296 (37%)]\tLoss: 0.028479\n",
      "Train Epoch: 3 [4480/10296 (43%)]\tLoss: 0.093144\n",
      "Train Epoch: 3 [5120/10296 (50%)]\tLoss: 0.057697\n",
      "Train Epoch: 3 [5760/10296 (56%)]\tLoss: 0.059924\n",
      "Train Epoch: 3 [6400/10296 (62%)]\tLoss: 0.079501\n",
      "Train Epoch: 3 [7040/10296 (68%)]\tLoss: 0.049537\n",
      "Train Epoch: 3 [7680/10296 (75%)]\tLoss: 0.009575\n",
      "Train Epoch: 3 [8320/10296 (81%)]\tLoss: 0.009100\n",
      "Train Epoch: 3 [8960/10296 (87%)]\tLoss: 0.003558\n",
      "Train Epoch: 3 [9600/10296 (93%)]\tLoss: 0.007270\n",
      "Train Epoch: 3 [8960/10296 (99%)]\tLoss: 0.017636\n",
      "Train Epoch: 4 [0/10296 (0%)]\tLoss: 0.014270\n",
      "Train Epoch: 4 [640/10296 (6%)]\tLoss: 0.041276\n",
      "Train Epoch: 4 [1280/10296 (12%)]\tLoss: 0.090409\n",
      "Train Epoch: 4 [1920/10296 (19%)]\tLoss: 0.069166\n",
      "Train Epoch: 4 [2560/10296 (25%)]\tLoss: 0.013812\n",
      "Train Epoch: 4 [3200/10296 (31%)]\tLoss: 0.052481\n",
      "Train Epoch: 4 [3840/10296 (37%)]\tLoss: 0.062624\n",
      "Train Epoch: 4 [4480/10296 (43%)]\tLoss: 0.080067\n",
      "Train Epoch: 4 [5120/10296 (50%)]\tLoss: 0.130630\n",
      "Train Epoch: 4 [5760/10296 (56%)]\tLoss: 0.054924\n",
      "Train Epoch: 4 [6400/10296 (62%)]\tLoss: 0.181698\n",
      "Train Epoch: 4 [7040/10296 (68%)]\tLoss: 0.019247\n",
      "Train Epoch: 4 [7680/10296 (75%)]\tLoss: 0.134850\n",
      "Train Epoch: 4 [8320/10296 (81%)]\tLoss: 0.028887\n",
      "Train Epoch: 4 [8960/10296 (87%)]\tLoss: 0.001034\n",
      "Train Epoch: 4 [9600/10296 (93%)]\tLoss: 0.027576\n",
      "Train Epoch: 4 [8960/10296 (99%)]\tLoss: 0.006489\n",
      "Train Epoch: 5 [0/10296 (0%)]\tLoss: 0.052103\n",
      "Train Epoch: 5 [640/10296 (6%)]\tLoss: 0.055508\n",
      "Train Epoch: 5 [1280/10296 (12%)]\tLoss: 0.040075\n",
      "Train Epoch: 5 [1920/10296 (19%)]\tLoss: 0.062987\n",
      "Train Epoch: 5 [2560/10296 (25%)]\tLoss: 0.054241\n",
      "Train Epoch: 5 [3200/10296 (31%)]\tLoss: 0.055823\n",
      "Train Epoch: 5 [3840/10296 (37%)]\tLoss: 0.025733\n",
      "Train Epoch: 5 [4480/10296 (43%)]\tLoss: 0.125099\n",
      "Train Epoch: 5 [5120/10296 (50%)]\tLoss: 0.023773\n",
      "Train Epoch: 5 [5760/10296 (56%)]\tLoss: 0.105026\n",
      "Train Epoch: 5 [6400/10296 (62%)]\tLoss: 0.020661\n",
      "Train Epoch: 5 [7040/10296 (68%)]\tLoss: 0.019037\n",
      "Train Epoch: 5 [7680/10296 (75%)]\tLoss: 0.053946\n",
      "Train Epoch: 5 [8320/10296 (81%)]\tLoss: 0.094173\n",
      "Train Epoch: 5 [8960/10296 (87%)]\tLoss: 0.036291\n",
      "Train Epoch: 5 [9600/10296 (93%)]\tLoss: 0.007450\n",
      "Train Epoch: 5 [8960/10296 (99%)]\tLoss: 0.033118\n",
      "Train Epoch: 6 [0/10296 (0%)]\tLoss: 0.028683\n",
      "Train Epoch: 6 [640/10296 (6%)]\tLoss: 0.058404\n",
      "Train Epoch: 6 [1280/10296 (12%)]\tLoss: 0.041299\n",
      "Train Epoch: 6 [1920/10296 (19%)]\tLoss: 0.045672\n",
      "Train Epoch: 6 [2560/10296 (25%)]\tLoss: 0.020690\n",
      "Train Epoch: 6 [3200/10296 (31%)]\tLoss: 0.030928\n",
      "Train Epoch: 6 [3840/10296 (37%)]\tLoss: 0.131995\n",
      "Train Epoch: 6 [4480/10296 (43%)]\tLoss: 0.005506\n",
      "Train Epoch: 6 [5120/10296 (50%)]\tLoss: 0.056042\n",
      "Train Epoch: 6 [5760/10296 (56%)]\tLoss: 0.013606\n",
      "Train Epoch: 6 [6400/10296 (62%)]\tLoss: 0.041297\n",
      "Train Epoch: 6 [7040/10296 (68%)]\tLoss: 0.027344\n",
      "Train Epoch: 6 [7680/10296 (75%)]\tLoss: 0.127482\n",
      "Train Epoch: 6 [8320/10296 (81%)]\tLoss: 0.036836\n",
      "Train Epoch: 6 [8960/10296 (87%)]\tLoss: 0.046408\n",
      "Train Epoch: 6 [9600/10296 (93%)]\tLoss: 0.043700\n",
      "Train Epoch: 6 [8960/10296 (99%)]\tLoss: 0.004403\n",
      "Train Epoch: 7 [0/10296 (0%)]\tLoss: 0.105095\n",
      "Train Epoch: 7 [640/10296 (6%)]\tLoss: 0.043923\n",
      "Train Epoch: 7 [1280/10296 (12%)]\tLoss: 0.007582\n",
      "Train Epoch: 7 [1920/10296 (19%)]\tLoss: 0.244938\n",
      "Train Epoch: 7 [2560/10296 (25%)]\tLoss: 0.004950\n",
      "Train Epoch: 7 [3200/10296 (31%)]\tLoss: 0.056250\n",
      "Train Epoch: 7 [3840/10296 (37%)]\tLoss: 0.104045\n",
      "Train Epoch: 7 [4480/10296 (43%)]\tLoss: 0.117518\n",
      "Train Epoch: 7 [5120/10296 (50%)]\tLoss: 0.002880\n",
      "Train Epoch: 7 [5760/10296 (56%)]\tLoss: 0.067432\n",
      "Train Epoch: 7 [6400/10296 (62%)]\tLoss: 0.008983\n",
      "Train Epoch: 7 [7040/10296 (68%)]\tLoss: 0.058423\n",
      "Train Epoch: 7 [7680/10296 (75%)]\tLoss: 0.049100\n",
      "Train Epoch: 7 [8320/10296 (81%)]\tLoss: 0.183340\n",
      "Train Epoch: 7 [8960/10296 (87%)]\tLoss: 0.040340\n",
      "Train Epoch: 7 [9600/10296 (93%)]\tLoss: 0.018052\n",
      "Train Epoch: 7 [8960/10296 (99%)]\tLoss: 0.098455\n",
      "Train Epoch: 8 [0/10296 (0%)]\tLoss: 0.064603\n",
      "Train Epoch: 8 [640/10296 (6%)]\tLoss: 0.014392\n",
      "Train Epoch: 8 [1280/10296 (12%)]\tLoss: 0.025927\n",
      "Train Epoch: 8 [1920/10296 (19%)]\tLoss: 0.063263\n",
      "Train Epoch: 8 [2560/10296 (25%)]\tLoss: 0.107936\n",
      "Train Epoch: 8 [3200/10296 (31%)]\tLoss: 0.006638\n",
      "Train Epoch: 8 [3840/10296 (37%)]\tLoss: 0.038927\n",
      "Train Epoch: 8 [4480/10296 (43%)]\tLoss: 0.027841\n",
      "Train Epoch: 8 [5120/10296 (50%)]\tLoss: 0.016041\n",
      "Train Epoch: 8 [5760/10296 (56%)]\tLoss: 0.012797\n",
      "Train Epoch: 8 [6400/10296 (62%)]\tLoss: 0.108365\n",
      "Train Epoch: 8 [7040/10296 (68%)]\tLoss: 0.033177\n",
      "Train Epoch: 8 [7680/10296 (75%)]\tLoss: 0.050823\n",
      "Train Epoch: 8 [8320/10296 (81%)]\tLoss: 0.091684\n",
      "Train Epoch: 8 [8960/10296 (87%)]\tLoss: 0.011557\n",
      "Train Epoch: 8 [9600/10296 (93%)]\tLoss: 0.011806\n",
      "Train Epoch: 8 [8960/10296 (99%)]\tLoss: 0.004113\n",
      "Train Epoch: 9 [0/10296 (0%)]\tLoss: 0.072695\n",
      "Train Epoch: 9 [640/10296 (6%)]\tLoss: 0.027656\n",
      "Train Epoch: 9 [1280/10296 (12%)]\tLoss: 0.026919\n",
      "Train Epoch: 9 [1920/10296 (19%)]\tLoss: 0.024537\n",
      "Train Epoch: 9 [2560/10296 (25%)]\tLoss: 0.015251\n",
      "Train Epoch: 9 [3200/10296 (31%)]\tLoss: 0.044196\n",
      "Train Epoch: 9 [3840/10296 (37%)]\tLoss: 0.108151\n",
      "Train Epoch: 9 [4480/10296 (43%)]\tLoss: 0.011942\n",
      "Train Epoch: 9 [5120/10296 (50%)]\tLoss: 0.112470\n",
      "Train Epoch: 9 [5760/10296 (56%)]\tLoss: 0.095900\n",
      "Train Epoch: 9 [6400/10296 (62%)]\tLoss: 0.013772\n",
      "Train Epoch: 9 [7040/10296 (68%)]\tLoss: 0.055070\n",
      "Train Epoch: 9 [7680/10296 (75%)]\tLoss: 0.114804\n",
      "Train Epoch: 9 [8320/10296 (81%)]\tLoss: 0.055875\n",
      "Train Epoch: 9 [8960/10296 (87%)]\tLoss: 0.060760\n",
      "Train Epoch: 9 [9600/10296 (93%)]\tLoss: 0.197669\n",
      "Train Epoch: 9 [8960/10296 (99%)]\tLoss: 0.033850\n",
      "Train Epoch: 10 [0/10296 (0%)]\tLoss: 0.015254\n",
      "Train Epoch: 10 [640/10296 (6%)]\tLoss: 0.011676\n",
      "Train Epoch: 10 [1280/10296 (12%)]\tLoss: 0.017411\n",
      "Train Epoch: 10 [1920/10296 (19%)]\tLoss: 0.097515\n",
      "Train Epoch: 10 [2560/10296 (25%)]\tLoss: 0.001785\n",
      "Train Epoch: 10 [3200/10296 (31%)]\tLoss: 0.051660\n",
      "Train Epoch: 10 [3840/10296 (37%)]\tLoss: 0.079953\n",
      "Train Epoch: 10 [4480/10296 (43%)]\tLoss: 0.020844\n",
      "Train Epoch: 10 [5120/10296 (50%)]\tLoss: 0.106517\n",
      "Train Epoch: 10 [5760/10296 (56%)]\tLoss: 0.024455\n",
      "Train Epoch: 10 [6400/10296 (62%)]\tLoss: 0.125350\n",
      "Train Epoch: 10 [7040/10296 (68%)]\tLoss: 0.037462\n",
      "Train Epoch: 10 [7680/10296 (75%)]\tLoss: 0.006256\n",
      "Train Epoch: 10 [8320/10296 (81%)]\tLoss: 0.039975\n",
      "Train Epoch: 10 [8960/10296 (87%)]\tLoss: 0.158008\n",
      "Train Epoch: 10 [9600/10296 (93%)]\tLoss: 0.001619\n",
      "Train Epoch: 10 [8960/10296 (99%)]\tLoss: 0.002430\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 0.079937\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 0.026620\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 0.021079\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 0.070899\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 0.011840\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 0.342685\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 0.019774\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 0.004123\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 0.060981\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 0.017381\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 0.033636\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 0.068129\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 0.099678\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 0.074691\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 0.038836\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 0.053299\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 0.027455\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.097348\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.011800\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.131301\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.020219\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.088623\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.036378\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.016423\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.024705\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.024735\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.065453\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.000792\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.006924\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.047028\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.175761\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.011085\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.018342\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.071093\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.038346\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.007625\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.091411\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.073241\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.014746\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.064588\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.002705\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.031554\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.016697\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.008779\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.089420\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.023501\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.025808\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.112153\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.017282\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.022663\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.086818\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.011564\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.010561\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.535680\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.009965\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.092069\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.036468\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.059856\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.012888\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.012361\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.071344\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.047422\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.084674\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.026164\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.019041\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.044119\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.034411\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.015142\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.015995\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.020172\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.023165\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.012575\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.002686\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.018756\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.006329\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.029642\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.011207\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.012540\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.018682\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.210344\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.044161\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.096044\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.070686\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.049450\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.005600\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.057097\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.000546\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.006304\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.020482\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.072608\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.023741\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.040805\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.111778\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.026881\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.047767\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.034301\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.010646\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.106263\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.019247\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.032461\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.007754\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.238470\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.002299\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.030895\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.117222\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.021128\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.007255\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.025207\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.013641\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.032719\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.048357\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.133459\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.016572\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.074827\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.045348\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.037245\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.038035\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.083815\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.052343\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.028416\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.025811\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.048104\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.047237\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.021156\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.052572\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.132450\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.002949\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.040400\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.006632\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.073458\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.039205\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.017814\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.060665\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.004268\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.016573\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.022746\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.024359\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.004490\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.004803\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.030614\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.062853\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.009962\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.074986\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.024228\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.050119\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.048910\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.009235\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.069334\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.087057\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.001328\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.031791\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.017630\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.008596\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.041935\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.119777\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.012464\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.316285\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.094089\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.024315\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.002907\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/3910 (0%)]\tLoss: 0.103800\n",
      "Train Epoch: 1 [640/3910 (16%)]\tLoss: 0.076580\n",
      "Train Epoch: 1 [1280/3910 (32%)]\tLoss: 0.037097\n",
      "Train Epoch: 1 [1920/3910 (48%)]\tLoss: 0.055214\n",
      "Train Epoch: 1 [2560/3910 (65%)]\tLoss: 0.098201\n",
      "Train Epoch: 1 [3200/3910 (81%)]\tLoss: 0.093887\n",
      "Train Epoch: 1 [3840/3910 (97%)]\tLoss: 0.013692\n",
      "Train Epoch: 2 [0/3910 (0%)]\tLoss: 0.059896\n",
      "Train Epoch: 2 [640/3910 (16%)]\tLoss: 0.078676\n",
      "Train Epoch: 2 [1280/3910 (32%)]\tLoss: 0.035434\n",
      "Train Epoch: 2 [1920/3910 (48%)]\tLoss: 0.046065\n",
      "Train Epoch: 2 [2560/3910 (65%)]\tLoss: 0.104859\n",
      "Train Epoch: 2 [3200/3910 (81%)]\tLoss: 0.082948\n",
      "Train Epoch: 2 [3840/3910 (97%)]\tLoss: 0.035462\n",
      "Train Epoch: 3 [0/3910 (0%)]\tLoss: 0.135932\n",
      "Train Epoch: 3 [640/3910 (16%)]\tLoss: 0.007929\n",
      "Train Epoch: 3 [1280/3910 (32%)]\tLoss: 0.138708\n",
      "Train Epoch: 3 [1920/3910 (48%)]\tLoss: 0.058188\n",
      "Train Epoch: 3 [2560/3910 (65%)]\tLoss: 0.237843\n",
      "Train Epoch: 3 [3200/3910 (81%)]\tLoss: 0.007788\n",
      "Train Epoch: 3 [3840/3910 (97%)]\tLoss: 0.068716\n",
      "Train Epoch: 4 [0/3910 (0%)]\tLoss: 0.016136\n",
      "Train Epoch: 4 [640/3910 (16%)]\tLoss: 0.010584\n",
      "Train Epoch: 4 [1280/3910 (32%)]\tLoss: 0.074075\n",
      "Train Epoch: 4 [1920/3910 (48%)]\tLoss: 0.007006\n",
      "Train Epoch: 4 [2560/3910 (65%)]\tLoss: 0.065948\n",
      "Train Epoch: 4 [3200/3910 (81%)]\tLoss: 0.128927\n",
      "Train Epoch: 4 [3840/3910 (97%)]\tLoss: 0.028582\n",
      "Train Epoch: 5 [0/3910 (0%)]\tLoss: 0.041710\n",
      "Train Epoch: 5 [640/3910 (16%)]\tLoss: 0.013552\n",
      "Train Epoch: 5 [1280/3910 (32%)]\tLoss: 0.034836\n",
      "Train Epoch: 5 [1920/3910 (48%)]\tLoss: 0.019757\n",
      "Train Epoch: 5 [2560/3910 (65%)]\tLoss: 0.073151\n",
      "Train Epoch: 5 [3200/3910 (81%)]\tLoss: 0.135016\n",
      "Train Epoch: 5 [3840/3910 (97%)]\tLoss: 0.024671\n",
      "Train Epoch: 6 [0/3910 (0%)]\tLoss: 0.035512\n",
      "Train Epoch: 6 [640/3910 (16%)]\tLoss: 0.002400\n",
      "Train Epoch: 6 [1280/3910 (32%)]\tLoss: 0.068155\n",
      "Train Epoch: 6 [1920/3910 (48%)]\tLoss: 0.051130\n",
      "Train Epoch: 6 [2560/3910 (65%)]\tLoss: 0.030466\n",
      "Train Epoch: 6 [3200/3910 (81%)]\tLoss: 0.033965\n",
      "Train Epoch: 6 [3840/3910 (97%)]\tLoss: 0.040248\n",
      "Train Epoch: 7 [0/3910 (0%)]\tLoss: 0.073615\n",
      "Train Epoch: 7 [640/3910 (16%)]\tLoss: 0.019975\n",
      "Train Epoch: 7 [1280/3910 (32%)]\tLoss: 0.056014\n",
      "Train Epoch: 7 [1920/3910 (48%)]\tLoss: 0.018375\n",
      "Train Epoch: 7 [2560/3910 (65%)]\tLoss: 0.017880\n",
      "Train Epoch: 7 [3200/3910 (81%)]\tLoss: 0.051584\n",
      "Train Epoch: 7 [3840/3910 (97%)]\tLoss: 0.070292\n",
      "Train Epoch: 8 [0/3910 (0%)]\tLoss: 0.064701\n",
      "Train Epoch: 8 [640/3910 (16%)]\tLoss: 0.011525\n",
      "Train Epoch: 8 [1280/3910 (32%)]\tLoss: 0.006843\n",
      "Train Epoch: 8 [1920/3910 (48%)]\tLoss: 0.052596\n",
      "Train Epoch: 8 [2560/3910 (65%)]\tLoss: 0.028904\n",
      "Train Epoch: 8 [3200/3910 (81%)]\tLoss: 0.010173\n",
      "Train Epoch: 8 [3840/3910 (97%)]\tLoss: 0.036300\n",
      "Train Epoch: 9 [0/3910 (0%)]\tLoss: 0.032474\n",
      "Train Epoch: 9 [640/3910 (16%)]\tLoss: 0.025380\n",
      "Train Epoch: 9 [1280/3910 (32%)]\tLoss: 0.005069\n",
      "Train Epoch: 9 [1920/3910 (48%)]\tLoss: 0.046129\n",
      "Train Epoch: 9 [2560/3910 (65%)]\tLoss: 0.015932\n",
      "Train Epoch: 9 [3200/3910 (81%)]\tLoss: 0.011641\n",
      "Train Epoch: 9 [3840/3910 (97%)]\tLoss: 0.091314\n",
      "Train Epoch: 10 [0/3910 (0%)]\tLoss: 0.063726\n",
      "Train Epoch: 10 [640/3910 (16%)]\tLoss: 0.005255\n",
      "Train Epoch: 10 [1280/3910 (32%)]\tLoss: 0.041077\n",
      "Train Epoch: 10 [1920/3910 (48%)]\tLoss: 0.013457\n",
      "Train Epoch: 10 [2560/3910 (65%)]\tLoss: 0.015662\n",
      "Train Epoch: 10 [3200/3910 (81%)]\tLoss: 0.005172\n",
      "Train Epoch: 10 [3840/3910 (97%)]\tLoss: 0.036488\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 0.173817\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 0.204533\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 0.137050\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 0.023270\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 0.006747\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 0.026457\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 0.055054\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 0.055867\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 0.013671\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 0.084550\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.018352\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.002361\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 0.009752\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 0.007454\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 0.028931\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.086656\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.009698\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.014892\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.025015\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.031262\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.005666\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.014737\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.082693\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.070663\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.006455\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.004123\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.005571\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.021032\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.025208\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.013732\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.013162\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.016434\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.042644\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.021779\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.000859\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.042358\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.002861\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.105342\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.023176\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.026443\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.032410\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.001230\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.050306\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.011603\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.015719\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.041898\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.027061\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.040942\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.010722\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.024117\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.043459\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.060932\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.009808\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.012008\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.035811\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.022112\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.154023\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.032171\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.017651\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.039634\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.004973\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.027119\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.018757\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.102362\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.008428\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.036363\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.063486\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.010363\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.010871\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.067455\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.015417\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.004553\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.004883\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.009287\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.015850\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.040367\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.204692\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.010165\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.003059\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.041402\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.012785\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.004836\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.076586\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.054366\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.009495\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.122088\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.006638\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.056657\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.008493\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.086248\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.012542\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.045059\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.012716\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.076019\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.037370\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.004509\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.059312\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.008683\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.024241\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.003785\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.025406\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.032928\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.041380\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.023235\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.002077\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.002745\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.085043\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.003906\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.009151\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.070195\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.011226\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.018206\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.003413\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.002090\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.004910\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.018082\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.043769\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.051482\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.008800\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.047517\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/5096 (0%)]\tLoss: 0.013336\n",
      "Train Epoch: 1 [640/5096 (12%)]\tLoss: 0.097472\n",
      "Train Epoch: 1 [1280/5096 (25%)]\tLoss: 0.012378\n",
      "Train Epoch: 1 [1920/5096 (38%)]\tLoss: 0.030890\n",
      "Train Epoch: 1 [2560/5096 (50%)]\tLoss: 0.005316\n",
      "Train Epoch: 1 [3200/5096 (62%)]\tLoss: 0.016532\n",
      "Train Epoch: 1 [3840/5096 (75%)]\tLoss: 0.023682\n",
      "Train Epoch: 1 [4480/5096 (88%)]\tLoss: 0.015831\n",
      "Train Epoch: 2 [0/5096 (0%)]\tLoss: 0.045418\n",
      "Train Epoch: 2 [640/5096 (12%)]\tLoss: 0.060269\n",
      "Train Epoch: 2 [1280/5096 (25%)]\tLoss: 0.005759\n",
      "Train Epoch: 2 [1920/5096 (38%)]\tLoss: 0.004449\n",
      "Train Epoch: 2 [2560/5096 (50%)]\tLoss: 0.012655\n",
      "Train Epoch: 2 [3200/5096 (62%)]\tLoss: 0.039728\n",
      "Train Epoch: 2 [3840/5096 (75%)]\tLoss: 0.018964\n",
      "Train Epoch: 2 [4480/5096 (88%)]\tLoss: 0.022365\n",
      "Train Epoch: 3 [0/5096 (0%)]\tLoss: 0.007370\n",
      "Train Epoch: 3 [640/5096 (12%)]\tLoss: 0.067160\n",
      "Train Epoch: 3 [1280/5096 (25%)]\tLoss: 0.022661\n",
      "Train Epoch: 3 [1920/5096 (38%)]\tLoss: 0.005297\n",
      "Train Epoch: 3 [2560/5096 (50%)]\tLoss: 0.081317\n",
      "Train Epoch: 3 [3200/5096 (62%)]\tLoss: 0.001157\n",
      "Train Epoch: 3 [3840/5096 (75%)]\tLoss: 0.011254\n",
      "Train Epoch: 3 [4480/5096 (88%)]\tLoss: 0.103577\n",
      "Train Epoch: 4 [0/5096 (0%)]\tLoss: 0.008717\n",
      "Train Epoch: 4 [640/5096 (12%)]\tLoss: 0.003182\n",
      "Train Epoch: 4 [1280/5096 (25%)]\tLoss: 0.024205\n",
      "Train Epoch: 4 [1920/5096 (38%)]\tLoss: 0.013180\n",
      "Train Epoch: 4 [2560/5096 (50%)]\tLoss: 0.058252\n",
      "Train Epoch: 4 [3200/5096 (62%)]\tLoss: 0.026891\n",
      "Train Epoch: 4 [3840/5096 (75%)]\tLoss: 0.003203\n",
      "Train Epoch: 4 [4480/5096 (88%)]\tLoss: 0.028807\n",
      "Train Epoch: 5 [0/5096 (0%)]\tLoss: 0.004622\n",
      "Train Epoch: 5 [640/5096 (12%)]\tLoss: 0.023834\n",
      "Train Epoch: 5 [1280/5096 (25%)]\tLoss: 0.003779\n",
      "Train Epoch: 5 [1920/5096 (38%)]\tLoss: 0.040399\n",
      "Train Epoch: 5 [2560/5096 (50%)]\tLoss: 0.013253\n",
      "Train Epoch: 5 [3200/5096 (62%)]\tLoss: 0.018501\n",
      "Train Epoch: 5 [3840/5096 (75%)]\tLoss: 0.040125\n",
      "Train Epoch: 5 [4480/5096 (88%)]\tLoss: 0.027540\n",
      "Train Epoch: 6 [0/5096 (0%)]\tLoss: 0.023158\n",
      "Train Epoch: 6 [640/5096 (12%)]\tLoss: 0.068091\n",
      "Train Epoch: 6 [1280/5096 (25%)]\tLoss: 0.037348\n",
      "Train Epoch: 6 [1920/5096 (38%)]\tLoss: 0.008502\n",
      "Train Epoch: 6 [2560/5096 (50%)]\tLoss: 0.015374\n",
      "Train Epoch: 6 [3200/5096 (62%)]\tLoss: 0.071112\n",
      "Train Epoch: 6 [3840/5096 (75%)]\tLoss: 0.003009\n",
      "Train Epoch: 6 [4480/5096 (88%)]\tLoss: 0.034879\n",
      "Train Epoch: 7 [0/5096 (0%)]\tLoss: 0.004386\n",
      "Train Epoch: 7 [640/5096 (12%)]\tLoss: 0.002064\n",
      "Train Epoch: 7 [1280/5096 (25%)]\tLoss: 0.028840\n",
      "Train Epoch: 7 [1920/5096 (38%)]\tLoss: 0.043558\n",
      "Train Epoch: 7 [2560/5096 (50%)]\tLoss: 0.011556\n",
      "Train Epoch: 7 [3200/5096 (62%)]\tLoss: 0.043823\n",
      "Train Epoch: 7 [3840/5096 (75%)]\tLoss: 0.019479\n",
      "Train Epoch: 7 [4480/5096 (88%)]\tLoss: 0.001741\n",
      "Train Epoch: 8 [0/5096 (0%)]\tLoss: 0.001000\n",
      "Train Epoch: 8 [640/5096 (12%)]\tLoss: 0.030718\n",
      "Train Epoch: 8 [1280/5096 (25%)]\tLoss: 0.079456\n",
      "Train Epoch: 8 [1920/5096 (38%)]\tLoss: 0.048151\n",
      "Train Epoch: 8 [2560/5096 (50%)]\tLoss: 0.006291\n",
      "Train Epoch: 8 [3200/5096 (62%)]\tLoss: 0.018684\n",
      "Train Epoch: 8 [3840/5096 (75%)]\tLoss: 0.100277\n",
      "Train Epoch: 8 [4480/5096 (88%)]\tLoss: 0.092026\n",
      "Train Epoch: 9 [0/5096 (0%)]\tLoss: 0.001413\n",
      "Train Epoch: 9 [640/5096 (12%)]\tLoss: 0.006124\n",
      "Train Epoch: 9 [1280/5096 (25%)]\tLoss: 0.002222\n",
      "Train Epoch: 9 [1920/5096 (38%)]\tLoss: 0.002487\n",
      "Train Epoch: 9 [2560/5096 (50%)]\tLoss: 0.004893\n",
      "Train Epoch: 9 [3200/5096 (62%)]\tLoss: 0.006062\n",
      "Train Epoch: 9 [3840/5096 (75%)]\tLoss: 0.004272\n",
      "Train Epoch: 9 [4480/5096 (88%)]\tLoss: 0.030073\n",
      "Train Epoch: 10 [0/5096 (0%)]\tLoss: 0.039102\n",
      "Train Epoch: 10 [640/5096 (12%)]\tLoss: 0.003281\n",
      "Train Epoch: 10 [1280/5096 (25%)]\tLoss: 0.053185\n",
      "Train Epoch: 10 [1920/5096 (38%)]\tLoss: 0.027504\n",
      "Train Epoch: 10 [2560/5096 (50%)]\tLoss: 0.014306\n",
      "Train Epoch: 10 [3200/5096 (62%)]\tLoss: 0.001300\n",
      "Train Epoch: 10 [3840/5096 (75%)]\tLoss: 0.038514\n",
      "Train Epoch: 10 [4480/5096 (88%)]\tLoss: 0.032069\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6865 (0%)]\tLoss: 0.101246\n",
      "Train Epoch: 1 [640/6865 (9%)]\tLoss: 0.036732\n",
      "Train Epoch: 1 [1280/6865 (19%)]\tLoss: 0.026785\n",
      "Train Epoch: 1 [1920/6865 (28%)]\tLoss: 0.139191\n",
      "Train Epoch: 1 [2560/6865 (37%)]\tLoss: 0.182367\n",
      "Train Epoch: 1 [3200/6865 (46%)]\tLoss: 0.074397\n",
      "Train Epoch: 1 [3840/6865 (56%)]\tLoss: 0.034421\n",
      "Train Epoch: 1 [4480/6865 (65%)]\tLoss: 0.057813\n",
      "Train Epoch: 1 [5120/6865 (74%)]\tLoss: 0.027150\n",
      "Train Epoch: 1 [5760/6865 (83%)]\tLoss: 0.069587\n",
      "Train Epoch: 1 [6400/6865 (93%)]\tLoss: 0.001755\n",
      "Train Epoch: 2 [0/6865 (0%)]\tLoss: 0.031625\n",
      "Train Epoch: 2 [640/6865 (9%)]\tLoss: 0.134598\n",
      "Train Epoch: 2 [1280/6865 (19%)]\tLoss: 0.083423\n",
      "Train Epoch: 2 [1920/6865 (28%)]\tLoss: 0.015608\n",
      "Train Epoch: 2 [2560/6865 (37%)]\tLoss: 0.059582\n",
      "Train Epoch: 2 [3200/6865 (46%)]\tLoss: 0.019646\n",
      "Train Epoch: 2 [3840/6865 (56%)]\tLoss: 0.362229\n",
      "Train Epoch: 2 [4480/6865 (65%)]\tLoss: 0.006228\n",
      "Train Epoch: 2 [5120/6865 (74%)]\tLoss: 0.028933\n",
      "Train Epoch: 2 [5760/6865 (83%)]\tLoss: 0.003301\n",
      "Train Epoch: 2 [6400/6865 (93%)]\tLoss: 0.012315\n",
      "Train Epoch: 3 [0/6865 (0%)]\tLoss: 0.019867\n",
      "Train Epoch: 3 [640/6865 (9%)]\tLoss: 0.022790\n",
      "Train Epoch: 3 [1280/6865 (19%)]\tLoss: 0.132461\n",
      "Train Epoch: 3 [1920/6865 (28%)]\tLoss: 0.044195\n",
      "Train Epoch: 3 [2560/6865 (37%)]\tLoss: 0.032222\n",
      "Train Epoch: 3 [3200/6865 (46%)]\tLoss: 0.010511\n",
      "Train Epoch: 3 [3840/6865 (56%)]\tLoss: 0.062841\n",
      "Train Epoch: 3 [4480/6865 (65%)]\tLoss: 0.025527\n",
      "Train Epoch: 3 [5120/6865 (74%)]\tLoss: 0.119909\n",
      "Train Epoch: 3 [5760/6865 (83%)]\tLoss: 0.048744\n",
      "Train Epoch: 3 [6400/6865 (93%)]\tLoss: 0.006903\n",
      "Train Epoch: 4 [0/6865 (0%)]\tLoss: 0.089098\n",
      "Train Epoch: 4 [640/6865 (9%)]\tLoss: 0.014752\n",
      "Train Epoch: 4 [1280/6865 (19%)]\tLoss: 0.015918\n",
      "Train Epoch: 4 [1920/6865 (28%)]\tLoss: 0.070008\n",
      "Train Epoch: 4 [2560/6865 (37%)]\tLoss: 0.002118\n",
      "Train Epoch: 4 [3200/6865 (46%)]\tLoss: 0.026515\n",
      "Train Epoch: 4 [3840/6865 (56%)]\tLoss: 0.012840\n",
      "Train Epoch: 4 [4480/6865 (65%)]\tLoss: 0.198281\n",
      "Train Epoch: 4 [5120/6865 (74%)]\tLoss: 0.103131\n",
      "Train Epoch: 4 [5760/6865 (83%)]\tLoss: 0.052247\n",
      "Train Epoch: 4 [6400/6865 (93%)]\tLoss: 0.053225\n",
      "Train Epoch: 5 [0/6865 (0%)]\tLoss: 0.003574\n",
      "Train Epoch: 5 [640/6865 (9%)]\tLoss: 0.081929\n",
      "Train Epoch: 5 [1280/6865 (19%)]\tLoss: 0.004572\n",
      "Train Epoch: 5 [1920/6865 (28%)]\tLoss: 0.060767\n",
      "Train Epoch: 5 [2560/6865 (37%)]\tLoss: 0.180147\n",
      "Train Epoch: 5 [3200/6865 (46%)]\tLoss: 0.002625\n",
      "Train Epoch: 5 [3840/6865 (56%)]\tLoss: 0.071869\n",
      "Train Epoch: 5 [4480/6865 (65%)]\tLoss: 0.014783\n",
      "Train Epoch: 5 [5120/6865 (74%)]\tLoss: 0.049344\n",
      "Train Epoch: 5 [5760/6865 (83%)]\tLoss: 0.043283\n",
      "Train Epoch: 5 [6400/6865 (93%)]\tLoss: 0.010206\n",
      "Train Epoch: 6 [0/6865 (0%)]\tLoss: 0.009702\n",
      "Train Epoch: 6 [640/6865 (9%)]\tLoss: 0.001722\n",
      "Train Epoch: 6 [1280/6865 (19%)]\tLoss: 0.010917\n",
      "Train Epoch: 6 [1920/6865 (28%)]\tLoss: 0.063105\n",
      "Train Epoch: 6 [2560/6865 (37%)]\tLoss: 0.007761\n",
      "Train Epoch: 6 [3200/6865 (46%)]\tLoss: 0.053070\n",
      "Train Epoch: 6 [3840/6865 (56%)]\tLoss: 0.053623\n",
      "Train Epoch: 6 [4480/6865 (65%)]\tLoss: 0.071323\n",
      "Train Epoch: 6 [5120/6865 (74%)]\tLoss: 0.020293\n",
      "Train Epoch: 6 [5760/6865 (83%)]\tLoss: 0.125535\n",
      "Train Epoch: 6 [6400/6865 (93%)]\tLoss: 0.005457\n",
      "Train Epoch: 7 [0/6865 (0%)]\tLoss: 0.027302\n",
      "Train Epoch: 7 [640/6865 (9%)]\tLoss: 0.038526\n",
      "Train Epoch: 7 [1280/6865 (19%)]\tLoss: 0.017514\n",
      "Train Epoch: 7 [1920/6865 (28%)]\tLoss: 0.002123\n",
      "Train Epoch: 7 [2560/6865 (37%)]\tLoss: 0.013198\n",
      "Train Epoch: 7 [3200/6865 (46%)]\tLoss: 0.002687\n",
      "Train Epoch: 7 [3840/6865 (56%)]\tLoss: 0.019960\n",
      "Train Epoch: 7 [4480/6865 (65%)]\tLoss: 0.006576\n",
      "Train Epoch: 7 [5120/6865 (74%)]\tLoss: 0.136291\n",
      "Train Epoch: 7 [5760/6865 (83%)]\tLoss: 0.021120\n",
      "Train Epoch: 7 [6400/6865 (93%)]\tLoss: 0.001007\n",
      "Train Epoch: 8 [0/6865 (0%)]\tLoss: 0.018839\n",
      "Train Epoch: 8 [640/6865 (9%)]\tLoss: 0.047890\n",
      "Train Epoch: 8 [1280/6865 (19%)]\tLoss: 0.022936\n",
      "Train Epoch: 8 [1920/6865 (28%)]\tLoss: 0.012103\n",
      "Train Epoch: 8 [2560/6865 (37%)]\tLoss: 0.011326\n",
      "Train Epoch: 8 [3200/6865 (46%)]\tLoss: 0.031704\n",
      "Train Epoch: 8 [3840/6865 (56%)]\tLoss: 0.027086\n",
      "Train Epoch: 8 [4480/6865 (65%)]\tLoss: 0.049040\n",
      "Train Epoch: 8 [5120/6865 (74%)]\tLoss: 0.031493\n",
      "Train Epoch: 8 [5760/6865 (83%)]\tLoss: 0.050769\n",
      "Train Epoch: 8 [6400/6865 (93%)]\tLoss: 0.000825\n",
      "Train Epoch: 9 [0/6865 (0%)]\tLoss: 0.038468\n",
      "Train Epoch: 9 [640/6865 (9%)]\tLoss: 0.002765\n",
      "Train Epoch: 9 [1280/6865 (19%)]\tLoss: 0.081160\n",
      "Train Epoch: 9 [1920/6865 (28%)]\tLoss: 0.011597\n",
      "Train Epoch: 9 [2560/6865 (37%)]\tLoss: 0.041460\n",
      "Train Epoch: 9 [3200/6865 (46%)]\tLoss: 0.007950\n",
      "Train Epoch: 9 [3840/6865 (56%)]\tLoss: 0.029472\n",
      "Train Epoch: 9 [4480/6865 (65%)]\tLoss: 0.004729\n",
      "Train Epoch: 9 [5120/6865 (74%)]\tLoss: 0.012138\n",
      "Train Epoch: 9 [5760/6865 (83%)]\tLoss: 0.050291\n",
      "Train Epoch: 9 [6400/6865 (93%)]\tLoss: 0.013350\n",
      "Train Epoch: 10 [0/6865 (0%)]\tLoss: 0.186121\n",
      "Train Epoch: 10 [640/6865 (9%)]\tLoss: 0.004351\n",
      "Train Epoch: 10 [1280/6865 (19%)]\tLoss: 0.042081\n",
      "Train Epoch: 10 [1920/6865 (28%)]\tLoss: 0.001194\n",
      "Train Epoch: 10 [2560/6865 (37%)]\tLoss: 0.023152\n",
      "Train Epoch: 10 [3200/6865 (46%)]\tLoss: 0.005274\n",
      "Train Epoch: 10 [3840/6865 (56%)]\tLoss: 0.001265\n",
      "Train Epoch: 10 [4480/6865 (65%)]\tLoss: 0.026895\n",
      "Train Epoch: 10 [5120/6865 (74%)]\tLoss: 0.021175\n",
      "Train Epoch: 10 [5760/6865 (83%)]\tLoss: 0.033717\n",
      "Train Epoch: 10 [6400/6865 (93%)]\tLoss: 0.004849\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.1373, Accuracy: 9890/10000 (99%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 0.278695\n",
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 0.094669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 0.067570\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 0.131051\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 0.098789\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 0.043961\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 0.092106\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 0.066355\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 0.082401\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 0.017268\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 0.128853\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 0.045376\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 0.136799\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 0.096977\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 0.033245\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 0.069268\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 0.037003\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 0.096862\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 0.124368\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 0.052466\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.043551\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 0.046542\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 0.039617\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.034238\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.037992\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 0.017891\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.026444\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 0.040788\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.101778\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.012197\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.122779\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.041375\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.395799\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.015680\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.034711\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.028464\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.057971\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.007373\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.077913\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.019478\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.048265\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.066018\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.290705\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.007345\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.063572\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.104993\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.020805\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.002840\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.193969\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.040391\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.206663\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.045143\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.231884\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.036793\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.234062\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.104878\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.094057\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.019543\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.013155\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.063511\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.053705\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.088208\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.064922\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.138590\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.245545\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.161547\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.056904\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.119316\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.058798\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.111462\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.065882\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.019614\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.090385\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.029709\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.060290\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.066099\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.039121\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.069986\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.009601\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.042333\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.049530\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.037150\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.043186\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.017422\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.003851\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.027630\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.019583\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.034210\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.014835\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.061369\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.006639\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.042889\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.052838\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.082729\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.023718\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.067648\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.034015\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.017669\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.011568\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.141902\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.020462\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.019142\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.089631\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.016679\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.035367\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.016585\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.018140\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.008652\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 0.040508\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.012262\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.048446\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.050008\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.071359\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.059974\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.077952\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.080457\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.059812\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.017413\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.079353\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.048947\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.011115\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.042084\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.076556\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.032619\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.176690\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.139367\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.174924\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.064837\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.194217\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.035225\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.094431\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.063521\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.044220\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.189886\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.007337\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.040469\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.099870\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.068919\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.038433\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.057422\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.024994\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.021937\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.052323\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.021962\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.022499\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.009317\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.024001\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.035886\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.007292\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.029699\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.057339\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.032220\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.020889\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.037407\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.035979\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.085004\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.029065\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.008370\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.015019\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.034728\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.016943\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.108616\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.023616\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.167022\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.054062\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.069302\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.058132\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.031250\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.064887\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.034374\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.028539\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.042146\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.067374\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.368056\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.061229\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.061069\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.049593\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.182450\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.038142\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.023117\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/5110 (0%)]\tLoss: 0.053327\n",
      "Train Epoch: 1 [640/5110 (12%)]\tLoss: 0.021206\n",
      "Train Epoch: 1 [1280/5110 (25%)]\tLoss: 0.110391\n",
      "Train Epoch: 1 [1920/5110 (38%)]\tLoss: 0.099680\n",
      "Train Epoch: 1 [2560/5110 (50%)]\tLoss: 0.061769\n",
      "Train Epoch: 1 [3200/5110 (62%)]\tLoss: 0.065616\n",
      "Train Epoch: 1 [3840/5110 (75%)]\tLoss: 0.037549\n",
      "Train Epoch: 1 [4480/5110 (88%)]\tLoss: 0.058184\n",
      "Train Epoch: 2 [0/5110 (0%)]\tLoss: 0.039631\n",
      "Train Epoch: 2 [640/5110 (12%)]\tLoss: 0.004733\n",
      "Train Epoch: 2 [1280/5110 (25%)]\tLoss: 0.027469\n",
      "Train Epoch: 2 [1920/5110 (38%)]\tLoss: 0.031162\n",
      "Train Epoch: 2 [2560/5110 (50%)]\tLoss: 0.036100\n",
      "Train Epoch: 2 [3200/5110 (62%)]\tLoss: 0.040105\n",
      "Train Epoch: 2 [3840/5110 (75%)]\tLoss: 0.040561\n",
      "Train Epoch: 2 [4480/5110 (88%)]\tLoss: 0.018412\n",
      "Train Epoch: 3 [0/5110 (0%)]\tLoss: 0.066006\n",
      "Train Epoch: 3 [640/5110 (12%)]\tLoss: 0.024296\n",
      "Train Epoch: 3 [1280/5110 (25%)]\tLoss: 0.046386\n",
      "Train Epoch: 3 [1920/5110 (38%)]\tLoss: 0.114486\n",
      "Train Epoch: 3 [2560/5110 (50%)]\tLoss: 0.018336\n",
      "Train Epoch: 3 [3200/5110 (62%)]\tLoss: 0.059554\n",
      "Train Epoch: 3 [3840/5110 (75%)]\tLoss: 0.031722\n",
      "Train Epoch: 3 [4480/5110 (88%)]\tLoss: 0.005125\n",
      "Train Epoch: 4 [0/5110 (0%)]\tLoss: 0.082538\n",
      "Train Epoch: 4 [640/5110 (12%)]\tLoss: 0.086383\n",
      "Train Epoch: 4 [1280/5110 (25%)]\tLoss: 0.004385\n",
      "Train Epoch: 4 [1920/5110 (38%)]\tLoss: 0.014590\n",
      "Train Epoch: 4 [2560/5110 (50%)]\tLoss: 0.031097\n",
      "Train Epoch: 4 [3200/5110 (62%)]\tLoss: 0.032083\n",
      "Train Epoch: 4 [3840/5110 (75%)]\tLoss: 0.219161\n",
      "Train Epoch: 4 [4480/5110 (88%)]\tLoss: 0.014693\n",
      "Train Epoch: 5 [0/5110 (0%)]\tLoss: 0.040282\n",
      "Train Epoch: 5 [640/5110 (12%)]\tLoss: 0.026791\n",
      "Train Epoch: 5 [1280/5110 (25%)]\tLoss: 0.081487\n",
      "Train Epoch: 5 [1920/5110 (38%)]\tLoss: 0.053740\n",
      "Train Epoch: 5 [2560/5110 (50%)]\tLoss: 0.008575\n",
      "Train Epoch: 5 [3200/5110 (62%)]\tLoss: 0.081136\n",
      "Train Epoch: 5 [3840/5110 (75%)]\tLoss: 0.073124\n",
      "Train Epoch: 5 [4480/5110 (88%)]\tLoss: 0.163347\n",
      "Train Epoch: 6 [0/5110 (0%)]\tLoss: 0.070831\n",
      "Train Epoch: 6 [640/5110 (12%)]\tLoss: 0.055285\n",
      "Train Epoch: 6 [1280/5110 (25%)]\tLoss: 0.158122\n",
      "Train Epoch: 6 [1920/5110 (38%)]\tLoss: 0.041456\n",
      "Train Epoch: 6 [2560/5110 (50%)]\tLoss: 0.079027\n",
      "Train Epoch: 6 [3200/5110 (62%)]\tLoss: 0.006275\n",
      "Train Epoch: 6 [3840/5110 (75%)]\tLoss: 0.020263\n",
      "Train Epoch: 6 [4480/5110 (88%)]\tLoss: 0.028668\n",
      "Train Epoch: 7 [0/5110 (0%)]\tLoss: 0.004540\n",
      "Train Epoch: 7 [640/5110 (12%)]\tLoss: 0.035158\n",
      "Train Epoch: 7 [1280/5110 (25%)]\tLoss: 0.042329\n",
      "Train Epoch: 7 [1920/5110 (38%)]\tLoss: 0.010900\n",
      "Train Epoch: 7 [2560/5110 (50%)]\tLoss: 0.085944\n",
      "Train Epoch: 7 [3200/5110 (62%)]\tLoss: 0.022398\n",
      "Train Epoch: 7 [3840/5110 (75%)]\tLoss: 0.013546\n",
      "Train Epoch: 7 [4480/5110 (88%)]\tLoss: 0.014261\n",
      "Train Epoch: 8 [0/5110 (0%)]\tLoss: 0.064907\n",
      "Train Epoch: 8 [640/5110 (12%)]\tLoss: 0.010842\n",
      "Train Epoch: 8 [1280/5110 (25%)]\tLoss: 0.064027\n",
      "Train Epoch: 8 [1920/5110 (38%)]\tLoss: 0.040556\n",
      "Train Epoch: 8 [2560/5110 (50%)]\tLoss: 0.137077\n",
      "Train Epoch: 8 [3200/5110 (62%)]\tLoss: 0.000998\n",
      "Train Epoch: 8 [3840/5110 (75%)]\tLoss: 0.003250\n",
      "Train Epoch: 8 [4480/5110 (88%)]\tLoss: 0.053645\n",
      "Train Epoch: 9 [0/5110 (0%)]\tLoss: 0.033396\n",
      "Train Epoch: 9 [640/5110 (12%)]\tLoss: 0.051109\n",
      "Train Epoch: 9 [1280/5110 (25%)]\tLoss: 0.010726\n",
      "Train Epoch: 9 [1920/5110 (38%)]\tLoss: 0.018905\n",
      "Train Epoch: 9 [2560/5110 (50%)]\tLoss: 0.080057\n",
      "Train Epoch: 9 [3200/5110 (62%)]\tLoss: 0.055970\n",
      "Train Epoch: 9 [3840/5110 (75%)]\tLoss: 0.051433\n",
      "Train Epoch: 9 [4480/5110 (88%)]\tLoss: 0.034913\n",
      "Train Epoch: 10 [0/5110 (0%)]\tLoss: 0.047506\n",
      "Train Epoch: 10 [640/5110 (12%)]\tLoss: 0.017648\n",
      "Train Epoch: 10 [1280/5110 (25%)]\tLoss: 0.057121\n",
      "Train Epoch: 10 [1920/5110 (38%)]\tLoss: 0.028913\n",
      "Train Epoch: 10 [2560/5110 (50%)]\tLoss: 0.015384\n",
      "Train Epoch: 10 [3200/5110 (62%)]\tLoss: 0.112640\n",
      "Train Epoch: 10 [3840/5110 (75%)]\tLoss: 0.020661\n",
      "Train Epoch: 10 [4480/5110 (88%)]\tLoss: 0.008206\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/10296 (0%)]\tLoss: 0.133228\n",
      "Train Epoch: 1 [640/10296 (6%)]\tLoss: 0.148726\n",
      "Train Epoch: 1 [1280/10296 (12%)]\tLoss: 0.097886\n",
      "Train Epoch: 1 [1920/10296 (19%)]\tLoss: 0.140669\n",
      "Train Epoch: 1 [2560/10296 (25%)]\tLoss: 0.106027\n",
      "Train Epoch: 1 [3200/10296 (31%)]\tLoss: 0.036797\n",
      "Train Epoch: 1 [3840/10296 (37%)]\tLoss: 0.106671\n",
      "Train Epoch: 1 [4480/10296 (43%)]\tLoss: 0.022555\n",
      "Train Epoch: 1 [5120/10296 (50%)]\tLoss: 0.054580\n",
      "Train Epoch: 1 [5760/10296 (56%)]\tLoss: 0.029472\n",
      "Train Epoch: 1 [6400/10296 (62%)]\tLoss: 0.011659\n",
      "Train Epoch: 1 [7040/10296 (68%)]\tLoss: 0.021917\n",
      "Train Epoch: 1 [7680/10296 (75%)]\tLoss: 0.056786\n",
      "Train Epoch: 1 [8320/10296 (81%)]\tLoss: 0.032073\n",
      "Train Epoch: 1 [8960/10296 (87%)]\tLoss: 0.032306\n",
      "Train Epoch: 1 [9600/10296 (93%)]\tLoss: 0.076862\n",
      "Train Epoch: 1 [8960/10296 (99%)]\tLoss: 0.039496\n",
      "Train Epoch: 2 [0/10296 (0%)]\tLoss: 0.026610\n",
      "Train Epoch: 2 [640/10296 (6%)]\tLoss: 0.076887\n",
      "Train Epoch: 2 [1280/10296 (12%)]\tLoss: 0.146540\n",
      "Train Epoch: 2 [1920/10296 (19%)]\tLoss: 0.023490\n",
      "Train Epoch: 2 [2560/10296 (25%)]\tLoss: 0.014463\n",
      "Train Epoch: 2 [3200/10296 (31%)]\tLoss: 0.066770\n",
      "Train Epoch: 2 [3840/10296 (37%)]\tLoss: 0.052792\n",
      "Train Epoch: 2 [4480/10296 (43%)]\tLoss: 0.094644\n",
      "Train Epoch: 2 [5120/10296 (50%)]\tLoss: 0.067630\n",
      "Train Epoch: 2 [5760/10296 (56%)]\tLoss: 0.063369\n",
      "Train Epoch: 2 [6400/10296 (62%)]\tLoss: 0.191986\n",
      "Train Epoch: 2 [7040/10296 (68%)]\tLoss: 0.025627\n",
      "Train Epoch: 2 [7680/10296 (75%)]\tLoss: 0.118619\n",
      "Train Epoch: 2 [8320/10296 (81%)]\tLoss: 0.023021\n",
      "Train Epoch: 2 [8960/10296 (87%)]\tLoss: 0.027436\n",
      "Train Epoch: 2 [9600/10296 (93%)]\tLoss: 0.049521\n",
      "Train Epoch: 2 [8960/10296 (99%)]\tLoss: 0.025830\n",
      "Train Epoch: 3 [0/10296 (0%)]\tLoss: 0.128542\n",
      "Train Epoch: 3 [640/10296 (6%)]\tLoss: 0.097657\n",
      "Train Epoch: 3 [1280/10296 (12%)]\tLoss: 0.075476\n",
      "Train Epoch: 3 [1920/10296 (19%)]\tLoss: 0.013577\n",
      "Train Epoch: 3 [2560/10296 (25%)]\tLoss: 0.034568\n",
      "Train Epoch: 3 [3200/10296 (31%)]\tLoss: 0.169451\n",
      "Train Epoch: 3 [3840/10296 (37%)]\tLoss: 0.112643\n",
      "Train Epoch: 3 [4480/10296 (43%)]\tLoss: 0.017846\n",
      "Train Epoch: 3 [5120/10296 (50%)]\tLoss: 0.058776\n",
      "Train Epoch: 3 [5760/10296 (56%)]\tLoss: 0.044550\n",
      "Train Epoch: 3 [6400/10296 (62%)]\tLoss: 0.156909\n",
      "Train Epoch: 3 [7040/10296 (68%)]\tLoss: 0.091995\n",
      "Train Epoch: 3 [7680/10296 (75%)]\tLoss: 0.166045\n",
      "Train Epoch: 3 [8320/10296 (81%)]\tLoss: 0.006855\n",
      "Train Epoch: 3 [8960/10296 (87%)]\tLoss: 0.027554\n",
      "Train Epoch: 3 [9600/10296 (93%)]\tLoss: 0.010736\n",
      "Train Epoch: 3 [8960/10296 (99%)]\tLoss: 0.148748\n",
      "Train Epoch: 4 [0/10296 (0%)]\tLoss: 0.066377\n",
      "Train Epoch: 4 [640/10296 (6%)]\tLoss: 0.025788\n",
      "Train Epoch: 4 [1280/10296 (12%)]\tLoss: 0.035751\n",
      "Train Epoch: 4 [1920/10296 (19%)]\tLoss: 0.004240\n",
      "Train Epoch: 4 [2560/10296 (25%)]\tLoss: 0.012960\n",
      "Train Epoch: 4 [3200/10296 (31%)]\tLoss: 0.065251\n",
      "Train Epoch: 4 [3840/10296 (37%)]\tLoss: 0.004137\n",
      "Train Epoch: 4 [4480/10296 (43%)]\tLoss: 0.026553\n",
      "Train Epoch: 4 [5120/10296 (50%)]\tLoss: 0.070183\n",
      "Train Epoch: 4 [5760/10296 (56%)]\tLoss: 0.043066\n",
      "Train Epoch: 4 [6400/10296 (62%)]\tLoss: 0.042515\n",
      "Train Epoch: 4 [7040/10296 (68%)]\tLoss: 0.059732\n",
      "Train Epoch: 4 [7680/10296 (75%)]\tLoss: 0.143538\n",
      "Train Epoch: 4 [8320/10296 (81%)]\tLoss: 0.087705\n",
      "Train Epoch: 4 [8960/10296 (87%)]\tLoss: 0.014971\n",
      "Train Epoch: 4 [9600/10296 (93%)]\tLoss: 0.036023\n",
      "Train Epoch: 4 [8960/10296 (99%)]\tLoss: 0.277886\n",
      "Train Epoch: 5 [0/10296 (0%)]\tLoss: 0.025137\n",
      "Train Epoch: 5 [640/10296 (6%)]\tLoss: 0.008672\n",
      "Train Epoch: 5 [1280/10296 (12%)]\tLoss: 0.063130\n",
      "Train Epoch: 5 [1920/10296 (19%)]\tLoss: 0.022185\n",
      "Train Epoch: 5 [2560/10296 (25%)]\tLoss: 0.016096\n",
      "Train Epoch: 5 [3200/10296 (31%)]\tLoss: 0.005341\n",
      "Train Epoch: 5 [3840/10296 (37%)]\tLoss: 0.020221\n",
      "Train Epoch: 5 [4480/10296 (43%)]\tLoss: 0.037322\n",
      "Train Epoch: 5 [5120/10296 (50%)]\tLoss: 0.056359\n",
      "Train Epoch: 5 [5760/10296 (56%)]\tLoss: 0.114754\n",
      "Train Epoch: 5 [6400/10296 (62%)]\tLoss: 0.033220\n",
      "Train Epoch: 5 [7040/10296 (68%)]\tLoss: 0.054276\n",
      "Train Epoch: 5 [7680/10296 (75%)]\tLoss: 0.092311\n",
      "Train Epoch: 5 [8320/10296 (81%)]\tLoss: 0.023017\n",
      "Train Epoch: 5 [8960/10296 (87%)]\tLoss: 0.061867\n",
      "Train Epoch: 5 [9600/10296 (93%)]\tLoss: 0.021650\n",
      "Train Epoch: 5 [8960/10296 (99%)]\tLoss: 0.007820\n",
      "Train Epoch: 6 [0/10296 (0%)]\tLoss: 0.024031\n",
      "Train Epoch: 6 [640/10296 (6%)]\tLoss: 0.036327\n",
      "Train Epoch: 6 [1280/10296 (12%)]\tLoss: 0.113862\n",
      "Train Epoch: 6 [1920/10296 (19%)]\tLoss: 0.051726\n",
      "Train Epoch: 6 [2560/10296 (25%)]\tLoss: 0.049703\n",
      "Train Epoch: 6 [3200/10296 (31%)]\tLoss: 0.008862\n",
      "Train Epoch: 6 [3840/10296 (37%)]\tLoss: 0.139667\n",
      "Train Epoch: 6 [4480/10296 (43%)]\tLoss: 0.025894\n",
      "Train Epoch: 6 [5120/10296 (50%)]\tLoss: 0.135631\n",
      "Train Epoch: 6 [5760/10296 (56%)]\tLoss: 0.160786\n",
      "Train Epoch: 6 [6400/10296 (62%)]\tLoss: 0.169916\n",
      "Train Epoch: 6 [7040/10296 (68%)]\tLoss: 0.038026\n",
      "Train Epoch: 6 [7680/10296 (75%)]\tLoss: 0.019416\n",
      "Train Epoch: 6 [8320/10296 (81%)]\tLoss: 0.005842\n",
      "Train Epoch: 6 [8960/10296 (87%)]\tLoss: 0.051498\n",
      "Train Epoch: 6 [9600/10296 (93%)]\tLoss: 0.003695\n",
      "Train Epoch: 6 [8960/10296 (99%)]\tLoss: 0.040519\n",
      "Train Epoch: 7 [0/10296 (0%)]\tLoss: 0.048799\n",
      "Train Epoch: 7 [640/10296 (6%)]\tLoss: 0.238654\n",
      "Train Epoch: 7 [1280/10296 (12%)]\tLoss: 0.040817\n",
      "Train Epoch: 7 [1920/10296 (19%)]\tLoss: 0.099081\n",
      "Train Epoch: 7 [2560/10296 (25%)]\tLoss: 0.020071\n",
      "Train Epoch: 7 [3200/10296 (31%)]\tLoss: 0.045383\n",
      "Train Epoch: 7 [3840/10296 (37%)]\tLoss: 0.048815\n",
      "Train Epoch: 7 [4480/10296 (43%)]\tLoss: 0.010057\n",
      "Train Epoch: 7 [5120/10296 (50%)]\tLoss: 0.041250\n",
      "Train Epoch: 7 [5760/10296 (56%)]\tLoss: 0.085909\n",
      "Train Epoch: 7 [6400/10296 (62%)]\tLoss: 0.049047\n",
      "Train Epoch: 7 [7040/10296 (68%)]\tLoss: 0.008404\n",
      "Train Epoch: 7 [7680/10296 (75%)]\tLoss: 0.044982\n",
      "Train Epoch: 7 [8320/10296 (81%)]\tLoss: 0.011336\n",
      "Train Epoch: 7 [8960/10296 (87%)]\tLoss: 0.038383\n",
      "Train Epoch: 7 [9600/10296 (93%)]\tLoss: 0.013572\n",
      "Train Epoch: 7 [8960/10296 (99%)]\tLoss: 0.092903\n",
      "Train Epoch: 8 [0/10296 (0%)]\tLoss: 0.086094\n",
      "Train Epoch: 8 [640/10296 (6%)]\tLoss: 0.037995\n",
      "Train Epoch: 8 [1280/10296 (12%)]\tLoss: 0.030497\n",
      "Train Epoch: 8 [1920/10296 (19%)]\tLoss: 0.066535\n",
      "Train Epoch: 8 [2560/10296 (25%)]\tLoss: 0.007564\n",
      "Train Epoch: 8 [3200/10296 (31%)]\tLoss: 0.016954\n",
      "Train Epoch: 8 [3840/10296 (37%)]\tLoss: 0.006920\n",
      "Train Epoch: 8 [4480/10296 (43%)]\tLoss: 0.007681\n",
      "Train Epoch: 8 [5120/10296 (50%)]\tLoss: 0.047970\n",
      "Train Epoch: 8 [5760/10296 (56%)]\tLoss: 0.014207\n",
      "Train Epoch: 8 [6400/10296 (62%)]\tLoss: 0.074771\n",
      "Train Epoch: 8 [7040/10296 (68%)]\tLoss: 0.069345\n",
      "Train Epoch: 8 [7680/10296 (75%)]\tLoss: 0.023587\n",
      "Train Epoch: 8 [8320/10296 (81%)]\tLoss: 0.042722\n",
      "Train Epoch: 8 [8960/10296 (87%)]\tLoss: 0.010973\n",
      "Train Epoch: 8 [9600/10296 (93%)]\tLoss: 0.019168\n",
      "Train Epoch: 8 [8960/10296 (99%)]\tLoss: 0.012361\n",
      "Train Epoch: 9 [0/10296 (0%)]\tLoss: 0.013558\n",
      "Train Epoch: 9 [640/10296 (6%)]\tLoss: 0.023943\n",
      "Train Epoch: 9 [1280/10296 (12%)]\tLoss: 0.095145\n",
      "Train Epoch: 9 [1920/10296 (19%)]\tLoss: 0.033280\n",
      "Train Epoch: 9 [2560/10296 (25%)]\tLoss: 0.116400\n",
      "Train Epoch: 9 [3200/10296 (31%)]\tLoss: 0.006445\n",
      "Train Epoch: 9 [3840/10296 (37%)]\tLoss: 0.014912\n",
      "Train Epoch: 9 [4480/10296 (43%)]\tLoss: 0.043740\n",
      "Train Epoch: 9 [5120/10296 (50%)]\tLoss: 0.028157\n",
      "Train Epoch: 9 [5760/10296 (56%)]\tLoss: 0.086168\n",
      "Train Epoch: 9 [6400/10296 (62%)]\tLoss: 0.021063\n",
      "Train Epoch: 9 [7040/10296 (68%)]\tLoss: 0.002805\n",
      "Train Epoch: 9 [7680/10296 (75%)]\tLoss: 0.007432\n",
      "Train Epoch: 9 [8320/10296 (81%)]\tLoss: 0.007059\n",
      "Train Epoch: 9 [8960/10296 (87%)]\tLoss: 0.010509\n",
      "Train Epoch: 9 [9600/10296 (93%)]\tLoss: 0.003311\n",
      "Train Epoch: 9 [8960/10296 (99%)]\tLoss: 0.035244\n",
      "Train Epoch: 10 [0/10296 (0%)]\tLoss: 0.040178\n",
      "Train Epoch: 10 [640/10296 (6%)]\tLoss: 0.006990\n",
      "Train Epoch: 10 [1280/10296 (12%)]\tLoss: 0.045975\n",
      "Train Epoch: 10 [1920/10296 (19%)]\tLoss: 0.053845\n",
      "Train Epoch: 10 [2560/10296 (25%)]\tLoss: 0.035450\n",
      "Train Epoch: 10 [3200/10296 (31%)]\tLoss: 0.046144\n",
      "Train Epoch: 10 [3840/10296 (37%)]\tLoss: 0.084826\n",
      "Train Epoch: 10 [4480/10296 (43%)]\tLoss: 0.045746\n",
      "Train Epoch: 10 [5120/10296 (50%)]\tLoss: 0.039180\n",
      "Train Epoch: 10 [5760/10296 (56%)]\tLoss: 0.134557\n",
      "Train Epoch: 10 [6400/10296 (62%)]\tLoss: 0.004198\n",
      "Train Epoch: 10 [7040/10296 (68%)]\tLoss: 0.013782\n",
      "Train Epoch: 10 [7680/10296 (75%)]\tLoss: 0.049238\n",
      "Train Epoch: 10 [8320/10296 (81%)]\tLoss: 0.020495\n",
      "Train Epoch: 10 [8960/10296 (87%)]\tLoss: 0.051222\n",
      "Train Epoch: 10 [9600/10296 (93%)]\tLoss: 0.068383\n",
      "Train Epoch: 10 [8960/10296 (99%)]\tLoss: 0.062933\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 0.071099\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 0.013586\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 0.068176\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 0.028045\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 0.087098\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 0.026451\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 0.035167\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 0.008500\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 0.108656\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 0.050719\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 0.059284\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 0.067511\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 0.003168\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 0.008497\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 0.037853\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 0.012653\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 0.057320\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.126493\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.129658\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.050564\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.047069\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.010513\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.028644\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.019836\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.061049\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.023572\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.004202\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.002186\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.022537\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.065286\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.022943\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.005964\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.039674\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.099829\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.014535\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.062986\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.009696\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.049000\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.013383\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.074199\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.025600\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.006124\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.026343\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.006489\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.007428\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.025283\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.035728\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.046771\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.005751\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.061624\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.014778\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.064819\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.073116\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.101968\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.009587\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.094058\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.052394\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.039430\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.023280\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.032004\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.065459\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.019633\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.029156\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.024190\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.050076\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.015572\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.158925\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.023785\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.032436\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.052575\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.032166\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.043369\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.020797\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.002099\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.083079\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.018058\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.001979\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.041793\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.046291\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.026144\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.045686\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.043629\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.211452\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.006021\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.011382\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.006500\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.114960\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.150289\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.006749\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.009928\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.015871\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.015544\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.015655\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.027078\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.018753\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.024924\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.026943\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.005771\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.013620\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.059001\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.017143\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.065540\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.034472\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.109752\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.020742\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.050593\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.015267\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.013488\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.036801\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.043660\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.008314\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.007107\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.045797\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.030418\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.073155\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.033729\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.022161\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.021822\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.024682\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.114776\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.077823\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.010128\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.022858\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.095157\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.095674\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.038783\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.021163\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.023045\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.041979\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.022399\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.049608\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.007440\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.012635\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.004288\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.030928\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.117072\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.039466\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.100120\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.023371\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.048276\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.023175\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.158851\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.025487\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.090350\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.012437\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.042526\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.005993\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.026605\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.014753\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.108475\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.009126\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.011277\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.012303\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.014840\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.027446\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.026446\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.007456\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.127882\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.022227\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.076815\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/3910 (0%)]\tLoss: 0.104868\n",
      "Train Epoch: 1 [640/3910 (16%)]\tLoss: 0.093270\n",
      "Train Epoch: 1 [1280/3910 (32%)]\tLoss: 0.109181\n",
      "Train Epoch: 1 [1920/3910 (48%)]\tLoss: 0.065272\n",
      "Train Epoch: 1 [2560/3910 (65%)]\tLoss: 0.025340\n",
      "Train Epoch: 1 [3200/3910 (81%)]\tLoss: 0.034007\n",
      "Train Epoch: 1 [3840/3910 (97%)]\tLoss: 0.088465\n",
      "Train Epoch: 2 [0/3910 (0%)]\tLoss: 0.095427\n",
      "Train Epoch: 2 [640/3910 (16%)]\tLoss: 0.041880\n",
      "Train Epoch: 2 [1280/3910 (32%)]\tLoss: 0.047838\n",
      "Train Epoch: 2 [1920/3910 (48%)]\tLoss: 0.110938\n",
      "Train Epoch: 2 [2560/3910 (65%)]\tLoss: 0.099586\n",
      "Train Epoch: 2 [3200/3910 (81%)]\tLoss: 0.021971\n",
      "Train Epoch: 2 [3840/3910 (97%)]\tLoss: 0.063419\n",
      "Train Epoch: 3 [0/3910 (0%)]\tLoss: 0.016636\n",
      "Train Epoch: 3 [640/3910 (16%)]\tLoss: 0.121100\n",
      "Train Epoch: 3 [1280/3910 (32%)]\tLoss: 0.061055\n",
      "Train Epoch: 3 [1920/3910 (48%)]\tLoss: 0.118555\n",
      "Train Epoch: 3 [2560/3910 (65%)]\tLoss: 0.041879\n",
      "Train Epoch: 3 [3200/3910 (81%)]\tLoss: 0.021558\n",
      "Train Epoch: 3 [3840/3910 (97%)]\tLoss: 0.067567\n",
      "Train Epoch: 4 [0/3910 (0%)]\tLoss: 0.010169\n",
      "Train Epoch: 4 [640/3910 (16%)]\tLoss: 0.112177\n",
      "Train Epoch: 4 [1280/3910 (32%)]\tLoss: 0.010434\n",
      "Train Epoch: 4 [1920/3910 (48%)]\tLoss: 0.069817\n",
      "Train Epoch: 4 [2560/3910 (65%)]\tLoss: 0.053520\n",
      "Train Epoch: 4 [3200/3910 (81%)]\tLoss: 0.017265\n",
      "Train Epoch: 4 [3840/3910 (97%)]\tLoss: 0.008057\n",
      "Train Epoch: 5 [0/3910 (0%)]\tLoss: 0.059773\n",
      "Train Epoch: 5 [640/3910 (16%)]\tLoss: 0.023907\n",
      "Train Epoch: 5 [1280/3910 (32%)]\tLoss: 0.090669\n",
      "Train Epoch: 5 [1920/3910 (48%)]\tLoss: 0.062654\n",
      "Train Epoch: 5 [2560/3910 (65%)]\tLoss: 0.044034\n",
      "Train Epoch: 5 [3200/3910 (81%)]\tLoss: 0.056493\n",
      "Train Epoch: 5 [3840/3910 (97%)]\tLoss: 0.049774\n",
      "Train Epoch: 6 [0/3910 (0%)]\tLoss: 0.016159\n",
      "Train Epoch: 6 [640/3910 (16%)]\tLoss: 0.154356\n",
      "Train Epoch: 6 [1280/3910 (32%)]\tLoss: 0.067201\n",
      "Train Epoch: 6 [1920/3910 (48%)]\tLoss: 0.048496\n",
      "Train Epoch: 6 [2560/3910 (65%)]\tLoss: 0.045491\n",
      "Train Epoch: 6 [3200/3910 (81%)]\tLoss: 0.018914\n",
      "Train Epoch: 6 [3840/3910 (97%)]\tLoss: 0.034129\n",
      "Train Epoch: 7 [0/3910 (0%)]\tLoss: 0.029259\n",
      "Train Epoch: 7 [640/3910 (16%)]\tLoss: 0.135038\n",
      "Train Epoch: 7 [1280/3910 (32%)]\tLoss: 0.052310\n",
      "Train Epoch: 7 [1920/3910 (48%)]\tLoss: 0.047819\n",
      "Train Epoch: 7 [2560/3910 (65%)]\tLoss: 0.065928\n",
      "Train Epoch: 7 [3200/3910 (81%)]\tLoss: 0.095300\n",
      "Train Epoch: 7 [3840/3910 (97%)]\tLoss: 0.082538\n",
      "Train Epoch: 8 [0/3910 (0%)]\tLoss: 0.001602\n",
      "Train Epoch: 8 [640/3910 (16%)]\tLoss: 0.042085\n",
      "Train Epoch: 8 [1280/3910 (32%)]\tLoss: 0.047486\n",
      "Train Epoch: 8 [1920/3910 (48%)]\tLoss: 0.049037\n",
      "Train Epoch: 8 [2560/3910 (65%)]\tLoss: 0.031772\n",
      "Train Epoch: 8 [3200/3910 (81%)]\tLoss: 0.012812\n",
      "Train Epoch: 8 [3840/3910 (97%)]\tLoss: 0.012245\n",
      "Train Epoch: 9 [0/3910 (0%)]\tLoss: 0.014067\n",
      "Train Epoch: 9 [640/3910 (16%)]\tLoss: 0.058053\n",
      "Train Epoch: 9 [1280/3910 (32%)]\tLoss: 0.014677\n",
      "Train Epoch: 9 [1920/3910 (48%)]\tLoss: 0.102054\n",
      "Train Epoch: 9 [2560/3910 (65%)]\tLoss: 0.010816\n",
      "Train Epoch: 9 [3200/3910 (81%)]\tLoss: 0.054264\n",
      "Train Epoch: 9 [3840/3910 (97%)]\tLoss: 0.014218\n",
      "Train Epoch: 10 [0/3910 (0%)]\tLoss: 0.019171\n",
      "Train Epoch: 10 [640/3910 (16%)]\tLoss: 0.020370\n",
      "Train Epoch: 10 [1280/3910 (32%)]\tLoss: 0.018482\n",
      "Train Epoch: 10 [1920/3910 (48%)]\tLoss: 0.009353\n",
      "Train Epoch: 10 [2560/3910 (65%)]\tLoss: 0.013784\n",
      "Train Epoch: 10 [3200/3910 (81%)]\tLoss: 0.003360\n",
      "Train Epoch: 10 [3840/3910 (97%)]\tLoss: 0.026948\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 0.144737\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 0.084464\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 0.099200\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 0.045930\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 0.050783\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 0.007072\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 0.191213\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 0.128419\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 0.019680\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 0.023555\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.063367\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.024148\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 0.021963\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 0.018669\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 0.064849\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.010074\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.067754\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.006340\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.034414\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.070351\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.055249\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.012050\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.024462\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.009530\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.061159\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.032236\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.011235\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.017952\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.000500\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.048845\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.021081\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.060513\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.013345\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.043113\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.007269\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.015482\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.034833\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.005040\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.043786\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.005684\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.017934\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.021744\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.014542\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.013213\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.009960\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.025508\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.000936\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.011813\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.057018\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.018197\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.005421\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.016425\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.018559\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.005073\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.024650\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.006230\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.020263\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.028234\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.029184\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.026898\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.046963\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.023443\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.014086\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.001991\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.013978\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.001462\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.066332\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.008322\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.040543\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.019949\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.007219\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.011570\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.041328\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.075270\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.010018\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.079243\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.045354\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.088710\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.004949\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.023343\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.003324\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.009021\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.004051\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.008200\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.009002\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.030465\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.019597\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.002277\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.016177\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.004427\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.014402\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.074472\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.015863\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.009597\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.115513\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.041282\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.078579\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.039691\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.021417\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.006725\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.035712\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.010042\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.054280\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.024327\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.004566\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.053924\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.026776\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.085549\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.051345\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.009761\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.078399\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.015125\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.081939\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.010269\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.000939\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.027827\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.000343\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.033333\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.014946\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.003376\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/5096 (0%)]\tLoss: 0.204368\n",
      "Train Epoch: 1 [640/5096 (12%)]\tLoss: 0.063129\n",
      "Train Epoch: 1 [1280/5096 (25%)]\tLoss: 0.068049\n",
      "Train Epoch: 1 [1920/5096 (38%)]\tLoss: 0.011512\n",
      "Train Epoch: 1 [2560/5096 (50%)]\tLoss: 0.006078\n",
      "Train Epoch: 1 [3200/5096 (62%)]\tLoss: 0.057215\n",
      "Train Epoch: 1 [3840/5096 (75%)]\tLoss: 0.013590\n",
      "Train Epoch: 1 [4480/5096 (88%)]\tLoss: 0.100990\n",
      "Train Epoch: 2 [0/5096 (0%)]\tLoss: 0.046385\n",
      "Train Epoch: 2 [640/5096 (12%)]\tLoss: 0.009345\n",
      "Train Epoch: 2 [1280/5096 (25%)]\tLoss: 0.096858\n",
      "Train Epoch: 2 [1920/5096 (38%)]\tLoss: 0.015878\n",
      "Train Epoch: 2 [2560/5096 (50%)]\tLoss: 0.018948\n",
      "Train Epoch: 2 [3200/5096 (62%)]\tLoss: 0.028132\n",
      "Train Epoch: 2 [3840/5096 (75%)]\tLoss: 0.016511\n",
      "Train Epoch: 2 [4480/5096 (88%)]\tLoss: 0.001047\n",
      "Train Epoch: 3 [0/5096 (0%)]\tLoss: 0.000568\n",
      "Train Epoch: 3 [640/5096 (12%)]\tLoss: 0.004012\n",
      "Train Epoch: 3 [1280/5096 (25%)]\tLoss: 0.036169\n",
      "Train Epoch: 3 [1920/5096 (38%)]\tLoss: 0.001680\n",
      "Train Epoch: 3 [2560/5096 (50%)]\tLoss: 0.012826\n",
      "Train Epoch: 3 [3200/5096 (62%)]\tLoss: 0.012914\n",
      "Train Epoch: 3 [3840/5096 (75%)]\tLoss: 0.010356\n",
      "Train Epoch: 3 [4480/5096 (88%)]\tLoss: 0.006838\n",
      "Train Epoch: 4 [0/5096 (0%)]\tLoss: 0.028641\n",
      "Train Epoch: 4 [640/5096 (12%)]\tLoss: 0.022418\n",
      "Train Epoch: 4 [1280/5096 (25%)]\tLoss: 0.019586\n",
      "Train Epoch: 4 [1920/5096 (38%)]\tLoss: 0.029553\n",
      "Train Epoch: 4 [2560/5096 (50%)]\tLoss: 0.016514\n",
      "Train Epoch: 4 [3200/5096 (62%)]\tLoss: 0.006324\n",
      "Train Epoch: 4 [3840/5096 (75%)]\tLoss: 0.004091\n",
      "Train Epoch: 4 [4480/5096 (88%)]\tLoss: 0.002825\n",
      "Train Epoch: 5 [0/5096 (0%)]\tLoss: 0.000613\n",
      "Train Epoch: 5 [640/5096 (12%)]\tLoss: 0.001883\n",
      "Train Epoch: 5 [1280/5096 (25%)]\tLoss: 0.009434\n",
      "Train Epoch: 5 [1920/5096 (38%)]\tLoss: 0.020990\n",
      "Train Epoch: 5 [2560/5096 (50%)]\tLoss: 0.009294\n",
      "Train Epoch: 5 [3200/5096 (62%)]\tLoss: 0.023858\n",
      "Train Epoch: 5 [3840/5096 (75%)]\tLoss: 0.007847\n",
      "Train Epoch: 5 [4480/5096 (88%)]\tLoss: 0.031826\n",
      "Train Epoch: 6 [0/5096 (0%)]\tLoss: 0.010400\n",
      "Train Epoch: 6 [640/5096 (12%)]\tLoss: 0.027866\n",
      "Train Epoch: 6 [1280/5096 (25%)]\tLoss: 0.112180\n",
      "Train Epoch: 6 [1920/5096 (38%)]\tLoss: 0.006213\n",
      "Train Epoch: 6 [2560/5096 (50%)]\tLoss: 0.018117\n",
      "Train Epoch: 6 [3200/5096 (62%)]\tLoss: 0.080577\n",
      "Train Epoch: 6 [3840/5096 (75%)]\tLoss: 0.016299\n",
      "Train Epoch: 6 [4480/5096 (88%)]\tLoss: 0.006948\n",
      "Train Epoch: 7 [0/5096 (0%)]\tLoss: 0.002557\n",
      "Train Epoch: 7 [640/5096 (12%)]\tLoss: 0.024460\n",
      "Train Epoch: 7 [1280/5096 (25%)]\tLoss: 0.009313\n",
      "Train Epoch: 7 [1920/5096 (38%)]\tLoss: 0.007404\n",
      "Train Epoch: 7 [2560/5096 (50%)]\tLoss: 0.002165\n",
      "Train Epoch: 7 [3200/5096 (62%)]\tLoss: 0.010907\n",
      "Train Epoch: 7 [3840/5096 (75%)]\tLoss: 0.002226\n",
      "Train Epoch: 7 [4480/5096 (88%)]\tLoss: 0.021234\n",
      "Train Epoch: 8 [0/5096 (0%)]\tLoss: 0.005909\n",
      "Train Epoch: 8 [640/5096 (12%)]\tLoss: 0.013698\n",
      "Train Epoch: 8 [1280/5096 (25%)]\tLoss: 0.021075\n",
      "Train Epoch: 8 [1920/5096 (38%)]\tLoss: 0.020170\n",
      "Train Epoch: 8 [2560/5096 (50%)]\tLoss: 0.063411\n",
      "Train Epoch: 8 [3200/5096 (62%)]\tLoss: 0.008641\n",
      "Train Epoch: 8 [3840/5096 (75%)]\tLoss: 0.046975\n",
      "Train Epoch: 8 [4480/5096 (88%)]\tLoss: 0.012127\n",
      "Train Epoch: 9 [0/5096 (0%)]\tLoss: 0.042660\n",
      "Train Epoch: 9 [640/5096 (12%)]\tLoss: 0.036552\n",
      "Train Epoch: 9 [1280/5096 (25%)]\tLoss: 0.027014\n",
      "Train Epoch: 9 [1920/5096 (38%)]\tLoss: 0.014105\n",
      "Train Epoch: 9 [2560/5096 (50%)]\tLoss: 0.226201\n",
      "Train Epoch: 9 [3200/5096 (62%)]\tLoss: 0.001545\n",
      "Train Epoch: 9 [3840/5096 (75%)]\tLoss: 0.011543\n",
      "Train Epoch: 9 [4480/5096 (88%)]\tLoss: 0.046903\n",
      "Train Epoch: 10 [0/5096 (0%)]\tLoss: 0.035499\n",
      "Train Epoch: 10 [640/5096 (12%)]\tLoss: 0.102548\n",
      "Train Epoch: 10 [1280/5096 (25%)]\tLoss: 0.015233\n",
      "Train Epoch: 10 [1920/5096 (38%)]\tLoss: 0.024572\n",
      "Train Epoch: 10 [2560/5096 (50%)]\tLoss: 0.002926\n",
      "Train Epoch: 10 [3200/5096 (62%)]\tLoss: 0.002759\n",
      "Train Epoch: 10 [3840/5096 (75%)]\tLoss: 0.007219\n",
      "Train Epoch: 10 [4480/5096 (88%)]\tLoss: 0.028123\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6865 (0%)]\tLoss: 0.122789\n",
      "Train Epoch: 1 [640/6865 (9%)]\tLoss: 0.192655\n",
      "Train Epoch: 1 [1280/6865 (19%)]\tLoss: 0.021466\n",
      "Train Epoch: 1 [1920/6865 (28%)]\tLoss: 0.003244\n",
      "Train Epoch: 1 [2560/6865 (37%)]\tLoss: 0.017545\n",
      "Train Epoch: 1 [3200/6865 (46%)]\tLoss: 0.007380\n",
      "Train Epoch: 1 [3840/6865 (56%)]\tLoss: 0.047749\n",
      "Train Epoch: 1 [4480/6865 (65%)]\tLoss: 0.032265\n",
      "Train Epoch: 1 [5120/6865 (74%)]\tLoss: 0.056229\n",
      "Train Epoch: 1 [5760/6865 (83%)]\tLoss: 0.008193\n",
      "Train Epoch: 1 [6400/6865 (93%)]\tLoss: 0.009081\n",
      "Train Epoch: 2 [0/6865 (0%)]\tLoss: 0.013113\n",
      "Train Epoch: 2 [640/6865 (9%)]\tLoss: 0.002186\n",
      "Train Epoch: 2 [1280/6865 (19%)]\tLoss: 0.025092\n",
      "Train Epoch: 2 [1920/6865 (28%)]\tLoss: 0.003407\n",
      "Train Epoch: 2 [2560/6865 (37%)]\tLoss: 0.004733\n",
      "Train Epoch: 2 [3200/6865 (46%)]\tLoss: 0.005770\n",
      "Train Epoch: 2 [3840/6865 (56%)]\tLoss: 0.003702\n",
      "Train Epoch: 2 [4480/6865 (65%)]\tLoss: 0.028506\n",
      "Train Epoch: 2 [5120/6865 (74%)]\tLoss: 0.047826\n",
      "Train Epoch: 2 [5760/6865 (83%)]\tLoss: 0.054766\n",
      "Train Epoch: 2 [6400/6865 (93%)]\tLoss: 0.051068\n",
      "Train Epoch: 3 [0/6865 (0%)]\tLoss: 0.000879\n",
      "Train Epoch: 3 [640/6865 (9%)]\tLoss: 0.046148\n",
      "Train Epoch: 3 [1280/6865 (19%)]\tLoss: 0.026434\n",
      "Train Epoch: 3 [1920/6865 (28%)]\tLoss: 0.005412\n",
      "Train Epoch: 3 [2560/6865 (37%)]\tLoss: 0.017898\n",
      "Train Epoch: 3 [3200/6865 (46%)]\tLoss: 0.069044\n",
      "Train Epoch: 3 [3840/6865 (56%)]\tLoss: 0.013328\n",
      "Train Epoch: 3 [4480/6865 (65%)]\tLoss: 0.024434\n",
      "Train Epoch: 3 [5120/6865 (74%)]\tLoss: 0.007401\n",
      "Train Epoch: 3 [5760/6865 (83%)]\tLoss: 0.004036\n",
      "Train Epoch: 3 [6400/6865 (93%)]\tLoss: 0.043053\n",
      "Train Epoch: 4 [0/6865 (0%)]\tLoss: 0.003545\n",
      "Train Epoch: 4 [640/6865 (9%)]\tLoss: 0.015124\n",
      "Train Epoch: 4 [1280/6865 (19%)]\tLoss: 0.098578\n",
      "Train Epoch: 4 [1920/6865 (28%)]\tLoss: 0.001550\n",
      "Train Epoch: 4 [2560/6865 (37%)]\tLoss: 0.020127\n",
      "Train Epoch: 4 [3200/6865 (46%)]\tLoss: 0.124930\n",
      "Train Epoch: 4 [3840/6865 (56%)]\tLoss: 0.005871\n",
      "Train Epoch: 4 [4480/6865 (65%)]\tLoss: 0.003291\n",
      "Train Epoch: 4 [5120/6865 (74%)]\tLoss: 0.189820\n",
      "Train Epoch: 4 [5760/6865 (83%)]\tLoss: 0.078815\n",
      "Train Epoch: 4 [6400/6865 (93%)]\tLoss: 0.012814\n",
      "Train Epoch: 5 [0/6865 (0%)]\tLoss: 0.007373\n",
      "Train Epoch: 5 [640/6865 (9%)]\tLoss: 0.005139\n",
      "Train Epoch: 5 [1280/6865 (19%)]\tLoss: 0.005993\n",
      "Train Epoch: 5 [1920/6865 (28%)]\tLoss: 0.023835\n",
      "Train Epoch: 5 [2560/6865 (37%)]\tLoss: 0.001080\n",
      "Train Epoch: 5 [3200/6865 (46%)]\tLoss: 0.020809\n",
      "Train Epoch: 5 [3840/6865 (56%)]\tLoss: 0.026035\n",
      "Train Epoch: 5 [4480/6865 (65%)]\tLoss: 0.003233\n",
      "Train Epoch: 5 [5120/6865 (74%)]\tLoss: 0.004257\n",
      "Train Epoch: 5 [5760/6865 (83%)]\tLoss: 0.003975\n",
      "Train Epoch: 5 [6400/6865 (93%)]\tLoss: 0.003011\n",
      "Train Epoch: 6 [0/6865 (0%)]\tLoss: 0.011182\n",
      "Train Epoch: 6 [640/6865 (9%)]\tLoss: 0.001878\n",
      "Train Epoch: 6 [1280/6865 (19%)]\tLoss: 0.042866\n",
      "Train Epoch: 6 [1920/6865 (28%)]\tLoss: 0.123795\n",
      "Train Epoch: 6 [2560/6865 (37%)]\tLoss: 0.064273\n",
      "Train Epoch: 6 [3200/6865 (46%)]\tLoss: 0.012031\n",
      "Train Epoch: 6 [3840/6865 (56%)]\tLoss: 0.013093\n",
      "Train Epoch: 6 [4480/6865 (65%)]\tLoss: 0.011290\n",
      "Train Epoch: 6 [5120/6865 (74%)]\tLoss: 0.014145\n",
      "Train Epoch: 6 [5760/6865 (83%)]\tLoss: 0.016691\n",
      "Train Epoch: 6 [6400/6865 (93%)]\tLoss: 0.013464\n",
      "Train Epoch: 7 [0/6865 (0%)]\tLoss: 0.006103\n",
      "Train Epoch: 7 [640/6865 (9%)]\tLoss: 0.015210\n",
      "Train Epoch: 7 [1280/6865 (19%)]\tLoss: 0.010029\n",
      "Train Epoch: 7 [1920/6865 (28%)]\tLoss: 0.018558\n",
      "Train Epoch: 7 [2560/6865 (37%)]\tLoss: 0.025815\n",
      "Train Epoch: 7 [3200/6865 (46%)]\tLoss: 0.040184\n",
      "Train Epoch: 7 [3840/6865 (56%)]\tLoss: 0.041559\n",
      "Train Epoch: 7 [4480/6865 (65%)]\tLoss: 0.048934\n",
      "Train Epoch: 7 [5120/6865 (74%)]\tLoss: 0.039861\n",
      "Train Epoch: 7 [5760/6865 (83%)]\tLoss: 0.017213\n",
      "Train Epoch: 7 [6400/6865 (93%)]\tLoss: 0.011874\n",
      "Train Epoch: 8 [0/6865 (0%)]\tLoss: 0.042955\n",
      "Train Epoch: 8 [640/6865 (9%)]\tLoss: 0.016911\n",
      "Train Epoch: 8 [1280/6865 (19%)]\tLoss: 0.071466\n",
      "Train Epoch: 8 [1920/6865 (28%)]\tLoss: 0.106106\n",
      "Train Epoch: 8 [2560/6865 (37%)]\tLoss: 0.038086\n",
      "Train Epoch: 8 [3200/6865 (46%)]\tLoss: 0.029010\n",
      "Train Epoch: 8 [3840/6865 (56%)]\tLoss: 0.000877\n",
      "Train Epoch: 8 [4480/6865 (65%)]\tLoss: 0.085735\n",
      "Train Epoch: 8 [5120/6865 (74%)]\tLoss: 0.019032\n",
      "Train Epoch: 8 [5760/6865 (83%)]\tLoss: 0.030837\n",
      "Train Epoch: 8 [6400/6865 (93%)]\tLoss: 0.041825\n",
      "Train Epoch: 9 [0/6865 (0%)]\tLoss: 0.007955\n",
      "Train Epoch: 9 [640/6865 (9%)]\tLoss: 0.026520\n",
      "Train Epoch: 9 [1280/6865 (19%)]\tLoss: 0.034693\n",
      "Train Epoch: 9 [1920/6865 (28%)]\tLoss: 0.011815\n",
      "Train Epoch: 9 [2560/6865 (37%)]\tLoss: 0.028654\n",
      "Train Epoch: 9 [3200/6865 (46%)]\tLoss: 0.030554\n",
      "Train Epoch: 9 [3840/6865 (56%)]\tLoss: 0.062153\n",
      "Train Epoch: 9 [4480/6865 (65%)]\tLoss: 0.091560\n",
      "Train Epoch: 9 [5120/6865 (74%)]\tLoss: 0.045229\n",
      "Train Epoch: 9 [5760/6865 (83%)]\tLoss: 0.008944\n",
      "Train Epoch: 9 [6400/6865 (93%)]\tLoss: 0.004350\n",
      "Train Epoch: 10 [0/6865 (0%)]\tLoss: 0.069409\n",
      "Train Epoch: 10 [640/6865 (9%)]\tLoss: 0.012779\n",
      "Train Epoch: 10 [1280/6865 (19%)]\tLoss: 0.060894\n",
      "Train Epoch: 10 [1920/6865 (28%)]\tLoss: 0.010427\n",
      "Train Epoch: 10 [2560/6865 (37%)]\tLoss: 0.000320\n",
      "Train Epoch: 10 [3200/6865 (46%)]\tLoss: 0.046627\n",
      "Train Epoch: 10 [3840/6865 (56%)]\tLoss: 0.017593\n",
      "Train Epoch: 10 [4480/6865 (65%)]\tLoss: 0.032585\n",
      "Train Epoch: 10 [5120/6865 (74%)]\tLoss: 0.052835\n",
      "Train Epoch: 10 [5760/6865 (83%)]\tLoss: 0.106833\n",
      "Train Epoch: 10 [6400/6865 (93%)]\tLoss: 0.056447\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.1300, Accuracy: 9891/10000 (99%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 0.075263\n",
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 0.054531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 0.094518\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 0.060182\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 0.100777\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 0.063787\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 0.035296\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 0.106922\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 0.040121\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 0.064635\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 0.118442\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 0.110322\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 0.042396\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 0.088665\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 0.094785\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 0.019728\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 0.009579\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 0.211988\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 0.061304\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 0.033393\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.040064\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 0.058555\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 0.013692\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.048813\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.053846\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 0.036178\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.076345\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 0.007155\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.057518\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.016018\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.066463\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.027370\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.021521\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.058335\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.034014\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.034395\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.028144\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.059759\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.069121\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.010089\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.117459\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.017395\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.055047\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.058822\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.032810\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.039045\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.050925\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.058411\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.060005\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.150094\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.028566\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.073631\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.009951\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.046450\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.015849\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.007047\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.010824\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.051456\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.021195\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.079212\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.284162\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.002218\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.025664\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.078981\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.006437\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.048965\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.081335\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.059200\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.057161\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.085996\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.093220\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.166161\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.080621\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.044134\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.156025\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.040013\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.038648\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.054071\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.005512\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.090812\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.007638\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.056911\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.048270\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.155519\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.032718\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.042120\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.039916\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.056174\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.004920\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.019013\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.024078\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.010875\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.073339\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.054238\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.118633\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.035782\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.035317\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.047085\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.014096\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.059228\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.093911\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.034449\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.023814\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.043214\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.269782\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.009361\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.019156\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.061183\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 0.001896\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.090244\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.050034\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.022571\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.034498\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.079327\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.032994\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.343484\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.020730\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.063937\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.032940\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.174397\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.036623\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.041781\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.053753\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.029808\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.065195\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.003415\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.045366\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.052922\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.177010\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.009806\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.025125\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.057370\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.086374\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.084006\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.076973\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.139453\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.042650\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.057394\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.013050\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.013423\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.016794\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.033206\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.064895\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.051640\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.036098\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.052741\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.028565\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.032003\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.182758\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.011676\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.039930\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.044789\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.091223\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.055990\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.021747\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.006370\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.010833\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.062792\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.015736\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.009635\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.110917\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.267474\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.024775\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.096073\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.009557\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.033272\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.060628\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.037592\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.005079\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.107872\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.006843\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.027635\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.010321\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.048969\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.072772\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.042807\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.006236\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.008493\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.032669\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.013978\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/5110 (0%)]\tLoss: 0.026004\n",
      "Train Epoch: 1 [640/5110 (12%)]\tLoss: 0.142032\n",
      "Train Epoch: 1 [1280/5110 (25%)]\tLoss: 0.042804\n",
      "Train Epoch: 1 [1920/5110 (38%)]\tLoss: 0.134821\n",
      "Train Epoch: 1 [2560/5110 (50%)]\tLoss: 0.152795\n",
      "Train Epoch: 1 [3200/5110 (62%)]\tLoss: 0.006627\n",
      "Train Epoch: 1 [3840/5110 (75%)]\tLoss: 0.045985\n",
      "Train Epoch: 1 [4480/5110 (88%)]\tLoss: 0.045494\n",
      "Train Epoch: 2 [0/5110 (0%)]\tLoss: 0.018892\n",
      "Train Epoch: 2 [640/5110 (12%)]\tLoss: 0.027843\n",
      "Train Epoch: 2 [1280/5110 (25%)]\tLoss: 0.035442\n",
      "Train Epoch: 2 [1920/5110 (38%)]\tLoss: 0.047400\n",
      "Train Epoch: 2 [2560/5110 (50%)]\tLoss: 0.111180\n",
      "Train Epoch: 2 [3200/5110 (62%)]\tLoss: 0.008409\n",
      "Train Epoch: 2 [3840/5110 (75%)]\tLoss: 0.044654\n",
      "Train Epoch: 2 [4480/5110 (88%)]\tLoss: 0.067846\n",
      "Train Epoch: 3 [0/5110 (0%)]\tLoss: 0.026529\n",
      "Train Epoch: 3 [640/5110 (12%)]\tLoss: 0.045877\n",
      "Train Epoch: 3 [1280/5110 (25%)]\tLoss: 0.060979\n",
      "Train Epoch: 3 [1920/5110 (38%)]\tLoss: 0.003015\n",
      "Train Epoch: 3 [2560/5110 (50%)]\tLoss: 0.048361\n",
      "Train Epoch: 3 [3200/5110 (62%)]\tLoss: 0.037684\n",
      "Train Epoch: 3 [3840/5110 (75%)]\tLoss: 0.014166\n",
      "Train Epoch: 3 [4480/5110 (88%)]\tLoss: 0.049311\n",
      "Train Epoch: 4 [0/5110 (0%)]\tLoss: 0.043861\n",
      "Train Epoch: 4 [640/5110 (12%)]\tLoss: 0.070113\n",
      "Train Epoch: 4 [1280/5110 (25%)]\tLoss: 0.080468\n",
      "Train Epoch: 4 [1920/5110 (38%)]\tLoss: 0.057979\n",
      "Train Epoch: 4 [2560/5110 (50%)]\tLoss: 0.010115\n",
      "Train Epoch: 4 [3200/5110 (62%)]\tLoss: 0.022673\n",
      "Train Epoch: 4 [3840/5110 (75%)]\tLoss: 0.022914\n",
      "Train Epoch: 4 [4480/5110 (88%)]\tLoss: 0.034755\n",
      "Train Epoch: 5 [0/5110 (0%)]\tLoss: 0.199773\n",
      "Train Epoch: 5 [640/5110 (12%)]\tLoss: 0.091785\n",
      "Train Epoch: 5 [1280/5110 (25%)]\tLoss: 0.047782\n",
      "Train Epoch: 5 [1920/5110 (38%)]\tLoss: 0.025220\n",
      "Train Epoch: 5 [2560/5110 (50%)]\tLoss: 0.027323\n",
      "Train Epoch: 5 [3200/5110 (62%)]\tLoss: 0.033335\n",
      "Train Epoch: 5 [3840/5110 (75%)]\tLoss: 0.020619\n",
      "Train Epoch: 5 [4480/5110 (88%)]\tLoss: 0.059695\n",
      "Train Epoch: 6 [0/5110 (0%)]\tLoss: 0.017062\n",
      "Train Epoch: 6 [640/5110 (12%)]\tLoss: 0.113909\n",
      "Train Epoch: 6 [1280/5110 (25%)]\tLoss: 0.141021\n",
      "Train Epoch: 6 [1920/5110 (38%)]\tLoss: 0.073159\n",
      "Train Epoch: 6 [2560/5110 (50%)]\tLoss: 0.040844\n",
      "Train Epoch: 6 [3200/5110 (62%)]\tLoss: 0.033611\n",
      "Train Epoch: 6 [3840/5110 (75%)]\tLoss: 0.064515\n",
      "Train Epoch: 6 [4480/5110 (88%)]\tLoss: 0.047061\n",
      "Train Epoch: 7 [0/5110 (0%)]\tLoss: 0.019362\n",
      "Train Epoch: 7 [640/5110 (12%)]\tLoss: 0.022268\n",
      "Train Epoch: 7 [1280/5110 (25%)]\tLoss: 0.196183\n",
      "Train Epoch: 7 [1920/5110 (38%)]\tLoss: 0.055233\n",
      "Train Epoch: 7 [2560/5110 (50%)]\tLoss: 0.017179\n",
      "Train Epoch: 7 [3200/5110 (62%)]\tLoss: 0.086564\n",
      "Train Epoch: 7 [3840/5110 (75%)]\tLoss: 0.021631\n",
      "Train Epoch: 7 [4480/5110 (88%)]\tLoss: 0.034205\n",
      "Train Epoch: 8 [0/5110 (0%)]\tLoss: 0.172433\n",
      "Train Epoch: 8 [640/5110 (12%)]\tLoss: 0.055998\n",
      "Train Epoch: 8 [1280/5110 (25%)]\tLoss: 0.069375\n",
      "Train Epoch: 8 [1920/5110 (38%)]\tLoss: 0.072817\n",
      "Train Epoch: 8 [2560/5110 (50%)]\tLoss: 0.004910\n",
      "Train Epoch: 8 [3200/5110 (62%)]\tLoss: 0.057756\n",
      "Train Epoch: 8 [3840/5110 (75%)]\tLoss: 0.013219\n",
      "Train Epoch: 8 [4480/5110 (88%)]\tLoss: 0.047107\n",
      "Train Epoch: 9 [0/5110 (0%)]\tLoss: 0.032907\n",
      "Train Epoch: 9 [640/5110 (12%)]\tLoss: 0.014381\n",
      "Train Epoch: 9 [1280/5110 (25%)]\tLoss: 0.025160\n",
      "Train Epoch: 9 [1920/5110 (38%)]\tLoss: 0.003334\n",
      "Train Epoch: 9 [2560/5110 (50%)]\tLoss: 0.008517\n",
      "Train Epoch: 9 [3200/5110 (62%)]\tLoss: 0.040609\n",
      "Train Epoch: 9 [3840/5110 (75%)]\tLoss: 0.016047\n",
      "Train Epoch: 9 [4480/5110 (88%)]\tLoss: 0.030030\n",
      "Train Epoch: 10 [0/5110 (0%)]\tLoss: 0.100219\n",
      "Train Epoch: 10 [640/5110 (12%)]\tLoss: 0.086696\n",
      "Train Epoch: 10 [1280/5110 (25%)]\tLoss: 0.015606\n",
      "Train Epoch: 10 [1920/5110 (38%)]\tLoss: 0.013475\n",
      "Train Epoch: 10 [2560/5110 (50%)]\tLoss: 0.032294\n",
      "Train Epoch: 10 [3200/5110 (62%)]\tLoss: 0.204756\n",
      "Train Epoch: 10 [3840/5110 (75%)]\tLoss: 0.022633\n",
      "Train Epoch: 10 [4480/5110 (88%)]\tLoss: 0.010309\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/10296 (0%)]\tLoss: 0.078609\n",
      "Train Epoch: 1 [640/10296 (6%)]\tLoss: 0.114398\n",
      "Train Epoch: 1 [1280/10296 (12%)]\tLoss: 0.010969\n",
      "Train Epoch: 1 [1920/10296 (19%)]\tLoss: 0.151440\n",
      "Train Epoch: 1 [2560/10296 (25%)]\tLoss: 0.076036\n",
      "Train Epoch: 1 [3200/10296 (31%)]\tLoss: 0.013565\n",
      "Train Epoch: 1 [3840/10296 (37%)]\tLoss: 0.084497\n",
      "Train Epoch: 1 [4480/10296 (43%)]\tLoss: 0.018281\n",
      "Train Epoch: 1 [5120/10296 (50%)]\tLoss: 0.075966\n",
      "Train Epoch: 1 [5760/10296 (56%)]\tLoss: 0.020479\n",
      "Train Epoch: 1 [6400/10296 (62%)]\tLoss: 0.129939\n",
      "Train Epoch: 1 [7040/10296 (68%)]\tLoss: 0.073418\n",
      "Train Epoch: 1 [7680/10296 (75%)]\tLoss: 0.016553\n",
      "Train Epoch: 1 [8320/10296 (81%)]\tLoss: 0.011280\n",
      "Train Epoch: 1 [8960/10296 (87%)]\tLoss: 0.014605\n",
      "Train Epoch: 1 [9600/10296 (93%)]\tLoss: 0.060850\n",
      "Train Epoch: 1 [8960/10296 (99%)]\tLoss: 0.027371\n",
      "Train Epoch: 2 [0/10296 (0%)]\tLoss: 0.036474\n",
      "Train Epoch: 2 [640/10296 (6%)]\tLoss: 0.097787\n",
      "Train Epoch: 2 [1280/10296 (12%)]\tLoss: 0.016574\n",
      "Train Epoch: 2 [1920/10296 (19%)]\tLoss: 0.082026\n",
      "Train Epoch: 2 [2560/10296 (25%)]\tLoss: 0.031635\n",
      "Train Epoch: 2 [3200/10296 (31%)]\tLoss: 0.078280\n",
      "Train Epoch: 2 [3840/10296 (37%)]\tLoss: 0.056002\n",
      "Train Epoch: 2 [4480/10296 (43%)]\tLoss: 0.093977\n",
      "Train Epoch: 2 [5120/10296 (50%)]\tLoss: 0.041077\n",
      "Train Epoch: 2 [5760/10296 (56%)]\tLoss: 0.059567\n",
      "Train Epoch: 2 [6400/10296 (62%)]\tLoss: 0.027799\n",
      "Train Epoch: 2 [7040/10296 (68%)]\tLoss: 0.051006\n",
      "Train Epoch: 2 [7680/10296 (75%)]\tLoss: 0.034890\n",
      "Train Epoch: 2 [8320/10296 (81%)]\tLoss: 0.026879\n",
      "Train Epoch: 2 [8960/10296 (87%)]\tLoss: 0.030931\n",
      "Train Epoch: 2 [9600/10296 (93%)]\tLoss: 0.004277\n",
      "Train Epoch: 2 [8960/10296 (99%)]\tLoss: 0.027402\n",
      "Train Epoch: 3 [0/10296 (0%)]\tLoss: 0.053848\n",
      "Train Epoch: 3 [640/10296 (6%)]\tLoss: 0.017989\n",
      "Train Epoch: 3 [1280/10296 (12%)]\tLoss: 0.063225\n",
      "Train Epoch: 3 [1920/10296 (19%)]\tLoss: 0.024535\n",
      "Train Epoch: 3 [2560/10296 (25%)]\tLoss: 0.040790\n",
      "Train Epoch: 3 [3200/10296 (31%)]\tLoss: 0.007208\n",
      "Train Epoch: 3 [3840/10296 (37%)]\tLoss: 0.042247\n",
      "Train Epoch: 3 [4480/10296 (43%)]\tLoss: 0.000092\n",
      "Train Epoch: 3 [5120/10296 (50%)]\tLoss: 0.005984\n",
      "Train Epoch: 3 [5760/10296 (56%)]\tLoss: 0.017360\n",
      "Train Epoch: 3 [6400/10296 (62%)]\tLoss: 0.003054\n",
      "Train Epoch: 3 [7040/10296 (68%)]\tLoss: 0.078922\n",
      "Train Epoch: 3 [7680/10296 (75%)]\tLoss: 0.006379\n",
      "Train Epoch: 3 [8320/10296 (81%)]\tLoss: 0.024728\n",
      "Train Epoch: 3 [8960/10296 (87%)]\tLoss: 0.044653\n",
      "Train Epoch: 3 [9600/10296 (93%)]\tLoss: 0.034550\n",
      "Train Epoch: 3 [8960/10296 (99%)]\tLoss: 0.020153\n",
      "Train Epoch: 4 [0/10296 (0%)]\tLoss: 0.079111\n",
      "Train Epoch: 4 [640/10296 (6%)]\tLoss: 0.108708\n",
      "Train Epoch: 4 [1280/10296 (12%)]\tLoss: 0.034770\n",
      "Train Epoch: 4 [1920/10296 (19%)]\tLoss: 0.168572\n",
      "Train Epoch: 4 [2560/10296 (25%)]\tLoss: 0.030702\n",
      "Train Epoch: 4 [3200/10296 (31%)]\tLoss: 0.020740\n",
      "Train Epoch: 4 [3840/10296 (37%)]\tLoss: 0.099607\n",
      "Train Epoch: 4 [4480/10296 (43%)]\tLoss: 0.102800\n",
      "Train Epoch: 4 [5120/10296 (50%)]\tLoss: 0.019799\n",
      "Train Epoch: 4 [5760/10296 (56%)]\tLoss: 0.008423\n",
      "Train Epoch: 4 [6400/10296 (62%)]\tLoss: 0.027641\n",
      "Train Epoch: 4 [7040/10296 (68%)]\tLoss: 0.107929\n",
      "Train Epoch: 4 [7680/10296 (75%)]\tLoss: 0.106575\n",
      "Train Epoch: 4 [8320/10296 (81%)]\tLoss: 0.060352\n",
      "Train Epoch: 4 [8960/10296 (87%)]\tLoss: 0.059560\n",
      "Train Epoch: 4 [9600/10296 (93%)]\tLoss: 0.065702\n",
      "Train Epoch: 4 [8960/10296 (99%)]\tLoss: 0.012803\n",
      "Train Epoch: 5 [0/10296 (0%)]\tLoss: 0.045577\n",
      "Train Epoch: 5 [640/10296 (6%)]\tLoss: 0.038163\n",
      "Train Epoch: 5 [1280/10296 (12%)]\tLoss: 0.041423\n",
      "Train Epoch: 5 [1920/10296 (19%)]\tLoss: 0.004417\n",
      "Train Epoch: 5 [2560/10296 (25%)]\tLoss: 0.053526\n",
      "Train Epoch: 5 [3200/10296 (31%)]\tLoss: 0.082000\n",
      "Train Epoch: 5 [3840/10296 (37%)]\tLoss: 0.089129\n",
      "Train Epoch: 5 [4480/10296 (43%)]\tLoss: 0.026613\n",
      "Train Epoch: 5 [5120/10296 (50%)]\tLoss: 0.143338\n",
      "Train Epoch: 5 [5760/10296 (56%)]\tLoss: 0.083810\n",
      "Train Epoch: 5 [6400/10296 (62%)]\tLoss: 0.002399\n",
      "Train Epoch: 5 [7040/10296 (68%)]\tLoss: 0.049637\n",
      "Train Epoch: 5 [7680/10296 (75%)]\tLoss: 0.024385\n",
      "Train Epoch: 5 [8320/10296 (81%)]\tLoss: 0.030423\n",
      "Train Epoch: 5 [8960/10296 (87%)]\tLoss: 0.190181\n",
      "Train Epoch: 5 [9600/10296 (93%)]\tLoss: 0.064181\n",
      "Train Epoch: 5 [8960/10296 (99%)]\tLoss: 0.032225\n",
      "Train Epoch: 6 [0/10296 (0%)]\tLoss: 0.016237\n",
      "Train Epoch: 6 [640/10296 (6%)]\tLoss: 0.015084\n",
      "Train Epoch: 6 [1280/10296 (12%)]\tLoss: 0.063232\n",
      "Train Epoch: 6 [1920/10296 (19%)]\tLoss: 0.019261\n",
      "Train Epoch: 6 [2560/10296 (25%)]\tLoss: 0.134197\n",
      "Train Epoch: 6 [3200/10296 (31%)]\tLoss: 0.135246\n",
      "Train Epoch: 6 [3840/10296 (37%)]\tLoss: 0.132734\n",
      "Train Epoch: 6 [4480/10296 (43%)]\tLoss: 0.018129\n",
      "Train Epoch: 6 [5120/10296 (50%)]\tLoss: 0.030809\n",
      "Train Epoch: 6 [5760/10296 (56%)]\tLoss: 0.006408\n",
      "Train Epoch: 6 [6400/10296 (62%)]\tLoss: 0.057629\n",
      "Train Epoch: 6 [7040/10296 (68%)]\tLoss: 0.024607\n",
      "Train Epoch: 6 [7680/10296 (75%)]\tLoss: 0.007424\n",
      "Train Epoch: 6 [8320/10296 (81%)]\tLoss: 0.005778\n",
      "Train Epoch: 6 [8960/10296 (87%)]\tLoss: 0.019910\n",
      "Train Epoch: 6 [9600/10296 (93%)]\tLoss: 0.002291\n",
      "Train Epoch: 6 [8960/10296 (99%)]\tLoss: 0.014425\n",
      "Train Epoch: 7 [0/10296 (0%)]\tLoss: 0.029796\n",
      "Train Epoch: 7 [640/10296 (6%)]\tLoss: 0.042539\n",
      "Train Epoch: 7 [1280/10296 (12%)]\tLoss: 0.047327\n",
      "Train Epoch: 7 [1920/10296 (19%)]\tLoss: 0.076240\n",
      "Train Epoch: 7 [2560/10296 (25%)]\tLoss: 0.077309\n",
      "Train Epoch: 7 [3200/10296 (31%)]\tLoss: 0.014429\n",
      "Train Epoch: 7 [3840/10296 (37%)]\tLoss: 0.010138\n",
      "Train Epoch: 7 [4480/10296 (43%)]\tLoss: 0.004699\n",
      "Train Epoch: 7 [5120/10296 (50%)]\tLoss: 0.092560\n",
      "Train Epoch: 7 [5760/10296 (56%)]\tLoss: 0.024083\n",
      "Train Epoch: 7 [6400/10296 (62%)]\tLoss: 0.041578\n",
      "Train Epoch: 7 [7040/10296 (68%)]\tLoss: 0.008481\n",
      "Train Epoch: 7 [7680/10296 (75%)]\tLoss: 0.106167\n",
      "Train Epoch: 7 [8320/10296 (81%)]\tLoss: 0.007533\n",
      "Train Epoch: 7 [8960/10296 (87%)]\tLoss: 0.007677\n",
      "Train Epoch: 7 [9600/10296 (93%)]\tLoss: 0.019500\n",
      "Train Epoch: 7 [8960/10296 (99%)]\tLoss: 0.023745\n",
      "Train Epoch: 8 [0/10296 (0%)]\tLoss: 0.180451\n",
      "Train Epoch: 8 [640/10296 (6%)]\tLoss: 0.007086\n",
      "Train Epoch: 8 [1280/10296 (12%)]\tLoss: 0.056401\n",
      "Train Epoch: 8 [1920/10296 (19%)]\tLoss: 0.079453\n",
      "Train Epoch: 8 [2560/10296 (25%)]\tLoss: 0.005361\n",
      "Train Epoch: 8 [3200/10296 (31%)]\tLoss: 0.069501\n",
      "Train Epoch: 8 [3840/10296 (37%)]\tLoss: 0.056918\n",
      "Train Epoch: 8 [4480/10296 (43%)]\tLoss: 0.056396\n",
      "Train Epoch: 8 [5120/10296 (50%)]\tLoss: 0.194550\n",
      "Train Epoch: 8 [5760/10296 (56%)]\tLoss: 0.010183\n",
      "Train Epoch: 8 [6400/10296 (62%)]\tLoss: 0.009412\n",
      "Train Epoch: 8 [7040/10296 (68%)]\tLoss: 0.047817\n",
      "Train Epoch: 8 [7680/10296 (75%)]\tLoss: 0.051628\n",
      "Train Epoch: 8 [8320/10296 (81%)]\tLoss: 0.047585\n",
      "Train Epoch: 8 [8960/10296 (87%)]\tLoss: 0.035466\n",
      "Train Epoch: 8 [9600/10296 (93%)]\tLoss: 0.055153\n",
      "Train Epoch: 8 [8960/10296 (99%)]\tLoss: 0.028509\n",
      "Train Epoch: 9 [0/10296 (0%)]\tLoss: 0.042608\n",
      "Train Epoch: 9 [640/10296 (6%)]\tLoss: 0.165942\n",
      "Train Epoch: 9 [1280/10296 (12%)]\tLoss: 0.082175\n",
      "Train Epoch: 9 [1920/10296 (19%)]\tLoss: 0.150542\n",
      "Train Epoch: 9 [2560/10296 (25%)]\tLoss: 0.008047\n",
      "Train Epoch: 9 [3200/10296 (31%)]\tLoss: 0.035870\n",
      "Train Epoch: 9 [3840/10296 (37%)]\tLoss: 0.069426\n",
      "Train Epoch: 9 [4480/10296 (43%)]\tLoss: 0.021221\n",
      "Train Epoch: 9 [5120/10296 (50%)]\tLoss: 0.047302\n",
      "Train Epoch: 9 [5760/10296 (56%)]\tLoss: 0.137053\n",
      "Train Epoch: 9 [6400/10296 (62%)]\tLoss: 0.013843\n",
      "Train Epoch: 9 [7040/10296 (68%)]\tLoss: 0.034044\n",
      "Train Epoch: 9 [7680/10296 (75%)]\tLoss: 0.169389\n",
      "Train Epoch: 9 [8320/10296 (81%)]\tLoss: 0.002988\n",
      "Train Epoch: 9 [8960/10296 (87%)]\tLoss: 0.007392\n",
      "Train Epoch: 9 [9600/10296 (93%)]\tLoss: 0.024567\n",
      "Train Epoch: 9 [8960/10296 (99%)]\tLoss: 0.097668\n",
      "Train Epoch: 10 [0/10296 (0%)]\tLoss: 0.078219\n",
      "Train Epoch: 10 [640/10296 (6%)]\tLoss: 0.115496\n",
      "Train Epoch: 10 [1280/10296 (12%)]\tLoss: 0.050126\n",
      "Train Epoch: 10 [1920/10296 (19%)]\tLoss: 0.032982\n",
      "Train Epoch: 10 [2560/10296 (25%)]\tLoss: 0.040604\n",
      "Train Epoch: 10 [3200/10296 (31%)]\tLoss: 0.040344\n",
      "Train Epoch: 10 [3840/10296 (37%)]\tLoss: 0.019415\n",
      "Train Epoch: 10 [4480/10296 (43%)]\tLoss: 0.020026\n",
      "Train Epoch: 10 [5120/10296 (50%)]\tLoss: 0.002505\n",
      "Train Epoch: 10 [5760/10296 (56%)]\tLoss: 0.048540\n",
      "Train Epoch: 10 [6400/10296 (62%)]\tLoss: 0.058639\n",
      "Train Epoch: 10 [7040/10296 (68%)]\tLoss: 0.039306\n",
      "Train Epoch: 10 [7680/10296 (75%)]\tLoss: 0.092125\n",
      "Train Epoch: 10 [8320/10296 (81%)]\tLoss: 0.062712\n",
      "Train Epoch: 10 [8960/10296 (87%)]\tLoss: 0.108148\n",
      "Train Epoch: 10 [9600/10296 (93%)]\tLoss: 0.061511\n",
      "Train Epoch: 10 [8960/10296 (99%)]\tLoss: 0.121314\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 0.010606\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 0.138797\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 0.038557\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 0.225897\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 0.163988\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 0.260034\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 0.010528\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 0.024310\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 0.021544\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 0.084236\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 0.004429\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 0.037894\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 0.012352\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 0.163819\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 0.056754\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 0.038749\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 0.013756\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.016542\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.123298\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.023999\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.034607\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.102026\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.015722\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.023411\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.085510\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.262888\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.107063\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.026373\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.071520\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.213712\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.045222\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.054109\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.130742\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.077872\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.017020\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.005603\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.034581\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.014459\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.013478\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.119810\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.041470\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.015793\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.056322\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.041075\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.009098\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.010574\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.070989\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.056714\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.099017\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.008121\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.022386\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.021419\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.131493\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.005844\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.029525\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.026077\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.038922\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.023081\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.052614\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.060246\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.026790\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.013996\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.020440\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.036192\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.020048\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.005500\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.117303\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.053018\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.102913\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.012519\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.061352\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.087172\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.012275\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.008665\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.057790\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.006383\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.009637\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.099025\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.015130\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.030512\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.033803\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.006301\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.030904\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.008475\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.052629\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.109524\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.027725\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.007095\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.072124\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.040703\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.030096\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.023696\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.091076\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.017454\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.007855\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.053954\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.002194\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.021126\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.002151\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.009954\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.014957\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.057415\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.026027\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.100334\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.027273\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.044177\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.013617\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.037111\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.001166\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.010759\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.004438\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.054692\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.053910\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.016267\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.034398\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.047934\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.107014\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.037717\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.045422\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.096768\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.032357\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.012334\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.024710\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.027174\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.012524\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.078668\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.109138\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.043047\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.137018\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.012283\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.036655\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.050670\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.034156\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.017795\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.003030\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.007140\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.020753\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.021952\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.010264\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.055877\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.035521\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.018573\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.082710\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.045464\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.031795\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.004129\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.015832\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.011472\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.042620\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.059947\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.051875\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.032705\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.065102\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.024879\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.008734\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.037035\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.077476\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.016191\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.020902\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.058800\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/3910 (0%)]\tLoss: 0.315602\n",
      "Train Epoch: 1 [640/3910 (16%)]\tLoss: 0.064531\n",
      "Train Epoch: 1 [1280/3910 (32%)]\tLoss: 0.046964\n",
      "Train Epoch: 1 [1920/3910 (48%)]\tLoss: 0.033007\n",
      "Train Epoch: 1 [2560/3910 (65%)]\tLoss: 0.028613\n",
      "Train Epoch: 1 [3200/3910 (81%)]\tLoss: 0.034691\n",
      "Train Epoch: 1 [3840/3910 (97%)]\tLoss: 0.008927\n",
      "Train Epoch: 2 [0/3910 (0%)]\tLoss: 0.040479\n",
      "Train Epoch: 2 [640/3910 (16%)]\tLoss: 0.082955\n",
      "Train Epoch: 2 [1280/3910 (32%)]\tLoss: 0.106022\n",
      "Train Epoch: 2 [1920/3910 (48%)]\tLoss: 0.005405\n",
      "Train Epoch: 2 [2560/3910 (65%)]\tLoss: 0.110028\n",
      "Train Epoch: 2 [3200/3910 (81%)]\tLoss: 0.037842\n",
      "Train Epoch: 2 [3840/3910 (97%)]\tLoss: 0.013233\n",
      "Train Epoch: 3 [0/3910 (0%)]\tLoss: 0.011323\n",
      "Train Epoch: 3 [640/3910 (16%)]\tLoss: 0.107576\n",
      "Train Epoch: 3 [1280/3910 (32%)]\tLoss: 0.113352\n",
      "Train Epoch: 3 [1920/3910 (48%)]\tLoss: 0.053289\n",
      "Train Epoch: 3 [2560/3910 (65%)]\tLoss: 0.016548\n",
      "Train Epoch: 3 [3200/3910 (81%)]\tLoss: 0.006779\n",
      "Train Epoch: 3 [3840/3910 (97%)]\tLoss: 0.039697\n",
      "Train Epoch: 4 [0/3910 (0%)]\tLoss: 0.078990\n",
      "Train Epoch: 4 [640/3910 (16%)]\tLoss: 0.036202\n",
      "Train Epoch: 4 [1280/3910 (32%)]\tLoss: 0.073624\n",
      "Train Epoch: 4 [1920/3910 (48%)]\tLoss: 0.023481\n",
      "Train Epoch: 4 [2560/3910 (65%)]\tLoss: 0.051061\n",
      "Train Epoch: 4 [3200/3910 (81%)]\tLoss: 0.038810\n",
      "Train Epoch: 4 [3840/3910 (97%)]\tLoss: 0.064049\n",
      "Train Epoch: 5 [0/3910 (0%)]\tLoss: 0.035113\n",
      "Train Epoch: 5 [640/3910 (16%)]\tLoss: 0.065877\n",
      "Train Epoch: 5 [1280/3910 (32%)]\tLoss: 0.066017\n",
      "Train Epoch: 5 [1920/3910 (48%)]\tLoss: 0.002978\n",
      "Train Epoch: 5 [2560/3910 (65%)]\tLoss: 0.016509\n",
      "Train Epoch: 5 [3200/3910 (81%)]\tLoss: 0.035881\n",
      "Train Epoch: 5 [3840/3910 (97%)]\tLoss: 0.018264\n",
      "Train Epoch: 6 [0/3910 (0%)]\tLoss: 0.173172\n",
      "Train Epoch: 6 [640/3910 (16%)]\tLoss: 0.082216\n",
      "Train Epoch: 6 [1280/3910 (32%)]\tLoss: 0.135020\n",
      "Train Epoch: 6 [1920/3910 (48%)]\tLoss: 0.062837\n",
      "Train Epoch: 6 [2560/3910 (65%)]\tLoss: 0.030927\n",
      "Train Epoch: 6 [3200/3910 (81%)]\tLoss: 0.030752\n",
      "Train Epoch: 6 [3840/3910 (97%)]\tLoss: 0.008406\n",
      "Train Epoch: 7 [0/3910 (0%)]\tLoss: 0.016462\n",
      "Train Epoch: 7 [640/3910 (16%)]\tLoss: 0.018081\n",
      "Train Epoch: 7 [1280/3910 (32%)]\tLoss: 0.081806\n",
      "Train Epoch: 7 [1920/3910 (48%)]\tLoss: 0.020192\n",
      "Train Epoch: 7 [2560/3910 (65%)]\tLoss: 0.028608\n",
      "Train Epoch: 7 [3200/3910 (81%)]\tLoss: 0.058879\n",
      "Train Epoch: 7 [3840/3910 (97%)]\tLoss: 0.023000\n",
      "Train Epoch: 8 [0/3910 (0%)]\tLoss: 0.024461\n",
      "Train Epoch: 8 [640/3910 (16%)]\tLoss: 0.074083\n",
      "Train Epoch: 8 [1280/3910 (32%)]\tLoss: 0.109592\n",
      "Train Epoch: 8 [1920/3910 (48%)]\tLoss: 0.047662\n",
      "Train Epoch: 8 [2560/3910 (65%)]\tLoss: 0.033854\n",
      "Train Epoch: 8 [3200/3910 (81%)]\tLoss: 0.091367\n",
      "Train Epoch: 8 [3840/3910 (97%)]\tLoss: 0.054186\n",
      "Train Epoch: 9 [0/3910 (0%)]\tLoss: 0.014020\n",
      "Train Epoch: 9 [640/3910 (16%)]\tLoss: 0.109019\n",
      "Train Epoch: 9 [1280/3910 (32%)]\tLoss: 0.019081\n",
      "Train Epoch: 9 [1920/3910 (48%)]\tLoss: 0.015110\n",
      "Train Epoch: 9 [2560/3910 (65%)]\tLoss: 0.084591\n",
      "Train Epoch: 9 [3200/3910 (81%)]\tLoss: 0.016613\n",
      "Train Epoch: 9 [3840/3910 (97%)]\tLoss: 0.012065\n",
      "Train Epoch: 10 [0/3910 (0%)]\tLoss: 0.133735\n",
      "Train Epoch: 10 [640/3910 (16%)]\tLoss: 0.094297\n",
      "Train Epoch: 10 [1280/3910 (32%)]\tLoss: 0.007752\n",
      "Train Epoch: 10 [1920/3910 (48%)]\tLoss: 0.026786\n",
      "Train Epoch: 10 [2560/3910 (65%)]\tLoss: 0.031338\n",
      "Train Epoch: 10 [3200/3910 (81%)]\tLoss: 0.020578\n",
      "Train Epoch: 10 [3840/3910 (97%)]\tLoss: 0.043308\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 0.114647\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 0.054015\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 0.083740\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 0.053091\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 0.013531\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 0.007432\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 0.016060\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 0.029007\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 0.001098\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 0.000723\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.086794\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.043379\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 0.011040\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 0.012339\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 0.199544\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.039075\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.013905\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.139624\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.043695\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.006594\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.042527\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.058147\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.022518\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.110196\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.018751\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.038362\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.012715\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.027738\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.106441\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.002832\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.001391\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.004541\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.058817\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.125663\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.005724\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.033977\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.050481\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.027310\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.013418\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.056466\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.018230\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.016608\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.016149\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.031017\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.062361\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.010453\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.029927\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.012189\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.032345\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.067070\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.040129\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.021934\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.063139\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.068611\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.066744\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.006401\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.112270\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.067268\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.014281\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.070666\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.036603\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.039674\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.062241\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.028095\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.030186\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.029508\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.062943\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.041921\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.005049\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.024427\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.043883\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.129615\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.075094\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.024235\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.074521\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.048854\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.018370\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.023260\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.006348\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.007588\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.108877\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.003086\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.014012\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.019538\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.015143\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.066213\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.001401\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.031858\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.017781\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.076101\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.012222\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.046002\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.020226\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.070399\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.009233\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.001074\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.059301\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.095921\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.056668\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.018123\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.065950\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.021673\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.008333\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.034075\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.005830\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.027355\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.007365\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.021905\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.014578\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.065169\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.009996\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.027297\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.002805\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.053150\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.012570\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.021268\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.022799\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.001551\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.012652\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.004970\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/5096 (0%)]\tLoss: 0.028216\n",
      "Train Epoch: 1 [640/5096 (12%)]\tLoss: 0.042345\n",
      "Train Epoch: 1 [1280/5096 (25%)]\tLoss: 0.064871\n",
      "Train Epoch: 1 [1920/5096 (38%)]\tLoss: 0.054300\n",
      "Train Epoch: 1 [2560/5096 (50%)]\tLoss: 0.022522\n",
      "Train Epoch: 1 [3200/5096 (62%)]\tLoss: 0.030405\n",
      "Train Epoch: 1 [3840/5096 (75%)]\tLoss: 0.019267\n",
      "Train Epoch: 1 [4480/5096 (88%)]\tLoss: 0.042293\n",
      "Train Epoch: 2 [0/5096 (0%)]\tLoss: 0.002411\n",
      "Train Epoch: 2 [640/5096 (12%)]\tLoss: 0.136376\n",
      "Train Epoch: 2 [1280/5096 (25%)]\tLoss: 0.004920\n",
      "Train Epoch: 2 [1920/5096 (38%)]\tLoss: 0.042289\n",
      "Train Epoch: 2 [2560/5096 (50%)]\tLoss: 0.014573\n",
      "Train Epoch: 2 [3200/5096 (62%)]\tLoss: 0.029828\n",
      "Train Epoch: 2 [3840/5096 (75%)]\tLoss: 0.141275\n",
      "Train Epoch: 2 [4480/5096 (88%)]\tLoss: 0.010870\n",
      "Train Epoch: 3 [0/5096 (0%)]\tLoss: 0.046912\n",
      "Train Epoch: 3 [640/5096 (12%)]\tLoss: 0.008168\n",
      "Train Epoch: 3 [1280/5096 (25%)]\tLoss: 0.007324\n",
      "Train Epoch: 3 [1920/5096 (38%)]\tLoss: 0.007526\n",
      "Train Epoch: 3 [2560/5096 (50%)]\tLoss: 0.096511\n",
      "Train Epoch: 3 [3200/5096 (62%)]\tLoss: 0.005758\n",
      "Train Epoch: 3 [3840/5096 (75%)]\tLoss: 0.022678\n",
      "Train Epoch: 3 [4480/5096 (88%)]\tLoss: 0.011993\n",
      "Train Epoch: 4 [0/5096 (0%)]\tLoss: 0.006091\n",
      "Train Epoch: 4 [640/5096 (12%)]\tLoss: 0.037673\n",
      "Train Epoch: 4 [1280/5096 (25%)]\tLoss: 0.055447\n",
      "Train Epoch: 4 [1920/5096 (38%)]\tLoss: 0.028766\n",
      "Train Epoch: 4 [2560/5096 (50%)]\tLoss: 0.011313\n",
      "Train Epoch: 4 [3200/5096 (62%)]\tLoss: 0.001028\n",
      "Train Epoch: 4 [3840/5096 (75%)]\tLoss: 0.058186\n",
      "Train Epoch: 4 [4480/5096 (88%)]\tLoss: 0.009820\n",
      "Train Epoch: 5 [0/5096 (0%)]\tLoss: 0.044679\n",
      "Train Epoch: 5 [640/5096 (12%)]\tLoss: 0.020900\n",
      "Train Epoch: 5 [1280/5096 (25%)]\tLoss: 0.046756\n",
      "Train Epoch: 5 [1920/5096 (38%)]\tLoss: 0.005876\n",
      "Train Epoch: 5 [2560/5096 (50%)]\tLoss: 0.045091\n",
      "Train Epoch: 5 [3200/5096 (62%)]\tLoss: 0.019558\n",
      "Train Epoch: 5 [3840/5096 (75%)]\tLoss: 0.061383\n",
      "Train Epoch: 5 [4480/5096 (88%)]\tLoss: 0.004531\n",
      "Train Epoch: 6 [0/5096 (0%)]\tLoss: 0.008209\n",
      "Train Epoch: 6 [640/5096 (12%)]\tLoss: 0.011534\n",
      "Train Epoch: 6 [1280/5096 (25%)]\tLoss: 0.017502\n",
      "Train Epoch: 6 [1920/5096 (38%)]\tLoss: 0.029538\n",
      "Train Epoch: 6 [2560/5096 (50%)]\tLoss: 0.123877\n",
      "Train Epoch: 6 [3200/5096 (62%)]\tLoss: 0.029213\n",
      "Train Epoch: 6 [3840/5096 (75%)]\tLoss: 0.023735\n",
      "Train Epoch: 6 [4480/5096 (88%)]\tLoss: 0.003123\n",
      "Train Epoch: 7 [0/5096 (0%)]\tLoss: 0.008328\n",
      "Train Epoch: 7 [640/5096 (12%)]\tLoss: 0.001193\n",
      "Train Epoch: 7 [1280/5096 (25%)]\tLoss: 0.000494\n",
      "Train Epoch: 7 [1920/5096 (38%)]\tLoss: 0.007444\n",
      "Train Epoch: 7 [2560/5096 (50%)]\tLoss: 0.059174\n",
      "Train Epoch: 7 [3200/5096 (62%)]\tLoss: 0.001510\n",
      "Train Epoch: 7 [3840/5096 (75%)]\tLoss: 0.073269\n",
      "Train Epoch: 7 [4480/5096 (88%)]\tLoss: 0.029750\n",
      "Train Epoch: 8 [0/5096 (0%)]\tLoss: 0.051336\n",
      "Train Epoch: 8 [640/5096 (12%)]\tLoss: 0.001073\n",
      "Train Epoch: 8 [1280/5096 (25%)]\tLoss: 0.026611\n",
      "Train Epoch: 8 [1920/5096 (38%)]\tLoss: 0.006058\n",
      "Train Epoch: 8 [2560/5096 (50%)]\tLoss: 0.010830\n",
      "Train Epoch: 8 [3200/5096 (62%)]\tLoss: 0.000371\n",
      "Train Epoch: 8 [3840/5096 (75%)]\tLoss: 0.016617\n",
      "Train Epoch: 8 [4480/5096 (88%)]\tLoss: 0.005367\n",
      "Train Epoch: 9 [0/5096 (0%)]\tLoss: 0.030718\n",
      "Train Epoch: 9 [640/5096 (12%)]\tLoss: 0.000655\n",
      "Train Epoch: 9 [1280/5096 (25%)]\tLoss: 0.031680\n",
      "Train Epoch: 9 [1920/5096 (38%)]\tLoss: 0.060580\n",
      "Train Epoch: 9 [2560/5096 (50%)]\tLoss: 0.009481\n",
      "Train Epoch: 9 [3200/5096 (62%)]\tLoss: 0.029499\n",
      "Train Epoch: 9 [3840/5096 (75%)]\tLoss: 0.038067\n",
      "Train Epoch: 9 [4480/5096 (88%)]\tLoss: 0.056879\n",
      "Train Epoch: 10 [0/5096 (0%)]\tLoss: 0.011930\n",
      "Train Epoch: 10 [640/5096 (12%)]\tLoss: 0.095067\n",
      "Train Epoch: 10 [1280/5096 (25%)]\tLoss: 0.056662\n",
      "Train Epoch: 10 [1920/5096 (38%)]\tLoss: 0.014167\n",
      "Train Epoch: 10 [2560/5096 (50%)]\tLoss: 0.042239\n",
      "Train Epoch: 10 [3200/5096 (62%)]\tLoss: 0.018858\n",
      "Train Epoch: 10 [3840/5096 (75%)]\tLoss: 0.009338\n",
      "Train Epoch: 10 [4480/5096 (88%)]\tLoss: 0.005349\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6865 (0%)]\tLoss: 0.126787\n",
      "Train Epoch: 1 [640/6865 (9%)]\tLoss: 0.050118\n",
      "Train Epoch: 1 [1280/6865 (19%)]\tLoss: 0.006386\n",
      "Train Epoch: 1 [1920/6865 (28%)]\tLoss: 0.074203\n",
      "Train Epoch: 1 [2560/6865 (37%)]\tLoss: 0.045395\n",
      "Train Epoch: 1 [3200/6865 (46%)]\tLoss: 0.104834\n",
      "Train Epoch: 1 [3840/6865 (56%)]\tLoss: 0.034823\n",
      "Train Epoch: 1 [4480/6865 (65%)]\tLoss: 0.144031\n",
      "Train Epoch: 1 [5120/6865 (74%)]\tLoss: 0.010868\n",
      "Train Epoch: 1 [5760/6865 (83%)]\tLoss: 0.039617\n",
      "Train Epoch: 1 [6400/6865 (93%)]\tLoss: 0.099307\n",
      "Train Epoch: 2 [0/6865 (0%)]\tLoss: 0.019314\n",
      "Train Epoch: 2 [640/6865 (9%)]\tLoss: 0.020755\n",
      "Train Epoch: 2 [1280/6865 (19%)]\tLoss: 0.096449\n",
      "Train Epoch: 2 [1920/6865 (28%)]\tLoss: 0.059523\n",
      "Train Epoch: 2 [2560/6865 (37%)]\tLoss: 0.032377\n",
      "Train Epoch: 2 [3200/6865 (46%)]\tLoss: 0.008972\n",
      "Train Epoch: 2 [3840/6865 (56%)]\tLoss: 0.035695\n",
      "Train Epoch: 2 [4480/6865 (65%)]\tLoss: 0.015054\n",
      "Train Epoch: 2 [5120/6865 (74%)]\tLoss: 0.053540\n",
      "Train Epoch: 2 [5760/6865 (83%)]\tLoss: 0.136726\n",
      "Train Epoch: 2 [6400/6865 (93%)]\tLoss: 0.054723\n",
      "Train Epoch: 3 [0/6865 (0%)]\tLoss: 0.070838\n",
      "Train Epoch: 3 [640/6865 (9%)]\tLoss: 0.055861\n",
      "Train Epoch: 3 [1280/6865 (19%)]\tLoss: 0.106085\n",
      "Train Epoch: 3 [1920/6865 (28%)]\tLoss: 0.011249\n",
      "Train Epoch: 3 [2560/6865 (37%)]\tLoss: 0.085813\n",
      "Train Epoch: 3 [3200/6865 (46%)]\tLoss: 0.003898\n",
      "Train Epoch: 3 [3840/6865 (56%)]\tLoss: 0.131457\n",
      "Train Epoch: 3 [4480/6865 (65%)]\tLoss: 0.032826\n",
      "Train Epoch: 3 [5120/6865 (74%)]\tLoss: 0.071799\n",
      "Train Epoch: 3 [5760/6865 (83%)]\tLoss: 0.056131\n",
      "Train Epoch: 3 [6400/6865 (93%)]\tLoss: 0.082858\n",
      "Train Epoch: 4 [0/6865 (0%)]\tLoss: 0.043337\n",
      "Train Epoch: 4 [640/6865 (9%)]\tLoss: 0.037169\n",
      "Train Epoch: 4 [1280/6865 (19%)]\tLoss: 0.042574\n",
      "Train Epoch: 4 [1920/6865 (28%)]\tLoss: 0.006220\n",
      "Train Epoch: 4 [2560/6865 (37%)]\tLoss: 0.039277\n",
      "Train Epoch: 4 [3200/6865 (46%)]\tLoss: 0.032908\n",
      "Train Epoch: 4 [3840/6865 (56%)]\tLoss: 0.025065\n",
      "Train Epoch: 4 [4480/6865 (65%)]\tLoss: 0.008176\n",
      "Train Epoch: 4 [5120/6865 (74%)]\tLoss: 0.059716\n",
      "Train Epoch: 4 [5760/6865 (83%)]\tLoss: 0.031463\n",
      "Train Epoch: 4 [6400/6865 (93%)]\tLoss: 0.037071\n",
      "Train Epoch: 5 [0/6865 (0%)]\tLoss: 0.011441\n",
      "Train Epoch: 5 [640/6865 (9%)]\tLoss: 0.009196\n",
      "Train Epoch: 5 [1280/6865 (19%)]\tLoss: 0.011101\n",
      "Train Epoch: 5 [1920/6865 (28%)]\tLoss: 0.009217\n",
      "Train Epoch: 5 [2560/6865 (37%)]\tLoss: 0.005604\n",
      "Train Epoch: 5 [3200/6865 (46%)]\tLoss: 0.005604\n",
      "Train Epoch: 5 [3840/6865 (56%)]\tLoss: 0.014002\n",
      "Train Epoch: 5 [4480/6865 (65%)]\tLoss: 0.075816\n",
      "Train Epoch: 5 [5120/6865 (74%)]\tLoss: 0.062775\n",
      "Train Epoch: 5 [5760/6865 (83%)]\tLoss: 0.015318\n",
      "Train Epoch: 5 [6400/6865 (93%)]\tLoss: 0.078843\n",
      "Train Epoch: 6 [0/6865 (0%)]\tLoss: 0.056917\n",
      "Train Epoch: 6 [640/6865 (9%)]\tLoss: 0.053711\n",
      "Train Epoch: 6 [1280/6865 (19%)]\tLoss: 0.003229\n",
      "Train Epoch: 6 [1920/6865 (28%)]\tLoss: 0.012310\n",
      "Train Epoch: 6 [2560/6865 (37%)]\tLoss: 0.013578\n",
      "Train Epoch: 6 [3200/6865 (46%)]\tLoss: 0.026799\n",
      "Train Epoch: 6 [3840/6865 (56%)]\tLoss: 0.039032\n",
      "Train Epoch: 6 [4480/6865 (65%)]\tLoss: 0.010967\n",
      "Train Epoch: 6 [5120/6865 (74%)]\tLoss: 0.010878\n",
      "Train Epoch: 6 [5760/6865 (83%)]\tLoss: 0.065847\n",
      "Train Epoch: 6 [6400/6865 (93%)]\tLoss: 0.029812\n",
      "Train Epoch: 7 [0/6865 (0%)]\tLoss: 0.007520\n",
      "Train Epoch: 7 [640/6865 (9%)]\tLoss: 0.077559\n",
      "Train Epoch: 7 [1280/6865 (19%)]\tLoss: 0.016008\n",
      "Train Epoch: 7 [1920/6865 (28%)]\tLoss: 0.036967\n",
      "Train Epoch: 7 [2560/6865 (37%)]\tLoss: 0.096211\n",
      "Train Epoch: 7 [3200/6865 (46%)]\tLoss: 0.014031\n",
      "Train Epoch: 7 [3840/6865 (56%)]\tLoss: 0.015190\n",
      "Train Epoch: 7 [4480/6865 (65%)]\tLoss: 0.018656\n",
      "Train Epoch: 7 [5120/6865 (74%)]\tLoss: 0.019844\n",
      "Train Epoch: 7 [5760/6865 (83%)]\tLoss: 0.148070\n",
      "Train Epoch: 7 [6400/6865 (93%)]\tLoss: 0.008417\n",
      "Train Epoch: 8 [0/6865 (0%)]\tLoss: 0.022804\n",
      "Train Epoch: 8 [640/6865 (9%)]\tLoss: 0.004354\n",
      "Train Epoch: 8 [1280/6865 (19%)]\tLoss: 0.002702\n",
      "Train Epoch: 8 [1920/6865 (28%)]\tLoss: 0.130207\n",
      "Train Epoch: 8 [2560/6865 (37%)]\tLoss: 0.006855\n",
      "Train Epoch: 8 [3200/6865 (46%)]\tLoss: 0.001674\n",
      "Train Epoch: 8 [3840/6865 (56%)]\tLoss: 0.074342\n",
      "Train Epoch: 8 [4480/6865 (65%)]\tLoss: 0.026098\n",
      "Train Epoch: 8 [5120/6865 (74%)]\tLoss: 0.115587\n",
      "Train Epoch: 8 [5760/6865 (83%)]\tLoss: 0.014465\n",
      "Train Epoch: 8 [6400/6865 (93%)]\tLoss: 0.009865\n",
      "Train Epoch: 9 [0/6865 (0%)]\tLoss: 0.011564\n",
      "Train Epoch: 9 [640/6865 (9%)]\tLoss: 0.001986\n",
      "Train Epoch: 9 [1280/6865 (19%)]\tLoss: 0.017003\n",
      "Train Epoch: 9 [1920/6865 (28%)]\tLoss: 0.009282\n",
      "Train Epoch: 9 [2560/6865 (37%)]\tLoss: 0.008625\n",
      "Train Epoch: 9 [3200/6865 (46%)]\tLoss: 0.001903\n",
      "Train Epoch: 9 [3840/6865 (56%)]\tLoss: 0.016386\n",
      "Train Epoch: 9 [4480/6865 (65%)]\tLoss: 0.014478\n",
      "Train Epoch: 9 [5120/6865 (74%)]\tLoss: 0.009500\n",
      "Train Epoch: 9 [5760/6865 (83%)]\tLoss: 0.018783\n",
      "Train Epoch: 9 [6400/6865 (93%)]\tLoss: 0.001185\n",
      "Train Epoch: 10 [0/6865 (0%)]\tLoss: 0.028324\n",
      "Train Epoch: 10 [640/6865 (9%)]\tLoss: 0.054826\n",
      "Train Epoch: 10 [1280/6865 (19%)]\tLoss: 0.002032\n",
      "Train Epoch: 10 [1920/6865 (28%)]\tLoss: 0.054699\n",
      "Train Epoch: 10 [2560/6865 (37%)]\tLoss: 0.011956\n",
      "Train Epoch: 10 [3200/6865 (46%)]\tLoss: 0.134126\n",
      "Train Epoch: 10 [3840/6865 (56%)]\tLoss: 0.086843\n",
      "Train Epoch: 10 [4480/6865 (65%)]\tLoss: 0.039003\n",
      "Train Epoch: 10 [5120/6865 (74%)]\tLoss: 0.010709\n",
      "Train Epoch: 10 [5760/6865 (83%)]\tLoss: 0.015210\n",
      "Train Epoch: 10 [6400/6865 (93%)]\tLoss: 0.004586\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.1318, Accuracy: 9889/10000 (99%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 0.096385\n",
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 0.048559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 0.030329\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 0.136939\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 0.039897\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 0.180983\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 0.104389\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 0.071797\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 0.063961\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 0.081057\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 0.093311\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 0.081588\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 0.039229\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 0.152142\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 0.024168\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 0.043052\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 0.053261\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 0.075171\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 0.052021\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 0.102925\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.005008\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 0.152203\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 0.143295\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.090243\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.091602\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 0.085744\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.043316\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 0.072185\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.012309\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.063532\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.063576\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.038156\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.019218\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.021414\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.140214\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.211585\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.025974\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.008725\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.041931\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.025169\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.024897\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.018323\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.045534\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.200976\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.008579\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.065336\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.002512\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.142104\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.020367\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.028469\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.037333\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.046955\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.059565\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.023396\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.021086\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.016861\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.003710\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.005120\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.042931\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.121452\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.036547\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.060529\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.020695\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.019563\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.065179\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.060245\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.025703\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.014954\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.091460\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.013404\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.016626\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.246328\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.125072\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.055012\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.071069\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.010583\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.034748\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.030683\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.116044\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.035778\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.089085\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.018933\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.168832\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.081036\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.018657\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.025628\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.015270\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.035810\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.030918\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.013326\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.029416\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.019281\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.038160\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.014157\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.038781\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.032195\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.080018\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.047345\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.010301\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.050452\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.016801\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.022539\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.016781\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.121347\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.024868\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.081064\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.089984\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.027090\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 0.015984\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.020977\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.027432\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.010676\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.021509\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.118962\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.025223\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.039025\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.009258\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.018550\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.047600\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.015729\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.060054\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.065404\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.076078\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.014308\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.231833\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.009734\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.069003\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.016070\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.020047\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.113871\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.005139\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.025111\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.007012\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.037770\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.014887\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.085124\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.031531\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.036605\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.032927\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.074762\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.107550\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.011618\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.141025\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.049838\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.027026\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.015033\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.051738\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.027233\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.046550\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.130478\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.012164\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.020368\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.020673\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.007836\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.122380\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.031596\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.010475\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.034534\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.025033\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.003836\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.022099\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.079616\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.009732\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.102043\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.156143\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.020645\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.008496\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.006516\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.014127\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.081379\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.053977\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.057302\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.021626\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.113061\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.014727\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.071902\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.109703\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.060278\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.009344\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.033333\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/5110 (0%)]\tLoss: 0.165931\n",
      "Train Epoch: 1 [640/5110 (12%)]\tLoss: 0.107936\n",
      "Train Epoch: 1 [1280/5110 (25%)]\tLoss: 0.118123\n",
      "Train Epoch: 1 [1920/5110 (38%)]\tLoss: 0.050994\n",
      "Train Epoch: 1 [2560/5110 (50%)]\tLoss: 0.059724\n",
      "Train Epoch: 1 [3200/5110 (62%)]\tLoss: 0.073727\n",
      "Train Epoch: 1 [3840/5110 (75%)]\tLoss: 0.050414\n",
      "Train Epoch: 1 [4480/5110 (88%)]\tLoss: 0.038941\n",
      "Train Epoch: 2 [0/5110 (0%)]\tLoss: 0.213331\n",
      "Train Epoch: 2 [640/5110 (12%)]\tLoss: 0.020364\n",
      "Train Epoch: 2 [1280/5110 (25%)]\tLoss: 0.096355\n",
      "Train Epoch: 2 [1920/5110 (38%)]\tLoss: 0.031108\n",
      "Train Epoch: 2 [2560/5110 (50%)]\tLoss: 0.131499\n",
      "Train Epoch: 2 [3200/5110 (62%)]\tLoss: 0.019683\n",
      "Train Epoch: 2 [3840/5110 (75%)]\tLoss: 0.013264\n",
      "Train Epoch: 2 [4480/5110 (88%)]\tLoss: 0.010502\n",
      "Train Epoch: 3 [0/5110 (0%)]\tLoss: 0.049303\n",
      "Train Epoch: 3 [640/5110 (12%)]\tLoss: 0.010242\n",
      "Train Epoch: 3 [1280/5110 (25%)]\tLoss: 0.017088\n",
      "Train Epoch: 3 [1920/5110 (38%)]\tLoss: 0.018372\n",
      "Train Epoch: 3 [2560/5110 (50%)]\tLoss: 0.009214\n",
      "Train Epoch: 3 [3200/5110 (62%)]\tLoss: 0.064499\n",
      "Train Epoch: 3 [3840/5110 (75%)]\tLoss: 0.046700\n",
      "Train Epoch: 3 [4480/5110 (88%)]\tLoss: 0.012382\n",
      "Train Epoch: 4 [0/5110 (0%)]\tLoss: 0.008657\n",
      "Train Epoch: 4 [640/5110 (12%)]\tLoss: 0.077743\n",
      "Train Epoch: 4 [1280/5110 (25%)]\tLoss: 0.008853\n",
      "Train Epoch: 4 [1920/5110 (38%)]\tLoss: 0.111552\n",
      "Train Epoch: 4 [2560/5110 (50%)]\tLoss: 0.051338\n",
      "Train Epoch: 4 [3200/5110 (62%)]\tLoss: 0.006710\n",
      "Train Epoch: 4 [3840/5110 (75%)]\tLoss: 0.025484\n",
      "Train Epoch: 4 [4480/5110 (88%)]\tLoss: 0.004771\n",
      "Train Epoch: 5 [0/5110 (0%)]\tLoss: 0.031613\n",
      "Train Epoch: 5 [640/5110 (12%)]\tLoss: 0.010779\n",
      "Train Epoch: 5 [1280/5110 (25%)]\tLoss: 0.098396\n",
      "Train Epoch: 5 [1920/5110 (38%)]\tLoss: 0.034894\n",
      "Train Epoch: 5 [2560/5110 (50%)]\tLoss: 0.062461\n",
      "Train Epoch: 5 [3200/5110 (62%)]\tLoss: 0.024863\n",
      "Train Epoch: 5 [3840/5110 (75%)]\tLoss: 0.010786\n",
      "Train Epoch: 5 [4480/5110 (88%)]\tLoss: 0.283661\n",
      "Train Epoch: 6 [0/5110 (0%)]\tLoss: 0.042067\n",
      "Train Epoch: 6 [640/5110 (12%)]\tLoss: 0.025067\n",
      "Train Epoch: 6 [1280/5110 (25%)]\tLoss: 0.010069\n",
      "Train Epoch: 6 [1920/5110 (38%)]\tLoss: 0.045460\n",
      "Train Epoch: 6 [2560/5110 (50%)]\tLoss: 0.040472\n",
      "Train Epoch: 6 [3200/5110 (62%)]\tLoss: 0.029519\n",
      "Train Epoch: 6 [3840/5110 (75%)]\tLoss: 0.043146\n",
      "Train Epoch: 6 [4480/5110 (88%)]\tLoss: 0.010323\n",
      "Train Epoch: 7 [0/5110 (0%)]\tLoss: 0.055990\n",
      "Train Epoch: 7 [640/5110 (12%)]\tLoss: 0.077441\n",
      "Train Epoch: 7 [1280/5110 (25%)]\tLoss: 0.025984\n",
      "Train Epoch: 7 [1920/5110 (38%)]\tLoss: 0.026433\n",
      "Train Epoch: 7 [2560/5110 (50%)]\tLoss: 0.068797\n",
      "Train Epoch: 7 [3200/5110 (62%)]\tLoss: 0.022650\n",
      "Train Epoch: 7 [3840/5110 (75%)]\tLoss: 0.062524\n",
      "Train Epoch: 7 [4480/5110 (88%)]\tLoss: 0.028591\n",
      "Train Epoch: 8 [0/5110 (0%)]\tLoss: 0.029413\n",
      "Train Epoch: 8 [640/5110 (12%)]\tLoss: 0.031514\n",
      "Train Epoch: 8 [1280/5110 (25%)]\tLoss: 0.044204\n",
      "Train Epoch: 8 [1920/5110 (38%)]\tLoss: 0.068487\n",
      "Train Epoch: 8 [2560/5110 (50%)]\tLoss: 0.081481\n",
      "Train Epoch: 8 [3200/5110 (62%)]\tLoss: 0.109706\n",
      "Train Epoch: 8 [3840/5110 (75%)]\tLoss: 0.026127\n",
      "Train Epoch: 8 [4480/5110 (88%)]\tLoss: 0.024911\n",
      "Train Epoch: 9 [0/5110 (0%)]\tLoss: 0.020442\n",
      "Train Epoch: 9 [640/5110 (12%)]\tLoss: 0.014605\n",
      "Train Epoch: 9 [1280/5110 (25%)]\tLoss: 0.022909\n",
      "Train Epoch: 9 [1920/5110 (38%)]\tLoss: 0.064373\n",
      "Train Epoch: 9 [2560/5110 (50%)]\tLoss: 0.024381\n",
      "Train Epoch: 9 [3200/5110 (62%)]\tLoss: 0.057793\n",
      "Train Epoch: 9 [3840/5110 (75%)]\tLoss: 0.036519\n",
      "Train Epoch: 9 [4480/5110 (88%)]\tLoss: 0.026511\n",
      "Train Epoch: 10 [0/5110 (0%)]\tLoss: 0.029214\n",
      "Train Epoch: 10 [640/5110 (12%)]\tLoss: 0.208625\n",
      "Train Epoch: 10 [1280/5110 (25%)]\tLoss: 0.020421\n",
      "Train Epoch: 10 [1920/5110 (38%)]\tLoss: 0.032336\n",
      "Train Epoch: 10 [2560/5110 (50%)]\tLoss: 0.016694\n",
      "Train Epoch: 10 [3200/5110 (62%)]\tLoss: 0.076860\n",
      "Train Epoch: 10 [3840/5110 (75%)]\tLoss: 0.015276\n",
      "Train Epoch: 10 [4480/5110 (88%)]\tLoss: 0.006946\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6766 (0%)]\tLoss: 0.216901\n",
      "Train Epoch: 1 [640/6766 (9%)]\tLoss: 0.069725\n",
      "Train Epoch: 1 [1280/6766 (19%)]\tLoss: 0.031437\n",
      "Train Epoch: 1 [1920/6766 (28%)]\tLoss: 0.087910\n",
      "Train Epoch: 1 [2560/6766 (38%)]\tLoss: 0.037813\n",
      "Train Epoch: 1 [3200/6766 (47%)]\tLoss: 0.047743\n",
      "Train Epoch: 1 [3840/6766 (57%)]\tLoss: 0.008049\n",
      "Train Epoch: 1 [4480/6766 (66%)]\tLoss: 0.098550\n",
      "Train Epoch: 1 [5120/6766 (75%)]\tLoss: 0.014518\n",
      "Train Epoch: 1 [5760/6766 (85%)]\tLoss: 0.040993\n",
      "Train Epoch: 1 [6400/6766 (94%)]\tLoss: 0.046676\n",
      "Train Epoch: 2 [0/6766 (0%)]\tLoss: 0.061215\n",
      "Train Epoch: 2 [640/6766 (9%)]\tLoss: 0.089071\n",
      "Train Epoch: 2 [1280/6766 (19%)]\tLoss: 0.051387\n",
      "Train Epoch: 2 [1920/6766 (28%)]\tLoss: 0.046492\n",
      "Train Epoch: 2 [2560/6766 (38%)]\tLoss: 0.026902\n",
      "Train Epoch: 2 [3200/6766 (47%)]\tLoss: 0.002377\n",
      "Train Epoch: 2 [3840/6766 (57%)]\tLoss: 0.019492\n",
      "Train Epoch: 2 [4480/6766 (66%)]\tLoss: 0.006082\n",
      "Train Epoch: 2 [5120/6766 (75%)]\tLoss: 0.012205\n",
      "Train Epoch: 2 [5760/6766 (85%)]\tLoss: 0.012389\n",
      "Train Epoch: 2 [6400/6766 (94%)]\tLoss: 0.172610\n",
      "Train Epoch: 3 [0/6766 (0%)]\tLoss: 0.011775\n",
      "Train Epoch: 3 [640/6766 (9%)]\tLoss: 0.004891\n",
      "Train Epoch: 3 [1280/6766 (19%)]\tLoss: 0.020204\n",
      "Train Epoch: 3 [1920/6766 (28%)]\tLoss: 0.081639\n",
      "Train Epoch: 3 [2560/6766 (38%)]\tLoss: 0.002046\n",
      "Train Epoch: 3 [3200/6766 (47%)]\tLoss: 0.017691\n",
      "Train Epoch: 3 [3840/6766 (57%)]\tLoss: 0.005339\n",
      "Train Epoch: 3 [4480/6766 (66%)]\tLoss: 0.006043\n",
      "Train Epoch: 3 [5120/6766 (75%)]\tLoss: 0.018474\n",
      "Train Epoch: 3 [5760/6766 (85%)]\tLoss: 0.040442\n",
      "Train Epoch: 3 [6400/6766 (94%)]\tLoss: 0.188475\n",
      "Train Epoch: 4 [0/6766 (0%)]\tLoss: 0.012637\n",
      "Train Epoch: 4 [640/6766 (9%)]\tLoss: 0.000886\n",
      "Train Epoch: 4 [1280/6766 (19%)]\tLoss: 0.019703\n",
      "Train Epoch: 4 [1920/6766 (28%)]\tLoss: 0.009866\n",
      "Train Epoch: 4 [2560/6766 (38%)]\tLoss: 0.006690\n",
      "Train Epoch: 4 [3200/6766 (47%)]\tLoss: 0.086354\n",
      "Train Epoch: 4 [3840/6766 (57%)]\tLoss: 0.004107\n",
      "Train Epoch: 4 [4480/6766 (66%)]\tLoss: 0.019693\n",
      "Train Epoch: 4 [5120/6766 (75%)]\tLoss: 0.007608\n",
      "Train Epoch: 4 [5760/6766 (85%)]\tLoss: 0.010593\n",
      "Train Epoch: 4 [6400/6766 (94%)]\tLoss: 0.275292\n",
      "Train Epoch: 5 [0/6766 (0%)]\tLoss: 0.021630\n",
      "Train Epoch: 5 [640/6766 (9%)]\tLoss: 0.023727\n",
      "Train Epoch: 5 [1280/6766 (19%)]\tLoss: 0.053512\n",
      "Train Epoch: 5 [1920/6766 (28%)]\tLoss: 0.039238\n",
      "Train Epoch: 5 [2560/6766 (38%)]\tLoss: 0.032797\n",
      "Train Epoch: 5 [3200/6766 (47%)]\tLoss: 0.019961\n",
      "Train Epoch: 5 [3840/6766 (57%)]\tLoss: 0.038958\n",
      "Train Epoch: 5 [4480/6766 (66%)]\tLoss: 0.042761\n",
      "Train Epoch: 5 [5120/6766 (75%)]\tLoss: 0.010207\n",
      "Train Epoch: 5 [5760/6766 (85%)]\tLoss: 0.011578\n",
      "Train Epoch: 5 [6400/6766 (94%)]\tLoss: 0.048001\n",
      "Train Epoch: 6 [0/6766 (0%)]\tLoss: 0.058613\n",
      "Train Epoch: 6 [640/6766 (9%)]\tLoss: 0.035244\n",
      "Train Epoch: 6 [1280/6766 (19%)]\tLoss: 0.068068\n",
      "Train Epoch: 6 [1920/6766 (28%)]\tLoss: 0.204901\n",
      "Train Epoch: 6 [2560/6766 (38%)]\tLoss: 0.067458\n",
      "Train Epoch: 6 [3200/6766 (47%)]\tLoss: 0.040329\n",
      "Train Epoch: 6 [3840/6766 (57%)]\tLoss: 0.014365\n",
      "Train Epoch: 6 [4480/6766 (66%)]\tLoss: 0.012264\n",
      "Train Epoch: 6 [5120/6766 (75%)]\tLoss: 0.005609\n",
      "Train Epoch: 6 [5760/6766 (85%)]\tLoss: 0.135061\n",
      "Train Epoch: 6 [6400/6766 (94%)]\tLoss: 0.023406\n",
      "Train Epoch: 7 [0/6766 (0%)]\tLoss: 0.044474\n",
      "Train Epoch: 7 [640/6766 (9%)]\tLoss: 0.021109\n",
      "Train Epoch: 7 [1280/6766 (19%)]\tLoss: 0.042123\n",
      "Train Epoch: 7 [1920/6766 (28%)]\tLoss: 0.026502\n",
      "Train Epoch: 7 [2560/6766 (38%)]\tLoss: 0.009317\n",
      "Train Epoch: 7 [3200/6766 (47%)]\tLoss: 0.058625\n",
      "Train Epoch: 7 [3840/6766 (57%)]\tLoss: 0.068251\n",
      "Train Epoch: 7 [4480/6766 (66%)]\tLoss: 0.009712\n",
      "Train Epoch: 7 [5120/6766 (75%)]\tLoss: 0.007416\n",
      "Train Epoch: 7 [5760/6766 (85%)]\tLoss: 0.013998\n",
      "Train Epoch: 7 [6400/6766 (94%)]\tLoss: 0.016261\n",
      "Train Epoch: 8 [0/6766 (0%)]\tLoss: 0.069246\n",
      "Train Epoch: 8 [640/6766 (9%)]\tLoss: 0.006471\n",
      "Train Epoch: 8 [1280/6766 (19%)]\tLoss: 0.019751\n",
      "Train Epoch: 8 [1920/6766 (28%)]\tLoss: 0.057561\n",
      "Train Epoch: 8 [2560/6766 (38%)]\tLoss: 0.056387\n",
      "Train Epoch: 8 [3200/6766 (47%)]\tLoss: 0.008514\n",
      "Train Epoch: 8 [3840/6766 (57%)]\tLoss: 0.024874\n",
      "Train Epoch: 8 [4480/6766 (66%)]\tLoss: 0.005970\n",
      "Train Epoch: 8 [5120/6766 (75%)]\tLoss: 0.011185\n",
      "Train Epoch: 8 [5760/6766 (85%)]\tLoss: 0.011277\n",
      "Train Epoch: 8 [6400/6766 (94%)]\tLoss: 0.009097\n",
      "Train Epoch: 9 [0/6766 (0%)]\tLoss: 0.052459\n",
      "Train Epoch: 9 [640/6766 (9%)]\tLoss: 0.032152\n",
      "Train Epoch: 9 [1280/6766 (19%)]\tLoss: 0.024188\n",
      "Train Epoch: 9 [1920/6766 (28%)]\tLoss: 0.069706\n",
      "Train Epoch: 9 [2560/6766 (38%)]\tLoss: 0.023984\n",
      "Train Epoch: 9 [3200/6766 (47%)]\tLoss: 0.075999\n",
      "Train Epoch: 9 [3840/6766 (57%)]\tLoss: 0.004691\n",
      "Train Epoch: 9 [4480/6766 (66%)]\tLoss: 0.012388\n",
      "Train Epoch: 9 [5120/6766 (75%)]\tLoss: 0.019862\n",
      "Train Epoch: 9 [5760/6766 (85%)]\tLoss: 0.000725\n",
      "Train Epoch: 9 [6400/6766 (94%)]\tLoss: 0.010506\n",
      "Train Epoch: 10 [0/6766 (0%)]\tLoss: 0.016423\n",
      "Train Epoch: 10 [640/6766 (9%)]\tLoss: 0.058656\n",
      "Train Epoch: 10 [1280/6766 (19%)]\tLoss: 0.036561\n",
      "Train Epoch: 10 [1920/6766 (28%)]\tLoss: 0.037866\n",
      "Train Epoch: 10 [2560/6766 (38%)]\tLoss: 0.006035\n",
      "Train Epoch: 10 [3200/6766 (47%)]\tLoss: 0.015872\n",
      "Train Epoch: 10 [3840/6766 (57%)]\tLoss: 0.004125\n",
      "Train Epoch: 10 [4480/6766 (66%)]\tLoss: 0.030858\n",
      "Train Epoch: 10 [5120/6766 (75%)]\tLoss: 0.027264\n",
      "Train Epoch: 10 [5760/6766 (85%)]\tLoss: 0.074643\n",
      "Train Epoch: 10 [6400/6766 (94%)]\tLoss: 0.026466\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 0.058072\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 0.011654\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 0.028792\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 0.069729\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 0.046291\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 0.029325\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 0.074145\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 0.025381\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 0.106375\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 0.092311\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 0.037860\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 0.063007\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 0.138365\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 0.015421\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 0.082749\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 0.050644\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 0.025215\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.006351\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.036172\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.052411\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.151525\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.049531\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.113590\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.028069\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.087246\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.039525\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.000560\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.033810\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.010605\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.049218\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.044269\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.050464\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.068740\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.087587\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.055754\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.015380\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.100824\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.031395\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.021479\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.101125\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.007690\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.050943\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.034737\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.146917\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.128592\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.045743\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.000868\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.011384\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.004571\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.145463\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.063267\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.023674\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.016258\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.145023\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.014806\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.034089\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.024167\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.132688\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.067095\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.021077\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.027336\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.004688\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.028099\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.011440\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.008823\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.010757\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.007377\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.078718\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.048030\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.005359\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.040248\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.018962\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.024680\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.032824\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.063557\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.069541\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.068918\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.012953\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.005563\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.046278\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.013067\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.012108\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.004494\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.011653\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.010462\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.015013\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.051090\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.011922\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.012489\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.096661\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.027909\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.042398\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.062648\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.072489\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.017216\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.017237\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.210697\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.048382\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.039202\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.031820\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.007818\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.047225\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.065471\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.006170\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.017122\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.006629\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.066226\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.023188\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.013842\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.035664\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.026654\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.008366\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.195867\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.044838\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.005036\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.123018\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.052502\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.011686\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.019559\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.074686\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.141782\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.073198\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.003855\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.170508\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.010405\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.014748\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.055649\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.069772\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.020348\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.108126\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.028268\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.077497\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.137395\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.005906\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.019102\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.028461\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.048679\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.086782\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.027048\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.013219\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.045796\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.048676\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.006230\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.019431\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.020761\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.019566\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.015065\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.043262\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.014750\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.025784\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.001763\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.134447\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.080576\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.014875\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.017757\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.033971\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.139151\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.053157\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.010108\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.023402\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/3910 (0%)]\tLoss: 0.102058\n",
      "Train Epoch: 1 [640/3910 (16%)]\tLoss: 0.044373\n",
      "Train Epoch: 1 [1280/3910 (32%)]\tLoss: 0.012367\n",
      "Train Epoch: 1 [1920/3910 (48%)]\tLoss: 0.163989\n",
      "Train Epoch: 1 [2560/3910 (65%)]\tLoss: 0.136408\n",
      "Train Epoch: 1 [3200/3910 (81%)]\tLoss: 0.081540\n",
      "Train Epoch: 1 [3840/3910 (97%)]\tLoss: 0.050736\n",
      "Train Epoch: 2 [0/3910 (0%)]\tLoss: 0.121332\n",
      "Train Epoch: 2 [640/3910 (16%)]\tLoss: 0.026733\n",
      "Train Epoch: 2 [1280/3910 (32%)]\tLoss: 0.043523\n",
      "Train Epoch: 2 [1920/3910 (48%)]\tLoss: 0.111548\n",
      "Train Epoch: 2 [2560/3910 (65%)]\tLoss: 0.021396\n",
      "Train Epoch: 2 [3200/3910 (81%)]\tLoss: 0.145593\n",
      "Train Epoch: 2 [3840/3910 (97%)]\tLoss: 0.023914\n",
      "Train Epoch: 3 [0/3910 (0%)]\tLoss: 0.076442\n",
      "Train Epoch: 3 [640/3910 (16%)]\tLoss: 0.036706\n",
      "Train Epoch: 3 [1280/3910 (32%)]\tLoss: 0.032839\n",
      "Train Epoch: 3 [1920/3910 (48%)]\tLoss: 0.068993\n",
      "Train Epoch: 3 [2560/3910 (65%)]\tLoss: 0.059222\n",
      "Train Epoch: 3 [3200/3910 (81%)]\tLoss: 0.035664\n",
      "Train Epoch: 3 [3840/3910 (97%)]\tLoss: 0.017745\n",
      "Train Epoch: 4 [0/3910 (0%)]\tLoss: 0.101578\n",
      "Train Epoch: 4 [640/3910 (16%)]\tLoss: 0.045750\n",
      "Train Epoch: 4 [1280/3910 (32%)]\tLoss: 0.071555\n",
      "Train Epoch: 4 [1920/3910 (48%)]\tLoss: 0.049894\n",
      "Train Epoch: 4 [2560/3910 (65%)]\tLoss: 0.015443\n",
      "Train Epoch: 4 [3200/3910 (81%)]\tLoss: 0.005768\n",
      "Train Epoch: 4 [3840/3910 (97%)]\tLoss: 0.177912\n",
      "Train Epoch: 5 [0/3910 (0%)]\tLoss: 0.023675\n",
      "Train Epoch: 5 [640/3910 (16%)]\tLoss: 0.052048\n",
      "Train Epoch: 5 [1280/3910 (32%)]\tLoss: 0.044809\n",
      "Train Epoch: 5 [1920/3910 (48%)]\tLoss: 0.016047\n",
      "Train Epoch: 5 [2560/3910 (65%)]\tLoss: 0.193795\n",
      "Train Epoch: 5 [3200/3910 (81%)]\tLoss: 0.045760\n",
      "Train Epoch: 5 [3840/3910 (97%)]\tLoss: 0.059056\n",
      "Train Epoch: 6 [0/3910 (0%)]\tLoss: 0.033346\n",
      "Train Epoch: 6 [640/3910 (16%)]\tLoss: 0.016842\n",
      "Train Epoch: 6 [1280/3910 (32%)]\tLoss: 0.096390\n",
      "Train Epoch: 6 [1920/3910 (48%)]\tLoss: 0.010818\n",
      "Train Epoch: 6 [2560/3910 (65%)]\tLoss: 0.051291\n",
      "Train Epoch: 6 [3200/3910 (81%)]\tLoss: 0.026548\n",
      "Train Epoch: 6 [3840/3910 (97%)]\tLoss: 0.029581\n",
      "Train Epoch: 7 [0/3910 (0%)]\tLoss: 0.102305\n",
      "Train Epoch: 7 [640/3910 (16%)]\tLoss: 0.039998\n",
      "Train Epoch: 7 [1280/3910 (32%)]\tLoss: 0.013612\n",
      "Train Epoch: 7 [1920/3910 (48%)]\tLoss: 0.079427\n",
      "Train Epoch: 7 [2560/3910 (65%)]\tLoss: 0.014698\n",
      "Train Epoch: 7 [3200/3910 (81%)]\tLoss: 0.022629\n",
      "Train Epoch: 7 [3840/3910 (97%)]\tLoss: 0.037846\n",
      "Train Epoch: 8 [0/3910 (0%)]\tLoss: 0.033750\n",
      "Train Epoch: 8 [640/3910 (16%)]\tLoss: 0.030963\n",
      "Train Epoch: 8 [1280/3910 (32%)]\tLoss: 0.086446\n",
      "Train Epoch: 8 [1920/3910 (48%)]\tLoss: 0.001216\n",
      "Train Epoch: 8 [2560/3910 (65%)]\tLoss: 0.038587\n",
      "Train Epoch: 8 [3200/3910 (81%)]\tLoss: 0.063796\n",
      "Train Epoch: 8 [3840/3910 (97%)]\tLoss: 0.026250\n",
      "Train Epoch: 9 [0/3910 (0%)]\tLoss: 0.034510\n",
      "Train Epoch: 9 [640/3910 (16%)]\tLoss: 0.032441\n",
      "Train Epoch: 9 [1280/3910 (32%)]\tLoss: 0.036443\n",
      "Train Epoch: 9 [1920/3910 (48%)]\tLoss: 0.062684\n",
      "Train Epoch: 9 [2560/3910 (65%)]\tLoss: 0.110572\n",
      "Train Epoch: 9 [3200/3910 (81%)]\tLoss: 0.063664\n",
      "Train Epoch: 9 [3840/3910 (97%)]\tLoss: 0.047201\n",
      "Train Epoch: 10 [0/3910 (0%)]\tLoss: 0.024842\n",
      "Train Epoch: 10 [640/3910 (16%)]\tLoss: 0.024438\n",
      "Train Epoch: 10 [1280/3910 (32%)]\tLoss: 0.001964\n",
      "Train Epoch: 10 [1920/3910 (48%)]\tLoss: 0.020211\n",
      "Train Epoch: 10 [2560/3910 (65%)]\tLoss: 0.061013\n",
      "Train Epoch: 10 [3200/3910 (81%)]\tLoss: 0.023297\n",
      "Train Epoch: 10 [3840/3910 (97%)]\tLoss: 0.009691\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 0.033169\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 0.042394\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 0.043686\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 0.040492\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 0.022812\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 0.107163\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 0.007912\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 0.081939\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 0.032899\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 0.007042\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.018636\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.065287\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 0.034609\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 0.055395\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 0.016726\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.003300\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.010821\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.045600\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.065565\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.086790\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.014911\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.039036\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.019913\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.011349\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.004877\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.030418\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.027214\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.042176\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.000947\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.013278\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.036184\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.017419\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.082895\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.077933\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.005346\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.044917\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.011051\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.024325\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.080138\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.019384\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.008350\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.008829\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.035718\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.055216\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.001262\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.069649\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.010067\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.094539\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.050693\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.016079\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.007071\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.004851\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.006425\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.015807\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.025908\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.081760\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.007726\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.080562\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.044559\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.000995\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.011071\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.028644\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.026343\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.048696\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.025148\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.066407\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.024266\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.011652\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.051565\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.003266\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.008101\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.009431\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.004714\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.034419\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.018688\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.025077\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.003770\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.030146\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.014892\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.024312\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.014436\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.006777\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.001272\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.045445\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.027270\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.005833\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.026797\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.006881\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.005590\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.007258\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.037151\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.104458\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.020039\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.015042\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.004507\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.005121\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.026670\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.001101\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.063446\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.014588\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.003326\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.014470\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.003745\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.058532\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.044287\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.003416\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.031299\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.042516\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.007181\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.003883\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.006192\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.036871\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.089532\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.007930\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.003410\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.007696\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.059452\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.013038\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.004274\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.028629\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/5096 (0%)]\tLoss: 0.095227\n",
      "Train Epoch: 1 [640/5096 (12%)]\tLoss: 0.014213\n",
      "Train Epoch: 1 [1280/5096 (25%)]\tLoss: 0.038733\n",
      "Train Epoch: 1 [1920/5096 (38%)]\tLoss: 0.099373\n",
      "Train Epoch: 1 [2560/5096 (50%)]\tLoss: 0.015658\n",
      "Train Epoch: 1 [3200/5096 (62%)]\tLoss: 0.074018\n",
      "Train Epoch: 1 [3840/5096 (75%)]\tLoss: 0.026696\n",
      "Train Epoch: 1 [4480/5096 (88%)]\tLoss: 0.005441\n",
      "Train Epoch: 2 [0/5096 (0%)]\tLoss: 0.016375\n",
      "Train Epoch: 2 [640/5096 (12%)]\tLoss: 0.127232\n",
      "Train Epoch: 2 [1280/5096 (25%)]\tLoss: 0.073901\n",
      "Train Epoch: 2 [1920/5096 (38%)]\tLoss: 0.029033\n",
      "Train Epoch: 2 [2560/5096 (50%)]\tLoss: 0.016938\n",
      "Train Epoch: 2 [3200/5096 (62%)]\tLoss: 0.036734\n",
      "Train Epoch: 2 [3840/5096 (75%)]\tLoss: 0.045918\n",
      "Train Epoch: 2 [4480/5096 (88%)]\tLoss: 0.011693\n",
      "Train Epoch: 3 [0/5096 (0%)]\tLoss: 0.024079\n",
      "Train Epoch: 3 [640/5096 (12%)]\tLoss: 0.021734\n",
      "Train Epoch: 3 [1280/5096 (25%)]\tLoss: 0.033016\n",
      "Train Epoch: 3 [1920/5096 (38%)]\tLoss: 0.056796\n",
      "Train Epoch: 3 [2560/5096 (50%)]\tLoss: 0.051841\n",
      "Train Epoch: 3 [3200/5096 (62%)]\tLoss: 0.002943\n",
      "Train Epoch: 3 [3840/5096 (75%)]\tLoss: 0.019955\n",
      "Train Epoch: 3 [4480/5096 (88%)]\tLoss: 0.123415\n",
      "Train Epoch: 4 [0/5096 (0%)]\tLoss: 0.008118\n",
      "Train Epoch: 4 [640/5096 (12%)]\tLoss: 0.149476\n",
      "Train Epoch: 4 [1280/5096 (25%)]\tLoss: 0.018270\n",
      "Train Epoch: 4 [1920/5096 (38%)]\tLoss: 0.000873\n",
      "Train Epoch: 4 [2560/5096 (50%)]\tLoss: 0.003529\n",
      "Train Epoch: 4 [3200/5096 (62%)]\tLoss: 0.145848\n",
      "Train Epoch: 4 [3840/5096 (75%)]\tLoss: 0.011203\n",
      "Train Epoch: 4 [4480/5096 (88%)]\tLoss: 0.012547\n",
      "Train Epoch: 5 [0/5096 (0%)]\tLoss: 0.004458\n",
      "Train Epoch: 5 [640/5096 (12%)]\tLoss: 0.083828\n",
      "Train Epoch: 5 [1280/5096 (25%)]\tLoss: 0.012792\n",
      "Train Epoch: 5 [1920/5096 (38%)]\tLoss: 0.021859\n",
      "Train Epoch: 5 [2560/5096 (50%)]\tLoss: 0.005753\n",
      "Train Epoch: 5 [3200/5096 (62%)]\tLoss: 0.121670\n",
      "Train Epoch: 5 [3840/5096 (75%)]\tLoss: 0.019239\n",
      "Train Epoch: 5 [4480/5096 (88%)]\tLoss: 0.004810\n",
      "Train Epoch: 6 [0/5096 (0%)]\tLoss: 0.058836\n",
      "Train Epoch: 6 [640/5096 (12%)]\tLoss: 0.025670\n",
      "Train Epoch: 6 [1280/5096 (25%)]\tLoss: 0.098514\n",
      "Train Epoch: 6 [1920/5096 (38%)]\tLoss: 0.035348\n",
      "Train Epoch: 6 [2560/5096 (50%)]\tLoss: 0.023759\n",
      "Train Epoch: 6 [3200/5096 (62%)]\tLoss: 0.025409\n",
      "Train Epoch: 6 [3840/5096 (75%)]\tLoss: 0.010935\n",
      "Train Epoch: 6 [4480/5096 (88%)]\tLoss: 0.037656\n",
      "Train Epoch: 7 [0/5096 (0%)]\tLoss: 0.003267\n",
      "Train Epoch: 7 [640/5096 (12%)]\tLoss: 0.004233\n",
      "Train Epoch: 7 [1280/5096 (25%)]\tLoss: 0.074770\n",
      "Train Epoch: 7 [1920/5096 (38%)]\tLoss: 0.080708\n",
      "Train Epoch: 7 [2560/5096 (50%)]\tLoss: 0.009944\n",
      "Train Epoch: 7 [3200/5096 (62%)]\tLoss: 0.011106\n",
      "Train Epoch: 7 [3840/5096 (75%)]\tLoss: 0.007564\n",
      "Train Epoch: 7 [4480/5096 (88%)]\tLoss: 0.004075\n",
      "Train Epoch: 8 [0/5096 (0%)]\tLoss: 0.013378\n",
      "Train Epoch: 8 [640/5096 (12%)]\tLoss: 0.023119\n",
      "Train Epoch: 8 [1280/5096 (25%)]\tLoss: 0.020956\n",
      "Train Epoch: 8 [1920/5096 (38%)]\tLoss: 0.003219\n",
      "Train Epoch: 8 [2560/5096 (50%)]\tLoss: 0.020552\n",
      "Train Epoch: 8 [3200/5096 (62%)]\tLoss: 0.019022\n",
      "Train Epoch: 8 [3840/5096 (75%)]\tLoss: 0.003854\n",
      "Train Epoch: 8 [4480/5096 (88%)]\tLoss: 0.026690\n",
      "Train Epoch: 9 [0/5096 (0%)]\tLoss: 0.008019\n",
      "Train Epoch: 9 [640/5096 (12%)]\tLoss: 0.068868\n",
      "Train Epoch: 9 [1280/5096 (25%)]\tLoss: 0.038402\n",
      "Train Epoch: 9 [1920/5096 (38%)]\tLoss: 0.010504\n",
      "Train Epoch: 9 [2560/5096 (50%)]\tLoss: 0.018278\n",
      "Train Epoch: 9 [3200/5096 (62%)]\tLoss: 0.019801\n",
      "Train Epoch: 9 [3840/5096 (75%)]\tLoss: 0.042114\n",
      "Train Epoch: 9 [4480/5096 (88%)]\tLoss: 0.053637\n",
      "Train Epoch: 10 [0/5096 (0%)]\tLoss: 0.013660\n",
      "Train Epoch: 10 [640/5096 (12%)]\tLoss: 0.012127\n",
      "Train Epoch: 10 [1280/5096 (25%)]\tLoss: 0.093532\n",
      "Train Epoch: 10 [1920/5096 (38%)]\tLoss: 0.001593\n",
      "Train Epoch: 10 [2560/5096 (50%)]\tLoss: 0.031764\n",
      "Train Epoch: 10 [3200/5096 (62%)]\tLoss: 0.095040\n",
      "Train Epoch: 10 [3840/5096 (75%)]\tLoss: 0.013839\n",
      "Train Epoch: 10 [4480/5096 (88%)]\tLoss: 0.040015\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/1599 (0%)]\tLoss: 0.097111\n",
      "Train Epoch: 1 [640/1599 (40%)]\tLoss: 0.265492\n",
      "Train Epoch: 1 [1280/1599 (80%)]\tLoss: 0.241466\n",
      "Train Epoch: 2 [0/1599 (0%)]\tLoss: 0.153402\n",
      "Train Epoch: 2 [640/1599 (40%)]\tLoss: 0.069584\n",
      "Train Epoch: 2 [1280/1599 (80%)]\tLoss: 0.109294\n",
      "Train Epoch: 3 [0/1599 (0%)]\tLoss: 0.026097\n",
      "Train Epoch: 3 [640/1599 (40%)]\tLoss: 0.042131\n",
      "Train Epoch: 3 [1280/1599 (80%)]\tLoss: 0.035307\n",
      "Train Epoch: 4 [0/1599 (0%)]\tLoss: 0.054817\n",
      "Train Epoch: 4 [640/1599 (40%)]\tLoss: 0.056869\n",
      "Train Epoch: 4 [1280/1599 (80%)]\tLoss: 0.089016\n",
      "Train Epoch: 5 [0/1599 (0%)]\tLoss: 0.110116\n",
      "Train Epoch: 5 [640/1599 (40%)]\tLoss: 0.015072\n",
      "Train Epoch: 5 [1280/1599 (80%)]\tLoss: 0.016377\n",
      "Train Epoch: 6 [0/1599 (0%)]\tLoss: 0.028453\n",
      "Train Epoch: 6 [640/1599 (40%)]\tLoss: 0.007214\n",
      "Train Epoch: 6 [1280/1599 (80%)]\tLoss: 0.046158\n",
      "Train Epoch: 7 [0/1599 (0%)]\tLoss: 0.001167\n",
      "Train Epoch: 7 [640/1599 (40%)]\tLoss: 0.138300\n",
      "Train Epoch: 7 [1280/1599 (80%)]\tLoss: 0.046332\n",
      "Train Epoch: 8 [0/1599 (0%)]\tLoss: 0.073525\n",
      "Train Epoch: 8 [640/1599 (40%)]\tLoss: 0.017726\n",
      "Train Epoch: 8 [1280/1599 (80%)]\tLoss: 0.135350\n",
      "Train Epoch: 9 [0/1599 (0%)]\tLoss: 0.055248\n",
      "Train Epoch: 9 [640/1599 (40%)]\tLoss: 0.032826\n",
      "Train Epoch: 9 [1280/1599 (80%)]\tLoss: 0.052065\n",
      "Train Epoch: 10 [0/1599 (0%)]\tLoss: 0.007868\n",
      "Train Epoch: 10 [640/1599 (40%)]\tLoss: 0.008077\n",
      "Train Epoch: 10 [1280/1599 (80%)]\tLoss: 0.025859\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/5266 (0%)]\tLoss: 0.045327\n",
      "Train Epoch: 1 [640/5266 (12%)]\tLoss: 0.008549\n",
      "Train Epoch: 1 [1280/5266 (24%)]\tLoss: 0.067613\n",
      "Train Epoch: 1 [1920/5266 (36%)]\tLoss: 0.070796\n",
      "Train Epoch: 1 [2560/5266 (48%)]\tLoss: 0.029604\n",
      "Train Epoch: 1 [3200/5266 (60%)]\tLoss: 0.007246\n",
      "Train Epoch: 1 [3840/5266 (72%)]\tLoss: 0.052677\n",
      "Train Epoch: 1 [4480/5266 (84%)]\tLoss: 0.009010\n",
      "Train Epoch: 1 [5120/5266 (96%)]\tLoss: 0.091542\n",
      "Train Epoch: 2 [0/5266 (0%)]\tLoss: 0.063980\n",
      "Train Epoch: 2 [640/5266 (12%)]\tLoss: 0.041244\n",
      "Train Epoch: 2 [1280/5266 (24%)]\tLoss: 0.012736\n",
      "Train Epoch: 2 [1920/5266 (36%)]\tLoss: 0.099701\n",
      "Train Epoch: 2 [2560/5266 (48%)]\tLoss: 0.007305\n",
      "Train Epoch: 2 [3200/5266 (60%)]\tLoss: 0.000293\n",
      "Train Epoch: 2 [3840/5266 (72%)]\tLoss: 0.017326\n",
      "Train Epoch: 2 [4480/5266 (84%)]\tLoss: 0.008709\n",
      "Train Epoch: 2 [5120/5266 (96%)]\tLoss: 0.002419\n",
      "Train Epoch: 3 [0/5266 (0%)]\tLoss: 0.020494\n",
      "Train Epoch: 3 [640/5266 (12%)]\tLoss: 0.131400\n",
      "Train Epoch: 3 [1280/5266 (24%)]\tLoss: 0.002829\n",
      "Train Epoch: 3 [1920/5266 (36%)]\tLoss: 0.001424\n",
      "Train Epoch: 3 [2560/5266 (48%)]\tLoss: 0.006294\n",
      "Train Epoch: 3 [3200/5266 (60%)]\tLoss: 0.019655\n",
      "Train Epoch: 3 [3840/5266 (72%)]\tLoss: 0.019109\n",
      "Train Epoch: 3 [4480/5266 (84%)]\tLoss: 0.045375\n",
      "Train Epoch: 3 [5120/5266 (96%)]\tLoss: 0.016170\n",
      "Train Epoch: 4 [0/5266 (0%)]\tLoss: 0.007324\n",
      "Train Epoch: 4 [640/5266 (12%)]\tLoss: 0.003447\n",
      "Train Epoch: 4 [1280/5266 (24%)]\tLoss: 0.000905\n",
      "Train Epoch: 4 [1920/5266 (36%)]\tLoss: 0.003454\n",
      "Train Epoch: 4 [2560/5266 (48%)]\tLoss: 0.004435\n",
      "Train Epoch: 4 [3200/5266 (60%)]\tLoss: 0.010644\n",
      "Train Epoch: 4 [3840/5266 (72%)]\tLoss: 0.014009\n",
      "Train Epoch: 4 [4480/5266 (84%)]\tLoss: 0.003016\n",
      "Train Epoch: 4 [5120/5266 (96%)]\tLoss: 0.071674\n",
      "Train Epoch: 5 [0/5266 (0%)]\tLoss: 0.006215\n",
      "Train Epoch: 5 [640/5266 (12%)]\tLoss: 0.019070\n",
      "Train Epoch: 5 [1280/5266 (24%)]\tLoss: 0.003291\n",
      "Train Epoch: 5 [1920/5266 (36%)]\tLoss: 0.003150\n",
      "Train Epoch: 5 [2560/5266 (48%)]\tLoss: 0.000520\n",
      "Train Epoch: 5 [3200/5266 (60%)]\tLoss: 0.000157\n",
      "Train Epoch: 5 [3840/5266 (72%)]\tLoss: 0.002417\n",
      "Train Epoch: 5 [4480/5266 (84%)]\tLoss: 0.112158\n",
      "Train Epoch: 5 [5120/5266 (96%)]\tLoss: 0.001500\n",
      "Train Epoch: 6 [0/5266 (0%)]\tLoss: 0.001186\n",
      "Train Epoch: 6 [640/5266 (12%)]\tLoss: 0.005382\n",
      "Train Epoch: 6 [1280/5266 (24%)]\tLoss: 0.007887\n",
      "Train Epoch: 6 [1920/5266 (36%)]\tLoss: 0.005524\n",
      "Train Epoch: 6 [2560/5266 (48%)]\tLoss: 0.001043\n",
      "Train Epoch: 6 [3200/5266 (60%)]\tLoss: 0.041986\n",
      "Train Epoch: 6 [3840/5266 (72%)]\tLoss: 0.037022\n",
      "Train Epoch: 6 [4480/5266 (84%)]\tLoss: 0.000603\n",
      "Train Epoch: 6 [5120/5266 (96%)]\tLoss: 0.003789\n",
      "Train Epoch: 7 [0/5266 (0%)]\tLoss: 0.005987\n",
      "Train Epoch: 7 [640/5266 (12%)]\tLoss: 0.028994\n",
      "Train Epoch: 7 [1280/5266 (24%)]\tLoss: 0.006789\n",
      "Train Epoch: 7 [1920/5266 (36%)]\tLoss: 0.006901\n",
      "Train Epoch: 7 [2560/5266 (48%)]\tLoss: 0.001429\n",
      "Train Epoch: 7 [3200/5266 (60%)]\tLoss: 0.075733\n",
      "Train Epoch: 7 [3840/5266 (72%)]\tLoss: 0.000204\n",
      "Train Epoch: 7 [4480/5266 (84%)]\tLoss: 0.011053\n",
      "Train Epoch: 7 [5120/5266 (96%)]\tLoss: 0.005778\n",
      "Train Epoch: 8 [0/5266 (0%)]\tLoss: 0.039602\n",
      "Train Epoch: 8 [640/5266 (12%)]\tLoss: 0.046030\n",
      "Train Epoch: 8 [1280/5266 (24%)]\tLoss: 0.004251\n",
      "Train Epoch: 8 [1920/5266 (36%)]\tLoss: 0.002839\n",
      "Train Epoch: 8 [2560/5266 (48%)]\tLoss: 0.031365\n",
      "Train Epoch: 8 [3200/5266 (60%)]\tLoss: 0.138386\n",
      "Train Epoch: 8 [3840/5266 (72%)]\tLoss: 0.025503\n",
      "Train Epoch: 8 [4480/5266 (84%)]\tLoss: 0.018317\n",
      "Train Epoch: 8 [5120/5266 (96%)]\tLoss: 0.004890\n",
      "Train Epoch: 9 [0/5266 (0%)]\tLoss: 0.101297\n",
      "Train Epoch: 9 [640/5266 (12%)]\tLoss: 0.001366\n",
      "Train Epoch: 9 [1280/5266 (24%)]\tLoss: 0.075926\n",
      "Train Epoch: 9 [1920/5266 (36%)]\tLoss: 0.003932\n",
      "Train Epoch: 9 [2560/5266 (48%)]\tLoss: 0.005262\n",
      "Train Epoch: 9 [3200/5266 (60%)]\tLoss: 0.046920\n",
      "Train Epoch: 9 [3840/5266 (72%)]\tLoss: 0.018165\n",
      "Train Epoch: 9 [4480/5266 (84%)]\tLoss: 0.031426\n",
      "Train Epoch: 9 [5120/5266 (96%)]\tLoss: 0.011604\n",
      "Train Epoch: 10 [0/5266 (0%)]\tLoss: 0.007589\n",
      "Train Epoch: 10 [640/5266 (12%)]\tLoss: 0.021776\n",
      "Train Epoch: 10 [1280/5266 (24%)]\tLoss: 0.006931\n",
      "Train Epoch: 10 [1920/5266 (36%)]\tLoss: 0.015859\n",
      "Train Epoch: 10 [2560/5266 (48%)]\tLoss: 0.007089\n",
      "Train Epoch: 10 [3200/5266 (60%)]\tLoss: 0.017198\n",
      "Train Epoch: 10 [3840/5266 (72%)]\tLoss: 0.008696\n",
      "Train Epoch: 10 [4480/5266 (84%)]\tLoss: 0.002734\n",
      "Train Epoch: 10 [5120/5266 (96%)]\tLoss: 0.000989\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/3530 (0%)]\tLoss: 0.048381\n",
      "Train Epoch: 1 [640/3530 (18%)]\tLoss: 0.089650\n",
      "Train Epoch: 1 [1280/3530 (36%)]\tLoss: 0.045343\n",
      "Train Epoch: 1 [1920/3530 (54%)]\tLoss: 0.245947\n",
      "Train Epoch: 1 [2560/3530 (71%)]\tLoss: 0.125379\n",
      "Train Epoch: 1 [3200/3530 (89%)]\tLoss: 0.020218\n",
      "Train Epoch: 2 [0/3530 (0%)]\tLoss: 0.056990\n",
      "Train Epoch: 2 [640/3530 (18%)]\tLoss: 0.082800\n",
      "Train Epoch: 2 [1280/3530 (36%)]\tLoss: 0.037793\n",
      "Train Epoch: 2 [1920/3530 (54%)]\tLoss: 0.252553\n",
      "Train Epoch: 2 [2560/3530 (71%)]\tLoss: 0.002648\n",
      "Train Epoch: 2 [3200/3530 (89%)]\tLoss: 0.057406\n",
      "Train Epoch: 3 [0/3530 (0%)]\tLoss: 0.023263\n",
      "Train Epoch: 3 [640/3530 (18%)]\tLoss: 0.055242\n",
      "Train Epoch: 3 [1280/3530 (36%)]\tLoss: 0.029160\n",
      "Train Epoch: 3 [1920/3530 (54%)]\tLoss: 0.017683\n",
      "Train Epoch: 3 [2560/3530 (71%)]\tLoss: 0.146887\n",
      "Train Epoch: 3 [3200/3530 (89%)]\tLoss: 0.041491\n",
      "Train Epoch: 4 [0/3530 (0%)]\tLoss: 0.029228\n",
      "Train Epoch: 4 [640/3530 (18%)]\tLoss: 0.065937\n",
      "Train Epoch: 4 [1280/3530 (36%)]\tLoss: 0.024562\n",
      "Train Epoch: 4 [1920/3530 (54%)]\tLoss: 0.019003\n",
      "Train Epoch: 4 [2560/3530 (71%)]\tLoss: 0.006455\n",
      "Train Epoch: 4 [3200/3530 (89%)]\tLoss: 0.046708\n",
      "Train Epoch: 5 [0/3530 (0%)]\tLoss: 0.016315\n",
      "Train Epoch: 5 [640/3530 (18%)]\tLoss: 0.042252\n",
      "Train Epoch: 5 [1280/3530 (36%)]\tLoss: 0.038211\n",
      "Train Epoch: 5 [1920/3530 (54%)]\tLoss: 0.037778\n",
      "Train Epoch: 5 [2560/3530 (71%)]\tLoss: 0.101957\n",
      "Train Epoch: 5 [3200/3530 (89%)]\tLoss: 0.241451\n",
      "Train Epoch: 6 [0/3530 (0%)]\tLoss: 0.222638\n",
      "Train Epoch: 6 [640/3530 (18%)]\tLoss: 0.031758\n",
      "Train Epoch: 6 [1280/3530 (36%)]\tLoss: 0.021408\n",
      "Train Epoch: 6 [1920/3530 (54%)]\tLoss: 0.122690\n",
      "Train Epoch: 6 [2560/3530 (71%)]\tLoss: 0.016275\n",
      "Train Epoch: 6 [3200/3530 (89%)]\tLoss: 0.021333\n",
      "Train Epoch: 7 [0/3530 (0%)]\tLoss: 0.037878\n",
      "Train Epoch: 7 [640/3530 (18%)]\tLoss: 0.039400\n",
      "Train Epoch: 7 [1280/3530 (36%)]\tLoss: 0.059176\n",
      "Train Epoch: 7 [1920/3530 (54%)]\tLoss: 0.033028\n",
      "Train Epoch: 7 [2560/3530 (71%)]\tLoss: 0.006726\n",
      "Train Epoch: 7 [3200/3530 (89%)]\tLoss: 0.119421\n",
      "Train Epoch: 8 [0/3530 (0%)]\tLoss: 0.024152\n",
      "Train Epoch: 8 [640/3530 (18%)]\tLoss: 0.120956\n",
      "Train Epoch: 8 [1280/3530 (36%)]\tLoss: 0.126863\n",
      "Train Epoch: 8 [1920/3530 (54%)]\tLoss: 0.008127\n",
      "Train Epoch: 8 [2560/3530 (71%)]\tLoss: 0.008011\n",
      "Train Epoch: 8 [3200/3530 (89%)]\tLoss: 0.018094\n",
      "Train Epoch: 9 [0/3530 (0%)]\tLoss: 0.030440\n",
      "Train Epoch: 9 [640/3530 (18%)]\tLoss: 0.021053\n",
      "Train Epoch: 9 [1280/3530 (36%)]\tLoss: 0.024559\n",
      "Train Epoch: 9 [1920/3530 (54%)]\tLoss: 0.046325\n",
      "Train Epoch: 9 [2560/3530 (71%)]\tLoss: 0.011606\n",
      "Train Epoch: 9 [3200/3530 (89%)]\tLoss: 0.078444\n",
      "Train Epoch: 10 [0/3530 (0%)]\tLoss: 0.117810\n",
      "Train Epoch: 10 [640/3530 (18%)]\tLoss: 0.024384\n",
      "Train Epoch: 10 [1280/3530 (36%)]\tLoss: 0.062579\n",
      "Train Epoch: 10 [1920/3530 (54%)]\tLoss: 0.018028\n",
      "Train Epoch: 10 [2560/3530 (71%)]\tLoss: 0.012257\n",
      "Train Epoch: 10 [3200/3530 (89%)]\tLoss: 0.012066\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.1275, Accuracy: 9889/10000 (99%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 0.280410\n",
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 0.022770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 0.058725\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 0.261235\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 0.031999\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 0.140491\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 0.042530\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 0.005505\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 0.010771\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 0.128249\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 0.059579\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 0.036588\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 0.015311\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 0.052750\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 0.036320\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 0.038382\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 0.023985\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 0.045528\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 0.017507\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 0.048325\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.243968\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 0.107824\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 0.007241\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.075647\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.021542\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 0.054573\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.047301\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 0.082411\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.004760\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.034572\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.138917\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.051352\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.039058\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.056749\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.083349\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.023630\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.013148\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.226808\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.039791\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.011738\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.035583\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.041574\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.165512\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.161170\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.061390\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.061420\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.063937\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.053825\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.116039\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.167134\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.030014\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.084074\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.043072\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.018290\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.159595\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.015580\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.031245\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.027785\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.005891\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.016539\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.074487\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.049271\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.097921\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.138594\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.024497\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.040343\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.038355\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.104029\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.066816\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.004927\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.002482\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.087053\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.012748\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.086127\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.003994\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.066820\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.019956\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.029298\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.034626\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.011014\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.019519\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.028156\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.009927\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.008631\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.073737\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.051929\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.034540\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.017348\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.083209\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.032011\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.041864\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.057195\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.029487\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.021710\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.030444\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.021750\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.011328\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.140862\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.016387\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.039854\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.080427\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.081634\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.128497\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.006759\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.036873\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.009381\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.095339\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.022472\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 0.077147\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.002081\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.034493\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.038707\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.044549\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.056136\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.034264\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.034888\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.073328\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.026544\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.020156\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.064589\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.008596\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.016523\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.024885\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.012606\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.034666\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.031046\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.009989\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.018181\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.017441\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.011043\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.070659\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.023860\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.024666\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.035533\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.070767\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.007336\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.061876\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.013737\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.002042\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.023061\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.036962\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.033345\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.049250\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.033831\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.046231\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.093742\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.123789\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.025218\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.025016\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.099538\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.024426\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.106319\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.042014\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.010474\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.030547\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.117333\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.053673\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.063993\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.049846\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.026427\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.024527\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.080765\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.014583\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.155638\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.007712\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.046929\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.145132\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.015628\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.032241\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.030035\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.015854\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.041297\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.028810\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.066315\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.112793\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.029906\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.118622\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.005913\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.212742\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.087953\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/5110 (0%)]\tLoss: 0.075538\n",
      "Train Epoch: 1 [640/5110 (12%)]\tLoss: 0.129270\n",
      "Train Epoch: 1 [1280/5110 (25%)]\tLoss: 0.036590\n",
      "Train Epoch: 1 [1920/5110 (38%)]\tLoss: 0.055038\n",
      "Train Epoch: 1 [2560/5110 (50%)]\tLoss: 0.016850\n",
      "Train Epoch: 1 [3200/5110 (62%)]\tLoss: 0.153244\n",
      "Train Epoch: 1 [3840/5110 (75%)]\tLoss: 0.112203\n",
      "Train Epoch: 1 [4480/5110 (88%)]\tLoss: 0.064872\n",
      "Train Epoch: 2 [0/5110 (0%)]\tLoss: 0.055075\n",
      "Train Epoch: 2 [640/5110 (12%)]\tLoss: 0.011039\n",
      "Train Epoch: 2 [1280/5110 (25%)]\tLoss: 0.060341\n",
      "Train Epoch: 2 [1920/5110 (38%)]\tLoss: 0.143780\n",
      "Train Epoch: 2 [2560/5110 (50%)]\tLoss: 0.200477\n",
      "Train Epoch: 2 [3200/5110 (62%)]\tLoss: 0.008616\n",
      "Train Epoch: 2 [3840/5110 (75%)]\tLoss: 0.008593\n",
      "Train Epoch: 2 [4480/5110 (88%)]\tLoss: 0.149139\n",
      "Train Epoch: 3 [0/5110 (0%)]\tLoss: 0.024483\n",
      "Train Epoch: 3 [640/5110 (12%)]\tLoss: 0.087307\n",
      "Train Epoch: 3 [1280/5110 (25%)]\tLoss: 0.013124\n",
      "Train Epoch: 3 [1920/5110 (38%)]\tLoss: 0.018617\n",
      "Train Epoch: 3 [2560/5110 (50%)]\tLoss: 0.015880\n",
      "Train Epoch: 3 [3200/5110 (62%)]\tLoss: 0.028509\n",
      "Train Epoch: 3 [3840/5110 (75%)]\tLoss: 0.076915\n",
      "Train Epoch: 3 [4480/5110 (88%)]\tLoss: 0.021852\n",
      "Train Epoch: 4 [0/5110 (0%)]\tLoss: 0.015996\n",
      "Train Epoch: 4 [640/5110 (12%)]\tLoss: 0.075477\n",
      "Train Epoch: 4 [1280/5110 (25%)]\tLoss: 0.037166\n",
      "Train Epoch: 4 [1920/5110 (38%)]\tLoss: 0.128133\n",
      "Train Epoch: 4 [2560/5110 (50%)]\tLoss: 0.035219\n",
      "Train Epoch: 4 [3200/5110 (62%)]\tLoss: 0.041534\n",
      "Train Epoch: 4 [3840/5110 (75%)]\tLoss: 0.041927\n",
      "Train Epoch: 4 [4480/5110 (88%)]\tLoss: 0.056499\n",
      "Train Epoch: 5 [0/5110 (0%)]\tLoss: 0.027125\n",
      "Train Epoch: 5 [640/5110 (12%)]\tLoss: 0.077489\n",
      "Train Epoch: 5 [1280/5110 (25%)]\tLoss: 0.018471\n",
      "Train Epoch: 5 [1920/5110 (38%)]\tLoss: 0.015912\n",
      "Train Epoch: 5 [2560/5110 (50%)]\tLoss: 0.118467\n",
      "Train Epoch: 5 [3200/5110 (62%)]\tLoss: 0.076679\n",
      "Train Epoch: 5 [3840/5110 (75%)]\tLoss: 0.017671\n",
      "Train Epoch: 5 [4480/5110 (88%)]\tLoss: 0.092573\n",
      "Train Epoch: 6 [0/5110 (0%)]\tLoss: 0.047211\n",
      "Train Epoch: 6 [640/5110 (12%)]\tLoss: 0.020333\n",
      "Train Epoch: 6 [1280/5110 (25%)]\tLoss: 0.014908\n",
      "Train Epoch: 6 [1920/5110 (38%)]\tLoss: 0.004162\n",
      "Train Epoch: 6 [2560/5110 (50%)]\tLoss: 0.072707\n",
      "Train Epoch: 6 [3200/5110 (62%)]\tLoss: 0.015087\n",
      "Train Epoch: 6 [3840/5110 (75%)]\tLoss: 0.016220\n",
      "Train Epoch: 6 [4480/5110 (88%)]\tLoss: 0.005088\n",
      "Train Epoch: 7 [0/5110 (0%)]\tLoss: 0.089620\n",
      "Train Epoch: 7 [640/5110 (12%)]\tLoss: 0.030518\n",
      "Train Epoch: 7 [1280/5110 (25%)]\tLoss: 0.004319\n",
      "Train Epoch: 7 [1920/5110 (38%)]\tLoss: 0.080363\n",
      "Train Epoch: 7 [2560/5110 (50%)]\tLoss: 0.051550\n",
      "Train Epoch: 7 [3200/5110 (62%)]\tLoss: 0.054564\n",
      "Train Epoch: 7 [3840/5110 (75%)]\tLoss: 0.122955\n",
      "Train Epoch: 7 [4480/5110 (88%)]\tLoss: 0.008373\n",
      "Train Epoch: 8 [0/5110 (0%)]\tLoss: 0.030719\n",
      "Train Epoch: 8 [640/5110 (12%)]\tLoss: 0.065375\n",
      "Train Epoch: 8 [1280/5110 (25%)]\tLoss: 0.016440\n",
      "Train Epoch: 8 [1920/5110 (38%)]\tLoss: 0.007737\n",
      "Train Epoch: 8 [2560/5110 (50%)]\tLoss: 0.009636\n",
      "Train Epoch: 8 [3200/5110 (62%)]\tLoss: 0.077318\n",
      "Train Epoch: 8 [3840/5110 (75%)]\tLoss: 0.064562\n",
      "Train Epoch: 8 [4480/5110 (88%)]\tLoss: 0.027589\n",
      "Train Epoch: 9 [0/5110 (0%)]\tLoss: 0.185576\n",
      "Train Epoch: 9 [640/5110 (12%)]\tLoss: 0.122878\n",
      "Train Epoch: 9 [1280/5110 (25%)]\tLoss: 0.006922\n",
      "Train Epoch: 9 [1920/5110 (38%)]\tLoss: 0.056899\n",
      "Train Epoch: 9 [2560/5110 (50%)]\tLoss: 0.078598\n",
      "Train Epoch: 9 [3200/5110 (62%)]\tLoss: 0.036000\n",
      "Train Epoch: 9 [3840/5110 (75%)]\tLoss: 0.130435\n",
      "Train Epoch: 9 [4480/5110 (88%)]\tLoss: 0.016749\n",
      "Train Epoch: 10 [0/5110 (0%)]\tLoss: 0.040428\n",
      "Train Epoch: 10 [640/5110 (12%)]\tLoss: 0.007742\n",
      "Train Epoch: 10 [1280/5110 (25%)]\tLoss: 0.031157\n",
      "Train Epoch: 10 [1920/5110 (38%)]\tLoss: 0.010623\n",
      "Train Epoch: 10 [2560/5110 (50%)]\tLoss: 0.052034\n",
      "Train Epoch: 10 [3200/5110 (62%)]\tLoss: 0.018509\n",
      "Train Epoch: 10 [3840/5110 (75%)]\tLoss: 0.064823\n",
      "Train Epoch: 10 [4480/5110 (88%)]\tLoss: 0.074911\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6766 (0%)]\tLoss: 0.034199\n",
      "Train Epoch: 1 [640/6766 (9%)]\tLoss: 0.036723\n",
      "Train Epoch: 1 [1280/6766 (19%)]\tLoss: 0.018269\n",
      "Train Epoch: 1 [1920/6766 (28%)]\tLoss: 0.006462\n",
      "Train Epoch: 1 [2560/6766 (38%)]\tLoss: 0.041608\n",
      "Train Epoch: 1 [3200/6766 (47%)]\tLoss: 0.121101\n",
      "Train Epoch: 1 [3840/6766 (57%)]\tLoss: 0.096776\n",
      "Train Epoch: 1 [4480/6766 (66%)]\tLoss: 0.007232\n",
      "Train Epoch: 1 [5120/6766 (75%)]\tLoss: 0.031304\n",
      "Train Epoch: 1 [5760/6766 (85%)]\tLoss: 0.019866\n",
      "Train Epoch: 1 [6400/6766 (94%)]\tLoss: 0.037153\n",
      "Train Epoch: 2 [0/6766 (0%)]\tLoss: 0.078508\n",
      "Train Epoch: 2 [640/6766 (9%)]\tLoss: 0.011043\n",
      "Train Epoch: 2 [1280/6766 (19%)]\tLoss: 0.018952\n",
      "Train Epoch: 2 [1920/6766 (28%)]\tLoss: 0.023600\n",
      "Train Epoch: 2 [2560/6766 (38%)]\tLoss: 0.045778\n",
      "Train Epoch: 2 [3200/6766 (47%)]\tLoss: 0.029391\n",
      "Train Epoch: 2 [3840/6766 (57%)]\tLoss: 0.009678\n",
      "Train Epoch: 2 [4480/6766 (66%)]\tLoss: 0.033018\n",
      "Train Epoch: 2 [5120/6766 (75%)]\tLoss: 0.001892\n",
      "Train Epoch: 2 [5760/6766 (85%)]\tLoss: 0.034173\n",
      "Train Epoch: 2 [6400/6766 (94%)]\tLoss: 0.052083\n",
      "Train Epoch: 3 [0/6766 (0%)]\tLoss: 0.070640\n",
      "Train Epoch: 3 [640/6766 (9%)]\tLoss: 0.023703\n",
      "Train Epoch: 3 [1280/6766 (19%)]\tLoss: 0.027528\n",
      "Train Epoch: 3 [1920/6766 (28%)]\tLoss: 0.007439\n",
      "Train Epoch: 3 [2560/6766 (38%)]\tLoss: 0.010322\n",
      "Train Epoch: 3 [3200/6766 (47%)]\tLoss: 0.083530\n",
      "Train Epoch: 3 [3840/6766 (57%)]\tLoss: 0.021294\n",
      "Train Epoch: 3 [4480/6766 (66%)]\tLoss: 0.040144\n",
      "Train Epoch: 3 [5120/6766 (75%)]\tLoss: 0.009325\n",
      "Train Epoch: 3 [5760/6766 (85%)]\tLoss: 0.052205\n",
      "Train Epoch: 3 [6400/6766 (94%)]\tLoss: 0.000629\n",
      "Train Epoch: 4 [0/6766 (0%)]\tLoss: 0.001036\n",
      "Train Epoch: 4 [640/6766 (9%)]\tLoss: 0.023637\n",
      "Train Epoch: 4 [1280/6766 (19%)]\tLoss: 0.003904\n",
      "Train Epoch: 4 [1920/6766 (28%)]\tLoss: 0.093004\n",
      "Train Epoch: 4 [2560/6766 (38%)]\tLoss: 0.007907\n",
      "Train Epoch: 4 [3200/6766 (47%)]\tLoss: 0.008366\n",
      "Train Epoch: 4 [3840/6766 (57%)]\tLoss: 0.045437\n",
      "Train Epoch: 4 [4480/6766 (66%)]\tLoss: 0.023480\n",
      "Train Epoch: 4 [5120/6766 (75%)]\tLoss: 0.003033\n",
      "Train Epoch: 4 [5760/6766 (85%)]\tLoss: 0.046187\n",
      "Train Epoch: 4 [6400/6766 (94%)]\tLoss: 0.007442\n",
      "Train Epoch: 5 [0/6766 (0%)]\tLoss: 0.046237\n",
      "Train Epoch: 5 [640/6766 (9%)]\tLoss: 0.045440\n",
      "Train Epoch: 5 [1280/6766 (19%)]\tLoss: 0.002390\n",
      "Train Epoch: 5 [1920/6766 (28%)]\tLoss: 0.049239\n",
      "Train Epoch: 5 [2560/6766 (38%)]\tLoss: 0.009679\n",
      "Train Epoch: 5 [3200/6766 (47%)]\tLoss: 0.029132\n",
      "Train Epoch: 5 [3840/6766 (57%)]\tLoss: 0.025554\n",
      "Train Epoch: 5 [4480/6766 (66%)]\tLoss: 0.047107\n",
      "Train Epoch: 5 [5120/6766 (75%)]\tLoss: 0.013481\n",
      "Train Epoch: 5 [5760/6766 (85%)]\tLoss: 0.129937\n",
      "Train Epoch: 5 [6400/6766 (94%)]\tLoss: 0.026131\n",
      "Train Epoch: 6 [0/6766 (0%)]\tLoss: 0.003948\n",
      "Train Epoch: 6 [640/6766 (9%)]\tLoss: 0.036772\n",
      "Train Epoch: 6 [1280/6766 (19%)]\tLoss: 0.019484\n",
      "Train Epoch: 6 [1920/6766 (28%)]\tLoss: 0.285613\n",
      "Train Epoch: 6 [2560/6766 (38%)]\tLoss: 0.054011\n",
      "Train Epoch: 6 [3200/6766 (47%)]\tLoss: 0.004061\n",
      "Train Epoch: 6 [3840/6766 (57%)]\tLoss: 0.010075\n",
      "Train Epoch: 6 [4480/6766 (66%)]\tLoss: 0.004389\n",
      "Train Epoch: 6 [5120/6766 (75%)]\tLoss: 0.032838\n",
      "Train Epoch: 6 [5760/6766 (85%)]\tLoss: 0.012837\n",
      "Train Epoch: 6 [6400/6766 (94%)]\tLoss: 0.069959\n",
      "Train Epoch: 7 [0/6766 (0%)]\tLoss: 0.105402\n",
      "Train Epoch: 7 [640/6766 (9%)]\tLoss: 0.061464\n",
      "Train Epoch: 7 [1280/6766 (19%)]\tLoss: 0.008502\n",
      "Train Epoch: 7 [1920/6766 (28%)]\tLoss: 0.031082\n",
      "Train Epoch: 7 [2560/6766 (38%)]\tLoss: 0.038860\n",
      "Train Epoch: 7 [3200/6766 (47%)]\tLoss: 0.028752\n",
      "Train Epoch: 7 [3840/6766 (57%)]\tLoss: 0.003433\n",
      "Train Epoch: 7 [4480/6766 (66%)]\tLoss: 0.003771\n",
      "Train Epoch: 7 [5120/6766 (75%)]\tLoss: 0.004073\n",
      "Train Epoch: 7 [5760/6766 (85%)]\tLoss: 0.081434\n",
      "Train Epoch: 7 [6400/6766 (94%)]\tLoss: 0.010128\n",
      "Train Epoch: 8 [0/6766 (0%)]\tLoss: 0.011799\n",
      "Train Epoch: 8 [640/6766 (9%)]\tLoss: 0.030627\n",
      "Train Epoch: 8 [1280/6766 (19%)]\tLoss: 0.007614\n",
      "Train Epoch: 8 [1920/6766 (28%)]\tLoss: 0.003296\n",
      "Train Epoch: 8 [2560/6766 (38%)]\tLoss: 0.057574\n",
      "Train Epoch: 8 [3200/6766 (47%)]\tLoss: 0.053653\n",
      "Train Epoch: 8 [3840/6766 (57%)]\tLoss: 0.006103\n",
      "Train Epoch: 8 [4480/6766 (66%)]\tLoss: 0.031492\n",
      "Train Epoch: 8 [5120/6766 (75%)]\tLoss: 0.020410\n",
      "Train Epoch: 8 [5760/6766 (85%)]\tLoss: 0.003227\n",
      "Train Epoch: 8 [6400/6766 (94%)]\tLoss: 0.006444\n",
      "Train Epoch: 9 [0/6766 (0%)]\tLoss: 0.209732\n",
      "Train Epoch: 9 [640/6766 (9%)]\tLoss: 0.057058\n",
      "Train Epoch: 9 [1280/6766 (19%)]\tLoss: 0.009799\n",
      "Train Epoch: 9 [1920/6766 (28%)]\tLoss: 0.015104\n",
      "Train Epoch: 9 [2560/6766 (38%)]\tLoss: 0.006039\n",
      "Train Epoch: 9 [3200/6766 (47%)]\tLoss: 0.048794\n",
      "Train Epoch: 9 [3840/6766 (57%)]\tLoss: 0.015194\n",
      "Train Epoch: 9 [4480/6766 (66%)]\tLoss: 0.012839\n",
      "Train Epoch: 9 [5120/6766 (75%)]\tLoss: 0.005927\n",
      "Train Epoch: 9 [5760/6766 (85%)]\tLoss: 0.011559\n",
      "Train Epoch: 9 [6400/6766 (94%)]\tLoss: 0.000924\n",
      "Train Epoch: 10 [0/6766 (0%)]\tLoss: 0.009595\n",
      "Train Epoch: 10 [640/6766 (9%)]\tLoss: 0.011250\n",
      "Train Epoch: 10 [1280/6766 (19%)]\tLoss: 0.022383\n",
      "Train Epoch: 10 [1920/6766 (28%)]\tLoss: 0.007295\n",
      "Train Epoch: 10 [2560/6766 (38%)]\tLoss: 0.024759\n",
      "Train Epoch: 10 [3200/6766 (47%)]\tLoss: 0.040856\n",
      "Train Epoch: 10 [3840/6766 (57%)]\tLoss: 0.106797\n",
      "Train Epoch: 10 [4480/6766 (66%)]\tLoss: 0.028501\n",
      "Train Epoch: 10 [5120/6766 (75%)]\tLoss: 0.052288\n",
      "Train Epoch: 10 [5760/6766 (85%)]\tLoss: 0.004980\n",
      "Train Epoch: 10 [6400/6766 (94%)]\tLoss: 0.003970\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 0.024374\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 0.027586\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 0.035529\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 0.107562\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 0.020145\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 0.010431\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 0.030521\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 0.119857\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 0.075636\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 0.004613\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 0.017263\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 0.106392\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 0.005048\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 0.044455\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 0.051846\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 0.026807\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 0.142240\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.008166\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.122529\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.009613\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.009014\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.004893\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.027189\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.011873\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.022377\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.032871\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.094830\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.022605\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.060868\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.079219\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.019882\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.071536\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.026956\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.098041\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.009170\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.106206\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.088025\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.076660\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.031566\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.045644\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.009303\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.100962\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.007391\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.129996\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.038890\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.030180\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.027106\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.010190\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.014588\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.137852\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.033828\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.300358\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.119689\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.069705\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.016891\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.016078\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.133600\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.051513\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.030440\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.013378\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.057932\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.047444\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.004364\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.010727\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.175115\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.059642\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.015547\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.007678\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.091700\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.024214\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.058525\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.051724\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.010743\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.031741\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.014366\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.045726\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.079346\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.050052\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.013966\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.056357\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.056133\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.012673\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.017204\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.028242\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.007292\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.008732\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.007835\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.048280\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.041511\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.046706\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.016503\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.054433\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.074358\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.048730\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.026329\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.035928\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.035463\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.060529\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.018780\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.063032\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.096373\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.050973\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.022618\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.050959\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.057528\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.015351\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.006229\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.022213\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.005617\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.023695\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.101622\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.029264\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.024564\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.012740\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.022903\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.137357\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.039220\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.010704\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.013087\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.053760\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.076589\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.090778\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.051832\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.012370\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.021104\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.018812\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.065126\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.024249\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.010988\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.072715\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.030267\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.003696\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.002664\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.005987\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.282997\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.002013\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.008289\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.029458\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.034683\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.064559\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.039517\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.007425\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.098263\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.111019\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.037561\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.018055\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.014814\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.011179\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.016123\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.026766\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.066667\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.020956\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.018246\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.069185\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.001416\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.095297\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.036445\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.013871\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.228663\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.064205\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/3910 (0%)]\tLoss: 0.047014\n",
      "Train Epoch: 1 [640/3910 (16%)]\tLoss: 0.106649\n",
      "Train Epoch: 1 [1280/3910 (32%)]\tLoss: 0.050886\n",
      "Train Epoch: 1 [1920/3910 (48%)]\tLoss: 0.032811\n",
      "Train Epoch: 1 [2560/3910 (65%)]\tLoss: 0.111052\n",
      "Train Epoch: 1 [3200/3910 (81%)]\tLoss: 0.252980\n",
      "Train Epoch: 1 [3840/3910 (97%)]\tLoss: 0.029282\n",
      "Train Epoch: 2 [0/3910 (0%)]\tLoss: 0.058639\n",
      "Train Epoch: 2 [640/3910 (16%)]\tLoss: 0.071157\n",
      "Train Epoch: 2 [1280/3910 (32%)]\tLoss: 0.020575\n",
      "Train Epoch: 2 [1920/3910 (48%)]\tLoss: 0.150126\n",
      "Train Epoch: 2 [2560/3910 (65%)]\tLoss: 0.194805\n",
      "Train Epoch: 2 [3200/3910 (81%)]\tLoss: 0.012236\n",
      "Train Epoch: 2 [3840/3910 (97%)]\tLoss: 0.035358\n",
      "Train Epoch: 3 [0/3910 (0%)]\tLoss: 0.153551\n",
      "Train Epoch: 3 [640/3910 (16%)]\tLoss: 0.043214\n",
      "Train Epoch: 3 [1280/3910 (32%)]\tLoss: 0.112861\n",
      "Train Epoch: 3 [1920/3910 (48%)]\tLoss: 0.015289\n",
      "Train Epoch: 3 [2560/3910 (65%)]\tLoss: 0.042236\n",
      "Train Epoch: 3 [3200/3910 (81%)]\tLoss: 0.032320\n",
      "Train Epoch: 3 [3840/3910 (97%)]\tLoss: 0.030519\n",
      "Train Epoch: 4 [0/3910 (0%)]\tLoss: 0.123408\n",
      "Train Epoch: 4 [640/3910 (16%)]\tLoss: 0.027790\n",
      "Train Epoch: 4 [1280/3910 (32%)]\tLoss: 0.118143\n",
      "Train Epoch: 4 [1920/3910 (48%)]\tLoss: 0.011915\n",
      "Train Epoch: 4 [2560/3910 (65%)]\tLoss: 0.027014\n",
      "Train Epoch: 4 [3200/3910 (81%)]\tLoss: 0.154081\n",
      "Train Epoch: 4 [3840/3910 (97%)]\tLoss: 0.020086\n",
      "Train Epoch: 5 [0/3910 (0%)]\tLoss: 0.012324\n",
      "Train Epoch: 5 [640/3910 (16%)]\tLoss: 0.029804\n",
      "Train Epoch: 5 [1280/3910 (32%)]\tLoss: 0.060851\n",
      "Train Epoch: 5 [1920/3910 (48%)]\tLoss: 0.004416\n",
      "Train Epoch: 5 [2560/3910 (65%)]\tLoss: 0.004977\n",
      "Train Epoch: 5 [3200/3910 (81%)]\tLoss: 0.001551\n",
      "Train Epoch: 5 [3840/3910 (97%)]\tLoss: 0.018657\n",
      "Train Epoch: 6 [0/3910 (0%)]\tLoss: 0.020080\n",
      "Train Epoch: 6 [640/3910 (16%)]\tLoss: 0.053493\n",
      "Train Epoch: 6 [1280/3910 (32%)]\tLoss: 0.167083\n",
      "Train Epoch: 6 [1920/3910 (48%)]\tLoss: 0.015114\n",
      "Train Epoch: 6 [2560/3910 (65%)]\tLoss: 0.064006\n",
      "Train Epoch: 6 [3200/3910 (81%)]\tLoss: 0.035091\n",
      "Train Epoch: 6 [3840/3910 (97%)]\tLoss: 0.129199\n",
      "Train Epoch: 7 [0/3910 (0%)]\tLoss: 0.038382\n",
      "Train Epoch: 7 [640/3910 (16%)]\tLoss: 0.026240\n",
      "Train Epoch: 7 [1280/3910 (32%)]\tLoss: 0.042191\n",
      "Train Epoch: 7 [1920/3910 (48%)]\tLoss: 0.009598\n",
      "Train Epoch: 7 [2560/3910 (65%)]\tLoss: 0.013133\n",
      "Train Epoch: 7 [3200/3910 (81%)]\tLoss: 0.091496\n",
      "Train Epoch: 7 [3840/3910 (97%)]\tLoss: 0.033367\n",
      "Train Epoch: 8 [0/3910 (0%)]\tLoss: 0.064331\n",
      "Train Epoch: 8 [640/3910 (16%)]\tLoss: 0.075744\n",
      "Train Epoch: 8 [1280/3910 (32%)]\tLoss: 0.113524\n",
      "Train Epoch: 8 [1920/3910 (48%)]\tLoss: 0.006972\n",
      "Train Epoch: 8 [2560/3910 (65%)]\tLoss: 0.090175\n",
      "Train Epoch: 8 [3200/3910 (81%)]\tLoss: 0.066526\n",
      "Train Epoch: 8 [3840/3910 (97%)]\tLoss: 0.043816\n",
      "Train Epoch: 9 [0/3910 (0%)]\tLoss: 0.019382\n",
      "Train Epoch: 9 [640/3910 (16%)]\tLoss: 0.022853\n",
      "Train Epoch: 9 [1280/3910 (32%)]\tLoss: 0.051033\n",
      "Train Epoch: 9 [1920/3910 (48%)]\tLoss: 0.022203\n",
      "Train Epoch: 9 [2560/3910 (65%)]\tLoss: 0.006898\n",
      "Train Epoch: 9 [3200/3910 (81%)]\tLoss: 0.020346\n",
      "Train Epoch: 9 [3840/3910 (97%)]\tLoss: 0.087648\n",
      "Train Epoch: 10 [0/3910 (0%)]\tLoss: 0.033152\n",
      "Train Epoch: 10 [640/3910 (16%)]\tLoss: 0.014468\n",
      "Train Epoch: 10 [1280/3910 (32%)]\tLoss: 0.099570\n",
      "Train Epoch: 10 [1920/3910 (48%)]\tLoss: 0.026650\n",
      "Train Epoch: 10 [2560/3910 (65%)]\tLoss: 0.008012\n",
      "Train Epoch: 10 [3200/3910 (81%)]\tLoss: 0.020514\n",
      "Train Epoch: 10 [3840/3910 (97%)]\tLoss: 0.015415\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 0.127358\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 0.071928\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 0.074327\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 0.097734\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 0.046441\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 0.092401\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 0.127922\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 0.081021\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 0.010439\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 0.016121\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.094196\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.066553\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 0.017368\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 0.011105\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 0.063715\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.149409\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.044307\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.036568\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.090843\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.045944\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.087489\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.088110\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.001355\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.004616\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.001827\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.004147\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.003950\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.016833\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.172465\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.080948\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.002031\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.083182\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.108130\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.020677\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.009241\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.020923\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.029930\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.015470\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.119062\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.015054\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.088612\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.054233\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.008543\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.001422\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.021607\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.015636\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.087752\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.005708\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.040945\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.007142\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.007210\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.082150\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.034778\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.059387\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.025056\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.155780\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.009076\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.004764\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.007766\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.022625\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.045592\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.007368\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.013109\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.033312\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.046437\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.013566\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.074665\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.004050\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.063210\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.031225\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.001509\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.039193\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.005893\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.010481\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.016715\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.025615\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.052777\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.018225\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.060176\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.070698\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.035150\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.006818\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.008247\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.007893\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.007645\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.022200\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.020197\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.040394\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.018714\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.145946\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.049014\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.002519\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.043391\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.003988\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.001272\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.033518\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.001077\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.073841\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.001788\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.002809\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.012050\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.000753\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.001728\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.004952\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.018065\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.103501\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.017769\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.003784\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.044478\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.038646\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.003974\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.010823\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.021189\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.009451\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.049572\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.007506\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.004106\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.008786\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.026506\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.004598\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/5096 (0%)]\tLoss: 0.043658\n",
      "Train Epoch: 1 [640/5096 (12%)]\tLoss: 0.266805\n",
      "Train Epoch: 1 [1280/5096 (25%)]\tLoss: 0.021164\n",
      "Train Epoch: 1 [1920/5096 (38%)]\tLoss: 0.006088\n",
      "Train Epoch: 1 [2560/5096 (50%)]\tLoss: 0.059167\n",
      "Train Epoch: 1 [3200/5096 (62%)]\tLoss: 0.052704\n",
      "Train Epoch: 1 [3840/5096 (75%)]\tLoss: 0.037928\n",
      "Train Epoch: 1 [4480/5096 (88%)]\tLoss: 0.001565\n",
      "Train Epoch: 2 [0/5096 (0%)]\tLoss: 0.037156\n",
      "Train Epoch: 2 [640/5096 (12%)]\tLoss: 0.006431\n",
      "Train Epoch: 2 [1280/5096 (25%)]\tLoss: 0.010749\n",
      "Train Epoch: 2 [1920/5096 (38%)]\tLoss: 0.006174\n",
      "Train Epoch: 2 [2560/5096 (50%)]\tLoss: 0.009592\n",
      "Train Epoch: 2 [3200/5096 (62%)]\tLoss: 0.002804\n",
      "Train Epoch: 2 [3840/5096 (75%)]\tLoss: 0.038420\n",
      "Train Epoch: 2 [4480/5096 (88%)]\tLoss: 0.000299\n",
      "Train Epoch: 3 [0/5096 (0%)]\tLoss: 0.009943\n",
      "Train Epoch: 3 [640/5096 (12%)]\tLoss: 0.013090\n",
      "Train Epoch: 3 [1280/5096 (25%)]\tLoss: 0.065515\n",
      "Train Epoch: 3 [1920/5096 (38%)]\tLoss: 0.005729\n",
      "Train Epoch: 3 [2560/5096 (50%)]\tLoss: 0.018688\n",
      "Train Epoch: 3 [3200/5096 (62%)]\tLoss: 0.042383\n",
      "Train Epoch: 3 [3840/5096 (75%)]\tLoss: 0.006424\n",
      "Train Epoch: 3 [4480/5096 (88%)]\tLoss: 0.003054\n",
      "Train Epoch: 4 [0/5096 (0%)]\tLoss: 0.044682\n",
      "Train Epoch: 4 [640/5096 (12%)]\tLoss: 0.003879\n",
      "Train Epoch: 4 [1280/5096 (25%)]\tLoss: 0.008895\n",
      "Train Epoch: 4 [1920/5096 (38%)]\tLoss: 0.005487\n",
      "Train Epoch: 4 [2560/5096 (50%)]\tLoss: 0.024142\n",
      "Train Epoch: 4 [3200/5096 (62%)]\tLoss: 0.003694\n",
      "Train Epoch: 4 [3840/5096 (75%)]\tLoss: 0.004047\n",
      "Train Epoch: 4 [4480/5096 (88%)]\tLoss: 0.019112\n",
      "Train Epoch: 5 [0/5096 (0%)]\tLoss: 0.022771\n",
      "Train Epoch: 5 [640/5096 (12%)]\tLoss: 0.006251\n",
      "Train Epoch: 5 [1280/5096 (25%)]\tLoss: 0.003681\n",
      "Train Epoch: 5 [1920/5096 (38%)]\tLoss: 0.041605\n",
      "Train Epoch: 5 [2560/5096 (50%)]\tLoss: 0.005668\n",
      "Train Epoch: 5 [3200/5096 (62%)]\tLoss: 0.069014\n",
      "Train Epoch: 5 [3840/5096 (75%)]\tLoss: 0.012218\n",
      "Train Epoch: 5 [4480/5096 (88%)]\tLoss: 0.002171\n",
      "Train Epoch: 6 [0/5096 (0%)]\tLoss: 0.149142\n",
      "Train Epoch: 6 [640/5096 (12%)]\tLoss: 0.047081\n",
      "Train Epoch: 6 [1280/5096 (25%)]\tLoss: 0.015208\n",
      "Train Epoch: 6 [1920/5096 (38%)]\tLoss: 0.011556\n",
      "Train Epoch: 6 [2560/5096 (50%)]\tLoss: 0.007670\n",
      "Train Epoch: 6 [3200/5096 (62%)]\tLoss: 0.006161\n",
      "Train Epoch: 6 [3840/5096 (75%)]\tLoss: 0.000788\n",
      "Train Epoch: 6 [4480/5096 (88%)]\tLoss: 0.030069\n",
      "Train Epoch: 7 [0/5096 (0%)]\tLoss: 0.010447\n",
      "Train Epoch: 7 [640/5096 (12%)]\tLoss: 0.009573\n",
      "Train Epoch: 7 [1280/5096 (25%)]\tLoss: 0.043080\n",
      "Train Epoch: 7 [1920/5096 (38%)]\tLoss: 0.142415\n",
      "Train Epoch: 7 [2560/5096 (50%)]\tLoss: 0.029590\n",
      "Train Epoch: 7 [3200/5096 (62%)]\tLoss: 0.004655\n",
      "Train Epoch: 7 [3840/5096 (75%)]\tLoss: 0.012613\n",
      "Train Epoch: 7 [4480/5096 (88%)]\tLoss: 0.007280\n",
      "Train Epoch: 8 [0/5096 (0%)]\tLoss: 0.024622\n",
      "Train Epoch: 8 [640/5096 (12%)]\tLoss: 0.009201\n",
      "Train Epoch: 8 [1280/5096 (25%)]\tLoss: 0.020210\n",
      "Train Epoch: 8 [1920/5096 (38%)]\tLoss: 0.009728\n",
      "Train Epoch: 8 [2560/5096 (50%)]\tLoss: 0.024123\n",
      "Train Epoch: 8 [3200/5096 (62%)]\tLoss: 0.047967\n",
      "Train Epoch: 8 [3840/5096 (75%)]\tLoss: 0.004158\n",
      "Train Epoch: 8 [4480/5096 (88%)]\tLoss: 0.002387\n",
      "Train Epoch: 9 [0/5096 (0%)]\tLoss: 0.004303\n",
      "Train Epoch: 9 [640/5096 (12%)]\tLoss: 0.019086\n",
      "Train Epoch: 9 [1280/5096 (25%)]\tLoss: 0.060782\n",
      "Train Epoch: 9 [1920/5096 (38%)]\tLoss: 0.008107\n",
      "Train Epoch: 9 [2560/5096 (50%)]\tLoss: 0.025173\n",
      "Train Epoch: 9 [3200/5096 (62%)]\tLoss: 0.002843\n",
      "Train Epoch: 9 [3840/5096 (75%)]\tLoss: 0.003281\n",
      "Train Epoch: 9 [4480/5096 (88%)]\tLoss: 0.121022\n",
      "Train Epoch: 10 [0/5096 (0%)]\tLoss: 0.002283\n",
      "Train Epoch: 10 [640/5096 (12%)]\tLoss: 0.001083\n",
      "Train Epoch: 10 [1280/5096 (25%)]\tLoss: 0.017950\n",
      "Train Epoch: 10 [1920/5096 (38%)]\tLoss: 0.095006\n",
      "Train Epoch: 10 [2560/5096 (50%)]\tLoss: 0.004551\n",
      "Train Epoch: 10 [3200/5096 (62%)]\tLoss: 0.032609\n",
      "Train Epoch: 10 [3840/5096 (75%)]\tLoss: 0.001091\n",
      "Train Epoch: 10 [4480/5096 (88%)]\tLoss: 0.002930\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/1599 (0%)]\tLoss: 0.611655\n",
      "Train Epoch: 1 [640/1599 (40%)]\tLoss: 0.031229\n",
      "Train Epoch: 1 [1280/1599 (80%)]\tLoss: 0.072354\n",
      "Train Epoch: 2 [0/1599 (0%)]\tLoss: 0.018222\n",
      "Train Epoch: 2 [640/1599 (40%)]\tLoss: 0.022650\n",
      "Train Epoch: 2 [1280/1599 (80%)]\tLoss: 0.069458\n",
      "Train Epoch: 3 [0/1599 (0%)]\tLoss: 0.162041\n",
      "Train Epoch: 3 [640/1599 (40%)]\tLoss: 0.043373\n",
      "Train Epoch: 3 [1280/1599 (80%)]\tLoss: 0.065385\n",
      "Train Epoch: 4 [0/1599 (0%)]\tLoss: 0.030683\n",
      "Train Epoch: 4 [640/1599 (40%)]\tLoss: 0.011415\n",
      "Train Epoch: 4 [1280/1599 (80%)]\tLoss: 0.022148\n",
      "Train Epoch: 5 [0/1599 (0%)]\tLoss: 0.135005\n",
      "Train Epoch: 5 [640/1599 (40%)]\tLoss: 0.076931\n",
      "Train Epoch: 5 [1280/1599 (80%)]\tLoss: 0.010837\n",
      "Train Epoch: 6 [0/1599 (0%)]\tLoss: 0.053114\n",
      "Train Epoch: 6 [640/1599 (40%)]\tLoss: 0.026047\n",
      "Train Epoch: 6 [1280/1599 (80%)]\tLoss: 0.012626\n",
      "Train Epoch: 7 [0/1599 (0%)]\tLoss: 0.003814\n",
      "Train Epoch: 7 [640/1599 (40%)]\tLoss: 0.012755\n",
      "Train Epoch: 7 [1280/1599 (80%)]\tLoss: 0.085999\n",
      "Train Epoch: 8 [0/1599 (0%)]\tLoss: 0.038105\n",
      "Train Epoch: 8 [640/1599 (40%)]\tLoss: 0.062074\n",
      "Train Epoch: 8 [1280/1599 (80%)]\tLoss: 0.006293\n",
      "Train Epoch: 9 [0/1599 (0%)]\tLoss: 0.045734\n",
      "Train Epoch: 9 [640/1599 (40%)]\tLoss: 0.067282\n",
      "Train Epoch: 9 [1280/1599 (80%)]\tLoss: 0.024961\n",
      "Train Epoch: 10 [0/1599 (0%)]\tLoss: 0.021421\n",
      "Train Epoch: 10 [640/1599 (40%)]\tLoss: 0.066697\n",
      "Train Epoch: 10 [1280/1599 (80%)]\tLoss: 0.136825\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/5266 (0%)]\tLoss: 0.107275\n",
      "Train Epoch: 1 [640/5266 (12%)]\tLoss: 0.023290\n",
      "Train Epoch: 1 [1280/5266 (24%)]\tLoss: 0.018837\n",
      "Train Epoch: 1 [1920/5266 (36%)]\tLoss: 0.056210\n",
      "Train Epoch: 1 [2560/5266 (48%)]\tLoss: 0.014565\n",
      "Train Epoch: 1 [3200/5266 (60%)]\tLoss: 0.007120\n",
      "Train Epoch: 1 [3840/5266 (72%)]\tLoss: 0.000782\n",
      "Train Epoch: 1 [4480/5266 (84%)]\tLoss: 0.048511\n",
      "Train Epoch: 1 [5120/5266 (96%)]\tLoss: 0.052165\n",
      "Train Epoch: 2 [0/5266 (0%)]\tLoss: 0.009878\n",
      "Train Epoch: 2 [640/5266 (12%)]\tLoss: 0.045811\n",
      "Train Epoch: 2 [1280/5266 (24%)]\tLoss: 0.092495\n",
      "Train Epoch: 2 [1920/5266 (36%)]\tLoss: 0.033322\n",
      "Train Epoch: 2 [2560/5266 (48%)]\tLoss: 0.001753\n",
      "Train Epoch: 2 [3200/5266 (60%)]\tLoss: 0.019341\n",
      "Train Epoch: 2 [3840/5266 (72%)]\tLoss: 0.051228\n",
      "Train Epoch: 2 [4480/5266 (84%)]\tLoss: 0.024262\n",
      "Train Epoch: 2 [5120/5266 (96%)]\tLoss: 0.015646\n",
      "Train Epoch: 3 [0/5266 (0%)]\tLoss: 0.006485\n",
      "Train Epoch: 3 [640/5266 (12%)]\tLoss: 0.034306\n",
      "Train Epoch: 3 [1280/5266 (24%)]\tLoss: 0.015765\n",
      "Train Epoch: 3 [1920/5266 (36%)]\tLoss: 0.006808\n",
      "Train Epoch: 3 [2560/5266 (48%)]\tLoss: 0.045141\n",
      "Train Epoch: 3 [3200/5266 (60%)]\tLoss: 0.002428\n",
      "Train Epoch: 3 [3840/5266 (72%)]\tLoss: 0.011795\n",
      "Train Epoch: 3 [4480/5266 (84%)]\tLoss: 0.034924\n",
      "Train Epoch: 3 [5120/5266 (96%)]\tLoss: 0.004241\n",
      "Train Epoch: 4 [0/5266 (0%)]\tLoss: 0.008647\n",
      "Train Epoch: 4 [640/5266 (12%)]\tLoss: 0.009728\n",
      "Train Epoch: 4 [1280/5266 (24%)]\tLoss: 0.023981\n",
      "Train Epoch: 4 [1920/5266 (36%)]\tLoss: 0.011771\n",
      "Train Epoch: 4 [2560/5266 (48%)]\tLoss: 0.001103\n",
      "Train Epoch: 4 [3200/5266 (60%)]\tLoss: 0.021582\n",
      "Train Epoch: 4 [3840/5266 (72%)]\tLoss: 0.012561\n",
      "Train Epoch: 4 [4480/5266 (84%)]\tLoss: 0.036742\n",
      "Train Epoch: 4 [5120/5266 (96%)]\tLoss: 0.004450\n",
      "Train Epoch: 5 [0/5266 (0%)]\tLoss: 0.002706\n",
      "Train Epoch: 5 [640/5266 (12%)]\tLoss: 0.025702\n",
      "Train Epoch: 5 [1280/5266 (24%)]\tLoss: 0.009313\n",
      "Train Epoch: 5 [1920/5266 (36%)]\tLoss: 0.006842\n",
      "Train Epoch: 5 [2560/5266 (48%)]\tLoss: 0.017574\n",
      "Train Epoch: 5 [3200/5266 (60%)]\tLoss: 0.027219\n",
      "Train Epoch: 5 [3840/5266 (72%)]\tLoss: 0.027039\n",
      "Train Epoch: 5 [4480/5266 (84%)]\tLoss: 0.019398\n",
      "Train Epoch: 5 [5120/5266 (96%)]\tLoss: 0.001764\n",
      "Train Epoch: 6 [0/5266 (0%)]\tLoss: 0.078594\n",
      "Train Epoch: 6 [640/5266 (12%)]\tLoss: 0.000979\n",
      "Train Epoch: 6 [1280/5266 (24%)]\tLoss: 0.039174\n",
      "Train Epoch: 6 [1920/5266 (36%)]\tLoss: 0.029508\n",
      "Train Epoch: 6 [2560/5266 (48%)]\tLoss: 0.000267\n",
      "Train Epoch: 6 [3200/5266 (60%)]\tLoss: 0.002131\n",
      "Train Epoch: 6 [3840/5266 (72%)]\tLoss: 0.039761\n",
      "Train Epoch: 6 [4480/5266 (84%)]\tLoss: 0.000383\n",
      "Train Epoch: 6 [5120/5266 (96%)]\tLoss: 0.000097\n",
      "Train Epoch: 7 [0/5266 (0%)]\tLoss: 0.003226\n",
      "Train Epoch: 7 [640/5266 (12%)]\tLoss: 0.008570\n",
      "Train Epoch: 7 [1280/5266 (24%)]\tLoss: 0.000276\n",
      "Train Epoch: 7 [1920/5266 (36%)]\tLoss: 0.027552\n",
      "Train Epoch: 7 [2560/5266 (48%)]\tLoss: 0.006850\n",
      "Train Epoch: 7 [3200/5266 (60%)]\tLoss: 0.026166\n",
      "Train Epoch: 7 [3840/5266 (72%)]\tLoss: 0.004570\n",
      "Train Epoch: 7 [4480/5266 (84%)]\tLoss: 0.001855\n",
      "Train Epoch: 7 [5120/5266 (96%)]\tLoss: 0.010419\n",
      "Train Epoch: 8 [0/5266 (0%)]\tLoss: 0.014888\n",
      "Train Epoch: 8 [640/5266 (12%)]\tLoss: 0.039683\n",
      "Train Epoch: 8 [1280/5266 (24%)]\tLoss: 0.097136\n",
      "Train Epoch: 8 [1920/5266 (36%)]\tLoss: 0.001930\n",
      "Train Epoch: 8 [2560/5266 (48%)]\tLoss: 0.000532\n",
      "Train Epoch: 8 [3200/5266 (60%)]\tLoss: 0.003430\n",
      "Train Epoch: 8 [3840/5266 (72%)]\tLoss: 0.009487\n",
      "Train Epoch: 8 [4480/5266 (84%)]\tLoss: 0.000113\n",
      "Train Epoch: 8 [5120/5266 (96%)]\tLoss: 0.003560\n",
      "Train Epoch: 9 [0/5266 (0%)]\tLoss: 0.052136\n",
      "Train Epoch: 9 [640/5266 (12%)]\tLoss: 0.001817\n",
      "Train Epoch: 9 [1280/5266 (24%)]\tLoss: 0.000632\n",
      "Train Epoch: 9 [1920/5266 (36%)]\tLoss: 0.057945\n",
      "Train Epoch: 9 [2560/5266 (48%)]\tLoss: 0.002860\n",
      "Train Epoch: 9 [3200/5266 (60%)]\tLoss: 0.006677\n",
      "Train Epoch: 9 [3840/5266 (72%)]\tLoss: 0.004339\n",
      "Train Epoch: 9 [4480/5266 (84%)]\tLoss: 0.010524\n",
      "Train Epoch: 9 [5120/5266 (96%)]\tLoss: 0.057134\n",
      "Train Epoch: 10 [0/5266 (0%)]\tLoss: 0.008907\n",
      "Train Epoch: 10 [640/5266 (12%)]\tLoss: 0.020710\n",
      "Train Epoch: 10 [1280/5266 (24%)]\tLoss: 0.002781\n",
      "Train Epoch: 10 [1920/5266 (36%)]\tLoss: 0.018001\n",
      "Train Epoch: 10 [2560/5266 (48%)]\tLoss: 0.000598\n",
      "Train Epoch: 10 [3200/5266 (60%)]\tLoss: 0.003943\n",
      "Train Epoch: 10 [3840/5266 (72%)]\tLoss: 0.036768\n",
      "Train Epoch: 10 [4480/5266 (84%)]\tLoss: 0.016020\n",
      "Train Epoch: 10 [5120/5266 (96%)]\tLoss: 0.004753\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/3530 (0%)]\tLoss: 0.179506\n",
      "Train Epoch: 1 [640/3530 (18%)]\tLoss: 0.160554\n",
      "Train Epoch: 1 [1280/3530 (36%)]\tLoss: 0.042685\n",
      "Train Epoch: 1 [1920/3530 (54%)]\tLoss: 0.018833\n",
      "Train Epoch: 1 [2560/3530 (71%)]\tLoss: 0.057303\n",
      "Train Epoch: 1 [3200/3530 (89%)]\tLoss: 0.091568\n",
      "Train Epoch: 2 [0/3530 (0%)]\tLoss: 0.048100\n",
      "Train Epoch: 2 [640/3530 (18%)]\tLoss: 0.023512\n",
      "Train Epoch: 2 [1280/3530 (36%)]\tLoss: 0.016035\n",
      "Train Epoch: 2 [1920/3530 (54%)]\tLoss: 0.008781\n",
      "Train Epoch: 2 [2560/3530 (71%)]\tLoss: 0.018378\n",
      "Train Epoch: 2 [3200/3530 (89%)]\tLoss: 0.061228\n",
      "Train Epoch: 3 [0/3530 (0%)]\tLoss: 0.030355\n",
      "Train Epoch: 3 [640/3530 (18%)]\tLoss: 0.020557\n",
      "Train Epoch: 3 [1280/3530 (36%)]\tLoss: 0.144275\n",
      "Train Epoch: 3 [1920/3530 (54%)]\tLoss: 0.026102\n",
      "Train Epoch: 3 [2560/3530 (71%)]\tLoss: 0.018188\n",
      "Train Epoch: 3 [3200/3530 (89%)]\tLoss: 0.057396\n",
      "Train Epoch: 4 [0/3530 (0%)]\tLoss: 0.060234\n",
      "Train Epoch: 4 [640/3530 (18%)]\tLoss: 0.017093\n",
      "Train Epoch: 4 [1280/3530 (36%)]\tLoss: 0.014940\n",
      "Train Epoch: 4 [1920/3530 (54%)]\tLoss: 0.037259\n",
      "Train Epoch: 4 [2560/3530 (71%)]\tLoss: 0.033451\n",
      "Train Epoch: 4 [3200/3530 (89%)]\tLoss: 0.046147\n",
      "Train Epoch: 5 [0/3530 (0%)]\tLoss: 0.165734\n",
      "Train Epoch: 5 [640/3530 (18%)]\tLoss: 0.020637\n",
      "Train Epoch: 5 [1280/3530 (36%)]\tLoss: 0.029412\n",
      "Train Epoch: 5 [1920/3530 (54%)]\tLoss: 0.051927\n",
      "Train Epoch: 5 [2560/3530 (71%)]\tLoss: 0.075664\n",
      "Train Epoch: 5 [3200/3530 (89%)]\tLoss: 0.010009\n",
      "Train Epoch: 6 [0/3530 (0%)]\tLoss: 0.104294\n",
      "Train Epoch: 6 [640/3530 (18%)]\tLoss: 0.055313\n",
      "Train Epoch: 6 [1280/3530 (36%)]\tLoss: 0.082822\n",
      "Train Epoch: 6 [1920/3530 (54%)]\tLoss: 0.058661\n",
      "Train Epoch: 6 [2560/3530 (71%)]\tLoss: 0.026385\n",
      "Train Epoch: 6 [3200/3530 (89%)]\tLoss: 0.010571\n",
      "Train Epoch: 7 [0/3530 (0%)]\tLoss: 0.014233\n",
      "Train Epoch: 7 [640/3530 (18%)]\tLoss: 0.040434\n",
      "Train Epoch: 7 [1280/3530 (36%)]\tLoss: 0.082798\n",
      "Train Epoch: 7 [1920/3530 (54%)]\tLoss: 0.049784\n",
      "Train Epoch: 7 [2560/3530 (71%)]\tLoss: 0.050108\n",
      "Train Epoch: 7 [3200/3530 (89%)]\tLoss: 0.022640\n",
      "Train Epoch: 8 [0/3530 (0%)]\tLoss: 0.053939\n",
      "Train Epoch: 8 [640/3530 (18%)]\tLoss: 0.007928\n",
      "Train Epoch: 8 [1280/3530 (36%)]\tLoss: 0.106259\n",
      "Train Epoch: 8 [1920/3530 (54%)]\tLoss: 0.071094\n",
      "Train Epoch: 8 [2560/3530 (71%)]\tLoss: 0.140156\n",
      "Train Epoch: 8 [3200/3530 (89%)]\tLoss: 0.011098\n",
      "Train Epoch: 9 [0/3530 (0%)]\tLoss: 0.004190\n",
      "Train Epoch: 9 [640/3530 (18%)]\tLoss: 0.059821\n",
      "Train Epoch: 9 [1280/3530 (36%)]\tLoss: 0.043594\n",
      "Train Epoch: 9 [1920/3530 (54%)]\tLoss: 0.037690\n",
      "Train Epoch: 9 [2560/3530 (71%)]\tLoss: 0.032729\n",
      "Train Epoch: 9 [3200/3530 (89%)]\tLoss: 0.026530\n",
      "Train Epoch: 10 [0/3530 (0%)]\tLoss: 0.156457\n",
      "Train Epoch: 10 [640/3530 (18%)]\tLoss: 0.057213\n",
      "Train Epoch: 10 [1280/3530 (36%)]\tLoss: 0.018658\n",
      "Train Epoch: 10 [1920/3530 (54%)]\tLoss: 0.010064\n",
      "Train Epoch: 10 [2560/3530 (71%)]\tLoss: 0.017516\n",
      "Train Epoch: 10 [3200/3530 (89%)]\tLoss: 0.008075\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.1268, Accuracy: 9888/10000 (99%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 0.043029\n",
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 0.078506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 0.054383\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 0.096872\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 0.051460\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 0.039571\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 0.009079\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 0.016332\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 0.004624\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 0.053510\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 0.020590\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 0.081057\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 0.119913\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 0.074756\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 0.053792\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 0.080795\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 0.137433\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 0.010969\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 0.082740\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 0.010630\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.036952\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 0.136308\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 0.071053\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.022862\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.022397\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 0.012407\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.035446\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 0.027560\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.095382\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.034481\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.056252\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.024811\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.007663\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.087372\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.022521\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.016525\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.184819\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.035566\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.005493\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.026958\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.114300\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.035138\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.015150\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.023468\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.014990\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.118687\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.130160\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.003516\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.047175\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.034612\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.041093\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.052133\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.049928\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.056184\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.026365\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.094642\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.028311\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.055040\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.207666\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.108247\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.007136\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.044351\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.060518\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.031956\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.026757\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.004849\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.113345\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.122454\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.049007\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.021168\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.093587\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.024545\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.085254\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.066507\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.053355\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.021966\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.040159\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.029873\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.080691\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.034810\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.064224\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.027980\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.014890\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.007885\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.055762\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.038554\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.025902\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.015247\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.071202\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.049286\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.011057\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.115170\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.040647\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.046918\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.041371\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.011067\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.011066\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.013659\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.038021\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.110777\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.058418\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.097492\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.016059\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.109129\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.008576\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.052310\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.011803\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.135181\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 0.083146\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.083623\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.020673\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.044097\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.020061\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.091622\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.012626\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.042302\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.008958\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.036329\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.053587\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.015782\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.043830\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.047254\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.032337\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.005086\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.014620\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.004422\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.012727\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.141445\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.024012\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.046513\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.083561\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.063155\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.028419\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.029060\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.042057\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.064249\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.027215\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.037738\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.108428\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.076661\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.009601\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.040466\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.066935\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.009241\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.011438\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.036625\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.044054\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.054838\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.022060\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.275776\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.023779\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.112802\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.016785\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.124113\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.045414\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.189467\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.035632\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.003847\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.036676\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.008698\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.056770\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.009349\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.052046\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.008592\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.053619\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.032301\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.069802\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.027173\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.157077\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.012296\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.054441\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.013696\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.039689\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.053704\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.010966\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.074084\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.048794\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.081422\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.109586\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.037357\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/5110 (0%)]\tLoss: 0.170377\n",
      "Train Epoch: 1 [640/5110 (12%)]\tLoss: 0.017152\n",
      "Train Epoch: 1 [1280/5110 (25%)]\tLoss: 0.039792\n",
      "Train Epoch: 1 [1920/5110 (38%)]\tLoss: 0.163626\n",
      "Train Epoch: 1 [2560/5110 (50%)]\tLoss: 0.010221\n",
      "Train Epoch: 1 [3200/5110 (62%)]\tLoss: 0.162127\n",
      "Train Epoch: 1 [3840/5110 (75%)]\tLoss: 0.079035\n",
      "Train Epoch: 1 [4480/5110 (88%)]\tLoss: 0.021175\n",
      "Train Epoch: 2 [0/5110 (0%)]\tLoss: 0.011265\n",
      "Train Epoch: 2 [640/5110 (12%)]\tLoss: 0.004911\n",
      "Train Epoch: 2 [1280/5110 (25%)]\tLoss: 0.009734\n",
      "Train Epoch: 2 [1920/5110 (38%)]\tLoss: 0.049464\n",
      "Train Epoch: 2 [2560/5110 (50%)]\tLoss: 0.022739\n",
      "Train Epoch: 2 [3200/5110 (62%)]\tLoss: 0.042104\n",
      "Train Epoch: 2 [3840/5110 (75%)]\tLoss: 0.043773\n",
      "Train Epoch: 2 [4480/5110 (88%)]\tLoss: 0.017964\n",
      "Train Epoch: 3 [0/5110 (0%)]\tLoss: 0.008968\n",
      "Train Epoch: 3 [640/5110 (12%)]\tLoss: 0.062635\n",
      "Train Epoch: 3 [1280/5110 (25%)]\tLoss: 0.111104\n",
      "Train Epoch: 3 [1920/5110 (38%)]\tLoss: 0.030320\n",
      "Train Epoch: 3 [2560/5110 (50%)]\tLoss: 0.033148\n",
      "Train Epoch: 3 [3200/5110 (62%)]\tLoss: 0.104061\n",
      "Train Epoch: 3 [3840/5110 (75%)]\tLoss: 0.065767\n",
      "Train Epoch: 3 [4480/5110 (88%)]\tLoss: 0.043761\n",
      "Train Epoch: 4 [0/5110 (0%)]\tLoss: 0.043823\n",
      "Train Epoch: 4 [640/5110 (12%)]\tLoss: 0.004178\n",
      "Train Epoch: 4 [1280/5110 (25%)]\tLoss: 0.026966\n",
      "Train Epoch: 4 [1920/5110 (38%)]\tLoss: 0.052485\n",
      "Train Epoch: 4 [2560/5110 (50%)]\tLoss: 0.026443\n",
      "Train Epoch: 4 [3200/5110 (62%)]\tLoss: 0.033823\n",
      "Train Epoch: 4 [3840/5110 (75%)]\tLoss: 0.034108\n",
      "Train Epoch: 4 [4480/5110 (88%)]\tLoss: 0.102094\n",
      "Train Epoch: 5 [0/5110 (0%)]\tLoss: 0.128522\n",
      "Train Epoch: 5 [640/5110 (12%)]\tLoss: 0.161822\n",
      "Train Epoch: 5 [1280/5110 (25%)]\tLoss: 0.113912\n",
      "Train Epoch: 5 [1920/5110 (38%)]\tLoss: 0.023759\n",
      "Train Epoch: 5 [2560/5110 (50%)]\tLoss: 0.007385\n",
      "Train Epoch: 5 [3200/5110 (62%)]\tLoss: 0.020491\n",
      "Train Epoch: 5 [3840/5110 (75%)]\tLoss: 0.015812\n",
      "Train Epoch: 5 [4480/5110 (88%)]\tLoss: 0.010612\n",
      "Train Epoch: 6 [0/5110 (0%)]\tLoss: 0.009289\n",
      "Train Epoch: 6 [640/5110 (12%)]\tLoss: 0.026130\n",
      "Train Epoch: 6 [1280/5110 (25%)]\tLoss: 0.022292\n",
      "Train Epoch: 6 [1920/5110 (38%)]\tLoss: 0.039774\n",
      "Train Epoch: 6 [2560/5110 (50%)]\tLoss: 0.065261\n",
      "Train Epoch: 6 [3200/5110 (62%)]\tLoss: 0.008549\n",
      "Train Epoch: 6 [3840/5110 (75%)]\tLoss: 0.040874\n",
      "Train Epoch: 6 [4480/5110 (88%)]\tLoss: 0.039929\n",
      "Train Epoch: 7 [0/5110 (0%)]\tLoss: 0.005293\n",
      "Train Epoch: 7 [640/5110 (12%)]\tLoss: 0.197520\n",
      "Train Epoch: 7 [1280/5110 (25%)]\tLoss: 0.008385\n",
      "Train Epoch: 7 [1920/5110 (38%)]\tLoss: 0.103414\n",
      "Train Epoch: 7 [2560/5110 (50%)]\tLoss: 0.053000\n",
      "Train Epoch: 7 [3200/5110 (62%)]\tLoss: 0.043878\n",
      "Train Epoch: 7 [3840/5110 (75%)]\tLoss: 0.059189\n",
      "Train Epoch: 7 [4480/5110 (88%)]\tLoss: 0.076945\n",
      "Train Epoch: 8 [0/5110 (0%)]\tLoss: 0.035885\n",
      "Train Epoch: 8 [640/5110 (12%)]\tLoss: 0.009152\n",
      "Train Epoch: 8 [1280/5110 (25%)]\tLoss: 0.031107\n",
      "Train Epoch: 8 [1920/5110 (38%)]\tLoss: 0.033035\n",
      "Train Epoch: 8 [2560/5110 (50%)]\tLoss: 0.067274\n",
      "Train Epoch: 8 [3200/5110 (62%)]\tLoss: 0.072774\n",
      "Train Epoch: 8 [3840/5110 (75%)]\tLoss: 0.010102\n",
      "Train Epoch: 8 [4480/5110 (88%)]\tLoss: 0.027861\n",
      "Train Epoch: 9 [0/5110 (0%)]\tLoss: 0.003628\n",
      "Train Epoch: 9 [640/5110 (12%)]\tLoss: 0.023824\n",
      "Train Epoch: 9 [1280/5110 (25%)]\tLoss: 0.011519\n",
      "Train Epoch: 9 [1920/5110 (38%)]\tLoss: 0.011922\n",
      "Train Epoch: 9 [2560/5110 (50%)]\tLoss: 0.026383\n",
      "Train Epoch: 9 [3200/5110 (62%)]\tLoss: 0.095529\n",
      "Train Epoch: 9 [3840/5110 (75%)]\tLoss: 0.081531\n",
      "Train Epoch: 9 [4480/5110 (88%)]\tLoss: 0.022462\n",
      "Train Epoch: 10 [0/5110 (0%)]\tLoss: 0.048739\n",
      "Train Epoch: 10 [640/5110 (12%)]\tLoss: 0.063641\n",
      "Train Epoch: 10 [1280/5110 (25%)]\tLoss: 0.060961\n",
      "Train Epoch: 10 [1920/5110 (38%)]\tLoss: 0.008932\n",
      "Train Epoch: 10 [2560/5110 (50%)]\tLoss: 0.003031\n",
      "Train Epoch: 10 [3200/5110 (62%)]\tLoss: 0.028739\n",
      "Train Epoch: 10 [3840/5110 (75%)]\tLoss: 0.001605\n",
      "Train Epoch: 10 [4480/5110 (88%)]\tLoss: 0.013919\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6766 (0%)]\tLoss: 0.097390\n",
      "Train Epoch: 1 [640/6766 (9%)]\tLoss: 0.138828\n",
      "Train Epoch: 1 [1280/6766 (19%)]\tLoss: 0.012284\n",
      "Train Epoch: 1 [1920/6766 (28%)]\tLoss: 0.083662\n",
      "Train Epoch: 1 [2560/6766 (38%)]\tLoss: 0.136777\n",
      "Train Epoch: 1 [3200/6766 (47%)]\tLoss: 0.013383\n",
      "Train Epoch: 1 [3840/6766 (57%)]\tLoss: 0.040329\n",
      "Train Epoch: 1 [4480/6766 (66%)]\tLoss: 0.129568\n",
      "Train Epoch: 1 [5120/6766 (75%)]\tLoss: 0.030407\n",
      "Train Epoch: 1 [5760/6766 (85%)]\tLoss: 0.019031\n",
      "Train Epoch: 1 [6400/6766 (94%)]\tLoss: 0.092154\n",
      "Train Epoch: 2 [0/6766 (0%)]\tLoss: 0.012713\n",
      "Train Epoch: 2 [640/6766 (9%)]\tLoss: 0.011974\n",
      "Train Epoch: 2 [1280/6766 (19%)]\tLoss: 0.056764\n",
      "Train Epoch: 2 [1920/6766 (28%)]\tLoss: 0.053363\n",
      "Train Epoch: 2 [2560/6766 (38%)]\tLoss: 0.004616\n",
      "Train Epoch: 2 [3200/6766 (47%)]\tLoss: 0.008647\n",
      "Train Epoch: 2 [3840/6766 (57%)]\tLoss: 0.009363\n",
      "Train Epoch: 2 [4480/6766 (66%)]\tLoss: 0.030584\n",
      "Train Epoch: 2 [5120/6766 (75%)]\tLoss: 0.012539\n",
      "Train Epoch: 2 [5760/6766 (85%)]\tLoss: 0.026537\n",
      "Train Epoch: 2 [6400/6766 (94%)]\tLoss: 0.015228\n",
      "Train Epoch: 3 [0/6766 (0%)]\tLoss: 0.024602\n",
      "Train Epoch: 3 [640/6766 (9%)]\tLoss: 0.046204\n",
      "Train Epoch: 3 [1280/6766 (19%)]\tLoss: 0.005873\n",
      "Train Epoch: 3 [1920/6766 (28%)]\tLoss: 0.051881\n",
      "Train Epoch: 3 [2560/6766 (38%)]\tLoss: 0.040717\n",
      "Train Epoch: 3 [3200/6766 (47%)]\tLoss: 0.024867\n",
      "Train Epoch: 3 [3840/6766 (57%)]\tLoss: 0.110928\n",
      "Train Epoch: 3 [4480/6766 (66%)]\tLoss: 0.015625\n",
      "Train Epoch: 3 [5120/6766 (75%)]\tLoss: 0.004424\n",
      "Train Epoch: 3 [5760/6766 (85%)]\tLoss: 0.025545\n",
      "Train Epoch: 3 [6400/6766 (94%)]\tLoss: 0.035039\n",
      "Train Epoch: 4 [0/6766 (0%)]\tLoss: 0.013456\n",
      "Train Epoch: 4 [640/6766 (9%)]\tLoss: 0.001312\n",
      "Train Epoch: 4 [1280/6766 (19%)]\tLoss: 0.001871\n",
      "Train Epoch: 4 [1920/6766 (28%)]\tLoss: 0.060848\n",
      "Train Epoch: 4 [2560/6766 (38%)]\tLoss: 0.048622\n",
      "Train Epoch: 4 [3200/6766 (47%)]\tLoss: 0.007073\n",
      "Train Epoch: 4 [3840/6766 (57%)]\tLoss: 0.013325\n",
      "Train Epoch: 4 [4480/6766 (66%)]\tLoss: 0.008508\n",
      "Train Epoch: 4 [5120/6766 (75%)]\tLoss: 0.069084\n",
      "Train Epoch: 4 [5760/6766 (85%)]\tLoss: 0.040659\n",
      "Train Epoch: 4 [6400/6766 (94%)]\tLoss: 0.017430\n",
      "Train Epoch: 5 [0/6766 (0%)]\tLoss: 0.081118\n",
      "Train Epoch: 5 [640/6766 (9%)]\tLoss: 0.010873\n",
      "Train Epoch: 5 [1280/6766 (19%)]\tLoss: 0.006213\n",
      "Train Epoch: 5 [1920/6766 (28%)]\tLoss: 0.006118\n",
      "Train Epoch: 5 [2560/6766 (38%)]\tLoss: 0.008035\n",
      "Train Epoch: 5 [3200/6766 (47%)]\tLoss: 0.024936\n",
      "Train Epoch: 5 [3840/6766 (57%)]\tLoss: 0.034523\n",
      "Train Epoch: 5 [4480/6766 (66%)]\tLoss: 0.011615\n",
      "Train Epoch: 5 [5120/6766 (75%)]\tLoss: 0.009156\n",
      "Train Epoch: 5 [5760/6766 (85%)]\tLoss: 0.009041\n",
      "Train Epoch: 5 [6400/6766 (94%)]\tLoss: 0.055127\n",
      "Train Epoch: 6 [0/6766 (0%)]\tLoss: 0.016220\n",
      "Train Epoch: 6 [640/6766 (9%)]\tLoss: 0.021866\n",
      "Train Epoch: 6 [1280/6766 (19%)]\tLoss: 0.064005\n",
      "Train Epoch: 6 [1920/6766 (28%)]\tLoss: 0.003498\n",
      "Train Epoch: 6 [2560/6766 (38%)]\tLoss: 0.025232\n",
      "Train Epoch: 6 [3200/6766 (47%)]\tLoss: 0.003741\n",
      "Train Epoch: 6 [3840/6766 (57%)]\tLoss: 0.006549\n",
      "Train Epoch: 6 [4480/6766 (66%)]\tLoss: 0.033644\n",
      "Train Epoch: 6 [5120/6766 (75%)]\tLoss: 0.002489\n",
      "Train Epoch: 6 [5760/6766 (85%)]\tLoss: 0.006254\n",
      "Train Epoch: 6 [6400/6766 (94%)]\tLoss: 0.029714\n",
      "Train Epoch: 7 [0/6766 (0%)]\tLoss: 0.016362\n",
      "Train Epoch: 7 [640/6766 (9%)]\tLoss: 0.033453\n",
      "Train Epoch: 7 [1280/6766 (19%)]\tLoss: 0.044638\n",
      "Train Epoch: 7 [1920/6766 (28%)]\tLoss: 0.004878\n",
      "Train Epoch: 7 [2560/6766 (38%)]\tLoss: 0.029206\n",
      "Train Epoch: 7 [3200/6766 (47%)]\tLoss: 0.022298\n",
      "Train Epoch: 7 [3840/6766 (57%)]\tLoss: 0.033033\n",
      "Train Epoch: 7 [4480/6766 (66%)]\tLoss: 0.089229\n",
      "Train Epoch: 7 [5120/6766 (75%)]\tLoss: 0.009669\n",
      "Train Epoch: 7 [5760/6766 (85%)]\tLoss: 0.035974\n",
      "Train Epoch: 7 [6400/6766 (94%)]\tLoss: 0.022604\n",
      "Train Epoch: 8 [0/6766 (0%)]\tLoss: 0.005223\n",
      "Train Epoch: 8 [640/6766 (9%)]\tLoss: 0.037553\n",
      "Train Epoch: 8 [1280/6766 (19%)]\tLoss: 0.035649\n",
      "Train Epoch: 8 [1920/6766 (28%)]\tLoss: 0.010075\n",
      "Train Epoch: 8 [2560/6766 (38%)]\tLoss: 0.034799\n",
      "Train Epoch: 8 [3200/6766 (47%)]\tLoss: 0.210709\n",
      "Train Epoch: 8 [3840/6766 (57%)]\tLoss: 0.064144\n",
      "Train Epoch: 8 [4480/6766 (66%)]\tLoss: 0.021459\n",
      "Train Epoch: 8 [5120/6766 (75%)]\tLoss: 0.005212\n",
      "Train Epoch: 8 [5760/6766 (85%)]\tLoss: 0.002806\n",
      "Train Epoch: 8 [6400/6766 (94%)]\tLoss: 0.005449\n",
      "Train Epoch: 9 [0/6766 (0%)]\tLoss: 0.027742\n",
      "Train Epoch: 9 [640/6766 (9%)]\tLoss: 0.111212\n",
      "Train Epoch: 9 [1280/6766 (19%)]\tLoss: 0.002736\n",
      "Train Epoch: 9 [1920/6766 (28%)]\tLoss: 0.023814\n",
      "Train Epoch: 9 [2560/6766 (38%)]\tLoss: 0.005256\n",
      "Train Epoch: 9 [3200/6766 (47%)]\tLoss: 0.001802\n",
      "Train Epoch: 9 [3840/6766 (57%)]\tLoss: 0.075461\n",
      "Train Epoch: 9 [4480/6766 (66%)]\tLoss: 0.029112\n",
      "Train Epoch: 9 [5120/6766 (75%)]\tLoss: 0.051165\n",
      "Train Epoch: 9 [5760/6766 (85%)]\tLoss: 0.022165\n",
      "Train Epoch: 9 [6400/6766 (94%)]\tLoss: 0.039325\n",
      "Train Epoch: 10 [0/6766 (0%)]\tLoss: 0.033946\n",
      "Train Epoch: 10 [640/6766 (9%)]\tLoss: 0.084267\n",
      "Train Epoch: 10 [1280/6766 (19%)]\tLoss: 0.019761\n",
      "Train Epoch: 10 [1920/6766 (28%)]\tLoss: 0.033923\n",
      "Train Epoch: 10 [2560/6766 (38%)]\tLoss: 0.008811\n",
      "Train Epoch: 10 [3200/6766 (47%)]\tLoss: 0.024601\n",
      "Train Epoch: 10 [3840/6766 (57%)]\tLoss: 0.000562\n",
      "Train Epoch: 10 [4480/6766 (66%)]\tLoss: 0.067808\n",
      "Train Epoch: 10 [5120/6766 (75%)]\tLoss: 0.010543\n",
      "Train Epoch: 10 [5760/6766 (85%)]\tLoss: 0.264609\n",
      "Train Epoch: 10 [6400/6766 (94%)]\tLoss: 0.020103\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 0.036490\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 0.056355\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 0.132084\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 0.035952\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 0.196010\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 0.145405\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 0.105514\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 0.022249\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 0.034064\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 0.024728\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 0.140860\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 0.019215\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 0.012080\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 0.057173\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 0.027530\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 0.072674\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 0.040217\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.079778\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.043003\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.064103\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.101506\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.042622\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.149754\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.024449\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.018940\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.022612\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.013170\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.006183\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.046589\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.008371\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.024667\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.025840\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.018089\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.019816\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.033167\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.025885\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.029063\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.013834\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.024863\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.023439\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.015693\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.003124\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.102243\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.027120\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.015890\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.098056\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.056141\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.012260\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.081901\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.093958\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.062826\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.056791\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.011027\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.066539\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.027672\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.005832\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.037349\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.060861\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.036222\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.036955\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.017993\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.013118\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.022101\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.008900\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.027091\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.047474\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.199945\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.031282\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.075620\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.024333\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.044071\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.013425\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.043273\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.008989\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.056258\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.027246\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.014535\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.077970\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.012012\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.040895\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.028872\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.037876\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.015799\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.023151\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.014465\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.037128\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.007689\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.025909\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.026279\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.129699\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.023776\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.037353\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.044707\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.053210\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.015879\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.034913\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.041365\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.057736\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.042286\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.015451\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.040948\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.010260\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.044979\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.070627\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.025701\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.032741\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.027566\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.041674\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.026355\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.054102\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.023844\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.007080\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.012902\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.092520\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.007037\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.011905\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.047895\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.053875\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.043360\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.009664\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.110836\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.079044\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.052272\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.108397\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.016301\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.064645\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.012419\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.002577\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.071622\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.013056\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.076653\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.039392\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.005344\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.013992\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.025671\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.007171\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.031447\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.002771\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.005774\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.061668\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.043494\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.057748\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.025780\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.154394\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.064730\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.005176\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.022084\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.080866\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.019672\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.010047\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.025973\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.024278\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.020476\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.034068\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.025241\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.016544\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.044914\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.014410\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.187939\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.100233\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/3910 (0%)]\tLoss: 0.140909\n",
      "Train Epoch: 1 [640/3910 (16%)]\tLoss: 0.074252\n",
      "Train Epoch: 1 [1280/3910 (32%)]\tLoss: 0.058821\n",
      "Train Epoch: 1 [1920/3910 (48%)]\tLoss: 0.074074\n",
      "Train Epoch: 1 [2560/3910 (65%)]\tLoss: 0.048851\n",
      "Train Epoch: 1 [3200/3910 (81%)]\tLoss: 0.204411\n",
      "Train Epoch: 1 [3840/3910 (97%)]\tLoss: 0.020545\n",
      "Train Epoch: 2 [0/3910 (0%)]\tLoss: 0.013005\n",
      "Train Epoch: 2 [640/3910 (16%)]\tLoss: 0.126009\n",
      "Train Epoch: 2 [1280/3910 (32%)]\tLoss: 0.024028\n",
      "Train Epoch: 2 [1920/3910 (48%)]\tLoss: 0.020605\n",
      "Train Epoch: 2 [2560/3910 (65%)]\tLoss: 0.037957\n",
      "Train Epoch: 2 [3200/3910 (81%)]\tLoss: 0.071768\n",
      "Train Epoch: 2 [3840/3910 (97%)]\tLoss: 0.100421\n",
      "Train Epoch: 3 [0/3910 (0%)]\tLoss: 0.045018\n",
      "Train Epoch: 3 [640/3910 (16%)]\tLoss: 0.024064\n",
      "Train Epoch: 3 [1280/3910 (32%)]\tLoss: 0.061408\n",
      "Train Epoch: 3 [1920/3910 (48%)]\tLoss: 0.053693\n",
      "Train Epoch: 3 [2560/3910 (65%)]\tLoss: 0.118526\n",
      "Train Epoch: 3 [3200/3910 (81%)]\tLoss: 0.112285\n",
      "Train Epoch: 3 [3840/3910 (97%)]\tLoss: 0.013215\n",
      "Train Epoch: 4 [0/3910 (0%)]\tLoss: 0.045162\n",
      "Train Epoch: 4 [640/3910 (16%)]\tLoss: 0.042447\n",
      "Train Epoch: 4 [1280/3910 (32%)]\tLoss: 0.070770\n",
      "Train Epoch: 4 [1920/3910 (48%)]\tLoss: 0.035914\n",
      "Train Epoch: 4 [2560/3910 (65%)]\tLoss: 0.045489\n",
      "Train Epoch: 4 [3200/3910 (81%)]\tLoss: 0.045699\n",
      "Train Epoch: 4 [3840/3910 (97%)]\tLoss: 0.075926\n",
      "Train Epoch: 5 [0/3910 (0%)]\tLoss: 0.032834\n",
      "Train Epoch: 5 [640/3910 (16%)]\tLoss: 0.030270\n",
      "Train Epoch: 5 [1280/3910 (32%)]\tLoss: 0.049299\n",
      "Train Epoch: 5 [1920/3910 (48%)]\tLoss: 0.048211\n",
      "Train Epoch: 5 [2560/3910 (65%)]\tLoss: 0.081559\n",
      "Train Epoch: 5 [3200/3910 (81%)]\tLoss: 0.023944\n",
      "Train Epoch: 5 [3840/3910 (97%)]\tLoss: 0.034941\n",
      "Train Epoch: 6 [0/3910 (0%)]\tLoss: 0.085130\n",
      "Train Epoch: 6 [640/3910 (16%)]\tLoss: 0.024793\n",
      "Train Epoch: 6 [1280/3910 (32%)]\tLoss: 0.048224\n",
      "Train Epoch: 6 [1920/3910 (48%)]\tLoss: 0.019135\n",
      "Train Epoch: 6 [2560/3910 (65%)]\tLoss: 0.003298\n",
      "Train Epoch: 6 [3200/3910 (81%)]\tLoss: 0.032812\n",
      "Train Epoch: 6 [3840/3910 (97%)]\tLoss: 0.023423\n",
      "Train Epoch: 7 [0/3910 (0%)]\tLoss: 0.021775\n",
      "Train Epoch: 7 [640/3910 (16%)]\tLoss: 0.051316\n",
      "Train Epoch: 7 [1280/3910 (32%)]\tLoss: 0.008338\n",
      "Train Epoch: 7 [1920/3910 (48%)]\tLoss: 0.081112\n",
      "Train Epoch: 7 [2560/3910 (65%)]\tLoss: 0.013648\n",
      "Train Epoch: 7 [3200/3910 (81%)]\tLoss: 0.046050\n",
      "Train Epoch: 7 [3840/3910 (97%)]\tLoss: 0.032812\n",
      "Train Epoch: 8 [0/3910 (0%)]\tLoss: 0.022825\n",
      "Train Epoch: 8 [640/3910 (16%)]\tLoss: 0.043765\n",
      "Train Epoch: 8 [1280/3910 (32%)]\tLoss: 0.018579\n",
      "Train Epoch: 8 [1920/3910 (48%)]\tLoss: 0.025382\n",
      "Train Epoch: 8 [2560/3910 (65%)]\tLoss: 0.067645\n",
      "Train Epoch: 8 [3200/3910 (81%)]\tLoss: 0.061483\n",
      "Train Epoch: 8 [3840/3910 (97%)]\tLoss: 0.014270\n",
      "Train Epoch: 9 [0/3910 (0%)]\tLoss: 0.043131\n",
      "Train Epoch: 9 [640/3910 (16%)]\tLoss: 0.015768\n",
      "Train Epoch: 9 [1280/3910 (32%)]\tLoss: 0.016325\n",
      "Train Epoch: 9 [1920/3910 (48%)]\tLoss: 0.068963\n",
      "Train Epoch: 9 [2560/3910 (65%)]\tLoss: 0.067544\n",
      "Train Epoch: 9 [3200/3910 (81%)]\tLoss: 0.025783\n",
      "Train Epoch: 9 [3840/3910 (97%)]\tLoss: 0.058238\n",
      "Train Epoch: 10 [0/3910 (0%)]\tLoss: 0.022998\n",
      "Train Epoch: 10 [640/3910 (16%)]\tLoss: 0.042298\n",
      "Train Epoch: 10 [1280/3910 (32%)]\tLoss: 0.032381\n",
      "Train Epoch: 10 [1920/3910 (48%)]\tLoss: 0.019066\n",
      "Train Epoch: 10 [2560/3910 (65%)]\tLoss: 0.020311\n",
      "Train Epoch: 10 [3200/3910 (81%)]\tLoss: 0.067990\n",
      "Train Epoch: 10 [3840/3910 (97%)]\tLoss: 0.072509\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 0.167419\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 0.087485\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 0.014178\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 0.050383\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 0.046298\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 0.057738\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 0.031401\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 0.062319\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 0.042045\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 0.068090\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.011816\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.027000\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 0.078897\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 0.071090\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 0.006335\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.019142\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.001380\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.025718\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.003747\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.043893\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.068566\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.005174\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.005422\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.005249\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.030644\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.006317\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.006221\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.007272\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.184745\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.010019\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.012642\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.130143\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.009046\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.006188\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.011290\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.006083\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.009031\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.030562\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.006530\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.006412\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.014576\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.032433\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.001507\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.060688\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.016280\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.001570\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.042057\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.011078\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.028726\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.003160\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.003604\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.006834\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.034705\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.020257\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.013530\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.010002\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.012166\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.017597\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.031475\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.011305\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.026594\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.153078\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.071558\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.019325\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.019016\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.039999\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.003447\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.040673\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.031418\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.001177\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.027639\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.000578\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.048694\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.012506\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.004648\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.003142\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.096956\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.025546\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.022452\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.013510\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.011484\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.069559\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.002119\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.035186\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.014018\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.003212\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.065956\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.064068\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.074635\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.013566\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.009897\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.236569\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.184166\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.003238\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.019383\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.059884\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.060318\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.010495\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.006055\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.010341\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.058915\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.000311\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.033793\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.007305\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.001370\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.009171\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.003067\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.001878\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.022548\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.042589\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.035628\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.011823\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.027414\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.006273\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.008765\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.023493\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.000649\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.047721\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.002132\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.029847\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/5096 (0%)]\tLoss: 0.029381\n",
      "Train Epoch: 1 [640/5096 (12%)]\tLoss: 0.122990\n",
      "Train Epoch: 1 [1280/5096 (25%)]\tLoss: 0.018720\n",
      "Train Epoch: 1 [1920/5096 (38%)]\tLoss: 0.021401\n",
      "Train Epoch: 1 [2560/5096 (50%)]\tLoss: 0.023986\n",
      "Train Epoch: 1 [3200/5096 (62%)]\tLoss: 0.016529\n",
      "Train Epoch: 1 [3840/5096 (75%)]\tLoss: 0.057891\n",
      "Train Epoch: 1 [4480/5096 (88%)]\tLoss: 0.112577\n",
      "Train Epoch: 2 [0/5096 (0%)]\tLoss: 0.063444\n",
      "Train Epoch: 2 [640/5096 (12%)]\tLoss: 0.034638\n",
      "Train Epoch: 2 [1280/5096 (25%)]\tLoss: 0.046871\n",
      "Train Epoch: 2 [1920/5096 (38%)]\tLoss: 0.014341\n",
      "Train Epoch: 2 [2560/5096 (50%)]\tLoss: 0.014081\n",
      "Train Epoch: 2 [3200/5096 (62%)]\tLoss: 0.004202\n",
      "Train Epoch: 2 [3840/5096 (75%)]\tLoss: 0.045865\n",
      "Train Epoch: 2 [4480/5096 (88%)]\tLoss: 0.005534\n",
      "Train Epoch: 3 [0/5096 (0%)]\tLoss: 0.011122\n",
      "Train Epoch: 3 [640/5096 (12%)]\tLoss: 0.019979\n",
      "Train Epoch: 3 [1280/5096 (25%)]\tLoss: 0.004617\n",
      "Train Epoch: 3 [1920/5096 (38%)]\tLoss: 0.003796\n",
      "Train Epoch: 3 [2560/5096 (50%)]\tLoss: 0.004270\n",
      "Train Epoch: 3 [3200/5096 (62%)]\tLoss: 0.004525\n",
      "Train Epoch: 3 [3840/5096 (75%)]\tLoss: 0.019830\n",
      "Train Epoch: 3 [4480/5096 (88%)]\tLoss: 0.015312\n",
      "Train Epoch: 4 [0/5096 (0%)]\tLoss: 0.066216\n",
      "Train Epoch: 4 [640/5096 (12%)]\tLoss: 0.003020\n",
      "Train Epoch: 4 [1280/5096 (25%)]\tLoss: 0.046877\n",
      "Train Epoch: 4 [1920/5096 (38%)]\tLoss: 0.014582\n",
      "Train Epoch: 4 [2560/5096 (50%)]\tLoss: 0.016113\n",
      "Train Epoch: 4 [3200/5096 (62%)]\tLoss: 0.047682\n",
      "Train Epoch: 4 [3840/5096 (75%)]\tLoss: 0.002753\n",
      "Train Epoch: 4 [4480/5096 (88%)]\tLoss: 0.004980\n",
      "Train Epoch: 5 [0/5096 (0%)]\tLoss: 0.001535\n",
      "Train Epoch: 5 [640/5096 (12%)]\tLoss: 0.011770\n",
      "Train Epoch: 5 [1280/5096 (25%)]\tLoss: 0.001123\n",
      "Train Epoch: 5 [1920/5096 (38%)]\tLoss: 0.042646\n",
      "Train Epoch: 5 [2560/5096 (50%)]\tLoss: 0.004748\n",
      "Train Epoch: 5 [3200/5096 (62%)]\tLoss: 0.011730\n",
      "Train Epoch: 5 [3840/5096 (75%)]\tLoss: 0.042793\n",
      "Train Epoch: 5 [4480/5096 (88%)]\tLoss: 0.017879\n",
      "Train Epoch: 6 [0/5096 (0%)]\tLoss: 0.002980\n",
      "Train Epoch: 6 [640/5096 (12%)]\tLoss: 0.002414\n",
      "Train Epoch: 6 [1280/5096 (25%)]\tLoss: 0.003105\n",
      "Train Epoch: 6 [1920/5096 (38%)]\tLoss: 0.026721\n",
      "Train Epoch: 6 [2560/5096 (50%)]\tLoss: 0.209607\n",
      "Train Epoch: 6 [3200/5096 (62%)]\tLoss: 0.045569\n",
      "Train Epoch: 6 [3840/5096 (75%)]\tLoss: 0.013910\n",
      "Train Epoch: 6 [4480/5096 (88%)]\tLoss: 0.008357\n",
      "Train Epoch: 7 [0/5096 (0%)]\tLoss: 0.009872\n",
      "Train Epoch: 7 [640/5096 (12%)]\tLoss: 0.021100\n",
      "Train Epoch: 7 [1280/5096 (25%)]\tLoss: 0.002577\n",
      "Train Epoch: 7 [1920/5096 (38%)]\tLoss: 0.017675\n",
      "Train Epoch: 7 [2560/5096 (50%)]\tLoss: 0.007309\n",
      "Train Epoch: 7 [3200/5096 (62%)]\tLoss: 0.016256\n",
      "Train Epoch: 7 [3840/5096 (75%)]\tLoss: 0.038697\n",
      "Train Epoch: 7 [4480/5096 (88%)]\tLoss: 0.038889\n",
      "Train Epoch: 8 [0/5096 (0%)]\tLoss: 0.032205\n",
      "Train Epoch: 8 [640/5096 (12%)]\tLoss: 0.027905\n",
      "Train Epoch: 8 [1280/5096 (25%)]\tLoss: 0.037224\n",
      "Train Epoch: 8 [1920/5096 (38%)]\tLoss: 0.085707\n",
      "Train Epoch: 8 [2560/5096 (50%)]\tLoss: 0.006240\n",
      "Train Epoch: 8 [3200/5096 (62%)]\tLoss: 0.007425\n",
      "Train Epoch: 8 [3840/5096 (75%)]\tLoss: 0.009471\n",
      "Train Epoch: 8 [4480/5096 (88%)]\tLoss: 0.067706\n",
      "Train Epoch: 9 [0/5096 (0%)]\tLoss: 0.038665\n",
      "Train Epoch: 9 [640/5096 (12%)]\tLoss: 0.005281\n",
      "Train Epoch: 9 [1280/5096 (25%)]\tLoss: 0.017688\n",
      "Train Epoch: 9 [1920/5096 (38%)]\tLoss: 0.024871\n",
      "Train Epoch: 9 [2560/5096 (50%)]\tLoss: 0.106030\n",
      "Train Epoch: 9 [3200/5096 (62%)]\tLoss: 0.005369\n",
      "Train Epoch: 9 [3840/5096 (75%)]\tLoss: 0.014148\n",
      "Train Epoch: 9 [4480/5096 (88%)]\tLoss: 0.010707\n",
      "Train Epoch: 10 [0/5096 (0%)]\tLoss: 0.006379\n",
      "Train Epoch: 10 [640/5096 (12%)]\tLoss: 0.013491\n",
      "Train Epoch: 10 [1280/5096 (25%)]\tLoss: 0.003027\n",
      "Train Epoch: 10 [1920/5096 (38%)]\tLoss: 0.011551\n",
      "Train Epoch: 10 [2560/5096 (50%)]\tLoss: 0.005097\n",
      "Train Epoch: 10 [3200/5096 (62%)]\tLoss: 0.004043\n",
      "Train Epoch: 10 [3840/5096 (75%)]\tLoss: 0.149997\n",
      "Train Epoch: 10 [4480/5096 (88%)]\tLoss: 0.013910\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/1599 (0%)]\tLoss: 0.061722\n",
      "Train Epoch: 1 [640/1599 (40%)]\tLoss: 0.073614\n",
      "Train Epoch: 1 [1280/1599 (80%)]\tLoss: 0.008193\n",
      "Train Epoch: 2 [0/1599 (0%)]\tLoss: 0.037101\n",
      "Train Epoch: 2 [640/1599 (40%)]\tLoss: 0.047156\n",
      "Train Epoch: 2 [1280/1599 (80%)]\tLoss: 0.061810\n",
      "Train Epoch: 3 [0/1599 (0%)]\tLoss: 0.021833\n",
      "Train Epoch: 3 [640/1599 (40%)]\tLoss: 0.053526\n",
      "Train Epoch: 3 [1280/1599 (80%)]\tLoss: 0.011242\n",
      "Train Epoch: 4 [0/1599 (0%)]\tLoss: 0.051592\n",
      "Train Epoch: 4 [640/1599 (40%)]\tLoss: 0.013393\n",
      "Train Epoch: 4 [1280/1599 (80%)]\tLoss: 0.024075\n",
      "Train Epoch: 5 [0/1599 (0%)]\tLoss: 0.014913\n",
      "Train Epoch: 5 [640/1599 (40%)]\tLoss: 0.003592\n",
      "Train Epoch: 5 [1280/1599 (80%)]\tLoss: 0.033737\n",
      "Train Epoch: 6 [0/1599 (0%)]\tLoss: 0.019207\n",
      "Train Epoch: 6 [640/1599 (40%)]\tLoss: 0.002240\n",
      "Train Epoch: 6 [1280/1599 (80%)]\tLoss: 0.021352\n",
      "Train Epoch: 7 [0/1599 (0%)]\tLoss: 0.009619\n",
      "Train Epoch: 7 [640/1599 (40%)]\tLoss: 0.064483\n",
      "Train Epoch: 7 [1280/1599 (80%)]\tLoss: 0.011103\n",
      "Train Epoch: 8 [0/1599 (0%)]\tLoss: 0.036647\n",
      "Train Epoch: 8 [640/1599 (40%)]\tLoss: 0.047277\n",
      "Train Epoch: 8 [1280/1599 (80%)]\tLoss: 0.050240\n",
      "Train Epoch: 9 [0/1599 (0%)]\tLoss: 0.042028\n",
      "Train Epoch: 9 [640/1599 (40%)]\tLoss: 0.055006\n",
      "Train Epoch: 9 [1280/1599 (80%)]\tLoss: 0.019163\n",
      "Train Epoch: 10 [0/1599 (0%)]\tLoss: 0.004900\n",
      "Train Epoch: 10 [640/1599 (40%)]\tLoss: 0.014958\n",
      "Train Epoch: 10 [1280/1599 (80%)]\tLoss: 0.013889\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/5266 (0%)]\tLoss: 0.210863\n",
      "Train Epoch: 1 [640/5266 (12%)]\tLoss: 0.028925\n",
      "Train Epoch: 1 [1280/5266 (24%)]\tLoss: 0.016230\n",
      "Train Epoch: 1 [1920/5266 (36%)]\tLoss: 0.045607\n",
      "Train Epoch: 1 [2560/5266 (48%)]\tLoss: 0.001708\n",
      "Train Epoch: 1 [3200/5266 (60%)]\tLoss: 0.004217\n",
      "Train Epoch: 1 [3840/5266 (72%)]\tLoss: 0.117264\n",
      "Train Epoch: 1 [4480/5266 (84%)]\tLoss: 0.018966\n",
      "Train Epoch: 1 [5120/5266 (96%)]\tLoss: 0.038305\n",
      "Train Epoch: 2 [0/5266 (0%)]\tLoss: 0.046331\n",
      "Train Epoch: 2 [640/5266 (12%)]\tLoss: 0.035346\n",
      "Train Epoch: 2 [1280/5266 (24%)]\tLoss: 0.014042\n",
      "Train Epoch: 2 [1920/5266 (36%)]\tLoss: 0.050515\n",
      "Train Epoch: 2 [2560/5266 (48%)]\tLoss: 0.005658\n",
      "Train Epoch: 2 [3200/5266 (60%)]\tLoss: 0.007493\n",
      "Train Epoch: 2 [3840/5266 (72%)]\tLoss: 0.062843\n",
      "Train Epoch: 2 [4480/5266 (84%)]\tLoss: 0.001800\n",
      "Train Epoch: 2 [5120/5266 (96%)]\tLoss: 0.035950\n",
      "Train Epoch: 3 [0/5266 (0%)]\tLoss: 0.004974\n",
      "Train Epoch: 3 [640/5266 (12%)]\tLoss: 0.075498\n",
      "Train Epoch: 3 [1280/5266 (24%)]\tLoss: 0.131451\n",
      "Train Epoch: 3 [1920/5266 (36%)]\tLoss: 0.017392\n",
      "Train Epoch: 3 [2560/5266 (48%)]\tLoss: 0.015135\n",
      "Train Epoch: 3 [3200/5266 (60%)]\tLoss: 0.004265\n",
      "Train Epoch: 3 [3840/5266 (72%)]\tLoss: 0.055239\n",
      "Train Epoch: 3 [4480/5266 (84%)]\tLoss: 0.013651\n",
      "Train Epoch: 3 [5120/5266 (96%)]\tLoss: 0.061201\n",
      "Train Epoch: 4 [0/5266 (0%)]\tLoss: 0.075997\n",
      "Train Epoch: 4 [640/5266 (12%)]\tLoss: 0.003753\n",
      "Train Epoch: 4 [1280/5266 (24%)]\tLoss: 0.037667\n",
      "Train Epoch: 4 [1920/5266 (36%)]\tLoss: 0.006078\n",
      "Train Epoch: 4 [2560/5266 (48%)]\tLoss: 0.011321\n",
      "Train Epoch: 4 [3200/5266 (60%)]\tLoss: 0.001887\n",
      "Train Epoch: 4 [3840/5266 (72%)]\tLoss: 0.115668\n",
      "Train Epoch: 4 [4480/5266 (84%)]\tLoss: 0.026873\n",
      "Train Epoch: 4 [5120/5266 (96%)]\tLoss: 0.046471\n",
      "Train Epoch: 5 [0/5266 (0%)]\tLoss: 0.027717\n",
      "Train Epoch: 5 [640/5266 (12%)]\tLoss: 0.027564\n",
      "Train Epoch: 5 [1280/5266 (24%)]\tLoss: 0.018930\n",
      "Train Epoch: 5 [1920/5266 (36%)]\tLoss: 0.004818\n",
      "Train Epoch: 5 [2560/5266 (48%)]\tLoss: 0.068571\n",
      "Train Epoch: 5 [3200/5266 (60%)]\tLoss: 0.002366\n",
      "Train Epoch: 5 [3840/5266 (72%)]\tLoss: 0.001407\n",
      "Train Epoch: 5 [4480/5266 (84%)]\tLoss: 0.073203\n",
      "Train Epoch: 5 [5120/5266 (96%)]\tLoss: 0.035322\n",
      "Train Epoch: 6 [0/5266 (0%)]\tLoss: 0.001787\n",
      "Train Epoch: 6 [640/5266 (12%)]\tLoss: 0.018809\n",
      "Train Epoch: 6 [1280/5266 (24%)]\tLoss: 0.014296\n",
      "Train Epoch: 6 [1920/5266 (36%)]\tLoss: 0.043224\n",
      "Train Epoch: 6 [2560/5266 (48%)]\tLoss: 0.002679\n",
      "Train Epoch: 6 [3200/5266 (60%)]\tLoss: 0.000508\n",
      "Train Epoch: 6 [3840/5266 (72%)]\tLoss: 0.001458\n",
      "Train Epoch: 6 [4480/5266 (84%)]\tLoss: 0.006036\n",
      "Train Epoch: 6 [5120/5266 (96%)]\tLoss: 0.017203\n",
      "Train Epoch: 7 [0/5266 (0%)]\tLoss: 0.002524\n",
      "Train Epoch: 7 [640/5266 (12%)]\tLoss: 0.219916\n",
      "Train Epoch: 7 [1280/5266 (24%)]\tLoss: 0.005642\n",
      "Train Epoch: 7 [1920/5266 (36%)]\tLoss: 0.005272\n",
      "Train Epoch: 7 [2560/5266 (48%)]\tLoss: 0.000909\n",
      "Train Epoch: 7 [3200/5266 (60%)]\tLoss: 0.008948\n",
      "Train Epoch: 7 [3840/5266 (72%)]\tLoss: 0.005302\n",
      "Train Epoch: 7 [4480/5266 (84%)]\tLoss: 0.005566\n",
      "Train Epoch: 7 [5120/5266 (96%)]\tLoss: 0.000102\n",
      "Train Epoch: 8 [0/5266 (0%)]\tLoss: 0.005387\n",
      "Train Epoch: 8 [640/5266 (12%)]\tLoss: 0.084602\n",
      "Train Epoch: 8 [1280/5266 (24%)]\tLoss: 0.014769\n",
      "Train Epoch: 8 [1920/5266 (36%)]\tLoss: 0.032337\n",
      "Train Epoch: 8 [2560/5266 (48%)]\tLoss: 0.025709\n",
      "Train Epoch: 8 [3200/5266 (60%)]\tLoss: 0.011232\n",
      "Train Epoch: 8 [3840/5266 (72%)]\tLoss: 0.001668\n",
      "Train Epoch: 8 [4480/5266 (84%)]\tLoss: 0.009200\n",
      "Train Epoch: 8 [5120/5266 (96%)]\tLoss: 0.002541\n",
      "Train Epoch: 9 [0/5266 (0%)]\tLoss: 0.007398\n",
      "Train Epoch: 9 [640/5266 (12%)]\tLoss: 0.002931\n",
      "Train Epoch: 9 [1280/5266 (24%)]\tLoss: 0.019106\n",
      "Train Epoch: 9 [1920/5266 (36%)]\tLoss: 0.001417\n",
      "Train Epoch: 9 [2560/5266 (48%)]\tLoss: 0.000447\n",
      "Train Epoch: 9 [3200/5266 (60%)]\tLoss: 0.001406\n",
      "Train Epoch: 9 [3840/5266 (72%)]\tLoss: 0.029316\n",
      "Train Epoch: 9 [4480/5266 (84%)]\tLoss: 0.008486\n",
      "Train Epoch: 9 [5120/5266 (96%)]\tLoss: 0.008698\n",
      "Train Epoch: 10 [0/5266 (0%)]\tLoss: 0.002619\n",
      "Train Epoch: 10 [640/5266 (12%)]\tLoss: 0.009233\n",
      "Train Epoch: 10 [1280/5266 (24%)]\tLoss: 0.021880\n",
      "Train Epoch: 10 [1920/5266 (36%)]\tLoss: 0.009883\n",
      "Train Epoch: 10 [2560/5266 (48%)]\tLoss: 0.026299\n",
      "Train Epoch: 10 [3200/5266 (60%)]\tLoss: 0.040097\n",
      "Train Epoch: 10 [3840/5266 (72%)]\tLoss: 0.014555\n",
      "Train Epoch: 10 [4480/5266 (84%)]\tLoss: 0.080289\n",
      "Train Epoch: 10 [5120/5266 (96%)]\tLoss: 0.033028\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/3530 (0%)]\tLoss: 0.082844\n",
      "Train Epoch: 1 [640/3530 (18%)]\tLoss: 0.043572\n",
      "Train Epoch: 1 [1280/3530 (36%)]\tLoss: 0.045557\n",
      "Train Epoch: 1 [1920/3530 (54%)]\tLoss: 0.012390\n",
      "Train Epoch: 1 [2560/3530 (71%)]\tLoss: 0.106854\n",
      "Train Epoch: 1 [3200/3530 (89%)]\tLoss: 0.129085\n",
      "Train Epoch: 2 [0/3530 (0%)]\tLoss: 0.082039\n",
      "Train Epoch: 2 [640/3530 (18%)]\tLoss: 0.037889\n",
      "Train Epoch: 2 [1280/3530 (36%)]\tLoss: 0.062482\n",
      "Train Epoch: 2 [1920/3530 (54%)]\tLoss: 0.027538\n",
      "Train Epoch: 2 [2560/3530 (71%)]\tLoss: 0.110840\n",
      "Train Epoch: 2 [3200/3530 (89%)]\tLoss: 0.125229\n",
      "Train Epoch: 3 [0/3530 (0%)]\tLoss: 0.008120\n",
      "Train Epoch: 3 [640/3530 (18%)]\tLoss: 0.154224\n",
      "Train Epoch: 3 [1280/3530 (36%)]\tLoss: 0.025271\n",
      "Train Epoch: 3 [1920/3530 (54%)]\tLoss: 0.019687\n",
      "Train Epoch: 3 [2560/3530 (71%)]\tLoss: 0.003091\n",
      "Train Epoch: 3 [3200/3530 (89%)]\tLoss: 0.031199\n",
      "Train Epoch: 4 [0/3530 (0%)]\tLoss: 0.030297\n",
      "Train Epoch: 4 [640/3530 (18%)]\tLoss: 0.031650\n",
      "Train Epoch: 4 [1280/3530 (36%)]\tLoss: 0.174952\n",
      "Train Epoch: 4 [1920/3530 (54%)]\tLoss: 0.105358\n",
      "Train Epoch: 4 [2560/3530 (71%)]\tLoss: 0.125500\n",
      "Train Epoch: 4 [3200/3530 (89%)]\tLoss: 0.038066\n",
      "Train Epoch: 5 [0/3530 (0%)]\tLoss: 0.012519\n",
      "Train Epoch: 5 [640/3530 (18%)]\tLoss: 0.040121\n",
      "Train Epoch: 5 [1280/3530 (36%)]\tLoss: 0.042868\n",
      "Train Epoch: 5 [1920/3530 (54%)]\tLoss: 0.013140\n",
      "Train Epoch: 5 [2560/3530 (71%)]\tLoss: 0.048479\n",
      "Train Epoch: 5 [3200/3530 (89%)]\tLoss: 0.186350\n",
      "Train Epoch: 6 [0/3530 (0%)]\tLoss: 0.011984\n",
      "Train Epoch: 6 [640/3530 (18%)]\tLoss: 0.088452\n",
      "Train Epoch: 6 [1280/3530 (36%)]\tLoss: 0.056150\n",
      "Train Epoch: 6 [1920/3530 (54%)]\tLoss: 0.057862\n",
      "Train Epoch: 6 [2560/3530 (71%)]\tLoss: 0.073270\n",
      "Train Epoch: 6 [3200/3530 (89%)]\tLoss: 0.160801\n",
      "Train Epoch: 7 [0/3530 (0%)]\tLoss: 0.013232\n",
      "Train Epoch: 7 [640/3530 (18%)]\tLoss: 0.045399\n",
      "Train Epoch: 7 [1280/3530 (36%)]\tLoss: 0.061967\n",
      "Train Epoch: 7 [1920/3530 (54%)]\tLoss: 0.039977\n",
      "Train Epoch: 7 [2560/3530 (71%)]\tLoss: 0.074185\n",
      "Train Epoch: 7 [3200/3530 (89%)]\tLoss: 0.042217\n",
      "Train Epoch: 8 [0/3530 (0%)]\tLoss: 0.078709\n",
      "Train Epoch: 8 [640/3530 (18%)]\tLoss: 0.076153\n",
      "Train Epoch: 8 [1280/3530 (36%)]\tLoss: 0.025799\n",
      "Train Epoch: 8 [1920/3530 (54%)]\tLoss: 0.033229\n",
      "Train Epoch: 8 [2560/3530 (71%)]\tLoss: 0.066940\n",
      "Train Epoch: 8 [3200/3530 (89%)]\tLoss: 0.061778\n",
      "Train Epoch: 9 [0/3530 (0%)]\tLoss: 0.017632\n",
      "Train Epoch: 9 [640/3530 (18%)]\tLoss: 0.035095\n",
      "Train Epoch: 9 [1280/3530 (36%)]\tLoss: 0.057053\n",
      "Train Epoch: 9 [1920/3530 (54%)]\tLoss: 0.023730\n",
      "Train Epoch: 9 [2560/3530 (71%)]\tLoss: 0.019859\n",
      "Train Epoch: 9 [3200/3530 (89%)]\tLoss: 0.003754\n",
      "Train Epoch: 10 [0/3530 (0%)]\tLoss: 0.045968\n",
      "Train Epoch: 10 [640/3530 (18%)]\tLoss: 0.022890\n",
      "Train Epoch: 10 [1280/3530 (36%)]\tLoss: 0.056634\n",
      "Train Epoch: 10 [1920/3530 (54%)]\tLoss: 0.024853\n",
      "Train Epoch: 10 [2560/3530 (71%)]\tLoss: 0.010929\n",
      "Train Epoch: 10 [3200/3530 (89%)]\tLoss: 0.003949\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.1232, Accuracy: 9886/10000 (99%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/11393 (0%)]\tLoss: 0.082621\n",
      "Train Epoch: 1 [640/11393 (6%)]\tLoss: 0.058177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\Federated-Dimensionality-Reduction\\model2.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1280/11393 (11%)]\tLoss: 0.048420\n",
      "Train Epoch: 1 [1920/11393 (17%)]\tLoss: 0.069679\n",
      "Train Epoch: 1 [2560/11393 (22%)]\tLoss: 0.025376\n",
      "Train Epoch: 1 [3200/11393 (28%)]\tLoss: 0.077116\n",
      "Train Epoch: 1 [3840/11393 (34%)]\tLoss: 0.063770\n",
      "Train Epoch: 1 [4480/11393 (39%)]\tLoss: 0.073290\n",
      "Train Epoch: 1 [5120/11393 (45%)]\tLoss: 0.156071\n",
      "Train Epoch: 1 [5760/11393 (50%)]\tLoss: 0.003696\n",
      "Train Epoch: 1 [6400/11393 (56%)]\tLoss: 0.069836\n",
      "Train Epoch: 1 [7040/11393 (61%)]\tLoss: 0.045863\n",
      "Train Epoch: 1 [7680/11393 (67%)]\tLoss: 0.061733\n",
      "Train Epoch: 1 [8320/11393 (73%)]\tLoss: 0.039099\n",
      "Train Epoch: 1 [8960/11393 (78%)]\tLoss: 0.010708\n",
      "Train Epoch: 1 [9600/11393 (84%)]\tLoss: 0.085073\n",
      "Train Epoch: 1 [10240/11393 (89%)]\tLoss: 0.068458\n",
      "Train Epoch: 1 [10880/11393 (95%)]\tLoss: 0.074419\n",
      "Train Epoch: 2 [0/11393 (0%)]\tLoss: 0.107277\n",
      "Train Epoch: 2 [640/11393 (6%)]\tLoss: 0.015333\n",
      "Train Epoch: 2 [1280/11393 (11%)]\tLoss: 0.020422\n",
      "Train Epoch: 2 [1920/11393 (17%)]\tLoss: 0.073275\n",
      "Train Epoch: 2 [2560/11393 (22%)]\tLoss: 0.016989\n",
      "Train Epoch: 2 [3200/11393 (28%)]\tLoss: 0.056178\n",
      "Train Epoch: 2 [3840/11393 (34%)]\tLoss: 0.015727\n",
      "Train Epoch: 2 [4480/11393 (39%)]\tLoss: 0.073278\n",
      "Train Epoch: 2 [5120/11393 (45%)]\tLoss: 0.045919\n",
      "Train Epoch: 2 [5760/11393 (50%)]\tLoss: 0.143171\n",
      "Train Epoch: 2 [6400/11393 (56%)]\tLoss: 0.036308\n",
      "Train Epoch: 2 [7040/11393 (61%)]\tLoss: 0.015772\n",
      "Train Epoch: 2 [7680/11393 (67%)]\tLoss: 0.027377\n",
      "Train Epoch: 2 [8320/11393 (73%)]\tLoss: 0.145374\n",
      "Train Epoch: 2 [8960/11393 (78%)]\tLoss: 0.019303\n",
      "Train Epoch: 2 [9600/11393 (84%)]\tLoss: 0.090912\n",
      "Train Epoch: 2 [10240/11393 (89%)]\tLoss: 0.013547\n",
      "Train Epoch: 2 [10880/11393 (95%)]\tLoss: 0.191840\n",
      "Train Epoch: 3 [0/11393 (0%)]\tLoss: 0.039517\n",
      "Train Epoch: 3 [640/11393 (6%)]\tLoss: 0.041129\n",
      "Train Epoch: 3 [1280/11393 (11%)]\tLoss: 0.104920\n",
      "Train Epoch: 3 [1920/11393 (17%)]\tLoss: 0.085738\n",
      "Train Epoch: 3 [2560/11393 (22%)]\tLoss: 0.048510\n",
      "Train Epoch: 3 [3200/11393 (28%)]\tLoss: 0.075218\n",
      "Train Epoch: 3 [3840/11393 (34%)]\tLoss: 0.055203\n",
      "Train Epoch: 3 [4480/11393 (39%)]\tLoss: 0.152997\n",
      "Train Epoch: 3 [5120/11393 (45%)]\tLoss: 0.034648\n",
      "Train Epoch: 3 [5760/11393 (50%)]\tLoss: 0.014943\n",
      "Train Epoch: 3 [6400/11393 (56%)]\tLoss: 0.050143\n",
      "Train Epoch: 3 [7040/11393 (61%)]\tLoss: 0.067188\n",
      "Train Epoch: 3 [7680/11393 (67%)]\tLoss: 0.047279\n",
      "Train Epoch: 3 [8320/11393 (73%)]\tLoss: 0.070566\n",
      "Train Epoch: 3 [8960/11393 (78%)]\tLoss: 0.074339\n",
      "Train Epoch: 3 [9600/11393 (84%)]\tLoss: 0.050678\n",
      "Train Epoch: 3 [10240/11393 (89%)]\tLoss: 0.038773\n",
      "Train Epoch: 3 [10880/11393 (95%)]\tLoss: 0.122002\n",
      "Train Epoch: 4 [0/11393 (0%)]\tLoss: 0.043953\n",
      "Train Epoch: 4 [640/11393 (6%)]\tLoss: 0.005559\n",
      "Train Epoch: 4 [1280/11393 (11%)]\tLoss: 0.042743\n",
      "Train Epoch: 4 [1920/11393 (17%)]\tLoss: 0.099323\n",
      "Train Epoch: 4 [2560/11393 (22%)]\tLoss: 0.051625\n",
      "Train Epoch: 4 [3200/11393 (28%)]\tLoss: 0.032539\n",
      "Train Epoch: 4 [3840/11393 (34%)]\tLoss: 0.064594\n",
      "Train Epoch: 4 [4480/11393 (39%)]\tLoss: 0.030120\n",
      "Train Epoch: 4 [5120/11393 (45%)]\tLoss: 0.101982\n",
      "Train Epoch: 4 [5760/11393 (50%)]\tLoss: 0.049663\n",
      "Train Epoch: 4 [6400/11393 (56%)]\tLoss: 0.053639\n",
      "Train Epoch: 4 [7040/11393 (61%)]\tLoss: 0.058932\n",
      "Train Epoch: 4 [7680/11393 (67%)]\tLoss: 0.079125\n",
      "Train Epoch: 4 [8320/11393 (73%)]\tLoss: 0.040982\n",
      "Train Epoch: 4 [8960/11393 (78%)]\tLoss: 0.152516\n",
      "Train Epoch: 4 [9600/11393 (84%)]\tLoss: 0.077143\n",
      "Train Epoch: 4 [10240/11393 (89%)]\tLoss: 0.036619\n",
      "Train Epoch: 4 [10880/11393 (95%)]\tLoss: 0.106378\n",
      "Train Epoch: 5 [0/11393 (0%)]\tLoss: 0.012209\n",
      "Train Epoch: 5 [640/11393 (6%)]\tLoss: 0.019777\n",
      "Train Epoch: 5 [1280/11393 (11%)]\tLoss: 0.041555\n",
      "Train Epoch: 5 [1920/11393 (17%)]\tLoss: 0.030227\n",
      "Train Epoch: 5 [2560/11393 (22%)]\tLoss: 0.107059\n",
      "Train Epoch: 5 [3200/11393 (28%)]\tLoss: 0.010756\n",
      "Train Epoch: 5 [3840/11393 (34%)]\tLoss: 0.061695\n",
      "Train Epoch: 5 [4480/11393 (39%)]\tLoss: 0.240062\n",
      "Train Epoch: 5 [5120/11393 (45%)]\tLoss: 0.007389\n",
      "Train Epoch: 5 [5760/11393 (50%)]\tLoss: 0.037566\n",
      "Train Epoch: 5 [6400/11393 (56%)]\tLoss: 0.014288\n",
      "Train Epoch: 5 [7040/11393 (61%)]\tLoss: 0.019962\n",
      "Train Epoch: 5 [7680/11393 (67%)]\tLoss: 0.184675\n",
      "Train Epoch: 5 [8320/11393 (73%)]\tLoss: 0.009578\n",
      "Train Epoch: 5 [8960/11393 (78%)]\tLoss: 0.039396\n",
      "Train Epoch: 5 [9600/11393 (84%)]\tLoss: 0.024040\n",
      "Train Epoch: 5 [10240/11393 (89%)]\tLoss: 0.006845\n",
      "Train Epoch: 5 [10880/11393 (95%)]\tLoss: 0.148426\n",
      "Train Epoch: 6 [0/11393 (0%)]\tLoss: 0.019301\n",
      "Train Epoch: 6 [640/11393 (6%)]\tLoss: 0.041358\n",
      "Train Epoch: 6 [1280/11393 (11%)]\tLoss: 0.089488\n",
      "Train Epoch: 6 [1920/11393 (17%)]\tLoss: 0.087439\n",
      "Train Epoch: 6 [2560/11393 (22%)]\tLoss: 0.018357\n",
      "Train Epoch: 6 [3200/11393 (28%)]\tLoss: 0.069011\n",
      "Train Epoch: 6 [3840/11393 (34%)]\tLoss: 0.103534\n",
      "Train Epoch: 6 [4480/11393 (39%)]\tLoss: 0.018233\n",
      "Train Epoch: 6 [5120/11393 (45%)]\tLoss: 0.050055\n",
      "Train Epoch: 6 [5760/11393 (50%)]\tLoss: 0.211192\n",
      "Train Epoch: 6 [6400/11393 (56%)]\tLoss: 0.014638\n",
      "Train Epoch: 6 [7040/11393 (61%)]\tLoss: 0.023223\n",
      "Train Epoch: 6 [7680/11393 (67%)]\tLoss: 0.058117\n",
      "Train Epoch: 6 [8320/11393 (73%)]\tLoss: 0.016330\n",
      "Train Epoch: 6 [8960/11393 (78%)]\tLoss: 0.130039\n",
      "Train Epoch: 6 [9600/11393 (84%)]\tLoss: 0.012738\n",
      "Train Epoch: 6 [10240/11393 (89%)]\tLoss: 0.035387\n",
      "Train Epoch: 6 [10880/11393 (95%)]\tLoss: 0.031915\n",
      "Train Epoch: 7 [0/11393 (0%)]\tLoss: 0.022413\n",
      "Train Epoch: 7 [640/11393 (6%)]\tLoss: 0.017561\n",
      "Train Epoch: 7 [1280/11393 (11%)]\tLoss: 0.093372\n",
      "Train Epoch: 7 [1920/11393 (17%)]\tLoss: 0.055209\n",
      "Train Epoch: 7 [2560/11393 (22%)]\tLoss: 0.009962\n",
      "Train Epoch: 7 [3200/11393 (28%)]\tLoss: 0.179609\n",
      "Train Epoch: 7 [3840/11393 (34%)]\tLoss: 0.006899\n",
      "Train Epoch: 7 [4480/11393 (39%)]\tLoss: 0.008924\n",
      "Train Epoch: 7 [5120/11393 (45%)]\tLoss: 0.063292\n",
      "Train Epoch: 7 [5760/11393 (50%)]\tLoss: 0.046171\n",
      "Train Epoch: 7 [6400/11393 (56%)]\tLoss: 0.087845\n",
      "Train Epoch: 7 [7040/11393 (61%)]\tLoss: 0.040163\n",
      "Train Epoch: 7 [7680/11393 (67%)]\tLoss: 0.075475\n",
      "Train Epoch: 7 [8320/11393 (73%)]\tLoss: 0.094416\n",
      "Train Epoch: 7 [8960/11393 (78%)]\tLoss: 0.050624\n",
      "Train Epoch: 7 [9600/11393 (84%)]\tLoss: 0.115323\n",
      "Train Epoch: 7 [10240/11393 (89%)]\tLoss: 0.027843\n",
      "Train Epoch: 7 [10880/11393 (95%)]\tLoss: 0.018797\n",
      "Train Epoch: 8 [0/11393 (0%)]\tLoss: 0.008361\n",
      "Train Epoch: 8 [640/11393 (6%)]\tLoss: 0.066894\n",
      "Train Epoch: 8 [1280/11393 (11%)]\tLoss: 0.049103\n",
      "Train Epoch: 8 [1920/11393 (17%)]\tLoss: 0.029448\n",
      "Train Epoch: 8 [2560/11393 (22%)]\tLoss: 0.013715\n",
      "Train Epoch: 8 [3200/11393 (28%)]\tLoss: 0.035714\n",
      "Train Epoch: 8 [3840/11393 (34%)]\tLoss: 0.047583\n",
      "Train Epoch: 8 [4480/11393 (39%)]\tLoss: 0.036014\n",
      "Train Epoch: 8 [5120/11393 (45%)]\tLoss: 0.211328\n",
      "Train Epoch: 8 [5760/11393 (50%)]\tLoss: 0.017584\n",
      "Train Epoch: 8 [6400/11393 (56%)]\tLoss: 0.044427\n",
      "Train Epoch: 8 [7040/11393 (61%)]\tLoss: 0.012375\n",
      "Train Epoch: 8 [7680/11393 (67%)]\tLoss: 0.021100\n",
      "Train Epoch: 8 [8320/11393 (73%)]\tLoss: 0.039245\n",
      "Train Epoch: 8 [8960/11393 (78%)]\tLoss: 0.008628\n",
      "Train Epoch: 8 [9600/11393 (84%)]\tLoss: 0.008230\n",
      "Train Epoch: 8 [10240/11393 (89%)]\tLoss: 0.099087\n",
      "Train Epoch: 8 [10880/11393 (95%)]\tLoss: 0.037556\n",
      "Train Epoch: 9 [0/11393 (0%)]\tLoss: 0.053998\n",
      "Train Epoch: 9 [640/11393 (6%)]\tLoss: 0.020202\n",
      "Train Epoch: 9 [1280/11393 (11%)]\tLoss: 0.015406\n",
      "Train Epoch: 9 [1920/11393 (17%)]\tLoss: 0.025247\n",
      "Train Epoch: 9 [2560/11393 (22%)]\tLoss: 0.048126\n",
      "Train Epoch: 9 [3200/11393 (28%)]\tLoss: 0.007389\n",
      "Train Epoch: 9 [3840/11393 (34%)]\tLoss: 0.054399\n",
      "Train Epoch: 9 [4480/11393 (39%)]\tLoss: 0.012318\n",
      "Train Epoch: 9 [5120/11393 (45%)]\tLoss: 0.106355\n",
      "Train Epoch: 9 [5760/11393 (50%)]\tLoss: 0.024974\n",
      "Train Epoch: 9 [6400/11393 (56%)]\tLoss: 0.139300\n",
      "Train Epoch: 9 [7040/11393 (61%)]\tLoss: 0.032476\n",
      "Train Epoch: 9 [7680/11393 (67%)]\tLoss: 0.073526\n",
      "Train Epoch: 9 [8320/11393 (73%)]\tLoss: 0.030747\n",
      "Train Epoch: 9 [8960/11393 (78%)]\tLoss: 0.010038\n",
      "Train Epoch: 9 [9600/11393 (84%)]\tLoss: 0.093032\n",
      "Train Epoch: 9 [10240/11393 (89%)]\tLoss: 0.011392\n",
      "Train Epoch: 9 [10880/11393 (95%)]\tLoss: 0.045624\n",
      "Train Epoch: 10 [0/11393 (0%)]\tLoss: 0.127416\n",
      "Train Epoch: 10 [640/11393 (6%)]\tLoss: 0.078235\n",
      "Train Epoch: 10 [1280/11393 (11%)]\tLoss: 0.026485\n",
      "Train Epoch: 10 [1920/11393 (17%)]\tLoss: 0.031336\n",
      "Train Epoch: 10 [2560/11393 (22%)]\tLoss: 0.056040\n",
      "Train Epoch: 10 [3200/11393 (28%)]\tLoss: 0.020012\n",
      "Train Epoch: 10 [3840/11393 (34%)]\tLoss: 0.065820\n",
      "Train Epoch: 10 [4480/11393 (39%)]\tLoss: 0.055385\n",
      "Train Epoch: 10 [5120/11393 (45%)]\tLoss: 0.003517\n",
      "Train Epoch: 10 [5760/11393 (50%)]\tLoss: 0.055052\n",
      "Train Epoch: 10 [6400/11393 (56%)]\tLoss: 0.051025\n",
      "Train Epoch: 10 [7040/11393 (61%)]\tLoss: 0.070588\n",
      "Train Epoch: 10 [7680/11393 (67%)]\tLoss: 0.003497\n",
      "Train Epoch: 10 [8320/11393 (73%)]\tLoss: 0.051660\n",
      "Train Epoch: 10 [8960/11393 (78%)]\tLoss: 0.002178\n",
      "Train Epoch: 10 [9600/11393 (84%)]\tLoss: 0.177832\n",
      "Train Epoch: 10 [10240/11393 (89%)]\tLoss: 0.073951\n",
      "Train Epoch: 10 [10880/11393 (95%)]\tLoss: 0.111655\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/5110 (0%)]\tLoss: 0.119177\n",
      "Train Epoch: 1 [640/5110 (12%)]\tLoss: 0.075772\n",
      "Train Epoch: 1 [1280/5110 (25%)]\tLoss: 0.023862\n",
      "Train Epoch: 1 [1920/5110 (38%)]\tLoss: 0.068363\n",
      "Train Epoch: 1 [2560/5110 (50%)]\tLoss: 0.031732\n",
      "Train Epoch: 1 [3200/5110 (62%)]\tLoss: 0.038171\n",
      "Train Epoch: 1 [3840/5110 (75%)]\tLoss: 0.026412\n",
      "Train Epoch: 1 [4480/5110 (88%)]\tLoss: 0.023759\n",
      "Train Epoch: 2 [0/5110 (0%)]\tLoss: 0.106109\n",
      "Train Epoch: 2 [640/5110 (12%)]\tLoss: 0.060899\n",
      "Train Epoch: 2 [1280/5110 (25%)]\tLoss: 0.009135\n",
      "Train Epoch: 2 [1920/5110 (38%)]\tLoss: 0.073867\n",
      "Train Epoch: 2 [2560/5110 (50%)]\tLoss: 0.014465\n",
      "Train Epoch: 2 [3200/5110 (62%)]\tLoss: 0.015940\n",
      "Train Epoch: 2 [3840/5110 (75%)]\tLoss: 0.028606\n",
      "Train Epoch: 2 [4480/5110 (88%)]\tLoss: 0.084706\n",
      "Train Epoch: 3 [0/5110 (0%)]\tLoss: 0.013219\n",
      "Train Epoch: 3 [640/5110 (12%)]\tLoss: 0.039836\n",
      "Train Epoch: 3 [1280/5110 (25%)]\tLoss: 0.005804\n",
      "Train Epoch: 3 [1920/5110 (38%)]\tLoss: 0.022063\n",
      "Train Epoch: 3 [2560/5110 (50%)]\tLoss: 0.042785\n",
      "Train Epoch: 3 [3200/5110 (62%)]\tLoss: 0.021311\n",
      "Train Epoch: 3 [3840/5110 (75%)]\tLoss: 0.058111\n",
      "Train Epoch: 3 [4480/5110 (88%)]\tLoss: 0.031198\n",
      "Train Epoch: 4 [0/5110 (0%)]\tLoss: 0.054016\n",
      "Train Epoch: 4 [640/5110 (12%)]\tLoss: 0.052630\n",
      "Train Epoch: 4 [1280/5110 (25%)]\tLoss: 0.017912\n",
      "Train Epoch: 4 [1920/5110 (38%)]\tLoss: 0.012802\n",
      "Train Epoch: 4 [2560/5110 (50%)]\tLoss: 0.070291\n",
      "Train Epoch: 4 [3200/5110 (62%)]\tLoss: 0.028132\n",
      "Train Epoch: 4 [3840/5110 (75%)]\tLoss: 0.124795\n",
      "Train Epoch: 4 [4480/5110 (88%)]\tLoss: 0.005026\n",
      "Train Epoch: 5 [0/5110 (0%)]\tLoss: 0.055102\n",
      "Train Epoch: 5 [640/5110 (12%)]\tLoss: 0.020495\n",
      "Train Epoch: 5 [1280/5110 (25%)]\tLoss: 0.086523\n",
      "Train Epoch: 5 [1920/5110 (38%)]\tLoss: 0.006995\n",
      "Train Epoch: 5 [2560/5110 (50%)]\tLoss: 0.046278\n",
      "Train Epoch: 5 [3200/5110 (62%)]\tLoss: 0.002455\n",
      "Train Epoch: 5 [3840/5110 (75%)]\tLoss: 0.009685\n",
      "Train Epoch: 5 [4480/5110 (88%)]\tLoss: 0.000406\n",
      "Train Epoch: 6 [0/5110 (0%)]\tLoss: 0.017285\n",
      "Train Epoch: 6 [640/5110 (12%)]\tLoss: 0.028949\n",
      "Train Epoch: 6 [1280/5110 (25%)]\tLoss: 0.126335\n",
      "Train Epoch: 6 [1920/5110 (38%)]\tLoss: 0.014404\n",
      "Train Epoch: 6 [2560/5110 (50%)]\tLoss: 0.078469\n",
      "Train Epoch: 6 [3200/5110 (62%)]\tLoss: 0.027336\n",
      "Train Epoch: 6 [3840/5110 (75%)]\tLoss: 0.062524\n",
      "Train Epoch: 6 [4480/5110 (88%)]\tLoss: 0.021715\n",
      "Train Epoch: 7 [0/5110 (0%)]\tLoss: 0.004815\n",
      "Train Epoch: 7 [640/5110 (12%)]\tLoss: 0.092989\n",
      "Train Epoch: 7 [1280/5110 (25%)]\tLoss: 0.046947\n",
      "Train Epoch: 7 [1920/5110 (38%)]\tLoss: 0.046217\n",
      "Train Epoch: 7 [2560/5110 (50%)]\tLoss: 0.159176\n",
      "Train Epoch: 7 [3200/5110 (62%)]\tLoss: 0.021291\n",
      "Train Epoch: 7 [3840/5110 (75%)]\tLoss: 0.081280\n",
      "Train Epoch: 7 [4480/5110 (88%)]\tLoss: 0.059107\n",
      "Train Epoch: 8 [0/5110 (0%)]\tLoss: 0.007124\n",
      "Train Epoch: 8 [640/5110 (12%)]\tLoss: 0.003144\n",
      "Train Epoch: 8 [1280/5110 (25%)]\tLoss: 0.057344\n",
      "Train Epoch: 8 [1920/5110 (38%)]\tLoss: 0.047770\n",
      "Train Epoch: 8 [2560/5110 (50%)]\tLoss: 0.056167\n",
      "Train Epoch: 8 [3200/5110 (62%)]\tLoss: 0.007324\n",
      "Train Epoch: 8 [3840/5110 (75%)]\tLoss: 0.116548\n",
      "Train Epoch: 8 [4480/5110 (88%)]\tLoss: 0.026804\n",
      "Train Epoch: 9 [0/5110 (0%)]\tLoss: 0.072679\n",
      "Train Epoch: 9 [640/5110 (12%)]\tLoss: 0.016235\n",
      "Train Epoch: 9 [1280/5110 (25%)]\tLoss: 0.094545\n",
      "Train Epoch: 9 [1920/5110 (38%)]\tLoss: 0.026704\n",
      "Train Epoch: 9 [2560/5110 (50%)]\tLoss: 0.059888\n",
      "Train Epoch: 9 [3200/5110 (62%)]\tLoss: 0.093856\n",
      "Train Epoch: 9 [3840/5110 (75%)]\tLoss: 0.029737\n",
      "Train Epoch: 9 [4480/5110 (88%)]\tLoss: 0.019733\n",
      "Train Epoch: 10 [0/5110 (0%)]\tLoss: 0.067774\n",
      "Train Epoch: 10 [640/5110 (12%)]\tLoss: 0.031709\n",
      "Train Epoch: 10 [1280/5110 (25%)]\tLoss: 0.064169\n",
      "Train Epoch: 10 [1920/5110 (38%)]\tLoss: 0.011896\n",
      "Train Epoch: 10 [2560/5110 (50%)]\tLoss: 0.025402\n",
      "Train Epoch: 10 [3200/5110 (62%)]\tLoss: 0.040402\n",
      "Train Epoch: 10 [3840/5110 (75%)]\tLoss: 0.065772\n",
      "Train Epoch: 10 [4480/5110 (88%)]\tLoss: 0.003864\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6766 (0%)]\tLoss: 0.034630\n",
      "Train Epoch: 1 [640/6766 (9%)]\tLoss: 0.053578\n",
      "Train Epoch: 1 [1280/6766 (19%)]\tLoss: 0.019539\n",
      "Train Epoch: 1 [1920/6766 (28%)]\tLoss: 0.133624\n",
      "Train Epoch: 1 [2560/6766 (38%)]\tLoss: 0.066622\n",
      "Train Epoch: 1 [3200/6766 (47%)]\tLoss: 0.099183\n",
      "Train Epoch: 1 [3840/6766 (57%)]\tLoss: 0.002674\n",
      "Train Epoch: 1 [4480/6766 (66%)]\tLoss: 0.001188\n",
      "Train Epoch: 1 [5120/6766 (75%)]\tLoss: 0.008381\n",
      "Train Epoch: 1 [5760/6766 (85%)]\tLoss: 0.154928\n",
      "Train Epoch: 1 [6400/6766 (94%)]\tLoss: 0.122017\n",
      "Train Epoch: 2 [0/6766 (0%)]\tLoss: 0.005877\n",
      "Train Epoch: 2 [640/6766 (9%)]\tLoss: 0.014495\n",
      "Train Epoch: 2 [1280/6766 (19%)]\tLoss: 0.087245\n",
      "Train Epoch: 2 [1920/6766 (28%)]\tLoss: 0.034188\n",
      "Train Epoch: 2 [2560/6766 (38%)]\tLoss: 0.071313\n",
      "Train Epoch: 2 [3200/6766 (47%)]\tLoss: 0.166514\n",
      "Train Epoch: 2 [3840/6766 (57%)]\tLoss: 0.006074\n",
      "Train Epoch: 2 [4480/6766 (66%)]\tLoss: 0.003061\n",
      "Train Epoch: 2 [5120/6766 (75%)]\tLoss: 0.097121\n",
      "Train Epoch: 2 [5760/6766 (85%)]\tLoss: 0.016496\n",
      "Train Epoch: 2 [6400/6766 (94%)]\tLoss: 0.122066\n",
      "Train Epoch: 3 [0/6766 (0%)]\tLoss: 0.025120\n",
      "Train Epoch: 3 [640/6766 (9%)]\tLoss: 0.036911\n",
      "Train Epoch: 3 [1280/6766 (19%)]\tLoss: 0.023572\n",
      "Train Epoch: 3 [1920/6766 (28%)]\tLoss: 0.065404\n",
      "Train Epoch: 3 [2560/6766 (38%)]\tLoss: 0.101728\n",
      "Train Epoch: 3 [3200/6766 (47%)]\tLoss: 0.029744\n",
      "Train Epoch: 3 [3840/6766 (57%)]\tLoss: 0.032396\n",
      "Train Epoch: 3 [4480/6766 (66%)]\tLoss: 0.003630\n",
      "Train Epoch: 3 [5120/6766 (75%)]\tLoss: 0.031273\n",
      "Train Epoch: 3 [5760/6766 (85%)]\tLoss: 0.012863\n",
      "Train Epoch: 3 [6400/6766 (94%)]\tLoss: 0.044909\n",
      "Train Epoch: 4 [0/6766 (0%)]\tLoss: 0.017546\n",
      "Train Epoch: 4 [640/6766 (9%)]\tLoss: 0.088888\n",
      "Train Epoch: 4 [1280/6766 (19%)]\tLoss: 0.013756\n",
      "Train Epoch: 4 [1920/6766 (28%)]\tLoss: 0.021514\n",
      "Train Epoch: 4 [2560/6766 (38%)]\tLoss: 0.039950\n",
      "Train Epoch: 4 [3200/6766 (47%)]\tLoss: 0.198562\n",
      "Train Epoch: 4 [3840/6766 (57%)]\tLoss: 0.005474\n",
      "Train Epoch: 4 [4480/6766 (66%)]\tLoss: 0.038908\n",
      "Train Epoch: 4 [5120/6766 (75%)]\tLoss: 0.047133\n",
      "Train Epoch: 4 [5760/6766 (85%)]\tLoss: 0.015466\n",
      "Train Epoch: 4 [6400/6766 (94%)]\tLoss: 0.054662\n",
      "Train Epoch: 5 [0/6766 (0%)]\tLoss: 0.003684\n",
      "Train Epoch: 5 [640/6766 (9%)]\tLoss: 0.039004\n",
      "Train Epoch: 5 [1280/6766 (19%)]\tLoss: 0.046918\n",
      "Train Epoch: 5 [1920/6766 (28%)]\tLoss: 0.029174\n",
      "Train Epoch: 5 [2560/6766 (38%)]\tLoss: 0.043473\n",
      "Train Epoch: 5 [3200/6766 (47%)]\tLoss: 0.005694\n",
      "Train Epoch: 5 [3840/6766 (57%)]\tLoss: 0.003443\n",
      "Train Epoch: 5 [4480/6766 (66%)]\tLoss: 0.023356\n",
      "Train Epoch: 5 [5120/6766 (75%)]\tLoss: 0.053893\n",
      "Train Epoch: 5 [5760/6766 (85%)]\tLoss: 0.004264\n",
      "Train Epoch: 5 [6400/6766 (94%)]\tLoss: 0.010607\n",
      "Train Epoch: 6 [0/6766 (0%)]\tLoss: 0.006631\n",
      "Train Epoch: 6 [640/6766 (9%)]\tLoss: 0.036009\n",
      "Train Epoch: 6 [1280/6766 (19%)]\tLoss: 0.013326\n",
      "Train Epoch: 6 [1920/6766 (28%)]\tLoss: 0.054804\n",
      "Train Epoch: 6 [2560/6766 (38%)]\tLoss: 0.167583\n",
      "Train Epoch: 6 [3200/6766 (47%)]\tLoss: 0.000736\n",
      "Train Epoch: 6 [3840/6766 (57%)]\tLoss: 0.019140\n",
      "Train Epoch: 6 [4480/6766 (66%)]\tLoss: 0.068984\n",
      "Train Epoch: 6 [5120/6766 (75%)]\tLoss: 0.036718\n",
      "Train Epoch: 6 [5760/6766 (85%)]\tLoss: 0.069585\n",
      "Train Epoch: 6 [6400/6766 (94%)]\tLoss: 0.016103\n",
      "Train Epoch: 7 [0/6766 (0%)]\tLoss: 0.139743\n",
      "Train Epoch: 7 [640/6766 (9%)]\tLoss: 0.072424\n",
      "Train Epoch: 7 [1280/6766 (19%)]\tLoss: 0.053717\n",
      "Train Epoch: 7 [1920/6766 (28%)]\tLoss: 0.013485\n",
      "Train Epoch: 7 [2560/6766 (38%)]\tLoss: 0.014395\n",
      "Train Epoch: 7 [3200/6766 (47%)]\tLoss: 0.057701\n",
      "Train Epoch: 7 [3840/6766 (57%)]\tLoss: 0.038608\n",
      "Train Epoch: 7 [4480/6766 (66%)]\tLoss: 0.009350\n",
      "Train Epoch: 7 [5120/6766 (75%)]\tLoss: 0.052125\n",
      "Train Epoch: 7 [5760/6766 (85%)]\tLoss: 0.027865\n",
      "Train Epoch: 7 [6400/6766 (94%)]\tLoss: 0.058999\n",
      "Train Epoch: 8 [0/6766 (0%)]\tLoss: 0.012132\n",
      "Train Epoch: 8 [640/6766 (9%)]\tLoss: 0.011474\n",
      "Train Epoch: 8 [1280/6766 (19%)]\tLoss: 0.003082\n",
      "Train Epoch: 8 [1920/6766 (28%)]\tLoss: 0.164448\n",
      "Train Epoch: 8 [2560/6766 (38%)]\tLoss: 0.117495\n",
      "Train Epoch: 8 [3200/6766 (47%)]\tLoss: 0.070010\n",
      "Train Epoch: 8 [3840/6766 (57%)]\tLoss: 0.021230\n",
      "Train Epoch: 8 [4480/6766 (66%)]\tLoss: 0.062568\n",
      "Train Epoch: 8 [5120/6766 (75%)]\tLoss: 0.023759\n",
      "Train Epoch: 8 [5760/6766 (85%)]\tLoss: 0.094356\n",
      "Train Epoch: 8 [6400/6766 (94%)]\tLoss: 0.003850\n",
      "Train Epoch: 9 [0/6766 (0%)]\tLoss: 0.090081\n",
      "Train Epoch: 9 [640/6766 (9%)]\tLoss: 0.002044\n",
      "Train Epoch: 9 [1280/6766 (19%)]\tLoss: 0.076173\n",
      "Train Epoch: 9 [1920/6766 (28%)]\tLoss: 0.010015\n",
      "Train Epoch: 9 [2560/6766 (38%)]\tLoss: 0.019537\n",
      "Train Epoch: 9 [3200/6766 (47%)]\tLoss: 0.069586\n",
      "Train Epoch: 9 [3840/6766 (57%)]\tLoss: 0.017093\n",
      "Train Epoch: 9 [4480/6766 (66%)]\tLoss: 0.010031\n",
      "Train Epoch: 9 [5120/6766 (75%)]\tLoss: 0.209863\n",
      "Train Epoch: 9 [5760/6766 (85%)]\tLoss: 0.004574\n",
      "Train Epoch: 9 [6400/6766 (94%)]\tLoss: 0.000870\n",
      "Train Epoch: 10 [0/6766 (0%)]\tLoss: 0.013011\n",
      "Train Epoch: 10 [640/6766 (9%)]\tLoss: 0.018170\n",
      "Train Epoch: 10 [1280/6766 (19%)]\tLoss: 0.006879\n",
      "Train Epoch: 10 [1920/6766 (28%)]\tLoss: 0.040997\n",
      "Train Epoch: 10 [2560/6766 (38%)]\tLoss: 0.001639\n",
      "Train Epoch: 10 [3200/6766 (47%)]\tLoss: 0.030010\n",
      "Train Epoch: 10 [3840/6766 (57%)]\tLoss: 0.044956\n",
      "Train Epoch: 10 [4480/6766 (66%)]\tLoss: 0.011439\n",
      "Train Epoch: 10 [5120/6766 (75%)]\tLoss: 0.026863\n",
      "Train Epoch: 10 [5760/6766 (85%)]\tLoss: 0.052711\n",
      "Train Epoch: 10 [6400/6766 (94%)]\tLoss: 0.018674\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/10061 (0%)]\tLoss: 0.108629\n",
      "Train Epoch: 1 [640/10061 (6%)]\tLoss: 0.052591\n",
      "Train Epoch: 1 [1280/10061 (13%)]\tLoss: 0.016760\n",
      "Train Epoch: 1 [1920/10061 (19%)]\tLoss: 0.043131\n",
      "Train Epoch: 1 [2560/10061 (25%)]\tLoss: 0.070376\n",
      "Train Epoch: 1 [3200/10061 (32%)]\tLoss: 0.113418\n",
      "Train Epoch: 1 [3840/10061 (38%)]\tLoss: 0.033513\n",
      "Train Epoch: 1 [4480/10061 (44%)]\tLoss: 0.078330\n",
      "Train Epoch: 1 [5120/10061 (51%)]\tLoss: 0.063248\n",
      "Train Epoch: 1 [5760/10061 (57%)]\tLoss: 0.132326\n",
      "Train Epoch: 1 [6400/10061 (63%)]\tLoss: 0.009419\n",
      "Train Epoch: 1 [7040/10061 (70%)]\tLoss: 0.305012\n",
      "Train Epoch: 1 [7680/10061 (76%)]\tLoss: 0.051399\n",
      "Train Epoch: 1 [8320/10061 (82%)]\tLoss: 0.020724\n",
      "Train Epoch: 1 [8960/10061 (89%)]\tLoss: 0.035585\n",
      "Train Epoch: 1 [9600/10061 (95%)]\tLoss: 0.013915\n",
      "Train Epoch: 2 [0/10061 (0%)]\tLoss: 0.025037\n",
      "Train Epoch: 2 [640/10061 (6%)]\tLoss: 0.019032\n",
      "Train Epoch: 2 [1280/10061 (13%)]\tLoss: 0.005353\n",
      "Train Epoch: 2 [1920/10061 (19%)]\tLoss: 0.123274\n",
      "Train Epoch: 2 [2560/10061 (25%)]\tLoss: 0.013996\n",
      "Train Epoch: 2 [3200/10061 (32%)]\tLoss: 0.011627\n",
      "Train Epoch: 2 [3840/10061 (38%)]\tLoss: 0.075474\n",
      "Train Epoch: 2 [4480/10061 (44%)]\tLoss: 0.007493\n",
      "Train Epoch: 2 [5120/10061 (51%)]\tLoss: 0.053229\n",
      "Train Epoch: 2 [5760/10061 (57%)]\tLoss: 0.048248\n",
      "Train Epoch: 2 [6400/10061 (63%)]\tLoss: 0.041600\n",
      "Train Epoch: 2 [7040/10061 (70%)]\tLoss: 0.011474\n",
      "Train Epoch: 2 [7680/10061 (76%)]\tLoss: 0.020678\n",
      "Train Epoch: 2 [8320/10061 (82%)]\tLoss: 0.125845\n",
      "Train Epoch: 2 [8960/10061 (89%)]\tLoss: 0.011117\n",
      "Train Epoch: 2 [9600/10061 (95%)]\tLoss: 0.020469\n",
      "Train Epoch: 3 [0/10061 (0%)]\tLoss: 0.007294\n",
      "Train Epoch: 3 [640/10061 (6%)]\tLoss: 0.006912\n",
      "Train Epoch: 3 [1280/10061 (13%)]\tLoss: 0.108271\n",
      "Train Epoch: 3 [1920/10061 (19%)]\tLoss: 0.048465\n",
      "Train Epoch: 3 [2560/10061 (25%)]\tLoss: 0.043938\n",
      "Train Epoch: 3 [3200/10061 (32%)]\tLoss: 0.048732\n",
      "Train Epoch: 3 [3840/10061 (38%)]\tLoss: 0.006727\n",
      "Train Epoch: 3 [4480/10061 (44%)]\tLoss: 0.038185\n",
      "Train Epoch: 3 [5120/10061 (51%)]\tLoss: 0.009510\n",
      "Train Epoch: 3 [5760/10061 (57%)]\tLoss: 0.187836\n",
      "Train Epoch: 3 [6400/10061 (63%)]\tLoss: 0.037453\n",
      "Train Epoch: 3 [7040/10061 (70%)]\tLoss: 0.015322\n",
      "Train Epoch: 3 [7680/10061 (76%)]\tLoss: 0.003511\n",
      "Train Epoch: 3 [8320/10061 (82%)]\tLoss: 0.081548\n",
      "Train Epoch: 3 [8960/10061 (89%)]\tLoss: 0.015253\n",
      "Train Epoch: 3 [9600/10061 (95%)]\tLoss: 0.053765\n",
      "Train Epoch: 4 [0/10061 (0%)]\tLoss: 0.089025\n",
      "Train Epoch: 4 [640/10061 (6%)]\tLoss: 0.044138\n",
      "Train Epoch: 4 [1280/10061 (13%)]\tLoss: 0.075296\n",
      "Train Epoch: 4 [1920/10061 (19%)]\tLoss: 0.042317\n",
      "Train Epoch: 4 [2560/10061 (25%)]\tLoss: 0.034412\n",
      "Train Epoch: 4 [3200/10061 (32%)]\tLoss: 0.155662\n",
      "Train Epoch: 4 [3840/10061 (38%)]\tLoss: 0.092752\n",
      "Train Epoch: 4 [4480/10061 (44%)]\tLoss: 0.029033\n",
      "Train Epoch: 4 [5120/10061 (51%)]\tLoss: 0.009013\n",
      "Train Epoch: 4 [5760/10061 (57%)]\tLoss: 0.005693\n",
      "Train Epoch: 4 [6400/10061 (63%)]\tLoss: 0.008913\n",
      "Train Epoch: 4 [7040/10061 (70%)]\tLoss: 0.015108\n",
      "Train Epoch: 4 [7680/10061 (76%)]\tLoss: 0.110338\n",
      "Train Epoch: 4 [8320/10061 (82%)]\tLoss: 0.029095\n",
      "Train Epoch: 4 [8960/10061 (89%)]\tLoss: 0.009535\n",
      "Train Epoch: 4 [9600/10061 (95%)]\tLoss: 0.085417\n",
      "Train Epoch: 5 [0/10061 (0%)]\tLoss: 0.012862\n",
      "Train Epoch: 5 [640/10061 (6%)]\tLoss: 0.087989\n",
      "Train Epoch: 5 [1280/10061 (13%)]\tLoss: 0.002540\n",
      "Train Epoch: 5 [1920/10061 (19%)]\tLoss: 0.022018\n",
      "Train Epoch: 5 [2560/10061 (25%)]\tLoss: 0.041230\n",
      "Train Epoch: 5 [3200/10061 (32%)]\tLoss: 0.026575\n",
      "Train Epoch: 5 [3840/10061 (38%)]\tLoss: 0.367823\n",
      "Train Epoch: 5 [4480/10061 (44%)]\tLoss: 0.011953\n",
      "Train Epoch: 5 [5120/10061 (51%)]\tLoss: 0.064781\n",
      "Train Epoch: 5 [5760/10061 (57%)]\tLoss: 0.041875\n",
      "Train Epoch: 5 [6400/10061 (63%)]\tLoss: 0.133849\n",
      "Train Epoch: 5 [7040/10061 (70%)]\tLoss: 0.046429\n",
      "Train Epoch: 5 [7680/10061 (76%)]\tLoss: 0.010240\n",
      "Train Epoch: 5 [8320/10061 (82%)]\tLoss: 0.153711\n",
      "Train Epoch: 5 [8960/10061 (89%)]\tLoss: 0.005452\n",
      "Train Epoch: 5 [9600/10061 (95%)]\tLoss: 0.067732\n",
      "Train Epoch: 6 [0/10061 (0%)]\tLoss: 0.040827\n",
      "Train Epoch: 6 [640/10061 (6%)]\tLoss: 0.107524\n",
      "Train Epoch: 6 [1280/10061 (13%)]\tLoss: 0.010665\n",
      "Train Epoch: 6 [1920/10061 (19%)]\tLoss: 0.028567\n",
      "Train Epoch: 6 [2560/10061 (25%)]\tLoss: 0.046645\n",
      "Train Epoch: 6 [3200/10061 (32%)]\tLoss: 0.065771\n",
      "Train Epoch: 6 [3840/10061 (38%)]\tLoss: 0.043284\n",
      "Train Epoch: 6 [4480/10061 (44%)]\tLoss: 0.034302\n",
      "Train Epoch: 6 [5120/10061 (51%)]\tLoss: 0.016629\n",
      "Train Epoch: 6 [5760/10061 (57%)]\tLoss: 0.025009\n",
      "Train Epoch: 6 [6400/10061 (63%)]\tLoss: 0.050089\n",
      "Train Epoch: 6 [7040/10061 (70%)]\tLoss: 0.008694\n",
      "Train Epoch: 6 [7680/10061 (76%)]\tLoss: 0.035905\n",
      "Train Epoch: 6 [8320/10061 (82%)]\tLoss: 0.010036\n",
      "Train Epoch: 6 [8960/10061 (89%)]\tLoss: 0.014541\n",
      "Train Epoch: 6 [9600/10061 (95%)]\tLoss: 0.004175\n",
      "Train Epoch: 7 [0/10061 (0%)]\tLoss: 0.094836\n",
      "Train Epoch: 7 [640/10061 (6%)]\tLoss: 0.017579\n",
      "Train Epoch: 7 [1280/10061 (13%)]\tLoss: 0.017180\n",
      "Train Epoch: 7 [1920/10061 (19%)]\tLoss: 0.009185\n",
      "Train Epoch: 7 [2560/10061 (25%)]\tLoss: 0.037624\n",
      "Train Epoch: 7 [3200/10061 (32%)]\tLoss: 0.014975\n",
      "Train Epoch: 7 [3840/10061 (38%)]\tLoss: 0.043334\n",
      "Train Epoch: 7 [4480/10061 (44%)]\tLoss: 0.010250\n",
      "Train Epoch: 7 [5120/10061 (51%)]\tLoss: 0.012049\n",
      "Train Epoch: 7 [5760/10061 (57%)]\tLoss: 0.047711\n",
      "Train Epoch: 7 [6400/10061 (63%)]\tLoss: 0.003693\n",
      "Train Epoch: 7 [7040/10061 (70%)]\tLoss: 0.032349\n",
      "Train Epoch: 7 [7680/10061 (76%)]\tLoss: 0.015443\n",
      "Train Epoch: 7 [8320/10061 (82%)]\tLoss: 0.031877\n",
      "Train Epoch: 7 [8960/10061 (89%)]\tLoss: 0.025963\n",
      "Train Epoch: 7 [9600/10061 (95%)]\tLoss: 0.009924\n",
      "Train Epoch: 8 [0/10061 (0%)]\tLoss: 0.021799\n",
      "Train Epoch: 8 [640/10061 (6%)]\tLoss: 0.049874\n",
      "Train Epoch: 8 [1280/10061 (13%)]\tLoss: 0.144038\n",
      "Train Epoch: 8 [1920/10061 (19%)]\tLoss: 0.043580\n",
      "Train Epoch: 8 [2560/10061 (25%)]\tLoss: 0.040646\n",
      "Train Epoch: 8 [3200/10061 (32%)]\tLoss: 0.008466\n",
      "Train Epoch: 8 [3840/10061 (38%)]\tLoss: 0.048476\n",
      "Train Epoch: 8 [4480/10061 (44%)]\tLoss: 0.002080\n",
      "Train Epoch: 8 [5120/10061 (51%)]\tLoss: 0.034312\n",
      "Train Epoch: 8 [5760/10061 (57%)]\tLoss: 0.339882\n",
      "Train Epoch: 8 [6400/10061 (63%)]\tLoss: 0.004704\n",
      "Train Epoch: 8 [7040/10061 (70%)]\tLoss: 0.036474\n",
      "Train Epoch: 8 [7680/10061 (76%)]\tLoss: 0.031568\n",
      "Train Epoch: 8 [8320/10061 (82%)]\tLoss: 0.117608\n",
      "Train Epoch: 8 [8960/10061 (89%)]\tLoss: 0.243734\n",
      "Train Epoch: 8 [9600/10061 (95%)]\tLoss: 0.079170\n",
      "Train Epoch: 9 [0/10061 (0%)]\tLoss: 0.012329\n",
      "Train Epoch: 9 [640/10061 (6%)]\tLoss: 0.056307\n",
      "Train Epoch: 9 [1280/10061 (13%)]\tLoss: 0.015199\n",
      "Train Epoch: 9 [1920/10061 (19%)]\tLoss: 0.016932\n",
      "Train Epoch: 9 [2560/10061 (25%)]\tLoss: 0.041108\n",
      "Train Epoch: 9 [3200/10061 (32%)]\tLoss: 0.008672\n",
      "Train Epoch: 9 [3840/10061 (38%)]\tLoss: 0.013300\n",
      "Train Epoch: 9 [4480/10061 (44%)]\tLoss: 0.033321\n",
      "Train Epoch: 9 [5120/10061 (51%)]\tLoss: 0.005176\n",
      "Train Epoch: 9 [5760/10061 (57%)]\tLoss: 0.018237\n",
      "Train Epoch: 9 [6400/10061 (63%)]\tLoss: 0.046210\n",
      "Train Epoch: 9 [7040/10061 (70%)]\tLoss: 0.026724\n",
      "Train Epoch: 9 [7680/10061 (76%)]\tLoss: 0.062973\n",
      "Train Epoch: 9 [8320/10061 (82%)]\tLoss: 0.018234\n",
      "Train Epoch: 9 [8960/10061 (89%)]\tLoss: 0.004816\n",
      "Train Epoch: 9 [9600/10061 (95%)]\tLoss: 0.036559\n",
      "Train Epoch: 10 [0/10061 (0%)]\tLoss: 0.016515\n",
      "Train Epoch: 10 [640/10061 (6%)]\tLoss: 0.006182\n",
      "Train Epoch: 10 [1280/10061 (13%)]\tLoss: 0.013925\n",
      "Train Epoch: 10 [1920/10061 (19%)]\tLoss: 0.046854\n",
      "Train Epoch: 10 [2560/10061 (25%)]\tLoss: 0.038518\n",
      "Train Epoch: 10 [3200/10061 (32%)]\tLoss: 0.106030\n",
      "Train Epoch: 10 [3840/10061 (38%)]\tLoss: 0.034837\n",
      "Train Epoch: 10 [4480/10061 (44%)]\tLoss: 0.031324\n",
      "Train Epoch: 10 [5120/10061 (51%)]\tLoss: 0.025464\n",
      "Train Epoch: 10 [5760/10061 (57%)]\tLoss: 0.055393\n",
      "Train Epoch: 10 [6400/10061 (63%)]\tLoss: 0.008483\n",
      "Train Epoch: 10 [7040/10061 (70%)]\tLoss: 0.016429\n",
      "Train Epoch: 10 [7680/10061 (76%)]\tLoss: 0.001520\n",
      "Train Epoch: 10 [8320/10061 (82%)]\tLoss: 0.058997\n",
      "Train Epoch: 10 [8960/10061 (89%)]\tLoss: 0.006735\n",
      "Train Epoch: 10 [9600/10061 (95%)]\tLoss: 0.030612\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/3910 (0%)]\tLoss: 0.108508\n",
      "Train Epoch: 1 [640/3910 (16%)]\tLoss: 0.078452\n",
      "Train Epoch: 1 [1280/3910 (32%)]\tLoss: 0.122867\n",
      "Train Epoch: 1 [1920/3910 (48%)]\tLoss: 0.011909\n",
      "Train Epoch: 1 [2560/3910 (65%)]\tLoss: 0.034764\n",
      "Train Epoch: 1 [3200/3910 (81%)]\tLoss: 0.025702\n",
      "Train Epoch: 1 [3840/3910 (97%)]\tLoss: 0.053875\n",
      "Train Epoch: 2 [0/3910 (0%)]\tLoss: 0.132179\n",
      "Train Epoch: 2 [640/3910 (16%)]\tLoss: 0.029996\n",
      "Train Epoch: 2 [1280/3910 (32%)]\tLoss: 0.013187\n",
      "Train Epoch: 2 [1920/3910 (48%)]\tLoss: 0.041472\n",
      "Train Epoch: 2 [2560/3910 (65%)]\tLoss: 0.068290\n",
      "Train Epoch: 2 [3200/3910 (81%)]\tLoss: 0.078634\n",
      "Train Epoch: 2 [3840/3910 (97%)]\tLoss: 0.012551\n",
      "Train Epoch: 3 [0/3910 (0%)]\tLoss: 0.058984\n",
      "Train Epoch: 3 [640/3910 (16%)]\tLoss: 0.092453\n",
      "Train Epoch: 3 [1280/3910 (32%)]\tLoss: 0.050849\n",
      "Train Epoch: 3 [1920/3910 (48%)]\tLoss: 0.060043\n",
      "Train Epoch: 3 [2560/3910 (65%)]\tLoss: 0.004977\n",
      "Train Epoch: 3 [3200/3910 (81%)]\tLoss: 0.145646\n",
      "Train Epoch: 3 [3840/3910 (97%)]\tLoss: 0.030706\n",
      "Train Epoch: 4 [0/3910 (0%)]\tLoss: 0.040135\n",
      "Train Epoch: 4 [640/3910 (16%)]\tLoss: 0.077837\n",
      "Train Epoch: 4 [1280/3910 (32%)]\tLoss: 0.013403\n",
      "Train Epoch: 4 [1920/3910 (48%)]\tLoss: 0.014446\n",
      "Train Epoch: 4 [2560/3910 (65%)]\tLoss: 0.007425\n",
      "Train Epoch: 4 [3200/3910 (81%)]\tLoss: 0.053306\n",
      "Train Epoch: 4 [3840/3910 (97%)]\tLoss: 0.043861\n",
      "Train Epoch: 5 [0/3910 (0%)]\tLoss: 0.011749\n",
      "Train Epoch: 5 [640/3910 (16%)]\tLoss: 0.005089\n",
      "Train Epoch: 5 [1280/3910 (32%)]\tLoss: 0.030485\n",
      "Train Epoch: 5 [1920/3910 (48%)]\tLoss: 0.041807\n",
      "Train Epoch: 5 [2560/3910 (65%)]\tLoss: 0.020686\n",
      "Train Epoch: 5 [3200/3910 (81%)]\tLoss: 0.009596\n",
      "Train Epoch: 5 [3840/3910 (97%)]\tLoss: 0.005457\n",
      "Train Epoch: 6 [0/3910 (0%)]\tLoss: 0.087969\n",
      "Train Epoch: 6 [640/3910 (16%)]\tLoss: 0.020330\n",
      "Train Epoch: 6 [1280/3910 (32%)]\tLoss: 0.027228\n",
      "Train Epoch: 6 [1920/3910 (48%)]\tLoss: 0.110387\n",
      "Train Epoch: 6 [2560/3910 (65%)]\tLoss: 0.033857\n",
      "Train Epoch: 6 [3200/3910 (81%)]\tLoss: 0.016705\n",
      "Train Epoch: 6 [3840/3910 (97%)]\tLoss: 0.051458\n",
      "Train Epoch: 7 [0/3910 (0%)]\tLoss: 0.016516\n",
      "Train Epoch: 7 [640/3910 (16%)]\tLoss: 0.135933\n",
      "Train Epoch: 7 [1280/3910 (32%)]\tLoss: 0.088711\n",
      "Train Epoch: 7 [1920/3910 (48%)]\tLoss: 0.026037\n",
      "Train Epoch: 7 [2560/3910 (65%)]\tLoss: 0.018562\n",
      "Train Epoch: 7 [3200/3910 (81%)]\tLoss: 0.010855\n",
      "Train Epoch: 7 [3840/3910 (97%)]\tLoss: 0.012692\n",
      "Train Epoch: 8 [0/3910 (0%)]\tLoss: 0.014561\n",
      "Train Epoch: 8 [640/3910 (16%)]\tLoss: 0.047098\n",
      "Train Epoch: 8 [1280/3910 (32%)]\tLoss: 0.086388\n",
      "Train Epoch: 8 [1920/3910 (48%)]\tLoss: 0.231399\n",
      "Train Epoch: 8 [2560/3910 (65%)]\tLoss: 0.047906\n",
      "Train Epoch: 8 [3200/3910 (81%)]\tLoss: 0.006264\n",
      "Train Epoch: 8 [3840/3910 (97%)]\tLoss: 0.006141\n",
      "Train Epoch: 9 [0/3910 (0%)]\tLoss: 0.038777\n",
      "Train Epoch: 9 [640/3910 (16%)]\tLoss: 0.047974\n",
      "Train Epoch: 9 [1280/3910 (32%)]\tLoss: 0.012071\n",
      "Train Epoch: 9 [1920/3910 (48%)]\tLoss: 0.028963\n",
      "Train Epoch: 9 [2560/3910 (65%)]\tLoss: 0.091681\n",
      "Train Epoch: 9 [3200/3910 (81%)]\tLoss: 0.051596\n",
      "Train Epoch: 9 [3840/3910 (97%)]\tLoss: 0.068953\n",
      "Train Epoch: 10 [0/3910 (0%)]\tLoss: 0.050243\n",
      "Train Epoch: 10 [640/3910 (16%)]\tLoss: 0.068780\n",
      "Train Epoch: 10 [1280/3910 (32%)]\tLoss: 0.096824\n",
      "Train Epoch: 10 [1920/3910 (48%)]\tLoss: 0.008995\n",
      "Train Epoch: 10 [2560/3910 (65%)]\tLoss: 0.135151\n",
      "Train Epoch: 10 [3200/3910 (81%)]\tLoss: 0.004550\n",
      "Train Epoch: 10 [3840/3910 (97%)]\tLoss: 0.052541\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/7269 (0%)]\tLoss: 0.126968\n",
      "Train Epoch: 1 [640/7269 (9%)]\tLoss: 0.129213\n",
      "Train Epoch: 1 [1280/7269 (18%)]\tLoss: 0.024769\n",
      "Train Epoch: 1 [1920/7269 (26%)]\tLoss: 0.273373\n",
      "Train Epoch: 1 [2560/7269 (35%)]\tLoss: 0.020748\n",
      "Train Epoch: 1 [3200/7269 (44%)]\tLoss: 0.057875\n",
      "Train Epoch: 1 [3840/7269 (53%)]\tLoss: 0.041444\n",
      "Train Epoch: 1 [4480/7269 (61%)]\tLoss: 0.013140\n",
      "Train Epoch: 1 [5120/7269 (70%)]\tLoss: 0.015596\n",
      "Train Epoch: 1 [5760/7269 (79%)]\tLoss: 0.006135\n",
      "Train Epoch: 1 [6400/7269 (88%)]\tLoss: 0.030817\n",
      "Train Epoch: 1 [7040/7269 (96%)]\tLoss: 0.047861\n",
      "Train Epoch: 2 [0/7269 (0%)]\tLoss: 0.042386\n",
      "Train Epoch: 2 [640/7269 (9%)]\tLoss: 0.013828\n",
      "Train Epoch: 2 [1280/7269 (18%)]\tLoss: 0.102206\n",
      "Train Epoch: 2 [1920/7269 (26%)]\tLoss: 0.009206\n",
      "Train Epoch: 2 [2560/7269 (35%)]\tLoss: 0.022179\n",
      "Train Epoch: 2 [3200/7269 (44%)]\tLoss: 0.004500\n",
      "Train Epoch: 2 [3840/7269 (53%)]\tLoss: 0.000580\n",
      "Train Epoch: 2 [4480/7269 (61%)]\tLoss: 0.006084\n",
      "Train Epoch: 2 [5120/7269 (70%)]\tLoss: 0.011469\n",
      "Train Epoch: 2 [5760/7269 (79%)]\tLoss: 0.127344\n",
      "Train Epoch: 2 [6400/7269 (88%)]\tLoss: 0.012817\n",
      "Train Epoch: 2 [7040/7269 (96%)]\tLoss: 0.109153\n",
      "Train Epoch: 3 [0/7269 (0%)]\tLoss: 0.007381\n",
      "Train Epoch: 3 [640/7269 (9%)]\tLoss: 0.061649\n",
      "Train Epoch: 3 [1280/7269 (18%)]\tLoss: 0.055678\n",
      "Train Epoch: 3 [1920/7269 (26%)]\tLoss: 0.011120\n",
      "Train Epoch: 3 [2560/7269 (35%)]\tLoss: 0.006877\n",
      "Train Epoch: 3 [3200/7269 (44%)]\tLoss: 0.011295\n",
      "Train Epoch: 3 [3840/7269 (53%)]\tLoss: 0.006592\n",
      "Train Epoch: 3 [4480/7269 (61%)]\tLoss: 0.019047\n",
      "Train Epoch: 3 [5120/7269 (70%)]\tLoss: 0.039804\n",
      "Train Epoch: 3 [5760/7269 (79%)]\tLoss: 0.003922\n",
      "Train Epoch: 3 [6400/7269 (88%)]\tLoss: 0.036098\n",
      "Train Epoch: 3 [7040/7269 (96%)]\tLoss: 0.035844\n",
      "Train Epoch: 4 [0/7269 (0%)]\tLoss: 0.014856\n",
      "Train Epoch: 4 [640/7269 (9%)]\tLoss: 0.026209\n",
      "Train Epoch: 4 [1280/7269 (18%)]\tLoss: 0.008643\n",
      "Train Epoch: 4 [1920/7269 (26%)]\tLoss: 0.033707\n",
      "Train Epoch: 4 [2560/7269 (35%)]\tLoss: 0.014613\n",
      "Train Epoch: 4 [3200/7269 (44%)]\tLoss: 0.070128\n",
      "Train Epoch: 4 [3840/7269 (53%)]\tLoss: 0.007864\n",
      "Train Epoch: 4 [4480/7269 (61%)]\tLoss: 0.088183\n",
      "Train Epoch: 4 [5120/7269 (70%)]\tLoss: 0.028955\n",
      "Train Epoch: 4 [5760/7269 (79%)]\tLoss: 0.008931\n",
      "Train Epoch: 4 [6400/7269 (88%)]\tLoss: 0.126610\n",
      "Train Epoch: 4 [7040/7269 (96%)]\tLoss: 0.064190\n",
      "Train Epoch: 5 [0/7269 (0%)]\tLoss: 0.021660\n",
      "Train Epoch: 5 [640/7269 (9%)]\tLoss: 0.002145\n",
      "Train Epoch: 5 [1280/7269 (18%)]\tLoss: 0.067757\n",
      "Train Epoch: 5 [1920/7269 (26%)]\tLoss: 0.020479\n",
      "Train Epoch: 5 [2560/7269 (35%)]\tLoss: 0.016798\n",
      "Train Epoch: 5 [3200/7269 (44%)]\tLoss: 0.040279\n",
      "Train Epoch: 5 [3840/7269 (53%)]\tLoss: 0.001339\n",
      "Train Epoch: 5 [4480/7269 (61%)]\tLoss: 0.019302\n",
      "Train Epoch: 5 [5120/7269 (70%)]\tLoss: 0.021988\n",
      "Train Epoch: 5 [5760/7269 (79%)]\tLoss: 0.032704\n",
      "Train Epoch: 5 [6400/7269 (88%)]\tLoss: 0.021224\n",
      "Train Epoch: 5 [7040/7269 (96%)]\tLoss: 0.003222\n",
      "Train Epoch: 6 [0/7269 (0%)]\tLoss: 0.028320\n",
      "Train Epoch: 6 [640/7269 (9%)]\tLoss: 0.001105\n",
      "Train Epoch: 6 [1280/7269 (18%)]\tLoss: 0.002434\n",
      "Train Epoch: 6 [1920/7269 (26%)]\tLoss: 0.026858\n",
      "Train Epoch: 6 [2560/7269 (35%)]\tLoss: 0.009594\n",
      "Train Epoch: 6 [3200/7269 (44%)]\tLoss: 0.002896\n",
      "Train Epoch: 6 [3840/7269 (53%)]\tLoss: 0.001855\n",
      "Train Epoch: 6 [4480/7269 (61%)]\tLoss: 0.008875\n",
      "Train Epoch: 6 [5120/7269 (70%)]\tLoss: 0.144507\n",
      "Train Epoch: 6 [5760/7269 (79%)]\tLoss: 0.057045\n",
      "Train Epoch: 6 [6400/7269 (88%)]\tLoss: 0.195714\n",
      "Train Epoch: 6 [7040/7269 (96%)]\tLoss: 0.020277\n",
      "Train Epoch: 7 [0/7269 (0%)]\tLoss: 0.048004\n",
      "Train Epoch: 7 [640/7269 (9%)]\tLoss: 0.003748\n",
      "Train Epoch: 7 [1280/7269 (18%)]\tLoss: 0.020051\n",
      "Train Epoch: 7 [1920/7269 (26%)]\tLoss: 0.018592\n",
      "Train Epoch: 7 [2560/7269 (35%)]\tLoss: 0.020717\n",
      "Train Epoch: 7 [3200/7269 (44%)]\tLoss: 0.002894\n",
      "Train Epoch: 7 [3840/7269 (53%)]\tLoss: 0.009595\n",
      "Train Epoch: 7 [4480/7269 (61%)]\tLoss: 0.008376\n",
      "Train Epoch: 7 [5120/7269 (70%)]\tLoss: 0.016468\n",
      "Train Epoch: 7 [5760/7269 (79%)]\tLoss: 0.001990\n",
      "Train Epoch: 7 [6400/7269 (88%)]\tLoss: 0.154250\n",
      "Train Epoch: 7 [7040/7269 (96%)]\tLoss: 0.074269\n",
      "Train Epoch: 8 [0/7269 (0%)]\tLoss: 0.001233\n",
      "Train Epoch: 8 [640/7269 (9%)]\tLoss: 0.010624\n",
      "Train Epoch: 8 [1280/7269 (18%)]\tLoss: 0.016445\n",
      "Train Epoch: 8 [1920/7269 (26%)]\tLoss: 0.007955\n",
      "Train Epoch: 8 [2560/7269 (35%)]\tLoss: 0.045389\n",
      "Train Epoch: 8 [3200/7269 (44%)]\tLoss: 0.000467\n",
      "Train Epoch: 8 [3840/7269 (53%)]\tLoss: 0.107934\n",
      "Train Epoch: 8 [4480/7269 (61%)]\tLoss: 0.075811\n",
      "Train Epoch: 8 [5120/7269 (70%)]\tLoss: 0.010939\n",
      "Train Epoch: 8 [5760/7269 (79%)]\tLoss: 0.034314\n",
      "Train Epoch: 8 [6400/7269 (88%)]\tLoss: 0.001635\n",
      "Train Epoch: 8 [7040/7269 (96%)]\tLoss: 0.004211\n",
      "Train Epoch: 9 [0/7269 (0%)]\tLoss: 0.004533\n",
      "Train Epoch: 9 [640/7269 (9%)]\tLoss: 0.009034\n",
      "Train Epoch: 9 [1280/7269 (18%)]\tLoss: 0.011463\n",
      "Train Epoch: 9 [1920/7269 (26%)]\tLoss: 0.055525\n",
      "Train Epoch: 9 [2560/7269 (35%)]\tLoss: 0.012622\n",
      "Train Epoch: 9 [3200/7269 (44%)]\tLoss: 0.005083\n",
      "Train Epoch: 9 [3840/7269 (53%)]\tLoss: 0.004167\n",
      "Train Epoch: 9 [4480/7269 (61%)]\tLoss: 0.002013\n",
      "Train Epoch: 9 [5120/7269 (70%)]\tLoss: 0.035965\n",
      "Train Epoch: 9 [5760/7269 (79%)]\tLoss: 0.000122\n",
      "Train Epoch: 9 [6400/7269 (88%)]\tLoss: 0.005740\n",
      "Train Epoch: 9 [7040/7269 (96%)]\tLoss: 0.039794\n",
      "Train Epoch: 10 [0/7269 (0%)]\tLoss: 0.006756\n",
      "Train Epoch: 10 [640/7269 (9%)]\tLoss: 0.008871\n",
      "Train Epoch: 10 [1280/7269 (18%)]\tLoss: 0.002671\n",
      "Train Epoch: 10 [1920/7269 (26%)]\tLoss: 0.038470\n",
      "Train Epoch: 10 [2560/7269 (35%)]\tLoss: 0.037267\n",
      "Train Epoch: 10 [3200/7269 (44%)]\tLoss: 0.056215\n",
      "Train Epoch: 10 [3840/7269 (53%)]\tLoss: 0.004392\n",
      "Train Epoch: 10 [4480/7269 (61%)]\tLoss: 0.018652\n",
      "Train Epoch: 10 [5120/7269 (70%)]\tLoss: 0.001069\n",
      "Train Epoch: 10 [5760/7269 (79%)]\tLoss: 0.002550\n",
      "Train Epoch: 10 [6400/7269 (88%)]\tLoss: 0.012397\n",
      "Train Epoch: 10 [7040/7269 (96%)]\tLoss: 0.014307\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/5096 (0%)]\tLoss: 0.077586\n",
      "Train Epoch: 1 [640/5096 (12%)]\tLoss: 0.029077\n",
      "Train Epoch: 1 [1280/5096 (25%)]\tLoss: 0.008518\n",
      "Train Epoch: 1 [1920/5096 (38%)]\tLoss: 0.001093\n",
      "Train Epoch: 1 [2560/5096 (50%)]\tLoss: 0.034739\n",
      "Train Epoch: 1 [3200/5096 (62%)]\tLoss: 0.162678\n",
      "Train Epoch: 1 [3840/5096 (75%)]\tLoss: 0.014371\n",
      "Train Epoch: 1 [4480/5096 (88%)]\tLoss: 0.039313\n",
      "Train Epoch: 2 [0/5096 (0%)]\tLoss: 0.001969\n",
      "Train Epoch: 2 [640/5096 (12%)]\tLoss: 0.043743\n",
      "Train Epoch: 2 [1280/5096 (25%)]\tLoss: 0.042655\n",
      "Train Epoch: 2 [1920/5096 (38%)]\tLoss: 0.124973\n",
      "Train Epoch: 2 [2560/5096 (50%)]\tLoss: 0.012948\n",
      "Train Epoch: 2 [3200/5096 (62%)]\tLoss: 0.030973\n",
      "Train Epoch: 2 [3840/5096 (75%)]\tLoss: 0.019982\n",
      "Train Epoch: 2 [4480/5096 (88%)]\tLoss: 0.054967\n",
      "Train Epoch: 3 [0/5096 (0%)]\tLoss: 0.061834\n",
      "Train Epoch: 3 [640/5096 (12%)]\tLoss: 0.003504\n",
      "Train Epoch: 3 [1280/5096 (25%)]\tLoss: 0.007159\n",
      "Train Epoch: 3 [1920/5096 (38%)]\tLoss: 0.027706\n",
      "Train Epoch: 3 [2560/5096 (50%)]\tLoss: 0.001379\n",
      "Train Epoch: 3 [3200/5096 (62%)]\tLoss: 0.044779\n",
      "Train Epoch: 3 [3840/5096 (75%)]\tLoss: 0.019466\n",
      "Train Epoch: 3 [4480/5096 (88%)]\tLoss: 0.043366\n",
      "Train Epoch: 4 [0/5096 (0%)]\tLoss: 0.001727\n",
      "Train Epoch: 4 [640/5096 (12%)]\tLoss: 0.006865\n",
      "Train Epoch: 4 [1280/5096 (25%)]\tLoss: 0.031950\n",
      "Train Epoch: 4 [1920/5096 (38%)]\tLoss: 0.054581\n",
      "Train Epoch: 4 [2560/5096 (50%)]\tLoss: 0.045541\n",
      "Train Epoch: 4 [3200/5096 (62%)]\tLoss: 0.031919\n",
      "Train Epoch: 4 [3840/5096 (75%)]\tLoss: 0.005568\n",
      "Train Epoch: 4 [4480/5096 (88%)]\tLoss: 0.044115\n",
      "Train Epoch: 5 [0/5096 (0%)]\tLoss: 0.033463\n",
      "Train Epoch: 5 [640/5096 (12%)]\tLoss: 0.059539\n",
      "Train Epoch: 5 [1280/5096 (25%)]\tLoss: 0.004892\n",
      "Train Epoch: 5 [1920/5096 (38%)]\tLoss: 0.056581\n",
      "Train Epoch: 5 [2560/5096 (50%)]\tLoss: 0.200157\n",
      "Train Epoch: 5 [3200/5096 (62%)]\tLoss: 0.033542\n",
      "Train Epoch: 5 [3840/5096 (75%)]\tLoss: 0.004328\n",
      "Train Epoch: 5 [4480/5096 (88%)]\tLoss: 0.005445\n",
      "Train Epoch: 6 [0/5096 (0%)]\tLoss: 0.035398\n",
      "Train Epoch: 6 [640/5096 (12%)]\tLoss: 0.005516\n",
      "Train Epoch: 6 [1280/5096 (25%)]\tLoss: 0.039156\n",
      "Train Epoch: 6 [1920/5096 (38%)]\tLoss: 0.004767\n",
      "Train Epoch: 6 [2560/5096 (50%)]\tLoss: 0.011607\n",
      "Train Epoch: 6 [3200/5096 (62%)]\tLoss: 0.004694\n",
      "Train Epoch: 6 [3840/5096 (75%)]\tLoss: 0.059430\n",
      "Train Epoch: 6 [4480/5096 (88%)]\tLoss: 0.022688\n",
      "Train Epoch: 7 [0/5096 (0%)]\tLoss: 0.016610\n",
      "Train Epoch: 7 [640/5096 (12%)]\tLoss: 0.004877\n",
      "Train Epoch: 7 [1280/5096 (25%)]\tLoss: 0.050313\n",
      "Train Epoch: 7 [1920/5096 (38%)]\tLoss: 0.001356\n",
      "Train Epoch: 7 [2560/5096 (50%)]\tLoss: 0.008419\n",
      "Train Epoch: 7 [3200/5096 (62%)]\tLoss: 0.006611\n",
      "Train Epoch: 7 [3840/5096 (75%)]\tLoss: 0.042667\n",
      "Train Epoch: 7 [4480/5096 (88%)]\tLoss: 0.021085\n",
      "Train Epoch: 8 [0/5096 (0%)]\tLoss: 0.017927\n",
      "Train Epoch: 8 [640/5096 (12%)]\tLoss: 0.000397\n",
      "Train Epoch: 8 [1280/5096 (25%)]\tLoss: 0.024996\n",
      "Train Epoch: 8 [1920/5096 (38%)]\tLoss: 0.013064\n",
      "Train Epoch: 8 [2560/5096 (50%)]\tLoss: 0.071374\n",
      "Train Epoch: 8 [3200/5096 (62%)]\tLoss: 0.057729\n",
      "Train Epoch: 8 [3840/5096 (75%)]\tLoss: 0.024119\n",
      "Train Epoch: 8 [4480/5096 (88%)]\tLoss: 0.044198\n",
      "Train Epoch: 9 [0/5096 (0%)]\tLoss: 0.002577\n",
      "Train Epoch: 9 [640/5096 (12%)]\tLoss: 0.002413\n",
      "Train Epoch: 9 [1280/5096 (25%)]\tLoss: 0.034234\n",
      "Train Epoch: 9 [1920/5096 (38%)]\tLoss: 0.011093\n",
      "Train Epoch: 9 [2560/5096 (50%)]\tLoss: 0.004298\n",
      "Train Epoch: 9 [3200/5096 (62%)]\tLoss: 0.120241\n",
      "Train Epoch: 9 [3840/5096 (75%)]\tLoss: 0.065847\n",
      "Train Epoch: 9 [4480/5096 (88%)]\tLoss: 0.154752\n",
      "Train Epoch: 10 [0/5096 (0%)]\tLoss: 0.049404\n",
      "Train Epoch: 10 [640/5096 (12%)]\tLoss: 0.013905\n",
      "Train Epoch: 10 [1280/5096 (25%)]\tLoss: 0.006760\n",
      "Train Epoch: 10 [1920/5096 (38%)]\tLoss: 0.008862\n",
      "Train Epoch: 10 [2560/5096 (50%)]\tLoss: 0.006244\n",
      "Train Epoch: 10 [3200/5096 (62%)]\tLoss: 0.004880\n",
      "Train Epoch: 10 [3840/5096 (75%)]\tLoss: 0.025860\n",
      "Train Epoch: 10 [4480/5096 (88%)]\tLoss: 0.084398\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/1599 (0%)]\tLoss: 0.022881\n",
      "Train Epoch: 1 [640/1599 (40%)]\tLoss: 0.025314\n",
      "Train Epoch: 1 [1280/1599 (80%)]\tLoss: 0.057229\n",
      "Train Epoch: 2 [0/1599 (0%)]\tLoss: 0.037583\n",
      "Train Epoch: 2 [640/1599 (40%)]\tLoss: 0.004604\n",
      "Train Epoch: 2 [1280/1599 (80%)]\tLoss: 0.028746\n",
      "Train Epoch: 3 [0/1599 (0%)]\tLoss: 0.010388\n",
      "Train Epoch: 3 [640/1599 (40%)]\tLoss: 0.024109\n",
      "Train Epoch: 3 [1280/1599 (80%)]\tLoss: 0.042498\n",
      "Train Epoch: 4 [0/1599 (0%)]\tLoss: 0.057426\n",
      "Train Epoch: 4 [640/1599 (40%)]\tLoss: 0.145705\n",
      "Train Epoch: 4 [1280/1599 (80%)]\tLoss: 0.010246\n",
      "Train Epoch: 5 [0/1599 (0%)]\tLoss: 0.003644\n",
      "Train Epoch: 5 [640/1599 (40%)]\tLoss: 0.031537\n",
      "Train Epoch: 5 [1280/1599 (80%)]\tLoss: 0.006228\n",
      "Train Epoch: 6 [0/1599 (0%)]\tLoss: 0.031644\n",
      "Train Epoch: 6 [640/1599 (40%)]\tLoss: 0.043123\n",
      "Train Epoch: 6 [1280/1599 (80%)]\tLoss: 0.037740\n",
      "Train Epoch: 7 [0/1599 (0%)]\tLoss: 0.003073\n",
      "Train Epoch: 7 [640/1599 (40%)]\tLoss: 0.042981\n",
      "Train Epoch: 7 [1280/1599 (80%)]\tLoss: 0.018098\n",
      "Train Epoch: 8 [0/1599 (0%)]\tLoss: 0.053206\n",
      "Train Epoch: 8 [640/1599 (40%)]\tLoss: 0.012044\n",
      "Train Epoch: 8 [1280/1599 (80%)]\tLoss: 0.065601\n",
      "Train Epoch: 9 [0/1599 (0%)]\tLoss: 0.008644\n",
      "Train Epoch: 9 [640/1599 (40%)]\tLoss: 0.008803\n",
      "Train Epoch: 9 [1280/1599 (80%)]\tLoss: 0.003611\n",
      "Train Epoch: 10 [0/1599 (0%)]\tLoss: 0.014739\n",
      "Train Epoch: 10 [640/1599 (40%)]\tLoss: 0.036827\n",
      "Train Epoch: 10 [1280/1599 (80%)]\tLoss: 0.071480\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/5266 (0%)]\tLoss: 0.203911\n",
      "Train Epoch: 1 [640/5266 (12%)]\tLoss: 0.080054\n",
      "Train Epoch: 1 [1280/5266 (24%)]\tLoss: 0.003600\n",
      "Train Epoch: 1 [1920/5266 (36%)]\tLoss: 0.052697\n",
      "Train Epoch: 1 [2560/5266 (48%)]\tLoss: 0.013425\n",
      "Train Epoch: 1 [3200/5266 (60%)]\tLoss: 0.004301\n",
      "Train Epoch: 1 [3840/5266 (72%)]\tLoss: 0.026887\n",
      "Train Epoch: 1 [4480/5266 (84%)]\tLoss: 0.000707\n",
      "Train Epoch: 1 [5120/5266 (96%)]\tLoss: 0.016331\n",
      "Train Epoch: 2 [0/5266 (0%)]\tLoss: 0.049809\n",
      "Train Epoch: 2 [640/5266 (12%)]\tLoss: 0.012792\n",
      "Train Epoch: 2 [1280/5266 (24%)]\tLoss: 0.013169\n",
      "Train Epoch: 2 [1920/5266 (36%)]\tLoss: 0.006475\n",
      "Train Epoch: 2 [2560/5266 (48%)]\tLoss: 0.030141\n",
      "Train Epoch: 2 [3200/5266 (60%)]\tLoss: 0.014893\n",
      "Train Epoch: 2 [3840/5266 (72%)]\tLoss: 0.130833\n",
      "Train Epoch: 2 [4480/5266 (84%)]\tLoss: 0.057720\n",
      "Train Epoch: 2 [5120/5266 (96%)]\tLoss: 0.005336\n",
      "Train Epoch: 3 [0/5266 (0%)]\tLoss: 0.011205\n",
      "Train Epoch: 3 [640/5266 (12%)]\tLoss: 0.157801\n",
      "Train Epoch: 3 [1280/5266 (24%)]\tLoss: 0.045677\n",
      "Train Epoch: 3 [1920/5266 (36%)]\tLoss: 0.012667\n",
      "Train Epoch: 3 [2560/5266 (48%)]\tLoss: 0.007220\n",
      "Train Epoch: 3 [3200/5266 (60%)]\tLoss: 0.037561\n",
      "Train Epoch: 3 [3840/5266 (72%)]\tLoss: 0.017361\n",
      "Train Epoch: 3 [4480/5266 (84%)]\tLoss: 0.001300\n",
      "Train Epoch: 3 [5120/5266 (96%)]\tLoss: 0.003990\n",
      "Train Epoch: 4 [0/5266 (0%)]\tLoss: 0.020616\n",
      "Train Epoch: 4 [640/5266 (12%)]\tLoss: 0.026243\n",
      "Train Epoch: 4 [1280/5266 (24%)]\tLoss: 0.001519\n",
      "Train Epoch: 4 [1920/5266 (36%)]\tLoss: 0.042906\n",
      "Train Epoch: 4 [2560/5266 (48%)]\tLoss: 0.000889\n",
      "Train Epoch: 4 [3200/5266 (60%)]\tLoss: 0.002675\n",
      "Train Epoch: 4 [3840/5266 (72%)]\tLoss: 0.004782\n",
      "Train Epoch: 4 [4480/5266 (84%)]\tLoss: 0.001051\n",
      "Train Epoch: 4 [5120/5266 (96%)]\tLoss: 0.010522\n",
      "Train Epoch: 5 [0/5266 (0%)]\tLoss: 0.035080\n",
      "Train Epoch: 5 [640/5266 (12%)]\tLoss: 0.004636\n",
      "Train Epoch: 5 [1280/5266 (24%)]\tLoss: 0.123196\n",
      "Train Epoch: 5 [1920/5266 (36%)]\tLoss: 0.016666\n",
      "Train Epoch: 5 [2560/5266 (48%)]\tLoss: 0.008215\n",
      "Train Epoch: 5 [3200/5266 (60%)]\tLoss: 0.093653\n",
      "Train Epoch: 5 [3840/5266 (72%)]\tLoss: 0.004340\n",
      "Train Epoch: 5 [4480/5266 (84%)]\tLoss: 0.049906\n",
      "Train Epoch: 5 [5120/5266 (96%)]\tLoss: 0.028185\n",
      "Train Epoch: 6 [0/5266 (0%)]\tLoss: 0.021541\n",
      "Train Epoch: 6 [640/5266 (12%)]\tLoss: 0.038962\n",
      "Train Epoch: 6 [1280/5266 (24%)]\tLoss: 0.003179\n",
      "Train Epoch: 6 [1920/5266 (36%)]\tLoss: 0.101201\n",
      "Train Epoch: 6 [2560/5266 (48%)]\tLoss: 0.045901\n",
      "Train Epoch: 6 [3200/5266 (60%)]\tLoss: 0.002250\n",
      "Train Epoch: 6 [3840/5266 (72%)]\tLoss: 0.029009\n",
      "Train Epoch: 6 [4480/5266 (84%)]\tLoss: 0.007964\n",
      "Train Epoch: 6 [5120/5266 (96%)]\tLoss: 0.010872\n",
      "Train Epoch: 7 [0/5266 (0%)]\tLoss: 0.000913\n",
      "Train Epoch: 7 [640/5266 (12%)]\tLoss: 0.070866\n",
      "Train Epoch: 7 [1280/5266 (24%)]\tLoss: 0.009560\n",
      "Train Epoch: 7 [1920/5266 (36%)]\tLoss: 0.001348\n",
      "Train Epoch: 7 [2560/5266 (48%)]\tLoss: 0.000455\n",
      "Train Epoch: 7 [3200/5266 (60%)]\tLoss: 0.128844\n",
      "Train Epoch: 7 [3840/5266 (72%)]\tLoss: 0.009082\n",
      "Train Epoch: 7 [4480/5266 (84%)]\tLoss: 0.030220\n",
      "Train Epoch: 7 [5120/5266 (96%)]\tLoss: 0.008975\n",
      "Train Epoch: 8 [0/5266 (0%)]\tLoss: 0.002627\n",
      "Train Epoch: 8 [640/5266 (12%)]\tLoss: 0.004367\n",
      "Train Epoch: 8 [1280/5266 (24%)]\tLoss: 0.072367\n",
      "Train Epoch: 8 [1920/5266 (36%)]\tLoss: 0.050510\n",
      "Train Epoch: 8 [2560/5266 (48%)]\tLoss: 0.002304\n",
      "Train Epoch: 8 [3200/5266 (60%)]\tLoss: 0.002870\n",
      "Train Epoch: 8 [3840/5266 (72%)]\tLoss: 0.017518\n",
      "Train Epoch: 8 [4480/5266 (84%)]\tLoss: 0.001424\n",
      "Train Epoch: 8 [5120/5266 (96%)]\tLoss: 0.144162\n",
      "Train Epoch: 9 [0/5266 (0%)]\tLoss: 0.005305\n",
      "Train Epoch: 9 [640/5266 (12%)]\tLoss: 0.006245\n",
      "Train Epoch: 9 [1280/5266 (24%)]\tLoss: 0.033285\n",
      "Train Epoch: 9 [1920/5266 (36%)]\tLoss: 0.001990\n",
      "Train Epoch: 9 [2560/5266 (48%)]\tLoss: 0.000484\n",
      "Train Epoch: 9 [3200/5266 (60%)]\tLoss: 0.160797\n",
      "Train Epoch: 9 [3840/5266 (72%)]\tLoss: 0.067092\n",
      "Train Epoch: 9 [4480/5266 (84%)]\tLoss: 0.030610\n",
      "Train Epoch: 9 [5120/5266 (96%)]\tLoss: 0.001356\n",
      "Train Epoch: 10 [0/5266 (0%)]\tLoss: 0.003230\n",
      "Train Epoch: 10 [640/5266 (12%)]\tLoss: 0.006616\n",
      "Train Epoch: 10 [1280/5266 (24%)]\tLoss: 0.026062\n",
      "Train Epoch: 10 [1920/5266 (36%)]\tLoss: 0.004225\n",
      "Train Epoch: 10 [2560/5266 (48%)]\tLoss: 0.008158\n",
      "Train Epoch: 10 [3200/5266 (60%)]\tLoss: 0.006666\n",
      "Train Epoch: 10 [3840/5266 (72%)]\tLoss: 0.054623\n",
      "Train Epoch: 10 [4480/5266 (84%)]\tLoss: 0.006178\n",
      "Train Epoch: 10 [5120/5266 (96%)]\tLoss: 0.079295\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/3530 (0%)]\tLoss: 0.042738\n",
      "Train Epoch: 1 [640/3530 (18%)]\tLoss: 0.033509\n",
      "Train Epoch: 1 [1280/3530 (36%)]\tLoss: 0.078945\n",
      "Train Epoch: 1 [1920/3530 (54%)]\tLoss: 0.128324\n",
      "Train Epoch: 1 [2560/3530 (71%)]\tLoss: 0.017368\n",
      "Train Epoch: 1 [3200/3530 (89%)]\tLoss: 0.019848\n",
      "Train Epoch: 2 [0/3530 (0%)]\tLoss: 0.118186\n",
      "Train Epoch: 2 [640/3530 (18%)]\tLoss: 0.030462\n",
      "Train Epoch: 2 [1280/3530 (36%)]\tLoss: 0.040519\n",
      "Train Epoch: 2 [1920/3530 (54%)]\tLoss: 0.032079\n",
      "Train Epoch: 2 [2560/3530 (71%)]\tLoss: 0.290844\n",
      "Train Epoch: 2 [3200/3530 (89%)]\tLoss: 0.012381\n",
      "Train Epoch: 3 [0/3530 (0%)]\tLoss: 0.011419\n",
      "Train Epoch: 3 [640/3530 (18%)]\tLoss: 0.029155\n",
      "Train Epoch: 3 [1280/3530 (36%)]\tLoss: 0.073731\n",
      "Train Epoch: 3 [1920/3530 (54%)]\tLoss: 0.035234\n",
      "Train Epoch: 3 [2560/3530 (71%)]\tLoss: 0.041282\n",
      "Train Epoch: 3 [3200/3530 (89%)]\tLoss: 0.018953\n",
      "Train Epoch: 4 [0/3530 (0%)]\tLoss: 0.028427\n",
      "Train Epoch: 4 [640/3530 (18%)]\tLoss: 0.067236\n",
      "Train Epoch: 4 [1280/3530 (36%)]\tLoss: 0.092698\n",
      "Train Epoch: 4 [1920/3530 (54%)]\tLoss: 0.059707\n",
      "Train Epoch: 4 [2560/3530 (71%)]\tLoss: 0.005829\n",
      "Train Epoch: 4 [3200/3530 (89%)]\tLoss: 0.007480\n",
      "Train Epoch: 5 [0/3530 (0%)]\tLoss: 0.033690\n",
      "Train Epoch: 5 [640/3530 (18%)]\tLoss: 0.018320\n",
      "Train Epoch: 5 [1280/3530 (36%)]\tLoss: 0.004549\n",
      "Train Epoch: 5 [1920/3530 (54%)]\tLoss: 0.178499\n",
      "Train Epoch: 5 [2560/3530 (71%)]\tLoss: 0.014540\n",
      "Train Epoch: 5 [3200/3530 (89%)]\tLoss: 0.002115\n",
      "Train Epoch: 6 [0/3530 (0%)]\tLoss: 0.043708\n",
      "Train Epoch: 6 [640/3530 (18%)]\tLoss: 0.200105\n",
      "Train Epoch: 6 [1280/3530 (36%)]\tLoss: 0.063239\n",
      "Train Epoch: 6 [1920/3530 (54%)]\tLoss: 0.042994\n",
      "Train Epoch: 6 [2560/3530 (71%)]\tLoss: 0.039761\n",
      "Train Epoch: 6 [3200/3530 (89%)]\tLoss: 0.041356\n",
      "Train Epoch: 7 [0/3530 (0%)]\tLoss: 0.077431\n",
      "Train Epoch: 7 [640/3530 (18%)]\tLoss: 0.005064\n",
      "Train Epoch: 7 [1280/3530 (36%)]\tLoss: 0.024409\n",
      "Train Epoch: 7 [1920/3530 (54%)]\tLoss: 0.029403\n",
      "Train Epoch: 7 [2560/3530 (71%)]\tLoss: 0.118924\n",
      "Train Epoch: 7 [3200/3530 (89%)]\tLoss: 0.012087\n",
      "Train Epoch: 8 [0/3530 (0%)]\tLoss: 0.132060\n",
      "Train Epoch: 8 [640/3530 (18%)]\tLoss: 0.067009\n",
      "Train Epoch: 8 [1280/3530 (36%)]\tLoss: 0.061932\n",
      "Train Epoch: 8 [1920/3530 (54%)]\tLoss: 0.011482\n",
      "Train Epoch: 8 [2560/3530 (71%)]\tLoss: 0.012078\n",
      "Train Epoch: 8 [3200/3530 (89%)]\tLoss: 0.011021\n",
      "Train Epoch: 9 [0/3530 (0%)]\tLoss: 0.065432\n",
      "Train Epoch: 9 [640/3530 (18%)]\tLoss: 0.082391\n",
      "Train Epoch: 9 [1280/3530 (36%)]\tLoss: 0.021429\n",
      "Train Epoch: 9 [1920/3530 (54%)]\tLoss: 0.082477\n",
      "Train Epoch: 9 [2560/3530 (71%)]\tLoss: 0.052654\n",
      "Train Epoch: 9 [3200/3530 (89%)]\tLoss: 0.035067\n",
      "Train Epoch: 10 [0/3530 (0%)]\tLoss: 0.068972\n",
      "Train Epoch: 10 [640/3530 (18%)]\tLoss: 0.158155\n",
      "Train Epoch: 10 [1280/3530 (36%)]\tLoss: 0.014401\n",
      "Train Epoch: 10 [1920/3530 (54%)]\tLoss: 0.055000\n",
      "Train Epoch: 10 [2560/3530 (71%)]\tLoss: 0.048742\n",
      "Train Epoch: 10 [3200/3530 (89%)]\tLoss: 0.048293\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "), classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [classification_model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")]\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.1253, Accuracy: 9892/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "partitioned_data_pca = partition.balanced_dirichlet_partition(trainingset_pca, partitions_number=num_clients, alpha=0.1)\n",
    "\n",
    "pca_client_loaders = []\n",
    "local_models_pca = [copy.deepcopy(global_model_pca) for _ in range(num_clients)]\n",
    "\n",
    "for client_idx, client_indices in partitioned_data_pca.items():\n",
    "    client_data = [trainingset_pca[i][0] for i in client_indices]  \n",
    "    client_labels = [trainingset_pca[i][1] for i in client_indices]  \n",
    "    \n",
    "    client_data = torch.stack(client_data, dim=0)\n",
    "    client_data = client_data.view(client_data.size(0), -1)  \n",
    "    \n",
    "    pca = PCADigitReducer(100)\n",
    "    client_data_reduced = pca.fit_transform(client_data.numpy())  \n",
    "    \n",
    "    client_data_reconstructed_np = pca.inverse_transform(client_data_reduced) \n",
    "    client_data_reconstructed = torch.tensor(client_data_reconstructed_np, dtype=torch.float32)\n",
    "    \n",
    "    client_data_reconstructed = client_data_reconstructed.view(-1, 1, 28, 28)\n",
    "    client_data_reconstructed = (client_data_reconstructed - 0.1307) / 0.3081  \n",
    "    \n",
    "    client_dataset_pca = CustomTensorDataset(client_data_reconstructed, torch.tensor(client_labels))\n",
    "    pca_client_loaders.append(DataLoader(client_dataset_pca, batch_size=batch_size_train, shuffle=True))\n",
    "\n",
    "\n",
    "\n",
    "rounds_pca = 4\n",
    "\n",
    "for round_idx in range(rounds_pca):\n",
    "    print(f\"Round {round_idx + 1}/{rounds_pca}\")\n",
    "    t1 = time.time()\n",
    "\n",
    "    local_weights_pca = []\n",
    "    for client_idx, client_model in enumerate(local_models_pca):\n",
    "        print(f\"Training client {client_idx + 1}\")\n",
    "        \n",
    "        optimizer = optim.SGD(client_model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "        train_losses = []\n",
    "        train_counter = []\n",
    "\n",
    "        for epoch in range(1, n_epochs + 1):  \n",
    "            train(epoch, client_model, pca_client_loaders[client_idx], optimizer, log_interval, train_losses, train_counter)\n",
    "        \n",
    "        client_weights = [param.data.numpy() for param in client_model.parameters()]\n",
    "        local_weights_pca.append(client_weights)\n",
    "        \n",
    "    global_weights_pca = federated_averaging(local_weights_pca)\n",
    "\n",
    "    distribute_global_model(global_weights_pca, local_models_pca, single=False)\n",
    "    distribute_global_model(global_weights_pca, global_model_pca, single=True)\n",
    "\n",
    "    test_losses = []\n",
    "    test(global_model_pca, test_loader_pca, test_losses)\n",
    "    t2 = time.time()\n",
    "    \n",
    "    test_accuracies_pca = []\n",
    "    correct = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader_pca:\n",
    "            output = global_model_pca(data)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            all_preds.extend(pred.cpu().numpy().flatten())\n",
    "            all_targets.extend(target.cpu().numpy().flatten())\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "    \n",
    "    accuracy = 100. * correct / len(test_loader_pca.dataset)\n",
    "    test_accuracies_pca.append(accuracy)\n",
    "    precision = precision_score(all_targets, all_preds, average='macro')\n",
    "    recall = recall_score(all_targets, all_preds, average='macro')\n",
    "    f1 = f1_score(all_targets, all_preds, average='macro')\n",
    "\n",
    "    results[\"pca\"][\"NoCluster\"] = {\"losses\": [], \"accuracy\": [], \"precision\": [], \"recall\": [], \"f1\": [], \"trainingTime\": []}\n",
    "\n",
    "    results[\"pca\"][\"NoCluster\"][\"losses\"].extend(test_losses)\n",
    "    results[\"pca\"][\"NoCluster\"][\"accuracy\"].extend(test_accuracies_pca)\n",
    "    results[\"pca\"][\"NoCluster\"][\"precision\"].append(precision)\n",
    "    results[\"pca\"][\"NoCluster\"][\"recall\"].append(recall)\n",
    "    results[\"pca\"][\"NoCluster\"][\"f1\"].append(f1)\n",
    "    results[\"pca\"][\"NoCluster\"][\"trainingTime\"].append(t2-t1)\n",
    "\n",
    "    ######################\n",
    "\n",
    "for num_cluster in num_clusters:\n",
    "    import cluster2\n",
    "\n",
    "    targets = trainingset.targets\n",
    "    num_classes = len(set(targets)) \n",
    "    clients = [cluster2.FederatedClient(cid, indices, targets, num_classes) for cid, indices in partitioned_data_pca.items()]\n",
    "    client_distributions = [client.compute_label_distribution() for client in clients]\n",
    "    server = cluster2.FederatedClusterServer(num_cluster)\n",
    "    aggregated_data = server.aggregate_client_data(client_distributions)\n",
    "    clustered_data = server.perform_greedy_clustering(aggregated_data, partitioned_data_pca)\n",
    "    \n",
    "    partitioned_data_pca_clustered = clustered_data\n",
    "    \"\"\"\n",
    "    import cluster\n",
    "\n",
    "    cluster = cluster.Cluster(num_clusters=num_cluster)\n",
    "    targets = trainingset_pca.targets\n",
    "    num_classes = len(set(targets))\n",
    "    clustered_data = cluster.apply_clustering(partitioned_data_pca, targets, num_classes)\n",
    "\n",
    "    partitioned_data_pca_clustered = clustered_data\n",
    "    \"\"\"\n",
    "    \n",
    "    pca_client_loaders_clustered = []\n",
    "\n",
    "    # Apply PCA after clustering\n",
    "    for client_idx, client_indices in partitioned_data_pca_clustered.items():\n",
    "        client_data = [trainingset_pca[i][0] for i in client_indices]  \n",
    "        client_labels = [trainingset_pca[i][1] for i in client_indices]  \n",
    "\n",
    "        client_data = torch.stack(client_data, dim=0)\n",
    "        client_data = client_data.view(client_data.size(0), -1)  \n",
    "        \n",
    "        pca = PCADigitReducer(100)\n",
    "        client_data_reduced = pca.fit_transform(client_data.numpy())  \n",
    "\n",
    "        client_data_reconstructed_np = pca.inverse_transform(client_data_reduced)  \n",
    "        client_data_reconstructed = torch.tensor(client_data_reconstructed_np, dtype=torch.float32)\n",
    "        \n",
    "        client_data_reconstructed = client_data_reconstructed.view(-1, 1, 28, 28)\n",
    "        client_data_reconstructed = (client_data_reconstructed - 0.1307) / 0.3081  \n",
    "\n",
    "        client_dataset_pca_clustered = CustomTensorDataset(client_data_reconstructed, torch.tensor(client_labels))\n",
    "        pca_client_loaders_clustered.append(DataLoader(client_dataset_pca_clustered, batch_size=batch_size_train, shuffle=True))\n",
    "\n",
    "    \n",
    "    for round_idx in range(rounds_pca):\n",
    "        print(f\"Round {round_idx + 1}/{rounds_pca}\")\n",
    "        t1 = time.time()\n",
    "    \n",
    "        local_weights_pca = []\n",
    "        for client_idx, client_model in enumerate(local_models_pca[0:num_cluster]):\n",
    "            print(f\"Training client {client_idx + 1}\")\n",
    "            \n",
    "            optimizer = optim.SGD(client_model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    \n",
    "            train_losses = []\n",
    "            train_counter = []\n",
    "    \n",
    "            for epoch in range(1, n_epochs + 1):  \n",
    "                train(epoch, client_model, pca_client_loaders_clustered[client_idx], optimizer, log_interval, train_losses, train_counter)\n",
    "            \n",
    "            client_weights = [param.data.numpy() for param in client_model.parameters()]\n",
    "            local_weights_pca.append(client_weights)\n",
    "            \n",
    "        global_weights_pca = federated_averaging(local_weights_pca)\n",
    "\n",
    "        distribute_global_model(global_weights_pca, local_models_pca, single=False)\n",
    "        distribute_global_model(global_weights_pca, global_model_pca, single=True)\n",
    "\n",
    "        test_losses = []\n",
    "        test(global_model_pca, test_loader_pca, test_losses)\n",
    "        t2 = time.time()\n",
    "        \n",
    "        test_accuracies_pca = []\n",
    "        correct = 0\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader_pca:\n",
    "                output = global_model_pca(data)\n",
    "                pred = output.data.max(1, keepdim=True)[1]\n",
    "                all_preds.extend(pred.cpu().numpy().flatten())\n",
    "                all_targets.extend(target.cpu().numpy().flatten())\n",
    "                correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "        \n",
    "        accuracy = 100. * correct / len(test_loader_pca.dataset)\n",
    "        test_accuracies_pca.append(accuracy)\n",
    "        precision = precision_score(all_targets, all_preds, average='macro')\n",
    "        recall = recall_score(all_targets, all_preds, average='macro')\n",
    "        f1 = f1_score(all_targets, all_preds, average='macro')\n",
    "\n",
    "        # Save clustered results for each partitions_number\n",
    "        if num_cluster not in clusteredResults[\"pca\"]:\n",
    "            clusteredResults[\"pca\"][num_cluster] = {\"losses\": [], \"accuracy\": [],\"precision\": [], \"recall\": [], \"f1\": [], \"trainingTime\": []}\n",
    "\n",
    "        clusteredResults[\"pca\"][num_cluster][\"losses\"].extend(test_losses)\n",
    "        clusteredResults[\"pca\"][num_cluster][\"accuracy\"].extend(test_accuracies_pca)\n",
    "        clusteredResults[\"pca\"][num_cluster][\"precision\"].append(precision)\n",
    "        clusteredResults[\"pca\"][num_cluster][\"recall\"].append(recall)\n",
    "        clusteredResults[\"pca\"][num_cluster][\"f1\"].append(f1)\n",
    "        clusteredResults[\"pca\"][num_cluster][\"trainingTime\"].append(t2-t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results (Non-Clustered): {'classic': {'NoCluster': {'losses': [0.24501373596191406], 'accuracy': [92.9], 'precision': [0.9309098216561166], 'recall': [0.9276528452830002], 'f1': [0.9277434346191409], 'trainingTime': [435.5968379974365]}}, 'pca': {'NoCluster': {'losses': [0.6247932067871094], 'accuracy': [95.78], 'precision': [0.9583060749319692], 'recall': [0.9576175275312065], 'f1': [0.9575328723752149], 'trainingTime': [183.08611583709717]}}, 'autoencoder': {}}\n",
      "Final Results (Clustered): {'classic': {2: {'losses': [0.1204822769165039, 0.08749838790893555, 0.07249506645202637, 0.060785656356811525], 'accuracy': [96.27, 97.19, 97.67, 98.14], 'precision': [0.9632515793011287, 0.9721386109418072, 0.9768669227165413, 0.9813319250860137], 'recall': [0.9621625225549579, 0.971475160915254, 0.9763796548629928, 0.9811212622375359], 'f1': [0.962393776406582, 0.9716119798862632, 0.9764990378783294, 0.9811580972366768], 'trainingTime': [504.0559151172638, 474.4601457118988, 544.6197488307953, 533.0191023349762]}, 4: {'losses': [0.06001741485595703, 0.05838548698425293, 0.05673707008361816, 0.05309056529998779], 'accuracy': [98.1, 98.12, 98.19, 98.32], 'precision': [0.9811562287140376, 0.9813572301612907, 0.9820578188825666, 0.9832905546122482], 'recall': [0.9806966420158905, 0.9809280375617003, 0.9815865702412536, 0.982929674820649], 'f1': [0.9808299287883108, 0.9810480411528595, 0.9817350006206664, 0.9830377366000199], 'trainingTime': [506.94481468200684, 487.1124300956726, 502.99854493141174, 540.8997662067413]}, 6: {'losses': [0.050726742553710936, 0.049660003662109375, 0.05301490592956543, 0.04876017589569092], 'accuracy': [98.29, 98.36, 98.24, 98.35], 'precision': [0.9830270901227113, 0.9837223443385896, 0.9825280751083889, 0.9836289937947296], 'recall': [0.9826906793827748, 0.9833908539464147, 0.9820702761851161, 0.9832994958661108], 'f1': [0.9827896753834622, 0.9835026378684859, 0.9821990093186598, 0.9833958293485185], 'trainingTime': [487.72357511520386, 487.9857530593872, 481.3204882144928, 481.73507380485535]}, 8: {'losses': [0.04373618450164795, 0.0432011287689209, 0.04283792133331299, 0.04246301174163818], 'accuracy': [98.51, 98.48, 98.55, 98.56], 'precision': [0.9851390092233403, 0.9848306150832388, 0.985544269984121, 0.9856251133296595], 'recall': [0.9849483653039044, 0.9846585158912736, 0.9853375684890302, 0.9854641304312904], 'f1': [0.9850139626087012, 0.9847181218625229, 0.9854145762840625, 0.9855161483147172], 'trainingTime': [470.2906153202057, 477.0972616672516, 477.7941300868988, 484.9117386341095]}, 10: {'losses': [0.04332637062072754, 0.04322692241668701, 0.04316799621582031, 0.04308138751983642], 'accuracy': [98.59, 98.62, 98.55, 98.57], 'precision': [0.9859315282208062, 0.9862215454862253, 0.9855366945805313, 0.9857353222220109], 'recall': [0.985714917083661, 0.986063449942234, 0.9853650010578623, 0.985537115772676], 'f1': [0.9857861761771047, 0.9860982591397848, 0.9854113291741188, 0.9855985790558354], 'trainingTime': [469.0093162059784, 478.97578620910645, 469.0331768989563, 456.13612842559814]}}, 'pca': {2: {'losses': [0.38039380798339845, 0.2578817810058594, 0.2188134811401367, 0.1951663818359375], 'accuracy': [97.65, 98.3, 98.55, 98.55], 'precision': [0.9766279169434758, 0.9831143393438332, 0.9855817683535717, 0.985703536729541], 'recall': [0.9761390480047553, 0.9826582150015634, 0.985219863200286, 0.9851679975796148], 'f1': [0.9762648727735019, 0.9828060119227515, 0.9853323713140456, 0.9853539699801208], 'trainingTime': [184.97050046920776, 190.66580510139465, 185.90055894851685, 234.52945494651794]}, 4: {'losses': [0.17553790435791017, 0.17635889892578124, 0.16848893432617187, 0.16226716003417968], 'accuracy': [98.66, 98.57, 98.68, 98.72], 'precision': [0.9867453101942466, 0.9859184986987624, 0.9869660616688136, 0.9873862926427854], 'recall': [0.9862541465379973, 0.9852607159977669, 0.9864051164722787, 0.9868353375170292], 'f1': [0.9864416532720487, 0.9855037437707687, 0.986616094749427, 0.9870458904003518], 'trainingTime': [181.78620147705078, 159.02861666679382, 164.2859184741974, 174.90674138069153]}, 6: {'losses': [0.15385300750732422, 0.15400955505371094, 0.1580075149536133, 0.1461931381225586], 'accuracy': [98.8, 98.75, 98.69, 98.78], 'precision': [0.9882129574655458, 0.9876978973503805, 0.9871970297217614, 0.9880126875620464], 'recall': [0.9876612829881953, 0.9871176203659567, 0.9865448995454317, 0.987466753542116], 'f1': [0.9878886243723993, 0.9873528340088585, 0.9868046212380011, 0.9876864941298008], 'trainingTime': [124.92650938034058, 119.75715065002441, 119.21622657775879, 119.81189584732056]}, 8: {'losses': [0.13891135559082032, 0.13731377716064452, 0.13003121871948242, 0.13181693725585938], 'accuracy': [98.91, 98.9, 98.91, 98.89], 'precision': [0.9892983599498061, 0.9891672235389427, 0.9892843979052828, 0.9891147551053704], 'recall': [0.9888456671858463, 0.9887500765501687, 0.9888563102378993, 0.9886981659653749], 'f1': [0.9890441540332533, 0.9889307464415598, 0.9890414441914928, 0.9888762630307356], 'trainingTime': [123.44969749450684, 118.31659746170044, 119.4871735572815, 120.37207531929016]}, 10: {'losses': [0.1275254249572754, 0.12678915328979493, 0.1231812484741211, 0.12529953155517579], 'accuracy': [98.89, 98.88, 98.86, 98.92], 'precision': [0.9891159607345296, 0.9889964226940255, 0.9888024792259575, 0.9893840450762186], 'recall': [0.9886810127924296, 0.9885764548324, 0.98835424517534, 0.9889552665285773], 'f1': [0.988866423249178, 0.988757296312952, 0.9885438231327723, 0.9891397958840955], 'trainingTime': [119.81087732315063, 120.47831392288208, 120.16149687767029, 118.86133170127869]}}, 'autoencoder': {}}\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Results (Non-Clustered):\", results)\n",
    "print(\"Final Results (Clustered):\", clusteredResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'classic': {'NoCluster': {'losses': [0.24501373596191406], 'accuracy': [92.9], 'precision': [0.9309098216561166], 'recall': [0.9276528452830002], 'f1': [0.9277434346191409], 'trainingTime': [435.5968379974365]}}, 'pca': {'NoCluster': {'losses': [0.6247932067871094], 'accuracy': [95.78], 'precision': [0.9583060749319692], 'recall': [0.9576175275312065], 'f1': [0.9575328723752149], 'trainingTime': [183.08611583709717]}}, 'autoencoder': {}}\n",
    "clusteredResults = {'classic': {2: {'losses': [0.1204822769165039, 0.08749838790893555, 0.07249506645202637, 0.060785656356811525], 'accuracy': [96.27, 97.19, 97.67, 98.14], 'precision': [0.9632515793011287, 0.9721386109418072, 0.9768669227165413, 0.9813319250860137], 'recall': [0.9621625225549579, 0.971475160915254, 0.9763796548629928, 0.9811212622375359], 'f1': [0.962393776406582, 0.9716119798862632, 0.9764990378783294, 0.9811580972366768], 'trainingTime': [504.0559151172638, 474.4601457118988, 544.6197488307953, 533.0191023349762]}, 4: {'losses': [0.06001741485595703, 0.05838548698425293, 0.05673707008361816, 0.05309056529998779], 'accuracy': [98.1, 98.12, 98.19, 98.32], 'precision': [0.9811562287140376, 0.9813572301612907, 0.9820578188825666, 0.9832905546122482], 'recall': [0.9806966420158905, 0.9809280375617003, 0.9815865702412536, 0.982929674820649], 'f1': [0.9808299287883108, 0.9810480411528595, 0.9817350006206664, 0.9830377366000199], 'trainingTime': [506.94481468200684, 487.1124300956726, 502.99854493141174, 540.8997662067413]}, 6: {'losses': [0.050726742553710936, 0.049660003662109375, 0.05301490592956543, 0.04876017589569092], 'accuracy': [98.29, 98.36, 98.24, 98.35], 'precision': [0.9830270901227113, 0.9837223443385896, 0.9825280751083889, 0.9836289937947296], 'recall': [0.9826906793827748, 0.9833908539464147, 0.9820702761851161, 0.9832994958661108], 'f1': [0.9827896753834622, 0.9835026378684859, 0.9821990093186598, 0.9833958293485185], 'trainingTime': [487.72357511520386, 487.9857530593872, 481.3204882144928, 481.73507380485535]}, 8: {'losses': [0.04373618450164795, 0.0432011287689209, 0.04283792133331299, 0.04246301174163818], 'accuracy': [98.51, 98.48, 98.55, 98.56], 'precision': [0.9851390092233403, 0.9848306150832388, 0.985544269984121, 0.9856251133296595], 'recall': [0.9849483653039044, 0.9846585158912736, 0.9853375684890302, 0.9854641304312904], 'f1': [0.9850139626087012, 0.9847181218625229, 0.9854145762840625, 0.9855161483147172], 'trainingTime': [470.2906153202057, 477.0972616672516, 477.7941300868988, 484.9117386341095]}, 10: {'losses': [0.04332637062072754, 0.04322692241668701, 0.04316799621582031, 0.04308138751983642], 'accuracy': [98.59, 98.62, 98.55, 98.57], 'precision': [0.9859315282208062, 0.9862215454862253, 0.9855366945805313, 0.9857353222220109], 'recall': [0.985714917083661, 0.986063449942234, 0.9853650010578623, 0.985537115772676], 'f1': [0.9857861761771047, 0.9860982591397848, 0.9854113291741188, 0.9855985790558354], 'trainingTime': [469.0093162059784, 478.97578620910645, 469.0331768989563, 456.13612842559814]}}, 'pca': {2: {'losses': [0.38039380798339845, 0.2578817810058594, 0.2188134811401367, 0.1951663818359375], 'accuracy': [97.65, 98.3, 98.55, 98.55], 'precision': [0.9766279169434758, 0.9831143393438332, 0.9855817683535717, 0.985703536729541], 'recall': [0.9761390480047553, 0.9826582150015634, 0.985219863200286, 0.9851679975796148], 'f1': [0.9762648727735019, 0.9828060119227515, 0.9853323713140456, 0.9853539699801208], 'trainingTime': [184.97050046920776, 190.66580510139465, 185.90055894851685, 234.52945494651794]}, 4: {'losses': [0.17553790435791017, 0.17635889892578124, 0.16848893432617187, 0.16226716003417968], 'accuracy': [98.66, 98.57, 98.68, 98.72], 'precision': [0.9867453101942466, 0.9859184986987624, 0.9869660616688136, 0.9873862926427854], 'recall': [0.9862541465379973, 0.9852607159977669, 0.9864051164722787, 0.9868353375170292], 'f1': [0.9864416532720487, 0.9855037437707687, 0.986616094749427, 0.9870458904003518], 'trainingTime': [181.78620147705078, 159.02861666679382, 164.2859184741974, 174.90674138069153]}, 6: {'losses': [0.15385300750732422, 0.15400955505371094, 0.1580075149536133, 0.1461931381225586], 'accuracy': [98.8, 98.75, 98.69, 98.78], 'precision': [0.9882129574655458, 0.9876978973503805, 0.9871970297217614, 0.9880126875620464], 'recall': [0.9876612829881953, 0.9871176203659567, 0.9865448995454317, 0.987466753542116], 'f1': [0.9878886243723993, 0.9873528340088585, 0.9868046212380011, 0.9876864941298008], 'trainingTime': [124.92650938034058, 119.75715065002441, 119.21622657775879, 119.81189584732056]}, 8: {'losses': [0.13891135559082032, 0.13731377716064452, 0.13003121871948242, 0.13181693725585938], 'accuracy': [98.91, 98.9, 98.91, 98.89], 'precision': [0.9892983599498061, 0.9891672235389427, 0.9892843979052828, 0.9891147551053704], 'recall': [0.9888456671858463, 0.9887500765501687, 0.9888563102378993, 0.9886981659653749], 'f1': [0.9890441540332533, 0.9889307464415598, 0.9890414441914928, 0.9888762630307356], 'trainingTime': [123.44969749450684, 118.31659746170044, 119.4871735572815, 120.37207531929016]}, 10: {'losses': [0.1275254249572754, 0.12678915328979493, 0.1231812484741211, 0.12529953155517579], 'accuracy': [98.89, 98.88, 98.86, 98.92], 'precision': [0.9891159607345296, 0.9889964226940255, 0.9888024792259575, 0.9893840450762186], 'recall': [0.9886810127924296, 0.9885764548324, 0.98835424517534, 0.9889552665285773], 'f1': [0.988866423249178, 0.988757296312952, 0.9885438231327723, 0.9891397958840955], 'trainingTime': [119.81087732315063, 120.47831392288208, 120.16149687767029, 118.86133170127869]}}, 'autoencoder': {}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder2(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU()\n",
       "    (10): Conv2d(32, 2, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (12): BatchNorm2d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (13): Flatten(start_dim=1, end_dim=-1)\n",
       "    (14): Linear(in_features=98, out_features=100, bias=True)\n",
       "    (15): ReLU()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=98, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Unflatten(dim=1, unflattened_size=(2, 7, 7))\n",
       "    (3): ConvTranspose2d(2, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU()\n",
       "    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (9): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): ReLU()\n",
       "    (11): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (12): ConvTranspose2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "trainingset_auto = train_loader_pca.dataset\n",
    "trial_model_auto = classification_model()\n",
    "global_model_auto = classification_model()\n",
    "autoencoder2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "partitioned_data_auto = partition.balanced_dirichlet_partition(trainingset_auto, partitions_number=num_clients, alpha=0.1)\n",
    "\n",
    "auto_client_loaders = [\n",
    "    DataLoader(Subset(trainingset_auto, indices), batch_size=batch_size_train, shuffle=True)\n",
    "    for indices in partitioned_data_auto.values()\n",
    "]\n",
    "\n",
    "auto_client_loader_reduced = []\n",
    "\n",
    "for i,client in enumerate(auto_client_loaders):\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    latent_features, labels = reduce_dimensions2(auto_client_loaders[i], autoencoder2.encoder, device)\n",
    "    latent_features = latent_features.detach()\n",
    "\n",
    "    reconstructed_images = autoencoder2.decoder(latent_features.to(device))  \n",
    "    reconstructed_images = reconstructed_images.view(-1, 1, 28, 28)  # Reshape to [batch_size, channels, height, width]\n",
    "\n",
    "    reconstructed_dataset = CustomTensorDataset(reconstructed_images.cpu(), labels)  \n",
    "    reduced_train_loader_auto = DataLoader(reconstructed_dataset, batch_size=batch_size_train, shuffle=True)\n",
    "    auto_client_loader_reduced.append(reduced_train_loader_auto)\n",
    "\n",
    "\n",
    "local_model_autoencoder = [copy.deepcopy(global_model_auto) for _ in range(num_clients)]\n",
    "\n",
    "\n",
    "\n",
    "rounds_auto = 4\n",
    "for round_idx in range(rounds_auto):\n",
    "    print(f\"Round {round_idx + 1}/{rounds_auto}\")\n",
    "    t1 = time.time()\n",
    "\n",
    "    local_weights_auto = []\n",
    "    for client_idx, client_model in enumerate(local_model_autoencoder):\n",
    "        print(f\"Training client {client_idx + 1}\")\n",
    "        \n",
    "        optimizer = optim.SGD(client_model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        \n",
    "        train_losses = []\n",
    "        train_counter = []\n",
    "\n",
    "        for epoch in range(1, n_epochs + 1):  \n",
    "            train(epoch, client_model, auto_client_loaders[client_idx], optimizer, log_interval, train_losses, train_counter)\n",
    "        \n",
    "        client_weights = [param.data.numpy() for param in client_model.parameters()]\n",
    "        local_weights_auto.append(client_weights)\n",
    "        \n",
    "    global_weights_auto = federated_averaging(local_weights_auto)\n",
    "\n",
    "    distribute_global_model(global_weights_auto, local_model_autoencoder, single=False)\n",
    "    distribute_global_model(global_weights_auto, global_model_auto, single=True)\n",
    "\n",
    "    test_losses = []\n",
    "    test(global_model_auto, test_loader_auto, test_losses)\n",
    "    t2 = time.time()\n",
    "\n",
    "    test_accuracies_auto = []\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader_auto:\n",
    "            output = global_model_auto(data)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            all_preds.extend(pred.cpu().numpy().flatten())\n",
    "            all_targets.extend(target.cpu().numpy().flatten())\n",
    "    \n",
    "    correct = sum(p == t for p, t in zip(all_preds, all_targets))\n",
    "    accuracy = 100. * correct / len(all_targets)\n",
    "    test_accuracies_auto.append(accuracy)\n",
    "    precision = precision_score(all_targets, all_preds, average='macro')\n",
    "    recall = recall_score(all_targets, all_preds, average='macro')\n",
    "    f1 = f1_score(all_targets, all_preds, average='macro')\n",
    "\n",
    "    # Save results for each partitions_number\n",
    "    \n",
    "    results[\"autoencoder\"][\"NoCluster\"] = {\"losses\": [], \"accuracy\": [], \"precision\": [], \"recall\": [], \"f1\": [], \"trainingTime\": []}\n",
    "\n",
    "    results[\"autoencoder\"][\"NoCluster\"][\"losses\"].extend(test_losses)\n",
    "    results[\"autoencoder\"][\"NoCluster\"][\"accuracy\"].extend(test_accuracies_auto)\n",
    "    results[\"autoencoder\"][\"NoCluster\"][\"precision\"].append(precision)\n",
    "    results[\"autoencoder\"][\"NoCluster\"][\"recall\"].append(recall)\n",
    "    results[\"autoencoder\"][\"NoCluster\"][\"f1\"].append(f1)\n",
    "    results[\"autoencoder\"][\"NoCluster\"][\"trainingTime\"].append(t2-t1)\n",
    "\n",
    "    ######################\n",
    "\n",
    "for num_cluster in num_clusters:\n",
    "    import cluster2\n",
    "\n",
    "    targets = trainingset.targets\n",
    "    num_classes = len(set(targets)) \n",
    "    clients = [cluster2.FederatedClient(cid, indices, targets, num_classes) for cid, indices in partitioned_data_auto.items()]\n",
    "    client_distributions = [client.compute_label_distribution() for client in clients]\n",
    "    server = cluster2.FederatedClusterServer(num_cluster)\n",
    "    aggregated_data = server.aggregate_client_data(client_distributions)\n",
    "    clustered_data = server.perform_greedy_clustering(aggregated_data, partitioned_data_auto)\n",
    "    \n",
    "    partitioned_data_auto_clustered = clustered_data\n",
    "    \"\"\"\n",
    "    \n",
    "    import cluster\n",
    "    cluster = cluster.Cluster(num_clusters=num_cluster)\n",
    "    \n",
    "    targets = trainingset_auto.targets\n",
    "    num_classes = len(set(targets)) \n",
    "    clustered_data = cluster.apply_clustering(partitioned_data_auto, targets, num_classes)\n",
    "    partitioned_data_auto_clustered = clustered_data\n",
    "    \"\"\"\n",
    "\n",
    "    auto_client_loaders_clustered = [\n",
    "        DataLoader(Subset(trainingset_auto, indices), batch_size=batch_size_train, shuffle=True)\n",
    "        for indices in partitioned_data_auto_clustered.values()\n",
    "    ]\n",
    "    \n",
    "    auto_client_loader_reduced = []\n",
    "\n",
    "    for i,client in enumerate(auto_client_loaders_clustered):\n",
    "        \n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        latent_features, labels = reduce_dimensions2(auto_client_loaders_clustered[i], autoencoder2.encoder, device)\n",
    "        latent_features = latent_features.detach()\n",
    "\n",
    "        reconstructed_images = autoencoder2.decoder(latent_features.to(device))  \n",
    "        reconstructed_images = reconstructed_images.view(-1, 1, 28, 28)  # Reshape to [batch_size, channels, height, width]\n",
    "\n",
    "        reconstructed_dataset = CustomTensorDataset(reconstructed_images.cpu(), labels)  \n",
    "        reduced_train_loader_auto = DataLoader(reconstructed_dataset, batch_size=batch_size_train, shuffle=True)\n",
    "        auto_client_loader_reduced.append(reduced_train_loader_auto)\n",
    "\n",
    "    for round_idx in range(rounds_auto):\n",
    "        print(f\"Round {round_idx + 1}/{rounds_auto}\")\n",
    "        t1 = time.time()\n",
    "\n",
    "        local_weights_auto = []\n",
    "        for client_idx, client_model in enumerate(local_model_autoencoder[0:num_cluster]):\n",
    "            print(f\"Training client {client_idx + 1}\")\n",
    "            \n",
    "            optimizer = optim.SGD(client_model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "            \n",
    "            train_losses = []\n",
    "            train_counter = []\n",
    "\n",
    "            for epoch in range(1, n_epochs + 1):  \n",
    "                train(epoch, client_model, auto_client_loader_reduced[client_idx], optimizer, log_interval, train_losses, train_counter)\n",
    "            \n",
    "            client_weights = [param.data.numpy() for param in client_model.parameters()]\n",
    "            local_weights_auto.append(client_weights)\n",
    "            \n",
    "        global_weights_auto = federated_averaging(local_weights_auto)\n",
    "\n",
    "        distribute_global_model(global_weights_auto, local_model_autoencoder, single=False)\n",
    "        distribute_global_model(global_weights_auto, global_model_auto, single=True)\n",
    "\n",
    "        test_losses = []\n",
    "        test(global_model_auto, test_loader_auto, test_losses)\n",
    "        t2 = time.time()\n",
    "        \n",
    "        test_accuracies_auto = []\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader_auto:\n",
    "                output = global_model_auto(data)\n",
    "                pred = output.data.max(1, keepdim=True)[1]\n",
    "                all_preds.extend(pred.cpu().numpy().flatten())\n",
    "                all_targets.extend(target.cpu().numpy().flatten())\n",
    "        \n",
    "        correct = sum(p == t for p, t in zip(all_preds, all_targets))\n",
    "        accuracy = 100. * correct / len(all_targets)\n",
    "        test_accuracies_auto.append(accuracy)\n",
    "        precision = precision_score(all_targets, all_preds, average='macro')\n",
    "        recall = recall_score(all_targets, all_preds, average='macro')\n",
    "        f1 = f1_score(all_targets, all_preds, average='macro')\n",
    "\n",
    "        # Save clustered results for each partitions_number\n",
    "        if num_cluster not in clusteredResults[\"autoencoder\"]:\n",
    "            clusteredResults[\"autoencoder\"][num_cluster] = {\"losses\": [], \"accuracy\": [],\"precision\": [], \"recall\": [], \"f1\": [], \"trainingTime\": []}\n",
    "\n",
    "        clusteredResults[\"autoencoder\"][num_cluster][\"losses\"].extend(test_losses)\n",
    "        clusteredResults[\"autoencoder\"][num_cluster][\"accuracy\"].extend(test_accuracies_auto)\n",
    "        clusteredResults[\"autoencoder\"][num_cluster][\"precision\"].append(precision)\n",
    "        clusteredResults[\"autoencoder\"][num_cluster][\"recall\"].append(recall)\n",
    "        clusteredResults[\"autoencoder\"][num_cluster][\"f1\"].append(f1)\n",
    "        clusteredResults[\"autoencoder\"][num_cluster][\"trainingTime\"].append(t2-t1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results (Non-Clustered): {'classic': {}, 'pca': {}, 'autoencoder': {'NoCluster': {'losses': [0.08878104782104493], 'accuracy': [97.2], 'precision': [0.9718793265539263], 'recall': [0.9719804845053612], 'f1': [0.9718887983444822], 'trainingTime': [178.18732500076294]}}}\n",
      "Final Results (Clustered): {'classic': {}, 'pca': {}, 'autoencoder': {2: {'losses': [0.07136679611206055, 0.06136421432495117, 0.05513326873779297, 0.05201905899047852], 'accuracy': [97.69, 98.03, 98.17, 98.27], 'precision': [0.976841204713496, 0.9802959110769823, 0.9816658229118413, 0.9826801499936868], 'recall': [0.9768340879579174, 0.9803244050256124, 0.9817130841383553, 0.9827771196881571], 'f1': [0.9767946530185825, 0.980275089282204, 0.9816482412731127, 0.9826799514005005], 'trainingTime': [69.5360062122345, 68.6651508808136, 68.08172130584717, 68.15843558311462]}, 4: {'losses': [0.047834548568725585, 0.04622954216003418, 0.04444165744781494, 0.043289639854431156], 'accuracy': [98.44, 98.53, 98.6, 98.59], 'precision': [0.9843162348871948, 0.9852548351533839, 0.9859419624443196, 0.9858296390022308], 'recall': [0.9843762326049124, 0.9852608583629715, 0.9859600670563399, 0.9858596018910069], 'f1': [0.9843227763534086, 0.9852424705592892, 0.9859324151424411, 0.9858289852054721], 'trainingTime': [68.15612936019897, 68.17081236839294, 68.10459113121033, 68.02183866500854]}, 6: {'losses': [0.04139673194885254, 0.0405659423828125, 0.03980033950805664, 0.04010178852081299], 'accuracy': [98.7, 98.69, 98.74, 98.74], 'precision': [0.9869260978058829, 0.9868279550803578, 0.9873328354732103, 0.9873076154682661], 'recall': [0.9870234017380184, 0.9868705151285952, 0.9873602295016719, 0.9874116846839918], 'f1': [0.9869596944326007, 0.9868358205647905, 0.987336289399026, 0.9873465913417494], 'trainingTime': [69.3339319229126, 71.15048813819885, 71.04662466049194, 70.77991724014282]}, 8: {'losses': [0.0395399227142334, 0.03911107120513916, 0.038977632331848144, 0.03829846420288086], 'accuracy': [98.73, 98.73, 98.73, 98.72], 'precision': [0.9872113805964441, 0.9871903495269967, 0.9872296459337416, 0.9871157707483322], 'recall': [0.9872536246761848, 0.9872542872603942, 0.9872516062789491, 0.9871572419013429], 'f1': [0.9872163815066243, 0.987207957089789, 0.9872246906406538, 0.9871216621513348], 'trainingTime': [71.5871217250824, 71.67779064178467, 71.47177767753601, 71.4891288280487]}, 10: {'losses': [0.038340018844604494, 0.03868247909545899, 0.03774585113525391, 0.03699915580749512], 'accuracy': [98.69, 98.75, 98.76, 98.75], 'precision': [0.9868231392958237, 0.987382708595012, 0.9875232877590726, 0.9874367352900444], 'recall': [0.9869129338178789, 0.9875468823837654, 0.9876135863219091, 0.9874827952863748], 'f1': [0.9868514641839639, 0.9874456670872747, 0.9875506548619442, 0.9874452301685013], 'trainingTime': [71.77292466163635, 71.95758533477783, 71.6460063457489, 71.91209387779236]}}}\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Results (Non-Clustered):\", results)\n",
    "print(\"Final Results (Clustered):\", clusteredResults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results\n",
    "results = {'classic': {'NoCluster': {'losses': [0.1341603889465332], 'accuracy': [95.75], 'precision': [0.9572877422229735], 'recall': [0.9571961914120001], 'f1': [0.9571833416542219], 'trainingTime': [265.7449953556061 * 4]}}, 'pca': {'NoCluster': {'losses': [0.467795263671875], 'accuracy': [97.11], 'precision': [0.9711488388971727], 'recall': [0.9710351789571735], 'f1': [0.9709998262999754], 'trainingTime': [143.9466438293457 * 4]}}, 'autoencoder': {'NoCluster': {'losses': [0.1336971321105957], 'accuracy': [96.08], 'precision': [0.9606735142936007], 'recall': [0.96051243211136], 'f1': [0.9605219691362622], 'trainingTime': [361.80671882629395 * 4]}}}\n",
    "clusteredResults = {'classic': {2: {'losses': [0.07973020935058593, 0.06610093612670899, 0.055510023498535156, 0.04812007923126221], 'accuracy': [97.51, 97.86, 98.26, 98.42], 'precision': [0.9750704308186731, 0.9787230069325545, 0.9826061058787967, 0.9842089101610426], 'recall': [0.9749636705875486, 0.978434708087619, 0.9825550206626618, 0.9841031264798271], 'f1': [0.9749818471120841, 0.9785203056126429, 0.9825517709480349, 0.9841343753151188], 'trainingTime': [259.0749258995056, 249.29273509979248, 248.9493854045868, 285.2244551181793]}, 4: {'losses': [0.04533520488739014, 0.044230483627319336, 0.04219058437347412, 0.03998064956665039], 'accuracy': [98.56, 98.58, 98.61, 98.8], 'precision': [0.9856446880465264, 0.9858514513411875, 0.9861107697238415, 0.9880000010020872], 'recall': [0.9854767724742798, 0.9856939303915953, 0.9859933148563158, 0.9879145452620067], 'f1': [0.9855444768118741, 0.9857445573891676, 0.9860289344569193, 0.9879441458631092], 'trainingTime': [277.78387904167175, 304.34704399108887, 280.04547667503357, 285.71227622032166]}, 6: {'losses': [0.03947805976867676, 0.038409397315979005, 0.03801198997497559, 0.03699978065490723], 'accuracy': [98.72, 98.83, 98.83, 98.87], 'precision': [0.9872571371580765, 0.988348152260289, 0.988306620641833, 0.9887333015904402], 'recall': [0.9870636941130921, 0.9882007980453681, 0.9882040629325365, 0.9885926869808541], 'f1': [0.9871380712685858, 0.9882533856273431, 0.9882391001357529, 0.9886442047858187], 'trainingTime': [282.28512740135193, 280.3706090450287, 283.73913741111755, 281.52455592155457]}, 8: {'losses': [0.037226670837402345, 0.036038009071350095, 0.03629348850250244, 0.03528419437408447], 'accuracy': [98.82, 98.87, 98.84, 98.89], 'precision': [0.9881739826462465, 0.988677044644305, 0.9883623750520505, 0.9888855696260436], 'recall': [0.9881261315529211, 0.9886073564961411, 0.9883127005866765, 0.9888111509906045], 'f1': [0.9881333867699713, 0.9886276011614854, 0.9883208404879692, 0.9888319444366533], 'trainingTime': [280.7432291507721, 283.6553919315338, 280.6503987312317, 280.66803884506226]}, 10: {'losses': [0.0350237096786499, 0.035031478881835935, 0.034522124671936036, 0.034536015129089354], 'accuracy': [98.94, 98.94, 98.93, 98.94], 'precision': [0.989416189439533, 0.9894175877962714, 0.9893287162455877, 0.9894312580808858], 'recall': [0.9892998643633831, 0.9892876224999563, 0.9892475327541094, 0.9893276513329836], 'f1': [0.9893417292840692, 0.9893381379919951, 0.9892713633929494, 0.9893627971858778], 'trainingTime': [285.8231530189514, 284.82549715042114, 291.401522397995, 290.5649530887604]}}, 'pca': {2: {'losses': [0.3560072265625, 0.2752729949951172, 0.26902828674316404, 0.25686016845703125], 'accuracy': [97.73, 98.11, 97.93, 98.01], 'precision': [0.9774180230456009, 0.981235548971984, 0.9795921285238915, 0.9803497399723666], 'recall': [0.9772862932882053, 0.9809207985633778, 0.9788828630485608, 0.9797034983279789], 'f1': [0.9772560379898685, 0.9810021257277943, 0.9791132232158921, 0.9798907977576052], 'trainingTime': [132.07864665985107, 130.61796593666077, 130.92007517814636, 132.167662858963]}, 4: {'losses': [0.21090608215332032, 0.20843525848388672, 0.19794453735351564, 0.20505394287109374], 'accuracy': [98.27, 98.2, 98.24, 98.16], 'precision': [0.9828948249202686, 0.9821942019739837, 0.9826791661708125, 0.9819353685903666], 'recall': [0.9823311149909998, 0.9815358687456147, 0.9819605432159475, 0.9810668576852164], 'f1': [0.9825072082423327, 0.9817590445778818, 0.9822107954686243, 0.9813777779713698], 'trainingTime': [131.4798469543457, 133.94486689567566, 131.0007450580597, 130.42566323280334]}, 6: {'losses': [0.20143018951416017, 0.2069422882080078, 0.2009674606323242, 0.19606947479248046], 'accuracy': [98.15, 98.01, 98.06, 98.11], 'precision': [0.9819319421170845, 0.9807051365840348, 0.9811891568689711, 0.9815641084066886], 'recall': [0.980979519409775, 0.9795180035207786, 0.980094361315059, 0.98059941742655], 'f1': [0.9812865865625737, 0.9799066732037905, 0.980447725970409, 0.9809154481444468], 'trainingTime': [131.697172164917, 133.9452362060547, 135.3488965034485, 131.8458354473114]}, 8: {'losses': [0.17972449188232423, 0.1773357666015625, 0.17569290008544922, 0.17883182830810546], 'accuracy': [98.23, 98.23, 98.2, 98.18], 'precision': [0.9825681295810782, 0.9826237594682976, 0.9823858267646312, 0.9821413544727114], 'recall': [0.9819448783127227, 0.9819236672269543, 0.9816027013385197, 0.9814128470128232], 'f1': [0.9821634858480778, 0.9821789698966177, 0.9818910677624009, 0.981673691925846], 'trainingTime': [132.78840589523315, 134.58112931251526, 132.767813205719, 135.18370294570923]}, 10: {'losses': [0.18083276672363283, 0.18719688720703126, 0.18125261535644532, 0.1794867645263672], 'accuracy': [98.13, 98.13, 98.12, 98.17], 'precision': [0.9817036726251812, 0.9816974313642468, 0.9815609143288573, 0.9820866517961555], 'recall': [0.980848887796478, 0.9808358094714359, 0.9807531880888654, 0.9812561516967534], 'f1': [0.9811548387530756, 0.9811351147044192, 0.9810412069107268, 0.9815499327455413], 'trainingTime': [132.14135599136353, 132.42528891563416, 131.3422474861145, 131.8548264503479]}}, 'autoencoder': {2: {'losses': [0.07995339126586914, 0.06515727577209472, 0.05763023223876953, 0.05367104377746582], 'accuracy': [97.51, 97.93, 98.13, 98.2], 'precision': [0.9749570914999415, 0.9791768598329653, 0.9811756740380966, 0.9818274518793879], 'recall': [0.975224726999048, 0.9794231141001065, 0.9813765366987329, 0.9820874839886132], 'f1': [0.9750269511460695, 0.9792529047442985, 0.9812382174670817, 0.9819145899232465], 'trainingTime': [143.1768937110901, 139.84844613075256, 138.66012859344482, 137.13505840301514]}, 4: {'losses': [0.05206445789337158, 0.04971218490600586, 0.04874599514007568, 0.04784202995300293], 'accuracy': [98.22, 98.41, 98.41, 98.45], 'precision': [0.9820299583036942, 0.9840133291616204, 0.9839324895569641, 0.9843883543749881], 'recall': [0.9821936848226812, 0.9840546142526483, 0.9841056859347372, 0.9844460213116338], 'f1': [0.9820676352906329, 0.9840084160949466, 0.9839825618236366, 0.9843839209503555], 'trainingTime': [152.141521692276, 152.46986317634583, 154.2525532245636, 157.5636944770813]}, 6: {'losses': [0.04617654266357422, 0.045315529441833494, 0.0448431303024292, 0.04438701992034912], 'accuracy': [98.47, 98.55, 98.59, 98.58], 'precision': [0.9845634881947619, 0.9853609080291974, 0.9857708778851981, 0.9856693789375093], 'recall': [0.984702970107549, 0.985469339072537, 0.9858744170217155, 0.9858066496284961], 'f1': [0.9846115303811007, 0.985396569154694, 0.9858018257150732, 0.9857184998970967], 'trainingTime': [145.9140019416809, 137.09092569351196, 138.29406547546387, 136.7299680709839]}, 8: {'losses': [0.04392026252746582, 0.04485087890625, 0.043983739852905275, 0.0435766487121582], 'accuracy': [98.57, 98.52, 98.54, 98.57], 'precision': [0.9855552081554755, 0.9850156504694588, 0.985230107781835, 0.985545342365476], 'recall': [0.9856505280504919, 0.9851571593613893, 0.9853843046891135, 0.9856450921204628], 'f1': [0.9855775717292646, 0.9850571233820877, 0.9852776398535218, 0.9855709208059908], 'trainingTime': [143.19044303894043, 138.71568179130554, 135.28253889083862, 132.55518913269043]}, 10: {'losses': [0.04255921497344971, 0.0423343412399292, 0.04270082702636719, 0.042011715126037595], 'accuracy': [98.56, 98.6, 98.56, 98.61], 'precision': [0.9854737820316846, 0.9858595764639613, 0.9854418231185111, 0.9859304053889127], 'recall': [0.9855570879603999, 0.986002836390804, 0.9855628986337688, 0.9860932567050004], 'f1': [0.9854884689302089, 0.9858972228391863, 0.985474425502263, 0.9859830940133023], 'trainingTime': [140.0167806148529, 138.1367106437683, 139.63958144187927, 155.32256507873535]}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Non-Clustered Results:\n",
      "classic:\n",
      "  Final Loss: {'NoCluster': 0.1341603889465332}\n",
      "  Final Accuracy: {'NoCluster': 95.75}\n",
      "  Final Precision: {'NoCluster': 0.9572877422229735}\n",
      "  Final F1 Score: {'NoCluster': 0.9571833416542219}\n",
      "  Final Recall: {'NoCluster': 0.9571961914120001}\n",
      "  Total Time: {'NoCluster': 1062.9799814224243}\n",
      "pca:\n",
      "  Final Loss: {'NoCluster': 0.467795263671875}\n",
      "  Final Accuracy: {'NoCluster': 97.11}\n",
      "  Final Precision: {'NoCluster': 0.9711488388971727}\n",
      "  Final F1 Score: {'NoCluster': 0.9709998262999754}\n",
      "  Final Recall: {'NoCluster': 0.9710351789571735}\n",
      "  Total Time: {'NoCluster': 575.7865753173828}\n",
      "autoencoder:\n",
      "  Final Loss: {'NoCluster': 0.1336971321105957}\n",
      "  Final Accuracy: {'NoCluster': 96.08}\n",
      "  Final Precision: {'NoCluster': 0.9606735142936007}\n",
      "  Final F1 Score: {'NoCluster': 0.9605219691362622}\n",
      "  Final Recall: {'NoCluster': 0.96051243211136}\n",
      "  Total Time: {'NoCluster': 1447.2268753051758}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clustered Results:\n",
      "classic:\n",
      "  Final Loss: {2: 0.04812007923126221, 4: 0.03998064956665039, 6: 0.03699978065490723, 8: 0.03528419437408447, 10: 0.034536015129089354}\n",
      "  Final Accuracy: {2: 98.42, 4: 98.8, 6: 98.87, 8: 98.89, 10: 98.94}\n",
      "  Final Precision: {2: 0.9842089101610426, 4: 0.9880000010020872, 6: 0.9887333015904402, 8: 0.9888855696260436, 10: 0.9894312580808858}\n",
      "  Final F1 Score: {2: 0.9841343753151188, 4: 0.9879441458631092, 6: 0.9886442047858187, 8: 0.9888319444366533, 10: 0.9893627971858778}\n",
      "  Final Recall: {2: 0.9841031264798271, 4: 0.9879145452620067, 6: 0.9885926869808541, 8: 0.9888111509906045, 10: 0.9893276513329836}\n",
      "  Total Time: {2: 1042.5415015220642, 4: 1147.8886759281158, 6: 1127.9194297790527, 8: 1125.7170586585999, 10: 1152.615125656128}\n",
      "pca:\n",
      "  Final Loss: {2: 0.25686016845703125, 4: 0.20505394287109374, 6: 0.19606947479248046, 8: 0.17883182830810546, 10: 0.1794867645263672}\n",
      "  Final Accuracy: {2: 98.01, 4: 98.16, 6: 98.11, 8: 98.18, 10: 98.17}\n",
      "  Final Precision: {2: 0.9803497399723666, 4: 0.9819353685903666, 6: 0.9815641084066886, 8: 0.9821413544727114, 10: 0.9820866517961555}\n",
      "  Final F1 Score: {2: 0.9798907977576052, 4: 0.9813777779713698, 6: 0.9809154481444468, 8: 0.981673691925846, 10: 0.9815499327455413}\n",
      "  Final Recall: {2: 0.9797034983279789, 4: 0.9810668576852164, 6: 0.98059941742655, 8: 0.9814128470128232, 10: 0.9812561516967534}\n",
      "  Total Time: {2: 525.7843506336212, 4: 526.8511221408844, 6: 532.8371403217316, 8: 535.3210513591766, 10: 527.7637188434601}\n",
      "autoencoder:\n",
      "  Final Loss: {2: 0.05367104377746582, 4: 0.04784202995300293, 6: 0.04438701992034912, 8: 0.0435766487121582, 10: 0.042011715126037595}\n",
      "  Final Accuracy: {2: 98.2, 4: 98.45, 6: 98.58, 8: 98.57, 10: 98.61}\n",
      "  Final Precision: {2: 0.9818274518793879, 4: 0.9843883543749881, 6: 0.9856693789375093, 8: 0.985545342365476, 10: 0.9859304053889127}\n",
      "  Final F1 Score: {2: 0.9819145899232465, 4: 0.9843839209503555, 6: 0.9857184998970967, 8: 0.9855709208059908, 10: 0.9859830940133023}\n",
      "  Final Recall: {2: 0.9820874839886132, 4: 0.9844460213116338, 6: 0.9858066496284961, 8: 0.9856450921204628, 10: 0.9860932567050004}\n",
      "  Total Time: {2: 558.8205268383026, 4: 616.4276325702667, 6: 558.0289611816406, 8: 549.743852853775, 10: 573.1156377792358}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to compute final metrics\n",
    "def compute_final_metrics(metrics):\n",
    "    final_loss = {alpha: data['losses'][-1] for alpha, data in metrics.items()}\n",
    "    final_accuracy = {alpha: data['accuracy'][-1] for alpha, data in metrics.items()}\n",
    "    final_precision = {alpha: data['precision'][-1] for alpha, data in metrics.items()}\n",
    "    final_f1 = {alpha: data['f1'][-1] for alpha, data in metrics.items()}\n",
    "    final_recall = {alpha: data['recall'][-1] for alpha, data in metrics.items()}\n",
    "\n",
    "    # Sum of all training times\n",
    "    total_time = {\n",
    "        alpha: sum(data.get('TrainingTime', data.get('trainingTime', [0])))\n",
    "        for alpha, data in metrics.items()\n",
    "    }\n",
    "\n",
    "    return final_loss, final_accuracy, final_precision, final_f1, final_recall, total_time\n",
    "\n",
    "# Function to print results\n",
    "def print_results(results, title):\n",
    "    print(f\"\\n{title}:\")\n",
    "    for method in results.keys():\n",
    "        final_loss, final_accuracy, final_precision, final_f1, final_recall, total_time = compute_final_metrics(results[method])\n",
    "        print(f\"{method}:\")\n",
    "        print(\"  Final Loss:\", final_loss)\n",
    "        print(\"  Final Accuracy:\", final_accuracy)\n",
    "        print(\"  Final Precision:\", final_precision)\n",
    "        print(\"  Final F1 Score:\", final_f1)\n",
    "        print(\"  Final Recall:\", final_recall)\n",
    "        print(\"  Total Time:\", total_time)\n",
    "\n",
    "# Function to plot the results\n",
    "def plot_results(results, title, filename):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # List of metrics to plot\n",
    "    metrics_names = [\"Loss\", \"Accuracy\", \"Precision\", \"F1 Score\", \"Recall\", \"Total Time\"]\n",
    "    for i, metric in enumerate(metrics_names):\n",
    "        plt.subplot(2, 3, i + 1)\n",
    "\n",
    "        # Plotting each method's metrics\n",
    "        for method in results.keys():\n",
    "            final_loss, final_accuracy, final_precision, final_f1, final_recall, total_time = compute_final_metrics(results[method])\n",
    "\n",
    "            # Select the right metric based on the iteration\n",
    "            metric_values = {\n",
    "                \"Loss\": final_loss,\n",
    "                \"Accuracy\": final_accuracy,\n",
    "                \"Precision\": final_precision,\n",
    "                \"F1 Score\": final_f1,\n",
    "                \"Recall\": final_recall,\n",
    "                \"Total Time\": total_time\n",
    "            }[metric]\n",
    "\n",
    "            # Plot the metric values for each method\n",
    "            plt.plot(list(metric_values.keys()) + ['NoCluster'], list(metric_values.values()) + [metric_values.get('NoCluster', np.nan)], marker='o', label=method)\n",
    "\n",
    "        plt.xlabel('Clusters')\n",
    "        plt.ylabel(metric)\n",
    "        plt.title(f'{title} - Clusters vs {metric}')\n",
    "        plt.legend()\n",
    "\n",
    "    # Adjust layout and save the plot\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "# Assuming 'results' and 'clusteredResults' are the data for the methods\n",
    "# Print and plot results for non-clustered and clustered data\n",
    "\n",
    "print_results(results, \"Non-Clustered Results\")\n",
    "plot_results(results, \"Non-Clustered Results\", \"non_clustered_results.png\")\n",
    "\n",
    "print_results(clusteredResults, \"Clustered Results\")\n",
    "plot_results(clusteredResults, \"Clustered Results\", \"clustered_results.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
