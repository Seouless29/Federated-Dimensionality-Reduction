{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset,TensorDataset\n",
    "from autoencoder import Autoencoder\n",
    "import torchvision\n",
    "from model2 import classification_model\n",
    "import copy\n",
    "import partition\n",
    "from pca import PCADigitReducer\n",
    "from autoencoder import reduce_dimensions\n",
    "from training import train,test, train_fashion,test_fashion\n",
    "from federated_learning import distribute_global_model, federated_averaging\n",
    "from model4 import MultilayerPerceptron\n",
    "import cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x22a875efad0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predefined stuff\n",
    "\n",
    "n_epochs = 5\n",
    "batch_size_train = 100\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "num_clusters = 2\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.2860,), (0.3204,))  \n",
    "])\n",
    "\n",
    "fashion_mnist_train_loader = DataLoader(\n",
    "    datasets.FashionMNIST('/files/', train=True, download=True, transform=fashion_mnist_transform),\n",
    "    batch_size=batch_size_train, shuffle=True\n",
    ")\n",
    "\n",
    "fashion_mnist_test_loader = DataLoader(\n",
    "    datasets.FashionMNIST('/files/', train=False, download=True, transform=fashion_mnist_transform),\n",
    "    batch_size=batch_size_test, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_pca = copy.copy(fashion_mnist_train_loader)\n",
    "test_loader_pca = copy.copy(fashion_mnist_test_loader)\n",
    "\n",
    "train_loader_auto = copy.copy(fashion_mnist_train_loader)\n",
    "test_loader_auto = copy.copy(fashion_mnist_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTensorDataset(TensorDataset):\n",
    "    def __init__(self, *tensors):\n",
    "        super().__init__(*tensors)\n",
    "        self.data = tensors[0]\n",
    "        self.targets = tensors[1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "train_labels = []\n",
    "for data, labels in train_loader_pca:\n",
    "    train_data.append(data.view(data.size(0), -1))  \n",
    "    train_labels.append(labels)\n",
    "train_data = torch.cat(train_data, dim=0)  \n",
    "train_labels = torch.cat(train_labels, dim=0)\n",
    "\n",
    "train_data_np = train_data.numpy()\n",
    "\n",
    "pca = PCADigitReducer(100)\n",
    "train_data_reduced = pca.fit_transform(train_data_np)  \n",
    "\n",
    "train_data_reconstructed_np = pca.inverse_transform(train_data_reduced) \n",
    "train_data_reconstructed = torch.tensor(train_data_reconstructed_np, dtype=torch.float32)\n",
    "\n",
    "train_data_reconstructed = train_data_reconstructed.view(-1, 1, 28, 28)\n",
    "\n",
    "train_data_reconstructed = (train_data_reconstructed - 0.2860) / 0.3204\n",
    "\n",
    "batch_size_train = train_loader_pca.batch_size\n",
    "train_dataset_pca = CustomTensorDataset(train_data_reconstructed, train_labels)\n",
    "train_loader_reduced_pca = DataLoader(train_dataset_pca, batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.6598843336105347\n",
      "Epoch [2/5], Loss: 0.6293150186538696\n",
      "Epoch [3/5], Loss: 0.6253346800804138\n",
      "Epoch [4/5], Loss: 0.5940108895301819\n",
      "Epoch [5/5], Loss: 0.6230719089508057\n"
     ]
    }
   ],
   "source": [
    "# Autoencoder\n",
    "latent_dim = 100  \n",
    "autoencoder = Autoencoder(latent_dim=latent_dim)\n",
    "auto_criterion = nn.MSELoss()\n",
    "auto_optimizer = optim.Adam(autoencoder.parameters(), lr=1e-3)\n",
    "auto_num_epochs = 5\n",
    "for epoch in range(auto_num_epochs): \n",
    "    for images, _ in train_loader_auto:\n",
    "        auto_optimizer.zero_grad()\n",
    "        reconstructed = autoencoder(images)\n",
    "        loss = auto_criterion(reconstructed, images)  \n",
    "        loss.backward()\n",
    "        auto_optimizer.step()\n",
    "        \n",
    "    print(f\"Epoch [{epoch+1}/5], Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.eval()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "latent_features, labels = reduce_dimensions(train_loader_auto, autoencoder.encoder, device)\n",
    "latent_features = latent_features.detach()\n",
    "\n",
    "reconstructed_images = autoencoder.decoder(latent_features.to(device))  \n",
    "reconstructed_images = reconstructed_images.view(-1, 1, 28, 28)  # Reshape to [batch_size, channels, height, width]\n",
    "\n",
    "reconstructed_dataset = CustomTensorDataset(reconstructed_images.cpu(), labels)  \n",
    "reduced_train_loader_auto = DataLoader(reconstructed_dataset, batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfPartitions = [4, 6, 8, 10]\n",
    "results = {\"classic\": {}, \"pca\": {}, \"autoencoder\": {}}\n",
    "clusteredResults = {\"classic\": {}, \"pca\": {}, \"autoencoder\": {}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingset = fashion_mnist_train_loader.dataset\n",
    "trial_model_strong = MultilayerPerceptron()\n",
    "global_model_classic_strong = MultilayerPerceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with 4 partitions...\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.291763\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 2.188995\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.042720\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 1.865229\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 1.641536\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 1.527857\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 1.497014\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 1.276385\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 1.261366\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 1.204960\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 1.018607\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 1.047656\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.982675\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 0.893204\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 0.923746\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.966124\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.793890\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 0.920538\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 0.740007\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 0.767733\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.737563\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 0.717167\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.700764\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 0.527387\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.622500\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.636444\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.704073\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 0.657193\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.735795\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 0.646610\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.609862\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 0.530015\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.642841\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 0.512312\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.715734\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.587219\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.519808\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 0.566132\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.492170\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 0.673457\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.565137\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 0.537171\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.480415\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 0.391380\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.576755\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.519653\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.623826\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 0.435745\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.585886\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 0.599453\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.609159\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 0.446936\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.563542\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 0.624925\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.532642\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.570418\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.503734\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 0.483793\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.597553\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 0.527175\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.535305\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 0.627928\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.391083\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 0.452914\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.388854\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.542010\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.487611\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 0.511524\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.384973\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 0.498711\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.572485\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 0.472268\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.537839\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 0.503615\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.430456\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.558137\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.435908\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 0.416708\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.420687\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 0.450127\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.502174\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 0.534553\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.507966\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 0.366777\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.287738\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.523494\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.450378\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 0.485945\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.371598\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 0.392804\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.503394\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 0.459482\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.424389\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 0.378237\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.477539\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.387996\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.483845\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 0.431558\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.433646\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 0.354172\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.440995\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 0.346456\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.347843\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 0.360365\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.306264\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.546384\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.450003\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 0.563868\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.520504\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 0.478922\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.380019\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 0.307508\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.365862\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 0.397639\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.449111\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.511657\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.373078\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 0.593148\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.341216\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 0.295403\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.389516\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 0.386643\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.325348\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 0.405815\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.497938\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.358791\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.351926\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 0.496980\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.512199\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 0.521439\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.421055\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 0.386432\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.504851\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 0.481546\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.398664\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.378538\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.411116\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 0.527727\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.487503\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 0.370652\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.397473\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 0.325059\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.379344\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 0.492082\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.426373\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.448140\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.438120\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 0.346637\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.448471\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 0.338032\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.505337\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 0.341757\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.478816\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 0.384300\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.454648\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.409440\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.250961\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 0.288819\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.388980\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 0.368776\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.299919\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 0.446202\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.354929\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 0.354497\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.435053\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.447190\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.460271\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 0.410714\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.431681\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 0.328081\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.284954\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 0.415960\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.306090\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 0.551659\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.459098\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.336885\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.396386\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 0.297500\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.397679\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 0.431103\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.472418\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 0.498164\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.396812\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 0.482866\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.496807\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.307561\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.390397\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 0.386366\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.234313\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 0.385444\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.416419\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 0.461599\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.416156\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 0.393953\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.250468\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.461621\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.367213\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 0.474557\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.394418\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 0.420491\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.407890\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 0.469951\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.402269\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 0.360345\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.417268\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.447197\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.200650\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 0.421264\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.371190\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 0.413280\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.517338\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 0.349293\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.311195\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 0.401967\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.481221\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.304653\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.395547\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 0.221844\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.376209\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 0.414564\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.383487\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 0.408039\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.248960\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 0.310746\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.398910\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.440995\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.374767\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 0.321746\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.349213\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 0.522894\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.458383\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 0.401947\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.566099\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 0.393365\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.327333\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.316863\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.301377\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 0.389587\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.266524\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 0.280456\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.551588\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 0.380349\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.335615\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 0.452377\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.425894\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.391894\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.520069\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 0.368026\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.379239\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 0.359574\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.371524\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 0.382315\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.534893\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 0.339022\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.318791\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.315083\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.323666\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 0.410301\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.437226\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 0.292356\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.359722\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 0.294518\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.305381\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 0.442816\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.362668\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.579047\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.450928\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 0.387708\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.345179\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 0.330888\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.347013\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 0.330550\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.395308\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 0.444161\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.337989\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.424124\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.250036\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 0.468442\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.397491\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 0.336163\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.323115\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 0.372921\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.491508\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 0.300108\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.397246\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.361094\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.278863\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 0.450794\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.269932\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 0.332064\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.356848\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 0.393284\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.282053\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 0.346154\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.336442\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.460399\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.405639\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 0.285503\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.434589\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 0.313974\n",
      "\n",
      "Test set: Avg. loss: 0.3590, Accuracy: 52175/60000 (87%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/23974 (0%)]\tLoss: 2.306381\n",
      "Train Epoch: 1 [1000/23974 (4%)]\tLoss: 2.125592\n",
      "Train Epoch: 1 [2000/23974 (8%)]\tLoss: 1.921805\n",
      "Train Epoch: 1 [3000/23974 (12%)]\tLoss: 1.651607\n",
      "Train Epoch: 1 [4000/23974 (17%)]\tLoss: 1.472449\n",
      "Train Epoch: 1 [5000/23974 (21%)]\tLoss: 1.298263\n",
      "Train Epoch: 1 [6000/23974 (25%)]\tLoss: 1.117951\n",
      "Train Epoch: 1 [7000/23974 (29%)]\tLoss: 1.115288\n",
      "Train Epoch: 1 [8000/23974 (33%)]\tLoss: 0.960989\n",
      "Train Epoch: 1 [9000/23974 (38%)]\tLoss: 0.798675\n",
      "Train Epoch: 1 [10000/23974 (42%)]\tLoss: 0.875257\n",
      "Train Epoch: 1 [11000/23974 (46%)]\tLoss: 0.659458\n",
      "Train Epoch: 1 [12000/23974 (50%)]\tLoss: 0.709653\n",
      "Train Epoch: 1 [13000/23974 (54%)]\tLoss: 0.696002\n",
      "Train Epoch: 1 [14000/23974 (58%)]\tLoss: 0.682567\n",
      "Train Epoch: 1 [15000/23974 (62%)]\tLoss: 0.560522\n",
      "Train Epoch: 1 [16000/23974 (67%)]\tLoss: 0.529703\n",
      "Train Epoch: 1 [17000/23974 (71%)]\tLoss: 0.530096\n",
      "Train Epoch: 1 [18000/23974 (75%)]\tLoss: 0.614151\n",
      "Train Epoch: 1 [19000/23974 (79%)]\tLoss: 0.602824\n",
      "Train Epoch: 1 [20000/23974 (83%)]\tLoss: 0.463495\n",
      "Train Epoch: 1 [21000/23974 (88%)]\tLoss: 0.443145\n",
      "Train Epoch: 1 [22000/23974 (92%)]\tLoss: 0.400267\n",
      "Train Epoch: 1 [23000/23974 (96%)]\tLoss: 0.454364\n",
      "Train Epoch: 2 [0/23974 (0%)]\tLoss: 0.497533\n",
      "Train Epoch: 2 [1000/23974 (4%)]\tLoss: 0.597886\n",
      "Train Epoch: 2 [2000/23974 (8%)]\tLoss: 0.496084\n",
      "Train Epoch: 2 [3000/23974 (12%)]\tLoss: 0.519696\n",
      "Train Epoch: 2 [4000/23974 (17%)]\tLoss: 0.494843\n",
      "Train Epoch: 2 [5000/23974 (21%)]\tLoss: 0.499410\n",
      "Train Epoch: 2 [6000/23974 (25%)]\tLoss: 0.532438\n",
      "Train Epoch: 2 [7000/23974 (29%)]\tLoss: 0.556824\n",
      "Train Epoch: 2 [8000/23974 (33%)]\tLoss: 0.476056\n",
      "Train Epoch: 2 [9000/23974 (38%)]\tLoss: 0.412635\n",
      "Train Epoch: 2 [10000/23974 (42%)]\tLoss: 0.491093\n",
      "Train Epoch: 2 [11000/23974 (46%)]\tLoss: 0.495587\n",
      "Train Epoch: 2 [12000/23974 (50%)]\tLoss: 0.371957\n",
      "Train Epoch: 2 [13000/23974 (54%)]\tLoss: 0.559289\n",
      "Train Epoch: 2 [14000/23974 (58%)]\tLoss: 0.470365\n",
      "Train Epoch: 2 [15000/23974 (62%)]\tLoss: 0.437290\n",
      "Train Epoch: 2 [16000/23974 (67%)]\tLoss: 0.475531\n",
      "Train Epoch: 2 [17000/23974 (71%)]\tLoss: 0.479986\n",
      "Train Epoch: 2 [18000/23974 (75%)]\tLoss: 0.397724\n",
      "Train Epoch: 2 [19000/23974 (79%)]\tLoss: 0.397750\n",
      "Train Epoch: 2 [20000/23974 (83%)]\tLoss: 0.379974\n",
      "Train Epoch: 2 [21000/23974 (88%)]\tLoss: 0.469113\n",
      "Train Epoch: 2 [22000/23974 (92%)]\tLoss: 0.566862\n",
      "Train Epoch: 2 [23000/23974 (96%)]\tLoss: 0.427596\n",
      "Train Epoch: 3 [0/23974 (0%)]\tLoss: 0.450959\n",
      "Train Epoch: 3 [1000/23974 (4%)]\tLoss: 0.429486\n",
      "Train Epoch: 3 [2000/23974 (8%)]\tLoss: 0.457258\n",
      "Train Epoch: 3 [3000/23974 (12%)]\tLoss: 0.531013\n",
      "Train Epoch: 3 [4000/23974 (17%)]\tLoss: 0.510433\n",
      "Train Epoch: 3 [5000/23974 (21%)]\tLoss: 0.432584\n",
      "Train Epoch: 3 [6000/23974 (25%)]\tLoss: 0.469840\n",
      "Train Epoch: 3 [7000/23974 (29%)]\tLoss: 0.320251\n",
      "Train Epoch: 3 [8000/23974 (33%)]\tLoss: 0.366604\n",
      "Train Epoch: 3 [9000/23974 (38%)]\tLoss: 0.282447\n",
      "Train Epoch: 3 [10000/23974 (42%)]\tLoss: 0.518988\n",
      "Train Epoch: 3 [11000/23974 (46%)]\tLoss: 0.540627\n",
      "Train Epoch: 3 [12000/23974 (50%)]\tLoss: 0.549125\n",
      "Train Epoch: 3 [13000/23974 (54%)]\tLoss: 0.372393\n",
      "Train Epoch: 3 [14000/23974 (58%)]\tLoss: 0.359659\n",
      "Train Epoch: 3 [15000/23974 (62%)]\tLoss: 0.443407\n",
      "Train Epoch: 3 [16000/23974 (67%)]\tLoss: 0.377344\n",
      "Train Epoch: 3 [17000/23974 (71%)]\tLoss: 0.568135\n",
      "Train Epoch: 3 [18000/23974 (75%)]\tLoss: 0.320577\n",
      "Train Epoch: 3 [19000/23974 (79%)]\tLoss: 0.515146\n",
      "Train Epoch: 3 [20000/23974 (83%)]\tLoss: 0.430683\n",
      "Train Epoch: 3 [21000/23974 (88%)]\tLoss: 0.336061\n",
      "Train Epoch: 3 [22000/23974 (92%)]\tLoss: 0.392039\n",
      "Train Epoch: 3 [23000/23974 (96%)]\tLoss: 0.415061\n",
      "Train Epoch: 4 [0/23974 (0%)]\tLoss: 0.275678\n",
      "Train Epoch: 4 [1000/23974 (4%)]\tLoss: 0.476605\n",
      "Train Epoch: 4 [2000/23974 (8%)]\tLoss: 0.440454\n",
      "Train Epoch: 4 [3000/23974 (12%)]\tLoss: 0.374869\n",
      "Train Epoch: 4 [4000/23974 (17%)]\tLoss: 0.426453\n",
      "Train Epoch: 4 [5000/23974 (21%)]\tLoss: 0.306476\n",
      "Train Epoch: 4 [6000/23974 (25%)]\tLoss: 0.356226\n",
      "Train Epoch: 4 [7000/23974 (29%)]\tLoss: 0.256721\n",
      "Train Epoch: 4 [8000/23974 (33%)]\tLoss: 0.383606\n",
      "Train Epoch: 4 [9000/23974 (38%)]\tLoss: 0.344664\n",
      "Train Epoch: 4 [10000/23974 (42%)]\tLoss: 0.498881\n",
      "Train Epoch: 4 [11000/23974 (46%)]\tLoss: 0.383263\n",
      "Train Epoch: 4 [12000/23974 (50%)]\tLoss: 0.438902\n",
      "Train Epoch: 4 [13000/23974 (54%)]\tLoss: 0.364009\n",
      "Train Epoch: 4 [14000/23974 (58%)]\tLoss: 0.329844\n",
      "Train Epoch: 4 [15000/23974 (62%)]\tLoss: 0.478497\n",
      "Train Epoch: 4 [16000/23974 (67%)]\tLoss: 0.313498\n",
      "Train Epoch: 4 [17000/23974 (71%)]\tLoss: 0.424518\n",
      "Train Epoch: 4 [18000/23974 (75%)]\tLoss: 0.445908\n",
      "Train Epoch: 4 [19000/23974 (79%)]\tLoss: 0.254140\n",
      "Train Epoch: 4 [20000/23974 (83%)]\tLoss: 0.305761\n",
      "Train Epoch: 4 [21000/23974 (88%)]\tLoss: 0.284239\n",
      "Train Epoch: 4 [22000/23974 (92%)]\tLoss: 0.502512\n",
      "Train Epoch: 4 [23000/23974 (96%)]\tLoss: 0.476677\n",
      "Train Epoch: 5 [0/23974 (0%)]\tLoss: 0.398232\n",
      "Train Epoch: 5 [1000/23974 (4%)]\tLoss: 0.479577\n",
      "Train Epoch: 5 [2000/23974 (8%)]\tLoss: 0.493000\n",
      "Train Epoch: 5 [3000/23974 (12%)]\tLoss: 0.376848\n",
      "Train Epoch: 5 [4000/23974 (17%)]\tLoss: 0.518436\n",
      "Train Epoch: 5 [5000/23974 (21%)]\tLoss: 0.541329\n",
      "Train Epoch: 5 [6000/23974 (25%)]\tLoss: 0.445513\n",
      "Train Epoch: 5 [7000/23974 (29%)]\tLoss: 0.307361\n",
      "Train Epoch: 5 [8000/23974 (33%)]\tLoss: 0.254346\n",
      "Train Epoch: 5 [9000/23974 (38%)]\tLoss: 0.283655\n",
      "Train Epoch: 5 [10000/23974 (42%)]\tLoss: 0.347750\n",
      "Train Epoch: 5 [11000/23974 (46%)]\tLoss: 0.379866\n",
      "Train Epoch: 5 [12000/23974 (50%)]\tLoss: 0.311352\n",
      "Train Epoch: 5 [13000/23974 (54%)]\tLoss: 0.328229\n",
      "Train Epoch: 5 [14000/23974 (58%)]\tLoss: 0.362079\n",
      "Train Epoch: 5 [15000/23974 (62%)]\tLoss: 0.260083\n",
      "Train Epoch: 5 [16000/23974 (67%)]\tLoss: 0.424755\n",
      "Train Epoch: 5 [17000/23974 (71%)]\tLoss: 0.323881\n",
      "Train Epoch: 5 [18000/23974 (75%)]\tLoss: 0.536516\n",
      "Train Epoch: 5 [19000/23974 (79%)]\tLoss: 0.336982\n",
      "Train Epoch: 5 [20000/23974 (83%)]\tLoss: 0.428688\n",
      "Train Epoch: 5 [21000/23974 (88%)]\tLoss: 0.337066\n",
      "Train Epoch: 5 [22000/23974 (92%)]\tLoss: 0.227223\n",
      "Train Epoch: 5 [23000/23974 (96%)]\tLoss: 0.510655\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7961 (0%)]\tLoss: 2.298564\n",
      "Train Epoch: 1 [1000/7961 (12%)]\tLoss: 2.069803\n",
      "Train Epoch: 1 [2000/7961 (25%)]\tLoss: 1.884372\n",
      "Train Epoch: 1 [3000/7961 (38%)]\tLoss: 1.621140\n",
      "Train Epoch: 1 [4000/7961 (50%)]\tLoss: 1.577194\n",
      "Train Epoch: 1 [5000/7961 (62%)]\tLoss: 1.300684\n",
      "Train Epoch: 1 [6000/7961 (75%)]\tLoss: 1.329785\n",
      "Train Epoch: 1 [7000/7961 (88%)]\tLoss: 1.174915\n",
      "Train Epoch: 2 [0/7961 (0%)]\tLoss: 1.273808\n",
      "Train Epoch: 2 [1000/7961 (12%)]\tLoss: 1.150380\n",
      "Train Epoch: 2 [2000/7961 (25%)]\tLoss: 1.061817\n",
      "Train Epoch: 2 [3000/7961 (38%)]\tLoss: 0.889134\n",
      "Train Epoch: 2 [4000/7961 (50%)]\tLoss: 1.151911\n",
      "Train Epoch: 2 [5000/7961 (62%)]\tLoss: 0.859200\n",
      "Train Epoch: 2 [6000/7961 (75%)]\tLoss: 0.717172\n",
      "Train Epoch: 2 [7000/7961 (88%)]\tLoss: 0.873949\n",
      "Train Epoch: 3 [0/7961 (0%)]\tLoss: 0.852253\n",
      "Train Epoch: 3 [1000/7961 (12%)]\tLoss: 0.789187\n",
      "Train Epoch: 3 [2000/7961 (25%)]\tLoss: 0.809888\n",
      "Train Epoch: 3 [3000/7961 (38%)]\tLoss: 0.875550\n",
      "Train Epoch: 3 [4000/7961 (50%)]\tLoss: 0.683579\n",
      "Train Epoch: 3 [5000/7961 (62%)]\tLoss: 0.776673\n",
      "Train Epoch: 3 [6000/7961 (75%)]\tLoss: 0.639746\n",
      "Train Epoch: 3 [7000/7961 (88%)]\tLoss: 0.801065\n",
      "Train Epoch: 4 [0/7961 (0%)]\tLoss: 0.615521\n",
      "Train Epoch: 4 [1000/7961 (12%)]\tLoss: 0.664249\n",
      "Train Epoch: 4 [2000/7961 (25%)]\tLoss: 0.752344\n",
      "Train Epoch: 4 [3000/7961 (38%)]\tLoss: 0.783117\n",
      "Train Epoch: 4 [4000/7961 (50%)]\tLoss: 0.725144\n",
      "Train Epoch: 4 [5000/7961 (62%)]\tLoss: 0.687112\n",
      "Train Epoch: 4 [6000/7961 (75%)]\tLoss: 0.653978\n",
      "Train Epoch: 4 [7000/7961 (88%)]\tLoss: 0.651536\n",
      "Train Epoch: 5 [0/7961 (0%)]\tLoss: 0.585855\n",
      "Train Epoch: 5 [1000/7961 (12%)]\tLoss: 0.667931\n",
      "Train Epoch: 5 [2000/7961 (25%)]\tLoss: 0.572375\n",
      "Train Epoch: 5 [3000/7961 (38%)]\tLoss: 0.689077\n",
      "Train Epoch: 5 [4000/7961 (50%)]\tLoss: 0.530741\n",
      "Train Epoch: 5 [5000/7961 (62%)]\tLoss: 0.688279\n",
      "Train Epoch: 5 [6000/7961 (75%)]\tLoss: 0.516971\n",
      "Train Epoch: 5 [7000/7961 (88%)]\tLoss: 0.609465\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/15584 (0%)]\tLoss: 2.325139\n",
      "Train Epoch: 1 [1000/15584 (6%)]\tLoss: 2.076356\n",
      "Train Epoch: 1 [2000/15584 (13%)]\tLoss: 1.715885\n",
      "Train Epoch: 1 [3000/15584 (19%)]\tLoss: 1.487005\n",
      "Train Epoch: 1 [4000/15584 (26%)]\tLoss: 1.253011\n",
      "Train Epoch: 1 [5000/15584 (32%)]\tLoss: 1.108768\n",
      "Train Epoch: 1 [6000/15584 (38%)]\tLoss: 0.883217\n",
      "Train Epoch: 1 [7000/15584 (45%)]\tLoss: 0.955438\n",
      "Train Epoch: 1 [8000/15584 (51%)]\tLoss: 0.818424\n",
      "Train Epoch: 1 [9000/15584 (58%)]\tLoss: 0.713919\n",
      "Train Epoch: 1 [10000/15584 (64%)]\tLoss: 0.896439\n",
      "Train Epoch: 1 [11000/15584 (71%)]\tLoss: 0.735719\n",
      "Train Epoch: 1 [12000/15584 (77%)]\tLoss: 0.713559\n",
      "Train Epoch: 1 [13000/15584 (83%)]\tLoss: 0.647520\n",
      "Train Epoch: 1 [14000/15584 (90%)]\tLoss: 0.720229\n",
      "Train Epoch: 1 [15000/15584 (96%)]\tLoss: 0.675116\n",
      "Train Epoch: 2 [0/15584 (0%)]\tLoss: 0.626486\n",
      "Train Epoch: 2 [1000/15584 (6%)]\tLoss: 0.535592\n",
      "Train Epoch: 2 [2000/15584 (13%)]\tLoss: 0.732952\n",
      "Train Epoch: 2 [3000/15584 (19%)]\tLoss: 0.643791\n",
      "Train Epoch: 2 [4000/15584 (26%)]\tLoss: 0.571423\n",
      "Train Epoch: 2 [5000/15584 (32%)]\tLoss: 0.663539\n",
      "Train Epoch: 2 [6000/15584 (38%)]\tLoss: 0.484969\n",
      "Train Epoch: 2 [7000/15584 (45%)]\tLoss: 0.648329\n",
      "Train Epoch: 2 [8000/15584 (51%)]\tLoss: 0.426877\n",
      "Train Epoch: 2 [9000/15584 (58%)]\tLoss: 0.584172\n",
      "Train Epoch: 2 [10000/15584 (64%)]\tLoss: 0.424885\n",
      "Train Epoch: 2 [11000/15584 (71%)]\tLoss: 0.450470\n",
      "Train Epoch: 2 [12000/15584 (77%)]\tLoss: 0.489424\n",
      "Train Epoch: 2 [13000/15584 (83%)]\tLoss: 0.558036\n",
      "Train Epoch: 2 [14000/15584 (90%)]\tLoss: 0.681945\n",
      "Train Epoch: 2 [15000/15584 (96%)]\tLoss: 0.504028\n",
      "Train Epoch: 3 [0/15584 (0%)]\tLoss: 0.651303\n",
      "Train Epoch: 3 [1000/15584 (6%)]\tLoss: 0.463693\n",
      "Train Epoch: 3 [2000/15584 (13%)]\tLoss: 0.451106\n",
      "Train Epoch: 3 [3000/15584 (19%)]\tLoss: 0.407662\n",
      "Train Epoch: 3 [4000/15584 (26%)]\tLoss: 0.525856\n",
      "Train Epoch: 3 [5000/15584 (32%)]\tLoss: 0.453677\n",
      "Train Epoch: 3 [6000/15584 (38%)]\tLoss: 0.425208\n",
      "Train Epoch: 3 [7000/15584 (45%)]\tLoss: 0.447838\n",
      "Train Epoch: 3 [8000/15584 (51%)]\tLoss: 0.408564\n",
      "Train Epoch: 3 [9000/15584 (58%)]\tLoss: 0.353056\n",
      "Train Epoch: 3 [10000/15584 (64%)]\tLoss: 0.348590\n",
      "Train Epoch: 3 [11000/15584 (71%)]\tLoss: 0.481055\n",
      "Train Epoch: 3 [12000/15584 (77%)]\tLoss: 0.426665\n",
      "Train Epoch: 3 [13000/15584 (83%)]\tLoss: 0.442224\n",
      "Train Epoch: 3 [14000/15584 (90%)]\tLoss: 0.408476\n",
      "Train Epoch: 3 [15000/15584 (96%)]\tLoss: 0.425424\n",
      "Train Epoch: 4 [0/15584 (0%)]\tLoss: 0.408924\n",
      "Train Epoch: 4 [1000/15584 (6%)]\tLoss: 0.466230\n",
      "Train Epoch: 4 [2000/15584 (13%)]\tLoss: 0.301488\n",
      "Train Epoch: 4 [3000/15584 (19%)]\tLoss: 0.419986\n",
      "Train Epoch: 4 [4000/15584 (26%)]\tLoss: 0.376031\n",
      "Train Epoch: 4 [5000/15584 (32%)]\tLoss: 0.398457\n",
      "Train Epoch: 4 [6000/15584 (38%)]\tLoss: 0.377297\n",
      "Train Epoch: 4 [7000/15584 (45%)]\tLoss: 0.359055\n",
      "Train Epoch: 4 [8000/15584 (51%)]\tLoss: 0.404292\n",
      "Train Epoch: 4 [9000/15584 (58%)]\tLoss: 0.297546\n",
      "Train Epoch: 4 [10000/15584 (64%)]\tLoss: 0.410467\n",
      "Train Epoch: 4 [11000/15584 (71%)]\tLoss: 0.492377\n",
      "Train Epoch: 4 [12000/15584 (77%)]\tLoss: 0.587176\n",
      "Train Epoch: 4 [13000/15584 (83%)]\tLoss: 0.426807\n",
      "Train Epoch: 4 [14000/15584 (90%)]\tLoss: 0.363154\n",
      "Train Epoch: 4 [15000/15584 (96%)]\tLoss: 0.309053\n",
      "Train Epoch: 5 [0/15584 (0%)]\tLoss: 0.434622\n",
      "Train Epoch: 5 [1000/15584 (6%)]\tLoss: 0.395816\n",
      "Train Epoch: 5 [2000/15584 (13%)]\tLoss: 0.347109\n",
      "Train Epoch: 5 [3000/15584 (19%)]\tLoss: 0.535277\n",
      "Train Epoch: 5 [4000/15584 (26%)]\tLoss: 0.350349\n",
      "Train Epoch: 5 [5000/15584 (32%)]\tLoss: 0.436914\n",
      "Train Epoch: 5 [6000/15584 (38%)]\tLoss: 0.227157\n",
      "Train Epoch: 5 [7000/15584 (45%)]\tLoss: 0.339580\n",
      "Train Epoch: 5 [8000/15584 (51%)]\tLoss: 0.235886\n",
      "Train Epoch: 5 [9000/15584 (58%)]\tLoss: 0.364577\n",
      "Train Epoch: 5 [10000/15584 (64%)]\tLoss: 0.399485\n",
      "Train Epoch: 5 [11000/15584 (71%)]\tLoss: 0.444891\n",
      "Train Epoch: 5 [12000/15584 (77%)]\tLoss: 0.353033\n",
      "Train Epoch: 5 [13000/15584 (83%)]\tLoss: 0.455763\n",
      "Train Epoch: 5 [14000/15584 (90%)]\tLoss: 0.312251\n",
      "Train Epoch: 5 [15000/15584 (96%)]\tLoss: 0.260005\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/12481 (0%)]\tLoss: 2.313322\n",
      "Train Epoch: 1 [1000/12481 (8%)]\tLoss: 1.781185\n",
      "Train Epoch: 1 [2000/12481 (16%)]\tLoss: 1.350540\n",
      "Train Epoch: 1 [3000/12481 (24%)]\tLoss: 0.945640\n",
      "Train Epoch: 1 [4000/12481 (32%)]\tLoss: 0.868182\n",
      "Train Epoch: 1 [5000/12481 (40%)]\tLoss: 0.933830\n",
      "Train Epoch: 1 [6000/12481 (48%)]\tLoss: 0.826504\n",
      "Train Epoch: 1 [7000/12481 (56%)]\tLoss: 0.744404\n",
      "Train Epoch: 1 [8000/12481 (64%)]\tLoss: 0.749364\n",
      "Train Epoch: 1 [9000/12481 (72%)]\tLoss: 0.656293\n",
      "Train Epoch: 1 [10000/12481 (80%)]\tLoss: 0.590111\n",
      "Train Epoch: 1 [11000/12481 (88%)]\tLoss: 0.563114\n",
      "Train Epoch: 1 [12000/12481 (96%)]\tLoss: 0.426913\n",
      "Train Epoch: 2 [0/12481 (0%)]\tLoss: 0.549312\n",
      "Train Epoch: 2 [1000/12481 (8%)]\tLoss: 0.515947\n",
      "Train Epoch: 2 [2000/12481 (16%)]\tLoss: 0.413869\n",
      "Train Epoch: 2 [3000/12481 (24%)]\tLoss: 0.407213\n",
      "Train Epoch: 2 [4000/12481 (32%)]\tLoss: 0.539850\n",
      "Train Epoch: 2 [5000/12481 (40%)]\tLoss: 0.460775\n",
      "Train Epoch: 2 [6000/12481 (48%)]\tLoss: 0.493003\n",
      "Train Epoch: 2 [7000/12481 (56%)]\tLoss: 0.507305\n",
      "Train Epoch: 2 [8000/12481 (64%)]\tLoss: 0.480616\n",
      "Train Epoch: 2 [9000/12481 (72%)]\tLoss: 0.326496\n",
      "Train Epoch: 2 [10000/12481 (80%)]\tLoss: 0.460728\n",
      "Train Epoch: 2 [11000/12481 (88%)]\tLoss: 0.345533\n",
      "Train Epoch: 2 [12000/12481 (96%)]\tLoss: 0.553406\n",
      "Train Epoch: 3 [0/12481 (0%)]\tLoss: 0.336103\n",
      "Train Epoch: 3 [1000/12481 (8%)]\tLoss: 0.367188\n",
      "Train Epoch: 3 [2000/12481 (16%)]\tLoss: 0.242745\n",
      "Train Epoch: 3 [3000/12481 (24%)]\tLoss: 0.516952\n",
      "Train Epoch: 3 [4000/12481 (32%)]\tLoss: 0.365514\n",
      "Train Epoch: 3 [5000/12481 (40%)]\tLoss: 0.239243\n",
      "Train Epoch: 3 [6000/12481 (48%)]\tLoss: 0.483006\n",
      "Train Epoch: 3 [7000/12481 (56%)]\tLoss: 0.410973\n",
      "Train Epoch: 3 [8000/12481 (64%)]\tLoss: 0.329309\n",
      "Train Epoch: 3 [9000/12481 (72%)]\tLoss: 0.444466\n",
      "Train Epoch: 3 [10000/12481 (80%)]\tLoss: 0.346155\n",
      "Train Epoch: 3 [11000/12481 (88%)]\tLoss: 0.488394\n",
      "Train Epoch: 3 [12000/12481 (96%)]\tLoss: 0.312105\n",
      "Train Epoch: 4 [0/12481 (0%)]\tLoss: 0.269789\n",
      "Train Epoch: 4 [1000/12481 (8%)]\tLoss: 0.357769\n",
      "Train Epoch: 4 [2000/12481 (16%)]\tLoss: 0.373398\n",
      "Train Epoch: 4 [3000/12481 (24%)]\tLoss: 0.306426\n",
      "Train Epoch: 4 [4000/12481 (32%)]\tLoss: 0.387726\n",
      "Train Epoch: 4 [5000/12481 (40%)]\tLoss: 0.463469\n",
      "Train Epoch: 4 [6000/12481 (48%)]\tLoss: 0.305863\n",
      "Train Epoch: 4 [7000/12481 (56%)]\tLoss: 0.286714\n",
      "Train Epoch: 4 [8000/12481 (64%)]\tLoss: 0.485308\n",
      "Train Epoch: 4 [9000/12481 (72%)]\tLoss: 0.191538\n",
      "Train Epoch: 4 [10000/12481 (80%)]\tLoss: 0.344808\n",
      "Train Epoch: 4 [11000/12481 (88%)]\tLoss: 0.371250\n",
      "Train Epoch: 4 [12000/12481 (96%)]\tLoss: 0.276267\n",
      "Train Epoch: 5 [0/12481 (0%)]\tLoss: 0.311031\n",
      "Train Epoch: 5 [1000/12481 (8%)]\tLoss: 0.360218\n",
      "Train Epoch: 5 [2000/12481 (16%)]\tLoss: 0.234586\n",
      "Train Epoch: 5 [3000/12481 (24%)]\tLoss: 0.470337\n",
      "Train Epoch: 5 [4000/12481 (32%)]\tLoss: 0.279058\n",
      "Train Epoch: 5 [5000/12481 (40%)]\tLoss: 0.297384\n",
      "Train Epoch: 5 [6000/12481 (48%)]\tLoss: 0.277215\n",
      "Train Epoch: 5 [7000/12481 (56%)]\tLoss: 0.249167\n",
      "Train Epoch: 5 [8000/12481 (64%)]\tLoss: 0.209542\n",
      "Train Epoch: 5 [9000/12481 (72%)]\tLoss: 0.317676\n",
      "Train Epoch: 5 [10000/12481 (80%)]\tLoss: 0.297894\n",
      "Train Epoch: 5 [11000/12481 (88%)]\tLoss: 0.283731\n",
      "Train Epoch: 5 [12000/12481 (96%)]\tLoss: 0.357064\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "4\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.6815, Accuracy: 7415/10000 (74%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/23974 (0%)]\tLoss: 0.672559\n",
      "Train Epoch: 1 [1000/23974 (4%)]\tLoss: 0.454082\n",
      "Train Epoch: 1 [2000/23974 (8%)]\tLoss: 0.497731\n",
      "Train Epoch: 1 [3000/23974 (12%)]\tLoss: 0.499138\n",
      "Train Epoch: 1 [4000/23974 (17%)]\tLoss: 0.462998\n",
      "Train Epoch: 1 [5000/23974 (21%)]\tLoss: 0.376054\n",
      "Train Epoch: 1 [6000/23974 (25%)]\tLoss: 0.342004\n",
      "Train Epoch: 1 [7000/23974 (29%)]\tLoss: 0.358216\n",
      "Train Epoch: 1 [8000/23974 (33%)]\tLoss: 0.384178\n",
      "Train Epoch: 1 [9000/23974 (38%)]\tLoss: 0.633569\n",
      "Train Epoch: 1 [10000/23974 (42%)]\tLoss: 0.634906\n",
      "Train Epoch: 1 [11000/23974 (46%)]\tLoss: 0.485512\n",
      "Train Epoch: 1 [12000/23974 (50%)]\tLoss: 0.488397\n",
      "Train Epoch: 1 [13000/23974 (54%)]\tLoss: 0.407143\n",
      "Train Epoch: 1 [14000/23974 (58%)]\tLoss: 0.381366\n",
      "Train Epoch: 1 [15000/23974 (62%)]\tLoss: 0.474339\n",
      "Train Epoch: 1 [16000/23974 (67%)]\tLoss: 0.467773\n",
      "Train Epoch: 1 [17000/23974 (71%)]\tLoss: 0.421645\n",
      "Train Epoch: 1 [18000/23974 (75%)]\tLoss: 0.586170\n",
      "Train Epoch: 1 [19000/23974 (79%)]\tLoss: 0.321330\n",
      "Train Epoch: 1 [20000/23974 (83%)]\tLoss: 0.390364\n",
      "Train Epoch: 1 [21000/23974 (88%)]\tLoss: 0.484485\n",
      "Train Epoch: 1 [22000/23974 (92%)]\tLoss: 0.488973\n",
      "Train Epoch: 1 [23000/23974 (96%)]\tLoss: 0.475356\n",
      "Train Epoch: 2 [0/23974 (0%)]\tLoss: 0.374237\n",
      "Train Epoch: 2 [1000/23974 (4%)]\tLoss: 0.331353\n",
      "Train Epoch: 2 [2000/23974 (8%)]\tLoss: 0.341208\n",
      "Train Epoch: 2 [3000/23974 (12%)]\tLoss: 0.348064\n",
      "Train Epoch: 2 [4000/23974 (17%)]\tLoss: 0.302143\n",
      "Train Epoch: 2 [5000/23974 (21%)]\tLoss: 0.471755\n",
      "Train Epoch: 2 [6000/23974 (25%)]\tLoss: 0.455667\n",
      "Train Epoch: 2 [7000/23974 (29%)]\tLoss: 0.487094\n",
      "Train Epoch: 2 [8000/23974 (33%)]\tLoss: 0.324405\n",
      "Train Epoch: 2 [9000/23974 (38%)]\tLoss: 0.366179\n",
      "Train Epoch: 2 [10000/23974 (42%)]\tLoss: 0.348179\n",
      "Train Epoch: 2 [11000/23974 (46%)]\tLoss: 0.310366\n",
      "Train Epoch: 2 [12000/23974 (50%)]\tLoss: 0.387989\n",
      "Train Epoch: 2 [13000/23974 (54%)]\tLoss: 0.366566\n",
      "Train Epoch: 2 [14000/23974 (58%)]\tLoss: 0.412727\n",
      "Train Epoch: 2 [15000/23974 (62%)]\tLoss: 0.390360\n",
      "Train Epoch: 2 [16000/23974 (67%)]\tLoss: 0.473242\n",
      "Train Epoch: 2 [17000/23974 (71%)]\tLoss: 0.397897\n",
      "Train Epoch: 2 [18000/23974 (75%)]\tLoss: 0.310751\n",
      "Train Epoch: 2 [19000/23974 (79%)]\tLoss: 0.261969\n",
      "Train Epoch: 2 [20000/23974 (83%)]\tLoss: 0.471256\n",
      "Train Epoch: 2 [21000/23974 (88%)]\tLoss: 0.395765\n",
      "Train Epoch: 2 [22000/23974 (92%)]\tLoss: 0.313587\n",
      "Train Epoch: 2 [23000/23974 (96%)]\tLoss: 0.361034\n",
      "Train Epoch: 3 [0/23974 (0%)]\tLoss: 0.492725\n",
      "Train Epoch: 3 [1000/23974 (4%)]\tLoss: 0.442723\n",
      "Train Epoch: 3 [2000/23974 (8%)]\tLoss: 0.386486\n",
      "Train Epoch: 3 [3000/23974 (12%)]\tLoss: 0.531058\n",
      "Train Epoch: 3 [4000/23974 (17%)]\tLoss: 0.484429\n",
      "Train Epoch: 3 [5000/23974 (21%)]\tLoss: 0.322137\n",
      "Train Epoch: 3 [6000/23974 (25%)]\tLoss: 0.304253\n",
      "Train Epoch: 3 [7000/23974 (29%)]\tLoss: 0.299482\n",
      "Train Epoch: 3 [8000/23974 (33%)]\tLoss: 0.369456\n",
      "Train Epoch: 3 [9000/23974 (38%)]\tLoss: 0.286426\n",
      "Train Epoch: 3 [10000/23974 (42%)]\tLoss: 0.549187\n",
      "Train Epoch: 3 [11000/23974 (46%)]\tLoss: 0.384409\n",
      "Train Epoch: 3 [12000/23974 (50%)]\tLoss: 0.348430\n",
      "Train Epoch: 3 [13000/23974 (54%)]\tLoss: 0.368115\n",
      "Train Epoch: 3 [14000/23974 (58%)]\tLoss: 0.420178\n",
      "Train Epoch: 3 [15000/23974 (62%)]\tLoss: 0.370090\n",
      "Train Epoch: 3 [16000/23974 (67%)]\tLoss: 0.225289\n",
      "Train Epoch: 3 [17000/23974 (71%)]\tLoss: 0.269605\n",
      "Train Epoch: 3 [18000/23974 (75%)]\tLoss: 0.382969\n",
      "Train Epoch: 3 [19000/23974 (79%)]\tLoss: 0.406248\n",
      "Train Epoch: 3 [20000/23974 (83%)]\tLoss: 0.266747\n",
      "Train Epoch: 3 [21000/23974 (88%)]\tLoss: 0.415973\n",
      "Train Epoch: 3 [22000/23974 (92%)]\tLoss: 0.436511\n",
      "Train Epoch: 3 [23000/23974 (96%)]\tLoss: 0.279885\n",
      "Train Epoch: 4 [0/23974 (0%)]\tLoss: 0.402349\n",
      "Train Epoch: 4 [1000/23974 (4%)]\tLoss: 0.455420\n",
      "Train Epoch: 4 [2000/23974 (8%)]\tLoss: 0.359162\n",
      "Train Epoch: 4 [3000/23974 (12%)]\tLoss: 0.321081\n",
      "Train Epoch: 4 [4000/23974 (17%)]\tLoss: 0.470901\n",
      "Train Epoch: 4 [5000/23974 (21%)]\tLoss: 0.449901\n",
      "Train Epoch: 4 [6000/23974 (25%)]\tLoss: 0.474168\n",
      "Train Epoch: 4 [7000/23974 (29%)]\tLoss: 0.344510\n",
      "Train Epoch: 4 [8000/23974 (33%)]\tLoss: 0.242495\n",
      "Train Epoch: 4 [9000/23974 (38%)]\tLoss: 0.333859\n",
      "Train Epoch: 4 [10000/23974 (42%)]\tLoss: 0.400143\n",
      "Train Epoch: 4 [11000/23974 (46%)]\tLoss: 0.590337\n",
      "Train Epoch: 4 [12000/23974 (50%)]\tLoss: 0.232471\n",
      "Train Epoch: 4 [13000/23974 (54%)]\tLoss: 0.308406\n",
      "Train Epoch: 4 [14000/23974 (58%)]\tLoss: 0.426045\n",
      "Train Epoch: 4 [15000/23974 (62%)]\tLoss: 0.492917\n",
      "Train Epoch: 4 [16000/23974 (67%)]\tLoss: 0.373363\n",
      "Train Epoch: 4 [17000/23974 (71%)]\tLoss: 0.263874\n",
      "Train Epoch: 4 [18000/23974 (75%)]\tLoss: 0.286893\n",
      "Train Epoch: 4 [19000/23974 (79%)]\tLoss: 0.304561\n",
      "Train Epoch: 4 [20000/23974 (83%)]\tLoss: 0.422410\n",
      "Train Epoch: 4 [21000/23974 (88%)]\tLoss: 0.311239\n",
      "Train Epoch: 4 [22000/23974 (92%)]\tLoss: 0.343359\n",
      "Train Epoch: 4 [23000/23974 (96%)]\tLoss: 0.363394\n",
      "Train Epoch: 5 [0/23974 (0%)]\tLoss: 0.332045\n",
      "Train Epoch: 5 [1000/23974 (4%)]\tLoss: 0.349161\n",
      "Train Epoch: 5 [2000/23974 (8%)]\tLoss: 0.419809\n",
      "Train Epoch: 5 [3000/23974 (12%)]\tLoss: 0.386848\n",
      "Train Epoch: 5 [4000/23974 (17%)]\tLoss: 0.325633\n",
      "Train Epoch: 5 [5000/23974 (21%)]\tLoss: 0.303234\n",
      "Train Epoch: 5 [6000/23974 (25%)]\tLoss: 0.317852\n",
      "Train Epoch: 5 [7000/23974 (29%)]\tLoss: 0.283768\n",
      "Train Epoch: 5 [8000/23974 (33%)]\tLoss: 0.371743\n",
      "Train Epoch: 5 [9000/23974 (38%)]\tLoss: 0.364217\n",
      "Train Epoch: 5 [10000/23974 (42%)]\tLoss: 0.287897\n",
      "Train Epoch: 5 [11000/23974 (46%)]\tLoss: 0.274687\n",
      "Train Epoch: 5 [12000/23974 (50%)]\tLoss: 0.395442\n",
      "Train Epoch: 5 [13000/23974 (54%)]\tLoss: 0.306630\n",
      "Train Epoch: 5 [14000/23974 (58%)]\tLoss: 0.262011\n",
      "Train Epoch: 5 [15000/23974 (62%)]\tLoss: 0.316407\n",
      "Train Epoch: 5 [16000/23974 (67%)]\tLoss: 0.229399\n",
      "Train Epoch: 5 [17000/23974 (71%)]\tLoss: 0.453528\n",
      "Train Epoch: 5 [18000/23974 (75%)]\tLoss: 0.417165\n",
      "Train Epoch: 5 [19000/23974 (79%)]\tLoss: 0.299557\n",
      "Train Epoch: 5 [20000/23974 (83%)]\tLoss: 0.373177\n",
      "Train Epoch: 5 [21000/23974 (88%)]\tLoss: 0.377619\n",
      "Train Epoch: 5 [22000/23974 (92%)]\tLoss: 0.410693\n",
      "Train Epoch: 5 [23000/23974 (96%)]\tLoss: 0.303045\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7961 (0%)]\tLoss: 0.792782\n",
      "Train Epoch: 1 [1000/7961 (12%)]\tLoss: 0.659031\n",
      "Train Epoch: 1 [2000/7961 (25%)]\tLoss: 0.587497\n",
      "Train Epoch: 1 [3000/7961 (38%)]\tLoss: 0.666393\n",
      "Train Epoch: 1 [4000/7961 (50%)]\tLoss: 0.549593\n",
      "Train Epoch: 1 [5000/7961 (62%)]\tLoss: 0.623369\n",
      "Train Epoch: 1 [6000/7961 (75%)]\tLoss: 0.543263\n",
      "Train Epoch: 1 [7000/7961 (88%)]\tLoss: 0.525926\n",
      "Train Epoch: 2 [0/7961 (0%)]\tLoss: 0.570310\n",
      "Train Epoch: 2 [1000/7961 (12%)]\tLoss: 0.485755\n",
      "Train Epoch: 2 [2000/7961 (25%)]\tLoss: 0.531528\n",
      "Train Epoch: 2 [3000/7961 (38%)]\tLoss: 0.401231\n",
      "Train Epoch: 2 [4000/7961 (50%)]\tLoss: 0.591575\n",
      "Train Epoch: 2 [5000/7961 (62%)]\tLoss: 0.457407\n",
      "Train Epoch: 2 [6000/7961 (75%)]\tLoss: 0.606091\n",
      "Train Epoch: 2 [7000/7961 (88%)]\tLoss: 0.595050\n",
      "Train Epoch: 3 [0/7961 (0%)]\tLoss: 0.497971\n",
      "Train Epoch: 3 [1000/7961 (12%)]\tLoss: 0.585217\n",
      "Train Epoch: 3 [2000/7961 (25%)]\tLoss: 0.620935\n",
      "Train Epoch: 3 [3000/7961 (38%)]\tLoss: 0.463277\n",
      "Train Epoch: 3 [4000/7961 (50%)]\tLoss: 0.440660\n",
      "Train Epoch: 3 [5000/7961 (62%)]\tLoss: 0.484462\n",
      "Train Epoch: 3 [6000/7961 (75%)]\tLoss: 0.393514\n",
      "Train Epoch: 3 [7000/7961 (88%)]\tLoss: 0.557404\n",
      "Train Epoch: 4 [0/7961 (0%)]\tLoss: 0.557996\n",
      "Train Epoch: 4 [1000/7961 (12%)]\tLoss: 0.477583\n",
      "Train Epoch: 4 [2000/7961 (25%)]\tLoss: 0.610749\n",
      "Train Epoch: 4 [3000/7961 (38%)]\tLoss: 0.543973\n",
      "Train Epoch: 4 [4000/7961 (50%)]\tLoss: 0.505020\n",
      "Train Epoch: 4 [5000/7961 (62%)]\tLoss: 0.506948\n",
      "Train Epoch: 4 [6000/7961 (75%)]\tLoss: 0.566959\n",
      "Train Epoch: 4 [7000/7961 (88%)]\tLoss: 0.540949\n",
      "Train Epoch: 5 [0/7961 (0%)]\tLoss: 0.425573\n",
      "Train Epoch: 5 [1000/7961 (12%)]\tLoss: 0.578333\n",
      "Train Epoch: 5 [2000/7961 (25%)]\tLoss: 0.357617\n",
      "Train Epoch: 5 [3000/7961 (38%)]\tLoss: 0.462915\n",
      "Train Epoch: 5 [4000/7961 (50%)]\tLoss: 0.539915\n",
      "Train Epoch: 5 [5000/7961 (62%)]\tLoss: 0.495977\n",
      "Train Epoch: 5 [6000/7961 (75%)]\tLoss: 0.530303\n",
      "Train Epoch: 5 [7000/7961 (88%)]\tLoss: 0.413023\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/15584 (0%)]\tLoss: 0.736999\n",
      "Train Epoch: 1 [1000/15584 (6%)]\tLoss: 0.530196\n",
      "Train Epoch: 1 [2000/15584 (13%)]\tLoss: 0.340388\n",
      "Train Epoch: 1 [3000/15584 (19%)]\tLoss: 0.441999\n",
      "Train Epoch: 1 [4000/15584 (26%)]\tLoss: 0.329793\n",
      "Train Epoch: 1 [5000/15584 (32%)]\tLoss: 0.315753\n",
      "Train Epoch: 1 [6000/15584 (38%)]\tLoss: 0.411080\n",
      "Train Epoch: 1 [7000/15584 (45%)]\tLoss: 0.388375\n",
      "Train Epoch: 1 [8000/15584 (51%)]\tLoss: 0.342050\n",
      "Train Epoch: 1 [9000/15584 (58%)]\tLoss: 0.271109\n",
      "Train Epoch: 1 [10000/15584 (64%)]\tLoss: 0.402251\n",
      "Train Epoch: 1 [11000/15584 (71%)]\tLoss: 0.426764\n",
      "Train Epoch: 1 [12000/15584 (77%)]\tLoss: 0.359913\n",
      "Train Epoch: 1 [13000/15584 (83%)]\tLoss: 0.357776\n",
      "Train Epoch: 1 [14000/15584 (90%)]\tLoss: 0.291551\n",
      "Train Epoch: 1 [15000/15584 (96%)]\tLoss: 0.318452\n",
      "Train Epoch: 2 [0/15584 (0%)]\tLoss: 0.390611\n",
      "Train Epoch: 2 [1000/15584 (6%)]\tLoss: 0.356401\n",
      "Train Epoch: 2 [2000/15584 (13%)]\tLoss: 0.433438\n",
      "Train Epoch: 2 [3000/15584 (19%)]\tLoss: 0.467254\n",
      "Train Epoch: 2 [4000/15584 (26%)]\tLoss: 0.259420\n",
      "Train Epoch: 2 [5000/15584 (32%)]\tLoss: 0.394420\n",
      "Train Epoch: 2 [6000/15584 (38%)]\tLoss: 0.252141\n",
      "Train Epoch: 2 [7000/15584 (45%)]\tLoss: 0.341951\n",
      "Train Epoch: 2 [8000/15584 (51%)]\tLoss: 0.345622\n",
      "Train Epoch: 2 [9000/15584 (58%)]\tLoss: 0.459068\n",
      "Train Epoch: 2 [10000/15584 (64%)]\tLoss: 0.331467\n",
      "Train Epoch: 2 [11000/15584 (71%)]\tLoss: 0.316314\n",
      "Train Epoch: 2 [12000/15584 (77%)]\tLoss: 0.343975\n",
      "Train Epoch: 2 [13000/15584 (83%)]\tLoss: 0.379192\n",
      "Train Epoch: 2 [14000/15584 (90%)]\tLoss: 0.236514\n",
      "Train Epoch: 2 [15000/15584 (96%)]\tLoss: 0.273281\n",
      "Train Epoch: 3 [0/15584 (0%)]\tLoss: 0.353139\n",
      "Train Epoch: 3 [1000/15584 (6%)]\tLoss: 0.320908\n",
      "Train Epoch: 3 [2000/15584 (13%)]\tLoss: 0.421433\n",
      "Train Epoch: 3 [3000/15584 (19%)]\tLoss: 0.337371\n",
      "Train Epoch: 3 [4000/15584 (26%)]\tLoss: 0.366851\n",
      "Train Epoch: 3 [5000/15584 (32%)]\tLoss: 0.243379\n",
      "Train Epoch: 3 [6000/15584 (38%)]\tLoss: 0.517405\n",
      "Train Epoch: 3 [7000/15584 (45%)]\tLoss: 0.269592\n",
      "Train Epoch: 3 [8000/15584 (51%)]\tLoss: 0.382953\n",
      "Train Epoch: 3 [9000/15584 (58%)]\tLoss: 0.345095\n",
      "Train Epoch: 3 [10000/15584 (64%)]\tLoss: 0.246020\n",
      "Train Epoch: 3 [11000/15584 (71%)]\tLoss: 0.295561\n",
      "Train Epoch: 3 [12000/15584 (77%)]\tLoss: 0.258050\n",
      "Train Epoch: 3 [13000/15584 (83%)]\tLoss: 0.400053\n",
      "Train Epoch: 3 [14000/15584 (90%)]\tLoss: 0.349720\n",
      "Train Epoch: 3 [15000/15584 (96%)]\tLoss: 0.400763\n",
      "Train Epoch: 4 [0/15584 (0%)]\tLoss: 0.219914\n",
      "Train Epoch: 4 [1000/15584 (6%)]\tLoss: 0.403137\n",
      "Train Epoch: 4 [2000/15584 (13%)]\tLoss: 0.388203\n",
      "Train Epoch: 4 [3000/15584 (19%)]\tLoss: 0.347161\n",
      "Train Epoch: 4 [4000/15584 (26%)]\tLoss: 0.291645\n",
      "Train Epoch: 4 [5000/15584 (32%)]\tLoss: 0.189851\n",
      "Train Epoch: 4 [6000/15584 (38%)]\tLoss: 0.211830\n",
      "Train Epoch: 4 [7000/15584 (45%)]\tLoss: 0.340925\n",
      "Train Epoch: 4 [8000/15584 (51%)]\tLoss: 0.320378\n",
      "Train Epoch: 4 [9000/15584 (58%)]\tLoss: 0.391449\n",
      "Train Epoch: 4 [10000/15584 (64%)]\tLoss: 0.315050\n",
      "Train Epoch: 4 [11000/15584 (71%)]\tLoss: 0.381275\n",
      "Train Epoch: 4 [12000/15584 (77%)]\tLoss: 0.291269\n",
      "Train Epoch: 4 [13000/15584 (83%)]\tLoss: 0.424044\n",
      "Train Epoch: 4 [14000/15584 (90%)]\tLoss: 0.259608\n",
      "Train Epoch: 4 [15000/15584 (96%)]\tLoss: 0.355582\n",
      "Train Epoch: 5 [0/15584 (0%)]\tLoss: 0.198247\n",
      "Train Epoch: 5 [1000/15584 (6%)]\tLoss: 0.316151\n",
      "Train Epoch: 5 [2000/15584 (13%)]\tLoss: 0.309947\n",
      "Train Epoch: 5 [3000/15584 (19%)]\tLoss: 0.210315\n",
      "Train Epoch: 5 [4000/15584 (26%)]\tLoss: 0.373966\n",
      "Train Epoch: 5 [5000/15584 (32%)]\tLoss: 0.413533\n",
      "Train Epoch: 5 [6000/15584 (38%)]\tLoss: 0.145825\n",
      "Train Epoch: 5 [7000/15584 (45%)]\tLoss: 0.228034\n",
      "Train Epoch: 5 [8000/15584 (51%)]\tLoss: 0.275546\n",
      "Train Epoch: 5 [9000/15584 (58%)]\tLoss: 0.267732\n",
      "Train Epoch: 5 [10000/15584 (64%)]\tLoss: 0.312192\n",
      "Train Epoch: 5 [11000/15584 (71%)]\tLoss: 0.372261\n",
      "Train Epoch: 5 [12000/15584 (77%)]\tLoss: 0.274842\n",
      "Train Epoch: 5 [13000/15584 (83%)]\tLoss: 0.273894\n",
      "Train Epoch: 5 [14000/15584 (90%)]\tLoss: 0.303135\n",
      "Train Epoch: 5 [15000/15584 (96%)]\tLoss: 0.287844\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/12481 (0%)]\tLoss: 0.440978\n",
      "Train Epoch: 1 [1000/12481 (8%)]\tLoss: 0.282986\n",
      "Train Epoch: 1 [2000/12481 (16%)]\tLoss: 0.244703\n",
      "Train Epoch: 1 [3000/12481 (24%)]\tLoss: 0.279186\n",
      "Train Epoch: 1 [4000/12481 (32%)]\tLoss: 0.191178\n",
      "Train Epoch: 1 [5000/12481 (40%)]\tLoss: 0.382850\n",
      "Train Epoch: 1 [6000/12481 (48%)]\tLoss: 0.241463\n",
      "Train Epoch: 1 [7000/12481 (56%)]\tLoss: 0.236868\n",
      "Train Epoch: 1 [8000/12481 (64%)]\tLoss: 0.335775\n",
      "Train Epoch: 1 [9000/12481 (72%)]\tLoss: 0.357908\n",
      "Train Epoch: 1 [10000/12481 (80%)]\tLoss: 0.213155\n",
      "Train Epoch: 1 [11000/12481 (88%)]\tLoss: 0.227105\n",
      "Train Epoch: 1 [12000/12481 (96%)]\tLoss: 0.192107\n",
      "Train Epoch: 2 [0/12481 (0%)]\tLoss: 0.345700\n",
      "Train Epoch: 2 [1000/12481 (8%)]\tLoss: 0.261588\n",
      "Train Epoch: 2 [2000/12481 (16%)]\tLoss: 0.235004\n",
      "Train Epoch: 2 [3000/12481 (24%)]\tLoss: 0.242549\n",
      "Train Epoch: 2 [4000/12481 (32%)]\tLoss: 0.186114\n",
      "Train Epoch: 2 [5000/12481 (40%)]\tLoss: 0.177825\n",
      "Train Epoch: 2 [6000/12481 (48%)]\tLoss: 0.293714\n",
      "Train Epoch: 2 [7000/12481 (56%)]\tLoss: 0.194832\n",
      "Train Epoch: 2 [8000/12481 (64%)]\tLoss: 0.257664\n",
      "Train Epoch: 2 [9000/12481 (72%)]\tLoss: 0.311307\n",
      "Train Epoch: 2 [10000/12481 (80%)]\tLoss: 0.298325\n",
      "Train Epoch: 2 [11000/12481 (88%)]\tLoss: 0.183182\n",
      "Train Epoch: 2 [12000/12481 (96%)]\tLoss: 0.237484\n",
      "Train Epoch: 3 [0/12481 (0%)]\tLoss: 0.236305\n",
      "Train Epoch: 3 [1000/12481 (8%)]\tLoss: 0.247562\n",
      "Train Epoch: 3 [2000/12481 (16%)]\tLoss: 0.296411\n",
      "Train Epoch: 3 [3000/12481 (24%)]\tLoss: 0.278210\n",
      "Train Epoch: 3 [4000/12481 (32%)]\tLoss: 0.211419\n",
      "Train Epoch: 3 [5000/12481 (40%)]\tLoss: 0.217256\n",
      "Train Epoch: 3 [6000/12481 (48%)]\tLoss: 0.261339\n",
      "Train Epoch: 3 [7000/12481 (56%)]\tLoss: 0.231943\n",
      "Train Epoch: 3 [8000/12481 (64%)]\tLoss: 0.304715\n",
      "Train Epoch: 3 [9000/12481 (72%)]\tLoss: 0.349266\n",
      "Train Epoch: 3 [10000/12481 (80%)]\tLoss: 0.241762\n",
      "Train Epoch: 3 [11000/12481 (88%)]\tLoss: 0.284461\n",
      "Train Epoch: 3 [12000/12481 (96%)]\tLoss: 0.182685\n",
      "Train Epoch: 4 [0/12481 (0%)]\tLoss: 0.288597\n",
      "Train Epoch: 4 [1000/12481 (8%)]\tLoss: 0.298474\n",
      "Train Epoch: 4 [2000/12481 (16%)]\tLoss: 0.308230\n",
      "Train Epoch: 4 [3000/12481 (24%)]\tLoss: 0.299969\n",
      "Train Epoch: 4 [4000/12481 (32%)]\tLoss: 0.340636\n",
      "Train Epoch: 4 [5000/12481 (40%)]\tLoss: 0.318256\n",
      "Train Epoch: 4 [6000/12481 (48%)]\tLoss: 0.217749\n",
      "Train Epoch: 4 [7000/12481 (56%)]\tLoss: 0.283528\n",
      "Train Epoch: 4 [8000/12481 (64%)]\tLoss: 0.219941\n",
      "Train Epoch: 4 [9000/12481 (72%)]\tLoss: 0.222593\n",
      "Train Epoch: 4 [10000/12481 (80%)]\tLoss: 0.196082\n",
      "Train Epoch: 4 [11000/12481 (88%)]\tLoss: 0.195528\n",
      "Train Epoch: 4 [12000/12481 (96%)]\tLoss: 0.157432\n",
      "Train Epoch: 5 [0/12481 (0%)]\tLoss: 0.163723\n",
      "Train Epoch: 5 [1000/12481 (8%)]\tLoss: 0.215316\n",
      "Train Epoch: 5 [2000/12481 (16%)]\tLoss: 0.320728\n",
      "Train Epoch: 5 [3000/12481 (24%)]\tLoss: 0.202527\n",
      "Train Epoch: 5 [4000/12481 (32%)]\tLoss: 0.214102\n",
      "Train Epoch: 5 [5000/12481 (40%)]\tLoss: 0.134641\n",
      "Train Epoch: 5 [6000/12481 (48%)]\tLoss: 0.280721\n",
      "Train Epoch: 5 [7000/12481 (56%)]\tLoss: 0.270792\n",
      "Train Epoch: 5 [8000/12481 (64%)]\tLoss: 0.262721\n",
      "Train Epoch: 5 [9000/12481 (72%)]\tLoss: 0.160012\n",
      "Train Epoch: 5 [10000/12481 (80%)]\tLoss: 0.211575\n",
      "Train Epoch: 5 [11000/12481 (88%)]\tLoss: 0.285931\n",
      "Train Epoch: 5 [12000/12481 (96%)]\tLoss: 0.183779\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "4\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4994, Accuracy: 8177/10000 (82%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/23974 (0%)]\tLoss: 0.494750\n",
      "Train Epoch: 1 [1000/23974 (4%)]\tLoss: 0.410389\n",
      "Train Epoch: 1 [2000/23974 (8%)]\tLoss: 0.349581\n",
      "Train Epoch: 1 [3000/23974 (12%)]\tLoss: 0.463911\n",
      "Train Epoch: 1 [4000/23974 (17%)]\tLoss: 0.343564\n",
      "Train Epoch: 1 [5000/23974 (21%)]\tLoss: 0.395754\n",
      "Train Epoch: 1 [6000/23974 (25%)]\tLoss: 0.281043\n",
      "Train Epoch: 1 [7000/23974 (29%)]\tLoss: 0.413773\n",
      "Train Epoch: 1 [8000/23974 (33%)]\tLoss: 0.350939\n",
      "Train Epoch: 1 [9000/23974 (38%)]\tLoss: 0.395065\n",
      "Train Epoch: 1 [10000/23974 (42%)]\tLoss: 0.364350\n",
      "Train Epoch: 1 [11000/23974 (46%)]\tLoss: 0.361855\n",
      "Train Epoch: 1 [12000/23974 (50%)]\tLoss: 0.283869\n",
      "Train Epoch: 1 [13000/23974 (54%)]\tLoss: 0.308755\n",
      "Train Epoch: 1 [14000/23974 (58%)]\tLoss: 0.276825\n",
      "Train Epoch: 1 [15000/23974 (62%)]\tLoss: 0.248780\n",
      "Train Epoch: 1 [16000/23974 (67%)]\tLoss: 0.363943\n",
      "Train Epoch: 1 [17000/23974 (71%)]\tLoss: 0.296721\n",
      "Train Epoch: 1 [18000/23974 (75%)]\tLoss: 0.502609\n",
      "Train Epoch: 1 [19000/23974 (79%)]\tLoss: 0.328167\n",
      "Train Epoch: 1 [20000/23974 (83%)]\tLoss: 0.354319\n",
      "Train Epoch: 1 [21000/23974 (88%)]\tLoss: 0.411336\n",
      "Train Epoch: 1 [22000/23974 (92%)]\tLoss: 0.374997\n",
      "Train Epoch: 1 [23000/23974 (96%)]\tLoss: 0.374461\n",
      "Train Epoch: 2 [0/23974 (0%)]\tLoss: 0.446840\n",
      "Train Epoch: 2 [1000/23974 (4%)]\tLoss: 0.247194\n",
      "Train Epoch: 2 [2000/23974 (8%)]\tLoss: 0.316062\n",
      "Train Epoch: 2 [3000/23974 (12%)]\tLoss: 0.361681\n",
      "Train Epoch: 2 [4000/23974 (17%)]\tLoss: 0.317553\n",
      "Train Epoch: 2 [5000/23974 (21%)]\tLoss: 0.297856\n",
      "Train Epoch: 2 [6000/23974 (25%)]\tLoss: 0.417347\n",
      "Train Epoch: 2 [7000/23974 (29%)]\tLoss: 0.305044\n",
      "Train Epoch: 2 [8000/23974 (33%)]\tLoss: 0.373316\n",
      "Train Epoch: 2 [9000/23974 (38%)]\tLoss: 0.304198\n",
      "Train Epoch: 2 [10000/23974 (42%)]\tLoss: 0.356537\n",
      "Train Epoch: 2 [11000/23974 (46%)]\tLoss: 0.323370\n",
      "Train Epoch: 2 [12000/23974 (50%)]\tLoss: 0.254387\n",
      "Train Epoch: 2 [13000/23974 (54%)]\tLoss: 0.326790\n",
      "Train Epoch: 2 [14000/23974 (58%)]\tLoss: 0.207006\n",
      "Train Epoch: 2 [15000/23974 (62%)]\tLoss: 0.277226\n",
      "Train Epoch: 2 [16000/23974 (67%)]\tLoss: 0.349534\n",
      "Train Epoch: 2 [17000/23974 (71%)]\tLoss: 0.246316\n",
      "Train Epoch: 2 [18000/23974 (75%)]\tLoss: 0.317901\n",
      "Train Epoch: 2 [19000/23974 (79%)]\tLoss: 0.392413\n",
      "Train Epoch: 2 [20000/23974 (83%)]\tLoss: 0.340420\n",
      "Train Epoch: 2 [21000/23974 (88%)]\tLoss: 0.453700\n",
      "Train Epoch: 2 [22000/23974 (92%)]\tLoss: 0.298460\n",
      "Train Epoch: 2 [23000/23974 (96%)]\tLoss: 0.346271\n",
      "Train Epoch: 3 [0/23974 (0%)]\tLoss: 0.311861\n",
      "Train Epoch: 3 [1000/23974 (4%)]\tLoss: 0.231770\n",
      "Train Epoch: 3 [2000/23974 (8%)]\tLoss: 0.240331\n",
      "Train Epoch: 3 [3000/23974 (12%)]\tLoss: 0.365323\n",
      "Train Epoch: 3 [4000/23974 (17%)]\tLoss: 0.523214\n",
      "Train Epoch: 3 [5000/23974 (21%)]\tLoss: 0.496131\n",
      "Train Epoch: 3 [6000/23974 (25%)]\tLoss: 0.380670\n",
      "Train Epoch: 3 [7000/23974 (29%)]\tLoss: 0.270023\n",
      "Train Epoch: 3 [8000/23974 (33%)]\tLoss: 0.236216\n",
      "Train Epoch: 3 [9000/23974 (38%)]\tLoss: 0.211667\n",
      "Train Epoch: 3 [10000/23974 (42%)]\tLoss: 0.360425\n",
      "Train Epoch: 3 [11000/23974 (46%)]\tLoss: 0.300256\n",
      "Train Epoch: 3 [12000/23974 (50%)]\tLoss: 0.365315\n",
      "Train Epoch: 3 [13000/23974 (54%)]\tLoss: 0.238896\n",
      "Train Epoch: 3 [14000/23974 (58%)]\tLoss: 0.344703\n",
      "Train Epoch: 3 [15000/23974 (62%)]\tLoss: 0.383420\n",
      "Train Epoch: 3 [16000/23974 (67%)]\tLoss: 0.415872\n",
      "Train Epoch: 3 [17000/23974 (71%)]\tLoss: 0.343700\n",
      "Train Epoch: 3 [18000/23974 (75%)]\tLoss: 0.304695\n",
      "Train Epoch: 3 [19000/23974 (79%)]\tLoss: 0.254276\n",
      "Train Epoch: 3 [20000/23974 (83%)]\tLoss: 0.292126\n",
      "Train Epoch: 3 [21000/23974 (88%)]\tLoss: 0.525524\n",
      "Train Epoch: 3 [22000/23974 (92%)]\tLoss: 0.437612\n",
      "Train Epoch: 3 [23000/23974 (96%)]\tLoss: 0.187615\n",
      "Train Epoch: 4 [0/23974 (0%)]\tLoss: 0.273398\n",
      "Train Epoch: 4 [1000/23974 (4%)]\tLoss: 0.372418\n",
      "Train Epoch: 4 [2000/23974 (8%)]\tLoss: 0.346602\n",
      "Train Epoch: 4 [3000/23974 (12%)]\tLoss: 0.283263\n",
      "Train Epoch: 4 [4000/23974 (17%)]\tLoss: 0.216238\n",
      "Train Epoch: 4 [5000/23974 (21%)]\tLoss: 0.413330\n",
      "Train Epoch: 4 [6000/23974 (25%)]\tLoss: 0.314367\n",
      "Train Epoch: 4 [7000/23974 (29%)]\tLoss: 0.356857\n",
      "Train Epoch: 4 [8000/23974 (33%)]\tLoss: 0.348440\n",
      "Train Epoch: 4 [9000/23974 (38%)]\tLoss: 0.388836\n",
      "Train Epoch: 4 [10000/23974 (42%)]\tLoss: 0.298580\n",
      "Train Epoch: 4 [11000/23974 (46%)]\tLoss: 0.307625\n",
      "Train Epoch: 4 [12000/23974 (50%)]\tLoss: 0.382775\n",
      "Train Epoch: 4 [13000/23974 (54%)]\tLoss: 0.407195\n",
      "Train Epoch: 4 [14000/23974 (58%)]\tLoss: 0.291599\n",
      "Train Epoch: 4 [15000/23974 (62%)]\tLoss: 0.381192\n",
      "Train Epoch: 4 [16000/23974 (67%)]\tLoss: 0.426773\n",
      "Train Epoch: 4 [17000/23974 (71%)]\tLoss: 0.233587\n",
      "Train Epoch: 4 [18000/23974 (75%)]\tLoss: 0.284700\n",
      "Train Epoch: 4 [19000/23974 (79%)]\tLoss: 0.238143\n",
      "Train Epoch: 4 [20000/23974 (83%)]\tLoss: 0.242684\n",
      "Train Epoch: 4 [21000/23974 (88%)]\tLoss: 0.516561\n",
      "Train Epoch: 4 [22000/23974 (92%)]\tLoss: 0.281138\n",
      "Train Epoch: 4 [23000/23974 (96%)]\tLoss: 0.404819\n",
      "Train Epoch: 5 [0/23974 (0%)]\tLoss: 0.219520\n",
      "Train Epoch: 5 [1000/23974 (4%)]\tLoss: 0.358314\n",
      "Train Epoch: 5 [2000/23974 (8%)]\tLoss: 0.290317\n",
      "Train Epoch: 5 [3000/23974 (12%)]\tLoss: 0.444892\n",
      "Train Epoch: 5 [4000/23974 (17%)]\tLoss: 0.293102\n",
      "Train Epoch: 5 [5000/23974 (21%)]\tLoss: 0.368993\n",
      "Train Epoch: 5 [6000/23974 (25%)]\tLoss: 0.346646\n",
      "Train Epoch: 5 [7000/23974 (29%)]\tLoss: 0.161014\n",
      "Train Epoch: 5 [8000/23974 (33%)]\tLoss: 0.250304\n",
      "Train Epoch: 5 [9000/23974 (38%)]\tLoss: 0.254716\n",
      "Train Epoch: 5 [10000/23974 (42%)]\tLoss: 0.340185\n",
      "Train Epoch: 5 [11000/23974 (46%)]\tLoss: 0.251138\n",
      "Train Epoch: 5 [12000/23974 (50%)]\tLoss: 0.231637\n",
      "Train Epoch: 5 [13000/23974 (54%)]\tLoss: 0.277492\n",
      "Train Epoch: 5 [14000/23974 (58%)]\tLoss: 0.275730\n",
      "Train Epoch: 5 [15000/23974 (62%)]\tLoss: 0.369110\n",
      "Train Epoch: 5 [16000/23974 (67%)]\tLoss: 0.235992\n",
      "Train Epoch: 5 [17000/23974 (71%)]\tLoss: 0.221245\n",
      "Train Epoch: 5 [18000/23974 (75%)]\tLoss: 0.382642\n",
      "Train Epoch: 5 [19000/23974 (79%)]\tLoss: 0.295673\n",
      "Train Epoch: 5 [20000/23974 (83%)]\tLoss: 0.262629\n",
      "Train Epoch: 5 [21000/23974 (88%)]\tLoss: 0.283016\n",
      "Train Epoch: 5 [22000/23974 (92%)]\tLoss: 0.259983\n",
      "Train Epoch: 5 [23000/23974 (96%)]\tLoss: 0.312769\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7961 (0%)]\tLoss: 0.669341\n",
      "Train Epoch: 1 [1000/7961 (12%)]\tLoss: 0.438529\n",
      "Train Epoch: 1 [2000/7961 (25%)]\tLoss: 0.445211\n",
      "Train Epoch: 1 [3000/7961 (38%)]\tLoss: 0.695293\n",
      "Train Epoch: 1 [4000/7961 (50%)]\tLoss: 0.546067\n",
      "Train Epoch: 1 [5000/7961 (62%)]\tLoss: 0.417392\n",
      "Train Epoch: 1 [6000/7961 (75%)]\tLoss: 0.447922\n",
      "Train Epoch: 1 [7000/7961 (88%)]\tLoss: 0.535130\n",
      "Train Epoch: 2 [0/7961 (0%)]\tLoss: 0.537673\n",
      "Train Epoch: 2 [1000/7961 (12%)]\tLoss: 0.358629\n",
      "Train Epoch: 2 [2000/7961 (25%)]\tLoss: 0.496009\n",
      "Train Epoch: 2 [3000/7961 (38%)]\tLoss: 0.346877\n",
      "Train Epoch: 2 [4000/7961 (50%)]\tLoss: 0.540137\n",
      "Train Epoch: 2 [5000/7961 (62%)]\tLoss: 0.521704\n",
      "Train Epoch: 2 [6000/7961 (75%)]\tLoss: 0.547044\n",
      "Train Epoch: 2 [7000/7961 (88%)]\tLoss: 0.511872\n",
      "Train Epoch: 3 [0/7961 (0%)]\tLoss: 0.455991\n",
      "Train Epoch: 3 [1000/7961 (12%)]\tLoss: 0.491077\n",
      "Train Epoch: 3 [2000/7961 (25%)]\tLoss: 0.441005\n",
      "Train Epoch: 3 [3000/7961 (38%)]\tLoss: 0.356148\n",
      "Train Epoch: 3 [4000/7961 (50%)]\tLoss: 0.455523\n",
      "Train Epoch: 3 [5000/7961 (62%)]\tLoss: 0.510950\n",
      "Train Epoch: 3 [6000/7961 (75%)]\tLoss: 0.434768\n",
      "Train Epoch: 3 [7000/7961 (88%)]\tLoss: 0.539294\n",
      "Train Epoch: 4 [0/7961 (0%)]\tLoss: 0.307444\n",
      "Train Epoch: 4 [1000/7961 (12%)]\tLoss: 0.404270\n",
      "Train Epoch: 4 [2000/7961 (25%)]\tLoss: 0.350659\n",
      "Train Epoch: 4 [3000/7961 (38%)]\tLoss: 0.368580\n",
      "Train Epoch: 4 [4000/7961 (50%)]\tLoss: 0.498865\n",
      "Train Epoch: 4 [5000/7961 (62%)]\tLoss: 0.361189\n",
      "Train Epoch: 4 [6000/7961 (75%)]\tLoss: 0.519923\n",
      "Train Epoch: 4 [7000/7961 (88%)]\tLoss: 0.355034\n",
      "Train Epoch: 5 [0/7961 (0%)]\tLoss: 0.378390\n",
      "Train Epoch: 5 [1000/7961 (12%)]\tLoss: 0.477393\n",
      "Train Epoch: 5 [2000/7961 (25%)]\tLoss: 0.457590\n",
      "Train Epoch: 5 [3000/7961 (38%)]\tLoss: 0.464444\n",
      "Train Epoch: 5 [4000/7961 (50%)]\tLoss: 0.398588\n",
      "Train Epoch: 5 [5000/7961 (62%)]\tLoss: 0.504359\n",
      "Train Epoch: 5 [6000/7961 (75%)]\tLoss: 0.432145\n",
      "Train Epoch: 5 [7000/7961 (88%)]\tLoss: 0.530136\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/15584 (0%)]\tLoss: 0.530142\n",
      "Train Epoch: 1 [1000/15584 (6%)]\tLoss: 0.271365\n",
      "Train Epoch: 1 [2000/15584 (13%)]\tLoss: 0.268631\n",
      "Train Epoch: 1 [3000/15584 (19%)]\tLoss: 0.324767\n",
      "Train Epoch: 1 [4000/15584 (26%)]\tLoss: 0.401219\n",
      "Train Epoch: 1 [5000/15584 (32%)]\tLoss: 0.349123\n",
      "Train Epoch: 1 [6000/15584 (38%)]\tLoss: 0.238305\n",
      "Train Epoch: 1 [7000/15584 (45%)]\tLoss: 0.259348\n",
      "Train Epoch: 1 [8000/15584 (51%)]\tLoss: 0.257513\n",
      "Train Epoch: 1 [9000/15584 (58%)]\tLoss: 0.287105\n",
      "Train Epoch: 1 [10000/15584 (64%)]\tLoss: 0.324138\n",
      "Train Epoch: 1 [11000/15584 (71%)]\tLoss: 0.306740\n",
      "Train Epoch: 1 [12000/15584 (77%)]\tLoss: 0.361927\n",
      "Train Epoch: 1 [13000/15584 (83%)]\tLoss: 0.454432\n",
      "Train Epoch: 1 [14000/15584 (90%)]\tLoss: 0.440446\n",
      "Train Epoch: 1 [15000/15584 (96%)]\tLoss: 0.406071\n",
      "Train Epoch: 2 [0/15584 (0%)]\tLoss: 0.353898\n",
      "Train Epoch: 2 [1000/15584 (6%)]\tLoss: 0.370392\n",
      "Train Epoch: 2 [2000/15584 (13%)]\tLoss: 0.263299\n",
      "Train Epoch: 2 [3000/15584 (19%)]\tLoss: 0.398977\n",
      "Train Epoch: 2 [4000/15584 (26%)]\tLoss: 0.328517\n",
      "Train Epoch: 2 [5000/15584 (32%)]\tLoss: 0.357823\n",
      "Train Epoch: 2 [6000/15584 (38%)]\tLoss: 0.348727\n",
      "Train Epoch: 2 [7000/15584 (45%)]\tLoss: 0.237037\n",
      "Train Epoch: 2 [8000/15584 (51%)]\tLoss: 0.186399\n",
      "Train Epoch: 2 [9000/15584 (58%)]\tLoss: 0.223321\n",
      "Train Epoch: 2 [10000/15584 (64%)]\tLoss: 0.287202\n",
      "Train Epoch: 2 [11000/15584 (71%)]\tLoss: 0.283339\n",
      "Train Epoch: 2 [12000/15584 (77%)]\tLoss: 0.319016\n",
      "Train Epoch: 2 [13000/15584 (83%)]\tLoss: 0.299494\n",
      "Train Epoch: 2 [14000/15584 (90%)]\tLoss: 0.253054\n",
      "Train Epoch: 2 [15000/15584 (96%)]\tLoss: 0.290574\n",
      "Train Epoch: 3 [0/15584 (0%)]\tLoss: 0.176952\n",
      "Train Epoch: 3 [1000/15584 (6%)]\tLoss: 0.276816\n",
      "Train Epoch: 3 [2000/15584 (13%)]\tLoss: 0.275717\n",
      "Train Epoch: 3 [3000/15584 (19%)]\tLoss: 0.274895\n",
      "Train Epoch: 3 [4000/15584 (26%)]\tLoss: 0.426223\n",
      "Train Epoch: 3 [5000/15584 (32%)]\tLoss: 0.212278\n",
      "Train Epoch: 3 [6000/15584 (38%)]\tLoss: 0.327621\n",
      "Train Epoch: 3 [7000/15584 (45%)]\tLoss: 0.320189\n",
      "Train Epoch: 3 [8000/15584 (51%)]\tLoss: 0.325762\n",
      "Train Epoch: 3 [9000/15584 (58%)]\tLoss: 0.322203\n",
      "Train Epoch: 3 [10000/15584 (64%)]\tLoss: 0.251610\n",
      "Train Epoch: 3 [11000/15584 (71%)]\tLoss: 0.257773\n",
      "Train Epoch: 3 [12000/15584 (77%)]\tLoss: 0.382721\n",
      "Train Epoch: 3 [13000/15584 (83%)]\tLoss: 0.302734\n",
      "Train Epoch: 3 [14000/15584 (90%)]\tLoss: 0.266036\n",
      "Train Epoch: 3 [15000/15584 (96%)]\tLoss: 0.357313\n",
      "Train Epoch: 4 [0/15584 (0%)]\tLoss: 0.395950\n",
      "Train Epoch: 4 [1000/15584 (6%)]\tLoss: 0.306564\n",
      "Train Epoch: 4 [2000/15584 (13%)]\tLoss: 0.186466\n",
      "Train Epoch: 4 [3000/15584 (19%)]\tLoss: 0.315499\n",
      "Train Epoch: 4 [4000/15584 (26%)]\tLoss: 0.306250\n",
      "Train Epoch: 4 [5000/15584 (32%)]\tLoss: 0.212939\n",
      "Train Epoch: 4 [6000/15584 (38%)]\tLoss: 0.293609\n",
      "Train Epoch: 4 [7000/15584 (45%)]\tLoss: 0.300173\n",
      "Train Epoch: 4 [8000/15584 (51%)]\tLoss: 0.316302\n",
      "Train Epoch: 4 [9000/15584 (58%)]\tLoss: 0.216295\n",
      "Train Epoch: 4 [10000/15584 (64%)]\tLoss: 0.237164\n",
      "Train Epoch: 4 [11000/15584 (71%)]\tLoss: 0.301064\n",
      "Train Epoch: 4 [12000/15584 (77%)]\tLoss: 0.381529\n",
      "Train Epoch: 4 [13000/15584 (83%)]\tLoss: 0.239055\n",
      "Train Epoch: 4 [14000/15584 (90%)]\tLoss: 0.324162\n",
      "Train Epoch: 4 [15000/15584 (96%)]\tLoss: 0.266253\n",
      "Train Epoch: 5 [0/15584 (0%)]\tLoss: 0.259326\n",
      "Train Epoch: 5 [1000/15584 (6%)]\tLoss: 0.402304\n",
      "Train Epoch: 5 [2000/15584 (13%)]\tLoss: 0.225811\n",
      "Train Epoch: 5 [3000/15584 (19%)]\tLoss: 0.276735\n",
      "Train Epoch: 5 [4000/15584 (26%)]\tLoss: 0.164904\n",
      "Train Epoch: 5 [5000/15584 (32%)]\tLoss: 0.236530\n",
      "Train Epoch: 5 [6000/15584 (38%)]\tLoss: 0.271138\n",
      "Train Epoch: 5 [7000/15584 (45%)]\tLoss: 0.337901\n",
      "Train Epoch: 5 [8000/15584 (51%)]\tLoss: 0.302248\n",
      "Train Epoch: 5 [9000/15584 (58%)]\tLoss: 0.245672\n",
      "Train Epoch: 5 [10000/15584 (64%)]\tLoss: 0.171826\n",
      "Train Epoch: 5 [11000/15584 (71%)]\tLoss: 0.195341\n",
      "Train Epoch: 5 [12000/15584 (77%)]\tLoss: 0.270622\n",
      "Train Epoch: 5 [13000/15584 (83%)]\tLoss: 0.271171\n",
      "Train Epoch: 5 [14000/15584 (90%)]\tLoss: 0.203149\n",
      "Train Epoch: 5 [15000/15584 (96%)]\tLoss: 0.272825\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/12481 (0%)]\tLoss: 0.213318\n",
      "Train Epoch: 1 [1000/12481 (8%)]\tLoss: 0.290083\n",
      "Train Epoch: 1 [2000/12481 (16%)]\tLoss: 0.279295\n",
      "Train Epoch: 1 [3000/12481 (24%)]\tLoss: 0.251068\n",
      "Train Epoch: 1 [4000/12481 (32%)]\tLoss: 0.349234\n",
      "Train Epoch: 1 [5000/12481 (40%)]\tLoss: 0.189977\n",
      "Train Epoch: 1 [6000/12481 (48%)]\tLoss: 0.238360\n",
      "Train Epoch: 1 [7000/12481 (56%)]\tLoss: 0.197817\n",
      "Train Epoch: 1 [8000/12481 (64%)]\tLoss: 0.137971\n",
      "Train Epoch: 1 [9000/12481 (72%)]\tLoss: 0.284006\n",
      "Train Epoch: 1 [10000/12481 (80%)]\tLoss: 0.251693\n",
      "Train Epoch: 1 [11000/12481 (88%)]\tLoss: 0.256328\n",
      "Train Epoch: 1 [12000/12481 (96%)]\tLoss: 0.140121\n",
      "Train Epoch: 2 [0/12481 (0%)]\tLoss: 0.280219\n",
      "Train Epoch: 2 [1000/12481 (8%)]\tLoss: 0.278638\n",
      "Train Epoch: 2 [2000/12481 (16%)]\tLoss: 0.156059\n",
      "Train Epoch: 2 [3000/12481 (24%)]\tLoss: 0.215742\n",
      "Train Epoch: 2 [4000/12481 (32%)]\tLoss: 0.169954\n",
      "Train Epoch: 2 [5000/12481 (40%)]\tLoss: 0.229753\n",
      "Train Epoch: 2 [6000/12481 (48%)]\tLoss: 0.201350\n",
      "Train Epoch: 2 [7000/12481 (56%)]\tLoss: 0.184181\n",
      "Train Epoch: 2 [8000/12481 (64%)]\tLoss: 0.258464\n",
      "Train Epoch: 2 [9000/12481 (72%)]\tLoss: 0.237721\n",
      "Train Epoch: 2 [10000/12481 (80%)]\tLoss: 0.325116\n",
      "Train Epoch: 2 [11000/12481 (88%)]\tLoss: 0.183405\n",
      "Train Epoch: 2 [12000/12481 (96%)]\tLoss: 0.329040\n",
      "Train Epoch: 3 [0/12481 (0%)]\tLoss: 0.197394\n",
      "Train Epoch: 3 [1000/12481 (8%)]\tLoss: 0.155881\n",
      "Train Epoch: 3 [2000/12481 (16%)]\tLoss: 0.446128\n",
      "Train Epoch: 3 [3000/12481 (24%)]\tLoss: 0.472973\n",
      "Train Epoch: 3 [4000/12481 (32%)]\tLoss: 0.151914\n",
      "Train Epoch: 3 [5000/12481 (40%)]\tLoss: 0.245407\n",
      "Train Epoch: 3 [6000/12481 (48%)]\tLoss: 0.206853\n",
      "Train Epoch: 3 [7000/12481 (56%)]\tLoss: 0.309658\n",
      "Train Epoch: 3 [8000/12481 (64%)]\tLoss: 0.208198\n",
      "Train Epoch: 3 [9000/12481 (72%)]\tLoss: 0.148491\n",
      "Train Epoch: 3 [10000/12481 (80%)]\tLoss: 0.244677\n",
      "Train Epoch: 3 [11000/12481 (88%)]\tLoss: 0.278593\n",
      "Train Epoch: 3 [12000/12481 (96%)]\tLoss: 0.216694\n",
      "Train Epoch: 4 [0/12481 (0%)]\tLoss: 0.180552\n",
      "Train Epoch: 4 [1000/12481 (8%)]\tLoss: 0.238654\n",
      "Train Epoch: 4 [2000/12481 (16%)]\tLoss: 0.169501\n",
      "Train Epoch: 4 [3000/12481 (24%)]\tLoss: 0.180770\n",
      "Train Epoch: 4 [4000/12481 (32%)]\tLoss: 0.343463\n",
      "Train Epoch: 4 [5000/12481 (40%)]\tLoss: 0.149144\n",
      "Train Epoch: 4 [6000/12481 (48%)]\tLoss: 0.147360\n",
      "Train Epoch: 4 [7000/12481 (56%)]\tLoss: 0.200792\n",
      "Train Epoch: 4 [8000/12481 (64%)]\tLoss: 0.209230\n",
      "Train Epoch: 4 [9000/12481 (72%)]\tLoss: 0.256912\n",
      "Train Epoch: 4 [10000/12481 (80%)]\tLoss: 0.200813\n",
      "Train Epoch: 4 [11000/12481 (88%)]\tLoss: 0.252049\n",
      "Train Epoch: 4 [12000/12481 (96%)]\tLoss: 0.278666\n",
      "Train Epoch: 5 [0/12481 (0%)]\tLoss: 0.152044\n",
      "Train Epoch: 5 [1000/12481 (8%)]\tLoss: 0.144630\n",
      "Train Epoch: 5 [2000/12481 (16%)]\tLoss: 0.207710\n",
      "Train Epoch: 5 [3000/12481 (24%)]\tLoss: 0.309825\n",
      "Train Epoch: 5 [4000/12481 (32%)]\tLoss: 0.213966\n",
      "Train Epoch: 5 [5000/12481 (40%)]\tLoss: 0.180497\n",
      "Train Epoch: 5 [6000/12481 (48%)]\tLoss: 0.198847\n",
      "Train Epoch: 5 [7000/12481 (56%)]\tLoss: 0.236488\n",
      "Train Epoch: 5 [8000/12481 (64%)]\tLoss: 0.248107\n",
      "Train Epoch: 5 [9000/12481 (72%)]\tLoss: 0.147323\n",
      "Train Epoch: 5 [10000/12481 (80%)]\tLoss: 0.185282\n",
      "Train Epoch: 5 [11000/12481 (88%)]\tLoss: 0.148598\n",
      "Train Epoch: 5 [12000/12481 (96%)]\tLoss: 0.341593\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "4\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4612, Accuracy: 8354/10000 (84%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/23974 (0%)]\tLoss: 0.383494\n",
      "Train Epoch: 1 [1000/23974 (4%)]\tLoss: 0.319012\n",
      "Train Epoch: 1 [2000/23974 (8%)]\tLoss: 0.336263\n",
      "Train Epoch: 1 [3000/23974 (12%)]\tLoss: 0.293590\n",
      "Train Epoch: 1 [4000/23974 (17%)]\tLoss: 0.353027\n",
      "Train Epoch: 1 [5000/23974 (21%)]\tLoss: 0.404204\n",
      "Train Epoch: 1 [6000/23974 (25%)]\tLoss: 0.432458\n",
      "Train Epoch: 1 [7000/23974 (29%)]\tLoss: 0.376815\n",
      "Train Epoch: 1 [8000/23974 (33%)]\tLoss: 0.378582\n",
      "Train Epoch: 1 [9000/23974 (38%)]\tLoss: 0.382833\n",
      "Train Epoch: 1 [10000/23974 (42%)]\tLoss: 0.307554\n",
      "Train Epoch: 1 [11000/23974 (46%)]\tLoss: 0.148862\n",
      "Train Epoch: 1 [12000/23974 (50%)]\tLoss: 0.344091\n",
      "Train Epoch: 1 [13000/23974 (54%)]\tLoss: 0.376493\n",
      "Train Epoch: 1 [14000/23974 (58%)]\tLoss: 0.276811\n",
      "Train Epoch: 1 [15000/23974 (62%)]\tLoss: 0.243981\n",
      "Train Epoch: 1 [16000/23974 (67%)]\tLoss: 0.452475\n",
      "Train Epoch: 1 [17000/23974 (71%)]\tLoss: 0.410701\n",
      "Train Epoch: 1 [18000/23974 (75%)]\tLoss: 0.367437\n",
      "Train Epoch: 1 [19000/23974 (79%)]\tLoss: 0.350937\n",
      "Train Epoch: 1 [20000/23974 (83%)]\tLoss: 0.175648\n",
      "Train Epoch: 1 [21000/23974 (88%)]\tLoss: 0.402741\n",
      "Train Epoch: 1 [22000/23974 (92%)]\tLoss: 0.172777\n",
      "Train Epoch: 1 [23000/23974 (96%)]\tLoss: 0.370877\n",
      "Train Epoch: 2 [0/23974 (0%)]\tLoss: 0.323420\n",
      "Train Epoch: 2 [1000/23974 (4%)]\tLoss: 0.229373\n",
      "Train Epoch: 2 [2000/23974 (8%)]\tLoss: 0.413296\n",
      "Train Epoch: 2 [3000/23974 (12%)]\tLoss: 0.190162\n",
      "Train Epoch: 2 [4000/23974 (17%)]\tLoss: 0.319774\n",
      "Train Epoch: 2 [5000/23974 (21%)]\tLoss: 0.362240\n",
      "Train Epoch: 2 [6000/23974 (25%)]\tLoss: 0.264887\n",
      "Train Epoch: 2 [7000/23974 (29%)]\tLoss: 0.318264\n",
      "Train Epoch: 2 [8000/23974 (33%)]\tLoss: 0.269648\n",
      "Train Epoch: 2 [9000/23974 (38%)]\tLoss: 0.286845\n",
      "Train Epoch: 2 [10000/23974 (42%)]\tLoss: 0.419635\n",
      "Train Epoch: 2 [11000/23974 (46%)]\tLoss: 0.301770\n",
      "Train Epoch: 2 [12000/23974 (50%)]\tLoss: 0.408822\n",
      "Train Epoch: 2 [13000/23974 (54%)]\tLoss: 0.275633\n",
      "Train Epoch: 2 [14000/23974 (58%)]\tLoss: 0.272491\n",
      "Train Epoch: 2 [15000/23974 (62%)]\tLoss: 0.370252\n",
      "Train Epoch: 2 [16000/23974 (67%)]\tLoss: 0.272274\n",
      "Train Epoch: 2 [17000/23974 (71%)]\tLoss: 0.275069\n",
      "Train Epoch: 2 [18000/23974 (75%)]\tLoss: 0.280370\n",
      "Train Epoch: 2 [19000/23974 (79%)]\tLoss: 0.356373\n",
      "Train Epoch: 2 [20000/23974 (83%)]\tLoss: 0.425848\n",
      "Train Epoch: 2 [21000/23974 (88%)]\tLoss: 0.465594\n",
      "Train Epoch: 2 [22000/23974 (92%)]\tLoss: 0.325321\n",
      "Train Epoch: 2 [23000/23974 (96%)]\tLoss: 0.282047\n",
      "Train Epoch: 3 [0/23974 (0%)]\tLoss: 0.177258\n",
      "Train Epoch: 3 [1000/23974 (4%)]\tLoss: 0.314688\n",
      "Train Epoch: 3 [2000/23974 (8%)]\tLoss: 0.400456\n",
      "Train Epoch: 3 [3000/23974 (12%)]\tLoss: 0.239021\n",
      "Train Epoch: 3 [4000/23974 (17%)]\tLoss: 0.378589\n",
      "Train Epoch: 3 [5000/23974 (21%)]\tLoss: 0.230059\n",
      "Train Epoch: 3 [6000/23974 (25%)]\tLoss: 0.371182\n",
      "Train Epoch: 3 [7000/23974 (29%)]\tLoss: 0.335145\n",
      "Train Epoch: 3 [8000/23974 (33%)]\tLoss: 0.405182\n",
      "Train Epoch: 3 [9000/23974 (38%)]\tLoss: 0.464383\n",
      "Train Epoch: 3 [10000/23974 (42%)]\tLoss: 0.260739\n",
      "Train Epoch: 3 [11000/23974 (46%)]\tLoss: 0.336336\n",
      "Train Epoch: 3 [12000/23974 (50%)]\tLoss: 0.174096\n",
      "Train Epoch: 3 [13000/23974 (54%)]\tLoss: 0.253988\n",
      "Train Epoch: 3 [14000/23974 (58%)]\tLoss: 0.287406\n",
      "Train Epoch: 3 [15000/23974 (62%)]\tLoss: 0.422598\n",
      "Train Epoch: 3 [16000/23974 (67%)]\tLoss: 0.373217\n",
      "Train Epoch: 3 [17000/23974 (71%)]\tLoss: 0.252996\n",
      "Train Epoch: 3 [18000/23974 (75%)]\tLoss: 0.353966\n",
      "Train Epoch: 3 [19000/23974 (79%)]\tLoss: 0.184918\n",
      "Train Epoch: 3 [20000/23974 (83%)]\tLoss: 0.341699\n",
      "Train Epoch: 3 [21000/23974 (88%)]\tLoss: 0.332752\n",
      "Train Epoch: 3 [22000/23974 (92%)]\tLoss: 0.332719\n",
      "Train Epoch: 3 [23000/23974 (96%)]\tLoss: 0.454698\n",
      "Train Epoch: 4 [0/23974 (0%)]\tLoss: 0.354593\n",
      "Train Epoch: 4 [1000/23974 (4%)]\tLoss: 0.291360\n",
      "Train Epoch: 4 [2000/23974 (8%)]\tLoss: 0.377593\n",
      "Train Epoch: 4 [3000/23974 (12%)]\tLoss: 0.422130\n",
      "Train Epoch: 4 [4000/23974 (17%)]\tLoss: 0.279337\n",
      "Train Epoch: 4 [5000/23974 (21%)]\tLoss: 0.534957\n",
      "Train Epoch: 4 [6000/23974 (25%)]\tLoss: 0.254196\n",
      "Train Epoch: 4 [7000/23974 (29%)]\tLoss: 0.323961\n",
      "Train Epoch: 4 [8000/23974 (33%)]\tLoss: 0.363287\n",
      "Train Epoch: 4 [9000/23974 (38%)]\tLoss: 0.322279\n",
      "Train Epoch: 4 [10000/23974 (42%)]\tLoss: 0.295487\n",
      "Train Epoch: 4 [11000/23974 (46%)]\tLoss: 0.274007\n",
      "Train Epoch: 4 [12000/23974 (50%)]\tLoss: 0.214091\n",
      "Train Epoch: 4 [13000/23974 (54%)]\tLoss: 0.266451\n",
      "Train Epoch: 4 [14000/23974 (58%)]\tLoss: 0.283820\n",
      "Train Epoch: 4 [15000/23974 (62%)]\tLoss: 0.329762\n",
      "Train Epoch: 4 [16000/23974 (67%)]\tLoss: 0.435925\n",
      "Train Epoch: 4 [17000/23974 (71%)]\tLoss: 0.405939\n",
      "Train Epoch: 4 [18000/23974 (75%)]\tLoss: 0.262149\n",
      "Train Epoch: 4 [19000/23974 (79%)]\tLoss: 0.245932\n",
      "Train Epoch: 4 [20000/23974 (83%)]\tLoss: 0.217026\n",
      "Train Epoch: 4 [21000/23974 (88%)]\tLoss: 0.450613\n",
      "Train Epoch: 4 [22000/23974 (92%)]\tLoss: 0.290258\n",
      "Train Epoch: 4 [23000/23974 (96%)]\tLoss: 0.206171\n",
      "Train Epoch: 5 [0/23974 (0%)]\tLoss: 0.252165\n",
      "Train Epoch: 5 [1000/23974 (4%)]\tLoss: 0.352075\n",
      "Train Epoch: 5 [2000/23974 (8%)]\tLoss: 0.289930\n",
      "Train Epoch: 5 [3000/23974 (12%)]\tLoss: 0.427299\n",
      "Train Epoch: 5 [4000/23974 (17%)]\tLoss: 0.261675\n",
      "Train Epoch: 5 [5000/23974 (21%)]\tLoss: 0.289699\n",
      "Train Epoch: 5 [6000/23974 (25%)]\tLoss: 0.190031\n",
      "Train Epoch: 5 [7000/23974 (29%)]\tLoss: 0.346381\n",
      "Train Epoch: 5 [8000/23974 (33%)]\tLoss: 0.207651\n",
      "Train Epoch: 5 [9000/23974 (38%)]\tLoss: 0.271149\n",
      "Train Epoch: 5 [10000/23974 (42%)]\tLoss: 0.341065\n",
      "Train Epoch: 5 [11000/23974 (46%)]\tLoss: 0.376769\n",
      "Train Epoch: 5 [12000/23974 (50%)]\tLoss: 0.259474\n",
      "Train Epoch: 5 [13000/23974 (54%)]\tLoss: 0.230006\n",
      "Train Epoch: 5 [14000/23974 (58%)]\tLoss: 0.326920\n",
      "Train Epoch: 5 [15000/23974 (62%)]\tLoss: 0.298654\n",
      "Train Epoch: 5 [16000/23974 (67%)]\tLoss: 0.216468\n",
      "Train Epoch: 5 [17000/23974 (71%)]\tLoss: 0.248118\n",
      "Train Epoch: 5 [18000/23974 (75%)]\tLoss: 0.263981\n",
      "Train Epoch: 5 [19000/23974 (79%)]\tLoss: 0.266918\n",
      "Train Epoch: 5 [20000/23974 (83%)]\tLoss: 0.207609\n",
      "Train Epoch: 5 [21000/23974 (88%)]\tLoss: 0.327600\n",
      "Train Epoch: 5 [22000/23974 (92%)]\tLoss: 0.288305\n",
      "Train Epoch: 5 [23000/23974 (96%)]\tLoss: 0.304074\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7961 (0%)]\tLoss: 0.604770\n",
      "Train Epoch: 1 [1000/7961 (12%)]\tLoss: 0.433952\n",
      "Train Epoch: 1 [2000/7961 (25%)]\tLoss: 0.368447\n",
      "Train Epoch: 1 [3000/7961 (38%)]\tLoss: 0.555644\n",
      "Train Epoch: 1 [4000/7961 (50%)]\tLoss: 0.464810\n",
      "Train Epoch: 1 [5000/7961 (62%)]\tLoss: 0.399715\n",
      "Train Epoch: 1 [6000/7961 (75%)]\tLoss: 0.317314\n",
      "Train Epoch: 1 [7000/7961 (88%)]\tLoss: 0.457321\n",
      "Train Epoch: 2 [0/7961 (0%)]\tLoss: 0.517416\n",
      "Train Epoch: 2 [1000/7961 (12%)]\tLoss: 0.354571\n",
      "Train Epoch: 2 [2000/7961 (25%)]\tLoss: 0.260567\n",
      "Train Epoch: 2 [3000/7961 (38%)]\tLoss: 0.395927\n",
      "Train Epoch: 2 [4000/7961 (50%)]\tLoss: 0.520434\n",
      "Train Epoch: 2 [5000/7961 (62%)]\tLoss: 0.488038\n",
      "Train Epoch: 2 [6000/7961 (75%)]\tLoss: 0.431085\n",
      "Train Epoch: 2 [7000/7961 (88%)]\tLoss: 0.361664\n",
      "Train Epoch: 3 [0/7961 (0%)]\tLoss: 0.341320\n",
      "Train Epoch: 3 [1000/7961 (12%)]\tLoss: 0.422490\n",
      "Train Epoch: 3 [2000/7961 (25%)]\tLoss: 0.474539\n",
      "Train Epoch: 3 [3000/7961 (38%)]\tLoss: 0.339924\n",
      "Train Epoch: 3 [4000/7961 (50%)]\tLoss: 0.516114\n",
      "Train Epoch: 3 [5000/7961 (62%)]\tLoss: 0.237951\n",
      "Train Epoch: 3 [6000/7961 (75%)]\tLoss: 0.455950\n",
      "Train Epoch: 3 [7000/7961 (88%)]\tLoss: 0.260968\n",
      "Train Epoch: 4 [0/7961 (0%)]\tLoss: 0.367092\n",
      "Train Epoch: 4 [1000/7961 (12%)]\tLoss: 0.295788\n",
      "Train Epoch: 4 [2000/7961 (25%)]\tLoss: 0.329299\n",
      "Train Epoch: 4 [3000/7961 (38%)]\tLoss: 0.412648\n",
      "Train Epoch: 4 [4000/7961 (50%)]\tLoss: 0.312489\n",
      "Train Epoch: 4 [5000/7961 (62%)]\tLoss: 0.286131\n",
      "Train Epoch: 4 [6000/7961 (75%)]\tLoss: 0.282240\n",
      "Train Epoch: 4 [7000/7961 (88%)]\tLoss: 0.341010\n",
      "Train Epoch: 5 [0/7961 (0%)]\tLoss: 0.431325\n",
      "Train Epoch: 5 [1000/7961 (12%)]\tLoss: 0.452351\n",
      "Train Epoch: 5 [2000/7961 (25%)]\tLoss: 0.248486\n",
      "Train Epoch: 5 [3000/7961 (38%)]\tLoss: 0.272779\n",
      "Train Epoch: 5 [4000/7961 (50%)]\tLoss: 0.425855\n",
      "Train Epoch: 5 [5000/7961 (62%)]\tLoss: 0.505761\n",
      "Train Epoch: 5 [6000/7961 (75%)]\tLoss: 0.443312\n",
      "Train Epoch: 5 [7000/7961 (88%)]\tLoss: 0.466857\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/15584 (0%)]\tLoss: 0.502187\n",
      "Train Epoch: 1 [1000/15584 (6%)]\tLoss: 0.286090\n",
      "Train Epoch: 1 [2000/15584 (13%)]\tLoss: 0.312642\n",
      "Train Epoch: 1 [3000/15584 (19%)]\tLoss: 0.237689\n",
      "Train Epoch: 1 [4000/15584 (26%)]\tLoss: 0.265192\n",
      "Train Epoch: 1 [5000/15584 (32%)]\tLoss: 0.294228\n",
      "Train Epoch: 1 [6000/15584 (38%)]\tLoss: 0.255014\n",
      "Train Epoch: 1 [7000/15584 (45%)]\tLoss: 0.198738\n",
      "Train Epoch: 1 [8000/15584 (51%)]\tLoss: 0.326756\n",
      "Train Epoch: 1 [9000/15584 (58%)]\tLoss: 0.301747\n",
      "Train Epoch: 1 [10000/15584 (64%)]\tLoss: 0.346971\n",
      "Train Epoch: 1 [11000/15584 (71%)]\tLoss: 0.363408\n",
      "Train Epoch: 1 [12000/15584 (77%)]\tLoss: 0.230656\n",
      "Train Epoch: 1 [13000/15584 (83%)]\tLoss: 0.349529\n",
      "Train Epoch: 1 [14000/15584 (90%)]\tLoss: 0.387868\n",
      "Train Epoch: 1 [15000/15584 (96%)]\tLoss: 0.254569\n",
      "Train Epoch: 2 [0/15584 (0%)]\tLoss: 0.315316\n",
      "Train Epoch: 2 [1000/15584 (6%)]\tLoss: 0.228893\n",
      "Train Epoch: 2 [2000/15584 (13%)]\tLoss: 0.188316\n",
      "Train Epoch: 2 [3000/15584 (19%)]\tLoss: 0.353498\n",
      "Train Epoch: 2 [4000/15584 (26%)]\tLoss: 0.249605\n",
      "Train Epoch: 2 [5000/15584 (32%)]\tLoss: 0.302332\n",
      "Train Epoch: 2 [6000/15584 (38%)]\tLoss: 0.224266\n",
      "Train Epoch: 2 [7000/15584 (45%)]\tLoss: 0.239762\n",
      "Train Epoch: 2 [8000/15584 (51%)]\tLoss: 0.317727\n",
      "Train Epoch: 2 [9000/15584 (58%)]\tLoss: 0.324447\n",
      "Train Epoch: 2 [10000/15584 (64%)]\tLoss: 0.203484\n",
      "Train Epoch: 2 [11000/15584 (71%)]\tLoss: 0.263851\n",
      "Train Epoch: 2 [12000/15584 (77%)]\tLoss: 0.330247\n",
      "Train Epoch: 2 [13000/15584 (83%)]\tLoss: 0.250890\n",
      "Train Epoch: 2 [14000/15584 (90%)]\tLoss: 0.236383\n",
      "Train Epoch: 2 [15000/15584 (96%)]\tLoss: 0.328981\n",
      "Train Epoch: 3 [0/15584 (0%)]\tLoss: 0.227306\n",
      "Train Epoch: 3 [1000/15584 (6%)]\tLoss: 0.285101\n",
      "Train Epoch: 3 [2000/15584 (13%)]\tLoss: 0.242315\n",
      "Train Epoch: 3 [3000/15584 (19%)]\tLoss: 0.286240\n",
      "Train Epoch: 3 [4000/15584 (26%)]\tLoss: 0.228537\n",
      "Train Epoch: 3 [5000/15584 (32%)]\tLoss: 0.204523\n",
      "Train Epoch: 3 [6000/15584 (38%)]\tLoss: 0.281010\n",
      "Train Epoch: 3 [7000/15584 (45%)]\tLoss: 0.279156\n",
      "Train Epoch: 3 [8000/15584 (51%)]\tLoss: 0.346389\n",
      "Train Epoch: 3 [9000/15584 (58%)]\tLoss: 0.274767\n",
      "Train Epoch: 3 [10000/15584 (64%)]\tLoss: 0.338485\n",
      "Train Epoch: 3 [11000/15584 (71%)]\tLoss: 0.290351\n",
      "Train Epoch: 3 [12000/15584 (77%)]\tLoss: 0.359137\n",
      "Train Epoch: 3 [13000/15584 (83%)]\tLoss: 0.146852\n",
      "Train Epoch: 3 [14000/15584 (90%)]\tLoss: 0.249581\n",
      "Train Epoch: 3 [15000/15584 (96%)]\tLoss: 0.241721\n",
      "Train Epoch: 4 [0/15584 (0%)]\tLoss: 0.409534\n",
      "Train Epoch: 4 [1000/15584 (6%)]\tLoss: 0.177854\n",
      "Train Epoch: 4 [2000/15584 (13%)]\tLoss: 0.163751\n",
      "Train Epoch: 4 [3000/15584 (19%)]\tLoss: 0.196194\n",
      "Train Epoch: 4 [4000/15584 (26%)]\tLoss: 0.201122\n",
      "Train Epoch: 4 [5000/15584 (32%)]\tLoss: 0.270563\n",
      "Train Epoch: 4 [6000/15584 (38%)]\tLoss: 0.226315\n",
      "Train Epoch: 4 [7000/15584 (45%)]\tLoss: 0.300778\n",
      "Train Epoch: 4 [8000/15584 (51%)]\tLoss: 0.201161\n",
      "Train Epoch: 4 [9000/15584 (58%)]\tLoss: 0.218381\n",
      "Train Epoch: 4 [10000/15584 (64%)]\tLoss: 0.421309\n",
      "Train Epoch: 4 [11000/15584 (71%)]\tLoss: 0.341861\n",
      "Train Epoch: 4 [12000/15584 (77%)]\tLoss: 0.248495\n",
      "Train Epoch: 4 [13000/15584 (83%)]\tLoss: 0.178457\n",
      "Train Epoch: 4 [14000/15584 (90%)]\tLoss: 0.282115\n",
      "Train Epoch: 4 [15000/15584 (96%)]\tLoss: 0.326032\n",
      "Train Epoch: 5 [0/15584 (0%)]\tLoss: 0.344955\n",
      "Train Epoch: 5 [1000/15584 (6%)]\tLoss: 0.208704\n",
      "Train Epoch: 5 [2000/15584 (13%)]\tLoss: 0.261267\n",
      "Train Epoch: 5 [3000/15584 (19%)]\tLoss: 0.202699\n",
      "Train Epoch: 5 [4000/15584 (26%)]\tLoss: 0.457988\n",
      "Train Epoch: 5 [5000/15584 (32%)]\tLoss: 0.331292\n",
      "Train Epoch: 5 [6000/15584 (38%)]\tLoss: 0.213939\n",
      "Train Epoch: 5 [7000/15584 (45%)]\tLoss: 0.149873\n",
      "Train Epoch: 5 [8000/15584 (51%)]\tLoss: 0.226303\n",
      "Train Epoch: 5 [9000/15584 (58%)]\tLoss: 0.267170\n",
      "Train Epoch: 5 [10000/15584 (64%)]\tLoss: 0.272384\n",
      "Train Epoch: 5 [11000/15584 (71%)]\tLoss: 0.340274\n",
      "Train Epoch: 5 [12000/15584 (77%)]\tLoss: 0.246037\n",
      "Train Epoch: 5 [13000/15584 (83%)]\tLoss: 0.206877\n",
      "Train Epoch: 5 [14000/15584 (90%)]\tLoss: 0.145015\n",
      "Train Epoch: 5 [15000/15584 (96%)]\tLoss: 0.211547\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/12481 (0%)]\tLoss: 0.256359\n",
      "Train Epoch: 1 [1000/12481 (8%)]\tLoss: 0.203673\n",
      "Train Epoch: 1 [2000/12481 (16%)]\tLoss: 0.403570\n",
      "Train Epoch: 1 [3000/12481 (24%)]\tLoss: 0.176749\n",
      "Train Epoch: 1 [4000/12481 (32%)]\tLoss: 0.212228\n",
      "Train Epoch: 1 [5000/12481 (40%)]\tLoss: 0.163388\n",
      "Train Epoch: 1 [6000/12481 (48%)]\tLoss: 0.266267\n",
      "Train Epoch: 1 [7000/12481 (56%)]\tLoss: 0.243237\n",
      "Train Epoch: 1 [8000/12481 (64%)]\tLoss: 0.336849\n",
      "Train Epoch: 1 [9000/12481 (72%)]\tLoss: 0.169869\n",
      "Train Epoch: 1 [10000/12481 (80%)]\tLoss: 0.150681\n",
      "Train Epoch: 1 [11000/12481 (88%)]\tLoss: 0.261301\n",
      "Train Epoch: 1 [12000/12481 (96%)]\tLoss: 0.228755\n",
      "Train Epoch: 2 [0/12481 (0%)]\tLoss: 0.243385\n",
      "Train Epoch: 2 [1000/12481 (8%)]\tLoss: 0.369474\n",
      "Train Epoch: 2 [2000/12481 (16%)]\tLoss: 0.189124\n",
      "Train Epoch: 2 [3000/12481 (24%)]\tLoss: 0.312093\n",
      "Train Epoch: 2 [4000/12481 (32%)]\tLoss: 0.254141\n",
      "Train Epoch: 2 [5000/12481 (40%)]\tLoss: 0.221912\n",
      "Train Epoch: 2 [6000/12481 (48%)]\tLoss: 0.156545\n",
      "Train Epoch: 2 [7000/12481 (56%)]\tLoss: 0.171094\n",
      "Train Epoch: 2 [8000/12481 (64%)]\tLoss: 0.232488\n",
      "Train Epoch: 2 [9000/12481 (72%)]\tLoss: 0.305198\n",
      "Train Epoch: 2 [10000/12481 (80%)]\tLoss: 0.154187\n",
      "Train Epoch: 2 [11000/12481 (88%)]\tLoss: 0.241269\n",
      "Train Epoch: 2 [12000/12481 (96%)]\tLoss: 0.302796\n",
      "Train Epoch: 3 [0/12481 (0%)]\tLoss: 0.231895\n",
      "Train Epoch: 3 [1000/12481 (8%)]\tLoss: 0.212150\n",
      "Train Epoch: 3 [2000/12481 (16%)]\tLoss: 0.272038\n",
      "Train Epoch: 3 [3000/12481 (24%)]\tLoss: 0.283389\n",
      "Train Epoch: 3 [4000/12481 (32%)]\tLoss: 0.175247\n",
      "Train Epoch: 3 [5000/12481 (40%)]\tLoss: 0.220783\n",
      "Train Epoch: 3 [6000/12481 (48%)]\tLoss: 0.338823\n",
      "Train Epoch: 3 [7000/12481 (56%)]\tLoss: 0.184734\n",
      "Train Epoch: 3 [8000/12481 (64%)]\tLoss: 0.237095\n",
      "Train Epoch: 3 [9000/12481 (72%)]\tLoss: 0.132989\n",
      "Train Epoch: 3 [10000/12481 (80%)]\tLoss: 0.289475\n",
      "Train Epoch: 3 [11000/12481 (88%)]\tLoss: 0.149924\n",
      "Train Epoch: 3 [12000/12481 (96%)]\tLoss: 0.208789\n",
      "Train Epoch: 4 [0/12481 (0%)]\tLoss: 0.181864\n",
      "Train Epoch: 4 [1000/12481 (8%)]\tLoss: 0.149433\n",
      "Train Epoch: 4 [2000/12481 (16%)]\tLoss: 0.135328\n",
      "Train Epoch: 4 [3000/12481 (24%)]\tLoss: 0.213831\n",
      "Train Epoch: 4 [4000/12481 (32%)]\tLoss: 0.112181\n",
      "Train Epoch: 4 [5000/12481 (40%)]\tLoss: 0.141332\n",
      "Train Epoch: 4 [6000/12481 (48%)]\tLoss: 0.324497\n",
      "Train Epoch: 4 [7000/12481 (56%)]\tLoss: 0.215308\n",
      "Train Epoch: 4 [8000/12481 (64%)]\tLoss: 0.255954\n",
      "Train Epoch: 4 [9000/12481 (72%)]\tLoss: 0.285337\n",
      "Train Epoch: 4 [10000/12481 (80%)]\tLoss: 0.167988\n",
      "Train Epoch: 4 [11000/12481 (88%)]\tLoss: 0.119982\n",
      "Train Epoch: 4 [12000/12481 (96%)]\tLoss: 0.216466\n",
      "Train Epoch: 5 [0/12481 (0%)]\tLoss: 0.223764\n",
      "Train Epoch: 5 [1000/12481 (8%)]\tLoss: 0.175890\n",
      "Train Epoch: 5 [2000/12481 (16%)]\tLoss: 0.110477\n",
      "Train Epoch: 5 [3000/12481 (24%)]\tLoss: 0.109746\n",
      "Train Epoch: 5 [4000/12481 (32%)]\tLoss: 0.221352\n",
      "Train Epoch: 5 [5000/12481 (40%)]\tLoss: 0.279315\n",
      "Train Epoch: 5 [6000/12481 (48%)]\tLoss: 0.179759\n",
      "Train Epoch: 5 [7000/12481 (56%)]\tLoss: 0.339806\n",
      "Train Epoch: 5 [8000/12481 (64%)]\tLoss: 0.208985\n",
      "Train Epoch: 5 [9000/12481 (72%)]\tLoss: 0.229678\n",
      "Train Epoch: 5 [10000/12481 (80%)]\tLoss: 0.192382\n",
      "Train Epoch: 5 [11000/12481 (88%)]\tLoss: 0.191200\n",
      "Train Epoch: 5 [12000/12481 (96%)]\tLoss: 0.231163\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "4\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4384, Accuracy: 8438/10000 (84%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/23974 (0%)]\tLoss: 0.460944\n",
      "Train Epoch: 1 [1000/23974 (4%)]\tLoss: 0.206027\n",
      "Train Epoch: 1 [2000/23974 (8%)]\tLoss: 0.338654\n",
      "Train Epoch: 1 [3000/23974 (12%)]\tLoss: 0.245403\n",
      "Train Epoch: 1 [4000/23974 (17%)]\tLoss: 0.313527\n",
      "Train Epoch: 1 [5000/23974 (21%)]\tLoss: 0.442905\n",
      "Train Epoch: 1 [6000/23974 (25%)]\tLoss: 0.273952\n",
      "Train Epoch: 1 [7000/23974 (29%)]\tLoss: 0.452854\n",
      "Train Epoch: 1 [8000/23974 (33%)]\tLoss: 0.215729\n",
      "Train Epoch: 1 [9000/23974 (38%)]\tLoss: 0.260677\n",
      "Train Epoch: 1 [10000/23974 (42%)]\tLoss: 0.360068\n",
      "Train Epoch: 1 [11000/23974 (46%)]\tLoss: 0.352359\n",
      "Train Epoch: 1 [12000/23974 (50%)]\tLoss: 0.401966\n",
      "Train Epoch: 1 [13000/23974 (54%)]\tLoss: 0.378208\n",
      "Train Epoch: 1 [14000/23974 (58%)]\tLoss: 0.370309\n",
      "Train Epoch: 1 [15000/23974 (62%)]\tLoss: 0.382400\n",
      "Train Epoch: 1 [16000/23974 (67%)]\tLoss: 0.249130\n",
      "Train Epoch: 1 [17000/23974 (71%)]\tLoss: 0.225856\n",
      "Train Epoch: 1 [18000/23974 (75%)]\tLoss: 0.241546\n",
      "Train Epoch: 1 [19000/23974 (79%)]\tLoss: 0.378490\n",
      "Train Epoch: 1 [20000/23974 (83%)]\tLoss: 0.474901\n",
      "Train Epoch: 1 [21000/23974 (88%)]\tLoss: 0.488715\n",
      "Train Epoch: 1 [22000/23974 (92%)]\tLoss: 0.283379\n",
      "Train Epoch: 1 [23000/23974 (96%)]\tLoss: 0.225687\n",
      "Train Epoch: 2 [0/23974 (0%)]\tLoss: 0.384113\n",
      "Train Epoch: 2 [1000/23974 (4%)]\tLoss: 0.295652\n",
      "Train Epoch: 2 [2000/23974 (8%)]\tLoss: 0.292280\n",
      "Train Epoch: 2 [3000/23974 (12%)]\tLoss: 0.346018\n",
      "Train Epoch: 2 [4000/23974 (17%)]\tLoss: 0.380800\n",
      "Train Epoch: 2 [5000/23974 (21%)]\tLoss: 0.332733\n",
      "Train Epoch: 2 [6000/23974 (25%)]\tLoss: 0.253900\n",
      "Train Epoch: 2 [7000/23974 (29%)]\tLoss: 0.195447\n",
      "Train Epoch: 2 [8000/23974 (33%)]\tLoss: 0.277019\n",
      "Train Epoch: 2 [9000/23974 (38%)]\tLoss: 0.328953\n",
      "Train Epoch: 2 [10000/23974 (42%)]\tLoss: 0.268125\n",
      "Train Epoch: 2 [11000/23974 (46%)]\tLoss: 0.351815\n",
      "Train Epoch: 2 [12000/23974 (50%)]\tLoss: 0.264953\n",
      "Train Epoch: 2 [13000/23974 (54%)]\tLoss: 0.356914\n",
      "Train Epoch: 2 [14000/23974 (58%)]\tLoss: 0.306092\n",
      "Train Epoch: 2 [15000/23974 (62%)]\tLoss: 0.328567\n",
      "Train Epoch: 2 [16000/23974 (67%)]\tLoss: 0.194964\n",
      "Train Epoch: 2 [17000/23974 (71%)]\tLoss: 0.325237\n",
      "Train Epoch: 2 [18000/23974 (75%)]\tLoss: 0.327078\n",
      "Train Epoch: 2 [19000/23974 (79%)]\tLoss: 0.278656\n",
      "Train Epoch: 2 [20000/23974 (83%)]\tLoss: 0.251796\n",
      "Train Epoch: 2 [21000/23974 (88%)]\tLoss: 0.268800\n",
      "Train Epoch: 2 [22000/23974 (92%)]\tLoss: 0.360018\n",
      "Train Epoch: 2 [23000/23974 (96%)]\tLoss: 0.353099\n",
      "Train Epoch: 3 [0/23974 (0%)]\tLoss: 0.281791\n",
      "Train Epoch: 3 [1000/23974 (4%)]\tLoss: 0.399078\n",
      "Train Epoch: 3 [2000/23974 (8%)]\tLoss: 0.309067\n",
      "Train Epoch: 3 [3000/23974 (12%)]\tLoss: 0.363497\n",
      "Train Epoch: 3 [4000/23974 (17%)]\tLoss: 0.199745\n",
      "Train Epoch: 3 [5000/23974 (21%)]\tLoss: 0.393980\n",
      "Train Epoch: 3 [6000/23974 (25%)]\tLoss: 0.266234\n",
      "Train Epoch: 3 [7000/23974 (29%)]\tLoss: 0.256157\n",
      "Train Epoch: 3 [8000/23974 (33%)]\tLoss: 0.282527\n",
      "Train Epoch: 3 [9000/23974 (38%)]\tLoss: 0.375650\n",
      "Train Epoch: 3 [10000/23974 (42%)]\tLoss: 0.224910\n",
      "Train Epoch: 3 [11000/23974 (46%)]\tLoss: 0.190230\n",
      "Train Epoch: 3 [12000/23974 (50%)]\tLoss: 0.264314\n",
      "Train Epoch: 3 [13000/23974 (54%)]\tLoss: 0.426593\n",
      "Train Epoch: 3 [14000/23974 (58%)]\tLoss: 0.321131\n",
      "Train Epoch: 3 [15000/23974 (62%)]\tLoss: 0.362648\n",
      "Train Epoch: 3 [16000/23974 (67%)]\tLoss: 0.358857\n",
      "Train Epoch: 3 [17000/23974 (71%)]\tLoss: 0.344624\n",
      "Train Epoch: 3 [18000/23974 (75%)]\tLoss: 0.344339\n",
      "Train Epoch: 3 [19000/23974 (79%)]\tLoss: 0.375542\n",
      "Train Epoch: 3 [20000/23974 (83%)]\tLoss: 0.420993\n",
      "Train Epoch: 3 [21000/23974 (88%)]\tLoss: 0.228557\n",
      "Train Epoch: 3 [22000/23974 (92%)]\tLoss: 0.258479\n",
      "Train Epoch: 3 [23000/23974 (96%)]\tLoss: 0.280896\n",
      "Train Epoch: 4 [0/23974 (0%)]\tLoss: 0.310637\n",
      "Train Epoch: 4 [1000/23974 (4%)]\tLoss: 0.101707\n",
      "Train Epoch: 4 [2000/23974 (8%)]\tLoss: 0.268277\n",
      "Train Epoch: 4 [3000/23974 (12%)]\tLoss: 0.277683\n",
      "Train Epoch: 4 [4000/23974 (17%)]\tLoss: 0.365931\n",
      "Train Epoch: 4 [5000/23974 (21%)]\tLoss: 0.303693\n",
      "Train Epoch: 4 [6000/23974 (25%)]\tLoss: 0.279882\n",
      "Train Epoch: 4 [7000/23974 (29%)]\tLoss: 0.276201\n",
      "Train Epoch: 4 [8000/23974 (33%)]\tLoss: 0.375712\n",
      "Train Epoch: 4 [9000/23974 (38%)]\tLoss: 0.171729\n",
      "Train Epoch: 4 [10000/23974 (42%)]\tLoss: 0.235198\n",
      "Train Epoch: 4 [11000/23974 (46%)]\tLoss: 0.326506\n",
      "Train Epoch: 4 [12000/23974 (50%)]\tLoss: 0.332997\n",
      "Train Epoch: 4 [13000/23974 (54%)]\tLoss: 0.299660\n",
      "Train Epoch: 4 [14000/23974 (58%)]\tLoss: 0.242419\n",
      "Train Epoch: 4 [15000/23974 (62%)]\tLoss: 0.231588\n",
      "Train Epoch: 4 [16000/23974 (67%)]\tLoss: 0.353618\n",
      "Train Epoch: 4 [17000/23974 (71%)]\tLoss: 0.327506\n",
      "Train Epoch: 4 [18000/23974 (75%)]\tLoss: 0.176382\n",
      "Train Epoch: 4 [19000/23974 (79%)]\tLoss: 0.381465\n",
      "Train Epoch: 4 [20000/23974 (83%)]\tLoss: 0.283658\n",
      "Train Epoch: 4 [21000/23974 (88%)]\tLoss: 0.208255\n",
      "Train Epoch: 4 [22000/23974 (92%)]\tLoss: 0.208388\n",
      "Train Epoch: 4 [23000/23974 (96%)]\tLoss: 0.313233\n",
      "Train Epoch: 5 [0/23974 (0%)]\tLoss: 0.288476\n",
      "Train Epoch: 5 [1000/23974 (4%)]\tLoss: 0.217412\n",
      "Train Epoch: 5 [2000/23974 (8%)]\tLoss: 0.224660\n",
      "Train Epoch: 5 [3000/23974 (12%)]\tLoss: 0.186128\n",
      "Train Epoch: 5 [4000/23974 (17%)]\tLoss: 0.462318\n",
      "Train Epoch: 5 [5000/23974 (21%)]\tLoss: 0.259254\n",
      "Train Epoch: 5 [6000/23974 (25%)]\tLoss: 0.204964\n",
      "Train Epoch: 5 [7000/23974 (29%)]\tLoss: 0.216165\n",
      "Train Epoch: 5 [8000/23974 (33%)]\tLoss: 0.200569\n",
      "Train Epoch: 5 [9000/23974 (38%)]\tLoss: 0.276671\n",
      "Train Epoch: 5 [10000/23974 (42%)]\tLoss: 0.240674\n",
      "Train Epoch: 5 [11000/23974 (46%)]\tLoss: 0.233988\n",
      "Train Epoch: 5 [12000/23974 (50%)]\tLoss: 0.265874\n",
      "Train Epoch: 5 [13000/23974 (54%)]\tLoss: 0.241892\n",
      "Train Epoch: 5 [14000/23974 (58%)]\tLoss: 0.212256\n",
      "Train Epoch: 5 [15000/23974 (62%)]\tLoss: 0.202906\n",
      "Train Epoch: 5 [16000/23974 (67%)]\tLoss: 0.356597\n",
      "Train Epoch: 5 [17000/23974 (71%)]\tLoss: 0.267574\n",
      "Train Epoch: 5 [18000/23974 (75%)]\tLoss: 0.261411\n",
      "Train Epoch: 5 [19000/23974 (79%)]\tLoss: 0.208542\n",
      "Train Epoch: 5 [20000/23974 (83%)]\tLoss: 0.396574\n",
      "Train Epoch: 5 [21000/23974 (88%)]\tLoss: 0.186917\n",
      "Train Epoch: 5 [22000/23974 (92%)]\tLoss: 0.314693\n",
      "Train Epoch: 5 [23000/23974 (96%)]\tLoss: 0.290697\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7961 (0%)]\tLoss: 0.471538\n",
      "Train Epoch: 1 [1000/7961 (12%)]\tLoss: 0.469422\n",
      "Train Epoch: 1 [2000/7961 (25%)]\tLoss: 0.592716\n",
      "Train Epoch: 1 [3000/7961 (38%)]\tLoss: 0.499164\n",
      "Train Epoch: 1 [4000/7961 (50%)]\tLoss: 0.419482\n",
      "Train Epoch: 1 [5000/7961 (62%)]\tLoss: 0.445211\n",
      "Train Epoch: 1 [6000/7961 (75%)]\tLoss: 0.445333\n",
      "Train Epoch: 1 [7000/7961 (88%)]\tLoss: 0.297495\n",
      "Train Epoch: 2 [0/7961 (0%)]\tLoss: 0.388938\n",
      "Train Epoch: 2 [1000/7961 (12%)]\tLoss: 0.539668\n",
      "Train Epoch: 2 [2000/7961 (25%)]\tLoss: 0.311562\n",
      "Train Epoch: 2 [3000/7961 (38%)]\tLoss: 0.478736\n",
      "Train Epoch: 2 [4000/7961 (50%)]\tLoss: 0.315509\n",
      "Train Epoch: 2 [5000/7961 (62%)]\tLoss: 0.348605\n",
      "Train Epoch: 2 [6000/7961 (75%)]\tLoss: 0.406014\n",
      "Train Epoch: 2 [7000/7961 (88%)]\tLoss: 0.348848\n",
      "Train Epoch: 3 [0/7961 (0%)]\tLoss: 0.413644\n",
      "Train Epoch: 3 [1000/7961 (12%)]\tLoss: 0.586576\n",
      "Train Epoch: 3 [2000/7961 (25%)]\tLoss: 0.387874\n",
      "Train Epoch: 3 [3000/7961 (38%)]\tLoss: 0.353832\n",
      "Train Epoch: 3 [4000/7961 (50%)]\tLoss: 0.413771\n",
      "Train Epoch: 3 [5000/7961 (62%)]\tLoss: 0.322523\n",
      "Train Epoch: 3 [6000/7961 (75%)]\tLoss: 0.416000\n",
      "Train Epoch: 3 [7000/7961 (88%)]\tLoss: 0.297277\n",
      "Train Epoch: 4 [0/7961 (0%)]\tLoss: 0.510418\n",
      "Train Epoch: 4 [1000/7961 (12%)]\tLoss: 0.262302\n",
      "Train Epoch: 4 [2000/7961 (25%)]\tLoss: 0.399045\n",
      "Train Epoch: 4 [3000/7961 (38%)]\tLoss: 0.379004\n",
      "Train Epoch: 4 [4000/7961 (50%)]\tLoss: 0.401338\n",
      "Train Epoch: 4 [5000/7961 (62%)]\tLoss: 0.490408\n",
      "Train Epoch: 4 [6000/7961 (75%)]\tLoss: 0.303305\n",
      "Train Epoch: 4 [7000/7961 (88%)]\tLoss: 0.293590\n",
      "Train Epoch: 5 [0/7961 (0%)]\tLoss: 0.351899\n",
      "Train Epoch: 5 [1000/7961 (12%)]\tLoss: 0.354506\n",
      "Train Epoch: 5 [2000/7961 (25%)]\tLoss: 0.302763\n",
      "Train Epoch: 5 [3000/7961 (38%)]\tLoss: 0.358658\n",
      "Train Epoch: 5 [4000/7961 (50%)]\tLoss: 0.322755\n",
      "Train Epoch: 5 [5000/7961 (62%)]\tLoss: 0.377375\n",
      "Train Epoch: 5 [6000/7961 (75%)]\tLoss: 0.312361\n",
      "Train Epoch: 5 [7000/7961 (88%)]\tLoss: 0.287251\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "4\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4370, Accuracy: 8490/10000 (85%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/23974 (0%)]\tLoss: 0.247994\n",
      "Train Epoch: 1 [1000/23974 (4%)]\tLoss: 0.305939\n",
      "Train Epoch: 1 [2000/23974 (8%)]\tLoss: 0.176179\n",
      "Train Epoch: 1 [3000/23974 (12%)]\tLoss: 0.199846\n",
      "Train Epoch: 1 [4000/23974 (17%)]\tLoss: 0.218106\n",
      "Train Epoch: 1 [5000/23974 (21%)]\tLoss: 0.289043\n",
      "Train Epoch: 1 [6000/23974 (25%)]\tLoss: 0.287602\n",
      "Train Epoch: 1 [7000/23974 (29%)]\tLoss: 0.319112\n",
      "Train Epoch: 1 [8000/23974 (33%)]\tLoss: 0.204849\n",
      "Train Epoch: 1 [9000/23974 (38%)]\tLoss: 0.220618\n",
      "Train Epoch: 1 [10000/23974 (42%)]\tLoss: 0.151353\n",
      "Train Epoch: 1 [11000/23974 (46%)]\tLoss: 0.245390\n",
      "Train Epoch: 1 [12000/23974 (50%)]\tLoss: 0.267728\n",
      "Train Epoch: 1 [13000/23974 (54%)]\tLoss: 0.249601\n",
      "Train Epoch: 1 [14000/23974 (58%)]\tLoss: 0.312629\n",
      "Train Epoch: 1 [15000/23974 (62%)]\tLoss: 0.342538\n",
      "Train Epoch: 1 [16000/23974 (67%)]\tLoss: 0.233847\n",
      "Train Epoch: 1 [17000/23974 (71%)]\tLoss: 0.380452\n",
      "Train Epoch: 1 [18000/23974 (75%)]\tLoss: 0.172486\n",
      "Train Epoch: 1 [19000/23974 (79%)]\tLoss: 0.230555\n",
      "Train Epoch: 1 [20000/23974 (83%)]\tLoss: 0.221351\n",
      "Train Epoch: 1 [21000/23974 (88%)]\tLoss: 0.211444\n",
      "Train Epoch: 1 [22000/23974 (92%)]\tLoss: 0.396759\n",
      "Train Epoch: 1 [23000/23974 (96%)]\tLoss: 0.295713\n",
      "Train Epoch: 2 [0/23974 (0%)]\tLoss: 0.371130\n",
      "Train Epoch: 2 [1000/23974 (4%)]\tLoss: 0.238774\n",
      "Train Epoch: 2 [2000/23974 (8%)]\tLoss: 0.237009\n",
      "Train Epoch: 2 [3000/23974 (12%)]\tLoss: 0.358746\n",
      "Train Epoch: 2 [4000/23974 (17%)]\tLoss: 0.365081\n",
      "Train Epoch: 2 [5000/23974 (21%)]\tLoss: 0.367563\n",
      "Train Epoch: 2 [6000/23974 (25%)]\tLoss: 0.291546\n",
      "Train Epoch: 2 [7000/23974 (29%)]\tLoss: 0.325933\n",
      "Train Epoch: 2 [8000/23974 (33%)]\tLoss: 0.403486\n",
      "Train Epoch: 2 [9000/23974 (38%)]\tLoss: 0.177200\n",
      "Train Epoch: 2 [10000/23974 (42%)]\tLoss: 0.308417\n",
      "Train Epoch: 2 [11000/23974 (46%)]\tLoss: 0.210112\n",
      "Train Epoch: 2 [12000/23974 (50%)]\tLoss: 0.248735\n",
      "Train Epoch: 2 [13000/23974 (54%)]\tLoss: 0.200548\n",
      "Train Epoch: 2 [14000/23974 (58%)]\tLoss: 0.316070\n",
      "Train Epoch: 2 [15000/23974 (62%)]\tLoss: 0.171049\n",
      "Train Epoch: 2 [16000/23974 (67%)]\tLoss: 0.273796\n",
      "Train Epoch: 2 [17000/23974 (71%)]\tLoss: 0.130485\n",
      "Train Epoch: 2 [18000/23974 (75%)]\tLoss: 0.304091\n",
      "Train Epoch: 2 [19000/23974 (79%)]\tLoss: 0.276479\n",
      "Train Epoch: 2 [20000/23974 (83%)]\tLoss: 0.159270\n",
      "Train Epoch: 2 [21000/23974 (88%)]\tLoss: 0.366179\n",
      "Train Epoch: 2 [22000/23974 (92%)]\tLoss: 0.310684\n",
      "Train Epoch: 2 [23000/23974 (96%)]\tLoss: 0.223459\n",
      "Train Epoch: 3 [0/23974 (0%)]\tLoss: 0.238651\n",
      "Train Epoch: 3 [1000/23974 (4%)]\tLoss: 0.266008\n",
      "Train Epoch: 3 [2000/23974 (8%)]\tLoss: 0.206664\n",
      "Train Epoch: 3 [3000/23974 (12%)]\tLoss: 0.290433\n",
      "Train Epoch: 3 [4000/23974 (17%)]\tLoss: 0.338410\n",
      "Train Epoch: 3 [5000/23974 (21%)]\tLoss: 0.308036\n",
      "Train Epoch: 3 [6000/23974 (25%)]\tLoss: 0.249398\n",
      "Train Epoch: 3 [7000/23974 (29%)]\tLoss: 0.129113\n",
      "Train Epoch: 3 [8000/23974 (33%)]\tLoss: 0.318546\n",
      "Train Epoch: 3 [9000/23974 (38%)]\tLoss: 0.164092\n",
      "Train Epoch: 3 [10000/23974 (42%)]\tLoss: 0.315493\n",
      "Train Epoch: 3 [11000/23974 (46%)]\tLoss: 0.305220\n",
      "Train Epoch: 3 [12000/23974 (50%)]\tLoss: 0.236662\n",
      "Train Epoch: 3 [13000/23974 (54%)]\tLoss: 0.364767\n",
      "Train Epoch: 3 [14000/23974 (58%)]\tLoss: 0.231738\n",
      "Train Epoch: 3 [15000/23974 (62%)]\tLoss: 0.280198\n",
      "Train Epoch: 3 [16000/23974 (67%)]\tLoss: 0.327399\n",
      "Train Epoch: 3 [17000/23974 (71%)]\tLoss: 0.326226\n",
      "Train Epoch: 3 [18000/23974 (75%)]\tLoss: 0.244009\n",
      "Train Epoch: 3 [19000/23974 (79%)]\tLoss: 0.268974\n",
      "Train Epoch: 3 [20000/23974 (83%)]\tLoss: 0.277685\n",
      "Train Epoch: 3 [21000/23974 (88%)]\tLoss: 0.263552\n",
      "Train Epoch: 3 [22000/23974 (92%)]\tLoss: 0.212391\n",
      "Train Epoch: 3 [23000/23974 (96%)]\tLoss: 0.270821\n",
      "Train Epoch: 4 [0/23974 (0%)]\tLoss: 0.261390\n",
      "Train Epoch: 4 [1000/23974 (4%)]\tLoss: 0.311194\n",
      "Train Epoch: 4 [2000/23974 (8%)]\tLoss: 0.266470\n",
      "Train Epoch: 4 [3000/23974 (12%)]\tLoss: 0.258685\n",
      "Train Epoch: 4 [4000/23974 (17%)]\tLoss: 0.260662\n",
      "Train Epoch: 4 [5000/23974 (21%)]\tLoss: 0.262578\n",
      "Train Epoch: 4 [6000/23974 (25%)]\tLoss: 0.179745\n",
      "Train Epoch: 4 [7000/23974 (29%)]\tLoss: 0.380936\n",
      "Train Epoch: 4 [8000/23974 (33%)]\tLoss: 0.192956\n",
      "Train Epoch: 4 [9000/23974 (38%)]\tLoss: 0.397550\n",
      "Train Epoch: 4 [10000/23974 (42%)]\tLoss: 0.337743\n",
      "Train Epoch: 4 [11000/23974 (46%)]\tLoss: 0.255180\n",
      "Train Epoch: 4 [12000/23974 (50%)]\tLoss: 0.153599\n",
      "Train Epoch: 4 [13000/23974 (54%)]\tLoss: 0.210852\n",
      "Train Epoch: 4 [14000/23974 (58%)]\tLoss: 0.265922\n",
      "Train Epoch: 4 [15000/23974 (62%)]\tLoss: 0.392196\n",
      "Train Epoch: 4 [16000/23974 (67%)]\tLoss: 0.258042\n",
      "Train Epoch: 4 [17000/23974 (71%)]\tLoss: 0.272575\n",
      "Train Epoch: 4 [18000/23974 (75%)]\tLoss: 0.213564\n",
      "Train Epoch: 4 [19000/23974 (79%)]\tLoss: 0.358697\n",
      "Train Epoch: 4 [20000/23974 (83%)]\tLoss: 0.238541\n",
      "Train Epoch: 4 [21000/23974 (88%)]\tLoss: 0.466834\n",
      "Train Epoch: 4 [22000/23974 (92%)]\tLoss: 0.274985\n",
      "Train Epoch: 4 [23000/23974 (96%)]\tLoss: 0.307793\n",
      "Train Epoch: 5 [0/23974 (0%)]\tLoss: 0.201101\n",
      "Train Epoch: 5 [1000/23974 (4%)]\tLoss: 0.316091\n",
      "Train Epoch: 5 [2000/23974 (8%)]\tLoss: 0.191047\n",
      "Train Epoch: 5 [3000/23974 (12%)]\tLoss: 0.369184\n",
      "Train Epoch: 5 [4000/23974 (17%)]\tLoss: 0.323581\n",
      "Train Epoch: 5 [5000/23974 (21%)]\tLoss: 0.350649\n",
      "Train Epoch: 5 [6000/23974 (25%)]\tLoss: 0.279552\n",
      "Train Epoch: 5 [7000/23974 (29%)]\tLoss: 0.269850\n",
      "Train Epoch: 5 [8000/23974 (33%)]\tLoss: 0.116268\n",
      "Train Epoch: 5 [9000/23974 (38%)]\tLoss: 0.289773\n",
      "Train Epoch: 5 [10000/23974 (42%)]\tLoss: 0.319347\n",
      "Train Epoch: 5 [11000/23974 (46%)]\tLoss: 0.332924\n",
      "Train Epoch: 5 [12000/23974 (50%)]\tLoss: 0.254707\n",
      "Train Epoch: 5 [13000/23974 (54%)]\tLoss: 0.153239\n",
      "Train Epoch: 5 [14000/23974 (58%)]\tLoss: 0.251253\n",
      "Train Epoch: 5 [15000/23974 (62%)]\tLoss: 0.213647\n",
      "Train Epoch: 5 [16000/23974 (67%)]\tLoss: 0.215841\n",
      "Train Epoch: 5 [17000/23974 (71%)]\tLoss: 0.288552\n",
      "Train Epoch: 5 [18000/23974 (75%)]\tLoss: 0.257827\n",
      "Train Epoch: 5 [19000/23974 (79%)]\tLoss: 0.357367\n",
      "Train Epoch: 5 [20000/23974 (83%)]\tLoss: 0.305783\n",
      "Train Epoch: 5 [21000/23974 (88%)]\tLoss: 0.168731\n",
      "Train Epoch: 5 [22000/23974 (92%)]\tLoss: 0.370080\n",
      "Train Epoch: 5 [23000/23974 (96%)]\tLoss: 0.187895\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7961 (0%)]\tLoss: 0.484744\n",
      "Train Epoch: 1 [1000/7961 (12%)]\tLoss: 0.407420\n",
      "Train Epoch: 1 [2000/7961 (25%)]\tLoss: 0.389906\n",
      "Train Epoch: 1 [3000/7961 (38%)]\tLoss: 0.419027\n",
      "Train Epoch: 1 [4000/7961 (50%)]\tLoss: 0.269234\n",
      "Train Epoch: 1 [5000/7961 (62%)]\tLoss: 0.438292\n",
      "Train Epoch: 1 [6000/7961 (75%)]\tLoss: 0.367007\n",
      "Train Epoch: 1 [7000/7961 (88%)]\tLoss: 0.233547\n",
      "Train Epoch: 2 [0/7961 (0%)]\tLoss: 0.302601\n",
      "Train Epoch: 2 [1000/7961 (12%)]\tLoss: 0.376808\n",
      "Train Epoch: 2 [2000/7961 (25%)]\tLoss: 0.256873\n",
      "Train Epoch: 2 [3000/7961 (38%)]\tLoss: 0.395616\n",
      "Train Epoch: 2 [4000/7961 (50%)]\tLoss: 0.407361\n",
      "Train Epoch: 2 [5000/7961 (62%)]\tLoss: 0.334336\n",
      "Train Epoch: 2 [6000/7961 (75%)]\tLoss: 0.279097\n",
      "Train Epoch: 2 [7000/7961 (88%)]\tLoss: 0.479642\n",
      "Train Epoch: 3 [0/7961 (0%)]\tLoss: 0.349257\n",
      "Train Epoch: 3 [1000/7961 (12%)]\tLoss: 0.445817\n",
      "Train Epoch: 3 [2000/7961 (25%)]\tLoss: 0.503811\n",
      "Train Epoch: 3 [3000/7961 (38%)]\tLoss: 0.418501\n",
      "Train Epoch: 3 [4000/7961 (50%)]\tLoss: 0.432393\n",
      "Train Epoch: 3 [5000/7961 (62%)]\tLoss: 0.214354\n",
      "Train Epoch: 3 [6000/7961 (75%)]\tLoss: 0.441260\n",
      "Train Epoch: 3 [7000/7961 (88%)]\tLoss: 0.427546\n",
      "Train Epoch: 4 [0/7961 (0%)]\tLoss: 0.348827\n",
      "Train Epoch: 4 [1000/7961 (12%)]\tLoss: 0.303346\n",
      "Train Epoch: 4 [2000/7961 (25%)]\tLoss: 0.458796\n",
      "Train Epoch: 4 [3000/7961 (38%)]\tLoss: 0.309657\n",
      "Train Epoch: 4 [4000/7961 (50%)]\tLoss: 0.281677\n",
      "Train Epoch: 4 [5000/7961 (62%)]\tLoss: 0.540343\n",
      "Train Epoch: 4 [6000/7961 (75%)]\tLoss: 0.418051\n",
      "Train Epoch: 4 [7000/7961 (88%)]\tLoss: 0.362085\n",
      "Train Epoch: 5 [0/7961 (0%)]\tLoss: 0.330235\n",
      "Train Epoch: 5 [1000/7961 (12%)]\tLoss: 0.375111\n",
      "Train Epoch: 5 [2000/7961 (25%)]\tLoss: 0.285156\n",
      "Train Epoch: 5 [3000/7961 (38%)]\tLoss: 0.299794\n",
      "Train Epoch: 5 [4000/7961 (50%)]\tLoss: 0.278397\n",
      "Train Epoch: 5 [5000/7961 (62%)]\tLoss: 0.311792\n",
      "Train Epoch: 5 [6000/7961 (75%)]\tLoss: 0.263383\n",
      "Train Epoch: 5 [7000/7961 (88%)]\tLoss: 0.303655\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "4\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4280, Accuracy: 8521/10000 (85%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/23974 (0%)]\tLoss: 0.291523\n",
      "Train Epoch: 1 [1000/23974 (4%)]\tLoss: 0.325185\n",
      "Train Epoch: 1 [2000/23974 (8%)]\tLoss: 0.210337\n",
      "Train Epoch: 1 [3000/23974 (12%)]\tLoss: 0.158695\n",
      "Train Epoch: 1 [4000/23974 (17%)]\tLoss: 0.287985\n",
      "Train Epoch: 1 [5000/23974 (21%)]\tLoss: 0.370634\n",
      "Train Epoch: 1 [6000/23974 (25%)]\tLoss: 0.345204\n",
      "Train Epoch: 1 [7000/23974 (29%)]\tLoss: 0.240593\n",
      "Train Epoch: 1 [8000/23974 (33%)]\tLoss: 0.159610\n",
      "Train Epoch: 1 [9000/23974 (38%)]\tLoss: 0.269986\n",
      "Train Epoch: 1 [10000/23974 (42%)]\tLoss: 0.394062\n",
      "Train Epoch: 1 [11000/23974 (46%)]\tLoss: 0.266629\n",
      "Train Epoch: 1 [12000/23974 (50%)]\tLoss: 0.238018\n",
      "Train Epoch: 1 [13000/23974 (54%)]\tLoss: 0.207133\n",
      "Train Epoch: 1 [14000/23974 (58%)]\tLoss: 0.238669\n",
      "Train Epoch: 1 [15000/23974 (62%)]\tLoss: 0.279432\n",
      "Train Epoch: 1 [16000/23974 (67%)]\tLoss: 0.152686\n",
      "Train Epoch: 1 [17000/23974 (71%)]\tLoss: 0.281259\n",
      "Train Epoch: 1 [18000/23974 (75%)]\tLoss: 0.408938\n",
      "Train Epoch: 1 [19000/23974 (79%)]\tLoss: 0.261427\n",
      "Train Epoch: 1 [20000/23974 (83%)]\tLoss: 0.231211\n",
      "Train Epoch: 1 [21000/23974 (88%)]\tLoss: 0.243905\n",
      "Train Epoch: 1 [22000/23974 (92%)]\tLoss: 0.291104\n",
      "Train Epoch: 1 [23000/23974 (96%)]\tLoss: 0.295674\n",
      "Train Epoch: 2 [0/23974 (0%)]\tLoss: 0.244868\n",
      "Train Epoch: 2 [1000/23974 (4%)]\tLoss: 0.247734\n",
      "Train Epoch: 2 [2000/23974 (8%)]\tLoss: 0.258425\n",
      "Train Epoch: 2 [3000/23974 (12%)]\tLoss: 0.272483\n",
      "Train Epoch: 2 [4000/23974 (17%)]\tLoss: 0.192225\n",
      "Train Epoch: 2 [5000/23974 (21%)]\tLoss: 0.417852\n",
      "Train Epoch: 2 [6000/23974 (25%)]\tLoss: 0.281153\n",
      "Train Epoch: 2 [7000/23974 (29%)]\tLoss: 0.222948\n",
      "Train Epoch: 2 [8000/23974 (33%)]\tLoss: 0.100000\n",
      "Train Epoch: 2 [9000/23974 (38%)]\tLoss: 0.311249\n",
      "Train Epoch: 2 [10000/23974 (42%)]\tLoss: 0.222241\n",
      "Train Epoch: 2 [11000/23974 (46%)]\tLoss: 0.247768\n",
      "Train Epoch: 2 [12000/23974 (50%)]\tLoss: 0.406735\n",
      "Train Epoch: 2 [13000/23974 (54%)]\tLoss: 0.239604\n",
      "Train Epoch: 2 [14000/23974 (58%)]\tLoss: 0.317906\n",
      "Train Epoch: 2 [15000/23974 (62%)]\tLoss: 0.252062\n",
      "Train Epoch: 2 [16000/23974 (67%)]\tLoss: 0.166832\n",
      "Train Epoch: 2 [17000/23974 (71%)]\tLoss: 0.347089\n",
      "Train Epoch: 2 [18000/23974 (75%)]\tLoss: 0.147510\n",
      "Train Epoch: 2 [19000/23974 (79%)]\tLoss: 0.252521\n",
      "Train Epoch: 2 [20000/23974 (83%)]\tLoss: 0.137647\n",
      "Train Epoch: 2 [21000/23974 (88%)]\tLoss: 0.191637\n",
      "Train Epoch: 2 [22000/23974 (92%)]\tLoss: 0.308896\n",
      "Train Epoch: 2 [23000/23974 (96%)]\tLoss: 0.256817\n",
      "Train Epoch: 3 [0/23974 (0%)]\tLoss: 0.299391\n",
      "Train Epoch: 3 [1000/23974 (4%)]\tLoss: 0.297223\n",
      "Train Epoch: 3 [2000/23974 (8%)]\tLoss: 0.254592\n",
      "Train Epoch: 3 [3000/23974 (12%)]\tLoss: 0.111204\n",
      "Train Epoch: 3 [4000/23974 (17%)]\tLoss: 0.373723\n",
      "Train Epoch: 3 [5000/23974 (21%)]\tLoss: 0.283294\n",
      "Train Epoch: 3 [6000/23974 (25%)]\tLoss: 0.219154\n",
      "Train Epoch: 3 [7000/23974 (29%)]\tLoss: 0.191398\n",
      "Train Epoch: 3 [8000/23974 (33%)]\tLoss: 0.281572\n",
      "Train Epoch: 3 [9000/23974 (38%)]\tLoss: 0.178122\n",
      "Train Epoch: 3 [10000/23974 (42%)]\tLoss: 0.213440\n",
      "Train Epoch: 3 [11000/23974 (46%)]\tLoss: 0.218416\n",
      "Train Epoch: 3 [12000/23974 (50%)]\tLoss: 0.162088\n",
      "Train Epoch: 3 [13000/23974 (54%)]\tLoss: 0.275738\n",
      "Train Epoch: 3 [14000/23974 (58%)]\tLoss: 0.266729\n",
      "Train Epoch: 3 [15000/23974 (62%)]\tLoss: 0.356532\n",
      "Train Epoch: 3 [16000/23974 (67%)]\tLoss: 0.371196\n",
      "Train Epoch: 3 [17000/23974 (71%)]\tLoss: 0.276746\n",
      "Train Epoch: 3 [18000/23974 (75%)]\tLoss: 0.255913\n",
      "Train Epoch: 3 [19000/23974 (79%)]\tLoss: 0.177708\n",
      "Train Epoch: 3 [20000/23974 (83%)]\tLoss: 0.286927\n",
      "Train Epoch: 3 [21000/23974 (88%)]\tLoss: 0.251411\n",
      "Train Epoch: 3 [22000/23974 (92%)]\tLoss: 0.240420\n",
      "Train Epoch: 3 [23000/23974 (96%)]\tLoss: 0.302982\n",
      "Train Epoch: 4 [0/23974 (0%)]\tLoss: 0.178884\n",
      "Train Epoch: 4 [1000/23974 (4%)]\tLoss: 0.151051\n",
      "Train Epoch: 4 [2000/23974 (8%)]\tLoss: 0.123015\n",
      "Train Epoch: 4 [3000/23974 (12%)]\tLoss: 0.310718\n",
      "Train Epoch: 4 [4000/23974 (17%)]\tLoss: 0.327097\n",
      "Train Epoch: 4 [5000/23974 (21%)]\tLoss: 0.344238\n",
      "Train Epoch: 4 [6000/23974 (25%)]\tLoss: 0.333051\n",
      "Train Epoch: 4 [7000/23974 (29%)]\tLoss: 0.204068\n",
      "Train Epoch: 4 [8000/23974 (33%)]\tLoss: 0.414872\n",
      "Train Epoch: 4 [9000/23974 (38%)]\tLoss: 0.244361\n",
      "Train Epoch: 4 [10000/23974 (42%)]\tLoss: 0.239058\n",
      "Train Epoch: 4 [11000/23974 (46%)]\tLoss: 0.145388\n",
      "Train Epoch: 4 [12000/23974 (50%)]\tLoss: 0.250841\n",
      "Train Epoch: 4 [13000/23974 (54%)]\tLoss: 0.276471\n",
      "Train Epoch: 4 [14000/23974 (58%)]\tLoss: 0.187765\n",
      "Train Epoch: 4 [15000/23974 (62%)]\tLoss: 0.207245\n",
      "Train Epoch: 4 [16000/23974 (67%)]\tLoss: 0.320815\n",
      "Train Epoch: 4 [17000/23974 (71%)]\tLoss: 0.325935\n",
      "Train Epoch: 4 [18000/23974 (75%)]\tLoss: 0.328975\n",
      "Train Epoch: 4 [19000/23974 (79%)]\tLoss: 0.240240\n",
      "Train Epoch: 4 [20000/23974 (83%)]\tLoss: 0.193546\n",
      "Train Epoch: 4 [21000/23974 (88%)]\tLoss: 0.205373\n",
      "Train Epoch: 4 [22000/23974 (92%)]\tLoss: 0.291054\n",
      "Train Epoch: 4 [23000/23974 (96%)]\tLoss: 0.146768\n",
      "Train Epoch: 5 [0/23974 (0%)]\tLoss: 0.327670\n",
      "Train Epoch: 5 [1000/23974 (4%)]\tLoss: 0.214086\n",
      "Train Epoch: 5 [2000/23974 (8%)]\tLoss: 0.225041\n",
      "Train Epoch: 5 [3000/23974 (12%)]\tLoss: 0.120885\n",
      "Train Epoch: 5 [4000/23974 (17%)]\tLoss: 0.338689\n",
      "Train Epoch: 5 [5000/23974 (21%)]\tLoss: 0.303651\n",
      "Train Epoch: 5 [6000/23974 (25%)]\tLoss: 0.230467\n",
      "Train Epoch: 5 [7000/23974 (29%)]\tLoss: 0.217259\n",
      "Train Epoch: 5 [8000/23974 (33%)]\tLoss: 0.199360\n",
      "Train Epoch: 5 [9000/23974 (38%)]\tLoss: 0.282411\n",
      "Train Epoch: 5 [10000/23974 (42%)]\tLoss: 0.364464\n",
      "Train Epoch: 5 [11000/23974 (46%)]\tLoss: 0.219490\n",
      "Train Epoch: 5 [12000/23974 (50%)]\tLoss: 0.274671\n",
      "Train Epoch: 5 [13000/23974 (54%)]\tLoss: 0.305429\n",
      "Train Epoch: 5 [14000/23974 (58%)]\tLoss: 0.242078\n",
      "Train Epoch: 5 [15000/23974 (62%)]\tLoss: 0.182039\n",
      "Train Epoch: 5 [16000/23974 (67%)]\tLoss: 0.242943\n",
      "Train Epoch: 5 [17000/23974 (71%)]\tLoss: 0.159986\n",
      "Train Epoch: 5 [18000/23974 (75%)]\tLoss: 0.189824\n",
      "Train Epoch: 5 [19000/23974 (79%)]\tLoss: 0.340509\n",
      "Train Epoch: 5 [20000/23974 (83%)]\tLoss: 0.222502\n",
      "Train Epoch: 5 [21000/23974 (88%)]\tLoss: 0.289517\n",
      "Train Epoch: 5 [22000/23974 (92%)]\tLoss: 0.253974\n",
      "Train Epoch: 5 [23000/23974 (96%)]\tLoss: 0.226648\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7961 (0%)]\tLoss: 0.479538\n",
      "Train Epoch: 1 [1000/7961 (12%)]\tLoss: 0.345160\n",
      "Train Epoch: 1 [2000/7961 (25%)]\tLoss: 0.220821\n",
      "Train Epoch: 1 [3000/7961 (38%)]\tLoss: 0.320741\n",
      "Train Epoch: 1 [4000/7961 (50%)]\tLoss: 0.390517\n",
      "Train Epoch: 1 [5000/7961 (62%)]\tLoss: 0.252834\n",
      "Train Epoch: 1 [6000/7961 (75%)]\tLoss: 0.379361\n",
      "Train Epoch: 1 [7000/7961 (88%)]\tLoss: 0.311598\n",
      "Train Epoch: 2 [0/7961 (0%)]\tLoss: 0.236980\n",
      "Train Epoch: 2 [1000/7961 (12%)]\tLoss: 0.319670\n",
      "Train Epoch: 2 [2000/7961 (25%)]\tLoss: 0.371698\n",
      "Train Epoch: 2 [3000/7961 (38%)]\tLoss: 0.414256\n",
      "Train Epoch: 2 [4000/7961 (50%)]\tLoss: 0.394616\n",
      "Train Epoch: 2 [5000/7961 (62%)]\tLoss: 0.338488\n",
      "Train Epoch: 2 [6000/7961 (75%)]\tLoss: 0.430223\n",
      "Train Epoch: 2 [7000/7961 (88%)]\tLoss: 0.375351\n",
      "Train Epoch: 3 [0/7961 (0%)]\tLoss: 0.271787\n",
      "Train Epoch: 3 [1000/7961 (12%)]\tLoss: 0.319646\n",
      "Train Epoch: 3 [2000/7961 (25%)]\tLoss: 0.269363\n",
      "Train Epoch: 3 [3000/7961 (38%)]\tLoss: 0.289398\n",
      "Train Epoch: 3 [4000/7961 (50%)]\tLoss: 0.323069\n",
      "Train Epoch: 3 [5000/7961 (62%)]\tLoss: 0.279574\n",
      "Train Epoch: 3 [6000/7961 (75%)]\tLoss: 0.301069\n",
      "Train Epoch: 3 [7000/7961 (88%)]\tLoss: 0.382521\n",
      "Train Epoch: 4 [0/7961 (0%)]\tLoss: 0.347952\n",
      "Train Epoch: 4 [1000/7961 (12%)]\tLoss: 0.331312\n",
      "Train Epoch: 4 [2000/7961 (25%)]\tLoss: 0.349383\n",
      "Train Epoch: 4 [3000/7961 (38%)]\tLoss: 0.230332\n",
      "Train Epoch: 4 [4000/7961 (50%)]\tLoss: 0.294063\n",
      "Train Epoch: 4 [5000/7961 (62%)]\tLoss: 0.268082\n",
      "Train Epoch: 4 [6000/7961 (75%)]\tLoss: 0.384886\n",
      "Train Epoch: 4 [7000/7961 (88%)]\tLoss: 0.366019\n",
      "Train Epoch: 5 [0/7961 (0%)]\tLoss: 0.273623\n",
      "Train Epoch: 5 [1000/7961 (12%)]\tLoss: 0.233558\n",
      "Train Epoch: 5 [2000/7961 (25%)]\tLoss: 0.335649\n",
      "Train Epoch: 5 [3000/7961 (38%)]\tLoss: 0.399444\n",
      "Train Epoch: 5 [4000/7961 (50%)]\tLoss: 0.330574\n",
      "Train Epoch: 5 [5000/7961 (62%)]\tLoss: 0.189385\n",
      "Train Epoch: 5 [6000/7961 (75%)]\tLoss: 0.211238\n",
      "Train Epoch: 5 [7000/7961 (88%)]\tLoss: 0.422759\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "4\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4115, Accuracy: 8560/10000 (86%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/23974 (0%)]\tLoss: 0.220927\n",
      "Train Epoch: 1 [1000/23974 (4%)]\tLoss: 0.404073\n",
      "Train Epoch: 1 [2000/23974 (8%)]\tLoss: 0.297594\n",
      "Train Epoch: 1 [3000/23974 (12%)]\tLoss: 0.305537\n",
      "Train Epoch: 1 [4000/23974 (17%)]\tLoss: 0.184867\n",
      "Train Epoch: 1 [5000/23974 (21%)]\tLoss: 0.458062\n",
      "Train Epoch: 1 [6000/23974 (25%)]\tLoss: 0.324826\n",
      "Train Epoch: 1 [7000/23974 (29%)]\tLoss: 0.358864\n",
      "Train Epoch: 1 [8000/23974 (33%)]\tLoss: 0.316236\n",
      "Train Epoch: 1 [9000/23974 (38%)]\tLoss: 0.378216\n",
      "Train Epoch: 1 [10000/23974 (42%)]\tLoss: 0.226485\n",
      "Train Epoch: 1 [11000/23974 (46%)]\tLoss: 0.286207\n",
      "Train Epoch: 1 [12000/23974 (50%)]\tLoss: 0.224525\n",
      "Train Epoch: 1 [13000/23974 (54%)]\tLoss: 0.132514\n",
      "Train Epoch: 1 [14000/23974 (58%)]\tLoss: 0.324337\n",
      "Train Epoch: 1 [15000/23974 (62%)]\tLoss: 0.272447\n",
      "Train Epoch: 1 [16000/23974 (67%)]\tLoss: 0.222023\n",
      "Train Epoch: 1 [17000/23974 (71%)]\tLoss: 0.210896\n",
      "Train Epoch: 1 [18000/23974 (75%)]\tLoss: 0.369389\n",
      "Train Epoch: 1 [19000/23974 (79%)]\tLoss: 0.299842\n",
      "Train Epoch: 1 [20000/23974 (83%)]\tLoss: 0.235743\n",
      "Train Epoch: 1 [21000/23974 (88%)]\tLoss: 0.315953\n",
      "Train Epoch: 1 [22000/23974 (92%)]\tLoss: 0.294889\n",
      "Train Epoch: 1 [23000/23974 (96%)]\tLoss: 0.275453\n",
      "Train Epoch: 2 [0/23974 (0%)]\tLoss: 0.190438\n",
      "Train Epoch: 2 [1000/23974 (4%)]\tLoss: 0.255542\n",
      "Train Epoch: 2 [2000/23974 (8%)]\tLoss: 0.278096\n",
      "Train Epoch: 2 [3000/23974 (12%)]\tLoss: 0.183016\n",
      "Train Epoch: 2 [4000/23974 (17%)]\tLoss: 0.182939\n",
      "Train Epoch: 2 [5000/23974 (21%)]\tLoss: 0.439815\n",
      "Train Epoch: 2 [6000/23974 (25%)]\tLoss: 0.275862\n",
      "Train Epoch: 2 [7000/23974 (29%)]\tLoss: 0.235533\n",
      "Train Epoch: 2 [8000/23974 (33%)]\tLoss: 0.261517\n",
      "Train Epoch: 2 [9000/23974 (38%)]\tLoss: 0.268942\n",
      "Train Epoch: 2 [10000/23974 (42%)]\tLoss: 0.220349\n",
      "Train Epoch: 2 [11000/23974 (46%)]\tLoss: 0.383312\n",
      "Train Epoch: 2 [12000/23974 (50%)]\tLoss: 0.251086\n",
      "Train Epoch: 2 [13000/23974 (54%)]\tLoss: 0.185798\n",
      "Train Epoch: 2 [14000/23974 (58%)]\tLoss: 0.195306\n",
      "Train Epoch: 2 [15000/23974 (62%)]\tLoss: 0.287155\n",
      "Train Epoch: 2 [16000/23974 (67%)]\tLoss: 0.331838\n",
      "Train Epoch: 2 [17000/23974 (71%)]\tLoss: 0.241068\n",
      "Train Epoch: 2 [18000/23974 (75%)]\tLoss: 0.329817\n",
      "Train Epoch: 2 [19000/23974 (79%)]\tLoss: 0.188412\n",
      "Train Epoch: 2 [20000/23974 (83%)]\tLoss: 0.290197\n",
      "Train Epoch: 2 [21000/23974 (88%)]\tLoss: 0.267810\n",
      "Train Epoch: 2 [22000/23974 (92%)]\tLoss: 0.318653\n",
      "Train Epoch: 2 [23000/23974 (96%)]\tLoss: 0.251537\n",
      "Train Epoch: 3 [0/23974 (0%)]\tLoss: 0.171378\n",
      "Train Epoch: 3 [1000/23974 (4%)]\tLoss: 0.345197\n",
      "Train Epoch: 3 [2000/23974 (8%)]\tLoss: 0.250805\n",
      "Train Epoch: 3 [3000/23974 (12%)]\tLoss: 0.232427\n",
      "Train Epoch: 3 [4000/23974 (17%)]\tLoss: 0.173632\n",
      "Train Epoch: 3 [5000/23974 (21%)]\tLoss: 0.144441\n",
      "Train Epoch: 3 [6000/23974 (25%)]\tLoss: 0.175711\n",
      "Train Epoch: 3 [7000/23974 (29%)]\tLoss: 0.199601\n",
      "Train Epoch: 3 [8000/23974 (33%)]\tLoss: 0.289137\n",
      "Train Epoch: 3 [9000/23974 (38%)]\tLoss: 0.262686\n",
      "Train Epoch: 3 [10000/23974 (42%)]\tLoss: 0.455147\n",
      "Train Epoch: 3 [11000/23974 (46%)]\tLoss: 0.212499\n",
      "Train Epoch: 3 [12000/23974 (50%)]\tLoss: 0.217379\n",
      "Train Epoch: 3 [13000/23974 (54%)]\tLoss: 0.277430\n",
      "Train Epoch: 3 [14000/23974 (58%)]\tLoss: 0.207694\n",
      "Train Epoch: 3 [15000/23974 (62%)]\tLoss: 0.288809\n",
      "Train Epoch: 3 [16000/23974 (67%)]\tLoss: 0.160306\n",
      "Train Epoch: 3 [17000/23974 (71%)]\tLoss: 0.347300\n",
      "Train Epoch: 3 [18000/23974 (75%)]\tLoss: 0.201631\n",
      "Train Epoch: 3 [19000/23974 (79%)]\tLoss: 0.194840\n",
      "Train Epoch: 3 [20000/23974 (83%)]\tLoss: 0.255937\n",
      "Train Epoch: 3 [21000/23974 (88%)]\tLoss: 0.363037\n",
      "Train Epoch: 3 [22000/23974 (92%)]\tLoss: 0.182440\n",
      "Train Epoch: 3 [23000/23974 (96%)]\tLoss: 0.344633\n",
      "Train Epoch: 4 [0/23974 (0%)]\tLoss: 0.231667\n",
      "Train Epoch: 4 [1000/23974 (4%)]\tLoss: 0.077856\n",
      "Train Epoch: 4 [2000/23974 (8%)]\tLoss: 0.206665\n",
      "Train Epoch: 4 [3000/23974 (12%)]\tLoss: 0.223915\n",
      "Train Epoch: 4 [4000/23974 (17%)]\tLoss: 0.213965\n",
      "Train Epoch: 4 [5000/23974 (21%)]\tLoss: 0.243856\n",
      "Train Epoch: 4 [6000/23974 (25%)]\tLoss: 0.306409\n",
      "Train Epoch: 4 [7000/23974 (29%)]\tLoss: 0.231014\n",
      "Train Epoch: 4 [8000/23974 (33%)]\tLoss: 0.212249\n",
      "Train Epoch: 4 [9000/23974 (38%)]\tLoss: 0.211109\n",
      "Train Epoch: 4 [10000/23974 (42%)]\tLoss: 0.352503\n",
      "Train Epoch: 4 [11000/23974 (46%)]\tLoss: 0.333642\n",
      "Train Epoch: 4 [12000/23974 (50%)]\tLoss: 0.185126\n",
      "Train Epoch: 4 [13000/23974 (54%)]\tLoss: 0.174936\n",
      "Train Epoch: 4 [14000/23974 (58%)]\tLoss: 0.281402\n",
      "Train Epoch: 4 [15000/23974 (62%)]\tLoss: 0.199985\n",
      "Train Epoch: 4 [16000/23974 (67%)]\tLoss: 0.348362\n",
      "Train Epoch: 4 [17000/23974 (71%)]\tLoss: 0.210511\n",
      "Train Epoch: 4 [18000/23974 (75%)]\tLoss: 0.229455\n",
      "Train Epoch: 4 [19000/23974 (79%)]\tLoss: 0.164180\n",
      "Train Epoch: 4 [20000/23974 (83%)]\tLoss: 0.234784\n",
      "Train Epoch: 4 [21000/23974 (88%)]\tLoss: 0.313511\n",
      "Train Epoch: 4 [22000/23974 (92%)]\tLoss: 0.274820\n",
      "Train Epoch: 4 [23000/23974 (96%)]\tLoss: 0.201773\n",
      "Train Epoch: 5 [0/23974 (0%)]\tLoss: 0.182245\n",
      "Train Epoch: 5 [1000/23974 (4%)]\tLoss: 0.202059\n",
      "Train Epoch: 5 [2000/23974 (8%)]\tLoss: 0.266094\n",
      "Train Epoch: 5 [3000/23974 (12%)]\tLoss: 0.194610\n",
      "Train Epoch: 5 [4000/23974 (17%)]\tLoss: 0.188332\n",
      "Train Epoch: 5 [5000/23974 (21%)]\tLoss: 0.185922\n",
      "Train Epoch: 5 [6000/23974 (25%)]\tLoss: 0.350412\n",
      "Train Epoch: 5 [7000/23974 (29%)]\tLoss: 0.185138\n",
      "Train Epoch: 5 [8000/23974 (33%)]\tLoss: 0.307407\n",
      "Train Epoch: 5 [9000/23974 (38%)]\tLoss: 0.200301\n",
      "Train Epoch: 5 [10000/23974 (42%)]\tLoss: 0.294865\n",
      "Train Epoch: 5 [11000/23974 (46%)]\tLoss: 0.328419\n",
      "Train Epoch: 5 [12000/23974 (50%)]\tLoss: 0.430760\n",
      "Train Epoch: 5 [13000/23974 (54%)]\tLoss: 0.200887\n",
      "Train Epoch: 5 [14000/23974 (58%)]\tLoss: 0.211719\n",
      "Train Epoch: 5 [15000/23974 (62%)]\tLoss: 0.242844\n",
      "Train Epoch: 5 [16000/23974 (67%)]\tLoss: 0.192521\n",
      "Train Epoch: 5 [17000/23974 (71%)]\tLoss: 0.270543\n",
      "Train Epoch: 5 [18000/23974 (75%)]\tLoss: 0.124373\n",
      "Train Epoch: 5 [19000/23974 (79%)]\tLoss: 0.265477\n",
      "Train Epoch: 5 [20000/23974 (83%)]\tLoss: 0.302048\n",
      "Train Epoch: 5 [21000/23974 (88%)]\tLoss: 0.304191\n",
      "Train Epoch: 5 [22000/23974 (92%)]\tLoss: 0.323358\n",
      "Train Epoch: 5 [23000/23974 (96%)]\tLoss: 0.195901\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7961 (0%)]\tLoss: 0.238946\n",
      "Train Epoch: 1 [1000/7961 (12%)]\tLoss: 0.312922\n",
      "Train Epoch: 1 [2000/7961 (25%)]\tLoss: 0.310297\n",
      "Train Epoch: 1 [3000/7961 (38%)]\tLoss: 0.272718\n",
      "Train Epoch: 1 [4000/7961 (50%)]\tLoss: 0.401354\n",
      "Train Epoch: 1 [5000/7961 (62%)]\tLoss: 0.351269\n",
      "Train Epoch: 1 [6000/7961 (75%)]\tLoss: 0.296666\n",
      "Train Epoch: 1 [7000/7961 (88%)]\tLoss: 0.182593\n",
      "Train Epoch: 2 [0/7961 (0%)]\tLoss: 0.478618\n",
      "Train Epoch: 2 [1000/7961 (12%)]\tLoss: 0.175967\n",
      "Train Epoch: 2 [2000/7961 (25%)]\tLoss: 0.232445\n",
      "Train Epoch: 2 [3000/7961 (38%)]\tLoss: 0.313642\n",
      "Train Epoch: 2 [4000/7961 (50%)]\tLoss: 0.243808\n",
      "Train Epoch: 2 [5000/7961 (62%)]\tLoss: 0.198555\n",
      "Train Epoch: 2 [6000/7961 (75%)]\tLoss: 0.201124\n",
      "Train Epoch: 2 [7000/7961 (88%)]\tLoss: 0.348895\n",
      "Train Epoch: 3 [0/7961 (0%)]\tLoss: 0.293424\n",
      "Train Epoch: 3 [1000/7961 (12%)]\tLoss: 0.377443\n",
      "Train Epoch: 3 [2000/7961 (25%)]\tLoss: 0.294777\n",
      "Train Epoch: 3 [3000/7961 (38%)]\tLoss: 0.338616\n",
      "Train Epoch: 3 [4000/7961 (50%)]\tLoss: 0.340025\n",
      "Train Epoch: 3 [5000/7961 (62%)]\tLoss: 0.376780\n",
      "Train Epoch: 3 [6000/7961 (75%)]\tLoss: 0.213409\n",
      "Train Epoch: 3 [7000/7961 (88%)]\tLoss: 0.292529\n",
      "Train Epoch: 4 [0/7961 (0%)]\tLoss: 0.367080\n",
      "Train Epoch: 4 [1000/7961 (12%)]\tLoss: 0.337425\n",
      "Train Epoch: 4 [2000/7961 (25%)]\tLoss: 0.287913\n",
      "Train Epoch: 4 [3000/7961 (38%)]\tLoss: 0.225085\n",
      "Train Epoch: 4 [4000/7961 (50%)]\tLoss: 0.258837\n",
      "Train Epoch: 4 [5000/7961 (62%)]\tLoss: 0.187894\n",
      "Train Epoch: 4 [6000/7961 (75%)]\tLoss: 0.348163\n",
      "Train Epoch: 4 [7000/7961 (88%)]\tLoss: 0.350516\n",
      "Train Epoch: 5 [0/7961 (0%)]\tLoss: 0.208652\n",
      "Train Epoch: 5 [1000/7961 (12%)]\tLoss: 0.459101\n",
      "Train Epoch: 5 [2000/7961 (25%)]\tLoss: 0.243076\n",
      "Train Epoch: 5 [3000/7961 (38%)]\tLoss: 0.285557\n",
      "Train Epoch: 5 [4000/7961 (50%)]\tLoss: 0.311261\n",
      "Train Epoch: 5 [5000/7961 (62%)]\tLoss: 0.234754\n",
      "Train Epoch: 5 [6000/7961 (75%)]\tLoss: 0.314281\n",
      "Train Epoch: 5 [7000/7961 (88%)]\tLoss: 0.264648\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "4\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4210, Accuracy: 8531/10000 (85%)\n",
      "\n",
      "Running experiment with 6 partitions...\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.338321\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 0.329798\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 0.410828\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 0.289944\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 0.289429\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 0.432160\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 0.368474\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 0.250645\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.317624\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 0.300199\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.292198\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 0.460522\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.379990\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 0.487229\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 0.330609\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.327374\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.433816\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 0.342737\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 0.417221\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 0.425493\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.506284\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 0.463696\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.299750\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 0.435918\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.312493\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.322840\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.359590\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 0.418432\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.320151\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 0.390427\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.344368\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 0.271823\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.365259\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 0.350892\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.395766\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.362648\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.445279\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 0.369751\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.332956\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 0.334017\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.324464\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 0.308576\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.323471\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 0.243139\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.369239\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.342873\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.370448\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 0.272987\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.390078\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 0.270766\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.258958\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 0.146061\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.275691\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 0.331804\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.303692\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.360708\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.343666\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 0.329989\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.215916\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 0.289844\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.355453\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 0.303742\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.365648\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 0.165284\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.370942\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.356979\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.328035\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 0.342444\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.351568\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 0.436508\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.307613\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 0.191346\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.335708\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 0.266216\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.419664\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.198210\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.375480\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 0.267215\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.458889\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 0.340793\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.373434\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 0.286614\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.500947\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 0.363588\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.394309\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.283161\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.443149\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 0.260634\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.335463\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 0.313979\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.413868\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 0.290116\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.360495\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 0.274972\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.483635\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.371601\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.379582\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 0.285433\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.332516\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 0.291584\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.328236\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 0.254409\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.438062\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 0.237764\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.243109\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.395192\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.299253\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 0.373336\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.340975\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 0.484401\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.400397\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 0.315379\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.266814\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 0.309330\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.315553\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.303986\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.345573\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 0.329187\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.364767\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 0.306555\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.374547\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 0.294673\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.265690\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 0.231476\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.293703\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.420396\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.264624\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 0.344478\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.247531\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 0.351633\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.295447\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 0.393548\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.281818\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 0.467330\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.362490\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.301766\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.428903\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 0.374061\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.354275\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 0.371550\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.316285\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 0.242023\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.373000\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 0.349374\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.284030\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.379816\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.197539\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 0.361631\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.397620\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 0.298121\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.367729\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 0.357222\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.386478\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 0.318644\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.382400\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.305440\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.241168\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 0.355642\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.326908\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 0.235893\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.365463\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 0.273187\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.284902\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 0.279490\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.419987\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.385145\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.296061\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 0.208021\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.191927\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 0.353498\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.375760\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 0.339589\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.337082\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 0.319306\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.491216\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.495021\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.243146\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 0.448929\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.380039\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 0.278561\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.415459\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 0.289817\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.393916\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 0.254047\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.148569\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.378138\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.404966\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 0.197572\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.461950\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 0.396087\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.310943\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 0.257133\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.272298\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 0.317039\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.345621\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.295442\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.331038\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 0.303357\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.314629\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 0.344067\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.274830\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 0.328072\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.255595\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 0.167587\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.334211\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.364275\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.261637\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 0.323561\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.425255\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 0.258173\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.381153\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 0.416864\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.382992\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 0.248605\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.335249\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.315295\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.463135\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 0.319566\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.307325\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 0.341143\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.316775\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 0.351756\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.268378\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 0.297883\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.259447\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.357927\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.358482\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 0.271023\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.327105\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 0.222881\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.406055\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 0.195394\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.406934\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 0.254023\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.356886\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.289301\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.247405\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 0.279886\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.292443\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 0.528551\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.245661\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 0.324897\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.309973\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 0.344937\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.224485\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.379975\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.312965\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 0.377892\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.209744\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 0.206331\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.234905\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 0.331677\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.370334\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 0.332155\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.265736\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.245257\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.213101\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 0.241782\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.353637\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 0.361627\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.352433\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 0.359598\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.322344\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 0.252277\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.249413\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.297802\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.461017\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 0.323457\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.293537\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 0.380802\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.293339\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 0.321251\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.306295\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 0.247472\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.325341\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.450630\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.401555\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 0.262095\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.327728\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 0.290858\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.273844\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 0.286500\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.241993\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 0.244271\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.174932\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.212843\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.243377\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 0.296422\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.228681\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 0.317248\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.216274\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 0.223049\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.292666\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 0.183652\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.226178\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.504219\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.173499\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 0.328434\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.277002\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 0.358644\n",
      "\n",
      "Test set: Avg. loss: 0.3008, Accuracy: 53457/60000 (89%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/8440 (0%)]\tLoss: 0.394230\n",
      "Train Epoch: 1 [1000/8440 (12%)]\tLoss: 0.234236\n",
      "Train Epoch: 1 [2000/8440 (24%)]\tLoss: 0.354649\n",
      "Train Epoch: 1 [3000/8440 (35%)]\tLoss: 0.321802\n",
      "Train Epoch: 1 [4000/8440 (47%)]\tLoss: 0.401836\n",
      "Train Epoch: 1 [5000/8440 (59%)]\tLoss: 0.331141\n",
      "Train Epoch: 1 [6000/8440 (71%)]\tLoss: 0.276999\n",
      "Train Epoch: 1 [7000/8440 (82%)]\tLoss: 0.207499\n",
      "Train Epoch: 1 [8000/8440 (94%)]\tLoss: 0.322458\n",
      "Train Epoch: 2 [0/8440 (0%)]\tLoss: 0.373766\n",
      "Train Epoch: 2 [1000/8440 (12%)]\tLoss: 0.251079\n",
      "Train Epoch: 2 [2000/8440 (24%)]\tLoss: 0.209636\n",
      "Train Epoch: 2 [3000/8440 (35%)]\tLoss: 0.299481\n",
      "Train Epoch: 2 [4000/8440 (47%)]\tLoss: 0.322280\n",
      "Train Epoch: 2 [5000/8440 (59%)]\tLoss: 0.247891\n",
      "Train Epoch: 2 [6000/8440 (71%)]\tLoss: 0.195944\n",
      "Train Epoch: 2 [7000/8440 (82%)]\tLoss: 0.296013\n",
      "Train Epoch: 2 [8000/8440 (94%)]\tLoss: 0.242558\n",
      "Train Epoch: 3 [0/8440 (0%)]\tLoss: 0.231270\n",
      "Train Epoch: 3 [1000/8440 (12%)]\tLoss: 0.206662\n",
      "Train Epoch: 3 [2000/8440 (24%)]\tLoss: 0.202155\n",
      "Train Epoch: 3 [3000/8440 (35%)]\tLoss: 0.217478\n",
      "Train Epoch: 3 [4000/8440 (47%)]\tLoss: 0.290193\n",
      "Train Epoch: 3 [5000/8440 (59%)]\tLoss: 0.196637\n",
      "Train Epoch: 3 [6000/8440 (71%)]\tLoss: 0.182760\n",
      "Train Epoch: 3 [7000/8440 (82%)]\tLoss: 0.247591\n",
      "Train Epoch: 3 [8000/8440 (94%)]\tLoss: 0.290249\n",
      "Train Epoch: 4 [0/8440 (0%)]\tLoss: 0.317085\n",
      "Train Epoch: 4 [1000/8440 (12%)]\tLoss: 0.367590\n",
      "Train Epoch: 4 [2000/8440 (24%)]\tLoss: 0.322727\n",
      "Train Epoch: 4 [3000/8440 (35%)]\tLoss: 0.369457\n",
      "Train Epoch: 4 [4000/8440 (47%)]\tLoss: 0.261326\n",
      "Train Epoch: 4 [5000/8440 (59%)]\tLoss: 0.212466\n",
      "Train Epoch: 4 [6000/8440 (71%)]\tLoss: 0.404745\n",
      "Train Epoch: 4 [7000/8440 (82%)]\tLoss: 0.293168\n",
      "Train Epoch: 4 [8000/8440 (94%)]\tLoss: 0.249603\n",
      "Train Epoch: 5 [0/8440 (0%)]\tLoss: 0.268255\n",
      "Train Epoch: 5 [1000/8440 (12%)]\tLoss: 0.245427\n",
      "Train Epoch: 5 [2000/8440 (24%)]\tLoss: 0.198625\n",
      "Train Epoch: 5 [3000/8440 (35%)]\tLoss: 0.214797\n",
      "Train Epoch: 5 [4000/8440 (47%)]\tLoss: 0.188901\n",
      "Train Epoch: 5 [5000/8440 (59%)]\tLoss: 0.301479\n",
      "Train Epoch: 5 [6000/8440 (71%)]\tLoss: 0.223393\n",
      "Train Epoch: 5 [7000/8440 (82%)]\tLoss: 0.215093\n",
      "Train Epoch: 5 [8000/8440 (94%)]\tLoss: 0.204157\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11811 (0%)]\tLoss: 0.186949\n",
      "Train Epoch: 1 [1000/11811 (8%)]\tLoss: 0.065788\n",
      "Train Epoch: 1 [2000/11811 (17%)]\tLoss: 0.063564\n",
      "Train Epoch: 1 [3000/11811 (25%)]\tLoss: 0.076983\n",
      "Train Epoch: 1 [4000/11811 (34%)]\tLoss: 0.060698\n",
      "Train Epoch: 1 [5000/11811 (42%)]\tLoss: 0.036847\n",
      "Train Epoch: 1 [6000/11811 (50%)]\tLoss: 0.054121\n",
      "Train Epoch: 1 [7000/11811 (59%)]\tLoss: 0.114595\n",
      "Train Epoch: 1 [8000/11811 (67%)]\tLoss: 0.093308\n",
      "Train Epoch: 1 [9000/11811 (76%)]\tLoss: 0.151599\n",
      "Train Epoch: 1 [10000/11811 (84%)]\tLoss: 0.259476\n",
      "Train Epoch: 1 [11000/11811 (92%)]\tLoss: 0.044521\n",
      "Train Epoch: 2 [0/11811 (0%)]\tLoss: 0.151849\n",
      "Train Epoch: 2 [1000/11811 (8%)]\tLoss: 0.169692\n",
      "Train Epoch: 2 [2000/11811 (17%)]\tLoss: 0.172788\n",
      "Train Epoch: 2 [3000/11811 (25%)]\tLoss: 0.091519\n",
      "Train Epoch: 2 [4000/11811 (34%)]\tLoss: 0.133923\n",
      "Train Epoch: 2 [5000/11811 (42%)]\tLoss: 0.179407\n",
      "Train Epoch: 2 [6000/11811 (50%)]\tLoss: 0.163000\n",
      "Train Epoch: 2 [7000/11811 (59%)]\tLoss: 0.074497\n",
      "Train Epoch: 2 [8000/11811 (67%)]\tLoss: 0.153169\n",
      "Train Epoch: 2 [9000/11811 (76%)]\tLoss: 0.142947\n",
      "Train Epoch: 2 [10000/11811 (84%)]\tLoss: 0.197223\n",
      "Train Epoch: 2 [11000/11811 (92%)]\tLoss: 0.179604\n",
      "Train Epoch: 3 [0/11811 (0%)]\tLoss: 0.129791\n",
      "Train Epoch: 3 [1000/11811 (8%)]\tLoss: 0.194325\n",
      "Train Epoch: 3 [2000/11811 (17%)]\tLoss: 0.135453\n",
      "Train Epoch: 3 [3000/11811 (25%)]\tLoss: 0.107735\n",
      "Train Epoch: 3 [4000/11811 (34%)]\tLoss: 0.166291\n",
      "Train Epoch: 3 [5000/11811 (42%)]\tLoss: 0.106594\n",
      "Train Epoch: 3 [6000/11811 (50%)]\tLoss: 0.148184\n",
      "Train Epoch: 3 [7000/11811 (59%)]\tLoss: 0.090658\n",
      "Train Epoch: 3 [8000/11811 (67%)]\tLoss: 0.195080\n",
      "Train Epoch: 3 [9000/11811 (76%)]\tLoss: 0.127928\n",
      "Train Epoch: 3 [10000/11811 (84%)]\tLoss: 0.159894\n",
      "Train Epoch: 3 [11000/11811 (92%)]\tLoss: 0.080703\n",
      "Train Epoch: 4 [0/11811 (0%)]\tLoss: 0.150219\n",
      "Train Epoch: 4 [1000/11811 (8%)]\tLoss: 0.233656\n",
      "Train Epoch: 4 [2000/11811 (17%)]\tLoss: 0.135526\n",
      "Train Epoch: 4 [3000/11811 (25%)]\tLoss: 0.063638\n",
      "Train Epoch: 4 [4000/11811 (34%)]\tLoss: 0.070787\n",
      "Train Epoch: 4 [5000/11811 (42%)]\tLoss: 0.223502\n",
      "Train Epoch: 4 [6000/11811 (50%)]\tLoss: 0.131899\n",
      "Train Epoch: 4 [7000/11811 (59%)]\tLoss: 0.209437\n",
      "Train Epoch: 4 [8000/11811 (67%)]\tLoss: 0.054982\n",
      "Train Epoch: 4 [9000/11811 (76%)]\tLoss: 0.095807\n",
      "Train Epoch: 4 [10000/11811 (84%)]\tLoss: 0.129295\n",
      "Train Epoch: 4 [11000/11811 (92%)]\tLoss: 0.068681\n",
      "Train Epoch: 5 [0/11811 (0%)]\tLoss: 0.121341\n",
      "Train Epoch: 5 [1000/11811 (8%)]\tLoss: 0.047853\n",
      "Train Epoch: 5 [2000/11811 (17%)]\tLoss: 0.085508\n",
      "Train Epoch: 5 [3000/11811 (25%)]\tLoss: 0.078626\n",
      "Train Epoch: 5 [4000/11811 (34%)]\tLoss: 0.078049\n",
      "Train Epoch: 5 [5000/11811 (42%)]\tLoss: 0.212535\n",
      "Train Epoch: 5 [6000/11811 (50%)]\tLoss: 0.102073\n",
      "Train Epoch: 5 [7000/11811 (59%)]\tLoss: 0.069311\n",
      "Train Epoch: 5 [8000/11811 (67%)]\tLoss: 0.159602\n",
      "Train Epoch: 5 [9000/11811 (76%)]\tLoss: 0.130023\n",
      "Train Epoch: 5 [10000/11811 (84%)]\tLoss: 0.018472\n",
      "Train Epoch: 5 [11000/11811 (92%)]\tLoss: 0.165861\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/9726 (0%)]\tLoss: 0.259676\n",
      "Train Epoch: 1 [1000/9726 (10%)]\tLoss: 0.187457\n",
      "Train Epoch: 1 [2000/9726 (20%)]\tLoss: 0.179113\n",
      "Train Epoch: 1 [3000/9726 (31%)]\tLoss: 0.208762\n",
      "Train Epoch: 1 [4000/9726 (41%)]\tLoss: 0.192995\n",
      "Train Epoch: 1 [5000/9726 (51%)]\tLoss: 0.214692\n",
      "Train Epoch: 1 [6000/9726 (61%)]\tLoss: 0.131247\n",
      "Train Epoch: 1 [7000/9726 (71%)]\tLoss: 0.228117\n",
      "Train Epoch: 1 [8000/9726 (82%)]\tLoss: 0.204123\n",
      "Train Epoch: 1 [9000/9726 (92%)]\tLoss: 0.176018\n",
      "Train Epoch: 2 [0/9726 (0%)]\tLoss: 0.303079\n",
      "Train Epoch: 2 [1000/9726 (10%)]\tLoss: 0.261936\n",
      "Train Epoch: 2 [2000/9726 (20%)]\tLoss: 0.206255\n",
      "Train Epoch: 2 [3000/9726 (31%)]\tLoss: 0.153235\n",
      "Train Epoch: 2 [4000/9726 (41%)]\tLoss: 0.436996\n",
      "Train Epoch: 2 [5000/9726 (51%)]\tLoss: 0.280745\n",
      "Train Epoch: 2 [6000/9726 (61%)]\tLoss: 0.193668\n",
      "Train Epoch: 2 [7000/9726 (71%)]\tLoss: 0.201682\n",
      "Train Epoch: 2 [8000/9726 (82%)]\tLoss: 0.254212\n",
      "Train Epoch: 2 [9000/9726 (92%)]\tLoss: 0.231449\n",
      "Train Epoch: 3 [0/9726 (0%)]\tLoss: 0.319698\n",
      "Train Epoch: 3 [1000/9726 (10%)]\tLoss: 0.146247\n",
      "Train Epoch: 3 [2000/9726 (20%)]\tLoss: 0.186735\n",
      "Train Epoch: 3 [3000/9726 (31%)]\tLoss: 0.164831\n",
      "Train Epoch: 3 [4000/9726 (41%)]\tLoss: 0.232383\n",
      "Train Epoch: 3 [5000/9726 (51%)]\tLoss: 0.232197\n",
      "Train Epoch: 3 [6000/9726 (61%)]\tLoss: 0.327537\n",
      "Train Epoch: 3 [7000/9726 (71%)]\tLoss: 0.177156\n",
      "Train Epoch: 3 [8000/9726 (82%)]\tLoss: 0.369366\n",
      "Train Epoch: 3 [9000/9726 (92%)]\tLoss: 0.311639\n",
      "Train Epoch: 4 [0/9726 (0%)]\tLoss: 0.201538\n",
      "Train Epoch: 4 [1000/9726 (10%)]\tLoss: 0.191036\n",
      "Train Epoch: 4 [2000/9726 (20%)]\tLoss: 0.103061\n",
      "Train Epoch: 4 [3000/9726 (31%)]\tLoss: 0.269891\n",
      "Train Epoch: 4 [4000/9726 (41%)]\tLoss: 0.223718\n",
      "Train Epoch: 4 [5000/9726 (51%)]\tLoss: 0.289247\n",
      "Train Epoch: 4 [6000/9726 (61%)]\tLoss: 0.116250\n",
      "Train Epoch: 4 [7000/9726 (71%)]\tLoss: 0.163011\n",
      "Train Epoch: 4 [8000/9726 (82%)]\tLoss: 0.136987\n",
      "Train Epoch: 4 [9000/9726 (92%)]\tLoss: 0.226740\n",
      "Train Epoch: 5 [0/9726 (0%)]\tLoss: 0.188333\n",
      "Train Epoch: 5 [1000/9726 (10%)]\tLoss: 0.269297\n",
      "Train Epoch: 5 [2000/9726 (20%)]\tLoss: 0.225864\n",
      "Train Epoch: 5 [3000/9726 (31%)]\tLoss: 0.183293\n",
      "Train Epoch: 5 [4000/9726 (41%)]\tLoss: 0.182754\n",
      "Train Epoch: 5 [5000/9726 (51%)]\tLoss: 0.253700\n",
      "Train Epoch: 5 [6000/9726 (61%)]\tLoss: 0.143992\n",
      "Train Epoch: 5 [7000/9726 (71%)]\tLoss: 0.241273\n",
      "Train Epoch: 5 [8000/9726 (82%)]\tLoss: 0.129153\n",
      "Train Epoch: 5 [9000/9726 (92%)]\tLoss: 0.166257\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/6491 (0%)]\tLoss: 0.614366\n",
      "Train Epoch: 1 [1000/6491 (15%)]\tLoss: 0.348784\n",
      "Train Epoch: 1 [2000/6491 (31%)]\tLoss: 0.393370\n",
      "Train Epoch: 1 [3000/6491 (46%)]\tLoss: 0.342958\n",
      "Train Epoch: 1 [4000/6491 (62%)]\tLoss: 0.446776\n",
      "Train Epoch: 1 [5000/6491 (77%)]\tLoss: 0.227214\n",
      "Train Epoch: 1 [6000/6491 (92%)]\tLoss: 0.382582\n",
      "Train Epoch: 2 [0/6491 (0%)]\tLoss: 0.282035\n",
      "Train Epoch: 2 [1000/6491 (15%)]\tLoss: 0.351878\n",
      "Train Epoch: 2 [2000/6491 (31%)]\tLoss: 0.327581\n",
      "Train Epoch: 2 [3000/6491 (46%)]\tLoss: 0.255583\n",
      "Train Epoch: 2 [4000/6491 (62%)]\tLoss: 0.287371\n",
      "Train Epoch: 2 [5000/6491 (77%)]\tLoss: 0.281302\n",
      "Train Epoch: 2 [6000/6491 (92%)]\tLoss: 0.457619\n",
      "Train Epoch: 3 [0/6491 (0%)]\tLoss: 0.253021\n",
      "Train Epoch: 3 [1000/6491 (15%)]\tLoss: 0.303160\n",
      "Train Epoch: 3 [2000/6491 (31%)]\tLoss: 0.363169\n",
      "Train Epoch: 3 [3000/6491 (46%)]\tLoss: 0.343185\n",
      "Train Epoch: 3 [4000/6491 (62%)]\tLoss: 0.220342\n",
      "Train Epoch: 3 [5000/6491 (77%)]\tLoss: 0.334870\n",
      "Train Epoch: 3 [6000/6491 (92%)]\tLoss: 0.325279\n",
      "Train Epoch: 4 [0/6491 (0%)]\tLoss: 0.386721\n",
      "Train Epoch: 4 [1000/6491 (15%)]\tLoss: 0.199883\n",
      "Train Epoch: 4 [2000/6491 (31%)]\tLoss: 0.342476\n",
      "Train Epoch: 4 [3000/6491 (46%)]\tLoss: 0.252512\n",
      "Train Epoch: 4 [4000/6491 (62%)]\tLoss: 0.430533\n",
      "Train Epoch: 4 [5000/6491 (77%)]\tLoss: 0.222428\n",
      "Train Epoch: 4 [6000/6491 (92%)]\tLoss: 0.226794\n",
      "Train Epoch: 5 [0/6491 (0%)]\tLoss: 0.379460\n",
      "Train Epoch: 5 [1000/6491 (15%)]\tLoss: 0.221876\n",
      "Train Epoch: 5 [2000/6491 (31%)]\tLoss: 0.390319\n",
      "Train Epoch: 5 [3000/6491 (46%)]\tLoss: 0.299137\n",
      "Train Epoch: 5 [4000/6491 (62%)]\tLoss: 0.322918\n",
      "Train Epoch: 5 [5000/6491 (77%)]\tLoss: 0.270726\n",
      "Train Epoch: 5 [6000/6491 (92%)]\tLoss: 0.319742\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/14118 (0%)]\tLoss: 0.480495\n",
      "Train Epoch: 1 [1000/14118 (7%)]\tLoss: 0.193383\n",
      "Train Epoch: 1 [2000/14118 (14%)]\tLoss: 0.145167\n",
      "Train Epoch: 1 [3000/14118 (21%)]\tLoss: 0.175063\n",
      "Train Epoch: 1 [4000/14118 (28%)]\tLoss: 0.258633\n",
      "Train Epoch: 1 [5000/14118 (35%)]\tLoss: 0.157673\n",
      "Train Epoch: 1 [6000/14118 (42%)]\tLoss: 0.334050\n",
      "Train Epoch: 1 [7000/14118 (49%)]\tLoss: 0.217243\n",
      "Train Epoch: 1 [8000/14118 (56%)]\tLoss: 0.230008\n",
      "Train Epoch: 1 [9000/14118 (63%)]\tLoss: 0.163158\n",
      "Train Epoch: 1 [10000/14118 (70%)]\tLoss: 0.163608\n",
      "Train Epoch: 1 [11000/14118 (77%)]\tLoss: 0.216515\n",
      "Train Epoch: 1 [12000/14118 (85%)]\tLoss: 0.182656\n",
      "Train Epoch: 1 [13000/14118 (92%)]\tLoss: 0.169971\n",
      "Train Epoch: 1 [14000/14118 (99%)]\tLoss: 0.219245\n",
      "Train Epoch: 2 [0/14118 (0%)]\tLoss: 0.111217\n",
      "Train Epoch: 2 [1000/14118 (7%)]\tLoss: 0.432168\n",
      "Train Epoch: 2 [2000/14118 (14%)]\tLoss: 0.217094\n",
      "Train Epoch: 2 [3000/14118 (21%)]\tLoss: 0.205924\n",
      "Train Epoch: 2 [4000/14118 (28%)]\tLoss: 0.345643\n",
      "Train Epoch: 2 [5000/14118 (35%)]\tLoss: 0.211514\n",
      "Train Epoch: 2 [6000/14118 (42%)]\tLoss: 0.144580\n",
      "Train Epoch: 2 [7000/14118 (49%)]\tLoss: 0.248127\n",
      "Train Epoch: 2 [8000/14118 (56%)]\tLoss: 0.158157\n",
      "Train Epoch: 2 [9000/14118 (63%)]\tLoss: 0.088156\n",
      "Train Epoch: 2 [10000/14118 (70%)]\tLoss: 0.249791\n",
      "Train Epoch: 2 [11000/14118 (77%)]\tLoss: 0.213633\n",
      "Train Epoch: 2 [12000/14118 (85%)]\tLoss: 0.265608\n",
      "Train Epoch: 2 [13000/14118 (92%)]\tLoss: 0.124418\n",
      "Train Epoch: 2 [14000/14118 (99%)]\tLoss: 0.137359\n",
      "Train Epoch: 3 [0/14118 (0%)]\tLoss: 0.218451\n",
      "Train Epoch: 3 [1000/14118 (7%)]\tLoss: 0.147712\n",
      "Train Epoch: 3 [2000/14118 (14%)]\tLoss: 0.193880\n",
      "Train Epoch: 3 [3000/14118 (21%)]\tLoss: 0.159611\n",
      "Train Epoch: 3 [4000/14118 (28%)]\tLoss: 0.150322\n",
      "Train Epoch: 3 [5000/14118 (35%)]\tLoss: 0.108860\n",
      "Train Epoch: 3 [6000/14118 (42%)]\tLoss: 0.137852\n",
      "Train Epoch: 3 [7000/14118 (49%)]\tLoss: 0.160125\n",
      "Train Epoch: 3 [8000/14118 (56%)]\tLoss: 0.236710\n",
      "Train Epoch: 3 [9000/14118 (63%)]\tLoss: 0.205751\n",
      "Train Epoch: 3 [10000/14118 (70%)]\tLoss: 0.155070\n",
      "Train Epoch: 3 [11000/14118 (77%)]\tLoss: 0.210387\n",
      "Train Epoch: 3 [12000/14118 (85%)]\tLoss: 0.262904\n",
      "Train Epoch: 3 [13000/14118 (92%)]\tLoss: 0.202684\n",
      "Train Epoch: 3 [14000/14118 (99%)]\tLoss: 0.142255\n",
      "Train Epoch: 4 [0/14118 (0%)]\tLoss: 0.204375\n",
      "Train Epoch: 4 [1000/14118 (7%)]\tLoss: 0.197509\n",
      "Train Epoch: 4 [2000/14118 (14%)]\tLoss: 0.241975\n",
      "Train Epoch: 4 [3000/14118 (21%)]\tLoss: 0.174805\n",
      "Train Epoch: 4 [4000/14118 (28%)]\tLoss: 0.215228\n",
      "Train Epoch: 4 [5000/14118 (35%)]\tLoss: 0.104340\n",
      "Train Epoch: 4 [6000/14118 (42%)]\tLoss: 0.096896\n",
      "Train Epoch: 4 [7000/14118 (49%)]\tLoss: 0.277337\n",
      "Train Epoch: 4 [8000/14118 (56%)]\tLoss: 0.168923\n",
      "Train Epoch: 4 [9000/14118 (63%)]\tLoss: 0.134503\n",
      "Train Epoch: 4 [10000/14118 (70%)]\tLoss: 0.117297\n",
      "Train Epoch: 4 [11000/14118 (77%)]\tLoss: 0.165135\n",
      "Train Epoch: 4 [12000/14118 (85%)]\tLoss: 0.310174\n",
      "Train Epoch: 4 [13000/14118 (92%)]\tLoss: 0.203846\n",
      "Train Epoch: 4 [14000/14118 (99%)]\tLoss: 0.143090\n",
      "Train Epoch: 5 [0/14118 (0%)]\tLoss: 0.128887\n",
      "Train Epoch: 5 [1000/14118 (7%)]\tLoss: 0.193548\n",
      "Train Epoch: 5 [2000/14118 (14%)]\tLoss: 0.128952\n",
      "Train Epoch: 5 [3000/14118 (21%)]\tLoss: 0.252827\n",
      "Train Epoch: 5 [4000/14118 (28%)]\tLoss: 0.142714\n",
      "Train Epoch: 5 [5000/14118 (35%)]\tLoss: 0.103781\n",
      "Train Epoch: 5 [6000/14118 (42%)]\tLoss: 0.173038\n",
      "Train Epoch: 5 [7000/14118 (49%)]\tLoss: 0.175567\n",
      "Train Epoch: 5 [8000/14118 (56%)]\tLoss: 0.123480\n",
      "Train Epoch: 5 [9000/14118 (63%)]\tLoss: 0.151489\n",
      "Train Epoch: 5 [10000/14118 (70%)]\tLoss: 0.175967\n",
      "Train Epoch: 5 [11000/14118 (77%)]\tLoss: 0.177933\n",
      "Train Epoch: 5 [12000/14118 (85%)]\tLoss: 0.128813\n",
      "Train Epoch: 5 [13000/14118 (92%)]\tLoss: 0.302269\n",
      "Train Epoch: 5 [14000/14118 (99%)]\tLoss: 0.261050\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/9414 (0%)]\tLoss: 0.271175\n",
      "Train Epoch: 1 [1000/9414 (11%)]\tLoss: 0.180638\n",
      "Train Epoch: 1 [2000/9414 (21%)]\tLoss: 0.209822\n",
      "Train Epoch: 1 [3000/9414 (32%)]\tLoss: 0.289869\n",
      "Train Epoch: 1 [4000/9414 (42%)]\tLoss: 0.284297\n",
      "Train Epoch: 1 [5000/9414 (53%)]\tLoss: 0.261262\n",
      "Train Epoch: 1 [6000/9414 (63%)]\tLoss: 0.176352\n",
      "Train Epoch: 1 [7000/9414 (74%)]\tLoss: 0.256245\n",
      "Train Epoch: 1 [8000/9414 (84%)]\tLoss: 0.290326\n",
      "Train Epoch: 1 [9000/9414 (95%)]\tLoss: 0.326265\n",
      "Train Epoch: 2 [0/9414 (0%)]\tLoss: 0.174310\n",
      "Train Epoch: 2 [1000/9414 (11%)]\tLoss: 0.288746\n",
      "Train Epoch: 2 [2000/9414 (21%)]\tLoss: 0.237552\n",
      "Train Epoch: 2 [3000/9414 (32%)]\tLoss: 0.344519\n",
      "Train Epoch: 2 [4000/9414 (42%)]\tLoss: 0.206181\n",
      "Train Epoch: 2 [5000/9414 (53%)]\tLoss: 0.196335\n",
      "Train Epoch: 2 [6000/9414 (63%)]\tLoss: 0.251782\n",
      "Train Epoch: 2 [7000/9414 (74%)]\tLoss: 0.307811\n",
      "Train Epoch: 2 [8000/9414 (84%)]\tLoss: 0.259917\n",
      "Train Epoch: 2 [9000/9414 (95%)]\tLoss: 0.197948\n",
      "Train Epoch: 3 [0/9414 (0%)]\tLoss: 0.199024\n",
      "Train Epoch: 3 [1000/9414 (11%)]\tLoss: 0.173490\n",
      "Train Epoch: 3 [2000/9414 (21%)]\tLoss: 0.189589\n",
      "Train Epoch: 3 [3000/9414 (32%)]\tLoss: 0.401727\n",
      "Train Epoch: 3 [4000/9414 (42%)]\tLoss: 0.372789\n",
      "Train Epoch: 3 [5000/9414 (53%)]\tLoss: 0.355502\n",
      "Train Epoch: 3 [6000/9414 (63%)]\tLoss: 0.251772\n",
      "Train Epoch: 3 [7000/9414 (74%)]\tLoss: 0.275472\n",
      "Train Epoch: 3 [8000/9414 (84%)]\tLoss: 0.181348\n",
      "Train Epoch: 3 [9000/9414 (95%)]\tLoss: 0.197387\n",
      "Train Epoch: 4 [0/9414 (0%)]\tLoss: 0.315153\n",
      "Train Epoch: 4 [1000/9414 (11%)]\tLoss: 0.283871\n",
      "Train Epoch: 4 [2000/9414 (21%)]\tLoss: 0.271746\n",
      "Train Epoch: 4 [3000/9414 (32%)]\tLoss: 0.309778\n",
      "Train Epoch: 4 [4000/9414 (42%)]\tLoss: 0.286039\n",
      "Train Epoch: 4 [5000/9414 (53%)]\tLoss: 0.174837\n",
      "Train Epoch: 4 [6000/9414 (63%)]\tLoss: 0.125481\n",
      "Train Epoch: 4 [7000/9414 (74%)]\tLoss: 0.140430\n",
      "Train Epoch: 4 [8000/9414 (84%)]\tLoss: 0.181724\n",
      "Train Epoch: 4 [9000/9414 (95%)]\tLoss: 0.190575\n",
      "Train Epoch: 5 [0/9414 (0%)]\tLoss: 0.134009\n",
      "Train Epoch: 5 [1000/9414 (11%)]\tLoss: 0.277927\n",
      "Train Epoch: 5 [2000/9414 (21%)]\tLoss: 0.277517\n",
      "Train Epoch: 5 [3000/9414 (32%)]\tLoss: 0.248173\n",
      "Train Epoch: 5 [4000/9414 (42%)]\tLoss: 0.138431\n",
      "Train Epoch: 5 [5000/9414 (53%)]\tLoss: 0.333817\n",
      "Train Epoch: 5 [6000/9414 (63%)]\tLoss: 0.246757\n",
      "Train Epoch: 5 [7000/9414 (74%)]\tLoss: 0.223307\n",
      "Train Epoch: 5 [8000/9414 (84%)]\tLoss: 0.234106\n",
      "Train Epoch: 5 [9000/9414 (95%)]\tLoss: 0.154990\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "6\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.3828, Accuracy: 8609/10000 (86%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/8440 (0%)]\tLoss: 0.205663\n",
      "Train Epoch: 1 [1000/8440 (12%)]\tLoss: 0.255027\n",
      "Train Epoch: 1 [2000/8440 (24%)]\tLoss: 0.318312\n",
      "Train Epoch: 1 [3000/8440 (35%)]\tLoss: 0.287060\n",
      "Train Epoch: 1 [4000/8440 (47%)]\tLoss: 0.347691\n",
      "Train Epoch: 1 [5000/8440 (59%)]\tLoss: 0.221360\n",
      "Train Epoch: 1 [6000/8440 (71%)]\tLoss: 0.302411\n",
      "Train Epoch: 1 [7000/8440 (82%)]\tLoss: 0.356494\n",
      "Train Epoch: 1 [8000/8440 (94%)]\tLoss: 0.328963\n",
      "Train Epoch: 2 [0/8440 (0%)]\tLoss: 0.219738\n",
      "Train Epoch: 2 [1000/8440 (12%)]\tLoss: 0.333796\n",
      "Train Epoch: 2 [2000/8440 (24%)]\tLoss: 0.323254\n",
      "Train Epoch: 2 [3000/8440 (35%)]\tLoss: 0.307220\n",
      "Train Epoch: 2 [4000/8440 (47%)]\tLoss: 0.256972\n",
      "Train Epoch: 2 [5000/8440 (59%)]\tLoss: 0.343357\n",
      "Train Epoch: 2 [6000/8440 (71%)]\tLoss: 0.177437\n",
      "Train Epoch: 2 [7000/8440 (82%)]\tLoss: 0.313556\n",
      "Train Epoch: 2 [8000/8440 (94%)]\tLoss: 0.180184\n",
      "Train Epoch: 3 [0/8440 (0%)]\tLoss: 0.220376\n",
      "Train Epoch: 3 [1000/8440 (12%)]\tLoss: 0.222918\n",
      "Train Epoch: 3 [2000/8440 (24%)]\tLoss: 0.231530\n",
      "Train Epoch: 3 [3000/8440 (35%)]\tLoss: 0.207046\n",
      "Train Epoch: 3 [4000/8440 (47%)]\tLoss: 0.215048\n",
      "Train Epoch: 3 [5000/8440 (59%)]\tLoss: 0.322628\n",
      "Train Epoch: 3 [6000/8440 (71%)]\tLoss: 0.250950\n",
      "Train Epoch: 3 [7000/8440 (82%)]\tLoss: 0.354660\n",
      "Train Epoch: 3 [8000/8440 (94%)]\tLoss: 0.367446\n",
      "Train Epoch: 4 [0/8440 (0%)]\tLoss: 0.252225\n",
      "Train Epoch: 4 [1000/8440 (12%)]\tLoss: 0.227690\n",
      "Train Epoch: 4 [2000/8440 (24%)]\tLoss: 0.212901\n",
      "Train Epoch: 4 [3000/8440 (35%)]\tLoss: 0.256725\n",
      "Train Epoch: 4 [4000/8440 (47%)]\tLoss: 0.225868\n",
      "Train Epoch: 4 [5000/8440 (59%)]\tLoss: 0.256587\n",
      "Train Epoch: 4 [6000/8440 (71%)]\tLoss: 0.283448\n",
      "Train Epoch: 4 [7000/8440 (82%)]\tLoss: 0.168955\n",
      "Train Epoch: 4 [8000/8440 (94%)]\tLoss: 0.255353\n",
      "Train Epoch: 5 [0/8440 (0%)]\tLoss: 0.224746\n",
      "Train Epoch: 5 [1000/8440 (12%)]\tLoss: 0.277065\n",
      "Train Epoch: 5 [2000/8440 (24%)]\tLoss: 0.380043\n",
      "Train Epoch: 5 [3000/8440 (35%)]\tLoss: 0.197293\n",
      "Train Epoch: 5 [4000/8440 (47%)]\tLoss: 0.281939\n",
      "Train Epoch: 5 [5000/8440 (59%)]\tLoss: 0.189374\n",
      "Train Epoch: 5 [6000/8440 (71%)]\tLoss: 0.275001\n",
      "Train Epoch: 5 [7000/8440 (82%)]\tLoss: 0.282400\n",
      "Train Epoch: 5 [8000/8440 (94%)]\tLoss: 0.270988\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11811 (0%)]\tLoss: 0.160609\n",
      "Train Epoch: 1 [1000/11811 (8%)]\tLoss: 0.130541\n",
      "Train Epoch: 1 [2000/11811 (17%)]\tLoss: 0.133287\n",
      "Train Epoch: 1 [3000/11811 (25%)]\tLoss: 0.144232\n",
      "Train Epoch: 1 [4000/11811 (34%)]\tLoss: 0.148880\n",
      "Train Epoch: 1 [5000/11811 (42%)]\tLoss: 0.090694\n",
      "Train Epoch: 1 [6000/11811 (50%)]\tLoss: 0.060704\n",
      "Train Epoch: 1 [7000/11811 (59%)]\tLoss: 0.076119\n",
      "Train Epoch: 1 [8000/11811 (67%)]\tLoss: 0.126583\n",
      "Train Epoch: 1 [9000/11811 (76%)]\tLoss: 0.168125\n",
      "Train Epoch: 1 [10000/11811 (84%)]\tLoss: 0.050211\n",
      "Train Epoch: 1 [11000/11811 (92%)]\tLoss: 0.267991\n",
      "Train Epoch: 2 [0/11811 (0%)]\tLoss: 0.210988\n",
      "Train Epoch: 2 [1000/11811 (8%)]\tLoss: 0.108415\n",
      "Train Epoch: 2 [2000/11811 (17%)]\tLoss: 0.107294\n",
      "Train Epoch: 2 [3000/11811 (25%)]\tLoss: 0.105384\n",
      "Train Epoch: 2 [4000/11811 (34%)]\tLoss: 0.114490\n",
      "Train Epoch: 2 [5000/11811 (42%)]\tLoss: 0.069833\n",
      "Train Epoch: 2 [6000/11811 (50%)]\tLoss: 0.100600\n",
      "Train Epoch: 2 [7000/11811 (59%)]\tLoss: 0.133965\n",
      "Train Epoch: 2 [8000/11811 (67%)]\tLoss: 0.206106\n",
      "Train Epoch: 2 [9000/11811 (76%)]\tLoss: 0.025364\n",
      "Train Epoch: 2 [10000/11811 (84%)]\tLoss: 0.061739\n",
      "Train Epoch: 2 [11000/11811 (92%)]\tLoss: 0.242470\n",
      "Train Epoch: 3 [0/11811 (0%)]\tLoss: 0.092864\n",
      "Train Epoch: 3 [1000/11811 (8%)]\tLoss: 0.233111\n",
      "Train Epoch: 3 [2000/11811 (17%)]\tLoss: 0.056871\n",
      "Train Epoch: 3 [3000/11811 (25%)]\tLoss: 0.072197\n",
      "Train Epoch: 3 [4000/11811 (34%)]\tLoss: 0.148002\n",
      "Train Epoch: 3 [5000/11811 (42%)]\tLoss: 0.111032\n",
      "Train Epoch: 3 [6000/11811 (50%)]\tLoss: 0.093266\n",
      "Train Epoch: 3 [7000/11811 (59%)]\tLoss: 0.085628\n",
      "Train Epoch: 3 [8000/11811 (67%)]\tLoss: 0.099421\n",
      "Train Epoch: 3 [9000/11811 (76%)]\tLoss: 0.089943\n",
      "Train Epoch: 3 [10000/11811 (84%)]\tLoss: 0.180185\n",
      "Train Epoch: 3 [11000/11811 (92%)]\tLoss: 0.114156\n",
      "Train Epoch: 4 [0/11811 (0%)]\tLoss: 0.038609\n",
      "Train Epoch: 4 [1000/11811 (8%)]\tLoss: 0.136363\n",
      "Train Epoch: 4 [2000/11811 (17%)]\tLoss: 0.060743\n",
      "Train Epoch: 4 [3000/11811 (25%)]\tLoss: 0.053989\n",
      "Train Epoch: 4 [4000/11811 (34%)]\tLoss: 0.125430\n",
      "Train Epoch: 4 [5000/11811 (42%)]\tLoss: 0.117397\n",
      "Train Epoch: 4 [6000/11811 (50%)]\tLoss: 0.079122\n",
      "Train Epoch: 4 [7000/11811 (59%)]\tLoss: 0.226551\n",
      "Train Epoch: 4 [8000/11811 (67%)]\tLoss: 0.105368\n",
      "Train Epoch: 4 [9000/11811 (76%)]\tLoss: 0.066356\n",
      "Train Epoch: 4 [10000/11811 (84%)]\tLoss: 0.163091\n",
      "Train Epoch: 4 [11000/11811 (92%)]\tLoss: 0.174021\n",
      "Train Epoch: 5 [0/11811 (0%)]\tLoss: 0.084407\n",
      "Train Epoch: 5 [1000/11811 (8%)]\tLoss: 0.173134\n",
      "Train Epoch: 5 [2000/11811 (17%)]\tLoss: 0.074331\n",
      "Train Epoch: 5 [3000/11811 (25%)]\tLoss: 0.082664\n",
      "Train Epoch: 5 [4000/11811 (34%)]\tLoss: 0.114946\n",
      "Train Epoch: 5 [5000/11811 (42%)]\tLoss: 0.046459\n",
      "Train Epoch: 5 [6000/11811 (50%)]\tLoss: 0.044341\n",
      "Train Epoch: 5 [7000/11811 (59%)]\tLoss: 0.081432\n",
      "Train Epoch: 5 [8000/11811 (67%)]\tLoss: 0.088412\n",
      "Train Epoch: 5 [9000/11811 (76%)]\tLoss: 0.047440\n",
      "Train Epoch: 5 [10000/11811 (84%)]\tLoss: 0.064315\n",
      "Train Epoch: 5 [11000/11811 (92%)]\tLoss: 0.105083\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/9726 (0%)]\tLoss: 0.323922\n",
      "Train Epoch: 1 [1000/9726 (10%)]\tLoss: 0.273807\n",
      "Train Epoch: 1 [2000/9726 (20%)]\tLoss: 0.174662\n",
      "Train Epoch: 1 [3000/9726 (31%)]\tLoss: 0.235084\n",
      "Train Epoch: 1 [4000/9726 (41%)]\tLoss: 0.191630\n",
      "Train Epoch: 1 [5000/9726 (51%)]\tLoss: 0.181159\n",
      "Train Epoch: 1 [6000/9726 (61%)]\tLoss: 0.240442\n",
      "Train Epoch: 1 [7000/9726 (71%)]\tLoss: 0.243338\n",
      "Train Epoch: 1 [8000/9726 (82%)]\tLoss: 0.259454\n",
      "Train Epoch: 1 [9000/9726 (92%)]\tLoss: 0.224252\n",
      "Train Epoch: 2 [0/9726 (0%)]\tLoss: 0.224323\n",
      "Train Epoch: 2 [1000/9726 (10%)]\tLoss: 0.229518\n",
      "Train Epoch: 2 [2000/9726 (20%)]\tLoss: 0.245689\n",
      "Train Epoch: 2 [3000/9726 (31%)]\tLoss: 0.222923\n",
      "Train Epoch: 2 [4000/9726 (41%)]\tLoss: 0.212917\n",
      "Train Epoch: 2 [5000/9726 (51%)]\tLoss: 0.242795\n",
      "Train Epoch: 2 [6000/9726 (61%)]\tLoss: 0.259349\n",
      "Train Epoch: 2 [7000/9726 (71%)]\tLoss: 0.240901\n",
      "Train Epoch: 2 [8000/9726 (82%)]\tLoss: 0.297272\n",
      "Train Epoch: 2 [9000/9726 (92%)]\tLoss: 0.331829\n",
      "Train Epoch: 3 [0/9726 (0%)]\tLoss: 0.233989\n",
      "Train Epoch: 3 [1000/9726 (10%)]\tLoss: 0.240021\n",
      "Train Epoch: 3 [2000/9726 (20%)]\tLoss: 0.368297\n",
      "Train Epoch: 3 [3000/9726 (31%)]\tLoss: 0.214201\n",
      "Train Epoch: 3 [4000/9726 (41%)]\tLoss: 0.197127\n",
      "Train Epoch: 3 [5000/9726 (51%)]\tLoss: 0.280733\n",
      "Train Epoch: 3 [6000/9726 (61%)]\tLoss: 0.215108\n",
      "Train Epoch: 3 [7000/9726 (71%)]\tLoss: 0.140977\n",
      "Train Epoch: 3 [8000/9726 (82%)]\tLoss: 0.360125\n",
      "Train Epoch: 3 [9000/9726 (92%)]\tLoss: 0.181422\n",
      "Train Epoch: 4 [0/9726 (0%)]\tLoss: 0.285583\n",
      "Train Epoch: 4 [1000/9726 (10%)]\tLoss: 0.192182\n",
      "Train Epoch: 4 [2000/9726 (20%)]\tLoss: 0.233060\n",
      "Train Epoch: 4 [3000/9726 (31%)]\tLoss: 0.204581\n",
      "Train Epoch: 4 [4000/9726 (41%)]\tLoss: 0.231102\n",
      "Train Epoch: 4 [5000/9726 (51%)]\tLoss: 0.170766\n",
      "Train Epoch: 4 [6000/9726 (61%)]\tLoss: 0.154083\n",
      "Train Epoch: 4 [7000/9726 (71%)]\tLoss: 0.150605\n",
      "Train Epoch: 4 [8000/9726 (82%)]\tLoss: 0.212972\n",
      "Train Epoch: 4 [9000/9726 (92%)]\tLoss: 0.224962\n",
      "Train Epoch: 5 [0/9726 (0%)]\tLoss: 0.187736\n",
      "Train Epoch: 5 [1000/9726 (10%)]\tLoss: 0.117370\n",
      "Train Epoch: 5 [2000/9726 (20%)]\tLoss: 0.166832\n",
      "Train Epoch: 5 [3000/9726 (31%)]\tLoss: 0.229908\n",
      "Train Epoch: 5 [4000/9726 (41%)]\tLoss: 0.174140\n",
      "Train Epoch: 5 [5000/9726 (51%)]\tLoss: 0.249512\n",
      "Train Epoch: 5 [6000/9726 (61%)]\tLoss: 0.307405\n",
      "Train Epoch: 5 [7000/9726 (71%)]\tLoss: 0.191725\n",
      "Train Epoch: 5 [8000/9726 (82%)]\tLoss: 0.213406\n",
      "Train Epoch: 5 [9000/9726 (92%)]\tLoss: 0.204781\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/6491 (0%)]\tLoss: 0.387668\n",
      "Train Epoch: 1 [1000/6491 (15%)]\tLoss: 0.300665\n",
      "Train Epoch: 1 [2000/6491 (31%)]\tLoss: 0.355380\n",
      "Train Epoch: 1 [3000/6491 (46%)]\tLoss: 0.333806\n",
      "Train Epoch: 1 [4000/6491 (62%)]\tLoss: 0.249763\n",
      "Train Epoch: 1 [5000/6491 (77%)]\tLoss: 0.283750\n",
      "Train Epoch: 1 [6000/6491 (92%)]\tLoss: 0.339067\n",
      "Train Epoch: 2 [0/6491 (0%)]\tLoss: 0.227554\n",
      "Train Epoch: 2 [1000/6491 (15%)]\tLoss: 0.242410\n",
      "Train Epoch: 2 [2000/6491 (31%)]\tLoss: 0.229681\n",
      "Train Epoch: 2 [3000/6491 (46%)]\tLoss: 0.409751\n",
      "Train Epoch: 2 [4000/6491 (62%)]\tLoss: 0.162905\n",
      "Train Epoch: 2 [5000/6491 (77%)]\tLoss: 0.326188\n",
      "Train Epoch: 2 [6000/6491 (92%)]\tLoss: 0.367812\n",
      "Train Epoch: 3 [0/6491 (0%)]\tLoss: 0.225068\n",
      "Train Epoch: 3 [1000/6491 (15%)]\tLoss: 0.296420\n",
      "Train Epoch: 3 [2000/6491 (31%)]\tLoss: 0.312366\n",
      "Train Epoch: 3 [3000/6491 (46%)]\tLoss: 0.418001\n",
      "Train Epoch: 3 [4000/6491 (62%)]\tLoss: 0.307098\n",
      "Train Epoch: 3 [5000/6491 (77%)]\tLoss: 0.345874\n",
      "Train Epoch: 3 [6000/6491 (92%)]\tLoss: 0.181937\n",
      "Train Epoch: 4 [0/6491 (0%)]\tLoss: 0.159537\n",
      "Train Epoch: 4 [1000/6491 (15%)]\tLoss: 0.363874\n",
      "Train Epoch: 4 [2000/6491 (31%)]\tLoss: 0.311672\n",
      "Train Epoch: 4 [3000/6491 (46%)]\tLoss: 0.370548\n",
      "Train Epoch: 4 [4000/6491 (62%)]\tLoss: 0.292581\n",
      "Train Epoch: 4 [5000/6491 (77%)]\tLoss: 0.157152\n",
      "Train Epoch: 4 [6000/6491 (92%)]\tLoss: 0.267334\n",
      "Train Epoch: 5 [0/6491 (0%)]\tLoss: 0.262721\n",
      "Train Epoch: 5 [1000/6491 (15%)]\tLoss: 0.345524\n",
      "Train Epoch: 5 [2000/6491 (31%)]\tLoss: 0.347916\n",
      "Train Epoch: 5 [3000/6491 (46%)]\tLoss: 0.190334\n",
      "Train Epoch: 5 [4000/6491 (62%)]\tLoss: 0.297026\n",
      "Train Epoch: 5 [5000/6491 (77%)]\tLoss: 0.377171\n",
      "Train Epoch: 5 [6000/6491 (92%)]\tLoss: 0.332439\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/14118 (0%)]\tLoss: 0.470610\n",
      "Train Epoch: 1 [1000/14118 (7%)]\tLoss: 0.212492\n",
      "Train Epoch: 1 [2000/14118 (14%)]\tLoss: 0.256766\n",
      "Train Epoch: 1 [3000/14118 (21%)]\tLoss: 0.259648\n",
      "Train Epoch: 1 [4000/14118 (28%)]\tLoss: 0.207095\n",
      "Train Epoch: 1 [5000/14118 (35%)]\tLoss: 0.316468\n",
      "Train Epoch: 1 [6000/14118 (42%)]\tLoss: 0.252385\n",
      "Train Epoch: 1 [7000/14118 (49%)]\tLoss: 0.166092\n",
      "Train Epoch: 1 [8000/14118 (56%)]\tLoss: 0.212432\n",
      "Train Epoch: 1 [9000/14118 (63%)]\tLoss: 0.282720\n",
      "Train Epoch: 1 [10000/14118 (70%)]\tLoss: 0.121152\n",
      "Train Epoch: 1 [11000/14118 (77%)]\tLoss: 0.144623\n",
      "Train Epoch: 1 [12000/14118 (85%)]\tLoss: 0.085062\n",
      "Train Epoch: 1 [13000/14118 (92%)]\tLoss: 0.195835\n",
      "Train Epoch: 1 [14000/14118 (99%)]\tLoss: 0.178501\n",
      "Train Epoch: 2 [0/14118 (0%)]\tLoss: 0.279429\n",
      "Train Epoch: 2 [1000/14118 (7%)]\tLoss: 0.158902\n",
      "Train Epoch: 2 [2000/14118 (14%)]\tLoss: 0.280225\n",
      "Train Epoch: 2 [3000/14118 (21%)]\tLoss: 0.152260\n",
      "Train Epoch: 2 [4000/14118 (28%)]\tLoss: 0.165238\n",
      "Train Epoch: 2 [5000/14118 (35%)]\tLoss: 0.234561\n",
      "Train Epoch: 2 [6000/14118 (42%)]\tLoss: 0.298434\n",
      "Train Epoch: 2 [7000/14118 (49%)]\tLoss: 0.152547\n",
      "Train Epoch: 2 [8000/14118 (56%)]\tLoss: 0.304373\n",
      "Train Epoch: 2 [9000/14118 (63%)]\tLoss: 0.180465\n",
      "Train Epoch: 2 [10000/14118 (70%)]\tLoss: 0.182662\n",
      "Train Epoch: 2 [11000/14118 (77%)]\tLoss: 0.160849\n",
      "Train Epoch: 2 [12000/14118 (85%)]\tLoss: 0.126191\n",
      "Train Epoch: 2 [13000/14118 (92%)]\tLoss: 0.319757\n",
      "Train Epoch: 2 [14000/14118 (99%)]\tLoss: 0.227864\n",
      "Train Epoch: 3 [0/14118 (0%)]\tLoss: 0.221723\n",
      "Train Epoch: 3 [1000/14118 (7%)]\tLoss: 0.239097\n",
      "Train Epoch: 3 [2000/14118 (14%)]\tLoss: 0.231716\n",
      "Train Epoch: 3 [3000/14118 (21%)]\tLoss: 0.246550\n",
      "Train Epoch: 3 [4000/14118 (28%)]\tLoss: 0.207622\n",
      "Train Epoch: 3 [5000/14118 (35%)]\tLoss: 0.366001\n",
      "Train Epoch: 3 [6000/14118 (42%)]\tLoss: 0.087841\n",
      "Train Epoch: 3 [7000/14118 (49%)]\tLoss: 0.170539\n",
      "Train Epoch: 3 [8000/14118 (56%)]\tLoss: 0.198814\n",
      "Train Epoch: 3 [9000/14118 (63%)]\tLoss: 0.179470\n",
      "Train Epoch: 3 [10000/14118 (70%)]\tLoss: 0.105720\n",
      "Train Epoch: 3 [11000/14118 (77%)]\tLoss: 0.220207\n",
      "Train Epoch: 3 [12000/14118 (85%)]\tLoss: 0.183990\n",
      "Train Epoch: 3 [13000/14118 (92%)]\tLoss: 0.196288\n",
      "Train Epoch: 3 [14000/14118 (99%)]\tLoss: 0.159514\n",
      "Train Epoch: 4 [0/14118 (0%)]\tLoss: 0.147688\n",
      "Train Epoch: 4 [1000/14118 (7%)]\tLoss: 0.201261\n",
      "Train Epoch: 4 [2000/14118 (14%)]\tLoss: 0.163021\n",
      "Train Epoch: 4 [3000/14118 (21%)]\tLoss: 0.093841\n",
      "Train Epoch: 4 [4000/14118 (28%)]\tLoss: 0.188152\n",
      "Train Epoch: 4 [5000/14118 (35%)]\tLoss: 0.255058\n",
      "Train Epoch: 4 [6000/14118 (42%)]\tLoss: 0.207433\n",
      "Train Epoch: 4 [7000/14118 (49%)]\tLoss: 0.136713\n",
      "Train Epoch: 4 [8000/14118 (56%)]\tLoss: 0.119707\n",
      "Train Epoch: 4 [9000/14118 (63%)]\tLoss: 0.233387\n",
      "Train Epoch: 4 [10000/14118 (70%)]\tLoss: 0.151703\n",
      "Train Epoch: 4 [11000/14118 (77%)]\tLoss: 0.188221\n",
      "Train Epoch: 4 [12000/14118 (85%)]\tLoss: 0.144414\n",
      "Train Epoch: 4 [13000/14118 (92%)]\tLoss: 0.119897\n",
      "Train Epoch: 4 [14000/14118 (99%)]\tLoss: 0.134606\n",
      "Train Epoch: 5 [0/14118 (0%)]\tLoss: 0.317533\n",
      "Train Epoch: 5 [1000/14118 (7%)]\tLoss: 0.181685\n",
      "Train Epoch: 5 [2000/14118 (14%)]\tLoss: 0.217825\n",
      "Train Epoch: 5 [3000/14118 (21%)]\tLoss: 0.156748\n",
      "Train Epoch: 5 [4000/14118 (28%)]\tLoss: 0.203349\n",
      "Train Epoch: 5 [5000/14118 (35%)]\tLoss: 0.183413\n",
      "Train Epoch: 5 [6000/14118 (42%)]\tLoss: 0.140663\n",
      "Train Epoch: 5 [7000/14118 (49%)]\tLoss: 0.109737\n",
      "Train Epoch: 5 [8000/14118 (56%)]\tLoss: 0.202974\n",
      "Train Epoch: 5 [9000/14118 (63%)]\tLoss: 0.192559\n",
      "Train Epoch: 5 [10000/14118 (70%)]\tLoss: 0.182132\n",
      "Train Epoch: 5 [11000/14118 (77%)]\tLoss: 0.127200\n",
      "Train Epoch: 5 [12000/14118 (85%)]\tLoss: 0.116136\n",
      "Train Epoch: 5 [13000/14118 (92%)]\tLoss: 0.236847\n",
      "Train Epoch: 5 [14000/14118 (99%)]\tLoss: 0.157721\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/9414 (0%)]\tLoss: 0.248512\n",
      "Train Epoch: 1 [1000/9414 (11%)]\tLoss: 0.285265\n",
      "Train Epoch: 1 [2000/9414 (21%)]\tLoss: 0.239719\n",
      "Train Epoch: 1 [3000/9414 (32%)]\tLoss: 0.251289\n",
      "Train Epoch: 1 [4000/9414 (42%)]\tLoss: 0.224847\n",
      "Train Epoch: 1 [5000/9414 (53%)]\tLoss: 0.231843\n",
      "Train Epoch: 1 [6000/9414 (63%)]\tLoss: 0.303539\n",
      "Train Epoch: 1 [7000/9414 (74%)]\tLoss: 0.211477\n",
      "Train Epoch: 1 [8000/9414 (84%)]\tLoss: 0.189894\n",
      "Train Epoch: 1 [9000/9414 (95%)]\tLoss: 0.247007\n",
      "Train Epoch: 2 [0/9414 (0%)]\tLoss: 0.387424\n",
      "Train Epoch: 2 [1000/9414 (11%)]\tLoss: 0.202737\n",
      "Train Epoch: 2 [2000/9414 (21%)]\tLoss: 0.306304\n",
      "Train Epoch: 2 [3000/9414 (32%)]\tLoss: 0.200950\n",
      "Train Epoch: 2 [4000/9414 (42%)]\tLoss: 0.197952\n",
      "Train Epoch: 2 [5000/9414 (53%)]\tLoss: 0.358864\n",
      "Train Epoch: 2 [6000/9414 (63%)]\tLoss: 0.246836\n",
      "Train Epoch: 2 [7000/9414 (74%)]\tLoss: 0.242205\n",
      "Train Epoch: 2 [8000/9414 (84%)]\tLoss: 0.202688\n",
      "Train Epoch: 2 [9000/9414 (95%)]\tLoss: 0.253157\n",
      "Train Epoch: 3 [0/9414 (0%)]\tLoss: 0.288316\n",
      "Train Epoch: 3 [1000/9414 (11%)]\tLoss: 0.305435\n",
      "Train Epoch: 3 [2000/9414 (21%)]\tLoss: 0.271127\n",
      "Train Epoch: 3 [3000/9414 (32%)]\tLoss: 0.356765\n",
      "Train Epoch: 3 [4000/9414 (42%)]\tLoss: 0.334095\n",
      "Train Epoch: 3 [5000/9414 (53%)]\tLoss: 0.309415\n",
      "Train Epoch: 3 [6000/9414 (63%)]\tLoss: 0.223086\n",
      "Train Epoch: 3 [7000/9414 (74%)]\tLoss: 0.161341\n",
      "Train Epoch: 3 [8000/9414 (84%)]\tLoss: 0.248615\n",
      "Train Epoch: 3 [9000/9414 (95%)]\tLoss: 0.294684\n",
      "Train Epoch: 4 [0/9414 (0%)]\tLoss: 0.136488\n",
      "Train Epoch: 4 [1000/9414 (11%)]\tLoss: 0.166276\n",
      "Train Epoch: 4 [2000/9414 (21%)]\tLoss: 0.184086\n",
      "Train Epoch: 4 [3000/9414 (32%)]\tLoss: 0.223043\n",
      "Train Epoch: 4 [4000/9414 (42%)]\tLoss: 0.199810\n",
      "Train Epoch: 4 [5000/9414 (53%)]\tLoss: 0.243155\n",
      "Train Epoch: 4 [6000/9414 (63%)]\tLoss: 0.233164\n",
      "Train Epoch: 4 [7000/9414 (74%)]\tLoss: 0.173797\n",
      "Train Epoch: 4 [8000/9414 (84%)]\tLoss: 0.243683\n",
      "Train Epoch: 4 [9000/9414 (95%)]\tLoss: 0.212483\n",
      "Train Epoch: 5 [0/9414 (0%)]\tLoss: 0.131284\n",
      "Train Epoch: 5 [1000/9414 (11%)]\tLoss: 0.172989\n",
      "Train Epoch: 5 [2000/9414 (21%)]\tLoss: 0.159201\n",
      "Train Epoch: 5 [3000/9414 (32%)]\tLoss: 0.129073\n",
      "Train Epoch: 5 [4000/9414 (42%)]\tLoss: 0.183648\n",
      "Train Epoch: 5 [5000/9414 (53%)]\tLoss: 0.249091\n",
      "Train Epoch: 5 [6000/9414 (63%)]\tLoss: 0.269144\n",
      "Train Epoch: 5 [7000/9414 (74%)]\tLoss: 0.215672\n",
      "Train Epoch: 5 [8000/9414 (84%)]\tLoss: 0.179919\n",
      "Train Epoch: 5 [9000/9414 (95%)]\tLoss: 0.142183\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "6\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.3832, Accuracy: 8627/10000 (86%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/8440 (0%)]\tLoss: 0.241649\n",
      "Train Epoch: 1 [1000/8440 (12%)]\tLoss: 0.296144\n",
      "Train Epoch: 1 [2000/8440 (24%)]\tLoss: 0.284523\n",
      "Train Epoch: 1 [3000/8440 (35%)]\tLoss: 0.201247\n",
      "Train Epoch: 1 [4000/8440 (47%)]\tLoss: 0.189222\n",
      "Train Epoch: 1 [5000/8440 (59%)]\tLoss: 0.273126\n",
      "Train Epoch: 1 [6000/8440 (71%)]\tLoss: 0.339449\n",
      "Train Epoch: 1 [7000/8440 (82%)]\tLoss: 0.362997\n",
      "Train Epoch: 1 [8000/8440 (94%)]\tLoss: 0.233866\n",
      "Train Epoch: 2 [0/8440 (0%)]\tLoss: 0.224665\n",
      "Train Epoch: 2 [1000/8440 (12%)]\tLoss: 0.167215\n",
      "Train Epoch: 2 [2000/8440 (24%)]\tLoss: 0.385940\n",
      "Train Epoch: 2 [3000/8440 (35%)]\tLoss: 0.320800\n",
      "Train Epoch: 2 [4000/8440 (47%)]\tLoss: 0.321766\n",
      "Train Epoch: 2 [5000/8440 (59%)]\tLoss: 0.292713\n",
      "Train Epoch: 2 [6000/8440 (71%)]\tLoss: 0.353645\n",
      "Train Epoch: 2 [7000/8440 (82%)]\tLoss: 0.323355\n",
      "Train Epoch: 2 [8000/8440 (94%)]\tLoss: 0.174085\n",
      "Train Epoch: 3 [0/8440 (0%)]\tLoss: 0.286561\n",
      "Train Epoch: 3 [1000/8440 (12%)]\tLoss: 0.272144\n",
      "Train Epoch: 3 [2000/8440 (24%)]\tLoss: 0.224716\n",
      "Train Epoch: 3 [3000/8440 (35%)]\tLoss: 0.149282\n",
      "Train Epoch: 3 [4000/8440 (47%)]\tLoss: 0.303431\n",
      "Train Epoch: 3 [5000/8440 (59%)]\tLoss: 0.256123\n",
      "Train Epoch: 3 [6000/8440 (71%)]\tLoss: 0.183549\n",
      "Train Epoch: 3 [7000/8440 (82%)]\tLoss: 0.332270\n",
      "Train Epoch: 3 [8000/8440 (94%)]\tLoss: 0.263954\n",
      "Train Epoch: 4 [0/8440 (0%)]\tLoss: 0.264519\n",
      "Train Epoch: 4 [1000/8440 (12%)]\tLoss: 0.295222\n",
      "Train Epoch: 4 [2000/8440 (24%)]\tLoss: 0.253147\n",
      "Train Epoch: 4 [3000/8440 (35%)]\tLoss: 0.277107\n",
      "Train Epoch: 4 [4000/8440 (47%)]\tLoss: 0.372686\n",
      "Train Epoch: 4 [5000/8440 (59%)]\tLoss: 0.192121\n",
      "Train Epoch: 4 [6000/8440 (71%)]\tLoss: 0.214813\n",
      "Train Epoch: 4 [7000/8440 (82%)]\tLoss: 0.229744\n",
      "Train Epoch: 4 [8000/8440 (94%)]\tLoss: 0.226247\n",
      "Train Epoch: 5 [0/8440 (0%)]\tLoss: 0.202481\n",
      "Train Epoch: 5 [1000/8440 (12%)]\tLoss: 0.178316\n",
      "Train Epoch: 5 [2000/8440 (24%)]\tLoss: 0.262351\n",
      "Train Epoch: 5 [3000/8440 (35%)]\tLoss: 0.220588\n",
      "Train Epoch: 5 [4000/8440 (47%)]\tLoss: 0.331437\n",
      "Train Epoch: 5 [5000/8440 (59%)]\tLoss: 0.360144\n",
      "Train Epoch: 5 [6000/8440 (71%)]\tLoss: 0.243865\n",
      "Train Epoch: 5 [7000/8440 (82%)]\tLoss: 0.279619\n",
      "Train Epoch: 5 [8000/8440 (94%)]\tLoss: 0.220892\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11811 (0%)]\tLoss: 0.276286\n",
      "Train Epoch: 1 [1000/11811 (8%)]\tLoss: 0.189442\n",
      "Train Epoch: 1 [2000/11811 (17%)]\tLoss: 0.284966\n",
      "Train Epoch: 1 [3000/11811 (25%)]\tLoss: 0.096236\n",
      "Train Epoch: 1 [4000/11811 (34%)]\tLoss: 0.078609\n",
      "Train Epoch: 1 [5000/11811 (42%)]\tLoss: 0.143331\n",
      "Train Epoch: 1 [6000/11811 (50%)]\tLoss: 0.221055\n",
      "Train Epoch: 1 [7000/11811 (59%)]\tLoss: 0.134385\n",
      "Train Epoch: 1 [8000/11811 (67%)]\tLoss: 0.190863\n",
      "Train Epoch: 1 [9000/11811 (76%)]\tLoss: 0.151154\n",
      "Train Epoch: 1 [10000/11811 (84%)]\tLoss: 0.120177\n",
      "Train Epoch: 1 [11000/11811 (92%)]\tLoss: 0.120811\n",
      "Train Epoch: 2 [0/11811 (0%)]\tLoss: 0.126401\n",
      "Train Epoch: 2 [1000/11811 (8%)]\tLoss: 0.074620\n",
      "Train Epoch: 2 [2000/11811 (17%)]\tLoss: 0.060730\n",
      "Train Epoch: 2 [3000/11811 (25%)]\tLoss: 0.163091\n",
      "Train Epoch: 2 [4000/11811 (34%)]\tLoss: 0.077959\n",
      "Train Epoch: 2 [5000/11811 (42%)]\tLoss: 0.057759\n",
      "Train Epoch: 2 [6000/11811 (50%)]\tLoss: 0.170107\n",
      "Train Epoch: 2 [7000/11811 (59%)]\tLoss: 0.127659\n",
      "Train Epoch: 2 [8000/11811 (67%)]\tLoss: 0.150536\n",
      "Train Epoch: 2 [9000/11811 (76%)]\tLoss: 0.134156\n",
      "Train Epoch: 2 [10000/11811 (84%)]\tLoss: 0.140573\n",
      "Train Epoch: 2 [11000/11811 (92%)]\tLoss: 0.053052\n",
      "Train Epoch: 3 [0/11811 (0%)]\tLoss: 0.178532\n",
      "Train Epoch: 3 [1000/11811 (8%)]\tLoss: 0.090711\n",
      "Train Epoch: 3 [2000/11811 (17%)]\tLoss: 0.190990\n",
      "Train Epoch: 3 [3000/11811 (25%)]\tLoss: 0.126274\n",
      "Train Epoch: 3 [4000/11811 (34%)]\tLoss: 0.109459\n",
      "Train Epoch: 3 [5000/11811 (42%)]\tLoss: 0.091032\n",
      "Train Epoch: 3 [6000/11811 (50%)]\tLoss: 0.160134\n",
      "Train Epoch: 3 [7000/11811 (59%)]\tLoss: 0.059162\n",
      "Train Epoch: 3 [8000/11811 (67%)]\tLoss: 0.151228\n",
      "Train Epoch: 3 [9000/11811 (76%)]\tLoss: 0.101502\n",
      "Train Epoch: 3 [10000/11811 (84%)]\tLoss: 0.073522\n",
      "Train Epoch: 3 [11000/11811 (92%)]\tLoss: 0.081186\n",
      "Train Epoch: 4 [0/11811 (0%)]\tLoss: 0.133542\n",
      "Train Epoch: 4 [1000/11811 (8%)]\tLoss: 0.113003\n",
      "Train Epoch: 4 [2000/11811 (17%)]\tLoss: 0.074574\n",
      "Train Epoch: 4 [3000/11811 (25%)]\tLoss: 0.065294\n",
      "Train Epoch: 4 [4000/11811 (34%)]\tLoss: 0.032328\n",
      "Train Epoch: 4 [5000/11811 (42%)]\tLoss: 0.052796\n",
      "Train Epoch: 4 [6000/11811 (50%)]\tLoss: 0.150119\n",
      "Train Epoch: 4 [7000/11811 (59%)]\tLoss: 0.131199\n",
      "Train Epoch: 4 [8000/11811 (67%)]\tLoss: 0.112897\n",
      "Train Epoch: 4 [9000/11811 (76%)]\tLoss: 0.026383\n",
      "Train Epoch: 4 [10000/11811 (84%)]\tLoss: 0.091467\n",
      "Train Epoch: 4 [11000/11811 (92%)]\tLoss: 0.080331\n",
      "Train Epoch: 5 [0/11811 (0%)]\tLoss: 0.033211\n",
      "Train Epoch: 5 [1000/11811 (8%)]\tLoss: 0.072602\n",
      "Train Epoch: 5 [2000/11811 (17%)]\tLoss: 0.079942\n",
      "Train Epoch: 5 [3000/11811 (25%)]\tLoss: 0.064555\n",
      "Train Epoch: 5 [4000/11811 (34%)]\tLoss: 0.079951\n",
      "Train Epoch: 5 [5000/11811 (42%)]\tLoss: 0.032678\n",
      "Train Epoch: 5 [6000/11811 (50%)]\tLoss: 0.092127\n",
      "Train Epoch: 5 [7000/11811 (59%)]\tLoss: 0.097347\n",
      "Train Epoch: 5 [8000/11811 (67%)]\tLoss: 0.073288\n",
      "Train Epoch: 5 [9000/11811 (76%)]\tLoss: 0.149028\n",
      "Train Epoch: 5 [10000/11811 (84%)]\tLoss: 0.077456\n",
      "Train Epoch: 5 [11000/11811 (92%)]\tLoss: 0.109496\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/9726 (0%)]\tLoss: 0.254891\n",
      "Train Epoch: 1 [1000/9726 (10%)]\tLoss: 0.239447\n",
      "Train Epoch: 1 [2000/9726 (20%)]\tLoss: 0.197616\n",
      "Train Epoch: 1 [3000/9726 (31%)]\tLoss: 0.240022\n",
      "Train Epoch: 1 [4000/9726 (41%)]\tLoss: 0.211571\n",
      "Train Epoch: 1 [5000/9726 (51%)]\tLoss: 0.179523\n",
      "Train Epoch: 1 [6000/9726 (61%)]\tLoss: 0.268852\n",
      "Train Epoch: 1 [7000/9726 (71%)]\tLoss: 0.337332\n",
      "Train Epoch: 1 [8000/9726 (82%)]\tLoss: 0.239854\n",
      "Train Epoch: 1 [9000/9726 (92%)]\tLoss: 0.171890\n",
      "Train Epoch: 2 [0/9726 (0%)]\tLoss: 0.182846\n",
      "Train Epoch: 2 [1000/9726 (10%)]\tLoss: 0.247250\n",
      "Train Epoch: 2 [2000/9726 (20%)]\tLoss: 0.191480\n",
      "Train Epoch: 2 [3000/9726 (31%)]\tLoss: 0.140018\n",
      "Train Epoch: 2 [4000/9726 (41%)]\tLoss: 0.238988\n",
      "Train Epoch: 2 [5000/9726 (51%)]\tLoss: 0.254564\n",
      "Train Epoch: 2 [6000/9726 (61%)]\tLoss: 0.218349\n",
      "Train Epoch: 2 [7000/9726 (71%)]\tLoss: 0.117674\n",
      "Train Epoch: 2 [8000/9726 (82%)]\tLoss: 0.139548\n",
      "Train Epoch: 2 [9000/9726 (92%)]\tLoss: 0.306217\n",
      "Train Epoch: 3 [0/9726 (0%)]\tLoss: 0.179081\n",
      "Train Epoch: 3 [1000/9726 (10%)]\tLoss: 0.165249\n",
      "Train Epoch: 3 [2000/9726 (20%)]\tLoss: 0.153912\n",
      "Train Epoch: 3 [3000/9726 (31%)]\tLoss: 0.180318\n",
      "Train Epoch: 3 [4000/9726 (41%)]\tLoss: 0.319667\n",
      "Train Epoch: 3 [5000/9726 (51%)]\tLoss: 0.172091\n",
      "Train Epoch: 3 [6000/9726 (61%)]\tLoss: 0.196707\n",
      "Train Epoch: 3 [7000/9726 (71%)]\tLoss: 0.220844\n",
      "Train Epoch: 3 [8000/9726 (82%)]\tLoss: 0.287095\n",
      "Train Epoch: 3 [9000/9726 (92%)]\tLoss: 0.248393\n",
      "Train Epoch: 4 [0/9726 (0%)]\tLoss: 0.186635\n",
      "Train Epoch: 4 [1000/9726 (10%)]\tLoss: 0.150589\n",
      "Train Epoch: 4 [2000/9726 (20%)]\tLoss: 0.138431\n",
      "Train Epoch: 4 [3000/9726 (31%)]\tLoss: 0.167696\n",
      "Train Epoch: 4 [4000/9726 (41%)]\tLoss: 0.222188\n",
      "Train Epoch: 4 [5000/9726 (51%)]\tLoss: 0.137766\n",
      "Train Epoch: 4 [6000/9726 (61%)]\tLoss: 0.251683\n",
      "Train Epoch: 4 [7000/9726 (71%)]\tLoss: 0.183834\n",
      "Train Epoch: 4 [8000/9726 (82%)]\tLoss: 0.195902\n",
      "Train Epoch: 4 [9000/9726 (92%)]\tLoss: 0.228285\n",
      "Train Epoch: 5 [0/9726 (0%)]\tLoss: 0.241560\n",
      "Train Epoch: 5 [1000/9726 (10%)]\tLoss: 0.215913\n",
      "Train Epoch: 5 [2000/9726 (20%)]\tLoss: 0.144416\n",
      "Train Epoch: 5 [3000/9726 (31%)]\tLoss: 0.227552\n",
      "Train Epoch: 5 [4000/9726 (41%)]\tLoss: 0.161506\n",
      "Train Epoch: 5 [5000/9726 (51%)]\tLoss: 0.186936\n",
      "Train Epoch: 5 [6000/9726 (61%)]\tLoss: 0.271653\n",
      "Train Epoch: 5 [7000/9726 (71%)]\tLoss: 0.243245\n",
      "Train Epoch: 5 [8000/9726 (82%)]\tLoss: 0.135301\n",
      "Train Epoch: 5 [9000/9726 (92%)]\tLoss: 0.197390\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/6491 (0%)]\tLoss: 0.400451\n",
      "Train Epoch: 1 [1000/6491 (15%)]\tLoss: 0.280239\n",
      "Train Epoch: 1 [2000/6491 (31%)]\tLoss: 0.407037\n",
      "Train Epoch: 1 [3000/6491 (46%)]\tLoss: 0.318816\n",
      "Train Epoch: 1 [4000/6491 (62%)]\tLoss: 0.404823\n",
      "Train Epoch: 1 [5000/6491 (77%)]\tLoss: 0.332800\n",
      "Train Epoch: 1 [6000/6491 (92%)]\tLoss: 0.356592\n",
      "Train Epoch: 2 [0/6491 (0%)]\tLoss: 0.217013\n",
      "Train Epoch: 2 [1000/6491 (15%)]\tLoss: 0.383219\n",
      "Train Epoch: 2 [2000/6491 (31%)]\tLoss: 0.270825\n",
      "Train Epoch: 2 [3000/6491 (46%)]\tLoss: 0.383018\n",
      "Train Epoch: 2 [4000/6491 (62%)]\tLoss: 0.316175\n",
      "Train Epoch: 2 [5000/6491 (77%)]\tLoss: 0.320665\n",
      "Train Epoch: 2 [6000/6491 (92%)]\tLoss: 0.205067\n",
      "Train Epoch: 3 [0/6491 (0%)]\tLoss: 0.341786\n",
      "Train Epoch: 3 [1000/6491 (15%)]\tLoss: 0.334579\n",
      "Train Epoch: 3 [2000/6491 (31%)]\tLoss: 0.299320\n",
      "Train Epoch: 3 [3000/6491 (46%)]\tLoss: 0.323888\n",
      "Train Epoch: 3 [4000/6491 (62%)]\tLoss: 0.257154\n",
      "Train Epoch: 3 [5000/6491 (77%)]\tLoss: 0.151564\n",
      "Train Epoch: 3 [6000/6491 (92%)]\tLoss: 0.257618\n",
      "Train Epoch: 4 [0/6491 (0%)]\tLoss: 0.317227\n",
      "Train Epoch: 4 [1000/6491 (15%)]\tLoss: 0.301317\n",
      "Train Epoch: 4 [2000/6491 (31%)]\tLoss: 0.172409\n",
      "Train Epoch: 4 [3000/6491 (46%)]\tLoss: 0.334737\n",
      "Train Epoch: 4 [4000/6491 (62%)]\tLoss: 0.332693\n",
      "Train Epoch: 4 [5000/6491 (77%)]\tLoss: 0.224157\n",
      "Train Epoch: 4 [6000/6491 (92%)]\tLoss: 0.289106\n",
      "Train Epoch: 5 [0/6491 (0%)]\tLoss: 0.336325\n",
      "Train Epoch: 5 [1000/6491 (15%)]\tLoss: 0.295707\n",
      "Train Epoch: 5 [2000/6491 (31%)]\tLoss: 0.228389\n",
      "Train Epoch: 5 [3000/6491 (46%)]\tLoss: 0.296520\n",
      "Train Epoch: 5 [4000/6491 (62%)]\tLoss: 0.334465\n",
      "Train Epoch: 5 [5000/6491 (77%)]\tLoss: 0.293765\n",
      "Train Epoch: 5 [6000/6491 (92%)]\tLoss: 0.275052\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/14118 (0%)]\tLoss: 0.359925\n",
      "Train Epoch: 1 [1000/14118 (7%)]\tLoss: 0.136595\n",
      "Train Epoch: 1 [2000/14118 (14%)]\tLoss: 0.214193\n",
      "Train Epoch: 1 [3000/14118 (21%)]\tLoss: 0.221703\n",
      "Train Epoch: 1 [4000/14118 (28%)]\tLoss: 0.190920\n",
      "Train Epoch: 1 [5000/14118 (35%)]\tLoss: 0.191878\n",
      "Train Epoch: 1 [6000/14118 (42%)]\tLoss: 0.228283\n",
      "Train Epoch: 1 [7000/14118 (49%)]\tLoss: 0.276257\n",
      "Train Epoch: 1 [8000/14118 (56%)]\tLoss: 0.177820\n",
      "Train Epoch: 1 [9000/14118 (63%)]\tLoss: 0.324691\n",
      "Train Epoch: 1 [10000/14118 (70%)]\tLoss: 0.144320\n",
      "Train Epoch: 1 [11000/14118 (77%)]\tLoss: 0.108682\n",
      "Train Epoch: 1 [12000/14118 (85%)]\tLoss: 0.266087\n",
      "Train Epoch: 1 [13000/14118 (92%)]\tLoss: 0.195828\n",
      "Train Epoch: 1 [14000/14118 (99%)]\tLoss: 0.201501\n",
      "Train Epoch: 2 [0/14118 (0%)]\tLoss: 0.200134\n",
      "Train Epoch: 2 [1000/14118 (7%)]\tLoss: 0.168554\n",
      "Train Epoch: 2 [2000/14118 (14%)]\tLoss: 0.245951\n",
      "Train Epoch: 2 [3000/14118 (21%)]\tLoss: 0.146075\n",
      "Train Epoch: 2 [4000/14118 (28%)]\tLoss: 0.077962\n",
      "Train Epoch: 2 [5000/14118 (35%)]\tLoss: 0.207647\n",
      "Train Epoch: 2 [6000/14118 (42%)]\tLoss: 0.140951\n",
      "Train Epoch: 2 [7000/14118 (49%)]\tLoss: 0.201701\n",
      "Train Epoch: 2 [8000/14118 (56%)]\tLoss: 0.178264\n",
      "Train Epoch: 2 [9000/14118 (63%)]\tLoss: 0.144082\n",
      "Train Epoch: 2 [10000/14118 (70%)]\tLoss: 0.153487\n",
      "Train Epoch: 2 [11000/14118 (77%)]\tLoss: 0.123099\n",
      "Train Epoch: 2 [12000/14118 (85%)]\tLoss: 0.128889\n",
      "Train Epoch: 2 [13000/14118 (92%)]\tLoss: 0.246769\n",
      "Train Epoch: 2 [14000/14118 (99%)]\tLoss: 0.148178\n",
      "Train Epoch: 3 [0/14118 (0%)]\tLoss: 0.211920\n",
      "Train Epoch: 3 [1000/14118 (7%)]\tLoss: 0.131926\n",
      "Train Epoch: 3 [2000/14118 (14%)]\tLoss: 0.185897\n",
      "Train Epoch: 3 [3000/14118 (21%)]\tLoss: 0.204498\n",
      "Train Epoch: 3 [4000/14118 (28%)]\tLoss: 0.317706\n",
      "Train Epoch: 3 [5000/14118 (35%)]\tLoss: 0.160776\n",
      "Train Epoch: 3 [6000/14118 (42%)]\tLoss: 0.186433\n",
      "Train Epoch: 3 [7000/14118 (49%)]\tLoss: 0.130665\n",
      "Train Epoch: 3 [8000/14118 (56%)]\tLoss: 0.146229\n",
      "Train Epoch: 3 [9000/14118 (63%)]\tLoss: 0.151654\n",
      "Train Epoch: 3 [10000/14118 (70%)]\tLoss: 0.122039\n",
      "Train Epoch: 3 [11000/14118 (77%)]\tLoss: 0.164268\n",
      "Train Epoch: 3 [12000/14118 (85%)]\tLoss: 0.269257\n",
      "Train Epoch: 3 [13000/14118 (92%)]\tLoss: 0.190214\n",
      "Train Epoch: 3 [14000/14118 (99%)]\tLoss: 0.304600\n",
      "Train Epoch: 4 [0/14118 (0%)]\tLoss: 0.239767\n",
      "Train Epoch: 4 [1000/14118 (7%)]\tLoss: 0.159594\n",
      "Train Epoch: 4 [2000/14118 (14%)]\tLoss: 0.114621\n",
      "Train Epoch: 4 [3000/14118 (21%)]\tLoss: 0.098150\n",
      "Train Epoch: 4 [4000/14118 (28%)]\tLoss: 0.189183\n",
      "Train Epoch: 4 [5000/14118 (35%)]\tLoss: 0.155387\n",
      "Train Epoch: 4 [6000/14118 (42%)]\tLoss: 0.047353\n",
      "Train Epoch: 4 [7000/14118 (49%)]\tLoss: 0.193575\n",
      "Train Epoch: 4 [8000/14118 (56%)]\tLoss: 0.101206\n",
      "Train Epoch: 4 [9000/14118 (63%)]\tLoss: 0.118512\n",
      "Train Epoch: 4 [10000/14118 (70%)]\tLoss: 0.201565\n",
      "Train Epoch: 4 [11000/14118 (77%)]\tLoss: 0.134614\n",
      "Train Epoch: 4 [12000/14118 (85%)]\tLoss: 0.177651\n",
      "Train Epoch: 4 [13000/14118 (92%)]\tLoss: 0.139462\n",
      "Train Epoch: 4 [14000/14118 (99%)]\tLoss: 0.253924\n",
      "Train Epoch: 5 [0/14118 (0%)]\tLoss: 0.185396\n",
      "Train Epoch: 5 [1000/14118 (7%)]\tLoss: 0.132241\n",
      "Train Epoch: 5 [2000/14118 (14%)]\tLoss: 0.159961\n",
      "Train Epoch: 5 [3000/14118 (21%)]\tLoss: 0.278434\n",
      "Train Epoch: 5 [4000/14118 (28%)]\tLoss: 0.138259\n",
      "Train Epoch: 5 [5000/14118 (35%)]\tLoss: 0.129366\n",
      "Train Epoch: 5 [6000/14118 (42%)]\tLoss: 0.098713\n",
      "Train Epoch: 5 [7000/14118 (49%)]\tLoss: 0.095487\n",
      "Train Epoch: 5 [8000/14118 (56%)]\tLoss: 0.142161\n",
      "Train Epoch: 5 [9000/14118 (63%)]\tLoss: 0.171286\n",
      "Train Epoch: 5 [10000/14118 (70%)]\tLoss: 0.154990\n",
      "Train Epoch: 5 [11000/14118 (77%)]\tLoss: 0.306384\n",
      "Train Epoch: 5 [12000/14118 (85%)]\tLoss: 0.278406\n",
      "Train Epoch: 5 [13000/14118 (92%)]\tLoss: 0.157568\n",
      "Train Epoch: 5 [14000/14118 (99%)]\tLoss: 0.134683\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/9414 (0%)]\tLoss: 0.441195\n",
      "Train Epoch: 1 [1000/9414 (11%)]\tLoss: 0.181436\n",
      "Train Epoch: 1 [2000/9414 (21%)]\tLoss: 0.254566\n",
      "Train Epoch: 1 [3000/9414 (32%)]\tLoss: 0.239194\n",
      "Train Epoch: 1 [4000/9414 (42%)]\tLoss: 0.239107\n",
      "Train Epoch: 1 [5000/9414 (53%)]\tLoss: 0.289867\n",
      "Train Epoch: 1 [6000/9414 (63%)]\tLoss: 0.281927\n",
      "Train Epoch: 1 [7000/9414 (74%)]\tLoss: 0.282008\n",
      "Train Epoch: 1 [8000/9414 (84%)]\tLoss: 0.201388\n",
      "Train Epoch: 1 [9000/9414 (95%)]\tLoss: 0.205626\n",
      "Train Epoch: 2 [0/9414 (0%)]\tLoss: 0.279798\n",
      "Train Epoch: 2 [1000/9414 (11%)]\tLoss: 0.215652\n",
      "Train Epoch: 2 [2000/9414 (21%)]\tLoss: 0.196649\n",
      "Train Epoch: 2 [3000/9414 (32%)]\tLoss: 0.185162\n",
      "Train Epoch: 2 [4000/9414 (42%)]\tLoss: 0.220544\n",
      "Train Epoch: 2 [5000/9414 (53%)]\tLoss: 0.196021\n",
      "Train Epoch: 2 [6000/9414 (63%)]\tLoss: 0.244882\n",
      "Train Epoch: 2 [7000/9414 (74%)]\tLoss: 0.140833\n",
      "Train Epoch: 2 [8000/9414 (84%)]\tLoss: 0.319385\n",
      "Train Epoch: 2 [9000/9414 (95%)]\tLoss: 0.157584\n",
      "Train Epoch: 3 [0/9414 (0%)]\tLoss: 0.231924\n",
      "Train Epoch: 3 [1000/9414 (11%)]\tLoss: 0.165677\n",
      "Train Epoch: 3 [2000/9414 (21%)]\tLoss: 0.141246\n",
      "Train Epoch: 3 [3000/9414 (32%)]\tLoss: 0.200053\n",
      "Train Epoch: 3 [4000/9414 (42%)]\tLoss: 0.223990\n",
      "Train Epoch: 3 [5000/9414 (53%)]\tLoss: 0.227946\n",
      "Train Epoch: 3 [6000/9414 (63%)]\tLoss: 0.206204\n",
      "Train Epoch: 3 [7000/9414 (74%)]\tLoss: 0.218031\n",
      "Train Epoch: 3 [8000/9414 (84%)]\tLoss: 0.154194\n",
      "Train Epoch: 3 [9000/9414 (95%)]\tLoss: 0.295229\n",
      "Train Epoch: 4 [0/9414 (0%)]\tLoss: 0.204006\n",
      "Train Epoch: 4 [1000/9414 (11%)]\tLoss: 0.233699\n",
      "Train Epoch: 4 [2000/9414 (21%)]\tLoss: 0.268016\n",
      "Train Epoch: 4 [3000/9414 (32%)]\tLoss: 0.238508\n",
      "Train Epoch: 4 [4000/9414 (42%)]\tLoss: 0.257351\n",
      "Train Epoch: 4 [5000/9414 (53%)]\tLoss: 0.182675\n",
      "Train Epoch: 4 [6000/9414 (63%)]\tLoss: 0.208729\n",
      "Train Epoch: 4 [7000/9414 (74%)]\tLoss: 0.253873\n",
      "Train Epoch: 4 [8000/9414 (84%)]\tLoss: 0.188494\n",
      "Train Epoch: 4 [9000/9414 (95%)]\tLoss: 0.234961\n",
      "Train Epoch: 5 [0/9414 (0%)]\tLoss: 0.249810\n",
      "Train Epoch: 5 [1000/9414 (11%)]\tLoss: 0.212639\n",
      "Train Epoch: 5 [2000/9414 (21%)]\tLoss: 0.178834\n",
      "Train Epoch: 5 [3000/9414 (32%)]\tLoss: 0.196037\n",
      "Train Epoch: 5 [4000/9414 (42%)]\tLoss: 0.163685\n",
      "Train Epoch: 5 [5000/9414 (53%)]\tLoss: 0.238486\n",
      "Train Epoch: 5 [6000/9414 (63%)]\tLoss: 0.166759\n",
      "Train Epoch: 5 [7000/9414 (74%)]\tLoss: 0.158189\n",
      "Train Epoch: 5 [8000/9414 (84%)]\tLoss: 0.187694\n",
      "Train Epoch: 5 [9000/9414 (95%)]\tLoss: 0.223282\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "6\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.3741, Accuracy: 8668/10000 (87%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/8440 (0%)]\tLoss: 0.198843\n",
      "Train Epoch: 1 [1000/8440 (12%)]\tLoss: 0.154673\n",
      "Train Epoch: 1 [2000/8440 (24%)]\tLoss: 0.356330\n",
      "Train Epoch: 1 [3000/8440 (35%)]\tLoss: 0.171932\n",
      "Train Epoch: 1 [4000/8440 (47%)]\tLoss: 0.224462\n",
      "Train Epoch: 1 [5000/8440 (59%)]\tLoss: 0.214471\n",
      "Train Epoch: 1 [6000/8440 (71%)]\tLoss: 0.249124\n",
      "Train Epoch: 1 [7000/8440 (82%)]\tLoss: 0.224714\n",
      "Train Epoch: 1 [8000/8440 (94%)]\tLoss: 0.304350\n",
      "Train Epoch: 2 [0/8440 (0%)]\tLoss: 0.281452\n",
      "Train Epoch: 2 [1000/8440 (12%)]\tLoss: 0.242072\n",
      "Train Epoch: 2 [2000/8440 (24%)]\tLoss: 0.304620\n",
      "Train Epoch: 2 [3000/8440 (35%)]\tLoss: 0.300074\n",
      "Train Epoch: 2 [4000/8440 (47%)]\tLoss: 0.218366\n",
      "Train Epoch: 2 [5000/8440 (59%)]\tLoss: 0.378707\n",
      "Train Epoch: 2 [6000/8440 (71%)]\tLoss: 0.389922\n",
      "Train Epoch: 2 [7000/8440 (82%)]\tLoss: 0.253495\n",
      "Train Epoch: 2 [8000/8440 (94%)]\tLoss: 0.249964\n",
      "Train Epoch: 3 [0/8440 (0%)]\tLoss: 0.330583\n",
      "Train Epoch: 3 [1000/8440 (12%)]\tLoss: 0.267515\n",
      "Train Epoch: 3 [2000/8440 (24%)]\tLoss: 0.165441\n",
      "Train Epoch: 3 [3000/8440 (35%)]\tLoss: 0.315938\n",
      "Train Epoch: 3 [4000/8440 (47%)]\tLoss: 0.224994\n",
      "Train Epoch: 3 [5000/8440 (59%)]\tLoss: 0.229262\n",
      "Train Epoch: 3 [6000/8440 (71%)]\tLoss: 0.115945\n",
      "Train Epoch: 3 [7000/8440 (82%)]\tLoss: 0.219299\n",
      "Train Epoch: 3 [8000/8440 (94%)]\tLoss: 0.136648\n",
      "Train Epoch: 4 [0/8440 (0%)]\tLoss: 0.217968\n",
      "Train Epoch: 4 [1000/8440 (12%)]\tLoss: 0.291232\n",
      "Train Epoch: 4 [2000/8440 (24%)]\tLoss: 0.326419\n",
      "Train Epoch: 4 [3000/8440 (35%)]\tLoss: 0.175176\n",
      "Train Epoch: 4 [4000/8440 (47%)]\tLoss: 0.184797\n",
      "Train Epoch: 4 [5000/8440 (59%)]\tLoss: 0.197914\n",
      "Train Epoch: 4 [6000/8440 (71%)]\tLoss: 0.326982\n",
      "Train Epoch: 4 [7000/8440 (82%)]\tLoss: 0.291981\n",
      "Train Epoch: 4 [8000/8440 (94%)]\tLoss: 0.324355\n",
      "Train Epoch: 5 [0/8440 (0%)]\tLoss: 0.275800\n",
      "Train Epoch: 5 [1000/8440 (12%)]\tLoss: 0.222430\n",
      "Train Epoch: 5 [2000/8440 (24%)]\tLoss: 0.317632\n",
      "Train Epoch: 5 [3000/8440 (35%)]\tLoss: 0.149584\n",
      "Train Epoch: 5 [4000/8440 (47%)]\tLoss: 0.209844\n",
      "Train Epoch: 5 [5000/8440 (59%)]\tLoss: 0.270091\n",
      "Train Epoch: 5 [6000/8440 (71%)]\tLoss: 0.139715\n",
      "Train Epoch: 5 [7000/8440 (82%)]\tLoss: 0.235374\n",
      "Train Epoch: 5 [8000/8440 (94%)]\tLoss: 0.237921\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11811 (0%)]\tLoss: 0.341387\n",
      "Train Epoch: 1 [1000/11811 (8%)]\tLoss: 0.186351\n",
      "Train Epoch: 1 [2000/11811 (17%)]\tLoss: 0.094739\n",
      "Train Epoch: 1 [3000/11811 (25%)]\tLoss: 0.095572\n",
      "Train Epoch: 1 [4000/11811 (34%)]\tLoss: 0.101454\n",
      "Train Epoch: 1 [5000/11811 (42%)]\tLoss: 0.084189\n",
      "Train Epoch: 1 [6000/11811 (50%)]\tLoss: 0.083665\n",
      "Train Epoch: 1 [7000/11811 (59%)]\tLoss: 0.133581\n",
      "Train Epoch: 1 [8000/11811 (67%)]\tLoss: 0.052452\n",
      "Train Epoch: 1 [9000/11811 (76%)]\tLoss: 0.141340\n",
      "Train Epoch: 1 [10000/11811 (84%)]\tLoss: 0.160992\n",
      "Train Epoch: 1 [11000/11811 (92%)]\tLoss: 0.148096\n",
      "Train Epoch: 2 [0/11811 (0%)]\tLoss: 0.129036\n",
      "Train Epoch: 2 [1000/11811 (8%)]\tLoss: 0.093535\n",
      "Train Epoch: 2 [2000/11811 (17%)]\tLoss: 0.167439\n",
      "Train Epoch: 2 [3000/11811 (25%)]\tLoss: 0.097463\n",
      "Train Epoch: 2 [4000/11811 (34%)]\tLoss: 0.061970\n",
      "Train Epoch: 2 [5000/11811 (42%)]\tLoss: 0.120210\n",
      "Train Epoch: 2 [6000/11811 (50%)]\tLoss: 0.097901\n",
      "Train Epoch: 2 [7000/11811 (59%)]\tLoss: 0.105993\n",
      "Train Epoch: 2 [8000/11811 (67%)]\tLoss: 0.186830\n",
      "Train Epoch: 2 [9000/11811 (76%)]\tLoss: 0.156039\n",
      "Train Epoch: 2 [10000/11811 (84%)]\tLoss: 0.208139\n",
      "Train Epoch: 2 [11000/11811 (92%)]\tLoss: 0.117222\n",
      "Train Epoch: 3 [0/11811 (0%)]\tLoss: 0.035438\n",
      "Train Epoch: 3 [1000/11811 (8%)]\tLoss: 0.089258\n",
      "Train Epoch: 3 [2000/11811 (17%)]\tLoss: 0.070871\n",
      "Train Epoch: 3 [3000/11811 (25%)]\tLoss: 0.069826\n",
      "Train Epoch: 3 [4000/11811 (34%)]\tLoss: 0.122072\n",
      "Train Epoch: 3 [5000/11811 (42%)]\tLoss: 0.131467\n",
      "Train Epoch: 3 [6000/11811 (50%)]\tLoss: 0.067296\n",
      "Train Epoch: 3 [7000/11811 (59%)]\tLoss: 0.055792\n",
      "Train Epoch: 3 [8000/11811 (67%)]\tLoss: 0.155389\n",
      "Train Epoch: 3 [9000/11811 (76%)]\tLoss: 0.063815\n",
      "Train Epoch: 3 [10000/11811 (84%)]\tLoss: 0.137225\n",
      "Train Epoch: 3 [11000/11811 (92%)]\tLoss: 0.138526\n",
      "Train Epoch: 4 [0/11811 (0%)]\tLoss: 0.085103\n",
      "Train Epoch: 4 [1000/11811 (8%)]\tLoss: 0.156059\n",
      "Train Epoch: 4 [2000/11811 (17%)]\tLoss: 0.087282\n",
      "Train Epoch: 4 [3000/11811 (25%)]\tLoss: 0.098896\n",
      "Train Epoch: 4 [4000/11811 (34%)]\tLoss: 0.041974\n",
      "Train Epoch: 4 [5000/11811 (42%)]\tLoss: 0.119545\n",
      "Train Epoch: 4 [6000/11811 (50%)]\tLoss: 0.084768\n",
      "Train Epoch: 4 [7000/11811 (59%)]\tLoss: 0.060880\n",
      "Train Epoch: 4 [8000/11811 (67%)]\tLoss: 0.121294\n",
      "Train Epoch: 4 [9000/11811 (76%)]\tLoss: 0.047908\n",
      "Train Epoch: 4 [10000/11811 (84%)]\tLoss: 0.172779\n",
      "Train Epoch: 4 [11000/11811 (92%)]\tLoss: 0.086653\n",
      "Train Epoch: 5 [0/11811 (0%)]\tLoss: 0.077602\n",
      "Train Epoch: 5 [1000/11811 (8%)]\tLoss: 0.104882\n",
      "Train Epoch: 5 [2000/11811 (17%)]\tLoss: 0.079002\n",
      "Train Epoch: 5 [3000/11811 (25%)]\tLoss: 0.193953\n",
      "Train Epoch: 5 [4000/11811 (34%)]\tLoss: 0.113302\n",
      "Train Epoch: 5 [5000/11811 (42%)]\tLoss: 0.082852\n",
      "Train Epoch: 5 [6000/11811 (50%)]\tLoss: 0.151946\n",
      "Train Epoch: 5 [7000/11811 (59%)]\tLoss: 0.051829\n",
      "Train Epoch: 5 [8000/11811 (67%)]\tLoss: 0.154221\n",
      "Train Epoch: 5 [9000/11811 (76%)]\tLoss: 0.054195\n",
      "Train Epoch: 5 [10000/11811 (84%)]\tLoss: 0.138472\n",
      "Train Epoch: 5 [11000/11811 (92%)]\tLoss: 0.185685\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/9726 (0%)]\tLoss: 0.247601\n",
      "Train Epoch: 1 [1000/9726 (10%)]\tLoss: 0.290008\n",
      "Train Epoch: 1 [2000/9726 (20%)]\tLoss: 0.223647\n",
      "Train Epoch: 1 [3000/9726 (31%)]\tLoss: 0.248626\n",
      "Train Epoch: 1 [4000/9726 (41%)]\tLoss: 0.198437\n",
      "Train Epoch: 1 [5000/9726 (51%)]\tLoss: 0.232705\n",
      "Train Epoch: 1 [6000/9726 (61%)]\tLoss: 0.098830\n",
      "Train Epoch: 1 [7000/9726 (71%)]\tLoss: 0.284599\n",
      "Train Epoch: 1 [8000/9726 (82%)]\tLoss: 0.154788\n",
      "Train Epoch: 1 [9000/9726 (92%)]\tLoss: 0.245204\n",
      "Train Epoch: 2 [0/9726 (0%)]\tLoss: 0.130123\n",
      "Train Epoch: 2 [1000/9726 (10%)]\tLoss: 0.197264\n",
      "Train Epoch: 2 [2000/9726 (20%)]\tLoss: 0.161608\n",
      "Train Epoch: 2 [3000/9726 (31%)]\tLoss: 0.235714\n",
      "Train Epoch: 2 [4000/9726 (41%)]\tLoss: 0.278582\n",
      "Train Epoch: 2 [5000/9726 (51%)]\tLoss: 0.232997\n",
      "Train Epoch: 2 [6000/9726 (61%)]\tLoss: 0.366810\n",
      "Train Epoch: 2 [7000/9726 (71%)]\tLoss: 0.189923\n",
      "Train Epoch: 2 [8000/9726 (82%)]\tLoss: 0.202338\n",
      "Train Epoch: 2 [9000/9726 (92%)]\tLoss: 0.267790\n",
      "Train Epoch: 3 [0/9726 (0%)]\tLoss: 0.245994\n",
      "Train Epoch: 3 [1000/9726 (10%)]\tLoss: 0.200674\n",
      "Train Epoch: 3 [2000/9726 (20%)]\tLoss: 0.295734\n",
      "Train Epoch: 3 [3000/9726 (31%)]\tLoss: 0.210632\n",
      "Train Epoch: 3 [4000/9726 (41%)]\tLoss: 0.204994\n",
      "Train Epoch: 3 [5000/9726 (51%)]\tLoss: 0.286922\n",
      "Train Epoch: 3 [6000/9726 (61%)]\tLoss: 0.152402\n",
      "Train Epoch: 3 [7000/9726 (71%)]\tLoss: 0.196502\n",
      "Train Epoch: 3 [8000/9726 (82%)]\tLoss: 0.221012\n",
      "Train Epoch: 3 [9000/9726 (92%)]\tLoss: 0.223182\n",
      "Train Epoch: 4 [0/9726 (0%)]\tLoss: 0.264624\n",
      "Train Epoch: 4 [1000/9726 (10%)]\tLoss: 0.131677\n",
      "Train Epoch: 4 [2000/9726 (20%)]\tLoss: 0.141820\n",
      "Train Epoch: 4 [3000/9726 (31%)]\tLoss: 0.197167\n",
      "Train Epoch: 4 [4000/9726 (41%)]\tLoss: 0.184403\n",
      "Train Epoch: 4 [5000/9726 (51%)]\tLoss: 0.148972\n",
      "Train Epoch: 4 [6000/9726 (61%)]\tLoss: 0.233662\n",
      "Train Epoch: 4 [7000/9726 (71%)]\tLoss: 0.239403\n",
      "Train Epoch: 4 [8000/9726 (82%)]\tLoss: 0.199032\n",
      "Train Epoch: 4 [9000/9726 (92%)]\tLoss: 0.185778\n",
      "Train Epoch: 5 [0/9726 (0%)]\tLoss: 0.156994\n",
      "Train Epoch: 5 [1000/9726 (10%)]\tLoss: 0.205196\n",
      "Train Epoch: 5 [2000/9726 (20%)]\tLoss: 0.186094\n",
      "Train Epoch: 5 [3000/9726 (31%)]\tLoss: 0.189014\n",
      "Train Epoch: 5 [4000/9726 (41%)]\tLoss: 0.193133\n",
      "Train Epoch: 5 [5000/9726 (51%)]\tLoss: 0.103602\n",
      "Train Epoch: 5 [6000/9726 (61%)]\tLoss: 0.205146\n",
      "Train Epoch: 5 [7000/9726 (71%)]\tLoss: 0.247749\n",
      "Train Epoch: 5 [8000/9726 (82%)]\tLoss: 0.200302\n",
      "Train Epoch: 5 [9000/9726 (92%)]\tLoss: 0.188875\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/6491 (0%)]\tLoss: 0.517500\n",
      "Train Epoch: 1 [1000/6491 (15%)]\tLoss: 0.291747\n",
      "Train Epoch: 1 [2000/6491 (31%)]\tLoss: 0.322917\n",
      "Train Epoch: 1 [3000/6491 (46%)]\tLoss: 0.186151\n",
      "Train Epoch: 1 [4000/6491 (62%)]\tLoss: 0.257860\n",
      "Train Epoch: 1 [5000/6491 (77%)]\tLoss: 0.244229\n",
      "Train Epoch: 1 [6000/6491 (92%)]\tLoss: 0.329346\n",
      "Train Epoch: 2 [0/6491 (0%)]\tLoss: 0.282049\n",
      "Train Epoch: 2 [1000/6491 (15%)]\tLoss: 0.270141\n",
      "Train Epoch: 2 [2000/6491 (31%)]\tLoss: 0.221666\n",
      "Train Epoch: 2 [3000/6491 (46%)]\tLoss: 0.318303\n",
      "Train Epoch: 2 [4000/6491 (62%)]\tLoss: 0.218419\n",
      "Train Epoch: 2 [5000/6491 (77%)]\tLoss: 0.395332\n",
      "Train Epoch: 2 [6000/6491 (92%)]\tLoss: 0.247336\n",
      "Train Epoch: 3 [0/6491 (0%)]\tLoss: 0.330664\n",
      "Train Epoch: 3 [1000/6491 (15%)]\tLoss: 0.314105\n",
      "Train Epoch: 3 [2000/6491 (31%)]\tLoss: 0.179454\n",
      "Train Epoch: 3 [3000/6491 (46%)]\tLoss: 0.388161\n",
      "Train Epoch: 3 [4000/6491 (62%)]\tLoss: 0.296191\n",
      "Train Epoch: 3 [5000/6491 (77%)]\tLoss: 0.278208\n",
      "Train Epoch: 3 [6000/6491 (92%)]\tLoss: 0.283259\n",
      "Train Epoch: 4 [0/6491 (0%)]\tLoss: 0.363555\n",
      "Train Epoch: 4 [1000/6491 (15%)]\tLoss: 0.230707\n",
      "Train Epoch: 4 [2000/6491 (31%)]\tLoss: 0.333181\n",
      "Train Epoch: 4 [3000/6491 (46%)]\tLoss: 0.428987\n",
      "Train Epoch: 4 [4000/6491 (62%)]\tLoss: 0.313330\n",
      "Train Epoch: 4 [5000/6491 (77%)]\tLoss: 0.327107\n",
      "Train Epoch: 4 [6000/6491 (92%)]\tLoss: 0.161524\n",
      "Train Epoch: 5 [0/6491 (0%)]\tLoss: 0.240324\n",
      "Train Epoch: 5 [1000/6491 (15%)]\tLoss: 0.387418\n",
      "Train Epoch: 5 [2000/6491 (31%)]\tLoss: 0.263653\n",
      "Train Epoch: 5 [3000/6491 (46%)]\tLoss: 0.272267\n",
      "Train Epoch: 5 [4000/6491 (62%)]\tLoss: 0.213918\n",
      "Train Epoch: 5 [5000/6491 (77%)]\tLoss: 0.235977\n",
      "Train Epoch: 5 [6000/6491 (92%)]\tLoss: 0.366898\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/14118 (0%)]\tLoss: 0.324973\n",
      "Train Epoch: 1 [1000/14118 (7%)]\tLoss: 0.141433\n",
      "Train Epoch: 1 [2000/14118 (14%)]\tLoss: 0.124336\n",
      "Train Epoch: 1 [3000/14118 (21%)]\tLoss: 0.307930\n",
      "Train Epoch: 1 [4000/14118 (28%)]\tLoss: 0.211398\n",
      "Train Epoch: 1 [5000/14118 (35%)]\tLoss: 0.188633\n",
      "Train Epoch: 1 [6000/14118 (42%)]\tLoss: 0.224545\n",
      "Train Epoch: 1 [7000/14118 (49%)]\tLoss: 0.184578\n",
      "Train Epoch: 1 [8000/14118 (56%)]\tLoss: 0.211427\n",
      "Train Epoch: 1 [9000/14118 (63%)]\tLoss: 0.197608\n",
      "Train Epoch: 1 [10000/14118 (70%)]\tLoss: 0.183627\n",
      "Train Epoch: 1 [11000/14118 (77%)]\tLoss: 0.194296\n",
      "Train Epoch: 1 [12000/14118 (85%)]\tLoss: 0.144930\n",
      "Train Epoch: 1 [13000/14118 (92%)]\tLoss: 0.275671\n",
      "Train Epoch: 1 [14000/14118 (99%)]\tLoss: 0.231178\n",
      "Train Epoch: 2 [0/14118 (0%)]\tLoss: 0.161946\n",
      "Train Epoch: 2 [1000/14118 (7%)]\tLoss: 0.246791\n",
      "Train Epoch: 2 [2000/14118 (14%)]\tLoss: 0.150799\n",
      "Train Epoch: 2 [3000/14118 (21%)]\tLoss: 0.213498\n",
      "Train Epoch: 2 [4000/14118 (28%)]\tLoss: 0.167836\n",
      "Train Epoch: 2 [5000/14118 (35%)]\tLoss: 0.229597\n",
      "Train Epoch: 2 [6000/14118 (42%)]\tLoss: 0.259931\n",
      "Train Epoch: 2 [7000/14118 (49%)]\tLoss: 0.228188\n",
      "Train Epoch: 2 [8000/14118 (56%)]\tLoss: 0.147588\n",
      "Train Epoch: 2 [9000/14118 (63%)]\tLoss: 0.158593\n",
      "Train Epoch: 2 [10000/14118 (70%)]\tLoss: 0.133531\n",
      "Train Epoch: 2 [11000/14118 (77%)]\tLoss: 0.184823\n",
      "Train Epoch: 2 [12000/14118 (85%)]\tLoss: 0.276617\n",
      "Train Epoch: 2 [13000/14118 (92%)]\tLoss: 0.329753\n",
      "Train Epoch: 2 [14000/14118 (99%)]\tLoss: 0.154614\n",
      "Train Epoch: 3 [0/14118 (0%)]\tLoss: 0.187471\n",
      "Train Epoch: 3 [1000/14118 (7%)]\tLoss: 0.183025\n",
      "Train Epoch: 3 [2000/14118 (14%)]\tLoss: 0.183803\n",
      "Train Epoch: 3 [3000/14118 (21%)]\tLoss: 0.222464\n",
      "Train Epoch: 3 [4000/14118 (28%)]\tLoss: 0.170388\n",
      "Train Epoch: 3 [5000/14118 (35%)]\tLoss: 0.246346\n",
      "Train Epoch: 3 [6000/14118 (42%)]\tLoss: 0.145661\n",
      "Train Epoch: 3 [7000/14118 (49%)]\tLoss: 0.186740\n",
      "Train Epoch: 3 [8000/14118 (56%)]\tLoss: 0.165607\n",
      "Train Epoch: 3 [9000/14118 (63%)]\tLoss: 0.207204\n",
      "Train Epoch: 3 [10000/14118 (70%)]\tLoss: 0.191393\n",
      "Train Epoch: 3 [11000/14118 (77%)]\tLoss: 0.188126\n",
      "Train Epoch: 3 [12000/14118 (85%)]\tLoss: 0.118311\n",
      "Train Epoch: 3 [13000/14118 (92%)]\tLoss: 0.119140\n",
      "Train Epoch: 3 [14000/14118 (99%)]\tLoss: 0.263290\n",
      "Train Epoch: 4 [0/14118 (0%)]\tLoss: 0.142733\n",
      "Train Epoch: 4 [1000/14118 (7%)]\tLoss: 0.217495\n",
      "Train Epoch: 4 [2000/14118 (14%)]\tLoss: 0.222578\n",
      "Train Epoch: 4 [3000/14118 (21%)]\tLoss: 0.153267\n",
      "Train Epoch: 4 [4000/14118 (28%)]\tLoss: 0.225417\n",
      "Train Epoch: 4 [5000/14118 (35%)]\tLoss: 0.201068\n",
      "Train Epoch: 4 [6000/14118 (42%)]\tLoss: 0.140241\n",
      "Train Epoch: 4 [7000/14118 (49%)]\tLoss: 0.159030\n",
      "Train Epoch: 4 [8000/14118 (56%)]\tLoss: 0.126396\n",
      "Train Epoch: 4 [9000/14118 (63%)]\tLoss: 0.183311\n",
      "Train Epoch: 4 [10000/14118 (70%)]\tLoss: 0.162124\n",
      "Train Epoch: 4 [11000/14118 (77%)]\tLoss: 0.178892\n",
      "Train Epoch: 4 [12000/14118 (85%)]\tLoss: 0.127351\n",
      "Train Epoch: 4 [13000/14118 (92%)]\tLoss: 0.137330\n",
      "Train Epoch: 4 [14000/14118 (99%)]\tLoss: 0.163438\n",
      "Train Epoch: 5 [0/14118 (0%)]\tLoss: 0.178663\n",
      "Train Epoch: 5 [1000/14118 (7%)]\tLoss: 0.265915\n",
      "Train Epoch: 5 [2000/14118 (14%)]\tLoss: 0.186432\n",
      "Train Epoch: 5 [3000/14118 (21%)]\tLoss: 0.175627\n",
      "Train Epoch: 5 [4000/14118 (28%)]\tLoss: 0.147158\n",
      "Train Epoch: 5 [5000/14118 (35%)]\tLoss: 0.183340\n",
      "Train Epoch: 5 [6000/14118 (42%)]\tLoss: 0.132092\n",
      "Train Epoch: 5 [7000/14118 (49%)]\tLoss: 0.158801\n",
      "Train Epoch: 5 [8000/14118 (56%)]\tLoss: 0.211054\n",
      "Train Epoch: 5 [9000/14118 (63%)]\tLoss: 0.117436\n",
      "Train Epoch: 5 [10000/14118 (70%)]\tLoss: 0.192504\n",
      "Train Epoch: 5 [11000/14118 (77%)]\tLoss: 0.173289\n",
      "Train Epoch: 5 [12000/14118 (85%)]\tLoss: 0.238444\n",
      "Train Epoch: 5 [13000/14118 (92%)]\tLoss: 0.095751\n",
      "Train Epoch: 5 [14000/14118 (99%)]\tLoss: 0.207336\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/9414 (0%)]\tLoss: 0.204640\n",
      "Train Epoch: 1 [1000/9414 (11%)]\tLoss: 0.269491\n",
      "Train Epoch: 1 [2000/9414 (21%)]\tLoss: 0.262987\n",
      "Train Epoch: 1 [3000/9414 (32%)]\tLoss: 0.219027\n",
      "Train Epoch: 1 [4000/9414 (42%)]\tLoss: 0.212421\n",
      "Train Epoch: 1 [5000/9414 (53%)]\tLoss: 0.274249\n",
      "Train Epoch: 1 [6000/9414 (63%)]\tLoss: 0.290109\n",
      "Train Epoch: 1 [7000/9414 (74%)]\tLoss: 0.216188\n",
      "Train Epoch: 1 [8000/9414 (84%)]\tLoss: 0.160223\n",
      "Train Epoch: 1 [9000/9414 (95%)]\tLoss: 0.132832\n",
      "Train Epoch: 2 [0/9414 (0%)]\tLoss: 0.273010\n",
      "Train Epoch: 2 [1000/9414 (11%)]\tLoss: 0.269725\n",
      "Train Epoch: 2 [2000/9414 (21%)]\tLoss: 0.209013\n",
      "Train Epoch: 2 [3000/9414 (32%)]\tLoss: 0.221794\n",
      "Train Epoch: 2 [4000/9414 (42%)]\tLoss: 0.276490\n",
      "Train Epoch: 2 [5000/9414 (53%)]\tLoss: 0.236585\n",
      "Train Epoch: 2 [6000/9414 (63%)]\tLoss: 0.274702\n",
      "Train Epoch: 2 [7000/9414 (74%)]\tLoss: 0.328062\n",
      "Train Epoch: 2 [8000/9414 (84%)]\tLoss: 0.244998\n",
      "Train Epoch: 2 [9000/9414 (95%)]\tLoss: 0.252795\n",
      "Train Epoch: 3 [0/9414 (0%)]\tLoss: 0.190127\n",
      "Train Epoch: 3 [1000/9414 (11%)]\tLoss: 0.207175\n",
      "Train Epoch: 3 [2000/9414 (21%)]\tLoss: 0.154448\n",
      "Train Epoch: 3 [3000/9414 (32%)]\tLoss: 0.313310\n",
      "Train Epoch: 3 [4000/9414 (42%)]\tLoss: 0.157122\n",
      "Train Epoch: 3 [5000/9414 (53%)]\tLoss: 0.238489\n",
      "Train Epoch: 3 [6000/9414 (63%)]\tLoss: 0.402739\n",
      "Train Epoch: 3 [7000/9414 (74%)]\tLoss: 0.189918\n",
      "Train Epoch: 3 [8000/9414 (84%)]\tLoss: 0.174400\n",
      "Train Epoch: 3 [9000/9414 (95%)]\tLoss: 0.207402\n",
      "Train Epoch: 4 [0/9414 (0%)]\tLoss: 0.290954\n",
      "Train Epoch: 4 [1000/9414 (11%)]\tLoss: 0.236297\n",
      "Train Epoch: 4 [2000/9414 (21%)]\tLoss: 0.221991\n",
      "Train Epoch: 4 [3000/9414 (32%)]\tLoss: 0.133939\n",
      "Train Epoch: 4 [4000/9414 (42%)]\tLoss: 0.216840\n",
      "Train Epoch: 4 [5000/9414 (53%)]\tLoss: 0.218463\n",
      "Train Epoch: 4 [6000/9414 (63%)]\tLoss: 0.201244\n",
      "Train Epoch: 4 [7000/9414 (74%)]\tLoss: 0.237649\n",
      "Train Epoch: 4 [8000/9414 (84%)]\tLoss: 0.180540\n",
      "Train Epoch: 4 [9000/9414 (95%)]\tLoss: 0.208572\n",
      "Train Epoch: 5 [0/9414 (0%)]\tLoss: 0.182337\n",
      "Train Epoch: 5 [1000/9414 (11%)]\tLoss: 0.253256\n",
      "Train Epoch: 5 [2000/9414 (21%)]\tLoss: 0.272620\n",
      "Train Epoch: 5 [3000/9414 (32%)]\tLoss: 0.192049\n",
      "Train Epoch: 5 [4000/9414 (42%)]\tLoss: 0.340902\n",
      "Train Epoch: 5 [5000/9414 (53%)]\tLoss: 0.264528\n",
      "Train Epoch: 5 [6000/9414 (63%)]\tLoss: 0.274810\n",
      "Train Epoch: 5 [7000/9414 (74%)]\tLoss: 0.254574\n",
      "Train Epoch: 5 [8000/9414 (84%)]\tLoss: 0.255758\n",
      "Train Epoch: 5 [9000/9414 (95%)]\tLoss: 0.169417\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "6\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.3696, Accuracy: 8670/10000 (87%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/8440 (0%)]\tLoss: 0.175539\n",
      "Train Epoch: 1 [1000/8440 (12%)]\tLoss: 0.366994\n",
      "Train Epoch: 1 [2000/8440 (24%)]\tLoss: 0.249946\n",
      "Train Epoch: 1 [3000/8440 (35%)]\tLoss: 0.190761\n",
      "Train Epoch: 1 [4000/8440 (47%)]\tLoss: 0.229380\n",
      "Train Epoch: 1 [5000/8440 (59%)]\tLoss: 0.278349\n",
      "Train Epoch: 1 [6000/8440 (71%)]\tLoss: 0.253312\n",
      "Train Epoch: 1 [7000/8440 (82%)]\tLoss: 0.244462\n",
      "Train Epoch: 1 [8000/8440 (94%)]\tLoss: 0.429617\n",
      "Train Epoch: 2 [0/8440 (0%)]\tLoss: 0.183825\n",
      "Train Epoch: 2 [1000/8440 (12%)]\tLoss: 0.215538\n",
      "Train Epoch: 2 [2000/8440 (24%)]\tLoss: 0.223331\n",
      "Train Epoch: 2 [3000/8440 (35%)]\tLoss: 0.294588\n",
      "Train Epoch: 2 [4000/8440 (47%)]\tLoss: 0.195510\n",
      "Train Epoch: 2 [5000/8440 (59%)]\tLoss: 0.352017\n",
      "Train Epoch: 2 [6000/8440 (71%)]\tLoss: 0.249442\n",
      "Train Epoch: 2 [7000/8440 (82%)]\tLoss: 0.276991\n",
      "Train Epoch: 2 [8000/8440 (94%)]\tLoss: 0.205931\n",
      "Train Epoch: 3 [0/8440 (0%)]\tLoss: 0.233201\n",
      "Train Epoch: 3 [1000/8440 (12%)]\tLoss: 0.195798\n",
      "Train Epoch: 3 [2000/8440 (24%)]\tLoss: 0.311374\n",
      "Train Epoch: 3 [3000/8440 (35%)]\tLoss: 0.222880\n",
      "Train Epoch: 3 [4000/8440 (47%)]\tLoss: 0.307573\n",
      "Train Epoch: 3 [5000/8440 (59%)]\tLoss: 0.235702\n",
      "Train Epoch: 3 [6000/8440 (71%)]\tLoss: 0.481742\n",
      "Train Epoch: 3 [7000/8440 (82%)]\tLoss: 0.288575\n",
      "Train Epoch: 3 [8000/8440 (94%)]\tLoss: 0.261585\n",
      "Train Epoch: 4 [0/8440 (0%)]\tLoss: 0.248645\n",
      "Train Epoch: 4 [1000/8440 (12%)]\tLoss: 0.257028\n",
      "Train Epoch: 4 [2000/8440 (24%)]\tLoss: 0.273643\n",
      "Train Epoch: 4 [3000/8440 (35%)]\tLoss: 0.186620\n",
      "Train Epoch: 4 [4000/8440 (47%)]\tLoss: 0.169101\n",
      "Train Epoch: 4 [5000/8440 (59%)]\tLoss: 0.156532\n",
      "Train Epoch: 4 [6000/8440 (71%)]\tLoss: 0.277375\n",
      "Train Epoch: 4 [7000/8440 (82%)]\tLoss: 0.251947\n",
      "Train Epoch: 4 [8000/8440 (94%)]\tLoss: 0.146224\n",
      "Train Epoch: 5 [0/8440 (0%)]\tLoss: 0.268787\n",
      "Train Epoch: 5 [1000/8440 (12%)]\tLoss: 0.247266\n",
      "Train Epoch: 5 [2000/8440 (24%)]\tLoss: 0.159309\n",
      "Train Epoch: 5 [3000/8440 (35%)]\tLoss: 0.186285\n",
      "Train Epoch: 5 [4000/8440 (47%)]\tLoss: 0.244154\n",
      "Train Epoch: 5 [5000/8440 (59%)]\tLoss: 0.222648\n",
      "Train Epoch: 5 [6000/8440 (71%)]\tLoss: 0.209640\n",
      "Train Epoch: 5 [7000/8440 (82%)]\tLoss: 0.159945\n",
      "Train Epoch: 5 [8000/8440 (94%)]\tLoss: 0.267752\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11811 (0%)]\tLoss: 0.325642\n",
      "Train Epoch: 1 [1000/11811 (8%)]\tLoss: 0.145503\n",
      "Train Epoch: 1 [2000/11811 (17%)]\tLoss: 0.215754\n",
      "Train Epoch: 1 [3000/11811 (25%)]\tLoss: 0.081878\n",
      "Train Epoch: 1 [4000/11811 (34%)]\tLoss: 0.170866\n",
      "Train Epoch: 1 [5000/11811 (42%)]\tLoss: 0.104977\n",
      "Train Epoch: 1 [6000/11811 (50%)]\tLoss: 0.116268\n",
      "Train Epoch: 1 [7000/11811 (59%)]\tLoss: 0.105585\n",
      "Train Epoch: 1 [8000/11811 (67%)]\tLoss: 0.114775\n",
      "Train Epoch: 1 [9000/11811 (76%)]\tLoss: 0.135171\n",
      "Train Epoch: 1 [10000/11811 (84%)]\tLoss: 0.136012\n",
      "Train Epoch: 1 [11000/11811 (92%)]\tLoss: 0.172562\n",
      "Train Epoch: 2 [0/11811 (0%)]\tLoss: 0.093439\n",
      "Train Epoch: 2 [1000/11811 (8%)]\tLoss: 0.052281\n",
      "Train Epoch: 2 [2000/11811 (17%)]\tLoss: 0.121950\n",
      "Train Epoch: 2 [3000/11811 (25%)]\tLoss: 0.144582\n",
      "Train Epoch: 2 [4000/11811 (34%)]\tLoss: 0.148081\n",
      "Train Epoch: 2 [5000/11811 (42%)]\tLoss: 0.066846\n",
      "Train Epoch: 2 [6000/11811 (50%)]\tLoss: 0.137090\n",
      "Train Epoch: 2 [7000/11811 (59%)]\tLoss: 0.151432\n",
      "Train Epoch: 2 [8000/11811 (67%)]\tLoss: 0.055663\n",
      "Train Epoch: 2 [9000/11811 (76%)]\tLoss: 0.065967\n",
      "Train Epoch: 2 [10000/11811 (84%)]\tLoss: 0.177158\n",
      "Train Epoch: 2 [11000/11811 (92%)]\tLoss: 0.047547\n",
      "Train Epoch: 3 [0/11811 (0%)]\tLoss: 0.112906\n",
      "Train Epoch: 3 [1000/11811 (8%)]\tLoss: 0.200450\n",
      "Train Epoch: 3 [2000/11811 (17%)]\tLoss: 0.148900\n",
      "Train Epoch: 3 [3000/11811 (25%)]\tLoss: 0.071698\n",
      "Train Epoch: 3 [4000/11811 (34%)]\tLoss: 0.098176\n",
      "Train Epoch: 3 [5000/11811 (42%)]\tLoss: 0.117246\n",
      "Train Epoch: 3 [6000/11811 (50%)]\tLoss: 0.123171\n",
      "Train Epoch: 3 [7000/11811 (59%)]\tLoss: 0.093269\n",
      "Train Epoch: 3 [8000/11811 (67%)]\tLoss: 0.075422\n",
      "Train Epoch: 3 [9000/11811 (76%)]\tLoss: 0.199645\n",
      "Train Epoch: 3 [10000/11811 (84%)]\tLoss: 0.186970\n",
      "Train Epoch: 3 [11000/11811 (92%)]\tLoss: 0.058532\n",
      "Train Epoch: 4 [0/11811 (0%)]\tLoss: 0.074884\n",
      "Train Epoch: 4 [1000/11811 (8%)]\tLoss: 0.112764\n",
      "Train Epoch: 4 [2000/11811 (17%)]\tLoss: 0.098870\n",
      "Train Epoch: 4 [3000/11811 (25%)]\tLoss: 0.074250\n",
      "Train Epoch: 4 [4000/11811 (34%)]\tLoss: 0.143104\n",
      "Train Epoch: 4 [5000/11811 (42%)]\tLoss: 0.084016\n",
      "Train Epoch: 4 [6000/11811 (50%)]\tLoss: 0.139905\n",
      "Train Epoch: 4 [7000/11811 (59%)]\tLoss: 0.043766\n",
      "Train Epoch: 4 [8000/11811 (67%)]\tLoss: 0.150712\n",
      "Train Epoch: 4 [9000/11811 (76%)]\tLoss: 0.091599\n",
      "Train Epoch: 4 [10000/11811 (84%)]\tLoss: 0.153862\n",
      "Train Epoch: 4 [11000/11811 (92%)]\tLoss: 0.093708\n",
      "Train Epoch: 5 [0/11811 (0%)]\tLoss: 0.083706\n",
      "Train Epoch: 5 [1000/11811 (8%)]\tLoss: 0.095472\n",
      "Train Epoch: 5 [2000/11811 (17%)]\tLoss: 0.095484\n",
      "Train Epoch: 5 [3000/11811 (25%)]\tLoss: 0.050430\n",
      "Train Epoch: 5 [4000/11811 (34%)]\tLoss: 0.074680\n",
      "Train Epoch: 5 [5000/11811 (42%)]\tLoss: 0.094088\n",
      "Train Epoch: 5 [6000/11811 (50%)]\tLoss: 0.068473\n",
      "Train Epoch: 5 [7000/11811 (59%)]\tLoss: 0.132013\n",
      "Train Epoch: 5 [8000/11811 (67%)]\tLoss: 0.140187\n",
      "Train Epoch: 5 [9000/11811 (76%)]\tLoss: 0.064281\n",
      "Train Epoch: 5 [10000/11811 (84%)]\tLoss: 0.044089\n",
      "Train Epoch: 5 [11000/11811 (92%)]\tLoss: 0.073799\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "6\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.3982, Accuracy: 8578/10000 (86%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/8440 (0%)]\tLoss: 0.262778\n",
      "Train Epoch: 1 [1000/8440 (12%)]\tLoss: 0.307185\n",
      "Train Epoch: 1 [2000/8440 (24%)]\tLoss: 0.328624\n",
      "Train Epoch: 1 [3000/8440 (35%)]\tLoss: 0.211600\n",
      "Train Epoch: 1 [4000/8440 (47%)]\tLoss: 0.381504\n",
      "Train Epoch: 1 [5000/8440 (59%)]\tLoss: 0.328205\n",
      "Train Epoch: 1 [6000/8440 (71%)]\tLoss: 0.184654\n",
      "Train Epoch: 1 [7000/8440 (82%)]\tLoss: 0.255327\n",
      "Train Epoch: 1 [8000/8440 (94%)]\tLoss: 0.214965\n",
      "Train Epoch: 2 [0/8440 (0%)]\tLoss: 0.267492\n",
      "Train Epoch: 2 [1000/8440 (12%)]\tLoss: 0.260147\n",
      "Train Epoch: 2 [2000/8440 (24%)]\tLoss: 0.284614\n",
      "Train Epoch: 2 [3000/8440 (35%)]\tLoss: 0.286291\n",
      "Train Epoch: 2 [4000/8440 (47%)]\tLoss: 0.161291\n",
      "Train Epoch: 2 [5000/8440 (59%)]\tLoss: 0.218242\n",
      "Train Epoch: 2 [6000/8440 (71%)]\tLoss: 0.249050\n",
      "Train Epoch: 2 [7000/8440 (82%)]\tLoss: 0.125615\n",
      "Train Epoch: 2 [8000/8440 (94%)]\tLoss: 0.307692\n",
      "Train Epoch: 3 [0/8440 (0%)]\tLoss: 0.164540\n",
      "Train Epoch: 3 [1000/8440 (12%)]\tLoss: 0.277106\n",
      "Train Epoch: 3 [2000/8440 (24%)]\tLoss: 0.279360\n",
      "Train Epoch: 3 [3000/8440 (35%)]\tLoss: 0.178082\n",
      "Train Epoch: 3 [4000/8440 (47%)]\tLoss: 0.359658\n",
      "Train Epoch: 3 [5000/8440 (59%)]\tLoss: 0.226244\n",
      "Train Epoch: 3 [6000/8440 (71%)]\tLoss: 0.172872\n",
      "Train Epoch: 3 [7000/8440 (82%)]\tLoss: 0.279783\n",
      "Train Epoch: 3 [8000/8440 (94%)]\tLoss: 0.284225\n",
      "Train Epoch: 4 [0/8440 (0%)]\tLoss: 0.180468\n",
      "Train Epoch: 4 [1000/8440 (12%)]\tLoss: 0.249262\n",
      "Train Epoch: 4 [2000/8440 (24%)]\tLoss: 0.200336\n",
      "Train Epoch: 4 [3000/8440 (35%)]\tLoss: 0.293368\n",
      "Train Epoch: 4 [4000/8440 (47%)]\tLoss: 0.157406\n",
      "Train Epoch: 4 [5000/8440 (59%)]\tLoss: 0.220866\n",
      "Train Epoch: 4 [6000/8440 (71%)]\tLoss: 0.286624\n",
      "Train Epoch: 4 [7000/8440 (82%)]\tLoss: 0.184478\n",
      "Train Epoch: 4 [8000/8440 (94%)]\tLoss: 0.184335\n",
      "Train Epoch: 5 [0/8440 (0%)]\tLoss: 0.277200\n",
      "Train Epoch: 5 [1000/8440 (12%)]\tLoss: 0.270852\n",
      "Train Epoch: 5 [2000/8440 (24%)]\tLoss: 0.274249\n",
      "Train Epoch: 5 [3000/8440 (35%)]\tLoss: 0.255726\n",
      "Train Epoch: 5 [4000/8440 (47%)]\tLoss: 0.232163\n",
      "Train Epoch: 5 [5000/8440 (59%)]\tLoss: 0.254270\n",
      "Train Epoch: 5 [6000/8440 (71%)]\tLoss: 0.275423\n",
      "Train Epoch: 5 [7000/8440 (82%)]\tLoss: 0.195710\n",
      "Train Epoch: 5 [8000/8440 (94%)]\tLoss: 0.371516\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11811 (0%)]\tLoss: 0.286006\n",
      "Train Epoch: 1 [1000/11811 (8%)]\tLoss: 0.122939\n",
      "Train Epoch: 1 [2000/11811 (17%)]\tLoss: 0.082514\n",
      "Train Epoch: 1 [3000/11811 (25%)]\tLoss: 0.133993\n",
      "Train Epoch: 1 [4000/11811 (34%)]\tLoss: 0.160901\n",
      "Train Epoch: 1 [5000/11811 (42%)]\tLoss: 0.093340\n",
      "Train Epoch: 1 [6000/11811 (50%)]\tLoss: 0.082537\n",
      "Train Epoch: 1 [7000/11811 (59%)]\tLoss: 0.085637\n",
      "Train Epoch: 1 [8000/11811 (67%)]\tLoss: 0.084633\n",
      "Train Epoch: 1 [9000/11811 (76%)]\tLoss: 0.127078\n",
      "Train Epoch: 1 [10000/11811 (84%)]\tLoss: 0.069623\n",
      "Train Epoch: 1 [11000/11811 (92%)]\tLoss: 0.130136\n",
      "Train Epoch: 2 [0/11811 (0%)]\tLoss: 0.055174\n",
      "Train Epoch: 2 [1000/11811 (8%)]\tLoss: 0.067653\n",
      "Train Epoch: 2 [2000/11811 (17%)]\tLoss: 0.061915\n",
      "Train Epoch: 2 [3000/11811 (25%)]\tLoss: 0.103351\n",
      "Train Epoch: 2 [4000/11811 (34%)]\tLoss: 0.111196\n",
      "Train Epoch: 2 [5000/11811 (42%)]\tLoss: 0.123781\n",
      "Train Epoch: 2 [6000/11811 (50%)]\tLoss: 0.103343\n",
      "Train Epoch: 2 [7000/11811 (59%)]\tLoss: 0.052887\n",
      "Train Epoch: 2 [8000/11811 (67%)]\tLoss: 0.105002\n",
      "Train Epoch: 2 [9000/11811 (76%)]\tLoss: 0.133003\n",
      "Train Epoch: 2 [10000/11811 (84%)]\tLoss: 0.035685\n",
      "Train Epoch: 2 [11000/11811 (92%)]\tLoss: 0.084221\n",
      "Train Epoch: 3 [0/11811 (0%)]\tLoss: 0.075024\n",
      "Train Epoch: 3 [1000/11811 (8%)]\tLoss: 0.109286\n",
      "Train Epoch: 3 [2000/11811 (17%)]\tLoss: 0.090517\n",
      "Train Epoch: 3 [3000/11811 (25%)]\tLoss: 0.066598\n",
      "Train Epoch: 3 [4000/11811 (34%)]\tLoss: 0.122852\n",
      "Train Epoch: 3 [5000/11811 (42%)]\tLoss: 0.057039\n",
      "Train Epoch: 3 [6000/11811 (50%)]\tLoss: 0.072545\n",
      "Train Epoch: 3 [7000/11811 (59%)]\tLoss: 0.068229\n",
      "Train Epoch: 3 [8000/11811 (67%)]\tLoss: 0.080345\n",
      "Train Epoch: 3 [9000/11811 (76%)]\tLoss: 0.084779\n",
      "Train Epoch: 3 [10000/11811 (84%)]\tLoss: 0.024681\n",
      "Train Epoch: 3 [11000/11811 (92%)]\tLoss: 0.033096\n",
      "Train Epoch: 4 [0/11811 (0%)]\tLoss: 0.152180\n",
      "Train Epoch: 4 [1000/11811 (8%)]\tLoss: 0.034269\n",
      "Train Epoch: 4 [2000/11811 (17%)]\tLoss: 0.130665\n",
      "Train Epoch: 4 [3000/11811 (25%)]\tLoss: 0.119102\n",
      "Train Epoch: 4 [4000/11811 (34%)]\tLoss: 0.137441\n",
      "Train Epoch: 4 [5000/11811 (42%)]\tLoss: 0.101074\n",
      "Train Epoch: 4 [6000/11811 (50%)]\tLoss: 0.039794\n",
      "Train Epoch: 4 [7000/11811 (59%)]\tLoss: 0.059862\n",
      "Train Epoch: 4 [8000/11811 (67%)]\tLoss: 0.130029\n",
      "Train Epoch: 4 [9000/11811 (76%)]\tLoss: 0.108829\n",
      "Train Epoch: 4 [10000/11811 (84%)]\tLoss: 0.074502\n",
      "Train Epoch: 4 [11000/11811 (92%)]\tLoss: 0.060678\n",
      "Train Epoch: 5 [0/11811 (0%)]\tLoss: 0.136214\n",
      "Train Epoch: 5 [1000/11811 (8%)]\tLoss: 0.076603\n",
      "Train Epoch: 5 [2000/11811 (17%)]\tLoss: 0.077659\n",
      "Train Epoch: 5 [3000/11811 (25%)]\tLoss: 0.116360\n",
      "Train Epoch: 5 [4000/11811 (34%)]\tLoss: 0.118646\n",
      "Train Epoch: 5 [5000/11811 (42%)]\tLoss: 0.068342\n",
      "Train Epoch: 5 [6000/11811 (50%)]\tLoss: 0.050122\n",
      "Train Epoch: 5 [7000/11811 (59%)]\tLoss: 0.101216\n",
      "Train Epoch: 5 [8000/11811 (67%)]\tLoss: 0.082308\n",
      "Train Epoch: 5 [9000/11811 (76%)]\tLoss: 0.082421\n",
      "Train Epoch: 5 [10000/11811 (84%)]\tLoss: 0.055603\n",
      "Train Epoch: 5 [11000/11811 (92%)]\tLoss: 0.161280\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "6\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.3958, Accuracy: 8577/10000 (86%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/8440 (0%)]\tLoss: 0.456823\n",
      "Train Epoch: 1 [1000/8440 (12%)]\tLoss: 0.255335\n",
      "Train Epoch: 1 [2000/8440 (24%)]\tLoss: 0.271027\n",
      "Train Epoch: 1 [3000/8440 (35%)]\tLoss: 0.201327\n",
      "Train Epoch: 1 [4000/8440 (47%)]\tLoss: 0.184974\n",
      "Train Epoch: 1 [5000/8440 (59%)]\tLoss: 0.169839\n",
      "Train Epoch: 1 [6000/8440 (71%)]\tLoss: 0.150758\n",
      "Train Epoch: 1 [7000/8440 (82%)]\tLoss: 0.111066\n",
      "Train Epoch: 1 [8000/8440 (94%)]\tLoss: 0.246221\n",
      "Train Epoch: 2 [0/8440 (0%)]\tLoss: 0.257657\n",
      "Train Epoch: 2 [1000/8440 (12%)]\tLoss: 0.348284\n",
      "Train Epoch: 2 [2000/8440 (24%)]\tLoss: 0.212066\n",
      "Train Epoch: 2 [3000/8440 (35%)]\tLoss: 0.201108\n",
      "Train Epoch: 2 [4000/8440 (47%)]\tLoss: 0.208821\n",
      "Train Epoch: 2 [5000/8440 (59%)]\tLoss: 0.257799\n",
      "Train Epoch: 2 [6000/8440 (71%)]\tLoss: 0.181615\n",
      "Train Epoch: 2 [7000/8440 (82%)]\tLoss: 0.342289\n",
      "Train Epoch: 2 [8000/8440 (94%)]\tLoss: 0.161366\n",
      "Train Epoch: 3 [0/8440 (0%)]\tLoss: 0.188900\n",
      "Train Epoch: 3 [1000/8440 (12%)]\tLoss: 0.171979\n",
      "Train Epoch: 3 [2000/8440 (24%)]\tLoss: 0.201112\n",
      "Train Epoch: 3 [3000/8440 (35%)]\tLoss: 0.170480\n",
      "Train Epoch: 3 [4000/8440 (47%)]\tLoss: 0.252543\n",
      "Train Epoch: 3 [5000/8440 (59%)]\tLoss: 0.102943\n",
      "Train Epoch: 3 [6000/8440 (71%)]\tLoss: 0.298003\n",
      "Train Epoch: 3 [7000/8440 (82%)]\tLoss: 0.205928\n",
      "Train Epoch: 3 [8000/8440 (94%)]\tLoss: 0.164838\n",
      "Train Epoch: 4 [0/8440 (0%)]\tLoss: 0.278711\n",
      "Train Epoch: 4 [1000/8440 (12%)]\tLoss: 0.172914\n",
      "Train Epoch: 4 [2000/8440 (24%)]\tLoss: 0.284003\n",
      "Train Epoch: 4 [3000/8440 (35%)]\tLoss: 0.201327\n",
      "Train Epoch: 4 [4000/8440 (47%)]\tLoss: 0.145051\n",
      "Train Epoch: 4 [5000/8440 (59%)]\tLoss: 0.185373\n",
      "Train Epoch: 4 [6000/8440 (71%)]\tLoss: 0.164189\n",
      "Train Epoch: 4 [7000/8440 (82%)]\tLoss: 0.168752\n",
      "Train Epoch: 4 [8000/8440 (94%)]\tLoss: 0.236616\n",
      "Train Epoch: 5 [0/8440 (0%)]\tLoss: 0.310460\n",
      "Train Epoch: 5 [1000/8440 (12%)]\tLoss: 0.169059\n",
      "Train Epoch: 5 [2000/8440 (24%)]\tLoss: 0.231873\n",
      "Train Epoch: 5 [3000/8440 (35%)]\tLoss: 0.135777\n",
      "Train Epoch: 5 [4000/8440 (47%)]\tLoss: 0.110798\n",
      "Train Epoch: 5 [5000/8440 (59%)]\tLoss: 0.228137\n",
      "Train Epoch: 5 [6000/8440 (71%)]\tLoss: 0.147138\n",
      "Train Epoch: 5 [7000/8440 (82%)]\tLoss: 0.241934\n",
      "Train Epoch: 5 [8000/8440 (94%)]\tLoss: 0.267399\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11811 (0%)]\tLoss: 0.246967\n",
      "Train Epoch: 1 [1000/11811 (8%)]\tLoss: 0.101664\n",
      "Train Epoch: 1 [2000/11811 (17%)]\tLoss: 0.031566\n",
      "Train Epoch: 1 [3000/11811 (25%)]\tLoss: 0.153427\n",
      "Train Epoch: 1 [4000/11811 (34%)]\tLoss: 0.117489\n",
      "Train Epoch: 1 [5000/11811 (42%)]\tLoss: 0.108563\n",
      "Train Epoch: 1 [6000/11811 (50%)]\tLoss: 0.112520\n",
      "Train Epoch: 1 [7000/11811 (59%)]\tLoss: 0.065843\n",
      "Train Epoch: 1 [8000/11811 (67%)]\tLoss: 0.136404\n",
      "Train Epoch: 1 [9000/11811 (76%)]\tLoss: 0.162941\n",
      "Train Epoch: 1 [10000/11811 (84%)]\tLoss: 0.157558\n",
      "Train Epoch: 1 [11000/11811 (92%)]\tLoss: 0.081251\n",
      "Train Epoch: 2 [0/11811 (0%)]\tLoss: 0.107235\n",
      "Train Epoch: 2 [1000/11811 (8%)]\tLoss: 0.113327\n",
      "Train Epoch: 2 [2000/11811 (17%)]\tLoss: 0.072496\n",
      "Train Epoch: 2 [3000/11811 (25%)]\tLoss: 0.114363\n",
      "Train Epoch: 2 [4000/11811 (34%)]\tLoss: 0.106690\n",
      "Train Epoch: 2 [5000/11811 (42%)]\tLoss: 0.121781\n",
      "Train Epoch: 2 [6000/11811 (50%)]\tLoss: 0.127940\n",
      "Train Epoch: 2 [7000/11811 (59%)]\tLoss: 0.066766\n",
      "Train Epoch: 2 [8000/11811 (67%)]\tLoss: 0.075251\n",
      "Train Epoch: 2 [9000/11811 (76%)]\tLoss: 0.048830\n",
      "Train Epoch: 2 [10000/11811 (84%)]\tLoss: 0.114906\n",
      "Train Epoch: 2 [11000/11811 (92%)]\tLoss: 0.025447\n",
      "Train Epoch: 3 [0/11811 (0%)]\tLoss: 0.071120\n",
      "Train Epoch: 3 [1000/11811 (8%)]\tLoss: 0.098204\n",
      "Train Epoch: 3 [2000/11811 (17%)]\tLoss: 0.063262\n",
      "Train Epoch: 3 [3000/11811 (25%)]\tLoss: 0.066761\n",
      "Train Epoch: 3 [4000/11811 (34%)]\tLoss: 0.050239\n",
      "Train Epoch: 3 [5000/11811 (42%)]\tLoss: 0.056545\n",
      "Train Epoch: 3 [6000/11811 (50%)]\tLoss: 0.045496\n",
      "Train Epoch: 3 [7000/11811 (59%)]\tLoss: 0.143534\n",
      "Train Epoch: 3 [8000/11811 (67%)]\tLoss: 0.080678\n",
      "Train Epoch: 3 [9000/11811 (76%)]\tLoss: 0.050976\n",
      "Train Epoch: 3 [10000/11811 (84%)]\tLoss: 0.065000\n",
      "Train Epoch: 3 [11000/11811 (92%)]\tLoss: 0.105164\n",
      "Train Epoch: 4 [0/11811 (0%)]\tLoss: 0.049731\n",
      "Train Epoch: 4 [1000/11811 (8%)]\tLoss: 0.043382\n",
      "Train Epoch: 4 [2000/11811 (17%)]\tLoss: 0.129076\n",
      "Train Epoch: 4 [3000/11811 (25%)]\tLoss: 0.062182\n",
      "Train Epoch: 4 [4000/11811 (34%)]\tLoss: 0.094320\n",
      "Train Epoch: 4 [5000/11811 (42%)]\tLoss: 0.080634\n",
      "Train Epoch: 4 [6000/11811 (50%)]\tLoss: 0.100366\n",
      "Train Epoch: 4 [7000/11811 (59%)]\tLoss: 0.088565\n",
      "Train Epoch: 4 [8000/11811 (67%)]\tLoss: 0.097649\n",
      "Train Epoch: 4 [9000/11811 (76%)]\tLoss: 0.098110\n",
      "Train Epoch: 4 [10000/11811 (84%)]\tLoss: 0.088249\n",
      "Train Epoch: 4 [11000/11811 (92%)]\tLoss: 0.079627\n",
      "Train Epoch: 5 [0/11811 (0%)]\tLoss: 0.049967\n",
      "Train Epoch: 5 [1000/11811 (8%)]\tLoss: 0.089696\n",
      "Train Epoch: 5 [2000/11811 (17%)]\tLoss: 0.097026\n",
      "Train Epoch: 5 [3000/11811 (25%)]\tLoss: 0.070241\n",
      "Train Epoch: 5 [4000/11811 (34%)]\tLoss: 0.063972\n",
      "Train Epoch: 5 [5000/11811 (42%)]\tLoss: 0.059694\n",
      "Train Epoch: 5 [6000/11811 (50%)]\tLoss: 0.137745\n",
      "Train Epoch: 5 [7000/11811 (59%)]\tLoss: 0.030180\n",
      "Train Epoch: 5 [8000/11811 (67%)]\tLoss: 0.066033\n",
      "Train Epoch: 5 [9000/11811 (76%)]\tLoss: 0.102718\n",
      "Train Epoch: 5 [10000/11811 (84%)]\tLoss: 0.093277\n",
      "Train Epoch: 5 [11000/11811 (92%)]\tLoss: 0.064865\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "6\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.3818, Accuracy: 8631/10000 (86%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/8440 (0%)]\tLoss: 0.220699\n",
      "Train Epoch: 1 [1000/8440 (12%)]\tLoss: 0.112977\n",
      "Train Epoch: 1 [2000/8440 (24%)]\tLoss: 0.400626\n",
      "Train Epoch: 1 [3000/8440 (35%)]\tLoss: 0.198132\n",
      "Train Epoch: 1 [4000/8440 (47%)]\tLoss: 0.277231\n",
      "Train Epoch: 1 [5000/8440 (59%)]\tLoss: 0.257737\n",
      "Train Epoch: 1 [6000/8440 (71%)]\tLoss: 0.132867\n",
      "Train Epoch: 1 [7000/8440 (82%)]\tLoss: 0.233534\n",
      "Train Epoch: 1 [8000/8440 (94%)]\tLoss: 0.199277\n",
      "Train Epoch: 2 [0/8440 (0%)]\tLoss: 0.287296\n",
      "Train Epoch: 2 [1000/8440 (12%)]\tLoss: 0.203217\n",
      "Train Epoch: 2 [2000/8440 (24%)]\tLoss: 0.223109\n",
      "Train Epoch: 2 [3000/8440 (35%)]\tLoss: 0.389341\n",
      "Train Epoch: 2 [4000/8440 (47%)]\tLoss: 0.173144\n",
      "Train Epoch: 2 [5000/8440 (59%)]\tLoss: 0.147952\n",
      "Train Epoch: 2 [6000/8440 (71%)]\tLoss: 0.194720\n",
      "Train Epoch: 2 [7000/8440 (82%)]\tLoss: 0.159980\n",
      "Train Epoch: 2 [8000/8440 (94%)]\tLoss: 0.161720\n",
      "Train Epoch: 3 [0/8440 (0%)]\tLoss: 0.192301\n",
      "Train Epoch: 3 [1000/8440 (12%)]\tLoss: 0.212414\n",
      "Train Epoch: 3 [2000/8440 (24%)]\tLoss: 0.217447\n",
      "Train Epoch: 3 [3000/8440 (35%)]\tLoss: 0.137611\n",
      "Train Epoch: 3 [4000/8440 (47%)]\tLoss: 0.277122\n",
      "Train Epoch: 3 [5000/8440 (59%)]\tLoss: 0.179199\n",
      "Train Epoch: 3 [6000/8440 (71%)]\tLoss: 0.199206\n",
      "Train Epoch: 3 [7000/8440 (82%)]\tLoss: 0.208968\n",
      "Train Epoch: 3 [8000/8440 (94%)]\tLoss: 0.222394\n",
      "Train Epoch: 4 [0/8440 (0%)]\tLoss: 0.175599\n",
      "Train Epoch: 4 [1000/8440 (12%)]\tLoss: 0.196672\n",
      "Train Epoch: 4 [2000/8440 (24%)]\tLoss: 0.325439\n",
      "Train Epoch: 4 [3000/8440 (35%)]\tLoss: 0.133725\n",
      "Train Epoch: 4 [4000/8440 (47%)]\tLoss: 0.191150\n",
      "Train Epoch: 4 [5000/8440 (59%)]\tLoss: 0.181683\n",
      "Train Epoch: 4 [6000/8440 (71%)]\tLoss: 0.195653\n",
      "Train Epoch: 4 [7000/8440 (82%)]\tLoss: 0.219600\n",
      "Train Epoch: 4 [8000/8440 (94%)]\tLoss: 0.232075\n",
      "Train Epoch: 5 [0/8440 (0%)]\tLoss: 0.211364\n",
      "Train Epoch: 5 [1000/8440 (12%)]\tLoss: 0.296759\n",
      "Train Epoch: 5 [2000/8440 (24%)]\tLoss: 0.175239\n",
      "Train Epoch: 5 [3000/8440 (35%)]\tLoss: 0.164136\n",
      "Train Epoch: 5 [4000/8440 (47%)]\tLoss: 0.144983\n",
      "Train Epoch: 5 [5000/8440 (59%)]\tLoss: 0.174403\n",
      "Train Epoch: 5 [6000/8440 (71%)]\tLoss: 0.113823\n",
      "Train Epoch: 5 [7000/8440 (82%)]\tLoss: 0.165165\n",
      "Train Epoch: 5 [8000/8440 (94%)]\tLoss: 0.140359\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11811 (0%)]\tLoss: 0.172157\n",
      "Train Epoch: 1 [1000/11811 (8%)]\tLoss: 0.085715\n",
      "Train Epoch: 1 [2000/11811 (17%)]\tLoss: 0.098767\n",
      "Train Epoch: 1 [3000/11811 (25%)]\tLoss: 0.042145\n",
      "Train Epoch: 1 [4000/11811 (34%)]\tLoss: 0.120171\n",
      "Train Epoch: 1 [5000/11811 (42%)]\tLoss: 0.016109\n",
      "Train Epoch: 1 [6000/11811 (50%)]\tLoss: 0.017205\n",
      "Train Epoch: 1 [7000/11811 (59%)]\tLoss: 0.033420\n",
      "Train Epoch: 1 [8000/11811 (67%)]\tLoss: 0.071015\n",
      "Train Epoch: 1 [9000/11811 (76%)]\tLoss: 0.073378\n",
      "Train Epoch: 1 [10000/11811 (84%)]\tLoss: 0.178435\n",
      "Train Epoch: 1 [11000/11811 (92%)]\tLoss: 0.143152\n",
      "Train Epoch: 2 [0/11811 (0%)]\tLoss: 0.073565\n",
      "Train Epoch: 2 [1000/11811 (8%)]\tLoss: 0.085765\n",
      "Train Epoch: 2 [2000/11811 (17%)]\tLoss: 0.127684\n",
      "Train Epoch: 2 [3000/11811 (25%)]\tLoss: 0.101982\n",
      "Train Epoch: 2 [4000/11811 (34%)]\tLoss: 0.063898\n",
      "Train Epoch: 2 [5000/11811 (42%)]\tLoss: 0.053778\n",
      "Train Epoch: 2 [6000/11811 (50%)]\tLoss: 0.079628\n",
      "Train Epoch: 2 [7000/11811 (59%)]\tLoss: 0.094298\n",
      "Train Epoch: 2 [8000/11811 (67%)]\tLoss: 0.073486\n",
      "Train Epoch: 2 [9000/11811 (76%)]\tLoss: 0.157109\n",
      "Train Epoch: 2 [10000/11811 (84%)]\tLoss: 0.071273\n",
      "Train Epoch: 2 [11000/11811 (92%)]\tLoss: 0.129516\n",
      "Train Epoch: 3 [0/11811 (0%)]\tLoss: 0.105328\n",
      "Train Epoch: 3 [1000/11811 (8%)]\tLoss: 0.093237\n",
      "Train Epoch: 3 [2000/11811 (17%)]\tLoss: 0.108004\n",
      "Train Epoch: 3 [3000/11811 (25%)]\tLoss: 0.058640\n",
      "Train Epoch: 3 [4000/11811 (34%)]\tLoss: 0.102857\n",
      "Train Epoch: 3 [5000/11811 (42%)]\tLoss: 0.181914\n",
      "Train Epoch: 3 [6000/11811 (50%)]\tLoss: 0.082271\n",
      "Train Epoch: 3 [7000/11811 (59%)]\tLoss: 0.033283\n",
      "Train Epoch: 3 [8000/11811 (67%)]\tLoss: 0.047473\n",
      "Train Epoch: 3 [9000/11811 (76%)]\tLoss: 0.039484\n",
      "Train Epoch: 3 [10000/11811 (84%)]\tLoss: 0.013112\n",
      "Train Epoch: 3 [11000/11811 (92%)]\tLoss: 0.099617\n",
      "Train Epoch: 4 [0/11811 (0%)]\tLoss: 0.082142\n",
      "Train Epoch: 4 [1000/11811 (8%)]\tLoss: 0.051161\n",
      "Train Epoch: 4 [2000/11811 (17%)]\tLoss: 0.049386\n",
      "Train Epoch: 4 [3000/11811 (25%)]\tLoss: 0.041757\n",
      "Train Epoch: 4 [4000/11811 (34%)]\tLoss: 0.072338\n",
      "Train Epoch: 4 [5000/11811 (42%)]\tLoss: 0.047735\n",
      "Train Epoch: 4 [6000/11811 (50%)]\tLoss: 0.107201\n",
      "Train Epoch: 4 [7000/11811 (59%)]\tLoss: 0.064976\n",
      "Train Epoch: 4 [8000/11811 (67%)]\tLoss: 0.137655\n",
      "Train Epoch: 4 [9000/11811 (76%)]\tLoss: 0.061769\n",
      "Train Epoch: 4 [10000/11811 (84%)]\tLoss: 0.047718\n",
      "Train Epoch: 4 [11000/11811 (92%)]\tLoss: 0.055010\n",
      "Train Epoch: 5 [0/11811 (0%)]\tLoss: 0.085994\n",
      "Train Epoch: 5 [1000/11811 (8%)]\tLoss: 0.056512\n",
      "Train Epoch: 5 [2000/11811 (17%)]\tLoss: 0.090759\n",
      "Train Epoch: 5 [3000/11811 (25%)]\tLoss: 0.043873\n",
      "Train Epoch: 5 [4000/11811 (34%)]\tLoss: 0.104486\n",
      "Train Epoch: 5 [5000/11811 (42%)]\tLoss: 0.113801\n",
      "Train Epoch: 5 [6000/11811 (50%)]\tLoss: 0.169740\n",
      "Train Epoch: 5 [7000/11811 (59%)]\tLoss: 0.067211\n",
      "Train Epoch: 5 [8000/11811 (67%)]\tLoss: 0.058956\n",
      "Train Epoch: 5 [9000/11811 (76%)]\tLoss: 0.054439\n",
      "Train Epoch: 5 [10000/11811 (84%)]\tLoss: 0.063266\n",
      "Train Epoch: 5 [11000/11811 (92%)]\tLoss: 0.086860\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "6\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4105, Accuracy: 8559/10000 (86%)\n",
      "\n",
      "Running experiment with 8 partitions...\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.273982\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 0.270311\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 0.381628\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 0.344588\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 0.307280\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 0.380333\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 0.386546\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 0.173143\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.483646\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 0.270410\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.268319\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 0.291255\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.292225\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 0.197144\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 0.210816\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.364400\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.294429\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 0.361142\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 0.317631\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 0.388192\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.323094\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 0.236569\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.435082\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 0.343929\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.335182\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.242500\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.274711\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 0.381853\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.321295\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 0.254622\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.339909\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 0.259905\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.241320\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 0.334231\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.331319\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.305183\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.272951\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 0.287942\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.407102\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 0.294433\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.410392\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 0.323345\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.307944\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 0.246475\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.459981\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.314318\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.376711\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 0.191230\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.323531\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 0.263507\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.289275\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 0.322968\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.342033\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 0.247612\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.239199\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.236090\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.381924\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 0.328000\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.279719\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 0.332328\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.390268\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 0.125356\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.211513\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 0.398069\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.271140\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.331902\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.286440\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 0.187780\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.259905\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 0.263249\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.274315\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 0.401816\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.243645\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 0.158443\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.350626\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.217413\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.317077\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 0.336170\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.283420\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 0.258942\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.162788\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 0.184287\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.320222\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 0.571533\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.328497\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.285157\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.309058\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 0.280507\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.264491\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 0.352610\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.279897\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 0.313087\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.316645\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 0.246974\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.366067\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.209041\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.242625\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 0.263075\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.176296\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 0.302566\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.272978\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 0.248972\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.218133\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 0.258697\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.241953\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.247681\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.209718\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 0.346434\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.262730\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 0.273070\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.231554\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 0.258857\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.321464\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 0.354099\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.410519\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.255581\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.324082\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 0.187023\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.233547\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 0.277397\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.211290\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 0.303357\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.301330\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 0.409890\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.354786\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.298434\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.284757\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 0.369088\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.303324\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 0.255025\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.377971\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 0.141215\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.300934\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 0.364847\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.149490\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.265339\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.390090\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 0.403181\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.244899\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 0.290070\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.302459\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 0.287921\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.340396\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 0.338377\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.231899\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.329943\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.324348\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 0.205354\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.317975\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 0.373219\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.311295\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 0.274346\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.288695\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 0.272259\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.266741\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.296186\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.284451\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 0.374739\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.214062\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 0.409086\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.230817\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 0.526666\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.173701\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 0.256914\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.227376\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.235931\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.248430\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 0.223095\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.307148\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 0.287211\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.197212\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 0.251498\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.210749\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 0.259383\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.353284\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.292607\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.315041\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 0.392356\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.264891\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 0.304437\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.239964\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 0.204756\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.210354\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 0.296198\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.342933\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.511314\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.375166\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 0.389550\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.221062\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 0.212926\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.249545\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 0.353114\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.190208\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 0.457558\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.174443\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.208246\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.220972\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 0.261950\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.337338\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 0.203213\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.323755\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 0.259632\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.268521\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 0.273625\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.362590\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.253705\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.218664\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 0.410639\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.273655\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 0.227094\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.289906\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 0.299709\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.222066\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 0.268583\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.292279\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.263747\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.295530\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 0.293412\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.302394\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 0.255386\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.420695\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 0.375091\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.212726\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 0.208635\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.146052\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.315883\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.225200\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 0.273480\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.135863\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 0.311334\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.227395\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 0.279673\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.206708\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 0.268173\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.299862\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.351882\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.399169\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 0.224156\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.366253\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 0.196374\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.249607\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 0.317617\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.236634\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 0.280136\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.350705\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.376080\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.163945\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 0.230938\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.239437\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 0.233304\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.255540\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 0.269038\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.170887\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 0.299174\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.346836\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.309207\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.349199\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 0.172405\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.174121\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 0.387521\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.307957\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 0.424176\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.317063\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 0.337845\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.278480\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.211903\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.218006\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 0.492790\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.354567\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 0.235041\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.223203\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 0.322395\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.275256\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 0.414590\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.325317\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.336054\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.215248\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 0.229494\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.411502\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 0.215819\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.258513\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 0.370971\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.283247\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 0.213472\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.287328\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.161108\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.244289\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 0.368240\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.285483\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 0.291477\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.247550\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 0.354318\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.235376\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 0.286387\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.266810\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.215015\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.323090\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 0.296152\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.243170\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 0.355035\n",
      "\n",
      "Test set: Avg. loss: 0.2676, Accuracy: 54068/60000 (90%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/7731 (0%)]\tLoss: 0.239006\n",
      "Train Epoch: 1 [1000/7731 (13%)]\tLoss: 0.228442\n",
      "Train Epoch: 1 [2000/7731 (26%)]\tLoss: 0.129543\n",
      "Train Epoch: 1 [3000/7731 (38%)]\tLoss: 0.108030\n",
      "Train Epoch: 1 [4000/7731 (51%)]\tLoss: 0.145550\n",
      "Train Epoch: 1 [5000/7731 (64%)]\tLoss: 0.168292\n",
      "Train Epoch: 1 [6000/7731 (77%)]\tLoss: 0.123177\n",
      "Train Epoch: 1 [7000/7731 (90%)]\tLoss: 0.120590\n",
      "Train Epoch: 2 [0/7731 (0%)]\tLoss: 0.192366\n",
      "Train Epoch: 2 [1000/7731 (13%)]\tLoss: 0.186636\n",
      "Train Epoch: 2 [2000/7731 (26%)]\tLoss: 0.082327\n",
      "Train Epoch: 2 [3000/7731 (38%)]\tLoss: 0.159598\n",
      "Train Epoch: 2 [4000/7731 (51%)]\tLoss: 0.174698\n",
      "Train Epoch: 2 [5000/7731 (64%)]\tLoss: 0.126722\n",
      "Train Epoch: 2 [6000/7731 (77%)]\tLoss: 0.149129\n",
      "Train Epoch: 2 [7000/7731 (90%)]\tLoss: 0.238741\n",
      "Train Epoch: 3 [0/7731 (0%)]\tLoss: 0.135203\n",
      "Train Epoch: 3 [1000/7731 (13%)]\tLoss: 0.124533\n",
      "Train Epoch: 3 [2000/7731 (26%)]\tLoss: 0.195425\n",
      "Train Epoch: 3 [3000/7731 (38%)]\tLoss: 0.077373\n",
      "Train Epoch: 3 [4000/7731 (51%)]\tLoss: 0.152714\n",
      "Train Epoch: 3 [5000/7731 (64%)]\tLoss: 0.255191\n",
      "Train Epoch: 3 [6000/7731 (77%)]\tLoss: 0.173563\n",
      "Train Epoch: 3 [7000/7731 (90%)]\tLoss: 0.183934\n",
      "Train Epoch: 4 [0/7731 (0%)]\tLoss: 0.175941\n",
      "Train Epoch: 4 [1000/7731 (13%)]\tLoss: 0.132028\n",
      "Train Epoch: 4 [2000/7731 (26%)]\tLoss: 0.053772\n",
      "Train Epoch: 4 [3000/7731 (38%)]\tLoss: 0.080838\n",
      "Train Epoch: 4 [4000/7731 (51%)]\tLoss: 0.150963\n",
      "Train Epoch: 4 [5000/7731 (64%)]\tLoss: 0.182941\n",
      "Train Epoch: 4 [6000/7731 (77%)]\tLoss: 0.180023\n",
      "Train Epoch: 4 [7000/7731 (90%)]\tLoss: 0.150736\n",
      "Train Epoch: 5 [0/7731 (0%)]\tLoss: 0.097538\n",
      "Train Epoch: 5 [1000/7731 (13%)]\tLoss: 0.106409\n",
      "Train Epoch: 5 [2000/7731 (26%)]\tLoss: 0.108186\n",
      "Train Epoch: 5 [3000/7731 (38%)]\tLoss: 0.155616\n",
      "Train Epoch: 5 [4000/7731 (51%)]\tLoss: 0.100444\n",
      "Train Epoch: 5 [5000/7731 (64%)]\tLoss: 0.112325\n",
      "Train Epoch: 5 [6000/7731 (77%)]\tLoss: 0.163610\n",
      "Train Epoch: 5 [7000/7731 (90%)]\tLoss: 0.118366\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11194 (0%)]\tLoss: 0.213352\n",
      "Train Epoch: 1 [1000/11194 (9%)]\tLoss: 0.137664\n",
      "Train Epoch: 1 [2000/11194 (18%)]\tLoss: 0.130465\n",
      "Train Epoch: 1 [3000/11194 (27%)]\tLoss: 0.138286\n",
      "Train Epoch: 1 [4000/11194 (36%)]\tLoss: 0.134091\n",
      "Train Epoch: 1 [5000/11194 (45%)]\tLoss: 0.223571\n",
      "Train Epoch: 1 [6000/11194 (54%)]\tLoss: 0.195911\n",
      "Train Epoch: 1 [7000/11194 (62%)]\tLoss: 0.279189\n",
      "Train Epoch: 1 [8000/11194 (71%)]\tLoss: 0.239543\n",
      "Train Epoch: 1 [9000/11194 (80%)]\tLoss: 0.125744\n",
      "Train Epoch: 1 [10000/11194 (89%)]\tLoss: 0.171150\n",
      "Train Epoch: 1 [11000/11194 (98%)]\tLoss: 0.137552\n",
      "Train Epoch: 2 [0/11194 (0%)]\tLoss: 0.214183\n",
      "Train Epoch: 2 [1000/11194 (9%)]\tLoss: 0.167262\n",
      "Train Epoch: 2 [2000/11194 (18%)]\tLoss: 0.164426\n",
      "Train Epoch: 2 [3000/11194 (27%)]\tLoss: 0.188160\n",
      "Train Epoch: 2 [4000/11194 (36%)]\tLoss: 0.188218\n",
      "Train Epoch: 2 [5000/11194 (45%)]\tLoss: 0.152186\n",
      "Train Epoch: 2 [6000/11194 (54%)]\tLoss: 0.191098\n",
      "Train Epoch: 2 [7000/11194 (62%)]\tLoss: 0.193396\n",
      "Train Epoch: 2 [8000/11194 (71%)]\tLoss: 0.191149\n",
      "Train Epoch: 2 [9000/11194 (80%)]\tLoss: 0.153738\n",
      "Train Epoch: 2 [10000/11194 (89%)]\tLoss: 0.315173\n",
      "Train Epoch: 2 [11000/11194 (98%)]\tLoss: 0.103391\n",
      "Train Epoch: 3 [0/11194 (0%)]\tLoss: 0.152173\n",
      "Train Epoch: 3 [1000/11194 (9%)]\tLoss: 0.137015\n",
      "Train Epoch: 3 [2000/11194 (18%)]\tLoss: 0.144295\n",
      "Train Epoch: 3 [3000/11194 (27%)]\tLoss: 0.077223\n",
      "Train Epoch: 3 [4000/11194 (36%)]\tLoss: 0.244067\n",
      "Train Epoch: 3 [5000/11194 (45%)]\tLoss: 0.101737\n",
      "Train Epoch: 3 [6000/11194 (54%)]\tLoss: 0.079400\n",
      "Train Epoch: 3 [7000/11194 (62%)]\tLoss: 0.063419\n",
      "Train Epoch: 3 [8000/11194 (71%)]\tLoss: 0.265771\n",
      "Train Epoch: 3 [9000/11194 (80%)]\tLoss: 0.120399\n",
      "Train Epoch: 3 [10000/11194 (89%)]\tLoss: 0.142028\n",
      "Train Epoch: 3 [11000/11194 (98%)]\tLoss: 0.166877\n",
      "Train Epoch: 4 [0/11194 (0%)]\tLoss: 0.188442\n",
      "Train Epoch: 4 [1000/11194 (9%)]\tLoss: 0.140233\n",
      "Train Epoch: 4 [2000/11194 (18%)]\tLoss: 0.141835\n",
      "Train Epoch: 4 [3000/11194 (27%)]\tLoss: 0.103340\n",
      "Train Epoch: 4 [4000/11194 (36%)]\tLoss: 0.090756\n",
      "Train Epoch: 4 [5000/11194 (45%)]\tLoss: 0.114606\n",
      "Train Epoch: 4 [6000/11194 (54%)]\tLoss: 0.116599\n",
      "Train Epoch: 4 [7000/11194 (62%)]\tLoss: 0.108287\n",
      "Train Epoch: 4 [8000/11194 (71%)]\tLoss: 0.166207\n",
      "Train Epoch: 4 [9000/11194 (80%)]\tLoss: 0.161599\n",
      "Train Epoch: 4 [10000/11194 (89%)]\tLoss: 0.172882\n",
      "Train Epoch: 4 [11000/11194 (98%)]\tLoss: 0.168390\n",
      "Train Epoch: 5 [0/11194 (0%)]\tLoss: 0.121841\n",
      "Train Epoch: 5 [1000/11194 (9%)]\tLoss: 0.178853\n",
      "Train Epoch: 5 [2000/11194 (18%)]\tLoss: 0.063478\n",
      "Train Epoch: 5 [3000/11194 (27%)]\tLoss: 0.158854\n",
      "Train Epoch: 5 [4000/11194 (36%)]\tLoss: 0.197562\n",
      "Train Epoch: 5 [5000/11194 (45%)]\tLoss: 0.135900\n",
      "Train Epoch: 5 [6000/11194 (54%)]\tLoss: 0.107143\n",
      "Train Epoch: 5 [7000/11194 (62%)]\tLoss: 0.088621\n",
      "Train Epoch: 5 [8000/11194 (71%)]\tLoss: 0.110754\n",
      "Train Epoch: 5 [9000/11194 (80%)]\tLoss: 0.173204\n",
      "Train Epoch: 5 [10000/11194 (89%)]\tLoss: 0.181092\n",
      "Train Epoch: 5 [11000/11194 (98%)]\tLoss: 0.131037\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/7891 (0%)]\tLoss: 0.260700\n",
      "Train Epoch: 1 [1000/7891 (13%)]\tLoss: 0.118888\n",
      "Train Epoch: 1 [2000/7891 (25%)]\tLoss: 0.139326\n",
      "Train Epoch: 1 [3000/7891 (38%)]\tLoss: 0.181369\n",
      "Train Epoch: 1 [4000/7891 (51%)]\tLoss: 0.161912\n",
      "Train Epoch: 1 [5000/7891 (63%)]\tLoss: 0.074719\n",
      "Train Epoch: 1 [6000/7891 (76%)]\tLoss: 0.247443\n",
      "Train Epoch: 1 [7000/7891 (89%)]\tLoss: 0.208420\n",
      "Train Epoch: 2 [0/7891 (0%)]\tLoss: 0.153585\n",
      "Train Epoch: 2 [1000/7891 (13%)]\tLoss: 0.082426\n",
      "Train Epoch: 2 [2000/7891 (25%)]\tLoss: 0.138689\n",
      "Train Epoch: 2 [3000/7891 (38%)]\tLoss: 0.124979\n",
      "Train Epoch: 2 [4000/7891 (51%)]\tLoss: 0.136580\n",
      "Train Epoch: 2 [5000/7891 (63%)]\tLoss: 0.158308\n",
      "Train Epoch: 2 [6000/7891 (76%)]\tLoss: 0.066227\n",
      "Train Epoch: 2 [7000/7891 (89%)]\tLoss: 0.048099\n",
      "Train Epoch: 3 [0/7891 (0%)]\tLoss: 0.109694\n",
      "Train Epoch: 3 [1000/7891 (13%)]\tLoss: 0.126640\n",
      "Train Epoch: 3 [2000/7891 (25%)]\tLoss: 0.133548\n",
      "Train Epoch: 3 [3000/7891 (38%)]\tLoss: 0.042080\n",
      "Train Epoch: 3 [4000/7891 (51%)]\tLoss: 0.173309\n",
      "Train Epoch: 3 [5000/7891 (63%)]\tLoss: 0.114463\n",
      "Train Epoch: 3 [6000/7891 (76%)]\tLoss: 0.120920\n",
      "Train Epoch: 3 [7000/7891 (89%)]\tLoss: 0.104611\n",
      "Train Epoch: 4 [0/7891 (0%)]\tLoss: 0.099183\n",
      "Train Epoch: 4 [1000/7891 (13%)]\tLoss: 0.079932\n",
      "Train Epoch: 4 [2000/7891 (25%)]\tLoss: 0.078260\n",
      "Train Epoch: 4 [3000/7891 (38%)]\tLoss: 0.088683\n",
      "Train Epoch: 4 [4000/7891 (51%)]\tLoss: 0.145548\n",
      "Train Epoch: 4 [5000/7891 (63%)]\tLoss: 0.132536\n",
      "Train Epoch: 4 [6000/7891 (76%)]\tLoss: 0.108044\n",
      "Train Epoch: 4 [7000/7891 (89%)]\tLoss: 0.065883\n",
      "Train Epoch: 5 [0/7891 (0%)]\tLoss: 0.053119\n",
      "Train Epoch: 5 [1000/7891 (13%)]\tLoss: 0.158604\n",
      "Train Epoch: 5 [2000/7891 (25%)]\tLoss: 0.075901\n",
      "Train Epoch: 5 [3000/7891 (38%)]\tLoss: 0.075538\n",
      "Train Epoch: 5 [4000/7891 (51%)]\tLoss: 0.038512\n",
      "Train Epoch: 5 [5000/7891 (63%)]\tLoss: 0.156251\n",
      "Train Epoch: 5 [6000/7891 (76%)]\tLoss: 0.113803\n",
      "Train Epoch: 5 [7000/7891 (89%)]\tLoss: 0.121244\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/3053 (0%)]\tLoss: 0.164862\n",
      "Train Epoch: 1 [1000/3053 (32%)]\tLoss: 0.094923\n",
      "Train Epoch: 1 [2000/3053 (65%)]\tLoss: 0.076227\n",
      "Train Epoch: 1 [1590/3053 (97%)]\tLoss: 0.191709\n",
      "Train Epoch: 2 [0/3053 (0%)]\tLoss: 0.259868\n",
      "Train Epoch: 2 [1000/3053 (32%)]\tLoss: 0.157634\n",
      "Train Epoch: 2 [2000/3053 (65%)]\tLoss: 0.148114\n",
      "Train Epoch: 2 [1590/3053 (97%)]\tLoss: 0.229807\n",
      "Train Epoch: 3 [0/3053 (0%)]\tLoss: 0.221758\n",
      "Train Epoch: 3 [1000/3053 (32%)]\tLoss: 0.119453\n",
      "Train Epoch: 3 [2000/3053 (65%)]\tLoss: 0.124623\n",
      "Train Epoch: 3 [1590/3053 (97%)]\tLoss: 0.144281\n",
      "Train Epoch: 4 [0/3053 (0%)]\tLoss: 0.181759\n",
      "Train Epoch: 4 [1000/3053 (32%)]\tLoss: 0.128616\n",
      "Train Epoch: 4 [2000/3053 (65%)]\tLoss: 0.108082\n",
      "Train Epoch: 4 [1590/3053 (97%)]\tLoss: 0.047313\n",
      "Train Epoch: 5 [0/3053 (0%)]\tLoss: 0.063471\n",
      "Train Epoch: 5 [1000/3053 (32%)]\tLoss: 0.062250\n",
      "Train Epoch: 5 [2000/3053 (65%)]\tLoss: 0.117087\n",
      "Train Epoch: 5 [1590/3053 (97%)]\tLoss: 0.055709\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/9145 (0%)]\tLoss: 0.358981\n",
      "Train Epoch: 1 [1000/9145 (11%)]\tLoss: 0.193794\n",
      "Train Epoch: 1 [2000/9145 (22%)]\tLoss: 0.227342\n",
      "Train Epoch: 1 [3000/9145 (33%)]\tLoss: 0.204093\n",
      "Train Epoch: 1 [4000/9145 (43%)]\tLoss: 0.233262\n",
      "Train Epoch: 1 [5000/9145 (54%)]\tLoss: 0.210035\n",
      "Train Epoch: 1 [6000/9145 (65%)]\tLoss: 0.271579\n",
      "Train Epoch: 1 [7000/9145 (76%)]\tLoss: 0.251629\n",
      "Train Epoch: 1 [8000/9145 (87%)]\tLoss: 0.195940\n",
      "Train Epoch: 1 [9000/9145 (98%)]\tLoss: 0.364008\n",
      "Train Epoch: 2 [0/9145 (0%)]\tLoss: 0.277019\n",
      "Train Epoch: 2 [1000/9145 (11%)]\tLoss: 0.269641\n",
      "Train Epoch: 2 [2000/9145 (22%)]\tLoss: 0.299841\n",
      "Train Epoch: 2 [3000/9145 (33%)]\tLoss: 0.166342\n",
      "Train Epoch: 2 [4000/9145 (43%)]\tLoss: 0.352359\n",
      "Train Epoch: 2 [5000/9145 (54%)]\tLoss: 0.299501\n",
      "Train Epoch: 2 [6000/9145 (65%)]\tLoss: 0.257540\n",
      "Train Epoch: 2 [7000/9145 (76%)]\tLoss: 0.299528\n",
      "Train Epoch: 2 [8000/9145 (87%)]\tLoss: 0.261081\n",
      "Train Epoch: 2 [9000/9145 (98%)]\tLoss: 0.158346\n",
      "Train Epoch: 3 [0/9145 (0%)]\tLoss: 0.166689\n",
      "Train Epoch: 3 [1000/9145 (11%)]\tLoss: 0.244819\n",
      "Train Epoch: 3 [2000/9145 (22%)]\tLoss: 0.231054\n",
      "Train Epoch: 3 [3000/9145 (33%)]\tLoss: 0.313291\n",
      "Train Epoch: 3 [4000/9145 (43%)]\tLoss: 0.232254\n",
      "Train Epoch: 3 [5000/9145 (54%)]\tLoss: 0.291004\n",
      "Train Epoch: 3 [6000/9145 (65%)]\tLoss: 0.365603\n",
      "Train Epoch: 3 [7000/9145 (76%)]\tLoss: 0.255122\n",
      "Train Epoch: 3 [8000/9145 (87%)]\tLoss: 0.232203\n",
      "Train Epoch: 3 [9000/9145 (98%)]\tLoss: 0.318095\n",
      "Train Epoch: 4 [0/9145 (0%)]\tLoss: 0.168017\n",
      "Train Epoch: 4 [1000/9145 (11%)]\tLoss: 0.235639\n",
      "Train Epoch: 4 [2000/9145 (22%)]\tLoss: 0.099694\n",
      "Train Epoch: 4 [3000/9145 (33%)]\tLoss: 0.249164\n",
      "Train Epoch: 4 [4000/9145 (43%)]\tLoss: 0.272115\n",
      "Train Epoch: 4 [5000/9145 (54%)]\tLoss: 0.287413\n",
      "Train Epoch: 4 [6000/9145 (65%)]\tLoss: 0.188676\n",
      "Train Epoch: 4 [7000/9145 (76%)]\tLoss: 0.190554\n",
      "Train Epoch: 4 [8000/9145 (87%)]\tLoss: 0.221951\n",
      "Train Epoch: 4 [9000/9145 (98%)]\tLoss: 0.215224\n",
      "Train Epoch: 5 [0/9145 (0%)]\tLoss: 0.185465\n",
      "Train Epoch: 5 [1000/9145 (11%)]\tLoss: 0.151217\n",
      "Train Epoch: 5 [2000/9145 (22%)]\tLoss: 0.097203\n",
      "Train Epoch: 5 [3000/9145 (33%)]\tLoss: 0.233673\n",
      "Train Epoch: 5 [4000/9145 (43%)]\tLoss: 0.146210\n",
      "Train Epoch: 5 [5000/9145 (54%)]\tLoss: 0.164235\n",
      "Train Epoch: 5 [6000/9145 (65%)]\tLoss: 0.273100\n",
      "Train Epoch: 5 [7000/9145 (76%)]\tLoss: 0.184546\n",
      "Train Epoch: 5 [8000/9145 (87%)]\tLoss: 0.270380\n",
      "Train Epoch: 5 [9000/9145 (98%)]\tLoss: 0.122310\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3021 (0%)]\tLoss: 0.242304\n",
      "Train Epoch: 1 [1000/3021 (32%)]\tLoss: 0.208171\n",
      "Train Epoch: 1 [2000/3021 (65%)]\tLoss: 0.094638\n",
      "Train Epoch: 1 [630/3021 (97%)]\tLoss: 0.051483\n",
      "Train Epoch: 2 [0/3021 (0%)]\tLoss: 0.114357\n",
      "Train Epoch: 2 [1000/3021 (32%)]\tLoss: 0.253393\n",
      "Train Epoch: 2 [2000/3021 (65%)]\tLoss: 0.167867\n",
      "Train Epoch: 2 [630/3021 (97%)]\tLoss: 0.252007\n",
      "Train Epoch: 3 [0/3021 (0%)]\tLoss: 0.089815\n",
      "Train Epoch: 3 [1000/3021 (32%)]\tLoss: 0.144832\n",
      "Train Epoch: 3 [2000/3021 (65%)]\tLoss: 0.259815\n",
      "Train Epoch: 3 [630/3021 (97%)]\tLoss: 0.185773\n",
      "Train Epoch: 4 [0/3021 (0%)]\tLoss: 0.170412\n",
      "Train Epoch: 4 [1000/3021 (32%)]\tLoss: 0.241040\n",
      "Train Epoch: 4 [2000/3021 (65%)]\tLoss: 0.232346\n",
      "Train Epoch: 4 [630/3021 (97%)]\tLoss: 0.105917\n",
      "Train Epoch: 5 [0/3021 (0%)]\tLoss: 0.171373\n",
      "Train Epoch: 5 [1000/3021 (32%)]\tLoss: 0.095434\n",
      "Train Epoch: 5 [2000/3021 (65%)]\tLoss: 0.179894\n",
      "Train Epoch: 5 [630/3021 (97%)]\tLoss: 0.135920\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/7953 (0%)]\tLoss: 0.594754\n",
      "Train Epoch: 1 [1000/7953 (12%)]\tLoss: 0.541861\n",
      "Train Epoch: 1 [2000/7953 (25%)]\tLoss: 0.262487\n",
      "Train Epoch: 1 [3000/7953 (38%)]\tLoss: 0.451906\n",
      "Train Epoch: 1 [4000/7953 (50%)]\tLoss: 0.470150\n",
      "Train Epoch: 1 [5000/7953 (62%)]\tLoss: 0.358886\n",
      "Train Epoch: 1 [6000/7953 (75%)]\tLoss: 0.456020\n",
      "Train Epoch: 1 [7000/7953 (88%)]\tLoss: 0.349721\n",
      "Train Epoch: 2 [0/7953 (0%)]\tLoss: 0.328299\n",
      "Train Epoch: 2 [1000/7953 (12%)]\tLoss: 0.409533\n",
      "Train Epoch: 2 [2000/7953 (25%)]\tLoss: 0.404261\n",
      "Train Epoch: 2 [3000/7953 (38%)]\tLoss: 0.448913\n",
      "Train Epoch: 2 [4000/7953 (50%)]\tLoss: 0.512683\n",
      "Train Epoch: 2 [5000/7953 (62%)]\tLoss: 0.446768\n",
      "Train Epoch: 2 [6000/7953 (75%)]\tLoss: 0.464436\n",
      "Train Epoch: 2 [7000/7953 (88%)]\tLoss: 0.434750\n",
      "Train Epoch: 3 [0/7953 (0%)]\tLoss: 0.368694\n",
      "Train Epoch: 3 [1000/7953 (12%)]\tLoss: 0.394367\n",
      "Train Epoch: 3 [2000/7953 (25%)]\tLoss: 0.388243\n",
      "Train Epoch: 3 [3000/7953 (38%)]\tLoss: 0.303926\n",
      "Train Epoch: 3 [4000/7953 (50%)]\tLoss: 0.290699\n",
      "Train Epoch: 3 [5000/7953 (62%)]\tLoss: 0.319752\n",
      "Train Epoch: 3 [6000/7953 (75%)]\tLoss: 0.398005\n",
      "Train Epoch: 3 [7000/7953 (88%)]\tLoss: 0.287400\n",
      "Train Epoch: 4 [0/7953 (0%)]\tLoss: 0.388660\n",
      "Train Epoch: 4 [1000/7953 (12%)]\tLoss: 0.346775\n",
      "Train Epoch: 4 [2000/7953 (25%)]\tLoss: 0.379423\n",
      "Train Epoch: 4 [3000/7953 (38%)]\tLoss: 0.339420\n",
      "Train Epoch: 4 [4000/7953 (50%)]\tLoss: 0.291942\n",
      "Train Epoch: 4 [5000/7953 (62%)]\tLoss: 0.428504\n",
      "Train Epoch: 4 [6000/7953 (75%)]\tLoss: 0.429160\n",
      "Train Epoch: 4 [7000/7953 (88%)]\tLoss: 0.343175\n",
      "Train Epoch: 5 [0/7953 (0%)]\tLoss: 0.323928\n",
      "Train Epoch: 5 [1000/7953 (12%)]\tLoss: 0.246070\n",
      "Train Epoch: 5 [2000/7953 (25%)]\tLoss: 0.197573\n",
      "Train Epoch: 5 [3000/7953 (38%)]\tLoss: 0.428172\n",
      "Train Epoch: 5 [4000/7953 (50%)]\tLoss: 0.443901\n",
      "Train Epoch: 5 [5000/7953 (62%)]\tLoss: 0.281535\n",
      "Train Epoch: 5 [6000/7953 (75%)]\tLoss: 0.288889\n",
      "Train Epoch: 5 [7000/7953 (88%)]\tLoss: 0.313807\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/10012 (0%)]\tLoss: 0.189028\n",
      "Train Epoch: 1 [1000/10012 (10%)]\tLoss: 0.113753\n",
      "Train Epoch: 1 [2000/10012 (20%)]\tLoss: 0.139700\n",
      "Train Epoch: 1 [3000/10012 (30%)]\tLoss: 0.100366\n",
      "Train Epoch: 1 [4000/10012 (40%)]\tLoss: 0.145938\n",
      "Train Epoch: 1 [5000/10012 (50%)]\tLoss: 0.213911\n",
      "Train Epoch: 1 [6000/10012 (59%)]\tLoss: 0.248250\n",
      "Train Epoch: 1 [7000/10012 (69%)]\tLoss: 0.076682\n",
      "Train Epoch: 1 [8000/10012 (79%)]\tLoss: 0.117214\n",
      "Train Epoch: 1 [9000/10012 (89%)]\tLoss: 0.101997\n",
      "Train Epoch: 1 [1200/10012 (99%)]\tLoss: 0.030412\n",
      "Train Epoch: 2 [0/10012 (0%)]\tLoss: 0.142407\n",
      "Train Epoch: 2 [1000/10012 (10%)]\tLoss: 0.165534\n",
      "Train Epoch: 2 [2000/10012 (20%)]\tLoss: 0.062970\n",
      "Train Epoch: 2 [3000/10012 (30%)]\tLoss: 0.062934\n",
      "Train Epoch: 2 [4000/10012 (40%)]\tLoss: 0.105602\n",
      "Train Epoch: 2 [5000/10012 (50%)]\tLoss: 0.209260\n",
      "Train Epoch: 2 [6000/10012 (59%)]\tLoss: 0.263596\n",
      "Train Epoch: 2 [7000/10012 (69%)]\tLoss: 0.178813\n",
      "Train Epoch: 2 [8000/10012 (79%)]\tLoss: 0.063212\n",
      "Train Epoch: 2 [9000/10012 (89%)]\tLoss: 0.221419\n",
      "Train Epoch: 2 [1200/10012 (99%)]\tLoss: 0.025573\n",
      "Train Epoch: 3 [0/10012 (0%)]\tLoss: 0.090144\n",
      "Train Epoch: 3 [1000/10012 (10%)]\tLoss: 0.108413\n",
      "Train Epoch: 3 [2000/10012 (20%)]\tLoss: 0.115215\n",
      "Train Epoch: 3 [3000/10012 (30%)]\tLoss: 0.153902\n",
      "Train Epoch: 3 [4000/10012 (40%)]\tLoss: 0.122802\n",
      "Train Epoch: 3 [5000/10012 (50%)]\tLoss: 0.091825\n",
      "Train Epoch: 3 [6000/10012 (59%)]\tLoss: 0.220708\n",
      "Train Epoch: 3 [7000/10012 (69%)]\tLoss: 0.108102\n",
      "Train Epoch: 3 [8000/10012 (79%)]\tLoss: 0.075360\n",
      "Train Epoch: 3 [9000/10012 (89%)]\tLoss: 0.132468\n",
      "Train Epoch: 3 [1200/10012 (99%)]\tLoss: 0.154434\n",
      "Train Epoch: 4 [0/10012 (0%)]\tLoss: 0.087621\n",
      "Train Epoch: 4 [1000/10012 (10%)]\tLoss: 0.207289\n",
      "Train Epoch: 4 [2000/10012 (20%)]\tLoss: 0.175367\n",
      "Train Epoch: 4 [3000/10012 (30%)]\tLoss: 0.098437\n",
      "Train Epoch: 4 [4000/10012 (40%)]\tLoss: 0.098963\n",
      "Train Epoch: 4 [5000/10012 (50%)]\tLoss: 0.183243\n",
      "Train Epoch: 4 [6000/10012 (59%)]\tLoss: 0.062588\n",
      "Train Epoch: 4 [7000/10012 (69%)]\tLoss: 0.076453\n",
      "Train Epoch: 4 [8000/10012 (79%)]\tLoss: 0.141900\n",
      "Train Epoch: 4 [9000/10012 (89%)]\tLoss: 0.028391\n",
      "Train Epoch: 4 [1200/10012 (99%)]\tLoss: 0.009477\n",
      "Train Epoch: 5 [0/10012 (0%)]\tLoss: 0.079081\n",
      "Train Epoch: 5 [1000/10012 (10%)]\tLoss: 0.057557\n",
      "Train Epoch: 5 [2000/10012 (20%)]\tLoss: 0.073412\n",
      "Train Epoch: 5 [3000/10012 (30%)]\tLoss: 0.066633\n",
      "Train Epoch: 5 [4000/10012 (40%)]\tLoss: 0.100307\n",
      "Train Epoch: 5 [5000/10012 (50%)]\tLoss: 0.181208\n",
      "Train Epoch: 5 [6000/10012 (59%)]\tLoss: 0.103264\n",
      "Train Epoch: 5 [7000/10012 (69%)]\tLoss: 0.097792\n",
      "Train Epoch: 5 [8000/10012 (79%)]\tLoss: 0.093283\n",
      "Train Epoch: 5 [9000/10012 (89%)]\tLoss: 0.067232\n",
      "Train Epoch: 5 [1200/10012 (99%)]\tLoss: 0.004973\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "8\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.3666, Accuracy: 8692/10000 (87%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/7731 (0%)]\tLoss: 0.170921\n",
      "Train Epoch: 1 [1000/7731 (13%)]\tLoss: 0.148975\n",
      "Train Epoch: 1 [2000/7731 (26%)]\tLoss: 0.134610\n",
      "Train Epoch: 1 [3000/7731 (38%)]\tLoss: 0.165932\n",
      "Train Epoch: 1 [4000/7731 (51%)]\tLoss: 0.137689\n",
      "Train Epoch: 1 [5000/7731 (64%)]\tLoss: 0.193304\n",
      "Train Epoch: 1 [6000/7731 (77%)]\tLoss: 0.120416\n",
      "Train Epoch: 1 [7000/7731 (90%)]\tLoss: 0.146133\n",
      "Train Epoch: 2 [0/7731 (0%)]\tLoss: 0.125412\n",
      "Train Epoch: 2 [1000/7731 (13%)]\tLoss: 0.098613\n",
      "Train Epoch: 2 [2000/7731 (26%)]\tLoss: 0.170521\n",
      "Train Epoch: 2 [3000/7731 (38%)]\tLoss: 0.233652\n",
      "Train Epoch: 2 [4000/7731 (51%)]\tLoss: 0.113559\n",
      "Train Epoch: 2 [5000/7731 (64%)]\tLoss: 0.134016\n",
      "Train Epoch: 2 [6000/7731 (77%)]\tLoss: 0.100219\n",
      "Train Epoch: 2 [7000/7731 (90%)]\tLoss: 0.092647\n",
      "Train Epoch: 3 [0/7731 (0%)]\tLoss: 0.165289\n",
      "Train Epoch: 3 [1000/7731 (13%)]\tLoss: 0.139515\n",
      "Train Epoch: 3 [2000/7731 (26%)]\tLoss: 0.145094\n",
      "Train Epoch: 3 [3000/7731 (38%)]\tLoss: 0.109098\n",
      "Train Epoch: 3 [4000/7731 (51%)]\tLoss: 0.144490\n",
      "Train Epoch: 3 [5000/7731 (64%)]\tLoss: 0.325742\n",
      "Train Epoch: 3 [6000/7731 (77%)]\tLoss: 0.119201\n",
      "Train Epoch: 3 [7000/7731 (90%)]\tLoss: 0.082261\n",
      "Train Epoch: 4 [0/7731 (0%)]\tLoss: 0.158997\n",
      "Train Epoch: 4 [1000/7731 (13%)]\tLoss: 0.164432\n",
      "Train Epoch: 4 [2000/7731 (26%)]\tLoss: 0.181555\n",
      "Train Epoch: 4 [3000/7731 (38%)]\tLoss: 0.076669\n",
      "Train Epoch: 4 [4000/7731 (51%)]\tLoss: 0.097484\n",
      "Train Epoch: 4 [5000/7731 (64%)]\tLoss: 0.253860\n",
      "Train Epoch: 4 [6000/7731 (77%)]\tLoss: 0.125918\n",
      "Train Epoch: 4 [7000/7731 (90%)]\tLoss: 0.175897\n",
      "Train Epoch: 5 [0/7731 (0%)]\tLoss: 0.170804\n",
      "Train Epoch: 5 [1000/7731 (13%)]\tLoss: 0.148451\n",
      "Train Epoch: 5 [2000/7731 (26%)]\tLoss: 0.147201\n",
      "Train Epoch: 5 [3000/7731 (38%)]\tLoss: 0.147595\n",
      "Train Epoch: 5 [4000/7731 (51%)]\tLoss: 0.051720\n",
      "Train Epoch: 5 [5000/7731 (64%)]\tLoss: 0.217023\n",
      "Train Epoch: 5 [6000/7731 (77%)]\tLoss: 0.129985\n",
      "Train Epoch: 5 [7000/7731 (90%)]\tLoss: 0.176338\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11194 (0%)]\tLoss: 0.242198\n",
      "Train Epoch: 1 [1000/11194 (9%)]\tLoss: 0.106562\n",
      "Train Epoch: 1 [2000/11194 (18%)]\tLoss: 0.185382\n",
      "Train Epoch: 1 [3000/11194 (27%)]\tLoss: 0.284111\n",
      "Train Epoch: 1 [4000/11194 (36%)]\tLoss: 0.139792\n",
      "Train Epoch: 1 [5000/11194 (45%)]\tLoss: 0.116855\n",
      "Train Epoch: 1 [6000/11194 (54%)]\tLoss: 0.077227\n",
      "Train Epoch: 1 [7000/11194 (62%)]\tLoss: 0.261474\n",
      "Train Epoch: 1 [8000/11194 (71%)]\tLoss: 0.092001\n",
      "Train Epoch: 1 [9000/11194 (80%)]\tLoss: 0.226097\n",
      "Train Epoch: 1 [10000/11194 (89%)]\tLoss: 0.215100\n",
      "Train Epoch: 1 [11000/11194 (98%)]\tLoss: 0.250958\n",
      "Train Epoch: 2 [0/11194 (0%)]\tLoss: 0.133950\n",
      "Train Epoch: 2 [1000/11194 (9%)]\tLoss: 0.116373\n",
      "Train Epoch: 2 [2000/11194 (18%)]\tLoss: 0.158635\n",
      "Train Epoch: 2 [3000/11194 (27%)]\tLoss: 0.174912\n",
      "Train Epoch: 2 [4000/11194 (36%)]\tLoss: 0.193633\n",
      "Train Epoch: 2 [5000/11194 (45%)]\tLoss: 0.124877\n",
      "Train Epoch: 2 [6000/11194 (54%)]\tLoss: 0.080319\n",
      "Train Epoch: 2 [7000/11194 (62%)]\tLoss: 0.146686\n",
      "Train Epoch: 2 [8000/11194 (71%)]\tLoss: 0.109254\n",
      "Train Epoch: 2 [9000/11194 (80%)]\tLoss: 0.156366\n",
      "Train Epoch: 2 [10000/11194 (89%)]\tLoss: 0.228697\n",
      "Train Epoch: 2 [11000/11194 (98%)]\tLoss: 0.149208\n",
      "Train Epoch: 3 [0/11194 (0%)]\tLoss: 0.132945\n",
      "Train Epoch: 3 [1000/11194 (9%)]\tLoss: 0.151644\n",
      "Train Epoch: 3 [2000/11194 (18%)]\tLoss: 0.194577\n",
      "Train Epoch: 3 [3000/11194 (27%)]\tLoss: 0.122164\n",
      "Train Epoch: 3 [4000/11194 (36%)]\tLoss: 0.098036\n",
      "Train Epoch: 3 [5000/11194 (45%)]\tLoss: 0.122962\n",
      "Train Epoch: 3 [6000/11194 (54%)]\tLoss: 0.139631\n",
      "Train Epoch: 3 [7000/11194 (62%)]\tLoss: 0.144603\n",
      "Train Epoch: 3 [8000/11194 (71%)]\tLoss: 0.119569\n",
      "Train Epoch: 3 [9000/11194 (80%)]\tLoss: 0.077191\n",
      "Train Epoch: 3 [10000/11194 (89%)]\tLoss: 0.143224\n",
      "Train Epoch: 3 [11000/11194 (98%)]\tLoss: 0.223567\n",
      "Train Epoch: 4 [0/11194 (0%)]\tLoss: 0.143133\n",
      "Train Epoch: 4 [1000/11194 (9%)]\tLoss: 0.184855\n",
      "Train Epoch: 4 [2000/11194 (18%)]\tLoss: 0.164198\n",
      "Train Epoch: 4 [3000/11194 (27%)]\tLoss: 0.195058\n",
      "Train Epoch: 4 [4000/11194 (36%)]\tLoss: 0.212438\n",
      "Train Epoch: 4 [5000/11194 (45%)]\tLoss: 0.105274\n",
      "Train Epoch: 4 [6000/11194 (54%)]\tLoss: 0.139978\n",
      "Train Epoch: 4 [7000/11194 (62%)]\tLoss: 0.141353\n",
      "Train Epoch: 4 [8000/11194 (71%)]\tLoss: 0.113663\n",
      "Train Epoch: 4 [9000/11194 (80%)]\tLoss: 0.196831\n",
      "Train Epoch: 4 [10000/11194 (89%)]\tLoss: 0.161212\n",
      "Train Epoch: 4 [11000/11194 (98%)]\tLoss: 0.133681\n",
      "Train Epoch: 5 [0/11194 (0%)]\tLoss: 0.222038\n",
      "Train Epoch: 5 [1000/11194 (9%)]\tLoss: 0.185356\n",
      "Train Epoch: 5 [2000/11194 (18%)]\tLoss: 0.071098\n",
      "Train Epoch: 5 [3000/11194 (27%)]\tLoss: 0.210385\n",
      "Train Epoch: 5 [4000/11194 (36%)]\tLoss: 0.144285\n",
      "Train Epoch: 5 [5000/11194 (45%)]\tLoss: 0.095770\n",
      "Train Epoch: 5 [6000/11194 (54%)]\tLoss: 0.160915\n",
      "Train Epoch: 5 [7000/11194 (62%)]\tLoss: 0.257148\n",
      "Train Epoch: 5 [8000/11194 (71%)]\tLoss: 0.144828\n",
      "Train Epoch: 5 [9000/11194 (80%)]\tLoss: 0.164322\n",
      "Train Epoch: 5 [10000/11194 (89%)]\tLoss: 0.136048\n",
      "Train Epoch: 5 [11000/11194 (98%)]\tLoss: 0.115637\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/7891 (0%)]\tLoss: 0.204283\n",
      "Train Epoch: 1 [1000/7891 (13%)]\tLoss: 0.208938\n",
      "Train Epoch: 1 [2000/7891 (25%)]\tLoss: 0.104365\n",
      "Train Epoch: 1 [3000/7891 (38%)]\tLoss: 0.164260\n",
      "Train Epoch: 1 [4000/7891 (51%)]\tLoss: 0.097796\n",
      "Train Epoch: 1 [5000/7891 (63%)]\tLoss: 0.189177\n",
      "Train Epoch: 1 [6000/7891 (76%)]\tLoss: 0.118267\n",
      "Train Epoch: 1 [7000/7891 (89%)]\tLoss: 0.172102\n",
      "Train Epoch: 2 [0/7891 (0%)]\tLoss: 0.055139\n",
      "Train Epoch: 2 [1000/7891 (13%)]\tLoss: 0.153646\n",
      "Train Epoch: 2 [2000/7891 (25%)]\tLoss: 0.167045\n",
      "Train Epoch: 2 [3000/7891 (38%)]\tLoss: 0.097331\n",
      "Train Epoch: 2 [4000/7891 (51%)]\tLoss: 0.096801\n",
      "Train Epoch: 2 [5000/7891 (63%)]\tLoss: 0.038673\n",
      "Train Epoch: 2 [6000/7891 (76%)]\tLoss: 0.171193\n",
      "Train Epoch: 2 [7000/7891 (89%)]\tLoss: 0.116423\n",
      "Train Epoch: 3 [0/7891 (0%)]\tLoss: 0.131193\n",
      "Train Epoch: 3 [1000/7891 (13%)]\tLoss: 0.146890\n",
      "Train Epoch: 3 [2000/7891 (25%)]\tLoss: 0.123485\n",
      "Train Epoch: 3 [3000/7891 (38%)]\tLoss: 0.072128\n",
      "Train Epoch: 3 [4000/7891 (51%)]\tLoss: 0.199242\n",
      "Train Epoch: 3 [5000/7891 (63%)]\tLoss: 0.099779\n",
      "Train Epoch: 3 [6000/7891 (76%)]\tLoss: 0.239917\n",
      "Train Epoch: 3 [7000/7891 (89%)]\tLoss: 0.074905\n",
      "Train Epoch: 4 [0/7891 (0%)]\tLoss: 0.068076\n",
      "Train Epoch: 4 [1000/7891 (13%)]\tLoss: 0.153841\n",
      "Train Epoch: 4 [2000/7891 (25%)]\tLoss: 0.111143\n",
      "Train Epoch: 4 [3000/7891 (38%)]\tLoss: 0.097739\n",
      "Train Epoch: 4 [4000/7891 (51%)]\tLoss: 0.105644\n",
      "Train Epoch: 4 [5000/7891 (63%)]\tLoss: 0.072473\n",
      "Train Epoch: 4 [6000/7891 (76%)]\tLoss: 0.112345\n",
      "Train Epoch: 4 [7000/7891 (89%)]\tLoss: 0.113083\n",
      "Train Epoch: 5 [0/7891 (0%)]\tLoss: 0.099784\n",
      "Train Epoch: 5 [1000/7891 (13%)]\tLoss: 0.068971\n",
      "Train Epoch: 5 [2000/7891 (25%)]\tLoss: 0.138356\n",
      "Train Epoch: 5 [3000/7891 (38%)]\tLoss: 0.206462\n",
      "Train Epoch: 5 [4000/7891 (51%)]\tLoss: 0.115570\n",
      "Train Epoch: 5 [5000/7891 (63%)]\tLoss: 0.145061\n",
      "Train Epoch: 5 [6000/7891 (76%)]\tLoss: 0.063762\n",
      "Train Epoch: 5 [7000/7891 (89%)]\tLoss: 0.102800\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/3053 (0%)]\tLoss: 0.192139\n",
      "Train Epoch: 1 [1000/3053 (32%)]\tLoss: 0.175338\n",
      "Train Epoch: 1 [2000/3053 (65%)]\tLoss: 0.116991\n",
      "Train Epoch: 1 [1590/3053 (97%)]\tLoss: 0.343305\n",
      "Train Epoch: 2 [0/3053 (0%)]\tLoss: 0.081432\n",
      "Train Epoch: 2 [1000/3053 (32%)]\tLoss: 0.111616\n",
      "Train Epoch: 2 [2000/3053 (65%)]\tLoss: 0.145447\n",
      "Train Epoch: 2 [1590/3053 (97%)]\tLoss: 0.128395\n",
      "Train Epoch: 3 [0/3053 (0%)]\tLoss: 0.099689\n",
      "Train Epoch: 3 [1000/3053 (32%)]\tLoss: 0.083011\n",
      "Train Epoch: 3 [2000/3053 (65%)]\tLoss: 0.126574\n",
      "Train Epoch: 3 [1590/3053 (97%)]\tLoss: 0.071139\n",
      "Train Epoch: 4 [0/3053 (0%)]\tLoss: 0.166893\n",
      "Train Epoch: 4 [1000/3053 (32%)]\tLoss: 0.095166\n",
      "Train Epoch: 4 [2000/3053 (65%)]\tLoss: 0.126323\n",
      "Train Epoch: 4 [1590/3053 (97%)]\tLoss: 0.140556\n",
      "Train Epoch: 5 [0/3053 (0%)]\tLoss: 0.062501\n",
      "Train Epoch: 5 [1000/3053 (32%)]\tLoss: 0.190829\n",
      "Train Epoch: 5 [2000/3053 (65%)]\tLoss: 0.177249\n",
      "Train Epoch: 5 [1590/3053 (97%)]\tLoss: 0.097470\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/9145 (0%)]\tLoss: 0.267027\n",
      "Train Epoch: 1 [1000/9145 (11%)]\tLoss: 0.204622\n",
      "Train Epoch: 1 [2000/9145 (22%)]\tLoss: 0.204458\n",
      "Train Epoch: 1 [3000/9145 (33%)]\tLoss: 0.289118\n",
      "Train Epoch: 1 [4000/9145 (43%)]\tLoss: 0.275059\n",
      "Train Epoch: 1 [5000/9145 (54%)]\tLoss: 0.275973\n",
      "Train Epoch: 1 [6000/9145 (65%)]\tLoss: 0.260762\n",
      "Train Epoch: 1 [7000/9145 (76%)]\tLoss: 0.298689\n",
      "Train Epoch: 1 [8000/9145 (87%)]\tLoss: 0.312955\n",
      "Train Epoch: 1 [9000/9145 (98%)]\tLoss: 0.258710\n",
      "Train Epoch: 2 [0/9145 (0%)]\tLoss: 0.167895\n",
      "Train Epoch: 2 [1000/9145 (11%)]\tLoss: 0.353607\n",
      "Train Epoch: 2 [2000/9145 (22%)]\tLoss: 0.191834\n",
      "Train Epoch: 2 [3000/9145 (33%)]\tLoss: 0.236646\n",
      "Train Epoch: 2 [4000/9145 (43%)]\tLoss: 0.263581\n",
      "Train Epoch: 2 [5000/9145 (54%)]\tLoss: 0.259168\n",
      "Train Epoch: 2 [6000/9145 (65%)]\tLoss: 0.221557\n",
      "Train Epoch: 2 [7000/9145 (76%)]\tLoss: 0.291371\n",
      "Train Epoch: 2 [8000/9145 (87%)]\tLoss: 0.108114\n",
      "Train Epoch: 2 [9000/9145 (98%)]\tLoss: 0.242577\n",
      "Train Epoch: 3 [0/9145 (0%)]\tLoss: 0.199328\n",
      "Train Epoch: 3 [1000/9145 (11%)]\tLoss: 0.204119\n",
      "Train Epoch: 3 [2000/9145 (22%)]\tLoss: 0.163033\n",
      "Train Epoch: 3 [3000/9145 (33%)]\tLoss: 0.250371\n",
      "Train Epoch: 3 [4000/9145 (43%)]\tLoss: 0.287619\n",
      "Train Epoch: 3 [5000/9145 (54%)]\tLoss: 0.207339\n",
      "Train Epoch: 3 [6000/9145 (65%)]\tLoss: 0.222259\n",
      "Train Epoch: 3 [7000/9145 (76%)]\tLoss: 0.275355\n",
      "Train Epoch: 3 [8000/9145 (87%)]\tLoss: 0.166265\n",
      "Train Epoch: 3 [9000/9145 (98%)]\tLoss: 0.201043\n",
      "Train Epoch: 4 [0/9145 (0%)]\tLoss: 0.226778\n",
      "Train Epoch: 4 [1000/9145 (11%)]\tLoss: 0.155326\n",
      "Train Epoch: 4 [2000/9145 (22%)]\tLoss: 0.255545\n",
      "Train Epoch: 4 [3000/9145 (33%)]\tLoss: 0.227908\n",
      "Train Epoch: 4 [4000/9145 (43%)]\tLoss: 0.116630\n",
      "Train Epoch: 4 [5000/9145 (54%)]\tLoss: 0.196348\n",
      "Train Epoch: 4 [6000/9145 (65%)]\tLoss: 0.222829\n",
      "Train Epoch: 4 [7000/9145 (76%)]\tLoss: 0.285831\n",
      "Train Epoch: 4 [8000/9145 (87%)]\tLoss: 0.181273\n",
      "Train Epoch: 4 [9000/9145 (98%)]\tLoss: 0.274739\n",
      "Train Epoch: 5 [0/9145 (0%)]\tLoss: 0.162810\n",
      "Train Epoch: 5 [1000/9145 (11%)]\tLoss: 0.202580\n",
      "Train Epoch: 5 [2000/9145 (22%)]\tLoss: 0.187374\n",
      "Train Epoch: 5 [3000/9145 (33%)]\tLoss: 0.236608\n",
      "Train Epoch: 5 [4000/9145 (43%)]\tLoss: 0.299579\n",
      "Train Epoch: 5 [5000/9145 (54%)]\tLoss: 0.143861\n",
      "Train Epoch: 5 [6000/9145 (65%)]\tLoss: 0.225273\n",
      "Train Epoch: 5 [7000/9145 (76%)]\tLoss: 0.233569\n",
      "Train Epoch: 5 [8000/9145 (87%)]\tLoss: 0.215630\n",
      "Train Epoch: 5 [9000/9145 (98%)]\tLoss: 0.289215\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3021 (0%)]\tLoss: 0.243244\n",
      "Train Epoch: 1 [1000/3021 (32%)]\tLoss: 0.146238\n",
      "Train Epoch: 1 [2000/3021 (65%)]\tLoss: 0.222455\n",
      "Train Epoch: 1 [630/3021 (97%)]\tLoss: 0.174025\n",
      "Train Epoch: 2 [0/3021 (0%)]\tLoss: 0.289709\n",
      "Train Epoch: 2 [1000/3021 (32%)]\tLoss: 0.246640\n",
      "Train Epoch: 2 [2000/3021 (65%)]\tLoss: 0.110167\n",
      "Train Epoch: 2 [630/3021 (97%)]\tLoss: 0.122433\n",
      "Train Epoch: 3 [0/3021 (0%)]\tLoss: 0.239899\n",
      "Train Epoch: 3 [1000/3021 (32%)]\tLoss: 0.182411\n",
      "Train Epoch: 3 [2000/3021 (65%)]\tLoss: 0.113079\n",
      "Train Epoch: 3 [630/3021 (97%)]\tLoss: 0.307710\n",
      "Train Epoch: 4 [0/3021 (0%)]\tLoss: 0.156672\n",
      "Train Epoch: 4 [1000/3021 (32%)]\tLoss: 0.211006\n",
      "Train Epoch: 4 [2000/3021 (65%)]\tLoss: 0.118430\n",
      "Train Epoch: 4 [630/3021 (97%)]\tLoss: 0.376289\n",
      "Train Epoch: 5 [0/3021 (0%)]\tLoss: 0.181074\n",
      "Train Epoch: 5 [1000/3021 (32%)]\tLoss: 0.184514\n",
      "Train Epoch: 5 [2000/3021 (65%)]\tLoss: 0.169535\n",
      "Train Epoch: 5 [630/3021 (97%)]\tLoss: 0.319724\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/7953 (0%)]\tLoss: 0.399237\n",
      "Train Epoch: 1 [1000/7953 (12%)]\tLoss: 0.379772\n",
      "Train Epoch: 1 [2000/7953 (25%)]\tLoss: 0.415840\n",
      "Train Epoch: 1 [3000/7953 (38%)]\tLoss: 0.418642\n",
      "Train Epoch: 1 [4000/7953 (50%)]\tLoss: 0.400477\n",
      "Train Epoch: 1 [5000/7953 (62%)]\tLoss: 0.534268\n",
      "Train Epoch: 1 [6000/7953 (75%)]\tLoss: 0.380762\n",
      "Train Epoch: 1 [7000/7953 (88%)]\tLoss: 0.350942\n",
      "Train Epoch: 2 [0/7953 (0%)]\tLoss: 0.478991\n",
      "Train Epoch: 2 [1000/7953 (12%)]\tLoss: 0.397169\n",
      "Train Epoch: 2 [2000/7953 (25%)]\tLoss: 0.284783\n",
      "Train Epoch: 2 [3000/7953 (38%)]\tLoss: 0.332640\n",
      "Train Epoch: 2 [4000/7953 (50%)]\tLoss: 0.453752\n",
      "Train Epoch: 2 [5000/7953 (62%)]\tLoss: 0.424982\n",
      "Train Epoch: 2 [6000/7953 (75%)]\tLoss: 0.442080\n",
      "Train Epoch: 2 [7000/7953 (88%)]\tLoss: 0.436182\n",
      "Train Epoch: 3 [0/7953 (0%)]\tLoss: 0.332147\n",
      "Train Epoch: 3 [1000/7953 (12%)]\tLoss: 0.342750\n",
      "Train Epoch: 3 [2000/7953 (25%)]\tLoss: 0.276247\n",
      "Train Epoch: 3 [3000/7953 (38%)]\tLoss: 0.387430\n",
      "Train Epoch: 3 [4000/7953 (50%)]\tLoss: 0.352506\n",
      "Train Epoch: 3 [5000/7953 (62%)]\tLoss: 0.272618\n",
      "Train Epoch: 3 [6000/7953 (75%)]\tLoss: 0.294129\n",
      "Train Epoch: 3 [7000/7953 (88%)]\tLoss: 0.405732\n",
      "Train Epoch: 4 [0/7953 (0%)]\tLoss: 0.332354\n",
      "Train Epoch: 4 [1000/7953 (12%)]\tLoss: 0.444628\n",
      "Train Epoch: 4 [2000/7953 (25%)]\tLoss: 0.378083\n",
      "Train Epoch: 4 [3000/7953 (38%)]\tLoss: 0.334560\n",
      "Train Epoch: 4 [4000/7953 (50%)]\tLoss: 0.454339\n",
      "Train Epoch: 4 [5000/7953 (62%)]\tLoss: 0.278428\n",
      "Train Epoch: 4 [6000/7953 (75%)]\tLoss: 0.317521\n",
      "Train Epoch: 4 [7000/7953 (88%)]\tLoss: 0.347138\n",
      "Train Epoch: 5 [0/7953 (0%)]\tLoss: 0.372681\n",
      "Train Epoch: 5 [1000/7953 (12%)]\tLoss: 0.331130\n",
      "Train Epoch: 5 [2000/7953 (25%)]\tLoss: 0.290896\n",
      "Train Epoch: 5 [3000/7953 (38%)]\tLoss: 0.281674\n",
      "Train Epoch: 5 [4000/7953 (50%)]\tLoss: 0.339606\n",
      "Train Epoch: 5 [5000/7953 (62%)]\tLoss: 0.318359\n",
      "Train Epoch: 5 [6000/7953 (75%)]\tLoss: 0.216543\n",
      "Train Epoch: 5 [7000/7953 (88%)]\tLoss: 0.229634\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/10012 (0%)]\tLoss: 0.323606\n",
      "Train Epoch: 1 [1000/10012 (10%)]\tLoss: 0.174701\n",
      "Train Epoch: 1 [2000/10012 (20%)]\tLoss: 0.144384\n",
      "Train Epoch: 1 [3000/10012 (30%)]\tLoss: 0.343137\n",
      "Train Epoch: 1 [4000/10012 (40%)]\tLoss: 0.082148\n",
      "Train Epoch: 1 [5000/10012 (50%)]\tLoss: 0.176803\n",
      "Train Epoch: 1 [6000/10012 (59%)]\tLoss: 0.082963\n",
      "Train Epoch: 1 [7000/10012 (69%)]\tLoss: 0.188130\n",
      "Train Epoch: 1 [8000/10012 (79%)]\tLoss: 0.204708\n",
      "Train Epoch: 1 [9000/10012 (89%)]\tLoss: 0.132263\n",
      "Train Epoch: 1 [1200/10012 (99%)]\tLoss: 0.023260\n",
      "Train Epoch: 2 [0/10012 (0%)]\tLoss: 0.067034\n",
      "Train Epoch: 2 [1000/10012 (10%)]\tLoss: 0.108671\n",
      "Train Epoch: 2 [2000/10012 (20%)]\tLoss: 0.173003\n",
      "Train Epoch: 2 [3000/10012 (30%)]\tLoss: 0.154735\n",
      "Train Epoch: 2 [4000/10012 (40%)]\tLoss: 0.204152\n",
      "Train Epoch: 2 [5000/10012 (50%)]\tLoss: 0.132479\n",
      "Train Epoch: 2 [6000/10012 (59%)]\tLoss: 0.089898\n",
      "Train Epoch: 2 [7000/10012 (69%)]\tLoss: 0.138148\n",
      "Train Epoch: 2 [8000/10012 (79%)]\tLoss: 0.117614\n",
      "Train Epoch: 2 [9000/10012 (89%)]\tLoss: 0.082005\n",
      "Train Epoch: 2 [1200/10012 (99%)]\tLoss: 0.171926\n",
      "Train Epoch: 3 [0/10012 (0%)]\tLoss: 0.283961\n",
      "Train Epoch: 3 [1000/10012 (10%)]\tLoss: 0.152701\n",
      "Train Epoch: 3 [2000/10012 (20%)]\tLoss: 0.156302\n",
      "Train Epoch: 3 [3000/10012 (30%)]\tLoss: 0.199453\n",
      "Train Epoch: 3 [4000/10012 (40%)]\tLoss: 0.112398\n",
      "Train Epoch: 3 [5000/10012 (50%)]\tLoss: 0.110059\n",
      "Train Epoch: 3 [6000/10012 (59%)]\tLoss: 0.103739\n",
      "Train Epoch: 3 [7000/10012 (69%)]\tLoss: 0.041119\n",
      "Train Epoch: 3 [8000/10012 (79%)]\tLoss: 0.125967\n",
      "Train Epoch: 3 [9000/10012 (89%)]\tLoss: 0.118673\n",
      "Train Epoch: 3 [1200/10012 (99%)]\tLoss: 0.004277\n",
      "Train Epoch: 4 [0/10012 (0%)]\tLoss: 0.066868\n",
      "Train Epoch: 4 [1000/10012 (10%)]\tLoss: 0.120333\n",
      "Train Epoch: 4 [2000/10012 (20%)]\tLoss: 0.169613\n",
      "Train Epoch: 4 [3000/10012 (30%)]\tLoss: 0.120556\n",
      "Train Epoch: 4 [4000/10012 (40%)]\tLoss: 0.139531\n",
      "Train Epoch: 4 [5000/10012 (50%)]\tLoss: 0.065852\n",
      "Train Epoch: 4 [6000/10012 (59%)]\tLoss: 0.101323\n",
      "Train Epoch: 4 [7000/10012 (69%)]\tLoss: 0.058772\n",
      "Train Epoch: 4 [8000/10012 (79%)]\tLoss: 0.098235\n",
      "Train Epoch: 4 [9000/10012 (89%)]\tLoss: 0.136991\n",
      "Train Epoch: 4 [1200/10012 (99%)]\tLoss: 0.267997\n",
      "Train Epoch: 5 [0/10012 (0%)]\tLoss: 0.217256\n",
      "Train Epoch: 5 [1000/10012 (10%)]\tLoss: 0.106215\n",
      "Train Epoch: 5 [2000/10012 (20%)]\tLoss: 0.169052\n",
      "Train Epoch: 5 [3000/10012 (30%)]\tLoss: 0.191163\n",
      "Train Epoch: 5 [4000/10012 (40%)]\tLoss: 0.076013\n",
      "Train Epoch: 5 [5000/10012 (50%)]\tLoss: 0.060482\n",
      "Train Epoch: 5 [6000/10012 (59%)]\tLoss: 0.129268\n",
      "Train Epoch: 5 [7000/10012 (69%)]\tLoss: 0.106956\n",
      "Train Epoch: 5 [8000/10012 (79%)]\tLoss: 0.114827\n",
      "Train Epoch: 5 [9000/10012 (89%)]\tLoss: 0.100452\n",
      "Train Epoch: 5 [1200/10012 (99%)]\tLoss: 0.374738\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "8\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.3617, Accuracy: 8700/10000 (87%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/7731 (0%)]\tLoss: 0.188224\n",
      "Train Epoch: 1 [1000/7731 (13%)]\tLoss: 0.126989\n",
      "Train Epoch: 1 [2000/7731 (26%)]\tLoss: 0.181299\n",
      "Train Epoch: 1 [3000/7731 (38%)]\tLoss: 0.146772\n",
      "Train Epoch: 1 [4000/7731 (51%)]\tLoss: 0.147488\n",
      "Train Epoch: 1 [5000/7731 (64%)]\tLoss: 0.097964\n",
      "Train Epoch: 1 [6000/7731 (77%)]\tLoss: 0.104732\n",
      "Train Epoch: 1 [7000/7731 (90%)]\tLoss: 0.143068\n",
      "Train Epoch: 2 [0/7731 (0%)]\tLoss: 0.113360\n",
      "Train Epoch: 2 [1000/7731 (13%)]\tLoss: 0.133754\n",
      "Train Epoch: 2 [2000/7731 (26%)]\tLoss: 0.107929\n",
      "Train Epoch: 2 [3000/7731 (38%)]\tLoss: 0.098938\n",
      "Train Epoch: 2 [4000/7731 (51%)]\tLoss: 0.095534\n",
      "Train Epoch: 2 [5000/7731 (64%)]\tLoss: 0.101201\n",
      "Train Epoch: 2 [6000/7731 (77%)]\tLoss: 0.141607\n",
      "Train Epoch: 2 [7000/7731 (90%)]\tLoss: 0.226910\n",
      "Train Epoch: 3 [0/7731 (0%)]\tLoss: 0.255810\n",
      "Train Epoch: 3 [1000/7731 (13%)]\tLoss: 0.093362\n",
      "Train Epoch: 3 [2000/7731 (26%)]\tLoss: 0.109531\n",
      "Train Epoch: 3 [3000/7731 (38%)]\tLoss: 0.244262\n",
      "Train Epoch: 3 [4000/7731 (51%)]\tLoss: 0.064165\n",
      "Train Epoch: 3 [5000/7731 (64%)]\tLoss: 0.163573\n",
      "Train Epoch: 3 [6000/7731 (77%)]\tLoss: 0.117159\n",
      "Train Epoch: 3 [7000/7731 (90%)]\tLoss: 0.181120\n",
      "Train Epoch: 4 [0/7731 (0%)]\tLoss: 0.101552\n",
      "Train Epoch: 4 [1000/7731 (13%)]\tLoss: 0.233614\n",
      "Train Epoch: 4 [2000/7731 (26%)]\tLoss: 0.125434\n",
      "Train Epoch: 4 [3000/7731 (38%)]\tLoss: 0.120752\n",
      "Train Epoch: 4 [4000/7731 (51%)]\tLoss: 0.125973\n",
      "Train Epoch: 4 [5000/7731 (64%)]\tLoss: 0.112095\n",
      "Train Epoch: 4 [6000/7731 (77%)]\tLoss: 0.159483\n",
      "Train Epoch: 4 [7000/7731 (90%)]\tLoss: 0.108051\n",
      "Train Epoch: 5 [0/7731 (0%)]\tLoss: 0.169516\n",
      "Train Epoch: 5 [1000/7731 (13%)]\tLoss: 0.155205\n",
      "Train Epoch: 5 [2000/7731 (26%)]\tLoss: 0.111596\n",
      "Train Epoch: 5 [3000/7731 (38%)]\tLoss: 0.133773\n",
      "Train Epoch: 5 [4000/7731 (51%)]\tLoss: 0.074662\n",
      "Train Epoch: 5 [5000/7731 (64%)]\tLoss: 0.119373\n",
      "Train Epoch: 5 [6000/7731 (77%)]\tLoss: 0.231445\n",
      "Train Epoch: 5 [7000/7731 (90%)]\tLoss: 0.089487\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11194 (0%)]\tLoss: 0.267890\n",
      "Train Epoch: 1 [1000/11194 (9%)]\tLoss: 0.144752\n",
      "Train Epoch: 1 [2000/11194 (18%)]\tLoss: 0.187805\n",
      "Train Epoch: 1 [3000/11194 (27%)]\tLoss: 0.111723\n",
      "Train Epoch: 1 [4000/11194 (36%)]\tLoss: 0.155121\n",
      "Train Epoch: 1 [5000/11194 (45%)]\tLoss: 0.184730\n",
      "Train Epoch: 1 [6000/11194 (54%)]\tLoss: 0.214747\n",
      "Train Epoch: 1 [7000/11194 (62%)]\tLoss: 0.138533\n",
      "Train Epoch: 1 [8000/11194 (71%)]\tLoss: 0.222536\n",
      "Train Epoch: 1 [9000/11194 (80%)]\tLoss: 0.180709\n",
      "Train Epoch: 1 [10000/11194 (89%)]\tLoss: 0.148002\n",
      "Train Epoch: 1 [11000/11194 (98%)]\tLoss: 0.207447\n",
      "Train Epoch: 2 [0/11194 (0%)]\tLoss: 0.134472\n",
      "Train Epoch: 2 [1000/11194 (9%)]\tLoss: 0.236284\n",
      "Train Epoch: 2 [2000/11194 (18%)]\tLoss: 0.164461\n",
      "Train Epoch: 2 [3000/11194 (27%)]\tLoss: 0.112593\n",
      "Train Epoch: 2 [4000/11194 (36%)]\tLoss: 0.128287\n",
      "Train Epoch: 2 [5000/11194 (45%)]\tLoss: 0.093368\n",
      "Train Epoch: 2 [6000/11194 (54%)]\tLoss: 0.096499\n",
      "Train Epoch: 2 [7000/11194 (62%)]\tLoss: 0.122908\n",
      "Train Epoch: 2 [8000/11194 (71%)]\tLoss: 0.169221\n",
      "Train Epoch: 2 [9000/11194 (80%)]\tLoss: 0.279625\n",
      "Train Epoch: 2 [10000/11194 (89%)]\tLoss: 0.167355\n",
      "Train Epoch: 2 [11000/11194 (98%)]\tLoss: 0.151239\n",
      "Train Epoch: 3 [0/11194 (0%)]\tLoss: 0.182906\n",
      "Train Epoch: 3 [1000/11194 (9%)]\tLoss: 0.143761\n",
      "Train Epoch: 3 [2000/11194 (18%)]\tLoss: 0.196269\n",
      "Train Epoch: 3 [3000/11194 (27%)]\tLoss: 0.180731\n",
      "Train Epoch: 3 [4000/11194 (36%)]\tLoss: 0.151967\n",
      "Train Epoch: 3 [5000/11194 (45%)]\tLoss: 0.213842\n",
      "Train Epoch: 3 [6000/11194 (54%)]\tLoss: 0.203863\n",
      "Train Epoch: 3 [7000/11194 (62%)]\tLoss: 0.165294\n",
      "Train Epoch: 3 [8000/11194 (71%)]\tLoss: 0.268198\n",
      "Train Epoch: 3 [9000/11194 (80%)]\tLoss: 0.117491\n",
      "Train Epoch: 3 [10000/11194 (89%)]\tLoss: 0.142278\n",
      "Train Epoch: 3 [11000/11194 (98%)]\tLoss: 0.098932\n",
      "Train Epoch: 4 [0/11194 (0%)]\tLoss: 0.146206\n",
      "Train Epoch: 4 [1000/11194 (9%)]\tLoss: 0.100025\n",
      "Train Epoch: 4 [2000/11194 (18%)]\tLoss: 0.139050\n",
      "Train Epoch: 4 [3000/11194 (27%)]\tLoss: 0.124032\n",
      "Train Epoch: 4 [4000/11194 (36%)]\tLoss: 0.144187\n",
      "Train Epoch: 4 [5000/11194 (45%)]\tLoss: 0.079115\n",
      "Train Epoch: 4 [6000/11194 (54%)]\tLoss: 0.212332\n",
      "Train Epoch: 4 [7000/11194 (62%)]\tLoss: 0.127306\n",
      "Train Epoch: 4 [8000/11194 (71%)]\tLoss: 0.168087\n",
      "Train Epoch: 4 [9000/11194 (80%)]\tLoss: 0.126404\n",
      "Train Epoch: 4 [10000/11194 (89%)]\tLoss: 0.145945\n",
      "Train Epoch: 4 [11000/11194 (98%)]\tLoss: 0.189638\n",
      "Train Epoch: 5 [0/11194 (0%)]\tLoss: 0.074840\n",
      "Train Epoch: 5 [1000/11194 (9%)]\tLoss: 0.129756\n",
      "Train Epoch: 5 [2000/11194 (18%)]\tLoss: 0.095554\n",
      "Train Epoch: 5 [3000/11194 (27%)]\tLoss: 0.155902\n",
      "Train Epoch: 5 [4000/11194 (36%)]\tLoss: 0.110127\n",
      "Train Epoch: 5 [5000/11194 (45%)]\tLoss: 0.089028\n",
      "Train Epoch: 5 [6000/11194 (54%)]\tLoss: 0.188437\n",
      "Train Epoch: 5 [7000/11194 (62%)]\tLoss: 0.164444\n",
      "Train Epoch: 5 [8000/11194 (71%)]\tLoss: 0.109665\n",
      "Train Epoch: 5 [9000/11194 (80%)]\tLoss: 0.127326\n",
      "Train Epoch: 5 [10000/11194 (89%)]\tLoss: 0.118392\n",
      "Train Epoch: 5 [11000/11194 (98%)]\tLoss: 0.118060\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/7891 (0%)]\tLoss: 0.256978\n",
      "Train Epoch: 1 [1000/7891 (13%)]\tLoss: 0.139074\n",
      "Train Epoch: 1 [2000/7891 (25%)]\tLoss: 0.116531\n",
      "Train Epoch: 1 [3000/7891 (38%)]\tLoss: 0.212626\n",
      "Train Epoch: 1 [4000/7891 (51%)]\tLoss: 0.072314\n",
      "Train Epoch: 1 [5000/7891 (63%)]\tLoss: 0.165356\n",
      "Train Epoch: 1 [6000/7891 (76%)]\tLoss: 0.149745\n",
      "Train Epoch: 1 [7000/7891 (89%)]\tLoss: 0.094479\n",
      "Train Epoch: 2 [0/7891 (0%)]\tLoss: 0.094734\n",
      "Train Epoch: 2 [1000/7891 (13%)]\tLoss: 0.163330\n",
      "Train Epoch: 2 [2000/7891 (25%)]\tLoss: 0.164555\n",
      "Train Epoch: 2 [3000/7891 (38%)]\tLoss: 0.088076\n",
      "Train Epoch: 2 [4000/7891 (51%)]\tLoss: 0.208370\n",
      "Train Epoch: 2 [5000/7891 (63%)]\tLoss: 0.154474\n",
      "Train Epoch: 2 [6000/7891 (76%)]\tLoss: 0.075446\n",
      "Train Epoch: 2 [7000/7891 (89%)]\tLoss: 0.229933\n",
      "Train Epoch: 3 [0/7891 (0%)]\tLoss: 0.086125\n",
      "Train Epoch: 3 [1000/7891 (13%)]\tLoss: 0.142613\n",
      "Train Epoch: 3 [2000/7891 (25%)]\tLoss: 0.068375\n",
      "Train Epoch: 3 [3000/7891 (38%)]\tLoss: 0.084243\n",
      "Train Epoch: 3 [4000/7891 (51%)]\tLoss: 0.159994\n",
      "Train Epoch: 3 [5000/7891 (63%)]\tLoss: 0.143927\n",
      "Train Epoch: 3 [6000/7891 (76%)]\tLoss: 0.142292\n",
      "Train Epoch: 3 [7000/7891 (89%)]\tLoss: 0.146122\n",
      "Train Epoch: 4 [0/7891 (0%)]\tLoss: 0.120233\n",
      "Train Epoch: 4 [1000/7891 (13%)]\tLoss: 0.201564\n",
      "Train Epoch: 4 [2000/7891 (25%)]\tLoss: 0.132698\n",
      "Train Epoch: 4 [3000/7891 (38%)]\tLoss: 0.124688\n",
      "Train Epoch: 4 [4000/7891 (51%)]\tLoss: 0.077770\n",
      "Train Epoch: 4 [5000/7891 (63%)]\tLoss: 0.133849\n",
      "Train Epoch: 4 [6000/7891 (76%)]\tLoss: 0.052825\n",
      "Train Epoch: 4 [7000/7891 (89%)]\tLoss: 0.155268\n",
      "Train Epoch: 5 [0/7891 (0%)]\tLoss: 0.091954\n",
      "Train Epoch: 5 [1000/7891 (13%)]\tLoss: 0.115526\n",
      "Train Epoch: 5 [2000/7891 (25%)]\tLoss: 0.209408\n",
      "Train Epoch: 5 [3000/7891 (38%)]\tLoss: 0.158938\n",
      "Train Epoch: 5 [4000/7891 (51%)]\tLoss: 0.078273\n",
      "Train Epoch: 5 [5000/7891 (63%)]\tLoss: 0.093467\n",
      "Train Epoch: 5 [6000/7891 (76%)]\tLoss: 0.089774\n",
      "Train Epoch: 5 [7000/7891 (89%)]\tLoss: 0.144155\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/3053 (0%)]\tLoss: 0.238843\n",
      "Train Epoch: 1 [1000/3053 (32%)]\tLoss: 0.176305\n",
      "Train Epoch: 1 [2000/3053 (65%)]\tLoss: 0.115985\n",
      "Train Epoch: 1 [1590/3053 (97%)]\tLoss: 0.123948\n",
      "Train Epoch: 2 [0/3053 (0%)]\tLoss: 0.174578\n",
      "Train Epoch: 2 [1000/3053 (32%)]\tLoss: 0.077294\n",
      "Train Epoch: 2 [2000/3053 (65%)]\tLoss: 0.071908\n",
      "Train Epoch: 2 [1590/3053 (97%)]\tLoss: 0.109520\n",
      "Train Epoch: 3 [0/3053 (0%)]\tLoss: 0.101161\n",
      "Train Epoch: 3 [1000/3053 (32%)]\tLoss: 0.063991\n",
      "Train Epoch: 3 [2000/3053 (65%)]\tLoss: 0.107103\n",
      "Train Epoch: 3 [1590/3053 (97%)]\tLoss: 0.103146\n",
      "Train Epoch: 4 [0/3053 (0%)]\tLoss: 0.107410\n",
      "Train Epoch: 4 [1000/3053 (32%)]\tLoss: 0.107226\n",
      "Train Epoch: 4 [2000/3053 (65%)]\tLoss: 0.140697\n",
      "Train Epoch: 4 [1590/3053 (97%)]\tLoss: 0.037936\n",
      "Train Epoch: 5 [0/3053 (0%)]\tLoss: 0.061653\n",
      "Train Epoch: 5 [1000/3053 (32%)]\tLoss: 0.158996\n",
      "Train Epoch: 5 [2000/3053 (65%)]\tLoss: 0.112982\n",
      "Train Epoch: 5 [1590/3053 (97%)]\tLoss: 0.091725\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/9145 (0%)]\tLoss: 0.150036\n",
      "Train Epoch: 1 [1000/9145 (11%)]\tLoss: 0.189498\n",
      "Train Epoch: 1 [2000/9145 (22%)]\tLoss: 0.249191\n",
      "Train Epoch: 1 [3000/9145 (33%)]\tLoss: 0.229178\n",
      "Train Epoch: 1 [4000/9145 (43%)]\tLoss: 0.153905\n",
      "Train Epoch: 1 [5000/9145 (54%)]\tLoss: 0.271675\n",
      "Train Epoch: 1 [6000/9145 (65%)]\tLoss: 0.277579\n",
      "Train Epoch: 1 [7000/9145 (76%)]\tLoss: 0.193869\n",
      "Train Epoch: 1 [8000/9145 (87%)]\tLoss: 0.167863\n",
      "Train Epoch: 1 [9000/9145 (98%)]\tLoss: 0.335288\n",
      "Train Epoch: 2 [0/9145 (0%)]\tLoss: 0.258413\n",
      "Train Epoch: 2 [1000/9145 (11%)]\tLoss: 0.142956\n",
      "Train Epoch: 2 [2000/9145 (22%)]\tLoss: 0.202992\n",
      "Train Epoch: 2 [3000/9145 (33%)]\tLoss: 0.292341\n",
      "Train Epoch: 2 [4000/9145 (43%)]\tLoss: 0.266903\n",
      "Train Epoch: 2 [5000/9145 (54%)]\tLoss: 0.168328\n",
      "Train Epoch: 2 [6000/9145 (65%)]\tLoss: 0.196795\n",
      "Train Epoch: 2 [7000/9145 (76%)]\tLoss: 0.225141\n",
      "Train Epoch: 2 [8000/9145 (87%)]\tLoss: 0.326895\n",
      "Train Epoch: 2 [9000/9145 (98%)]\tLoss: 0.180682\n",
      "Train Epoch: 3 [0/9145 (0%)]\tLoss: 0.201540\n",
      "Train Epoch: 3 [1000/9145 (11%)]\tLoss: 0.237366\n",
      "Train Epoch: 3 [2000/9145 (22%)]\tLoss: 0.141964\n",
      "Train Epoch: 3 [3000/9145 (33%)]\tLoss: 0.211784\n",
      "Train Epoch: 3 [4000/9145 (43%)]\tLoss: 0.197499\n",
      "Train Epoch: 3 [5000/9145 (54%)]\tLoss: 0.264552\n",
      "Train Epoch: 3 [6000/9145 (65%)]\tLoss: 0.341520\n",
      "Train Epoch: 3 [7000/9145 (76%)]\tLoss: 0.269096\n",
      "Train Epoch: 3 [8000/9145 (87%)]\tLoss: 0.327008\n",
      "Train Epoch: 3 [9000/9145 (98%)]\tLoss: 0.221488\n",
      "Train Epoch: 4 [0/9145 (0%)]\tLoss: 0.266681\n",
      "Train Epoch: 4 [1000/9145 (11%)]\tLoss: 0.122478\n",
      "Train Epoch: 4 [2000/9145 (22%)]\tLoss: 0.209430\n",
      "Train Epoch: 4 [3000/9145 (33%)]\tLoss: 0.201516\n",
      "Train Epoch: 4 [4000/9145 (43%)]\tLoss: 0.273828\n",
      "Train Epoch: 4 [5000/9145 (54%)]\tLoss: 0.296604\n",
      "Train Epoch: 4 [6000/9145 (65%)]\tLoss: 0.219492\n",
      "Train Epoch: 4 [7000/9145 (76%)]\tLoss: 0.234018\n",
      "Train Epoch: 4 [8000/9145 (87%)]\tLoss: 0.197672\n",
      "Train Epoch: 4 [9000/9145 (98%)]\tLoss: 0.189847\n",
      "Train Epoch: 5 [0/9145 (0%)]\tLoss: 0.277397\n",
      "Train Epoch: 5 [1000/9145 (11%)]\tLoss: 0.129530\n",
      "Train Epoch: 5 [2000/9145 (22%)]\tLoss: 0.160572\n",
      "Train Epoch: 5 [3000/9145 (33%)]\tLoss: 0.130672\n",
      "Train Epoch: 5 [4000/9145 (43%)]\tLoss: 0.163991\n",
      "Train Epoch: 5 [5000/9145 (54%)]\tLoss: 0.142046\n",
      "Train Epoch: 5 [6000/9145 (65%)]\tLoss: 0.163212\n",
      "Train Epoch: 5 [7000/9145 (76%)]\tLoss: 0.125324\n",
      "Train Epoch: 5 [8000/9145 (87%)]\tLoss: 0.203466\n",
      "Train Epoch: 5 [9000/9145 (98%)]\tLoss: 0.307519\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3021 (0%)]\tLoss: 0.291687\n",
      "Train Epoch: 1 [1000/3021 (32%)]\tLoss: 0.173209\n",
      "Train Epoch: 1 [2000/3021 (65%)]\tLoss: 0.203022\n",
      "Train Epoch: 1 [630/3021 (97%)]\tLoss: 0.191445\n",
      "Train Epoch: 2 [0/3021 (0%)]\tLoss: 0.164469\n",
      "Train Epoch: 2 [1000/3021 (32%)]\tLoss: 0.239934\n",
      "Train Epoch: 2 [2000/3021 (65%)]\tLoss: 0.244346\n",
      "Train Epoch: 2 [630/3021 (97%)]\tLoss: 0.091322\n",
      "Train Epoch: 3 [0/3021 (0%)]\tLoss: 0.182769\n",
      "Train Epoch: 3 [1000/3021 (32%)]\tLoss: 0.191371\n",
      "Train Epoch: 3 [2000/3021 (65%)]\tLoss: 0.141902\n",
      "Train Epoch: 3 [630/3021 (97%)]\tLoss: 0.209875\n",
      "Train Epoch: 4 [0/3021 (0%)]\tLoss: 0.170940\n",
      "Train Epoch: 4 [1000/3021 (32%)]\tLoss: 0.156908\n",
      "Train Epoch: 4 [2000/3021 (65%)]\tLoss: 0.109960\n",
      "Train Epoch: 4 [630/3021 (97%)]\tLoss: 0.034346\n",
      "Train Epoch: 5 [0/3021 (0%)]\tLoss: 0.183624\n",
      "Train Epoch: 5 [1000/3021 (32%)]\tLoss: 0.124323\n",
      "Train Epoch: 5 [2000/3021 (65%)]\tLoss: 0.154523\n",
      "Train Epoch: 5 [630/3021 (97%)]\tLoss: 0.130189\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/7953 (0%)]\tLoss: 0.348745\n",
      "Train Epoch: 1 [1000/7953 (12%)]\tLoss: 0.362624\n",
      "Train Epoch: 1 [2000/7953 (25%)]\tLoss: 0.378231\n",
      "Train Epoch: 1 [3000/7953 (38%)]\tLoss: 0.330436\n",
      "Train Epoch: 1 [4000/7953 (50%)]\tLoss: 0.497103\n",
      "Train Epoch: 1 [5000/7953 (62%)]\tLoss: 0.323170\n",
      "Train Epoch: 1 [6000/7953 (75%)]\tLoss: 0.400007\n",
      "Train Epoch: 1 [7000/7953 (88%)]\tLoss: 0.306101\n",
      "Train Epoch: 2 [0/7953 (0%)]\tLoss: 0.346730\n",
      "Train Epoch: 2 [1000/7953 (12%)]\tLoss: 0.228687\n",
      "Train Epoch: 2 [2000/7953 (25%)]\tLoss: 0.315125\n",
      "Train Epoch: 2 [3000/7953 (38%)]\tLoss: 0.364297\n",
      "Train Epoch: 2 [4000/7953 (50%)]\tLoss: 0.251779\n",
      "Train Epoch: 2 [5000/7953 (62%)]\tLoss: 0.363495\n",
      "Train Epoch: 2 [6000/7953 (75%)]\tLoss: 0.331217\n",
      "Train Epoch: 2 [7000/7953 (88%)]\tLoss: 0.351432\n",
      "Train Epoch: 3 [0/7953 (0%)]\tLoss: 0.418994\n",
      "Train Epoch: 3 [1000/7953 (12%)]\tLoss: 0.409097\n",
      "Train Epoch: 3 [2000/7953 (25%)]\tLoss: 0.488995\n",
      "Train Epoch: 3 [3000/7953 (38%)]\tLoss: 0.331097\n",
      "Train Epoch: 3 [4000/7953 (50%)]\tLoss: 0.516285\n",
      "Train Epoch: 3 [5000/7953 (62%)]\tLoss: 0.547086\n",
      "Train Epoch: 3 [6000/7953 (75%)]\tLoss: 0.247380\n",
      "Train Epoch: 3 [7000/7953 (88%)]\tLoss: 0.339798\n",
      "Train Epoch: 4 [0/7953 (0%)]\tLoss: 0.295639\n",
      "Train Epoch: 4 [1000/7953 (12%)]\tLoss: 0.379949\n",
      "Train Epoch: 4 [2000/7953 (25%)]\tLoss: 0.376402\n",
      "Train Epoch: 4 [3000/7953 (38%)]\tLoss: 0.311559\n",
      "Train Epoch: 4 [4000/7953 (50%)]\tLoss: 0.286491\n",
      "Train Epoch: 4 [5000/7953 (62%)]\tLoss: 0.410225\n",
      "Train Epoch: 4 [6000/7953 (75%)]\tLoss: 0.272626\n",
      "Train Epoch: 4 [7000/7953 (88%)]\tLoss: 0.286663\n",
      "Train Epoch: 5 [0/7953 (0%)]\tLoss: 0.247115\n",
      "Train Epoch: 5 [1000/7953 (12%)]\tLoss: 0.289232\n",
      "Train Epoch: 5 [2000/7953 (25%)]\tLoss: 0.304576\n",
      "Train Epoch: 5 [3000/7953 (38%)]\tLoss: 0.390142\n",
      "Train Epoch: 5 [4000/7953 (50%)]\tLoss: 0.434095\n",
      "Train Epoch: 5 [5000/7953 (62%)]\tLoss: 0.309309\n",
      "Train Epoch: 5 [6000/7953 (75%)]\tLoss: 0.337043\n",
      "Train Epoch: 5 [7000/7953 (88%)]\tLoss: 0.461898\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/10012 (0%)]\tLoss: 0.280077\n",
      "Train Epoch: 1 [1000/10012 (10%)]\tLoss: 0.278787\n",
      "Train Epoch: 1 [2000/10012 (20%)]\tLoss: 0.118666\n",
      "Train Epoch: 1 [3000/10012 (30%)]\tLoss: 0.123783\n",
      "Train Epoch: 1 [4000/10012 (40%)]\tLoss: 0.137317\n",
      "Train Epoch: 1 [5000/10012 (50%)]\tLoss: 0.192271\n",
      "Train Epoch: 1 [6000/10012 (59%)]\tLoss: 0.129570\n",
      "Train Epoch: 1 [7000/10012 (69%)]\tLoss: 0.185755\n",
      "Train Epoch: 1 [8000/10012 (79%)]\tLoss: 0.078270\n",
      "Train Epoch: 1 [9000/10012 (89%)]\tLoss: 0.141072\n",
      "Train Epoch: 1 [1200/10012 (99%)]\tLoss: 0.003224\n",
      "Train Epoch: 2 [0/10012 (0%)]\tLoss: 0.106627\n",
      "Train Epoch: 2 [1000/10012 (10%)]\tLoss: 0.150094\n",
      "Train Epoch: 2 [2000/10012 (20%)]\tLoss: 0.153399\n",
      "Train Epoch: 2 [3000/10012 (30%)]\tLoss: 0.097830\n",
      "Train Epoch: 2 [4000/10012 (40%)]\tLoss: 0.108668\n",
      "Train Epoch: 2 [5000/10012 (50%)]\tLoss: 0.077493\n",
      "Train Epoch: 2 [6000/10012 (59%)]\tLoss: 0.174953\n",
      "Train Epoch: 2 [7000/10012 (69%)]\tLoss: 0.199047\n",
      "Train Epoch: 2 [8000/10012 (79%)]\tLoss: 0.082214\n",
      "Train Epoch: 2 [9000/10012 (89%)]\tLoss: 0.046992\n",
      "Train Epoch: 2 [1200/10012 (99%)]\tLoss: 0.024825\n",
      "Train Epoch: 3 [0/10012 (0%)]\tLoss: 0.160397\n",
      "Train Epoch: 3 [1000/10012 (10%)]\tLoss: 0.202013\n",
      "Train Epoch: 3 [2000/10012 (20%)]\tLoss: 0.123558\n",
      "Train Epoch: 3 [3000/10012 (30%)]\tLoss: 0.079109\n",
      "Train Epoch: 3 [4000/10012 (40%)]\tLoss: 0.172013\n",
      "Train Epoch: 3 [5000/10012 (50%)]\tLoss: 0.076805\n",
      "Train Epoch: 3 [6000/10012 (59%)]\tLoss: 0.240283\n",
      "Train Epoch: 3 [7000/10012 (69%)]\tLoss: 0.105715\n",
      "Train Epoch: 3 [8000/10012 (79%)]\tLoss: 0.117019\n",
      "Train Epoch: 3 [9000/10012 (89%)]\tLoss: 0.185703\n",
      "Train Epoch: 3 [1200/10012 (99%)]\tLoss: 0.300175\n",
      "Train Epoch: 4 [0/10012 (0%)]\tLoss: 0.155616\n",
      "Train Epoch: 4 [1000/10012 (10%)]\tLoss: 0.227451\n",
      "Train Epoch: 4 [2000/10012 (20%)]\tLoss: 0.201445\n",
      "Train Epoch: 4 [3000/10012 (30%)]\tLoss: 0.073763\n",
      "Train Epoch: 4 [4000/10012 (40%)]\tLoss: 0.282857\n",
      "Train Epoch: 4 [5000/10012 (50%)]\tLoss: 0.108777\n",
      "Train Epoch: 4 [6000/10012 (59%)]\tLoss: 0.181895\n",
      "Train Epoch: 4 [7000/10012 (69%)]\tLoss: 0.127567\n",
      "Train Epoch: 4 [8000/10012 (79%)]\tLoss: 0.081984\n",
      "Train Epoch: 4 [9000/10012 (89%)]\tLoss: 0.220568\n",
      "Train Epoch: 4 [1200/10012 (99%)]\tLoss: 0.253952\n",
      "Train Epoch: 5 [0/10012 (0%)]\tLoss: 0.145924\n",
      "Train Epoch: 5 [1000/10012 (10%)]\tLoss: 0.164064\n",
      "Train Epoch: 5 [2000/10012 (20%)]\tLoss: 0.035897\n",
      "Train Epoch: 5 [3000/10012 (30%)]\tLoss: 0.129426\n",
      "Train Epoch: 5 [4000/10012 (40%)]\tLoss: 0.103324\n",
      "Train Epoch: 5 [5000/10012 (50%)]\tLoss: 0.061696\n",
      "Train Epoch: 5 [6000/10012 (59%)]\tLoss: 0.216141\n",
      "Train Epoch: 5 [7000/10012 (69%)]\tLoss: 0.108135\n",
      "Train Epoch: 5 [8000/10012 (79%)]\tLoss: 0.086403\n",
      "Train Epoch: 5 [9000/10012 (89%)]\tLoss: 0.071656\n",
      "Train Epoch: 5 [1200/10012 (99%)]\tLoss: 0.426989\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "8\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.3649, Accuracy: 8704/10000 (87%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/7731 (0%)]\tLoss: 0.151116\n",
      "Train Epoch: 1 [1000/7731 (13%)]\tLoss: 0.130212\n",
      "Train Epoch: 1 [2000/7731 (26%)]\tLoss: 0.095850\n",
      "Train Epoch: 1 [3000/7731 (38%)]\tLoss: 0.157233\n",
      "Train Epoch: 1 [4000/7731 (51%)]\tLoss: 0.090614\n",
      "Train Epoch: 1 [5000/7731 (64%)]\tLoss: 0.129455\n",
      "Train Epoch: 1 [6000/7731 (77%)]\tLoss: 0.185016\n",
      "Train Epoch: 1 [7000/7731 (90%)]\tLoss: 0.172444\n",
      "Train Epoch: 2 [0/7731 (0%)]\tLoss: 0.105151\n",
      "Train Epoch: 2 [1000/7731 (13%)]\tLoss: 0.080646\n",
      "Train Epoch: 2 [2000/7731 (26%)]\tLoss: 0.099826\n",
      "Train Epoch: 2 [3000/7731 (38%)]\tLoss: 0.229495\n",
      "Train Epoch: 2 [4000/7731 (51%)]\tLoss: 0.101721\n",
      "Train Epoch: 2 [5000/7731 (64%)]\tLoss: 0.072247\n",
      "Train Epoch: 2 [6000/7731 (77%)]\tLoss: 0.150942\n",
      "Train Epoch: 2 [7000/7731 (90%)]\tLoss: 0.153960\n",
      "Train Epoch: 3 [0/7731 (0%)]\tLoss: 0.128708\n",
      "Train Epoch: 3 [1000/7731 (13%)]\tLoss: 0.107469\n",
      "Train Epoch: 3 [2000/7731 (26%)]\tLoss: 0.064906\n",
      "Train Epoch: 3 [3000/7731 (38%)]\tLoss: 0.110500\n",
      "Train Epoch: 3 [4000/7731 (51%)]\tLoss: 0.286094\n",
      "Train Epoch: 3 [5000/7731 (64%)]\tLoss: 0.143422\n",
      "Train Epoch: 3 [6000/7731 (77%)]\tLoss: 0.117808\n",
      "Train Epoch: 3 [7000/7731 (90%)]\tLoss: 0.126176\n",
      "Train Epoch: 4 [0/7731 (0%)]\tLoss: 0.115175\n",
      "Train Epoch: 4 [1000/7731 (13%)]\tLoss: 0.093515\n",
      "Train Epoch: 4 [2000/7731 (26%)]\tLoss: 0.101191\n",
      "Train Epoch: 4 [3000/7731 (38%)]\tLoss: 0.089939\n",
      "Train Epoch: 4 [4000/7731 (51%)]\tLoss: 0.063127\n",
      "Train Epoch: 4 [5000/7731 (64%)]\tLoss: 0.067269\n",
      "Train Epoch: 4 [6000/7731 (77%)]\tLoss: 0.107506\n",
      "Train Epoch: 4 [7000/7731 (90%)]\tLoss: 0.083134\n",
      "Train Epoch: 5 [0/7731 (0%)]\tLoss: 0.068689\n",
      "Train Epoch: 5 [1000/7731 (13%)]\tLoss: 0.086144\n",
      "Train Epoch: 5 [2000/7731 (26%)]\tLoss: 0.080312\n",
      "Train Epoch: 5 [3000/7731 (38%)]\tLoss: 0.059140\n",
      "Train Epoch: 5 [4000/7731 (51%)]\tLoss: 0.113256\n",
      "Train Epoch: 5 [5000/7731 (64%)]\tLoss: 0.073335\n",
      "Train Epoch: 5 [6000/7731 (77%)]\tLoss: 0.190221\n",
      "Train Epoch: 5 [7000/7731 (90%)]\tLoss: 0.066327\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11194 (0%)]\tLoss: 0.326844\n",
      "Train Epoch: 1 [1000/11194 (9%)]\tLoss: 0.144523\n",
      "Train Epoch: 1 [2000/11194 (18%)]\tLoss: 0.177496\n",
      "Train Epoch: 1 [3000/11194 (27%)]\tLoss: 0.130611\n",
      "Train Epoch: 1 [4000/11194 (36%)]\tLoss: 0.152271\n",
      "Train Epoch: 1 [5000/11194 (45%)]\tLoss: 0.218360\n",
      "Train Epoch: 1 [6000/11194 (54%)]\tLoss: 0.159846\n",
      "Train Epoch: 1 [7000/11194 (62%)]\tLoss: 0.160050\n",
      "Train Epoch: 1 [8000/11194 (71%)]\tLoss: 0.196817\n",
      "Train Epoch: 1 [9000/11194 (80%)]\tLoss: 0.066044\n",
      "Train Epoch: 1 [10000/11194 (89%)]\tLoss: 0.126817\n",
      "Train Epoch: 1 [11000/11194 (98%)]\tLoss: 0.213337\n",
      "Train Epoch: 2 [0/11194 (0%)]\tLoss: 0.164095\n",
      "Train Epoch: 2 [1000/11194 (9%)]\tLoss: 0.209498\n",
      "Train Epoch: 2 [2000/11194 (18%)]\tLoss: 0.152035\n",
      "Train Epoch: 2 [3000/11194 (27%)]\tLoss: 0.239109\n",
      "Train Epoch: 2 [4000/11194 (36%)]\tLoss: 0.194191\n",
      "Train Epoch: 2 [5000/11194 (45%)]\tLoss: 0.223937\n",
      "Train Epoch: 2 [6000/11194 (54%)]\tLoss: 0.096261\n",
      "Train Epoch: 2 [7000/11194 (62%)]\tLoss: 0.121506\n",
      "Train Epoch: 2 [8000/11194 (71%)]\tLoss: 0.096559\n",
      "Train Epoch: 2 [9000/11194 (80%)]\tLoss: 0.202741\n",
      "Train Epoch: 2 [10000/11194 (89%)]\tLoss: 0.221542\n",
      "Train Epoch: 2 [11000/11194 (98%)]\tLoss: 0.207610\n",
      "Train Epoch: 3 [0/11194 (0%)]\tLoss: 0.078757\n",
      "Train Epoch: 3 [1000/11194 (9%)]\tLoss: 0.123605\n",
      "Train Epoch: 3 [2000/11194 (18%)]\tLoss: 0.088241\n",
      "Train Epoch: 3 [3000/11194 (27%)]\tLoss: 0.135488\n",
      "Train Epoch: 3 [4000/11194 (36%)]\tLoss: 0.152680\n",
      "Train Epoch: 3 [5000/11194 (45%)]\tLoss: 0.237351\n",
      "Train Epoch: 3 [6000/11194 (54%)]\tLoss: 0.096129\n",
      "Train Epoch: 3 [7000/11194 (62%)]\tLoss: 0.192198\n",
      "Train Epoch: 3 [8000/11194 (71%)]\tLoss: 0.138290\n",
      "Train Epoch: 3 [9000/11194 (80%)]\tLoss: 0.137504\n",
      "Train Epoch: 3 [10000/11194 (89%)]\tLoss: 0.138602\n",
      "Train Epoch: 3 [11000/11194 (98%)]\tLoss: 0.108560\n",
      "Train Epoch: 4 [0/11194 (0%)]\tLoss: 0.120876\n",
      "Train Epoch: 4 [1000/11194 (9%)]\tLoss: 0.126214\n",
      "Train Epoch: 4 [2000/11194 (18%)]\tLoss: 0.155817\n",
      "Train Epoch: 4 [3000/11194 (27%)]\tLoss: 0.108462\n",
      "Train Epoch: 4 [4000/11194 (36%)]\tLoss: 0.102900\n",
      "Train Epoch: 4 [5000/11194 (45%)]\tLoss: 0.182249\n",
      "Train Epoch: 4 [6000/11194 (54%)]\tLoss: 0.111919\n",
      "Train Epoch: 4 [7000/11194 (62%)]\tLoss: 0.132795\n",
      "Train Epoch: 4 [8000/11194 (71%)]\tLoss: 0.102192\n",
      "Train Epoch: 4 [9000/11194 (80%)]\tLoss: 0.150102\n",
      "Train Epoch: 4 [10000/11194 (89%)]\tLoss: 0.194144\n",
      "Train Epoch: 4 [11000/11194 (98%)]\tLoss: 0.096885\n",
      "Train Epoch: 5 [0/11194 (0%)]\tLoss: 0.098363\n",
      "Train Epoch: 5 [1000/11194 (9%)]\tLoss: 0.176888\n",
      "Train Epoch: 5 [2000/11194 (18%)]\tLoss: 0.151472\n",
      "Train Epoch: 5 [3000/11194 (27%)]\tLoss: 0.127735\n",
      "Train Epoch: 5 [4000/11194 (36%)]\tLoss: 0.163274\n",
      "Train Epoch: 5 [5000/11194 (45%)]\tLoss: 0.206328\n",
      "Train Epoch: 5 [6000/11194 (54%)]\tLoss: 0.184202\n",
      "Train Epoch: 5 [7000/11194 (62%)]\tLoss: 0.136730\n",
      "Train Epoch: 5 [8000/11194 (71%)]\tLoss: 0.149591\n",
      "Train Epoch: 5 [9000/11194 (80%)]\tLoss: 0.166620\n",
      "Train Epoch: 5 [10000/11194 (89%)]\tLoss: 0.183727\n",
      "Train Epoch: 5 [11000/11194 (98%)]\tLoss: 0.140135\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/7891 (0%)]\tLoss: 0.212084\n",
      "Train Epoch: 1 [1000/7891 (13%)]\tLoss: 0.153261\n",
      "Train Epoch: 1 [2000/7891 (25%)]\tLoss: 0.162351\n",
      "Train Epoch: 1 [3000/7891 (38%)]\tLoss: 0.176753\n",
      "Train Epoch: 1 [4000/7891 (51%)]\tLoss: 0.242821\n",
      "Train Epoch: 1 [5000/7891 (63%)]\tLoss: 0.148710\n",
      "Train Epoch: 1 [6000/7891 (76%)]\tLoss: 0.056138\n",
      "Train Epoch: 1 [7000/7891 (89%)]\tLoss: 0.134791\n",
      "Train Epoch: 2 [0/7891 (0%)]\tLoss: 0.078693\n",
      "Train Epoch: 2 [1000/7891 (13%)]\tLoss: 0.135552\n",
      "Train Epoch: 2 [2000/7891 (25%)]\tLoss: 0.180382\n",
      "Train Epoch: 2 [3000/7891 (38%)]\tLoss: 0.064723\n",
      "Train Epoch: 2 [4000/7891 (51%)]\tLoss: 0.147284\n",
      "Train Epoch: 2 [5000/7891 (63%)]\tLoss: 0.081375\n",
      "Train Epoch: 2 [6000/7891 (76%)]\tLoss: 0.180309\n",
      "Train Epoch: 2 [7000/7891 (89%)]\tLoss: 0.114187\n",
      "Train Epoch: 3 [0/7891 (0%)]\tLoss: 0.053442\n",
      "Train Epoch: 3 [1000/7891 (13%)]\tLoss: 0.156287\n",
      "Train Epoch: 3 [2000/7891 (25%)]\tLoss: 0.058133\n",
      "Train Epoch: 3 [3000/7891 (38%)]\tLoss: 0.221589\n",
      "Train Epoch: 3 [4000/7891 (51%)]\tLoss: 0.136921\n",
      "Train Epoch: 3 [5000/7891 (63%)]\tLoss: 0.073496\n",
      "Train Epoch: 3 [6000/7891 (76%)]\tLoss: 0.074770\n",
      "Train Epoch: 3 [7000/7891 (89%)]\tLoss: 0.137710\n",
      "Train Epoch: 4 [0/7891 (0%)]\tLoss: 0.107812\n",
      "Train Epoch: 4 [1000/7891 (13%)]\tLoss: 0.093224\n",
      "Train Epoch: 4 [2000/7891 (25%)]\tLoss: 0.118629\n",
      "Train Epoch: 4 [3000/7891 (38%)]\tLoss: 0.083197\n",
      "Train Epoch: 4 [4000/7891 (51%)]\tLoss: 0.053713\n",
      "Train Epoch: 4 [5000/7891 (63%)]\tLoss: 0.095961\n",
      "Train Epoch: 4 [6000/7891 (76%)]\tLoss: 0.143291\n",
      "Train Epoch: 4 [7000/7891 (89%)]\tLoss: 0.142341\n",
      "Train Epoch: 5 [0/7891 (0%)]\tLoss: 0.110559\n",
      "Train Epoch: 5 [1000/7891 (13%)]\tLoss: 0.074617\n",
      "Train Epoch: 5 [2000/7891 (25%)]\tLoss: 0.101219\n",
      "Train Epoch: 5 [3000/7891 (38%)]\tLoss: 0.129214\n",
      "Train Epoch: 5 [4000/7891 (51%)]\tLoss: 0.116393\n",
      "Train Epoch: 5 [5000/7891 (63%)]\tLoss: 0.096650\n",
      "Train Epoch: 5 [6000/7891 (76%)]\tLoss: 0.069261\n",
      "Train Epoch: 5 [7000/7891 (89%)]\tLoss: 0.121736\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/3053 (0%)]\tLoss: 0.152307\n",
      "Train Epoch: 1 [1000/3053 (32%)]\tLoss: 0.184849\n",
      "Train Epoch: 1 [2000/3053 (65%)]\tLoss: 0.155180\n",
      "Train Epoch: 1 [1590/3053 (97%)]\tLoss: 0.046139\n",
      "Train Epoch: 2 [0/3053 (0%)]\tLoss: 0.087711\n",
      "Train Epoch: 2 [1000/3053 (32%)]\tLoss: 0.182821\n",
      "Train Epoch: 2 [2000/3053 (65%)]\tLoss: 0.055711\n",
      "Train Epoch: 2 [1590/3053 (97%)]\tLoss: 0.054053\n",
      "Train Epoch: 3 [0/3053 (0%)]\tLoss: 0.229642\n",
      "Train Epoch: 3 [1000/3053 (32%)]\tLoss: 0.111747\n",
      "Train Epoch: 3 [2000/3053 (65%)]\tLoss: 0.119942\n",
      "Train Epoch: 3 [1590/3053 (97%)]\tLoss: 0.112433\n",
      "Train Epoch: 4 [0/3053 (0%)]\tLoss: 0.109843\n",
      "Train Epoch: 4 [1000/3053 (32%)]\tLoss: 0.132466\n",
      "Train Epoch: 4 [2000/3053 (65%)]\tLoss: 0.232888\n",
      "Train Epoch: 4 [1590/3053 (97%)]\tLoss: 0.090576\n",
      "Train Epoch: 5 [0/3053 (0%)]\tLoss: 0.109356\n",
      "Train Epoch: 5 [1000/3053 (32%)]\tLoss: 0.115440\n",
      "Train Epoch: 5 [2000/3053 (65%)]\tLoss: 0.112755\n",
      "Train Epoch: 5 [1590/3053 (97%)]\tLoss: 0.129377\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/9145 (0%)]\tLoss: 0.320545\n",
      "Train Epoch: 1 [1000/9145 (11%)]\tLoss: 0.332747\n",
      "Train Epoch: 1 [2000/9145 (22%)]\tLoss: 0.191041\n",
      "Train Epoch: 1 [3000/9145 (33%)]\tLoss: 0.269996\n",
      "Train Epoch: 1 [4000/9145 (43%)]\tLoss: 0.308046\n",
      "Train Epoch: 1 [5000/9145 (54%)]\tLoss: 0.122755\n",
      "Train Epoch: 1 [6000/9145 (65%)]\tLoss: 0.217055\n",
      "Train Epoch: 1 [7000/9145 (76%)]\tLoss: 0.270973\n",
      "Train Epoch: 1 [8000/9145 (87%)]\tLoss: 0.238256\n",
      "Train Epoch: 1 [9000/9145 (98%)]\tLoss: 0.275601\n",
      "Train Epoch: 2 [0/9145 (0%)]\tLoss: 0.272384\n",
      "Train Epoch: 2 [1000/9145 (11%)]\tLoss: 0.199108\n",
      "Train Epoch: 2 [2000/9145 (22%)]\tLoss: 0.153454\n",
      "Train Epoch: 2 [3000/9145 (33%)]\tLoss: 0.393473\n",
      "Train Epoch: 2 [4000/9145 (43%)]\tLoss: 0.139370\n",
      "Train Epoch: 2 [5000/9145 (54%)]\tLoss: 0.238693\n",
      "Train Epoch: 2 [6000/9145 (65%)]\tLoss: 0.114737\n",
      "Train Epoch: 2 [7000/9145 (76%)]\tLoss: 0.153616\n",
      "Train Epoch: 2 [8000/9145 (87%)]\tLoss: 0.244130\n",
      "Train Epoch: 2 [9000/9145 (98%)]\tLoss: 0.204616\n",
      "Train Epoch: 3 [0/9145 (0%)]\tLoss: 0.311793\n",
      "Train Epoch: 3 [1000/9145 (11%)]\tLoss: 0.289373\n",
      "Train Epoch: 3 [2000/9145 (22%)]\tLoss: 0.220972\n",
      "Train Epoch: 3 [3000/9145 (33%)]\tLoss: 0.297988\n",
      "Train Epoch: 3 [4000/9145 (43%)]\tLoss: 0.184703\n",
      "Train Epoch: 3 [5000/9145 (54%)]\tLoss: 0.189337\n",
      "Train Epoch: 3 [6000/9145 (65%)]\tLoss: 0.231267\n",
      "Train Epoch: 3 [7000/9145 (76%)]\tLoss: 0.137241\n",
      "Train Epoch: 3 [8000/9145 (87%)]\tLoss: 0.247469\n",
      "Train Epoch: 3 [9000/9145 (98%)]\tLoss: 0.205712\n",
      "Train Epoch: 4 [0/9145 (0%)]\tLoss: 0.151668\n",
      "Train Epoch: 4 [1000/9145 (11%)]\tLoss: 0.194399\n",
      "Train Epoch: 4 [2000/9145 (22%)]\tLoss: 0.286232\n",
      "Train Epoch: 4 [3000/9145 (33%)]\tLoss: 0.219360\n",
      "Train Epoch: 4 [4000/9145 (43%)]\tLoss: 0.168232\n",
      "Train Epoch: 4 [5000/9145 (54%)]\tLoss: 0.153059\n",
      "Train Epoch: 4 [6000/9145 (65%)]\tLoss: 0.229423\n",
      "Train Epoch: 4 [7000/9145 (76%)]\tLoss: 0.187820\n",
      "Train Epoch: 4 [8000/9145 (87%)]\tLoss: 0.253691\n",
      "Train Epoch: 4 [9000/9145 (98%)]\tLoss: 0.354196\n",
      "Train Epoch: 5 [0/9145 (0%)]\tLoss: 0.268170\n",
      "Train Epoch: 5 [1000/9145 (11%)]\tLoss: 0.154606\n",
      "Train Epoch: 5 [2000/9145 (22%)]\tLoss: 0.196595\n",
      "Train Epoch: 5 [3000/9145 (33%)]\tLoss: 0.149044\n",
      "Train Epoch: 5 [4000/9145 (43%)]\tLoss: 0.147216\n",
      "Train Epoch: 5 [5000/9145 (54%)]\tLoss: 0.167086\n",
      "Train Epoch: 5 [6000/9145 (65%)]\tLoss: 0.151164\n",
      "Train Epoch: 5 [7000/9145 (76%)]\tLoss: 0.226824\n",
      "Train Epoch: 5 [8000/9145 (87%)]\tLoss: 0.244307\n",
      "Train Epoch: 5 [9000/9145 (98%)]\tLoss: 0.253735\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3021 (0%)]\tLoss: 0.280610\n",
      "Train Epoch: 1 [1000/3021 (32%)]\tLoss: 0.154090\n",
      "Train Epoch: 1 [2000/3021 (65%)]\tLoss: 0.242102\n",
      "Train Epoch: 1 [630/3021 (97%)]\tLoss: 0.453201\n",
      "Train Epoch: 2 [0/3021 (0%)]\tLoss: 0.272854\n",
      "Train Epoch: 2 [1000/3021 (32%)]\tLoss: 0.120035\n",
      "Train Epoch: 2 [2000/3021 (65%)]\tLoss: 0.120652\n",
      "Train Epoch: 2 [630/3021 (97%)]\tLoss: 0.310424\n",
      "Train Epoch: 3 [0/3021 (0%)]\tLoss: 0.144132\n",
      "Train Epoch: 3 [1000/3021 (32%)]\tLoss: 0.191638\n",
      "Train Epoch: 3 [2000/3021 (65%)]\tLoss: 0.173391\n",
      "Train Epoch: 3 [630/3021 (97%)]\tLoss: 0.213258\n",
      "Train Epoch: 4 [0/3021 (0%)]\tLoss: 0.117994\n",
      "Train Epoch: 4 [1000/3021 (32%)]\tLoss: 0.188197\n",
      "Train Epoch: 4 [2000/3021 (65%)]\tLoss: 0.132342\n",
      "Train Epoch: 4 [630/3021 (97%)]\tLoss: 0.050559\n",
      "Train Epoch: 5 [0/3021 (0%)]\tLoss: 0.174857\n",
      "Train Epoch: 5 [1000/3021 (32%)]\tLoss: 0.080229\n",
      "Train Epoch: 5 [2000/3021 (65%)]\tLoss: 0.198345\n",
      "Train Epoch: 5 [630/3021 (97%)]\tLoss: 0.081581\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/7953 (0%)]\tLoss: 0.348418\n",
      "Train Epoch: 1 [1000/7953 (12%)]\tLoss: 0.498840\n",
      "Train Epoch: 1 [2000/7953 (25%)]\tLoss: 0.344508\n",
      "Train Epoch: 1 [3000/7953 (38%)]\tLoss: 0.422853\n",
      "Train Epoch: 1 [4000/7953 (50%)]\tLoss: 0.371762\n",
      "Train Epoch: 1 [5000/7953 (62%)]\tLoss: 0.208157\n",
      "Train Epoch: 1 [6000/7953 (75%)]\tLoss: 0.363979\n",
      "Train Epoch: 1 [7000/7953 (88%)]\tLoss: 0.345918\n",
      "Train Epoch: 2 [0/7953 (0%)]\tLoss: 0.257821\n",
      "Train Epoch: 2 [1000/7953 (12%)]\tLoss: 0.327054\n",
      "Train Epoch: 2 [2000/7953 (25%)]\tLoss: 0.299748\n",
      "Train Epoch: 2 [3000/7953 (38%)]\tLoss: 0.200724\n",
      "Train Epoch: 2 [4000/7953 (50%)]\tLoss: 0.436340\n",
      "Train Epoch: 2 [5000/7953 (62%)]\tLoss: 0.472103\n",
      "Train Epoch: 2 [6000/7953 (75%)]\tLoss: 0.415602\n",
      "Train Epoch: 2 [7000/7953 (88%)]\tLoss: 0.315093\n",
      "Train Epoch: 3 [0/7953 (0%)]\tLoss: 0.358902\n",
      "Train Epoch: 3 [1000/7953 (12%)]\tLoss: 0.470516\n",
      "Train Epoch: 3 [2000/7953 (25%)]\tLoss: 0.347078\n",
      "Train Epoch: 3 [3000/7953 (38%)]\tLoss: 0.290608\n",
      "Train Epoch: 3 [4000/7953 (50%)]\tLoss: 0.265566\n",
      "Train Epoch: 3 [5000/7953 (62%)]\tLoss: 0.380126\n",
      "Train Epoch: 3 [6000/7953 (75%)]\tLoss: 0.386703\n",
      "Train Epoch: 3 [7000/7953 (88%)]\tLoss: 0.342186\n",
      "Train Epoch: 4 [0/7953 (0%)]\tLoss: 0.277582\n",
      "Train Epoch: 4 [1000/7953 (12%)]\tLoss: 0.270032\n",
      "Train Epoch: 4 [2000/7953 (25%)]\tLoss: 0.342889\n",
      "Train Epoch: 4 [3000/7953 (38%)]\tLoss: 0.276873\n",
      "Train Epoch: 4 [4000/7953 (50%)]\tLoss: 0.489143\n",
      "Train Epoch: 4 [5000/7953 (62%)]\tLoss: 0.366751\n",
      "Train Epoch: 4 [6000/7953 (75%)]\tLoss: 0.317417\n",
      "Train Epoch: 4 [7000/7953 (88%)]\tLoss: 0.379620\n",
      "Train Epoch: 5 [0/7953 (0%)]\tLoss: 0.362449\n",
      "Train Epoch: 5 [1000/7953 (12%)]\tLoss: 0.324407\n",
      "Train Epoch: 5 [2000/7953 (25%)]\tLoss: 0.281824\n",
      "Train Epoch: 5 [3000/7953 (38%)]\tLoss: 0.243123\n",
      "Train Epoch: 5 [4000/7953 (50%)]\tLoss: 0.324967\n",
      "Train Epoch: 5 [5000/7953 (62%)]\tLoss: 0.330189\n",
      "Train Epoch: 5 [6000/7953 (75%)]\tLoss: 0.316238\n",
      "Train Epoch: 5 [7000/7953 (88%)]\tLoss: 0.313904\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/10012 (0%)]\tLoss: 0.272853\n",
      "Train Epoch: 1 [1000/10012 (10%)]\tLoss: 0.111388\n",
      "Train Epoch: 1 [2000/10012 (20%)]\tLoss: 0.123374\n",
      "Train Epoch: 1 [3000/10012 (30%)]\tLoss: 0.253859\n",
      "Train Epoch: 1 [4000/10012 (40%)]\tLoss: 0.174824\n",
      "Train Epoch: 1 [5000/10012 (50%)]\tLoss: 0.190928\n",
      "Train Epoch: 1 [6000/10012 (59%)]\tLoss: 0.200249\n",
      "Train Epoch: 1 [7000/10012 (69%)]\tLoss: 0.150147\n",
      "Train Epoch: 1 [8000/10012 (79%)]\tLoss: 0.070217\n",
      "Train Epoch: 1 [9000/10012 (89%)]\tLoss: 0.073026\n",
      "Train Epoch: 1 [1200/10012 (99%)]\tLoss: 0.410649\n",
      "Train Epoch: 2 [0/10012 (0%)]\tLoss: 0.130519\n",
      "Train Epoch: 2 [1000/10012 (10%)]\tLoss: 0.059012\n",
      "Train Epoch: 2 [2000/10012 (20%)]\tLoss: 0.053285\n",
      "Train Epoch: 2 [3000/10012 (30%)]\tLoss: 0.079142\n",
      "Train Epoch: 2 [4000/10012 (40%)]\tLoss: 0.135136\n",
      "Train Epoch: 2 [5000/10012 (50%)]\tLoss: 0.079705\n",
      "Train Epoch: 2 [6000/10012 (59%)]\tLoss: 0.201721\n",
      "Train Epoch: 2 [7000/10012 (69%)]\tLoss: 0.034154\n",
      "Train Epoch: 2 [8000/10012 (79%)]\tLoss: 0.069241\n",
      "Train Epoch: 2 [9000/10012 (89%)]\tLoss: 0.149125\n",
      "Train Epoch: 2 [1200/10012 (99%)]\tLoss: 0.029999\n",
      "Train Epoch: 3 [0/10012 (0%)]\tLoss: 0.156030\n",
      "Train Epoch: 3 [1000/10012 (10%)]\tLoss: 0.099662\n",
      "Train Epoch: 3 [2000/10012 (20%)]\tLoss: 0.144046\n",
      "Train Epoch: 3 [3000/10012 (30%)]\tLoss: 0.133215\n",
      "Train Epoch: 3 [4000/10012 (40%)]\tLoss: 0.108038\n",
      "Train Epoch: 3 [5000/10012 (50%)]\tLoss: 0.075611\n",
      "Train Epoch: 3 [6000/10012 (59%)]\tLoss: 0.057514\n",
      "Train Epoch: 3 [7000/10012 (69%)]\tLoss: 0.050839\n",
      "Train Epoch: 3 [8000/10012 (79%)]\tLoss: 0.073890\n",
      "Train Epoch: 3 [9000/10012 (89%)]\tLoss: 0.088938\n",
      "Train Epoch: 3 [1200/10012 (99%)]\tLoss: 0.001896\n",
      "Train Epoch: 4 [0/10012 (0%)]\tLoss: 0.050212\n",
      "Train Epoch: 4 [1000/10012 (10%)]\tLoss: 0.109335\n",
      "Train Epoch: 4 [2000/10012 (20%)]\tLoss: 0.162474\n",
      "Train Epoch: 4 [3000/10012 (30%)]\tLoss: 0.120357\n",
      "Train Epoch: 4 [4000/10012 (40%)]\tLoss: 0.130286\n",
      "Train Epoch: 4 [5000/10012 (50%)]\tLoss: 0.093977\n",
      "Train Epoch: 4 [6000/10012 (59%)]\tLoss: 0.080384\n",
      "Train Epoch: 4 [7000/10012 (69%)]\tLoss: 0.129026\n",
      "Train Epoch: 4 [8000/10012 (79%)]\tLoss: 0.190559\n",
      "Train Epoch: 4 [9000/10012 (89%)]\tLoss: 0.200593\n",
      "Train Epoch: 4 [1200/10012 (99%)]\tLoss: 0.016180\n",
      "Train Epoch: 5 [0/10012 (0%)]\tLoss: 0.127323\n",
      "Train Epoch: 5 [1000/10012 (10%)]\tLoss: 0.099772\n",
      "Train Epoch: 5 [2000/10012 (20%)]\tLoss: 0.068150\n",
      "Train Epoch: 5 [3000/10012 (30%)]\tLoss: 0.086808\n",
      "Train Epoch: 5 [4000/10012 (40%)]\tLoss: 0.077993\n",
      "Train Epoch: 5 [5000/10012 (50%)]\tLoss: 0.148491\n",
      "Train Epoch: 5 [6000/10012 (59%)]\tLoss: 0.269761\n",
      "Train Epoch: 5 [7000/10012 (69%)]\tLoss: 0.141552\n",
      "Train Epoch: 5 [8000/10012 (79%)]\tLoss: 0.079282\n",
      "Train Epoch: 5 [9000/10012 (89%)]\tLoss: 0.066023\n",
      "Train Epoch: 5 [1200/10012 (99%)]\tLoss: 0.117625\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "8\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.3626, Accuracy: 8701/10000 (87%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/7731 (0%)]\tLoss: 0.367591\n",
      "Train Epoch: 1 [1000/7731 (13%)]\tLoss: 0.170550\n",
      "Train Epoch: 1 [2000/7731 (26%)]\tLoss: 0.067124\n",
      "Train Epoch: 1 [3000/7731 (38%)]\tLoss: 0.107685\n",
      "Train Epoch: 1 [4000/7731 (51%)]\tLoss: 0.147868\n",
      "Train Epoch: 1 [5000/7731 (64%)]\tLoss: 0.251745\n",
      "Train Epoch: 1 [6000/7731 (77%)]\tLoss: 0.122164\n",
      "Train Epoch: 1 [7000/7731 (90%)]\tLoss: 0.099082\n",
      "Train Epoch: 2 [0/7731 (0%)]\tLoss: 0.158257\n",
      "Train Epoch: 2 [1000/7731 (13%)]\tLoss: 0.164234\n",
      "Train Epoch: 2 [2000/7731 (26%)]\tLoss: 0.131074\n",
      "Train Epoch: 2 [3000/7731 (38%)]\tLoss: 0.076613\n",
      "Train Epoch: 2 [4000/7731 (51%)]\tLoss: 0.118563\n",
      "Train Epoch: 2 [5000/7731 (64%)]\tLoss: 0.178081\n",
      "Train Epoch: 2 [6000/7731 (77%)]\tLoss: 0.147153\n",
      "Train Epoch: 2 [7000/7731 (90%)]\tLoss: 0.093530\n",
      "Train Epoch: 3 [0/7731 (0%)]\tLoss: 0.162039\n",
      "Train Epoch: 3 [1000/7731 (13%)]\tLoss: 0.137298\n",
      "Train Epoch: 3 [2000/7731 (26%)]\tLoss: 0.110976\n",
      "Train Epoch: 3 [3000/7731 (38%)]\tLoss: 0.152281\n",
      "Train Epoch: 3 [4000/7731 (51%)]\tLoss: 0.173553\n",
      "Train Epoch: 3 [5000/7731 (64%)]\tLoss: 0.109211\n",
      "Train Epoch: 3 [6000/7731 (77%)]\tLoss: 0.105838\n",
      "Train Epoch: 3 [7000/7731 (90%)]\tLoss: 0.076128\n",
      "Train Epoch: 4 [0/7731 (0%)]\tLoss: 0.188602\n",
      "Train Epoch: 4 [1000/7731 (13%)]\tLoss: 0.097771\n",
      "Train Epoch: 4 [2000/7731 (26%)]\tLoss: 0.117863\n",
      "Train Epoch: 4 [3000/7731 (38%)]\tLoss: 0.143984\n",
      "Train Epoch: 4 [4000/7731 (51%)]\tLoss: 0.134321\n",
      "Train Epoch: 4 [5000/7731 (64%)]\tLoss: 0.093208\n",
      "Train Epoch: 4 [6000/7731 (77%)]\tLoss: 0.132215\n",
      "Train Epoch: 4 [7000/7731 (90%)]\tLoss: 0.066142\n",
      "Train Epoch: 5 [0/7731 (0%)]\tLoss: 0.120276\n",
      "Train Epoch: 5 [1000/7731 (13%)]\tLoss: 0.109056\n",
      "Train Epoch: 5 [2000/7731 (26%)]\tLoss: 0.111053\n",
      "Train Epoch: 5 [3000/7731 (38%)]\tLoss: 0.169121\n",
      "Train Epoch: 5 [4000/7731 (51%)]\tLoss: 0.084564\n",
      "Train Epoch: 5 [5000/7731 (64%)]\tLoss: 0.072615\n",
      "Train Epoch: 5 [6000/7731 (77%)]\tLoss: 0.097749\n",
      "Train Epoch: 5 [7000/7731 (90%)]\tLoss: 0.144979\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11194 (0%)]\tLoss: 0.232930\n",
      "Train Epoch: 1 [1000/11194 (9%)]\tLoss: 0.257983\n",
      "Train Epoch: 1 [2000/11194 (18%)]\tLoss: 0.209851\n",
      "Train Epoch: 1 [3000/11194 (27%)]\tLoss: 0.206274\n",
      "Train Epoch: 1 [4000/11194 (36%)]\tLoss: 0.172846\n",
      "Train Epoch: 1 [5000/11194 (45%)]\tLoss: 0.148901\n",
      "Train Epoch: 1 [6000/11194 (54%)]\tLoss: 0.154654\n",
      "Train Epoch: 1 [7000/11194 (62%)]\tLoss: 0.180711\n",
      "Train Epoch: 1 [8000/11194 (71%)]\tLoss: 0.175237\n",
      "Train Epoch: 1 [9000/11194 (80%)]\tLoss: 0.063135\n",
      "Train Epoch: 1 [10000/11194 (89%)]\tLoss: 0.104756\n",
      "Train Epoch: 1 [11000/11194 (98%)]\tLoss: 0.131695\n",
      "Train Epoch: 2 [0/11194 (0%)]\tLoss: 0.197176\n",
      "Train Epoch: 2 [1000/11194 (9%)]\tLoss: 0.184379\n",
      "Train Epoch: 2 [2000/11194 (18%)]\tLoss: 0.156786\n",
      "Train Epoch: 2 [3000/11194 (27%)]\tLoss: 0.219500\n",
      "Train Epoch: 2 [4000/11194 (36%)]\tLoss: 0.211074\n",
      "Train Epoch: 2 [5000/11194 (45%)]\tLoss: 0.121182\n",
      "Train Epoch: 2 [6000/11194 (54%)]\tLoss: 0.111933\n",
      "Train Epoch: 2 [7000/11194 (62%)]\tLoss: 0.074948\n",
      "Train Epoch: 2 [8000/11194 (71%)]\tLoss: 0.130136\n",
      "Train Epoch: 2 [9000/11194 (80%)]\tLoss: 0.097998\n",
      "Train Epoch: 2 [10000/11194 (89%)]\tLoss: 0.191154\n",
      "Train Epoch: 2 [11000/11194 (98%)]\tLoss: 0.097269\n",
      "Train Epoch: 3 [0/11194 (0%)]\tLoss: 0.136468\n",
      "Train Epoch: 3 [1000/11194 (9%)]\tLoss: 0.191369\n",
      "Train Epoch: 3 [2000/11194 (18%)]\tLoss: 0.154902\n",
      "Train Epoch: 3 [3000/11194 (27%)]\tLoss: 0.212528\n",
      "Train Epoch: 3 [4000/11194 (36%)]\tLoss: 0.158924\n",
      "Train Epoch: 3 [5000/11194 (45%)]\tLoss: 0.114524\n",
      "Train Epoch: 3 [6000/11194 (54%)]\tLoss: 0.181704\n",
      "Train Epoch: 3 [7000/11194 (62%)]\tLoss: 0.182174\n",
      "Train Epoch: 3 [8000/11194 (71%)]\tLoss: 0.118669\n",
      "Train Epoch: 3 [9000/11194 (80%)]\tLoss: 0.099327\n",
      "Train Epoch: 3 [10000/11194 (89%)]\tLoss: 0.265996\n",
      "Train Epoch: 3 [11000/11194 (98%)]\tLoss: 0.221922\n",
      "Train Epoch: 4 [0/11194 (0%)]\tLoss: 0.141770\n",
      "Train Epoch: 4 [1000/11194 (9%)]\tLoss: 0.132817\n",
      "Train Epoch: 4 [2000/11194 (18%)]\tLoss: 0.060449\n",
      "Train Epoch: 4 [3000/11194 (27%)]\tLoss: 0.089424\n",
      "Train Epoch: 4 [4000/11194 (36%)]\tLoss: 0.215374\n",
      "Train Epoch: 4 [5000/11194 (45%)]\tLoss: 0.208678\n",
      "Train Epoch: 4 [6000/11194 (54%)]\tLoss: 0.214066\n",
      "Train Epoch: 4 [7000/11194 (62%)]\tLoss: 0.159470\n",
      "Train Epoch: 4 [8000/11194 (71%)]\tLoss: 0.090414\n",
      "Train Epoch: 4 [9000/11194 (80%)]\tLoss: 0.168334\n",
      "Train Epoch: 4 [10000/11194 (89%)]\tLoss: 0.202835\n",
      "Train Epoch: 4 [11000/11194 (98%)]\tLoss: 0.135142\n",
      "Train Epoch: 5 [0/11194 (0%)]\tLoss: 0.128785\n",
      "Train Epoch: 5 [1000/11194 (9%)]\tLoss: 0.196982\n",
      "Train Epoch: 5 [2000/11194 (18%)]\tLoss: 0.123535\n",
      "Train Epoch: 5 [3000/11194 (27%)]\tLoss: 0.106621\n",
      "Train Epoch: 5 [4000/11194 (36%)]\tLoss: 0.107952\n",
      "Train Epoch: 5 [5000/11194 (45%)]\tLoss: 0.129385\n",
      "Train Epoch: 5 [6000/11194 (54%)]\tLoss: 0.101784\n",
      "Train Epoch: 5 [7000/11194 (62%)]\tLoss: 0.125711\n",
      "Train Epoch: 5 [8000/11194 (71%)]\tLoss: 0.133023\n",
      "Train Epoch: 5 [9000/11194 (80%)]\tLoss: 0.190732\n",
      "Train Epoch: 5 [10000/11194 (89%)]\tLoss: 0.121621\n",
      "Train Epoch: 5 [11000/11194 (98%)]\tLoss: 0.186099\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "8\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4063, Accuracy: 8596/10000 (86%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/7731 (0%)]\tLoss: 0.130747\n",
      "Train Epoch: 1 [1000/7731 (13%)]\tLoss: 0.124974\n",
      "Train Epoch: 1 [2000/7731 (26%)]\tLoss: 0.063057\n",
      "Train Epoch: 1 [3000/7731 (38%)]\tLoss: 0.065009\n",
      "Train Epoch: 1 [4000/7731 (51%)]\tLoss: 0.239379\n",
      "Train Epoch: 1 [5000/7731 (64%)]\tLoss: 0.145287\n",
      "Train Epoch: 1 [6000/7731 (77%)]\tLoss: 0.232624\n",
      "Train Epoch: 1 [7000/7731 (90%)]\tLoss: 0.075440\n",
      "Train Epoch: 2 [0/7731 (0%)]\tLoss: 0.068425\n",
      "Train Epoch: 2 [1000/7731 (13%)]\tLoss: 0.154827\n",
      "Train Epoch: 2 [2000/7731 (26%)]\tLoss: 0.090031\n",
      "Train Epoch: 2 [3000/7731 (38%)]\tLoss: 0.175744\n",
      "Train Epoch: 2 [4000/7731 (51%)]\tLoss: 0.133384\n",
      "Train Epoch: 2 [5000/7731 (64%)]\tLoss: 0.141076\n",
      "Train Epoch: 2 [6000/7731 (77%)]\tLoss: 0.143887\n",
      "Train Epoch: 2 [7000/7731 (90%)]\tLoss: 0.147364\n",
      "Train Epoch: 3 [0/7731 (0%)]\tLoss: 0.147550\n",
      "Train Epoch: 3 [1000/7731 (13%)]\tLoss: 0.110471\n",
      "Train Epoch: 3 [2000/7731 (26%)]\tLoss: 0.135239\n",
      "Train Epoch: 3 [3000/7731 (38%)]\tLoss: 0.063815\n",
      "Train Epoch: 3 [4000/7731 (51%)]\tLoss: 0.195647\n",
      "Train Epoch: 3 [5000/7731 (64%)]\tLoss: 0.110505\n",
      "Train Epoch: 3 [6000/7731 (77%)]\tLoss: 0.208025\n",
      "Train Epoch: 3 [7000/7731 (90%)]\tLoss: 0.122047\n",
      "Train Epoch: 4 [0/7731 (0%)]\tLoss: 0.104002\n",
      "Train Epoch: 4 [1000/7731 (13%)]\tLoss: 0.127050\n",
      "Train Epoch: 4 [2000/7731 (26%)]\tLoss: 0.078996\n",
      "Train Epoch: 4 [3000/7731 (38%)]\tLoss: 0.108799\n",
      "Train Epoch: 4 [4000/7731 (51%)]\tLoss: 0.130763\n",
      "Train Epoch: 4 [5000/7731 (64%)]\tLoss: 0.148145\n",
      "Train Epoch: 4 [6000/7731 (77%)]\tLoss: 0.142415\n",
      "Train Epoch: 4 [7000/7731 (90%)]\tLoss: 0.120449\n",
      "Train Epoch: 5 [0/7731 (0%)]\tLoss: 0.175035\n",
      "Train Epoch: 5 [1000/7731 (13%)]\tLoss: 0.084007\n",
      "Train Epoch: 5 [2000/7731 (26%)]\tLoss: 0.073867\n",
      "Train Epoch: 5 [3000/7731 (38%)]\tLoss: 0.096314\n",
      "Train Epoch: 5 [4000/7731 (51%)]\tLoss: 0.255012\n",
      "Train Epoch: 5 [5000/7731 (64%)]\tLoss: 0.208030\n",
      "Train Epoch: 5 [6000/7731 (77%)]\tLoss: 0.104170\n",
      "Train Epoch: 5 [7000/7731 (90%)]\tLoss: 0.097970\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11194 (0%)]\tLoss: 0.323983\n",
      "Train Epoch: 1 [1000/11194 (9%)]\tLoss: 0.190389\n",
      "Train Epoch: 1 [2000/11194 (18%)]\tLoss: 0.081540\n",
      "Train Epoch: 1 [3000/11194 (27%)]\tLoss: 0.105849\n",
      "Train Epoch: 1 [4000/11194 (36%)]\tLoss: 0.115789\n",
      "Train Epoch: 1 [5000/11194 (45%)]\tLoss: 0.085627\n",
      "Train Epoch: 1 [6000/11194 (54%)]\tLoss: 0.149689\n",
      "Train Epoch: 1 [7000/11194 (62%)]\tLoss: 0.198937\n",
      "Train Epoch: 1 [8000/11194 (71%)]\tLoss: 0.110374\n",
      "Train Epoch: 1 [9000/11194 (80%)]\tLoss: 0.101286\n",
      "Train Epoch: 1 [10000/11194 (89%)]\tLoss: 0.185721\n",
      "Train Epoch: 1 [11000/11194 (98%)]\tLoss: 0.132246\n",
      "Train Epoch: 2 [0/11194 (0%)]\tLoss: 0.146830\n",
      "Train Epoch: 2 [1000/11194 (9%)]\tLoss: 0.134761\n",
      "Train Epoch: 2 [2000/11194 (18%)]\tLoss: 0.149440\n",
      "Train Epoch: 2 [3000/11194 (27%)]\tLoss: 0.201030\n",
      "Train Epoch: 2 [4000/11194 (36%)]\tLoss: 0.141031\n",
      "Train Epoch: 2 [5000/11194 (45%)]\tLoss: 0.119257\n",
      "Train Epoch: 2 [6000/11194 (54%)]\tLoss: 0.187030\n",
      "Train Epoch: 2 [7000/11194 (62%)]\tLoss: 0.104836\n",
      "Train Epoch: 2 [8000/11194 (71%)]\tLoss: 0.126590\n",
      "Train Epoch: 2 [9000/11194 (80%)]\tLoss: 0.147215\n",
      "Train Epoch: 2 [10000/11194 (89%)]\tLoss: 0.121533\n",
      "Train Epoch: 2 [11000/11194 (98%)]\tLoss: 0.200943\n",
      "Train Epoch: 3 [0/11194 (0%)]\tLoss: 0.184613\n",
      "Train Epoch: 3 [1000/11194 (9%)]\tLoss: 0.086803\n",
      "Train Epoch: 3 [2000/11194 (18%)]\tLoss: 0.061688\n",
      "Train Epoch: 3 [3000/11194 (27%)]\tLoss: 0.134149\n",
      "Train Epoch: 3 [4000/11194 (36%)]\tLoss: 0.183848\n",
      "Train Epoch: 3 [5000/11194 (45%)]\tLoss: 0.172848\n",
      "Train Epoch: 3 [6000/11194 (54%)]\tLoss: 0.100124\n",
      "Train Epoch: 3 [7000/11194 (62%)]\tLoss: 0.098961\n",
      "Train Epoch: 3 [8000/11194 (71%)]\tLoss: 0.148109\n",
      "Train Epoch: 3 [9000/11194 (80%)]\tLoss: 0.125357\n",
      "Train Epoch: 3 [10000/11194 (89%)]\tLoss: 0.104002\n",
      "Train Epoch: 3 [11000/11194 (98%)]\tLoss: 0.191569\n",
      "Train Epoch: 4 [0/11194 (0%)]\tLoss: 0.087293\n",
      "Train Epoch: 4 [1000/11194 (9%)]\tLoss: 0.138832\n",
      "Train Epoch: 4 [2000/11194 (18%)]\tLoss: 0.086386\n",
      "Train Epoch: 4 [3000/11194 (27%)]\tLoss: 0.090506\n",
      "Train Epoch: 4 [4000/11194 (36%)]\tLoss: 0.198009\n",
      "Train Epoch: 4 [5000/11194 (45%)]\tLoss: 0.109251\n",
      "Train Epoch: 4 [6000/11194 (54%)]\tLoss: 0.093333\n",
      "Train Epoch: 4 [7000/11194 (62%)]\tLoss: 0.200628\n",
      "Train Epoch: 4 [8000/11194 (71%)]\tLoss: 0.076379\n",
      "Train Epoch: 4 [9000/11194 (80%)]\tLoss: 0.102999\n",
      "Train Epoch: 4 [10000/11194 (89%)]\tLoss: 0.117845\n",
      "Train Epoch: 4 [11000/11194 (98%)]\tLoss: 0.112775\n",
      "Train Epoch: 5 [0/11194 (0%)]\tLoss: 0.138753\n",
      "Train Epoch: 5 [1000/11194 (9%)]\tLoss: 0.081283\n",
      "Train Epoch: 5 [2000/11194 (18%)]\tLoss: 0.101224\n",
      "Train Epoch: 5 [3000/11194 (27%)]\tLoss: 0.119808\n",
      "Train Epoch: 5 [4000/11194 (36%)]\tLoss: 0.113441\n",
      "Train Epoch: 5 [5000/11194 (45%)]\tLoss: 0.184104\n",
      "Train Epoch: 5 [6000/11194 (54%)]\tLoss: 0.172898\n",
      "Train Epoch: 5 [7000/11194 (62%)]\tLoss: 0.110354\n",
      "Train Epoch: 5 [8000/11194 (71%)]\tLoss: 0.150330\n",
      "Train Epoch: 5 [9000/11194 (80%)]\tLoss: 0.111567\n",
      "Train Epoch: 5 [10000/11194 (89%)]\tLoss: 0.124176\n",
      "Train Epoch: 5 [11000/11194 (98%)]\tLoss: 0.111011\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "8\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4301, Accuracy: 8566/10000 (86%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/7731 (0%)]\tLoss: 0.185816\n",
      "Train Epoch: 1 [1000/7731 (13%)]\tLoss: 0.235536\n",
      "Train Epoch: 1 [2000/7731 (26%)]\tLoss: 0.066460\n",
      "Train Epoch: 1 [3000/7731 (38%)]\tLoss: 0.175310\n",
      "Train Epoch: 1 [4000/7731 (51%)]\tLoss: 0.036101\n",
      "Train Epoch: 1 [5000/7731 (64%)]\tLoss: 0.075361\n",
      "Train Epoch: 1 [6000/7731 (77%)]\tLoss: 0.250038\n",
      "Train Epoch: 1 [7000/7731 (90%)]\tLoss: 0.100390\n",
      "Train Epoch: 2 [0/7731 (0%)]\tLoss: 0.090793\n",
      "Train Epoch: 2 [1000/7731 (13%)]\tLoss: 0.093653\n",
      "Train Epoch: 2 [2000/7731 (26%)]\tLoss: 0.103609\n",
      "Train Epoch: 2 [3000/7731 (38%)]\tLoss: 0.095310\n",
      "Train Epoch: 2 [4000/7731 (51%)]\tLoss: 0.086027\n",
      "Train Epoch: 2 [5000/7731 (64%)]\tLoss: 0.111383\n",
      "Train Epoch: 2 [6000/7731 (77%)]\tLoss: 0.061236\n",
      "Train Epoch: 2 [7000/7731 (90%)]\tLoss: 0.142012\n",
      "Train Epoch: 3 [0/7731 (0%)]\tLoss: 0.167750\n",
      "Train Epoch: 3 [1000/7731 (13%)]\tLoss: 0.140000\n",
      "Train Epoch: 3 [2000/7731 (26%)]\tLoss: 0.208523\n",
      "Train Epoch: 3 [3000/7731 (38%)]\tLoss: 0.132908\n",
      "Train Epoch: 3 [4000/7731 (51%)]\tLoss: 0.159899\n",
      "Train Epoch: 3 [5000/7731 (64%)]\tLoss: 0.071935\n",
      "Train Epoch: 3 [6000/7731 (77%)]\tLoss: 0.090912\n",
      "Train Epoch: 3 [7000/7731 (90%)]\tLoss: 0.202073\n",
      "Train Epoch: 4 [0/7731 (0%)]\tLoss: 0.057977\n",
      "Train Epoch: 4 [1000/7731 (13%)]\tLoss: 0.085243\n",
      "Train Epoch: 4 [2000/7731 (26%)]\tLoss: 0.059850\n",
      "Train Epoch: 4 [3000/7731 (38%)]\tLoss: 0.146128\n",
      "Train Epoch: 4 [4000/7731 (51%)]\tLoss: 0.096278\n",
      "Train Epoch: 4 [5000/7731 (64%)]\tLoss: 0.054019\n",
      "Train Epoch: 4 [6000/7731 (77%)]\tLoss: 0.069305\n",
      "Train Epoch: 4 [7000/7731 (90%)]\tLoss: 0.134383\n",
      "Train Epoch: 5 [0/7731 (0%)]\tLoss: 0.121187\n",
      "Train Epoch: 5 [1000/7731 (13%)]\tLoss: 0.052744\n",
      "Train Epoch: 5 [2000/7731 (26%)]\tLoss: 0.030343\n",
      "Train Epoch: 5 [3000/7731 (38%)]\tLoss: 0.143935\n",
      "Train Epoch: 5 [4000/7731 (51%)]\tLoss: 0.045698\n",
      "Train Epoch: 5 [5000/7731 (64%)]\tLoss: 0.052680\n",
      "Train Epoch: 5 [6000/7731 (77%)]\tLoss: 0.039221\n",
      "Train Epoch: 5 [7000/7731 (90%)]\tLoss: 0.135926\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11194 (0%)]\tLoss: 0.370325\n",
      "Train Epoch: 1 [1000/11194 (9%)]\tLoss: 0.124448\n",
      "Train Epoch: 1 [2000/11194 (18%)]\tLoss: 0.196289\n",
      "Train Epoch: 1 [3000/11194 (27%)]\tLoss: 0.108653\n",
      "Train Epoch: 1 [4000/11194 (36%)]\tLoss: 0.070015\n",
      "Train Epoch: 1 [5000/11194 (45%)]\tLoss: 0.097832\n",
      "Train Epoch: 1 [6000/11194 (54%)]\tLoss: 0.092166\n",
      "Train Epoch: 1 [7000/11194 (62%)]\tLoss: 0.130300\n",
      "Train Epoch: 1 [8000/11194 (71%)]\tLoss: 0.126451\n",
      "Train Epoch: 1 [9000/11194 (80%)]\tLoss: 0.097106\n",
      "Train Epoch: 1 [10000/11194 (89%)]\tLoss: 0.197207\n",
      "Train Epoch: 1 [11000/11194 (98%)]\tLoss: 0.206107\n",
      "Train Epoch: 2 [0/11194 (0%)]\tLoss: 0.075343\n",
      "Train Epoch: 2 [1000/11194 (9%)]\tLoss: 0.171136\n",
      "Train Epoch: 2 [2000/11194 (18%)]\tLoss: 0.129426\n",
      "Train Epoch: 2 [3000/11194 (27%)]\tLoss: 0.045239\n",
      "Train Epoch: 2 [4000/11194 (36%)]\tLoss: 0.090265\n",
      "Train Epoch: 2 [5000/11194 (45%)]\tLoss: 0.103606\n",
      "Train Epoch: 2 [6000/11194 (54%)]\tLoss: 0.100263\n",
      "Train Epoch: 2 [7000/11194 (62%)]\tLoss: 0.088680\n",
      "Train Epoch: 2 [8000/11194 (71%)]\tLoss: 0.142510\n",
      "Train Epoch: 2 [9000/11194 (80%)]\tLoss: 0.117252\n",
      "Train Epoch: 2 [10000/11194 (89%)]\tLoss: 0.104229\n",
      "Train Epoch: 2 [11000/11194 (98%)]\tLoss: 0.090725\n",
      "Train Epoch: 3 [0/11194 (0%)]\tLoss: 0.163288\n",
      "Train Epoch: 3 [1000/11194 (9%)]\tLoss: 0.091891\n",
      "Train Epoch: 3 [2000/11194 (18%)]\tLoss: 0.072413\n",
      "Train Epoch: 3 [3000/11194 (27%)]\tLoss: 0.142335\n",
      "Train Epoch: 3 [4000/11194 (36%)]\tLoss: 0.140360\n",
      "Train Epoch: 3 [5000/11194 (45%)]\tLoss: 0.184730\n",
      "Train Epoch: 3 [6000/11194 (54%)]\tLoss: 0.095652\n",
      "Train Epoch: 3 [7000/11194 (62%)]\tLoss: 0.121264\n",
      "Train Epoch: 3 [8000/11194 (71%)]\tLoss: 0.088190\n",
      "Train Epoch: 3 [9000/11194 (80%)]\tLoss: 0.177880\n",
      "Train Epoch: 3 [10000/11194 (89%)]\tLoss: 0.229168\n",
      "Train Epoch: 3 [11000/11194 (98%)]\tLoss: 0.138490\n",
      "Train Epoch: 4 [0/11194 (0%)]\tLoss: 0.113279\n",
      "Train Epoch: 4 [1000/11194 (9%)]\tLoss: 0.062360\n",
      "Train Epoch: 4 [2000/11194 (18%)]\tLoss: 0.127612\n",
      "Train Epoch: 4 [3000/11194 (27%)]\tLoss: 0.072064\n",
      "Train Epoch: 4 [4000/11194 (36%)]\tLoss: 0.061164\n",
      "Train Epoch: 4 [5000/11194 (45%)]\tLoss: 0.091442\n",
      "Train Epoch: 4 [6000/11194 (54%)]\tLoss: 0.138210\n",
      "Train Epoch: 4 [7000/11194 (62%)]\tLoss: 0.118209\n",
      "Train Epoch: 4 [8000/11194 (71%)]\tLoss: 0.096209\n",
      "Train Epoch: 4 [9000/11194 (80%)]\tLoss: 0.097299\n",
      "Train Epoch: 4 [10000/11194 (89%)]\tLoss: 0.109850\n",
      "Train Epoch: 4 [11000/11194 (98%)]\tLoss: 0.204481\n",
      "Train Epoch: 5 [0/11194 (0%)]\tLoss: 0.142875\n",
      "Train Epoch: 5 [1000/11194 (9%)]\tLoss: 0.099946\n",
      "Train Epoch: 5 [2000/11194 (18%)]\tLoss: 0.112581\n",
      "Train Epoch: 5 [3000/11194 (27%)]\tLoss: 0.144900\n",
      "Train Epoch: 5 [4000/11194 (36%)]\tLoss: 0.126749\n",
      "Train Epoch: 5 [5000/11194 (45%)]\tLoss: 0.099290\n",
      "Train Epoch: 5 [6000/11194 (54%)]\tLoss: 0.099815\n",
      "Train Epoch: 5 [7000/11194 (62%)]\tLoss: 0.100573\n",
      "Train Epoch: 5 [8000/11194 (71%)]\tLoss: 0.176145\n",
      "Train Epoch: 5 [9000/11194 (80%)]\tLoss: 0.112449\n",
      "Train Epoch: 5 [10000/11194 (89%)]\tLoss: 0.055523\n",
      "Train Epoch: 5 [11000/11194 (98%)]\tLoss: 0.083822\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "8\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4149, Accuracy: 8604/10000 (86%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/7731 (0%)]\tLoss: 0.149336\n",
      "Train Epoch: 1 [1000/7731 (13%)]\tLoss: 0.126503\n",
      "Train Epoch: 1 [2000/7731 (26%)]\tLoss: 0.100952\n",
      "Train Epoch: 1 [3000/7731 (38%)]\tLoss: 0.100274\n",
      "Train Epoch: 1 [4000/7731 (51%)]\tLoss: 0.118336\n",
      "Train Epoch: 1 [5000/7731 (64%)]\tLoss: 0.075667\n",
      "Train Epoch: 1 [6000/7731 (77%)]\tLoss: 0.128426\n",
      "Train Epoch: 1 [7000/7731 (90%)]\tLoss: 0.039794\n",
      "Train Epoch: 2 [0/7731 (0%)]\tLoss: 0.119464\n",
      "Train Epoch: 2 [1000/7731 (13%)]\tLoss: 0.055633\n",
      "Train Epoch: 2 [2000/7731 (26%)]\tLoss: 0.170673\n",
      "Train Epoch: 2 [3000/7731 (38%)]\tLoss: 0.033213\n",
      "Train Epoch: 2 [4000/7731 (51%)]\tLoss: 0.094087\n",
      "Train Epoch: 2 [5000/7731 (64%)]\tLoss: 0.093963\n",
      "Train Epoch: 2 [6000/7731 (77%)]\tLoss: 0.105966\n",
      "Train Epoch: 2 [7000/7731 (90%)]\tLoss: 0.070680\n",
      "Train Epoch: 3 [0/7731 (0%)]\tLoss: 0.115385\n",
      "Train Epoch: 3 [1000/7731 (13%)]\tLoss: 0.122760\n",
      "Train Epoch: 3 [2000/7731 (26%)]\tLoss: 0.086423\n",
      "Train Epoch: 3 [3000/7731 (38%)]\tLoss: 0.066244\n",
      "Train Epoch: 3 [4000/7731 (51%)]\tLoss: 0.074564\n",
      "Train Epoch: 3 [5000/7731 (64%)]\tLoss: 0.121470\n",
      "Train Epoch: 3 [6000/7731 (77%)]\tLoss: 0.189143\n",
      "Train Epoch: 3 [7000/7731 (90%)]\tLoss: 0.169203\n",
      "Train Epoch: 4 [0/7731 (0%)]\tLoss: 0.086466\n",
      "Train Epoch: 4 [1000/7731 (13%)]\tLoss: 0.106637\n",
      "Train Epoch: 4 [2000/7731 (26%)]\tLoss: 0.067685\n",
      "Train Epoch: 4 [3000/7731 (38%)]\tLoss: 0.080317\n",
      "Train Epoch: 4 [4000/7731 (51%)]\tLoss: 0.078914\n",
      "Train Epoch: 4 [5000/7731 (64%)]\tLoss: 0.083894\n",
      "Train Epoch: 4 [6000/7731 (77%)]\tLoss: 0.097967\n",
      "Train Epoch: 4 [7000/7731 (90%)]\tLoss: 0.079309\n",
      "Train Epoch: 5 [0/7731 (0%)]\tLoss: 0.114214\n",
      "Train Epoch: 5 [1000/7731 (13%)]\tLoss: 0.064102\n",
      "Train Epoch: 5 [2000/7731 (26%)]\tLoss: 0.037047\n",
      "Train Epoch: 5 [3000/7731 (38%)]\tLoss: 0.085186\n",
      "Train Epoch: 5 [4000/7731 (51%)]\tLoss: 0.066728\n",
      "Train Epoch: 5 [5000/7731 (64%)]\tLoss: 0.048444\n",
      "Train Epoch: 5 [6000/7731 (77%)]\tLoss: 0.080548\n",
      "Train Epoch: 5 [7000/7731 (90%)]\tLoss: 0.047524\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11194 (0%)]\tLoss: 0.294678\n",
      "Train Epoch: 1 [1000/11194 (9%)]\tLoss: 0.090391\n",
      "Train Epoch: 1 [2000/11194 (18%)]\tLoss: 0.153381\n",
      "Train Epoch: 1 [3000/11194 (27%)]\tLoss: 0.112530\n",
      "Train Epoch: 1 [4000/11194 (36%)]\tLoss: 0.181873\n",
      "Train Epoch: 1 [5000/11194 (45%)]\tLoss: 0.130398\n",
      "Train Epoch: 1 [6000/11194 (54%)]\tLoss: 0.148054\n",
      "Train Epoch: 1 [7000/11194 (62%)]\tLoss: 0.106444\n",
      "Train Epoch: 1 [8000/11194 (71%)]\tLoss: 0.131603\n",
      "Train Epoch: 1 [9000/11194 (80%)]\tLoss: 0.196587\n",
      "Train Epoch: 1 [10000/11194 (89%)]\tLoss: 0.113884\n",
      "Train Epoch: 1 [11000/11194 (98%)]\tLoss: 0.112225\n",
      "Train Epoch: 2 [0/11194 (0%)]\tLoss: 0.113694\n",
      "Train Epoch: 2 [1000/11194 (9%)]\tLoss: 0.063617\n",
      "Train Epoch: 2 [2000/11194 (18%)]\tLoss: 0.103060\n",
      "Train Epoch: 2 [3000/11194 (27%)]\tLoss: 0.102539\n",
      "Train Epoch: 2 [4000/11194 (36%)]\tLoss: 0.115901\n",
      "Train Epoch: 2 [5000/11194 (45%)]\tLoss: 0.143868\n",
      "Train Epoch: 2 [6000/11194 (54%)]\tLoss: 0.125787\n",
      "Train Epoch: 2 [7000/11194 (62%)]\tLoss: 0.176799\n",
      "Train Epoch: 2 [8000/11194 (71%)]\tLoss: 0.124050\n",
      "Train Epoch: 2 [9000/11194 (80%)]\tLoss: 0.080788\n",
      "Train Epoch: 2 [10000/11194 (89%)]\tLoss: 0.147768\n",
      "Train Epoch: 2 [11000/11194 (98%)]\tLoss: 0.110582\n",
      "Train Epoch: 3 [0/11194 (0%)]\tLoss: 0.100828\n",
      "Train Epoch: 3 [1000/11194 (9%)]\tLoss: 0.104062\n",
      "Train Epoch: 3 [2000/11194 (18%)]\tLoss: 0.138521\n",
      "Train Epoch: 3 [3000/11194 (27%)]\tLoss: 0.088182\n",
      "Train Epoch: 3 [4000/11194 (36%)]\tLoss: 0.100240\n",
      "Train Epoch: 3 [5000/11194 (45%)]\tLoss: 0.063251\n",
      "Train Epoch: 3 [6000/11194 (54%)]\tLoss: 0.144905\n",
      "Train Epoch: 3 [7000/11194 (62%)]\tLoss: 0.109257\n",
      "Train Epoch: 3 [8000/11194 (71%)]\tLoss: 0.092058\n",
      "Train Epoch: 3 [9000/11194 (80%)]\tLoss: 0.089066\n",
      "Train Epoch: 3 [10000/11194 (89%)]\tLoss: 0.134504\n",
      "Train Epoch: 3 [11000/11194 (98%)]\tLoss: 0.118370\n",
      "Train Epoch: 4 [0/11194 (0%)]\tLoss: 0.104278\n",
      "Train Epoch: 4 [1000/11194 (9%)]\tLoss: 0.084095\n",
      "Train Epoch: 4 [2000/11194 (18%)]\tLoss: 0.119552\n",
      "Train Epoch: 4 [3000/11194 (27%)]\tLoss: 0.106692\n",
      "Train Epoch: 4 [4000/11194 (36%)]\tLoss: 0.156742\n",
      "Train Epoch: 4 [5000/11194 (45%)]\tLoss: 0.111615\n",
      "Train Epoch: 4 [6000/11194 (54%)]\tLoss: 0.114283\n",
      "Train Epoch: 4 [7000/11194 (62%)]\tLoss: 0.063021\n",
      "Train Epoch: 4 [8000/11194 (71%)]\tLoss: 0.116530\n",
      "Train Epoch: 4 [9000/11194 (80%)]\tLoss: 0.067674\n",
      "Train Epoch: 4 [10000/11194 (89%)]\tLoss: 0.085949\n",
      "Train Epoch: 4 [11000/11194 (98%)]\tLoss: 0.073064\n",
      "Train Epoch: 5 [0/11194 (0%)]\tLoss: 0.100327\n",
      "Train Epoch: 5 [1000/11194 (9%)]\tLoss: 0.043711\n",
      "Train Epoch: 5 [2000/11194 (18%)]\tLoss: 0.077813\n",
      "Train Epoch: 5 [3000/11194 (27%)]\tLoss: 0.109497\n",
      "Train Epoch: 5 [4000/11194 (36%)]\tLoss: 0.072228\n",
      "Train Epoch: 5 [5000/11194 (45%)]\tLoss: 0.113413\n",
      "Train Epoch: 5 [6000/11194 (54%)]\tLoss: 0.109221\n",
      "Train Epoch: 5 [7000/11194 (62%)]\tLoss: 0.097330\n",
      "Train Epoch: 5 [8000/11194 (71%)]\tLoss: 0.073422\n",
      "Train Epoch: 5 [9000/11194 (80%)]\tLoss: 0.026219\n",
      "Train Epoch: 5 [10000/11194 (89%)]\tLoss: 0.081392\n",
      "Train Epoch: 5 [11000/11194 (98%)]\tLoss: 0.111551\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "8\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4176, Accuracy: 8609/10000 (86%)\n",
      "\n",
      "Running experiment with 10 partitions...\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.193846\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 0.258454\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 0.278082\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 0.247663\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 0.299239\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 0.159852\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 0.301984\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 0.219667\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.248878\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 0.136375\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.229488\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 0.320167\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.272981\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 0.288385\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 0.363055\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.315425\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.156082\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 0.279397\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 0.268346\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 0.208262\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.361701\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 0.241524\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.221521\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 0.305377\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.250726\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.291434\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.281504\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 0.208781\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.293436\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 0.321030\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.282145\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 0.317603\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.262353\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 0.171316\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.193050\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.295746\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.298949\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 0.234177\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.204571\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 0.303726\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.257879\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 0.298604\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.203910\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 0.218561\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.274898\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.160760\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.243860\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 0.220369\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.216612\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 0.222033\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.263002\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 0.336880\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.283064\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 0.244725\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.296127\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.230549\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.149970\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 0.299499\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.230879\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 0.259044\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.180157\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 0.276131\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.561043\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 0.183672\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.233596\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.381940\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.237100\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 0.208058\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.151837\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 0.249188\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.172535\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 0.388610\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.347146\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 0.312531\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.339197\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.350745\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.120028\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 0.213667\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.368036\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 0.306315\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.187526\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 0.255866\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.216365\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 0.285984\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.255577\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.270113\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.270562\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 0.229866\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.287810\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 0.329601\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.232430\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 0.320060\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.219433\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 0.223142\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.333459\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.269618\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.252257\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 0.330229\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.255709\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 0.197280\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.156140\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 0.309133\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.354756\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 0.381324\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.302834\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.287516\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.306610\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 0.273703\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.262283\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 0.363262\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.306808\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 0.367792\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.280877\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 0.377860\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.200013\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.172460\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.276643\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 0.181837\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.271152\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 0.240547\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.256872\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 0.303229\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.384766\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 0.193380\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.241445\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.243978\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.248766\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 0.305571\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.213755\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 0.271928\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.240333\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 0.292181\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.192680\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 0.163696\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.194946\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.280157\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.232277\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 0.218326\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.206002\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 0.249571\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.276421\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 0.211295\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.283056\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 0.352550\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.317915\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.325316\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.293152\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 0.265109\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.211433\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 0.251224\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.201631\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 0.276548\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.304363\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 0.254258\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.320720\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.224370\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.242266\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 0.198028\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.286068\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 0.211345\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.214743\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 0.218357\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.373267\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 0.164914\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.184761\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.342303\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.329023\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 0.211693\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.251532\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 0.410123\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.291168\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 0.240648\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.245598\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 0.334511\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.178955\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.188292\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.186598\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 0.278461\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.327885\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 0.219739\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.215872\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 0.212033\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.198588\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 0.322285\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.220771\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.151292\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.203423\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 0.218087\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.278366\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 0.319505\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.189531\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 0.240341\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.315583\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 0.290372\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.322586\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.345692\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.228458\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 0.286368\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.269060\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 0.216807\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.266819\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 0.248556\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.231515\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 0.230141\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.399305\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.292387\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.216970\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 0.271288\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.269818\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 0.413288\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.253521\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 0.179601\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.228584\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 0.170015\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.211967\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.282411\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.416233\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 0.322557\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.298529\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 0.296968\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.296495\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 0.259652\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.243113\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 0.205775\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.215189\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.207433\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.311464\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 0.255791\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.254331\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 0.203276\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.269474\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 0.172609\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.213861\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 0.260679\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.176844\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.327840\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.244910\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 0.176437\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.256320\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 0.373459\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.239405\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 0.152932\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.137723\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 0.414283\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.309162\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.220763\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.206590\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 0.232581\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.227665\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 0.234333\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.247204\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 0.233540\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.239114\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 0.266465\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.261293\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.304806\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.133351\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 0.182292\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.228186\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 0.288796\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.186465\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 0.179299\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.175614\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 0.214704\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.243639\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.215219\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.281772\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 0.250088\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.200931\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 0.298459\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.145349\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 0.193089\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.317913\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 0.275177\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.175194\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.445456\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.162777\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 0.232571\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.329014\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 0.257121\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.243390\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 0.294251\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.152424\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 0.187966\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.269423\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.280236\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.183972\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 0.248168\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.215055\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 0.252522\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.270175\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 0.215613\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.216577\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 0.349214\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.199368\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.186331\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.208551\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 0.196700\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.285302\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 0.228601\n",
      "\n",
      "Test set: Avg. loss: 0.2486, Accuracy: 54727/60000 (91%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.435207\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.243636\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.183053\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.235887\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.181628\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.172204\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.247610\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.236732\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.186678\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.139975\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.189616\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.296395\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.202541\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.198000\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.164190\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.178783\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.041497\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.127772\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.076086\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.072569\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.070289\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.063673\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.040659\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.082501\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.032871\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.076294\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.028547\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.054861\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.062881\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.083545\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.066240\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.186525\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.044648\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.045163\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.085946\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.023303\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.127576\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.115743\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.062931\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.139667\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.125088\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.038053\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.049931\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.091252\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.076158\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.020072\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.030534\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.024108\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.012402\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.062006\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.044805\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.081959\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.134198\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.069143\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.069532\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.104758\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.118663\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.075659\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.028900\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.074017\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.092543\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.135220\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.084579\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.065400\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.042100\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.155931\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.111584\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.128331\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.117100\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.092119\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.101270\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.071917\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.092979\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.090045\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.134063\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.095299\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.137999\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.143688\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.141490\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.081182\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.054871\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.109609\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.024231\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.080734\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.054608\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.124166\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.056241\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.069420\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.028802\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.104788\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.256326\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.079718\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.116736\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.143431\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.118230\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.091627\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.059463\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.160266\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.115622\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.148096\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.297691\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.105019\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.052171\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.112990\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.163187\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.099749\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.089536\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.257328\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.105351\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.060107\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.139495\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.164775\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.124816\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.226157\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.105151\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.062524\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.096819\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.151072\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.116911\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.084820\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.186539\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.126549\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.205558\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.237523\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.189700\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.127325\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.273294\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.246017\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.263812\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.124655\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.077365\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.396985\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.211526\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.328049\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.218934\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.239337\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.278834\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.179805\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.156815\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.183613\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.156478\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.092619\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.136841\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.196941\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.223122\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.160976\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.096606\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.243789\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.116439\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.185731\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.220819\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.229284\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.279542\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.258800\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.201586\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.159169\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.114730\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.151860\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.165385\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.129758\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.221107\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.090788\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.154396\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.286881\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.153088\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.177341\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.137457\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.274507\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.148584\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.224670\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.483495\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.193059\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.373533\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.349304\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.269138\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.278706\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.276803\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.300681\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.253962\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.199379\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.211070\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.266047\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.163111\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.279073\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.210097\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.213737\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.255708\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.215671\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.388773\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.218994\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.205054\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.213079\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.271097\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.173669\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.305324\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.261261\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.392265\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.239966\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.230976\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.178438\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.206711\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.175433\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.264504\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.203698\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.262371\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.276685\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.145697\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.174876\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.232173\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.245519\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.245188\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.132388\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.366841\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.201742\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.221030\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.228743\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.255370\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.316077\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.181519\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.169122\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.260083\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.071073\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.105483\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.175786\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.086219\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.221554\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.318266\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.154248\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.132851\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.056415\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.198195\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.088072\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.104854\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.083179\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.216748\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.137748\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.108917\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.117809\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.124674\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.107668\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.167148\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.100115\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.156481\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.164119\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.050249\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.133537\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.071367\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.124188\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.205736\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.071266\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.077387\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.099776\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.110139\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.065146\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.087613\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.431451\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.338492\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.177339\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.155401\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.180473\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.338749\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.146682\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.273248\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.201773\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.157425\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.171006\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.152744\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.200626\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.179567\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.219460\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.263302\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.185826\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.219452\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.281983\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.247827\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.189158\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.200917\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.261383\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.186304\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.119598\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.171694\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.203415\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.170197\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.173651\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.270422\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.132386\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.187455\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.174838\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.142113\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.257803\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.178897\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.199446\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.177355\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.089517\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.246302\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.069982\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.118796\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.105124\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.097318\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.183435\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.123191\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.229340\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.068670\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.202631\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.144219\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.131841\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.125749\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.119267\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.267765\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.149355\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.105995\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.116789\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.167834\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.171276\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.065301\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.083116\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.226060\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.128537\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.100653\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.136605\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.111402\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.131553\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.063546\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.113258\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.138126\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.3591, Accuracy: 8747/10000 (87%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.231139\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.204682\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.230793\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.234683\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.206807\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.216042\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.226292\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.127243\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.184289\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.251071\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.210069\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.133915\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.146929\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.165134\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.215194\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.302348\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.147414\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.024123\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.088476\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.100172\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.091849\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.148704\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.079029\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.047630\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.125613\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.059323\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.016541\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.059841\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.143191\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.033903\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.065657\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.059063\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.069993\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.075894\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.021972\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.040447\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.067839\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.072804\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.099703\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.052381\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.071928\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.058276\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.033444\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.066569\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.047159\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.058113\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.075579\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.082108\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.111293\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.034249\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.051066\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.072509\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.026173\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.075745\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.096506\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.090120\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.101214\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.083243\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.052971\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.094086\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.234382\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.096698\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.117179\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.116860\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.095844\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.081672\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.074780\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.162463\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.084892\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.136459\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.069602\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.063562\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.064388\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.041240\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.047972\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.072255\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.049597\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.050001\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.046828\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.081697\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.031948\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.061210\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.060956\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.148523\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.070680\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.067239\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.030766\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.059248\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.031210\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.099299\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.354353\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.130864\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.112268\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.118466\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.133440\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.159865\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.064568\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.130894\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.147812\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.140321\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.139573\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.162717\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.082514\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.075430\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.104700\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.117458\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.183312\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.107633\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.081149\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.076614\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.128546\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.148413\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.122052\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.088761\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.192994\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.100532\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.231069\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.111733\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.063646\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.097594\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.304265\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.147170\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.134016\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.161532\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.145913\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.140290\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.243491\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.221535\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.145480\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.121187\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.161779\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.141684\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.145989\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.149903\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.111955\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.130572\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.186491\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.173853\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.206717\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.102596\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.232977\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.106461\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.168539\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.194537\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.156750\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.067944\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.163266\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.134907\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.182435\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.119476\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.247460\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.203745\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.188275\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.258001\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.182240\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.243031\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.240572\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.100704\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.105935\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.183154\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.174649\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.212139\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.192485\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.174665\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.181652\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.112104\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.167834\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.173101\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.212421\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.343918\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.239023\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.302991\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.228605\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.289314\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.279994\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.178754\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.314665\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.421317\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.238091\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.256788\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.265569\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.236767\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.151880\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.319912\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.185715\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.165141\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.198611\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.326120\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.278185\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.233458\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.208774\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.150498\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.230969\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.205337\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.220151\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.282049\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.179130\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.158865\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.239428\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.193713\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.261945\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.166856\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.287957\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.218055\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.185068\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.304603\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.294068\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.258633\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.176491\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.175620\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.230606\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.166595\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.085063\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.200707\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.202172\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.289795\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.252745\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.256465\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.192258\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.182723\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.287816\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.138934\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.088535\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.050753\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.227047\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.144981\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.092657\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.079312\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.159394\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.106286\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.117437\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.182802\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.094211\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.185688\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.123717\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.138898\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.124082\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.026038\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.093837\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.149311\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.066261\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.114954\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.187014\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.057700\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.123825\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.081027\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.060110\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.125605\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.097598\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.129530\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.239435\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.078398\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.236209\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.103660\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.337414\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.426063\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.228625\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.264622\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.310148\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.144090\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.245181\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.281390\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.333531\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.117173\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.092054\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.240550\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.114917\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.089946\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.250796\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.176736\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.294170\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.090756\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.251912\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.167582\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.162159\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.219793\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.138267\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.215686\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.224675\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.111061\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.204885\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.250607\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.098060\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.260619\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.055082\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.093843\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.265513\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.128978\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.168377\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.261102\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.206410\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.187419\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.197113\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.083759\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.225828\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.363146\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.197659\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.098965\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.233002\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.109074\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.117796\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.097702\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.186333\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.111674\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.108391\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.134869\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.132262\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.080387\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.164652\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.099735\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.109806\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.193283\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.073131\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.127842\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.160636\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.149580\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.185753\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.048076\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.111371\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.117850\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.120353\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.122858\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.076810\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.115979\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.098953\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.3577, Accuracy: 8751/10000 (88%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.276080\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.379878\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.292027\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.161701\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.185022\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.167640\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.207072\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.200356\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.246098\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.130353\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.150584\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.221084\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.152510\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.177060\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.159817\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.243906\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.089356\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.076165\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.103317\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.085276\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.051613\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.030427\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.087480\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.087721\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.058781\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.053823\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.142806\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.110192\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.100856\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.057456\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.111431\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.101585\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.033873\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.029666\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.050664\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.030575\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.095035\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.122373\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.071770\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.098757\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.065669\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.096737\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.058373\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.047108\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.021681\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.124905\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.045481\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.103664\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.042766\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.046117\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.050742\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.053769\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.145241\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.092180\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.024932\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.135865\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.088519\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.067616\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.059005\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.128765\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.086473\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.056810\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.071566\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.113706\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.101555\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.129478\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.068301\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.115262\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.033578\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.081545\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.071957\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.058618\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.059163\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.035637\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.066105\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.061039\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.083422\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.050611\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.072938\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.045214\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.078604\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.023730\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.055260\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.111363\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.038961\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.062042\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.066304\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.091344\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.043126\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.052541\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.244260\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.150609\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.100375\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.169057\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.222726\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.112138\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.178518\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.056657\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.090189\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.124937\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.148602\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.076738\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.152883\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.138061\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.169764\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.095352\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.157381\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.120468\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.148551\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.110393\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.100684\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.097397\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.149501\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.088366\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.081970\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.080091\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.125830\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.135451\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.192227\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.093563\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.223292\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.241881\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.137480\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.211282\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.081733\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.158514\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.148957\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.164521\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.146556\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.150661\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.241535\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.137893\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.167146\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.200827\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.099315\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.117632\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.132374\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.217561\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.081172\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.112453\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.190700\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.145216\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.131445\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.147946\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.109645\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.154905\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.173013\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.218233\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.148661\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.141375\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.175398\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.127784\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.205228\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.219948\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.249368\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.214391\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.082552\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.181081\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.138591\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.247252\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.206075\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.350921\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.136151\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.161646\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.225797\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.128171\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.195822\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.148177\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.241660\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.257468\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.253836\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.346445\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.236868\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.262416\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.280751\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.412601\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.327254\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.247017\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.287443\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.399593\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.197840\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.163119\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.163543\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.214172\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.278180\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.325012\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.187231\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.261175\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.165290\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.244973\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.259352\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.158393\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.270325\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.152508\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.237977\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.350807\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.299674\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.160030\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.257922\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.155141\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.247904\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.208971\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.254595\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.161420\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.238930\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.234554\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.294803\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.276338\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.264998\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.207300\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.169658\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.214246\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.163182\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.368759\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.182866\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.174869\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.227928\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.161904\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.163533\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.173082\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.513994\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.074168\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.115775\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.089320\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.242384\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.143704\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.140075\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.135459\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.106395\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.129299\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.119388\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.114522\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.171512\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.133586\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.178364\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.153700\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.090307\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.068338\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.094812\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.131106\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.083794\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.065886\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.133826\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.131824\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.052050\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.159526\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.040992\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.189146\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.139460\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.068026\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.125482\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.060514\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.134363\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.079767\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.067206\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.265691\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.254876\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.299767\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.205826\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.175425\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.141167\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.277576\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.302522\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.164271\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.131218\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.156240\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.169929\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.264852\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.178885\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.109431\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.169213\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.077219\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.193341\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.147568\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.155852\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.254911\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.296078\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.099484\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.190854\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.218137\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.268907\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.156167\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.118863\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.173167\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.121717\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.152255\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.154200\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.246004\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.191059\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.138926\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.148963\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.087742\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.147708\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.171416\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.350824\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.213903\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.180497\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.199665\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.085887\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.103981\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.126803\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.178854\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.142364\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.162952\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.066195\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.055355\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.072748\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.129216\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.172882\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.154362\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.159266\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.149983\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.162861\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.053918\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.094463\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.126235\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.138077\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.095562\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.055719\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.074903\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.139472\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.085394\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.057459\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.112487\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.081419\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.3514, Accuracy: 8763/10000 (88%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.202716\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.168514\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.438704\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.186960\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.206923\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.155579\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.202315\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.151740\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.167049\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.205270\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.142010\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.164939\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.157779\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.182610\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.184547\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.236644\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.083638\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.076217\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.142008\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.129583\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.027482\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.092345\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.166358\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.072202\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.059659\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.063780\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.100788\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.107862\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.098740\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.060015\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.095447\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.055822\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.086107\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.065848\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.162182\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.044507\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.059870\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.053164\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.087651\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.037234\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.099786\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.025173\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.115057\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.075342\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.126820\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.065061\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.088387\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.060487\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.051730\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.101084\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.061130\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.092635\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.019314\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.082268\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.051627\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.166086\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.120952\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.099263\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.078761\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.097167\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.113375\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.077701\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.348916\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.118930\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.047340\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.156921\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.064268\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.056945\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.034117\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.037009\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.102725\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.082823\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.185218\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.077164\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.105015\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.028271\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.078042\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.103886\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.057636\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.040717\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.192271\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.078403\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.062133\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.100760\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.033338\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.105694\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.092692\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.089573\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.047302\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.044203\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.221830\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.142484\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.225460\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.093351\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.129837\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.229839\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.089470\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.134232\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.161623\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.116444\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.126256\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.125395\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.144854\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.062803\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.132297\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.121428\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.119238\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.095159\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.118231\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.160736\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.117357\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.071758\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.110992\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.094429\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.147024\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.075274\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.046600\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.085891\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.110230\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.161170\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.254515\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.183990\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.165182\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.198980\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.290249\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.199636\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.203286\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.138896\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.187538\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.108851\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.176992\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.140917\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.112767\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.144552\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.202060\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.136012\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.171190\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.210461\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.150530\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.124231\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.205573\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.149029\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.192015\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.134305\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.137951\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.299394\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.212961\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.113707\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.108732\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.102204\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.272178\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.197208\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.175922\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.175312\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.138064\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.268285\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.260824\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.141547\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.191487\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.119792\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.294144\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.118992\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.196240\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.140490\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.101722\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.261435\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.052388\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.094719\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.158500\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.160700\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.405779\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.263658\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.326269\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.252709\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.261503\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.280040\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.314059\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.209802\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.145575\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.324119\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.285452\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.196802\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.121626\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.301897\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.231949\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.319970\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.203968\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.184854\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.121778\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.339761\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.228620\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.177292\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.467564\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.239030\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.180679\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.137007\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.177454\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.196870\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.306301\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.145265\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.227960\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.379816\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.198502\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.189777\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.150408\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.200089\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.095709\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.106503\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.176925\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.176282\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.186354\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.294933\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.226322\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.155236\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.161310\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.176435\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.201172\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.155158\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.172914\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.205427\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.363322\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.179736\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.174121\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.137799\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.169992\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.051877\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.277949\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.194681\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.174133\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.174094\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.122931\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.066858\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.132012\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.123221\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.085538\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.068757\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.100316\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.144544\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.050299\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.203231\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.197311\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.119821\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.061899\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.101822\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.144352\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.101847\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.121948\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.037267\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.081844\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.078391\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.119196\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.146855\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.185466\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.118367\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.127494\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.412811\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.170839\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.143425\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.184497\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.182722\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.180883\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.174236\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.172208\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.216670\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.158722\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.256221\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.186620\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.217988\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.243977\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.138798\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.127211\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.234822\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.148318\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.140186\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.164660\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.095170\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.106749\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.134721\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.102515\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.266323\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.224776\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.173392\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.192910\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.112270\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.141347\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.153539\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.177554\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.179253\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.249123\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.132855\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.159702\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.133597\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.163721\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.084529\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.114694\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.147580\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.248169\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.093894\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.248950\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.049835\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.083010\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.142339\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.081621\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.112326\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.172096\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.056583\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.233669\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.080472\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.147558\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.072201\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.126822\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.159547\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.121223\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.145091\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.154687\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.103548\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.133858\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.127776\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.092857\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.058237\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.111441\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.142339\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.251700\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.072537\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.080159\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.3532, Accuracy: 8749/10000 (87%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.216749\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.292013\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.163320\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.179982\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.181977\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.256750\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.162113\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.101055\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.218984\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.213741\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.108969\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.212730\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.111948\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.153050\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.146698\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.267046\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.126335\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.248567\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.041562\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.076456\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.051034\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.083452\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.057175\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.074579\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.064329\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.078923\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.070946\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.047917\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.104797\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.131543\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.046364\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.099514\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.079076\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.027686\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.083913\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.065077\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.111661\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.089636\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.052941\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.022923\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.055884\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.041776\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.051307\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.066561\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.023070\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.059356\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.059766\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.048310\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.084090\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.038444\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.047612\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.100386\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.085363\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.035288\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.054722\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4234, Accuracy: 8515/10000 (85%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.235914\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.194192\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.268015\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.171562\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.170320\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.178407\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.166262\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.158073\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.196729\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.134020\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.101079\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.155221\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.132484\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.152591\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.113256\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.116796\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.047590\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.032738\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.113188\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.062863\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.052355\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.018994\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.074058\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.067883\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.107083\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.018621\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.028603\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.023973\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.062388\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.106303\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.122164\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.040423\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.081428\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.071960\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.038427\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.035168\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.138215\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.046818\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.040231\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.090031\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.057735\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.107072\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.055651\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.056575\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.044775\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.114460\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.056150\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.018435\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.055678\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.047313\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.046339\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.058542\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.072949\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.054863\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.047177\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4306, Accuracy: 8517/10000 (85%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.198813\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.182909\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.168068\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.225784\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.143737\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.200870\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.117015\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.131683\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.176443\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.155053\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.117077\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.194096\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.127778\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.150537\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.161985\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.132142\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.065265\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.049018\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.105703\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.086156\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.056370\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.079549\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.082785\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.032524\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.074170\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.007821\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.048359\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.054938\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.073569\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.156988\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.095777\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.065474\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.048101\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.040330\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.055227\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.056669\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.103402\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.065784\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.038013\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.031421\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.113704\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.044150\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.047990\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.036495\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.041468\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.053796\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.037277\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.043594\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.057264\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.050157\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.068229\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.065063\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.049153\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.128106\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.033676\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4589, Accuracy: 8431/10000 (84%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.248671\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.167793\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.099104\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.085120\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.166104\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.120905\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.126161\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.133193\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.102996\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.117824\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.125731\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.134089\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.205044\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.118554\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.135903\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.094119\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.050879\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.100411\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.060555\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.088494\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.029374\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.052262\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.063299\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.058718\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.076508\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.040845\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.034562\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.056355\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.040344\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.086805\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.061489\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.034531\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.045189\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.019347\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.043111\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.035902\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.034340\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.078649\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.043895\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.025898\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.068059\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.093537\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.068674\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.039869\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.054876\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.036152\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.023878\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.096848\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.037768\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.059005\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.050169\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.035697\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.030167\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.081605\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.071790\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4647, Accuracy: 8456/10000 (85%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for partitions_number in numberOfPartitions:\n",
    "    print(f\"Running experiment with {partitions_number} partitions...\")\n",
    "\n",
    "    partitioned_data_classic = partition.balanced_dirichlet_partition(trainingset, partitions_number=partitions_number, alpha=0.5)\n",
    "\n",
    "    classic_client_loaders = [\n",
    "        DataLoader(Subset(trainingset, indices), batch_size=batch_size_train, shuffle=True)\n",
    "        for indices in partitioned_data_classic.values()\n",
    "    ]\n",
    "\n",
    "    num_clients = partitions_number\n",
    "    local_models_classic_strong = [copy.deepcopy(global_model_classic_strong) for _ in range(num_clients)]\n",
    "\n",
    "  # Classic strong\n",
    "    optimizer = optim.SGD(trial_model_strong.parameters(), lr=learning_rate,\n",
    "                          momentum=momentum)\n",
    "    \n",
    "    train_losses = []\n",
    "    train_counter = []\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):  \n",
    "        train_fashion(epoch, trial_model_strong, fashion_mnist_train_loader, optimizer, log_interval, train_losses, train_counter)\n",
    "    \n",
    "\n",
    "\n",
    "    test_losses_classic_strong = []\n",
    "    test_fashion(trial_model_strong,fashion_mnist_train_loader,test_losses_classic_strong)\n",
    "\n",
    "    rounds_classic = 4\n",
    "    \n",
    "    for round_idx in range(rounds_classic):\n",
    "        \n",
    "        print(f\"Round {round_idx + 1}/{rounds_classic}\")\n",
    "    \n",
    "        local_weights_classic = []\n",
    "        for client_idx, client_model in enumerate(local_models_classic_strong):\n",
    "            print(f\"Training client {client_idx + 1}\")\n",
    "            \n",
    "            optimizer = optim.SGD(client_model.parameters(), lr=learning_rate,\n",
    "                          momentum=momentum)\n",
    "    \n",
    "            train_losses = []\n",
    "            train_counter = []\n",
    "    \n",
    "            for epoch in range(1, n_epochs + 1):  \n",
    "                train_fashion(epoch, client_model, classic_client_loaders[client_idx], optimizer, log_interval, train_losses, train_counter)\n",
    "            \n",
    "            client_weights = [param.data.numpy() for param in client_model.parameters()]\n",
    "            local_weights_classic.append(client_weights)\n",
    "            \n",
    "    \n",
    "        global_weights_classic = federated_averaging(local_weights_classic)\n",
    "    \n",
    "    \n",
    "        distribute_global_model(global_weights_classic,local_models_classic_strong,single=False)\n",
    "    \n",
    "        distribute_global_model(global_weights_classic,global_model_classic_strong,single=True)\n",
    "        test_losses = []\n",
    "        test_fashion(global_model_classic_strong,fashion_mnist_test_loader,test_losses)\n",
    "\n",
    "        test_accuracies_classic = []\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in fashion_mnist_test_loader:\n",
    "                output = global_model_classic(data)\n",
    "                pred = output.data.max(1, keepdim=True)[1]\n",
    "                correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "        accuracy = 100. * correct / len(fashion_mnist_test_loader.dataset)\n",
    "        test_accuracies_classic.append(accuracy)\n",
    "\n",
    "        # Save results for non-clustered classic\n",
    "        if partitions_number not in results[\"classic\"]:\n",
    "            results[\"classic\"][partitions_number] = {\"losses\": [], \"accuracy\": []}\n",
    "\n",
    "        results[\"classic\"][partitions_number][\"losses\"].extend(test_losses)\n",
    "        results[\"classic\"][partitions_number][\"accuracy\"].extend(test_accuracies_classic)\n",
    "\n",
    "    ######################\n",
    "    import cluster\n",
    "    cluster = cluster.Cluster(num_clusters=4)\n",
    "    \n",
    "    targets = trainingset.targets\n",
    "    num_classes = len(set(targets)) \n",
    "    clustered_data = cluster.apply_clustering(partitioned_data_classic, targets, num_classes)\n",
    "    \n",
    "    partitioned_data_classic_clustered = clustered_data\n",
    "\n",
    "    classic_client_loaders_clustered = [\n",
    "        DataLoader(Subset(trainingset, indices), batch_size=batch_size_train, shuffle=True)\n",
    "        for indices in partitioned_data_classic_clustered.values()\n",
    "    ]\n",
    "\n",
    "    for round_idx in range(rounds_classic):\n",
    "        print(f\"Round {round_idx + 1}/{rounds_classic}\")\n",
    "\n",
    "        local_weights_classic = []\n",
    "        for client_idx, client_model in enumerate(local_models_classic_strong[0:num_clusters]):\n",
    "            print(f\"Training client {client_idx + 1}\")\n",
    "            \n",
    "            optimizer = optim.SGD(client_model.parameters(), lr=learning_rate,\n",
    "                          momentum=momentum)\n",
    "    \n",
    "            train_losses = []\n",
    "            train_counter = []\n",
    "    \n",
    "            for epoch in range(1, n_epochs + 1):  \n",
    "                train_fashion(epoch, client_model, classic_client_loaders[client_idx], optimizer, log_interval, train_losses, train_counter)\n",
    "            \n",
    "            client_weights = [param.data.numpy() for param in client_model.parameters()]\n",
    "            local_weights_classic.append(client_weights)\n",
    "            \n",
    "    \n",
    "        global_weights_classic = federated_averaging(local_weights_classic)\n",
    "    \n",
    "    \n",
    "        distribute_global_model(global_weights_classic,local_models_classic_strong,single=False)\n",
    "    \n",
    "        distribute_global_model(global_weights_classic,global_model_classic_strong,single=True)\n",
    "        test_losses = []\n",
    "        test_fashion(global_model_classic_strong,fashion_mnist_test_loader,test_losses)\n",
    "\n",
    "        test_accuracies_classic = []\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in fashion_mnist_test_loader:\n",
    "                output = global_model_classic(data)\n",
    "                pred = output.data.max(1, keepdim=True)[1]\n",
    "                correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "        accuracy = 100. * correct / len(fashion_mnist_test_loader.dataset)\n",
    "        test_accuracies_classic.append(accuracy)\n",
    "\n",
    "        # Save results for clustered classic\n",
    "        if partitions_number not in clusteredResults[\"classic\"]:\n",
    "            clusteredResults[\"classic\"][partitions_number] = {\"losses\": [], \"accuracy\": []}\n",
    "\n",
    "        clusteredResults[\"classic\"][partitions_number][\"losses\"].extend(test_losses)\n",
    "        clusteredResults[\"classic\"][partitions_number][\"accuracy\"].extend(test_accuracies_classic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results (Non-Clustered): {'classic': {4: {'losses': [0.6815479064941407, 0.49938775939941404, 0.46115848693847655, 0.4383513153076172], 'accuracy': [10.29, 10.05, 10.41, 10.14]}, 6: {'losses': [0.382756201171875, 0.38323160400390627, 0.3741429901123047, 0.36963440551757815], 'accuracy': [10.28, 10.22, 10.08, 10.48]}, 8: {'losses': [0.36661693725585937, 0.3617134796142578, 0.3648541442871094, 0.3626453094482422], 'accuracy': [10.42, 10.1, 10.52, 10.87]}, 10: {'losses': [0.3590808044433594, 0.3577126373291016, 0.35142200622558595, 0.3532148468017578], 'accuracy': [10.6, 9.53, 10.48, 9.72]}}, 'pca': {}, 'autoencoder': {}}\n",
      "Final Results (Clustered): {'classic': {4: {'losses': [0.43703709716796874, 0.4280464233398438, 0.41145969848632813, 0.42101661376953126], 'accuracy': [10.17, 9.97, 10.26, 9.91]}, 6: {'losses': [0.3982194122314453, 0.395793017578125, 0.38184085693359376, 0.4105090576171875], 'accuracy': [9.9, 10.49, 10.04, 10.6]}, 8: {'losses': [0.40630611267089844, 0.43011572265625, 0.41488186645507813, 0.41762550048828123], 'accuracy': [10.14, 9.79, 9.97, 9.88]}, 10: {'losses': [0.42335987243652345, 0.43057445068359373, 0.4588637054443359, 0.4647010650634766], 'accuracy': [10.01, 10.33, 9.53, 9.97]}}, 'pca': {}, 'autoencoder': {}}\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Results (Non-Clustered):\", results)\n",
    "print(\"Final Results (Clustered):\", clusteredResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingset_pca = train_loader_reduced_pca.dataset\n",
    "trial_model_pca_strong = MultilayerPerceptron()\n",
    "global_model_pca_strong = MultilayerPerceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with 4 partitions...\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.318449\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 0.379597\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 0.343822\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 0.312408\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 0.246673\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 0.242567\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 0.230922\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 0.353246\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.177990\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 0.160976\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.305976\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 0.407932\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.288919\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 0.294784\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 0.182461\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.275527\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.336187\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 0.188078\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 0.257024\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 0.161711\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.305498\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 0.276169\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.325928\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 0.360964\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.188735\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.285779\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.300931\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 0.244410\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.428380\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 0.219541\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.215548\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 0.361686\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.362264\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 0.164792\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.195643\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.368179\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.270769\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 0.275968\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.295523\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 0.290969\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.198132\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 0.304092\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.253853\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 0.312068\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.291315\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.261963\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.262909\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 0.376005\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.304589\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 0.123749\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.280649\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 0.321906\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.257332\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 0.190287\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.186122\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.357768\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.274029\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 0.234750\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.279035\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 0.240060\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.297431\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 0.303474\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.228565\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 0.216100\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.241873\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.192249\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.251033\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 0.393759\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.263692\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 0.262607\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.355106\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 0.222282\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.276008\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 0.227452\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.398478\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.233970\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.295628\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 0.330538\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.211620\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 0.217453\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.277914\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 0.212507\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.201241\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 0.243871\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.255065\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.255498\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.295442\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 0.263258\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.262798\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 0.410579\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.273775\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 0.279046\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.167300\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 0.202212\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.202037\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.300118\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.373512\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 0.372793\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.289673\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 0.137847\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.288500\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 0.433982\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.386425\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 0.359599\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.258116\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.255752\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.252471\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 0.421371\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.418484\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 0.305699\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.133785\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 0.287446\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.267971\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 0.251030\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.313939\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.229541\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.316001\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 0.313328\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.184842\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 0.243529\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.151181\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 0.377428\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.182838\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 0.370399\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.254903\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.331165\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.285928\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 0.257062\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.277725\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 0.227121\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.278073\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 0.289556\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.196683\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 0.243405\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.311179\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.182170\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.385083\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 0.221710\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.267063\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 0.228022\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.224492\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 0.266807\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.344559\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 0.343750\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.281519\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.199908\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.423777\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 0.347412\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.290992\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 0.180764\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.508057\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 0.301672\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.313607\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 0.327445\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.267517\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.187303\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.187380\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 0.209772\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.283906\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 0.397784\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.268600\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 0.283114\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.321061\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 0.245437\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.196230\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.240083\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.259361\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 0.329888\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.295873\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 0.360907\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.168286\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 0.249824\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.210867\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 0.160151\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.345470\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.372642\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.245996\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 0.281352\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.417213\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 0.284937\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.260348\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 0.229728\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.278525\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 0.293077\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.225348\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.251440\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.280133\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 0.161229\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.229412\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 0.165158\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.198496\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 0.212987\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.236104\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 0.223907\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.266079\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.263432\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.248767\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 0.340688\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.204041\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 0.352362\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.315885\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 0.105317\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.334316\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 0.288205\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.181559\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.191704\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.280466\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 0.365357\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.272949\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 0.208453\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.187991\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 0.234223\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.289917\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 0.322202\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.130216\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.204259\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.275930\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 0.289736\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.291988\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 0.213485\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.260344\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 0.300933\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.272218\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 0.261853\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.261408\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.240319\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.166483\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 0.382677\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.294274\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 0.230791\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.300835\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 0.273995\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.301439\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 0.311569\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.192346\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.314955\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.330720\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 0.200943\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.335453\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 0.285893\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.215536\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 0.238104\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.214678\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 0.321648\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.239112\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.270951\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.207326\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 0.372707\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.247786\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 0.244059\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.500206\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 0.341982\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.259188\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 0.220620\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.296484\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.230741\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.311867\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 0.251523\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.164325\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 0.163268\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.214388\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 0.180113\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.523729\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 0.253905\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.344233\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.245095\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.275164\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 0.299861\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.269941\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 0.294073\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.278255\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 0.304303\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.188040\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 0.222528\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.238256\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.215772\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.224999\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 0.253923\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.238044\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 0.197408\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.124396\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 0.310861\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.241400\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 0.278021\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.340102\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.295598\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.147885\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 0.416760\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.325099\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 0.230937\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.269706\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 0.409333\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.307660\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 0.319986\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.285723\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.308988\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.325064\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 0.225861\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.271069\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 0.339042\n",
      "\n",
      "Test set: Avg. loss: 0.2541, Accuracy: 54290/60000 (90%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/23974 (0%)]\tLoss: 2.418487\n",
      "Train Epoch: 1 [1000/23974 (4%)]\tLoss: 1.509308\n",
      "Train Epoch: 1 [2000/23974 (8%)]\tLoss: 0.966035\n",
      "Train Epoch: 1 [3000/23974 (12%)]\tLoss: 0.807469\n",
      "Train Epoch: 1 [4000/23974 (17%)]\tLoss: 0.611239\n",
      "Train Epoch: 1 [5000/23974 (21%)]\tLoss: 0.461714\n",
      "Train Epoch: 1 [6000/23974 (25%)]\tLoss: 0.625897\n",
      "Train Epoch: 1 [7000/23974 (29%)]\tLoss: 0.528459\n",
      "Train Epoch: 1 [8000/23974 (33%)]\tLoss: 0.664611\n",
      "Train Epoch: 1 [9000/23974 (38%)]\tLoss: 0.420466\n",
      "Train Epoch: 1 [10000/23974 (42%)]\tLoss: 0.486293\n",
      "Train Epoch: 1 [11000/23974 (46%)]\tLoss: 0.786699\n",
      "Train Epoch: 1 [12000/23974 (50%)]\tLoss: 0.431499\n",
      "Train Epoch: 1 [13000/23974 (54%)]\tLoss: 0.402763\n",
      "Train Epoch: 1 [14000/23974 (58%)]\tLoss: 0.440867\n",
      "Train Epoch: 1 [15000/23974 (62%)]\tLoss: 0.750921\n",
      "Train Epoch: 1 [16000/23974 (67%)]\tLoss: 0.420493\n",
      "Train Epoch: 1 [17000/23974 (71%)]\tLoss: 0.466683\n",
      "Train Epoch: 1 [18000/23974 (75%)]\tLoss: 0.564324\n",
      "Train Epoch: 1 [19000/23974 (79%)]\tLoss: 0.363656\n",
      "Train Epoch: 1 [20000/23974 (83%)]\tLoss: 0.382153\n",
      "Train Epoch: 1 [21000/23974 (88%)]\tLoss: 0.361521\n",
      "Train Epoch: 1 [22000/23974 (92%)]\tLoss: 0.340781\n",
      "Train Epoch: 1 [23000/23974 (96%)]\tLoss: 0.321144\n",
      "Train Epoch: 2 [0/23974 (0%)]\tLoss: 0.294041\n",
      "Train Epoch: 2 [1000/23974 (4%)]\tLoss: 0.457271\n",
      "Train Epoch: 2 [2000/23974 (8%)]\tLoss: 0.287419\n",
      "Train Epoch: 2 [3000/23974 (12%)]\tLoss: 0.355007\n",
      "Train Epoch: 2 [4000/23974 (17%)]\tLoss: 0.357347\n",
      "Train Epoch: 2 [5000/23974 (21%)]\tLoss: 0.242931\n",
      "Train Epoch: 2 [6000/23974 (25%)]\tLoss: 0.423327\n",
      "Train Epoch: 2 [7000/23974 (29%)]\tLoss: 0.321238\n",
      "Train Epoch: 2 [8000/23974 (33%)]\tLoss: 0.483208\n",
      "Train Epoch: 2 [9000/23974 (38%)]\tLoss: 0.466195\n",
      "Train Epoch: 2 [10000/23974 (42%)]\tLoss: 0.459914\n",
      "Train Epoch: 2 [11000/23974 (46%)]\tLoss: 0.491152\n",
      "Train Epoch: 2 [12000/23974 (50%)]\tLoss: 0.395330\n",
      "Train Epoch: 2 [13000/23974 (54%)]\tLoss: 0.406423\n",
      "Train Epoch: 2 [14000/23974 (58%)]\tLoss: 0.354978\n",
      "Train Epoch: 2 [15000/23974 (62%)]\tLoss: 0.248500\n",
      "Train Epoch: 2 [16000/23974 (67%)]\tLoss: 0.329826\n",
      "Train Epoch: 2 [17000/23974 (71%)]\tLoss: 0.387914\n",
      "Train Epoch: 2 [18000/23974 (75%)]\tLoss: 0.289525\n",
      "Train Epoch: 2 [19000/23974 (79%)]\tLoss: 0.505303\n",
      "Train Epoch: 2 [20000/23974 (83%)]\tLoss: 0.302606\n",
      "Train Epoch: 2 [21000/23974 (88%)]\tLoss: 0.337232\n",
      "Train Epoch: 2 [22000/23974 (92%)]\tLoss: 0.642378\n",
      "Train Epoch: 2 [23000/23974 (96%)]\tLoss: 0.300633\n",
      "Train Epoch: 3 [0/23974 (0%)]\tLoss: 0.445117\n",
      "Train Epoch: 3 [1000/23974 (4%)]\tLoss: 0.323703\n",
      "Train Epoch: 3 [2000/23974 (8%)]\tLoss: 0.392422\n",
      "Train Epoch: 3 [3000/23974 (12%)]\tLoss: 0.301072\n",
      "Train Epoch: 3 [4000/23974 (17%)]\tLoss: 0.334236\n",
      "Train Epoch: 3 [5000/23974 (21%)]\tLoss: 0.480484\n",
      "Train Epoch: 3 [6000/23974 (25%)]\tLoss: 0.267376\n",
      "Train Epoch: 3 [7000/23974 (29%)]\tLoss: 0.364266\n",
      "Train Epoch: 3 [8000/23974 (33%)]\tLoss: 0.482629\n",
      "Train Epoch: 3 [9000/23974 (38%)]\tLoss: 0.423253\n",
      "Train Epoch: 3 [10000/23974 (42%)]\tLoss: 0.371881\n",
      "Train Epoch: 3 [11000/23974 (46%)]\tLoss: 0.472163\n",
      "Train Epoch: 3 [12000/23974 (50%)]\tLoss: 0.403056\n",
      "Train Epoch: 3 [13000/23974 (54%)]\tLoss: 0.240771\n",
      "Train Epoch: 3 [14000/23974 (58%)]\tLoss: 0.422643\n",
      "Train Epoch: 3 [15000/23974 (62%)]\tLoss: 0.339548\n",
      "Train Epoch: 3 [16000/23974 (67%)]\tLoss: 0.432390\n",
      "Train Epoch: 3 [17000/23974 (71%)]\tLoss: 0.275006\n",
      "Train Epoch: 3 [18000/23974 (75%)]\tLoss: 0.384189\n",
      "Train Epoch: 3 [19000/23974 (79%)]\tLoss: 0.397589\n",
      "Train Epoch: 3 [20000/23974 (83%)]\tLoss: 0.355709\n",
      "Train Epoch: 3 [21000/23974 (88%)]\tLoss: 0.325220\n",
      "Train Epoch: 3 [22000/23974 (92%)]\tLoss: 0.561327\n",
      "Train Epoch: 3 [23000/23974 (96%)]\tLoss: 0.303427\n",
      "Train Epoch: 4 [0/23974 (0%)]\tLoss: 0.470920\n",
      "Train Epoch: 4 [1000/23974 (4%)]\tLoss: 0.320588\n",
      "Train Epoch: 4 [2000/23974 (8%)]\tLoss: 0.254314\n",
      "Train Epoch: 4 [3000/23974 (12%)]\tLoss: 0.357335\n",
      "Train Epoch: 4 [4000/23974 (17%)]\tLoss: 0.332981\n",
      "Train Epoch: 4 [5000/23974 (21%)]\tLoss: 0.356167\n",
      "Train Epoch: 4 [6000/23974 (25%)]\tLoss: 0.441376\n",
      "Train Epoch: 4 [7000/23974 (29%)]\tLoss: 0.339003\n",
      "Train Epoch: 4 [8000/23974 (33%)]\tLoss: 0.343589\n",
      "Train Epoch: 4 [9000/23974 (38%)]\tLoss: 0.296656\n",
      "Train Epoch: 4 [10000/23974 (42%)]\tLoss: 0.298339\n",
      "Train Epoch: 4 [11000/23974 (46%)]\tLoss: 0.323166\n",
      "Train Epoch: 4 [12000/23974 (50%)]\tLoss: 0.276406\n",
      "Train Epoch: 4 [13000/23974 (54%)]\tLoss: 0.205205\n",
      "Train Epoch: 4 [14000/23974 (58%)]\tLoss: 0.353968\n",
      "Train Epoch: 4 [15000/23974 (62%)]\tLoss: 0.326835\n",
      "Train Epoch: 4 [16000/23974 (67%)]\tLoss: 0.275773\n",
      "Train Epoch: 4 [17000/23974 (71%)]\tLoss: 0.408546\n",
      "Train Epoch: 4 [18000/23974 (75%)]\tLoss: 0.360178\n",
      "Train Epoch: 4 [19000/23974 (79%)]\tLoss: 0.227418\n",
      "Train Epoch: 4 [20000/23974 (83%)]\tLoss: 0.239571\n",
      "Train Epoch: 4 [21000/23974 (88%)]\tLoss: 0.439120\n",
      "Train Epoch: 4 [22000/23974 (92%)]\tLoss: 0.207387\n",
      "Train Epoch: 4 [23000/23974 (96%)]\tLoss: 0.432743\n",
      "Train Epoch: 5 [0/23974 (0%)]\tLoss: 0.293053\n",
      "Train Epoch: 5 [1000/23974 (4%)]\tLoss: 0.270519\n",
      "Train Epoch: 5 [2000/23974 (8%)]\tLoss: 0.325204\n",
      "Train Epoch: 5 [3000/23974 (12%)]\tLoss: 0.258488\n",
      "Train Epoch: 5 [4000/23974 (17%)]\tLoss: 0.496928\n",
      "Train Epoch: 5 [5000/23974 (21%)]\tLoss: 0.308577\n",
      "Train Epoch: 5 [6000/23974 (25%)]\tLoss: 0.265121\n",
      "Train Epoch: 5 [7000/23974 (29%)]\tLoss: 0.411276\n",
      "Train Epoch: 5 [8000/23974 (33%)]\tLoss: 0.243159\n",
      "Train Epoch: 5 [9000/23974 (38%)]\tLoss: 0.199238\n",
      "Train Epoch: 5 [10000/23974 (42%)]\tLoss: 0.307086\n",
      "Train Epoch: 5 [11000/23974 (46%)]\tLoss: 0.232541\n",
      "Train Epoch: 5 [12000/23974 (50%)]\tLoss: 0.268206\n",
      "Train Epoch: 5 [13000/23974 (54%)]\tLoss: 0.243948\n",
      "Train Epoch: 5 [14000/23974 (58%)]\tLoss: 0.480615\n",
      "Train Epoch: 5 [15000/23974 (62%)]\tLoss: 0.248002\n",
      "Train Epoch: 5 [16000/23974 (67%)]\tLoss: 0.286645\n",
      "Train Epoch: 5 [17000/23974 (71%)]\tLoss: 0.374206\n",
      "Train Epoch: 5 [18000/23974 (75%)]\tLoss: 0.404221\n",
      "Train Epoch: 5 [19000/23974 (79%)]\tLoss: 0.338470\n",
      "Train Epoch: 5 [20000/23974 (83%)]\tLoss: 0.290526\n",
      "Train Epoch: 5 [21000/23974 (88%)]\tLoss: 0.285284\n",
      "Train Epoch: 5 [22000/23974 (92%)]\tLoss: 0.253450\n",
      "Train Epoch: 5 [23000/23974 (96%)]\tLoss: 0.438572\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7961 (0%)]\tLoss: 2.394607\n",
      "Train Epoch: 1 [1000/7961 (12%)]\tLoss: 1.547799\n",
      "Train Epoch: 1 [2000/7961 (25%)]\tLoss: 1.033601\n",
      "Train Epoch: 1 [3000/7961 (38%)]\tLoss: 0.857210\n",
      "Train Epoch: 1 [4000/7961 (50%)]\tLoss: 0.827202\n",
      "Train Epoch: 1 [5000/7961 (62%)]\tLoss: 0.743350\n",
      "Train Epoch: 1 [6000/7961 (75%)]\tLoss: 0.656916\n",
      "Train Epoch: 1 [7000/7961 (88%)]\tLoss: 0.706729\n",
      "Train Epoch: 2 [0/7961 (0%)]\tLoss: 0.806765\n",
      "Train Epoch: 2 [1000/7961 (12%)]\tLoss: 0.762838\n",
      "Train Epoch: 2 [2000/7961 (25%)]\tLoss: 0.598588\n",
      "Train Epoch: 2 [3000/7961 (38%)]\tLoss: 0.609171\n",
      "Train Epoch: 2 [4000/7961 (50%)]\tLoss: 0.579493\n",
      "Train Epoch: 2 [5000/7961 (62%)]\tLoss: 0.555661\n",
      "Train Epoch: 2 [6000/7961 (75%)]\tLoss: 0.524912\n",
      "Train Epoch: 2 [7000/7961 (88%)]\tLoss: 0.567732\n",
      "Train Epoch: 3 [0/7961 (0%)]\tLoss: 0.592238\n",
      "Train Epoch: 3 [1000/7961 (12%)]\tLoss: 0.753444\n",
      "Train Epoch: 3 [2000/7961 (25%)]\tLoss: 0.647391\n",
      "Train Epoch: 3 [3000/7961 (38%)]\tLoss: 0.562711\n",
      "Train Epoch: 3 [4000/7961 (50%)]\tLoss: 0.479750\n",
      "Train Epoch: 3 [5000/7961 (62%)]\tLoss: 0.431940\n",
      "Train Epoch: 3 [6000/7961 (75%)]\tLoss: 0.494996\n",
      "Train Epoch: 3 [7000/7961 (88%)]\tLoss: 0.533584\n",
      "Train Epoch: 4 [0/7961 (0%)]\tLoss: 0.655296\n",
      "Train Epoch: 4 [1000/7961 (12%)]\tLoss: 0.505773\n",
      "Train Epoch: 4 [2000/7961 (25%)]\tLoss: 0.497855\n",
      "Train Epoch: 4 [3000/7961 (38%)]\tLoss: 0.399111\n",
      "Train Epoch: 4 [4000/7961 (50%)]\tLoss: 0.400725\n",
      "Train Epoch: 4 [5000/7961 (62%)]\tLoss: 0.446939\n",
      "Train Epoch: 4 [6000/7961 (75%)]\tLoss: 0.440439\n",
      "Train Epoch: 4 [7000/7961 (88%)]\tLoss: 0.472300\n",
      "Train Epoch: 5 [0/7961 (0%)]\tLoss: 0.527235\n",
      "Train Epoch: 5 [1000/7961 (12%)]\tLoss: 0.495997\n",
      "Train Epoch: 5 [2000/7961 (25%)]\tLoss: 0.541209\n",
      "Train Epoch: 5 [3000/7961 (38%)]\tLoss: 0.469358\n",
      "Train Epoch: 5 [4000/7961 (50%)]\tLoss: 0.367267\n",
      "Train Epoch: 5 [5000/7961 (62%)]\tLoss: 0.494441\n",
      "Train Epoch: 5 [6000/7961 (75%)]\tLoss: 0.437150\n",
      "Train Epoch: 5 [7000/7961 (88%)]\tLoss: 0.473089\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/15584 (0%)]\tLoss: 2.339319\n",
      "Train Epoch: 1 [1000/15584 (6%)]\tLoss: 1.265676\n",
      "Train Epoch: 1 [2000/15584 (13%)]\tLoss: 0.646374\n",
      "Train Epoch: 1 [3000/15584 (19%)]\tLoss: 0.634239\n",
      "Train Epoch: 1 [4000/15584 (26%)]\tLoss: 0.521997\n",
      "Train Epoch: 1 [5000/15584 (32%)]\tLoss: 0.530710\n",
      "Train Epoch: 1 [6000/15584 (38%)]\tLoss: 0.531188\n",
      "Train Epoch: 1 [7000/15584 (45%)]\tLoss: 0.445060\n",
      "Train Epoch: 1 [8000/15584 (51%)]\tLoss: 0.516442\n",
      "Train Epoch: 1 [9000/15584 (58%)]\tLoss: 0.380685\n",
      "Train Epoch: 1 [10000/15584 (64%)]\tLoss: 0.394994\n",
      "Train Epoch: 1 [11000/15584 (71%)]\tLoss: 0.515435\n",
      "Train Epoch: 1 [12000/15584 (77%)]\tLoss: 0.390068\n",
      "Train Epoch: 1 [13000/15584 (83%)]\tLoss: 0.460856\n",
      "Train Epoch: 1 [14000/15584 (90%)]\tLoss: 0.492446\n",
      "Train Epoch: 1 [15000/15584 (96%)]\tLoss: 0.264323\n",
      "Train Epoch: 2 [0/15584 (0%)]\tLoss: 0.523907\n",
      "Train Epoch: 2 [1000/15584 (6%)]\tLoss: 0.359186\n",
      "Train Epoch: 2 [2000/15584 (13%)]\tLoss: 0.338610\n",
      "Train Epoch: 2 [3000/15584 (19%)]\tLoss: 0.270184\n",
      "Train Epoch: 2 [4000/15584 (26%)]\tLoss: 0.339546\n",
      "Train Epoch: 2 [5000/15584 (32%)]\tLoss: 0.438397\n",
      "Train Epoch: 2 [6000/15584 (38%)]\tLoss: 0.318777\n",
      "Train Epoch: 2 [7000/15584 (45%)]\tLoss: 0.393037\n",
      "Train Epoch: 2 [8000/15584 (51%)]\tLoss: 0.290442\n",
      "Train Epoch: 2 [9000/15584 (58%)]\tLoss: 0.284366\n",
      "Train Epoch: 2 [10000/15584 (64%)]\tLoss: 0.594041\n",
      "Train Epoch: 2 [11000/15584 (71%)]\tLoss: 0.536351\n",
      "Train Epoch: 2 [12000/15584 (77%)]\tLoss: 0.343622\n",
      "Train Epoch: 2 [13000/15584 (83%)]\tLoss: 0.352606\n",
      "Train Epoch: 2 [14000/15584 (90%)]\tLoss: 0.218915\n",
      "Train Epoch: 2 [15000/15584 (96%)]\tLoss: 0.298825\n",
      "Train Epoch: 3 [0/15584 (0%)]\tLoss: 0.388469\n",
      "Train Epoch: 3 [1000/15584 (6%)]\tLoss: 0.302983\n",
      "Train Epoch: 3 [2000/15584 (13%)]\tLoss: 0.473693\n",
      "Train Epoch: 3 [3000/15584 (19%)]\tLoss: 0.307101\n",
      "Train Epoch: 3 [4000/15584 (26%)]\tLoss: 0.276109\n",
      "Train Epoch: 3 [5000/15584 (32%)]\tLoss: 0.287477\n",
      "Train Epoch: 3 [6000/15584 (38%)]\tLoss: 0.276881\n",
      "Train Epoch: 3 [7000/15584 (45%)]\tLoss: 0.374108\n",
      "Train Epoch: 3 [8000/15584 (51%)]\tLoss: 0.406305\n",
      "Train Epoch: 3 [9000/15584 (58%)]\tLoss: 0.357533\n",
      "Train Epoch: 3 [10000/15584 (64%)]\tLoss: 0.360940\n",
      "Train Epoch: 3 [11000/15584 (71%)]\tLoss: 0.525962\n",
      "Train Epoch: 3 [12000/15584 (77%)]\tLoss: 0.349302\n",
      "Train Epoch: 3 [13000/15584 (83%)]\tLoss: 0.371279\n",
      "Train Epoch: 3 [14000/15584 (90%)]\tLoss: 0.328462\n",
      "Train Epoch: 3 [15000/15584 (96%)]\tLoss: 0.298341\n",
      "Train Epoch: 4 [0/15584 (0%)]\tLoss: 0.360200\n",
      "Train Epoch: 4 [1000/15584 (6%)]\tLoss: 0.560255\n",
      "Train Epoch: 4 [2000/15584 (13%)]\tLoss: 0.285916\n",
      "Train Epoch: 4 [3000/15584 (19%)]\tLoss: 0.360426\n",
      "Train Epoch: 4 [4000/15584 (26%)]\tLoss: 0.476840\n",
      "Train Epoch: 4 [5000/15584 (32%)]\tLoss: 0.289675\n",
      "Train Epoch: 4 [6000/15584 (38%)]\tLoss: 0.258088\n",
      "Train Epoch: 4 [7000/15584 (45%)]\tLoss: 0.283103\n",
      "Train Epoch: 4 [8000/15584 (51%)]\tLoss: 0.299430\n",
      "Train Epoch: 4 [9000/15584 (58%)]\tLoss: 0.329477\n",
      "Train Epoch: 4 [10000/15584 (64%)]\tLoss: 0.253498\n",
      "Train Epoch: 4 [11000/15584 (71%)]\tLoss: 0.367343\n",
      "Train Epoch: 4 [12000/15584 (77%)]\tLoss: 0.312526\n",
      "Train Epoch: 4 [13000/15584 (83%)]\tLoss: 0.243778\n",
      "Train Epoch: 4 [14000/15584 (90%)]\tLoss: 0.313409\n",
      "Train Epoch: 4 [15000/15584 (96%)]\tLoss: 0.224751\n",
      "Train Epoch: 5 [0/15584 (0%)]\tLoss: 0.376773\n",
      "Train Epoch: 5 [1000/15584 (6%)]\tLoss: 0.168514\n",
      "Train Epoch: 5 [2000/15584 (13%)]\tLoss: 0.276186\n",
      "Train Epoch: 5 [3000/15584 (19%)]\tLoss: 0.320677\n",
      "Train Epoch: 5 [4000/15584 (26%)]\tLoss: 0.269415\n",
      "Train Epoch: 5 [5000/15584 (32%)]\tLoss: 0.212275\n",
      "Train Epoch: 5 [6000/15584 (38%)]\tLoss: 0.505042\n",
      "Train Epoch: 5 [7000/15584 (45%)]\tLoss: 0.237050\n",
      "Train Epoch: 5 [8000/15584 (51%)]\tLoss: 0.256114\n",
      "Train Epoch: 5 [9000/15584 (58%)]\tLoss: 0.284579\n",
      "Train Epoch: 5 [10000/15584 (64%)]\tLoss: 0.458357\n",
      "Train Epoch: 5 [11000/15584 (71%)]\tLoss: 0.262248\n",
      "Train Epoch: 5 [12000/15584 (77%)]\tLoss: 0.180574\n",
      "Train Epoch: 5 [13000/15584 (83%)]\tLoss: 0.206545\n",
      "Train Epoch: 5 [14000/15584 (90%)]\tLoss: 0.343889\n",
      "Train Epoch: 5 [15000/15584 (96%)]\tLoss: 0.286847\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/12481 (0%)]\tLoss: 2.200076\n",
      "Train Epoch: 1 [1000/12481 (8%)]\tLoss: 0.838478\n",
      "Train Epoch: 1 [2000/12481 (16%)]\tLoss: 0.604290\n",
      "Train Epoch: 1 [3000/12481 (24%)]\tLoss: 0.652983\n",
      "Train Epoch: 1 [4000/12481 (32%)]\tLoss: 0.472727\n",
      "Train Epoch: 1 [5000/12481 (40%)]\tLoss: 0.525756\n",
      "Train Epoch: 1 [6000/12481 (48%)]\tLoss: 0.481194\n",
      "Train Epoch: 1 [7000/12481 (56%)]\tLoss: 0.576605\n",
      "Train Epoch: 1 [8000/12481 (64%)]\tLoss: 0.313864\n",
      "Train Epoch: 1 [9000/12481 (72%)]\tLoss: 0.340301\n",
      "Train Epoch: 1 [10000/12481 (80%)]\tLoss: 0.495033\n",
      "Train Epoch: 1 [11000/12481 (88%)]\tLoss: 0.297672\n",
      "Train Epoch: 1 [12000/12481 (96%)]\tLoss: 0.414648\n",
      "Train Epoch: 2 [0/12481 (0%)]\tLoss: 0.414621\n",
      "Train Epoch: 2 [1000/12481 (8%)]\tLoss: 0.320419\n",
      "Train Epoch: 2 [2000/12481 (16%)]\tLoss: 0.246640\n",
      "Train Epoch: 2 [3000/12481 (24%)]\tLoss: 0.182396\n",
      "Train Epoch: 2 [4000/12481 (32%)]\tLoss: 0.286948\n",
      "Train Epoch: 2 [5000/12481 (40%)]\tLoss: 0.282157\n",
      "Train Epoch: 2 [6000/12481 (48%)]\tLoss: 0.262113\n",
      "Train Epoch: 2 [7000/12481 (56%)]\tLoss: 0.457631\n",
      "Train Epoch: 2 [8000/12481 (64%)]\tLoss: 0.326159\n",
      "Train Epoch: 2 [9000/12481 (72%)]\tLoss: 0.372663\n",
      "Train Epoch: 2 [10000/12481 (80%)]\tLoss: 0.303512\n",
      "Train Epoch: 2 [11000/12481 (88%)]\tLoss: 0.211673\n",
      "Train Epoch: 2 [12000/12481 (96%)]\tLoss: 0.313084\n",
      "Train Epoch: 3 [0/12481 (0%)]\tLoss: 0.270349\n",
      "Train Epoch: 3 [1000/12481 (8%)]\tLoss: 0.263576\n",
      "Train Epoch: 3 [2000/12481 (16%)]\tLoss: 0.232961\n",
      "Train Epoch: 3 [3000/12481 (24%)]\tLoss: 0.325622\n",
      "Train Epoch: 3 [4000/12481 (32%)]\tLoss: 0.266676\n",
      "Train Epoch: 3 [5000/12481 (40%)]\tLoss: 0.242692\n",
      "Train Epoch: 3 [6000/12481 (48%)]\tLoss: 0.365803\n",
      "Train Epoch: 3 [7000/12481 (56%)]\tLoss: 0.279554\n",
      "Train Epoch: 3 [8000/12481 (64%)]\tLoss: 0.390402\n",
      "Train Epoch: 3 [9000/12481 (72%)]\tLoss: 0.417257\n",
      "Train Epoch: 3 [10000/12481 (80%)]\tLoss: 0.318291\n",
      "Train Epoch: 3 [11000/12481 (88%)]\tLoss: 0.257137\n",
      "Train Epoch: 3 [12000/12481 (96%)]\tLoss: 0.289958\n",
      "Train Epoch: 4 [0/12481 (0%)]\tLoss: 0.260105\n",
      "Train Epoch: 4 [1000/12481 (8%)]\tLoss: 0.351756\n",
      "Train Epoch: 4 [2000/12481 (16%)]\tLoss: 0.267734\n",
      "Train Epoch: 4 [3000/12481 (24%)]\tLoss: 0.229701\n",
      "Train Epoch: 4 [4000/12481 (32%)]\tLoss: 0.305044\n",
      "Train Epoch: 4 [5000/12481 (40%)]\tLoss: 0.394673\n",
      "Train Epoch: 4 [6000/12481 (48%)]\tLoss: 0.221212\n",
      "Train Epoch: 4 [7000/12481 (56%)]\tLoss: 0.294809\n",
      "Train Epoch: 4 [8000/12481 (64%)]\tLoss: 0.250629\n",
      "Train Epoch: 4 [9000/12481 (72%)]\tLoss: 0.230053\n",
      "Train Epoch: 4 [10000/12481 (80%)]\tLoss: 0.235331\n",
      "Train Epoch: 4 [11000/12481 (88%)]\tLoss: 0.227391\n",
      "Train Epoch: 4 [12000/12481 (96%)]\tLoss: 0.235671\n",
      "Train Epoch: 5 [0/12481 (0%)]\tLoss: 0.205825\n",
      "Train Epoch: 5 [1000/12481 (8%)]\tLoss: 0.237435\n",
      "Train Epoch: 5 [2000/12481 (16%)]\tLoss: 0.317023\n",
      "Train Epoch: 5 [3000/12481 (24%)]\tLoss: 0.185981\n",
      "Train Epoch: 5 [4000/12481 (32%)]\tLoss: 0.268051\n",
      "Train Epoch: 5 [5000/12481 (40%)]\tLoss: 0.229597\n",
      "Train Epoch: 5 [6000/12481 (48%)]\tLoss: 0.198340\n",
      "Train Epoch: 5 [7000/12481 (56%)]\tLoss: 0.310716\n",
      "Train Epoch: 5 [8000/12481 (64%)]\tLoss: 0.230951\n",
      "Train Epoch: 5 [9000/12481 (72%)]\tLoss: 0.282372\n",
      "Train Epoch: 5 [10000/12481 (80%)]\tLoss: 0.258975\n",
      "Train Epoch: 5 [11000/12481 (88%)]\tLoss: 0.256324\n",
      "Train Epoch: 5 [12000/12481 (96%)]\tLoss: 0.385168\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "4\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.1179, Accuracy: 7894/10000 (79%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/23974 (0%)]\tLoss: 0.537552\n",
      "Train Epoch: 1 [1000/23974 (4%)]\tLoss: 0.312812\n",
      "Train Epoch: 1 [2000/23974 (8%)]\tLoss: 0.368806\n",
      "Train Epoch: 1 [3000/23974 (12%)]\tLoss: 0.338787\n",
      "Train Epoch: 1 [4000/23974 (17%)]\tLoss: 0.408501\n",
      "Train Epoch: 1 [5000/23974 (21%)]\tLoss: 0.328846\n",
      "Train Epoch: 1 [6000/23974 (25%)]\tLoss: 0.492386\n",
      "Train Epoch: 1 [7000/23974 (29%)]\tLoss: 0.316191\n",
      "Train Epoch: 1 [8000/23974 (33%)]\tLoss: 0.485354\n",
      "Train Epoch: 1 [9000/23974 (38%)]\tLoss: 0.385098\n",
      "Train Epoch: 1 [10000/23974 (42%)]\tLoss: 0.423835\n",
      "Train Epoch: 1 [11000/23974 (46%)]\tLoss: 0.435707\n",
      "Train Epoch: 1 [12000/23974 (50%)]\tLoss: 0.331357\n",
      "Train Epoch: 1 [13000/23974 (54%)]\tLoss: 0.320372\n",
      "Train Epoch: 1 [14000/23974 (58%)]\tLoss: 0.363849\n",
      "Train Epoch: 1 [15000/23974 (62%)]\tLoss: 0.527920\n",
      "Train Epoch: 1 [16000/23974 (67%)]\tLoss: 0.308641\n",
      "Train Epoch: 1 [17000/23974 (71%)]\tLoss: 0.227105\n",
      "Train Epoch: 1 [18000/23974 (75%)]\tLoss: 0.261022\n",
      "Train Epoch: 1 [19000/23974 (79%)]\tLoss: 0.323546\n",
      "Train Epoch: 1 [20000/23974 (83%)]\tLoss: 0.374312\n",
      "Train Epoch: 1 [21000/23974 (88%)]\tLoss: 0.465429\n",
      "Train Epoch: 1 [22000/23974 (92%)]\tLoss: 0.443969\n",
      "Train Epoch: 1 [23000/23974 (96%)]\tLoss: 0.280905\n",
      "Train Epoch: 2 [0/23974 (0%)]\tLoss: 0.506733\n",
      "Train Epoch: 2 [1000/23974 (4%)]\tLoss: 0.210844\n",
      "Train Epoch: 2 [2000/23974 (8%)]\tLoss: 0.445234\n",
      "Train Epoch: 2 [3000/23974 (12%)]\tLoss: 0.309091\n",
      "Train Epoch: 2 [4000/23974 (17%)]\tLoss: 0.418879\n",
      "Train Epoch: 2 [5000/23974 (21%)]\tLoss: 0.452254\n",
      "Train Epoch: 2 [6000/23974 (25%)]\tLoss: 0.387186\n",
      "Train Epoch: 2 [7000/23974 (29%)]\tLoss: 0.359814\n",
      "Train Epoch: 2 [8000/23974 (33%)]\tLoss: 0.265659\n",
      "Train Epoch: 2 [9000/23974 (38%)]\tLoss: 0.333061\n",
      "Train Epoch: 2 [10000/23974 (42%)]\tLoss: 0.285824\n",
      "Train Epoch: 2 [11000/23974 (46%)]\tLoss: 0.331748\n",
      "Train Epoch: 2 [12000/23974 (50%)]\tLoss: 0.337943\n",
      "Train Epoch: 2 [13000/23974 (54%)]\tLoss: 0.197562\n",
      "Train Epoch: 2 [14000/23974 (58%)]\tLoss: 0.431694\n",
      "Train Epoch: 2 [15000/23974 (62%)]\tLoss: 0.293492\n",
      "Train Epoch: 2 [16000/23974 (67%)]\tLoss: 0.310761\n",
      "Train Epoch: 2 [17000/23974 (71%)]\tLoss: 0.244623\n",
      "Train Epoch: 2 [18000/23974 (75%)]\tLoss: 0.313322\n",
      "Train Epoch: 2 [19000/23974 (79%)]\tLoss: 0.257752\n",
      "Train Epoch: 2 [20000/23974 (83%)]\tLoss: 0.526310\n",
      "Train Epoch: 2 [21000/23974 (88%)]\tLoss: 0.226943\n",
      "Train Epoch: 2 [22000/23974 (92%)]\tLoss: 0.238090\n",
      "Train Epoch: 2 [23000/23974 (96%)]\tLoss: 0.362198\n",
      "Train Epoch: 3 [0/23974 (0%)]\tLoss: 0.311817\n",
      "Train Epoch: 3 [1000/23974 (4%)]\tLoss: 0.237153\n",
      "Train Epoch: 3 [2000/23974 (8%)]\tLoss: 0.273081\n",
      "Train Epoch: 3 [3000/23974 (12%)]\tLoss: 0.444628\n",
      "Train Epoch: 3 [4000/23974 (17%)]\tLoss: 0.318179\n",
      "Train Epoch: 3 [5000/23974 (21%)]\tLoss: 0.254085\n",
      "Train Epoch: 3 [6000/23974 (25%)]\tLoss: 0.226876\n",
      "Train Epoch: 3 [7000/23974 (29%)]\tLoss: 0.340219\n",
      "Train Epoch: 3 [8000/23974 (33%)]\tLoss: 0.246919\n",
      "Train Epoch: 3 [9000/23974 (38%)]\tLoss: 0.264628\n",
      "Train Epoch: 3 [10000/23974 (42%)]\tLoss: 0.371639\n",
      "Train Epoch: 3 [11000/23974 (46%)]\tLoss: 0.256117\n",
      "Train Epoch: 3 [12000/23974 (50%)]\tLoss: 0.261778\n",
      "Train Epoch: 3 [13000/23974 (54%)]\tLoss: 0.350738\n",
      "Train Epoch: 3 [14000/23974 (58%)]\tLoss: 0.461045\n",
      "Train Epoch: 3 [15000/23974 (62%)]\tLoss: 0.359916\n",
      "Train Epoch: 3 [16000/23974 (67%)]\tLoss: 0.281157\n",
      "Train Epoch: 3 [17000/23974 (71%)]\tLoss: 0.294769\n",
      "Train Epoch: 3 [18000/23974 (75%)]\tLoss: 0.259425\n",
      "Train Epoch: 3 [19000/23974 (79%)]\tLoss: 0.290508\n",
      "Train Epoch: 3 [20000/23974 (83%)]\tLoss: 0.345435\n",
      "Train Epoch: 3 [21000/23974 (88%)]\tLoss: 0.227046\n",
      "Train Epoch: 3 [22000/23974 (92%)]\tLoss: 0.207593\n",
      "Train Epoch: 3 [23000/23974 (96%)]\tLoss: 0.361728\n",
      "Train Epoch: 4 [0/23974 (0%)]\tLoss: 0.353846\n",
      "Train Epoch: 4 [1000/23974 (4%)]\tLoss: 0.223015\n",
      "Train Epoch: 4 [2000/23974 (8%)]\tLoss: 0.413342\n",
      "Train Epoch: 4 [3000/23974 (12%)]\tLoss: 0.223487\n",
      "Train Epoch: 4 [4000/23974 (17%)]\tLoss: 0.399859\n",
      "Train Epoch: 4 [5000/23974 (21%)]\tLoss: 0.328855\n",
      "Train Epoch: 4 [6000/23974 (25%)]\tLoss: 0.352699\n",
      "Train Epoch: 4 [7000/23974 (29%)]\tLoss: 0.426270\n",
      "Train Epoch: 4 [8000/23974 (33%)]\tLoss: 0.226579\n",
      "Train Epoch: 4 [9000/23974 (38%)]\tLoss: 0.341316\n",
      "Train Epoch: 4 [10000/23974 (42%)]\tLoss: 0.328365\n",
      "Train Epoch: 4 [11000/23974 (46%)]\tLoss: 0.276911\n",
      "Train Epoch: 4 [12000/23974 (50%)]\tLoss: 0.410612\n",
      "Train Epoch: 4 [13000/23974 (54%)]\tLoss: 0.292693\n",
      "Train Epoch: 4 [14000/23974 (58%)]\tLoss: 0.270235\n",
      "Train Epoch: 4 [15000/23974 (62%)]\tLoss: 0.488757\n",
      "Train Epoch: 4 [16000/23974 (67%)]\tLoss: 0.232977\n",
      "Train Epoch: 4 [17000/23974 (71%)]\tLoss: 0.418597\n",
      "Train Epoch: 4 [18000/23974 (75%)]\tLoss: 0.269169\n",
      "Train Epoch: 4 [19000/23974 (79%)]\tLoss: 0.393438\n",
      "Train Epoch: 4 [20000/23974 (83%)]\tLoss: 0.199561\n",
      "Train Epoch: 4 [21000/23974 (88%)]\tLoss: 0.429733\n",
      "Train Epoch: 4 [22000/23974 (92%)]\tLoss: 0.408421\n",
      "Train Epoch: 4 [23000/23974 (96%)]\tLoss: 0.236548\n",
      "Train Epoch: 5 [0/23974 (0%)]\tLoss: 0.281197\n",
      "Train Epoch: 5 [1000/23974 (4%)]\tLoss: 0.282598\n",
      "Train Epoch: 5 [2000/23974 (8%)]\tLoss: 0.338762\n",
      "Train Epoch: 5 [3000/23974 (12%)]\tLoss: 0.185163\n",
      "Train Epoch: 5 [4000/23974 (17%)]\tLoss: 0.248507\n",
      "Train Epoch: 5 [5000/23974 (21%)]\tLoss: 0.307419\n",
      "Train Epoch: 5 [6000/23974 (25%)]\tLoss: 0.255751\n",
      "Train Epoch: 5 [7000/23974 (29%)]\tLoss: 0.352702\n",
      "Train Epoch: 5 [8000/23974 (33%)]\tLoss: 0.318461\n",
      "Train Epoch: 5 [9000/23974 (38%)]\tLoss: 0.297373\n",
      "Train Epoch: 5 [10000/23974 (42%)]\tLoss: 0.236421\n",
      "Train Epoch: 5 [11000/23974 (46%)]\tLoss: 0.234556\n",
      "Train Epoch: 5 [12000/23974 (50%)]\tLoss: 0.387624\n",
      "Train Epoch: 5 [13000/23974 (54%)]\tLoss: 0.242659\n",
      "Train Epoch: 5 [14000/23974 (58%)]\tLoss: 0.241338\n",
      "Train Epoch: 5 [15000/23974 (62%)]\tLoss: 0.177347\n",
      "Train Epoch: 5 [16000/23974 (67%)]\tLoss: 0.329284\n",
      "Train Epoch: 5 [17000/23974 (71%)]\tLoss: 0.203672\n",
      "Train Epoch: 5 [18000/23974 (75%)]\tLoss: 0.285504\n",
      "Train Epoch: 5 [19000/23974 (79%)]\tLoss: 0.393517\n",
      "Train Epoch: 5 [20000/23974 (83%)]\tLoss: 0.285771\n",
      "Train Epoch: 5 [21000/23974 (88%)]\tLoss: 0.431103\n",
      "Train Epoch: 5 [22000/23974 (92%)]\tLoss: 0.262221\n",
      "Train Epoch: 5 [23000/23974 (96%)]\tLoss: 0.357824\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7961 (0%)]\tLoss: 0.688484\n",
      "Train Epoch: 1 [1000/7961 (12%)]\tLoss: 0.623182\n",
      "Train Epoch: 1 [2000/7961 (25%)]\tLoss: 0.479679\n",
      "Train Epoch: 1 [3000/7961 (38%)]\tLoss: 0.470367\n",
      "Train Epoch: 1 [4000/7961 (50%)]\tLoss: 0.541512\n",
      "Train Epoch: 1 [5000/7961 (62%)]\tLoss: 0.467442\n",
      "Train Epoch: 1 [6000/7961 (75%)]\tLoss: 0.543698\n",
      "Train Epoch: 1 [7000/7961 (88%)]\tLoss: 0.487935\n",
      "Train Epoch: 2 [0/7961 (0%)]\tLoss: 0.473570\n",
      "Train Epoch: 2 [1000/7961 (12%)]\tLoss: 0.418727\n",
      "Train Epoch: 2 [2000/7961 (25%)]\tLoss: 0.512506\n",
      "Train Epoch: 2 [3000/7961 (38%)]\tLoss: 0.587161\n",
      "Train Epoch: 2 [4000/7961 (50%)]\tLoss: 0.528900\n",
      "Train Epoch: 2 [5000/7961 (62%)]\tLoss: 0.562536\n",
      "Train Epoch: 2 [6000/7961 (75%)]\tLoss: 0.281971\n",
      "Train Epoch: 2 [7000/7961 (88%)]\tLoss: 0.425418\n",
      "Train Epoch: 3 [0/7961 (0%)]\tLoss: 0.504313\n",
      "Train Epoch: 3 [1000/7961 (12%)]\tLoss: 0.534832\n",
      "Train Epoch: 3 [2000/7961 (25%)]\tLoss: 0.426179\n",
      "Train Epoch: 3 [3000/7961 (38%)]\tLoss: 0.430437\n",
      "Train Epoch: 3 [4000/7961 (50%)]\tLoss: 0.488952\n",
      "Train Epoch: 3 [5000/7961 (62%)]\tLoss: 0.347795\n",
      "Train Epoch: 3 [6000/7961 (75%)]\tLoss: 0.365564\n",
      "Train Epoch: 3 [7000/7961 (88%)]\tLoss: 0.471380\n",
      "Train Epoch: 4 [0/7961 (0%)]\tLoss: 0.358622\n",
      "Train Epoch: 4 [1000/7961 (12%)]\tLoss: 0.462323\n",
      "Train Epoch: 4 [2000/7961 (25%)]\tLoss: 0.369996\n",
      "Train Epoch: 4 [3000/7961 (38%)]\tLoss: 0.380180\n",
      "Train Epoch: 4 [4000/7961 (50%)]\tLoss: 0.337604\n",
      "Train Epoch: 4 [5000/7961 (62%)]\tLoss: 0.296431\n",
      "Train Epoch: 4 [6000/7961 (75%)]\tLoss: 0.334848\n",
      "Train Epoch: 4 [7000/7961 (88%)]\tLoss: 0.350958\n",
      "Train Epoch: 5 [0/7961 (0%)]\tLoss: 0.375310\n",
      "Train Epoch: 5 [1000/7961 (12%)]\tLoss: 0.385346\n",
      "Train Epoch: 5 [2000/7961 (25%)]\tLoss: 0.384104\n",
      "Train Epoch: 5 [3000/7961 (38%)]\tLoss: 0.444066\n",
      "Train Epoch: 5 [4000/7961 (50%)]\tLoss: 0.514464\n",
      "Train Epoch: 5 [5000/7961 (62%)]\tLoss: 0.375651\n",
      "Train Epoch: 5 [6000/7961 (75%)]\tLoss: 0.284589\n",
      "Train Epoch: 5 [7000/7961 (88%)]\tLoss: 0.384046\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/15584 (0%)]\tLoss: 0.492801\n",
      "Train Epoch: 1 [1000/15584 (6%)]\tLoss: 0.400566\n",
      "Train Epoch: 1 [2000/15584 (13%)]\tLoss: 0.296306\n",
      "Train Epoch: 1 [3000/15584 (19%)]\tLoss: 0.364559\n",
      "Train Epoch: 1 [4000/15584 (26%)]\tLoss: 0.465014\n",
      "Train Epoch: 1 [5000/15584 (32%)]\tLoss: 0.338375\n",
      "Train Epoch: 1 [6000/15584 (38%)]\tLoss: 0.271993\n",
      "Train Epoch: 1 [7000/15584 (45%)]\tLoss: 0.306985\n",
      "Train Epoch: 1 [8000/15584 (51%)]\tLoss: 0.525265\n",
      "Train Epoch: 1 [9000/15584 (58%)]\tLoss: 0.381082\n",
      "Train Epoch: 1 [10000/15584 (64%)]\tLoss: 0.256463\n",
      "Train Epoch: 1 [11000/15584 (71%)]\tLoss: 0.298913\n",
      "Train Epoch: 1 [12000/15584 (77%)]\tLoss: 0.296848\n",
      "Train Epoch: 1 [13000/15584 (83%)]\tLoss: 0.375509\n",
      "Train Epoch: 1 [14000/15584 (90%)]\tLoss: 0.418105\n",
      "Train Epoch: 1 [15000/15584 (96%)]\tLoss: 0.260534\n",
      "Train Epoch: 2 [0/15584 (0%)]\tLoss: 0.282117\n",
      "Train Epoch: 2 [1000/15584 (6%)]\tLoss: 0.415247\n",
      "Train Epoch: 2 [2000/15584 (13%)]\tLoss: 0.330935\n",
      "Train Epoch: 2 [3000/15584 (19%)]\tLoss: 0.390441\n",
      "Train Epoch: 2 [4000/15584 (26%)]\tLoss: 0.281788\n",
      "Train Epoch: 2 [5000/15584 (32%)]\tLoss: 0.383333\n",
      "Train Epoch: 2 [6000/15584 (38%)]\tLoss: 0.238063\n",
      "Train Epoch: 2 [7000/15584 (45%)]\tLoss: 0.404306\n",
      "Train Epoch: 2 [8000/15584 (51%)]\tLoss: 0.290086\n",
      "Train Epoch: 2 [9000/15584 (58%)]\tLoss: 0.299223\n",
      "Train Epoch: 2 [10000/15584 (64%)]\tLoss: 0.301207\n",
      "Train Epoch: 2 [11000/15584 (71%)]\tLoss: 0.371504\n",
      "Train Epoch: 2 [12000/15584 (77%)]\tLoss: 0.242910\n",
      "Train Epoch: 2 [13000/15584 (83%)]\tLoss: 0.302066\n",
      "Train Epoch: 2 [14000/15584 (90%)]\tLoss: 0.268262\n",
      "Train Epoch: 2 [15000/15584 (96%)]\tLoss: 0.367529\n",
      "Train Epoch: 3 [0/15584 (0%)]\tLoss: 0.295378\n",
      "Train Epoch: 3 [1000/15584 (6%)]\tLoss: 0.339267\n",
      "Train Epoch: 3 [2000/15584 (13%)]\tLoss: 0.433874\n",
      "Train Epoch: 3 [3000/15584 (19%)]\tLoss: 0.242303\n",
      "Train Epoch: 3 [4000/15584 (26%)]\tLoss: 0.232202\n",
      "Train Epoch: 3 [5000/15584 (32%)]\tLoss: 0.265119\n",
      "Train Epoch: 3 [6000/15584 (38%)]\tLoss: 0.334922\n",
      "Train Epoch: 3 [7000/15584 (45%)]\tLoss: 0.378296\n",
      "Train Epoch: 3 [8000/15584 (51%)]\tLoss: 0.277375\n",
      "Train Epoch: 3 [9000/15584 (58%)]\tLoss: 0.252119\n",
      "Train Epoch: 3 [10000/15584 (64%)]\tLoss: 0.380724\n",
      "Train Epoch: 3 [11000/15584 (71%)]\tLoss: 0.251948\n",
      "Train Epoch: 3 [12000/15584 (77%)]\tLoss: 0.204421\n",
      "Train Epoch: 3 [13000/15584 (83%)]\tLoss: 0.303334\n",
      "Train Epoch: 3 [14000/15584 (90%)]\tLoss: 0.290238\n",
      "Train Epoch: 3 [15000/15584 (96%)]\tLoss: 0.184335\n",
      "Train Epoch: 4 [0/15584 (0%)]\tLoss: 0.250612\n",
      "Train Epoch: 4 [1000/15584 (6%)]\tLoss: 0.258946\n",
      "Train Epoch: 4 [2000/15584 (13%)]\tLoss: 0.182024\n",
      "Train Epoch: 4 [3000/15584 (19%)]\tLoss: 0.233810\n",
      "Train Epoch: 4 [4000/15584 (26%)]\tLoss: 0.206057\n",
      "Train Epoch: 4 [5000/15584 (32%)]\tLoss: 0.413588\n",
      "Train Epoch: 4 [6000/15584 (38%)]\tLoss: 0.192282\n",
      "Train Epoch: 4 [7000/15584 (45%)]\tLoss: 0.271933\n",
      "Train Epoch: 4 [8000/15584 (51%)]\tLoss: 0.314262\n",
      "Train Epoch: 4 [9000/15584 (58%)]\tLoss: 0.438741\n",
      "Train Epoch: 4 [10000/15584 (64%)]\tLoss: 0.181044\n",
      "Train Epoch: 4 [11000/15584 (71%)]\tLoss: 0.222909\n",
      "Train Epoch: 4 [12000/15584 (77%)]\tLoss: 0.238730\n",
      "Train Epoch: 4 [13000/15584 (83%)]\tLoss: 0.264790\n",
      "Train Epoch: 4 [14000/15584 (90%)]\tLoss: 0.251594\n",
      "Train Epoch: 4 [15000/15584 (96%)]\tLoss: 0.311579\n",
      "Train Epoch: 5 [0/15584 (0%)]\tLoss: 0.279891\n",
      "Train Epoch: 5 [1000/15584 (6%)]\tLoss: 0.243640\n",
      "Train Epoch: 5 [2000/15584 (13%)]\tLoss: 0.216904\n",
      "Train Epoch: 5 [3000/15584 (19%)]\tLoss: 0.220752\n",
      "Train Epoch: 5 [4000/15584 (26%)]\tLoss: 0.260778\n",
      "Train Epoch: 5 [5000/15584 (32%)]\tLoss: 0.327782\n",
      "Train Epoch: 5 [6000/15584 (38%)]\tLoss: 0.380558\n",
      "Train Epoch: 5 [7000/15584 (45%)]\tLoss: 0.313986\n",
      "Train Epoch: 5 [8000/15584 (51%)]\tLoss: 0.127492\n",
      "Train Epoch: 5 [9000/15584 (58%)]\tLoss: 0.203421\n",
      "Train Epoch: 5 [10000/15584 (64%)]\tLoss: 0.180578\n",
      "Train Epoch: 5 [11000/15584 (71%)]\tLoss: 0.263494\n",
      "Train Epoch: 5 [12000/15584 (77%)]\tLoss: 0.288351\n",
      "Train Epoch: 5 [13000/15584 (83%)]\tLoss: 0.311775\n",
      "Train Epoch: 5 [14000/15584 (90%)]\tLoss: 0.270717\n",
      "Train Epoch: 5 [15000/15584 (96%)]\tLoss: 0.373278\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/12481 (0%)]\tLoss: 0.170528\n",
      "Train Epoch: 1 [1000/12481 (8%)]\tLoss: 0.150819\n",
      "Train Epoch: 1 [2000/12481 (16%)]\tLoss: 0.225433\n",
      "Train Epoch: 1 [3000/12481 (24%)]\tLoss: 0.155168\n",
      "Train Epoch: 1 [4000/12481 (32%)]\tLoss: 0.255072\n",
      "Train Epoch: 1 [5000/12481 (40%)]\tLoss: 0.311383\n",
      "Train Epoch: 1 [6000/12481 (48%)]\tLoss: 0.215679\n",
      "Train Epoch: 1 [7000/12481 (56%)]\tLoss: 0.206379\n",
      "Train Epoch: 1 [8000/12481 (64%)]\tLoss: 0.309170\n",
      "Train Epoch: 1 [9000/12481 (72%)]\tLoss: 0.248258\n",
      "Train Epoch: 1 [10000/12481 (80%)]\tLoss: 0.285052\n",
      "Train Epoch: 1 [11000/12481 (88%)]\tLoss: 0.211753\n",
      "Train Epoch: 1 [12000/12481 (96%)]\tLoss: 0.302902\n",
      "Train Epoch: 2 [0/12481 (0%)]\tLoss: 0.439816\n",
      "Train Epoch: 2 [1000/12481 (8%)]\tLoss: 0.259061\n",
      "Train Epoch: 2 [2000/12481 (16%)]\tLoss: 0.240843\n",
      "Train Epoch: 2 [3000/12481 (24%)]\tLoss: 0.351242\n",
      "Train Epoch: 2 [4000/12481 (32%)]\tLoss: 0.339006\n",
      "Train Epoch: 2 [5000/12481 (40%)]\tLoss: 0.284451\n",
      "Train Epoch: 2 [6000/12481 (48%)]\tLoss: 0.311099\n",
      "Train Epoch: 2 [7000/12481 (56%)]\tLoss: 0.137763\n",
      "Train Epoch: 2 [8000/12481 (64%)]\tLoss: 0.181748\n",
      "Train Epoch: 2 [9000/12481 (72%)]\tLoss: 0.168185\n",
      "Train Epoch: 2 [10000/12481 (80%)]\tLoss: 0.209710\n",
      "Train Epoch: 2 [11000/12481 (88%)]\tLoss: 0.194611\n",
      "Train Epoch: 2 [12000/12481 (96%)]\tLoss: 0.254235\n",
      "Train Epoch: 3 [0/12481 (0%)]\tLoss: 0.176752\n",
      "Train Epoch: 3 [1000/12481 (8%)]\tLoss: 0.287581\n",
      "Train Epoch: 3 [2000/12481 (16%)]\tLoss: 0.257805\n",
      "Train Epoch: 3 [3000/12481 (24%)]\tLoss: 0.235659\n",
      "Train Epoch: 3 [4000/12481 (32%)]\tLoss: 0.182139\n",
      "Train Epoch: 3 [5000/12481 (40%)]\tLoss: 0.257008\n",
      "Train Epoch: 3 [6000/12481 (48%)]\tLoss: 0.364780\n",
      "Train Epoch: 3 [7000/12481 (56%)]\tLoss: 0.166761\n",
      "Train Epoch: 3 [8000/12481 (64%)]\tLoss: 0.137969\n",
      "Train Epoch: 3 [9000/12481 (72%)]\tLoss: 0.264166\n",
      "Train Epoch: 3 [10000/12481 (80%)]\tLoss: 0.297522\n",
      "Train Epoch: 3 [11000/12481 (88%)]\tLoss: 0.219626\n",
      "Train Epoch: 3 [12000/12481 (96%)]\tLoss: 0.194582\n",
      "Train Epoch: 4 [0/12481 (0%)]\tLoss: 0.189986\n",
      "Train Epoch: 4 [1000/12481 (8%)]\tLoss: 0.243938\n",
      "Train Epoch: 4 [2000/12481 (16%)]\tLoss: 0.231594\n",
      "Train Epoch: 4 [3000/12481 (24%)]\tLoss: 0.329325\n",
      "Train Epoch: 4 [4000/12481 (32%)]\tLoss: 0.206621\n",
      "Train Epoch: 4 [5000/12481 (40%)]\tLoss: 0.202812\n",
      "Train Epoch: 4 [6000/12481 (48%)]\tLoss: 0.221999\n",
      "Train Epoch: 4 [7000/12481 (56%)]\tLoss: 0.234629\n",
      "Train Epoch: 4 [8000/12481 (64%)]\tLoss: 0.151135\n",
      "Train Epoch: 4 [9000/12481 (72%)]\tLoss: 0.215160\n",
      "Train Epoch: 4 [10000/12481 (80%)]\tLoss: 0.101682\n",
      "Train Epoch: 4 [11000/12481 (88%)]\tLoss: 0.263954\n",
      "Train Epoch: 4 [12000/12481 (96%)]\tLoss: 0.239782\n",
      "Train Epoch: 5 [0/12481 (0%)]\tLoss: 0.100797\n",
      "Train Epoch: 5 [1000/12481 (8%)]\tLoss: 0.176950\n",
      "Train Epoch: 5 [2000/12481 (16%)]\tLoss: 0.321642\n",
      "Train Epoch: 5 [3000/12481 (24%)]\tLoss: 0.230692\n",
      "Train Epoch: 5 [4000/12481 (32%)]\tLoss: 0.221049\n",
      "Train Epoch: 5 [5000/12481 (40%)]\tLoss: 0.089307\n",
      "Train Epoch: 5 [6000/12481 (48%)]\tLoss: 0.103282\n",
      "Train Epoch: 5 [7000/12481 (56%)]\tLoss: 0.288491\n",
      "Train Epoch: 5 [8000/12481 (64%)]\tLoss: 0.285313\n",
      "Train Epoch: 5 [9000/12481 (72%)]\tLoss: 0.108246\n",
      "Train Epoch: 5 [10000/12481 (80%)]\tLoss: 0.192135\n",
      "Train Epoch: 5 [11000/12481 (88%)]\tLoss: 0.278387\n",
      "Train Epoch: 5 [12000/12481 (96%)]\tLoss: 0.295546\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "4\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9524, Accuracy: 8221/10000 (82%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/23974 (0%)]\tLoss: 0.427669\n",
      "Train Epoch: 1 [1000/23974 (4%)]\tLoss: 0.252771\n",
      "Train Epoch: 1 [2000/23974 (8%)]\tLoss: 0.233300\n",
      "Train Epoch: 1 [3000/23974 (12%)]\tLoss: 0.398515\n",
      "Train Epoch: 1 [4000/23974 (17%)]\tLoss: 0.310825\n",
      "Train Epoch: 1 [5000/23974 (21%)]\tLoss: 0.374308\n",
      "Train Epoch: 1 [6000/23974 (25%)]\tLoss: 0.305825\n",
      "Train Epoch: 1 [7000/23974 (29%)]\tLoss: 0.253145\n",
      "Train Epoch: 1 [8000/23974 (33%)]\tLoss: 0.303742\n",
      "Train Epoch: 1 [9000/23974 (38%)]\tLoss: 0.317021\n",
      "Train Epoch: 1 [10000/23974 (42%)]\tLoss: 0.382454\n",
      "Train Epoch: 1 [11000/23974 (46%)]\tLoss: 0.302674\n",
      "Train Epoch: 1 [12000/23974 (50%)]\tLoss: 0.296823\n",
      "Train Epoch: 1 [13000/23974 (54%)]\tLoss: 0.329117\n",
      "Train Epoch: 1 [14000/23974 (58%)]\tLoss: 0.250852\n",
      "Train Epoch: 1 [15000/23974 (62%)]\tLoss: 0.303111\n",
      "Train Epoch: 1 [16000/23974 (67%)]\tLoss: 0.313677\n",
      "Train Epoch: 1 [17000/23974 (71%)]\tLoss: 0.241623\n",
      "Train Epoch: 1 [18000/23974 (75%)]\tLoss: 0.341670\n",
      "Train Epoch: 1 [19000/23974 (79%)]\tLoss: 0.304382\n",
      "Train Epoch: 1 [20000/23974 (83%)]\tLoss: 0.240916\n",
      "Train Epoch: 1 [21000/23974 (88%)]\tLoss: 0.287791\n",
      "Train Epoch: 1 [22000/23974 (92%)]\tLoss: 0.370384\n",
      "Train Epoch: 1 [23000/23974 (96%)]\tLoss: 0.249381\n",
      "Train Epoch: 2 [0/23974 (0%)]\tLoss: 0.259618\n",
      "Train Epoch: 2 [1000/23974 (4%)]\tLoss: 0.354035\n",
      "Train Epoch: 2 [2000/23974 (8%)]\tLoss: 0.226820\n",
      "Train Epoch: 2 [3000/23974 (12%)]\tLoss: 0.465798\n",
      "Train Epoch: 2 [4000/23974 (17%)]\tLoss: 0.334556\n",
      "Train Epoch: 2 [5000/23974 (21%)]\tLoss: 0.297221\n",
      "Train Epoch: 2 [6000/23974 (25%)]\tLoss: 0.298980\n",
      "Train Epoch: 2 [7000/23974 (29%)]\tLoss: 0.277369\n",
      "Train Epoch: 2 [8000/23974 (33%)]\tLoss: 0.381008\n",
      "Train Epoch: 2 [9000/23974 (38%)]\tLoss: 0.279083\n",
      "Train Epoch: 2 [10000/23974 (42%)]\tLoss: 0.319897\n",
      "Train Epoch: 2 [11000/23974 (46%)]\tLoss: 0.389146\n",
      "Train Epoch: 2 [12000/23974 (50%)]\tLoss: 0.199391\n",
      "Train Epoch: 2 [13000/23974 (54%)]\tLoss: 0.267316\n",
      "Train Epoch: 2 [14000/23974 (58%)]\tLoss: 0.345579\n",
      "Train Epoch: 2 [15000/23974 (62%)]\tLoss: 0.256736\n",
      "Train Epoch: 2 [16000/23974 (67%)]\tLoss: 0.287418\n",
      "Train Epoch: 2 [17000/23974 (71%)]\tLoss: 0.280044\n",
      "Train Epoch: 2 [18000/23974 (75%)]\tLoss: 0.298699\n",
      "Train Epoch: 2 [19000/23974 (79%)]\tLoss: 0.231424\n",
      "Train Epoch: 2 [20000/23974 (83%)]\tLoss: 0.214978\n",
      "Train Epoch: 2 [21000/23974 (88%)]\tLoss: 0.172131\n",
      "Train Epoch: 2 [22000/23974 (92%)]\tLoss: 0.315560\n",
      "Train Epoch: 2 [23000/23974 (96%)]\tLoss: 0.220987\n",
      "Train Epoch: 3 [0/23974 (0%)]\tLoss: 0.557844\n",
      "Train Epoch: 3 [1000/23974 (4%)]\tLoss: 0.379466\n",
      "Train Epoch: 3 [2000/23974 (8%)]\tLoss: 0.348323\n",
      "Train Epoch: 3 [3000/23974 (12%)]\tLoss: 0.338369\n",
      "Train Epoch: 3 [4000/23974 (17%)]\tLoss: 0.390374\n",
      "Train Epoch: 3 [5000/23974 (21%)]\tLoss: 0.351405\n",
      "Train Epoch: 3 [6000/23974 (25%)]\tLoss: 0.199831\n",
      "Train Epoch: 3 [7000/23974 (29%)]\tLoss: 0.300678\n",
      "Train Epoch: 3 [8000/23974 (33%)]\tLoss: 0.257921\n",
      "Train Epoch: 3 [9000/23974 (38%)]\tLoss: 0.343277\n",
      "Train Epoch: 3 [10000/23974 (42%)]\tLoss: 0.373533\n",
      "Train Epoch: 3 [11000/23974 (46%)]\tLoss: 0.341397\n",
      "Train Epoch: 3 [12000/23974 (50%)]\tLoss: 0.221442\n",
      "Train Epoch: 3 [13000/23974 (54%)]\tLoss: 0.364324\n",
      "Train Epoch: 3 [14000/23974 (58%)]\tLoss: 0.320455\n",
      "Train Epoch: 3 [15000/23974 (62%)]\tLoss: 0.278649\n",
      "Train Epoch: 3 [16000/23974 (67%)]\tLoss: 0.288074\n",
      "Train Epoch: 3 [17000/23974 (71%)]\tLoss: 0.292926\n",
      "Train Epoch: 3 [18000/23974 (75%)]\tLoss: 0.240094\n",
      "Train Epoch: 3 [19000/23974 (79%)]\tLoss: 0.293152\n",
      "Train Epoch: 3 [20000/23974 (83%)]\tLoss: 0.350435\n",
      "Train Epoch: 3 [21000/23974 (88%)]\tLoss: 0.284430\n",
      "Train Epoch: 3 [22000/23974 (92%)]\tLoss: 0.294758\n",
      "Train Epoch: 3 [23000/23974 (96%)]\tLoss: 0.272718\n",
      "Train Epoch: 4 [0/23974 (0%)]\tLoss: 0.202162\n",
      "Train Epoch: 4 [1000/23974 (4%)]\tLoss: 0.201630\n",
      "Train Epoch: 4 [2000/23974 (8%)]\tLoss: 0.246893\n",
      "Train Epoch: 4 [3000/23974 (12%)]\tLoss: 0.315924\n",
      "Train Epoch: 4 [4000/23974 (17%)]\tLoss: 0.280821\n",
      "Train Epoch: 4 [5000/23974 (21%)]\tLoss: 0.239949\n",
      "Train Epoch: 4 [6000/23974 (25%)]\tLoss: 0.201306\n",
      "Train Epoch: 4 [7000/23974 (29%)]\tLoss: 0.339420\n",
      "Train Epoch: 4 [8000/23974 (33%)]\tLoss: 0.164114\n",
      "Train Epoch: 4 [9000/23974 (38%)]\tLoss: 0.258427\n",
      "Train Epoch: 4 [10000/23974 (42%)]\tLoss: 0.197875\n",
      "Train Epoch: 4 [11000/23974 (46%)]\tLoss: 0.389047\n",
      "Train Epoch: 4 [12000/23974 (50%)]\tLoss: 0.208590\n",
      "Train Epoch: 4 [13000/23974 (54%)]\tLoss: 0.347363\n",
      "Train Epoch: 4 [14000/23974 (58%)]\tLoss: 0.282754\n",
      "Train Epoch: 4 [15000/23974 (62%)]\tLoss: 0.355270\n",
      "Train Epoch: 4 [16000/23974 (67%)]\tLoss: 0.274447\n",
      "Train Epoch: 4 [17000/23974 (71%)]\tLoss: 0.242628\n",
      "Train Epoch: 4 [18000/23974 (75%)]\tLoss: 0.313343\n",
      "Train Epoch: 4 [19000/23974 (79%)]\tLoss: 0.280626\n",
      "Train Epoch: 4 [20000/23974 (83%)]\tLoss: 0.266652\n",
      "Train Epoch: 4 [21000/23974 (88%)]\tLoss: 0.377239\n",
      "Train Epoch: 4 [22000/23974 (92%)]\tLoss: 0.376849\n",
      "Train Epoch: 4 [23000/23974 (96%)]\tLoss: 0.420706\n",
      "Train Epoch: 5 [0/23974 (0%)]\tLoss: 0.187844\n",
      "Train Epoch: 5 [1000/23974 (4%)]\tLoss: 0.254650\n",
      "Train Epoch: 5 [2000/23974 (8%)]\tLoss: 0.279791\n",
      "Train Epoch: 5 [3000/23974 (12%)]\tLoss: 0.441452\n",
      "Train Epoch: 5 [4000/23974 (17%)]\tLoss: 0.332557\n",
      "Train Epoch: 5 [5000/23974 (21%)]\tLoss: 0.326587\n",
      "Train Epoch: 5 [6000/23974 (25%)]\tLoss: 0.182197\n",
      "Train Epoch: 5 [7000/23974 (29%)]\tLoss: 0.423711\n",
      "Train Epoch: 5 [8000/23974 (33%)]\tLoss: 0.232237\n",
      "Train Epoch: 5 [9000/23974 (38%)]\tLoss: 0.182193\n",
      "Train Epoch: 5 [10000/23974 (42%)]\tLoss: 0.255764\n",
      "Train Epoch: 5 [11000/23974 (46%)]\tLoss: 0.242345\n",
      "Train Epoch: 5 [12000/23974 (50%)]\tLoss: 0.314045\n",
      "Train Epoch: 5 [13000/23974 (54%)]\tLoss: 0.205588\n",
      "Train Epoch: 5 [14000/23974 (58%)]\tLoss: 0.279665\n",
      "Train Epoch: 5 [15000/23974 (62%)]\tLoss: 0.227613\n",
      "Train Epoch: 5 [16000/23974 (67%)]\tLoss: 0.299702\n",
      "Train Epoch: 5 [17000/23974 (71%)]\tLoss: 0.287772\n",
      "Train Epoch: 5 [18000/23974 (75%)]\tLoss: 0.225135\n",
      "Train Epoch: 5 [19000/23974 (79%)]\tLoss: 0.367290\n",
      "Train Epoch: 5 [20000/23974 (83%)]\tLoss: 0.258887\n",
      "Train Epoch: 5 [21000/23974 (88%)]\tLoss: 0.248109\n",
      "Train Epoch: 5 [22000/23974 (92%)]\tLoss: 0.348450\n",
      "Train Epoch: 5 [23000/23974 (96%)]\tLoss: 0.280256\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7961 (0%)]\tLoss: 0.377007\n",
      "Train Epoch: 1 [1000/7961 (12%)]\tLoss: 0.565157\n",
      "Train Epoch: 1 [2000/7961 (25%)]\tLoss: 0.318085\n",
      "Train Epoch: 1 [3000/7961 (38%)]\tLoss: 0.359808\n",
      "Train Epoch: 1 [4000/7961 (50%)]\tLoss: 0.382298\n",
      "Train Epoch: 1 [5000/7961 (62%)]\tLoss: 0.366192\n",
      "Train Epoch: 1 [6000/7961 (75%)]\tLoss: 0.522732\n",
      "Train Epoch: 1 [7000/7961 (88%)]\tLoss: 0.408238\n",
      "Train Epoch: 2 [0/7961 (0%)]\tLoss: 0.437900\n",
      "Train Epoch: 2 [1000/7961 (12%)]\tLoss: 0.348606\n",
      "Train Epoch: 2 [2000/7961 (25%)]\tLoss: 0.431382\n",
      "Train Epoch: 2 [3000/7961 (38%)]\tLoss: 0.369212\n",
      "Train Epoch: 2 [4000/7961 (50%)]\tLoss: 0.349776\n",
      "Train Epoch: 2 [5000/7961 (62%)]\tLoss: 0.441156\n",
      "Train Epoch: 2 [6000/7961 (75%)]\tLoss: 0.414813\n",
      "Train Epoch: 2 [7000/7961 (88%)]\tLoss: 0.386917\n",
      "Train Epoch: 3 [0/7961 (0%)]\tLoss: 0.298574\n",
      "Train Epoch: 3 [1000/7961 (12%)]\tLoss: 0.400368\n",
      "Train Epoch: 3 [2000/7961 (25%)]\tLoss: 0.406988\n",
      "Train Epoch: 3 [3000/7961 (38%)]\tLoss: 0.496686\n",
      "Train Epoch: 3 [4000/7961 (50%)]\tLoss: 0.471456\n",
      "Train Epoch: 3 [5000/7961 (62%)]\tLoss: 0.426746\n",
      "Train Epoch: 3 [6000/7961 (75%)]\tLoss: 0.411052\n",
      "Train Epoch: 3 [7000/7961 (88%)]\tLoss: 0.391001\n",
      "Train Epoch: 4 [0/7961 (0%)]\tLoss: 0.485050\n",
      "Train Epoch: 4 [1000/7961 (12%)]\tLoss: 0.343745\n",
      "Train Epoch: 4 [2000/7961 (25%)]\tLoss: 0.392438\n",
      "Train Epoch: 4 [3000/7961 (38%)]\tLoss: 0.284571\n",
      "Train Epoch: 4 [4000/7961 (50%)]\tLoss: 0.329251\n",
      "Train Epoch: 4 [5000/7961 (62%)]\tLoss: 0.289189\n",
      "Train Epoch: 4 [6000/7961 (75%)]\tLoss: 0.446861\n",
      "Train Epoch: 4 [7000/7961 (88%)]\tLoss: 0.261283\n",
      "Train Epoch: 5 [0/7961 (0%)]\tLoss: 0.437583\n",
      "Train Epoch: 5 [1000/7961 (12%)]\tLoss: 0.414117\n",
      "Train Epoch: 5 [2000/7961 (25%)]\tLoss: 0.220866\n",
      "Train Epoch: 5 [3000/7961 (38%)]\tLoss: 0.328845\n",
      "Train Epoch: 5 [4000/7961 (50%)]\tLoss: 0.246951\n",
      "Train Epoch: 5 [5000/7961 (62%)]\tLoss: 0.340888\n",
      "Train Epoch: 5 [6000/7961 (75%)]\tLoss: 0.305262\n",
      "Train Epoch: 5 [7000/7961 (88%)]\tLoss: 0.368240\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/15584 (0%)]\tLoss: 0.427900\n",
      "Train Epoch: 1 [1000/15584 (6%)]\tLoss: 0.264536\n",
      "Train Epoch: 1 [2000/15584 (13%)]\tLoss: 0.268483\n",
      "Train Epoch: 1 [3000/15584 (19%)]\tLoss: 0.248043\n",
      "Train Epoch: 1 [4000/15584 (26%)]\tLoss: 0.229315\n",
      "Train Epoch: 1 [5000/15584 (32%)]\tLoss: 0.209561\n",
      "Train Epoch: 1 [6000/15584 (38%)]\tLoss: 0.327360\n",
      "Train Epoch: 1 [7000/15584 (45%)]\tLoss: 0.220683\n",
      "Train Epoch: 1 [8000/15584 (51%)]\tLoss: 0.403187\n",
      "Train Epoch: 1 [9000/15584 (58%)]\tLoss: 0.175249\n",
      "Train Epoch: 1 [10000/15584 (64%)]\tLoss: 0.419315\n",
      "Train Epoch: 1 [11000/15584 (71%)]\tLoss: 0.294878\n",
      "Train Epoch: 1 [12000/15584 (77%)]\tLoss: 0.277331\n",
      "Train Epoch: 1 [13000/15584 (83%)]\tLoss: 0.303018\n",
      "Train Epoch: 1 [14000/15584 (90%)]\tLoss: 0.349694\n",
      "Train Epoch: 1 [15000/15584 (96%)]\tLoss: 0.222752\n",
      "Train Epoch: 2 [0/15584 (0%)]\tLoss: 0.270077\n",
      "Train Epoch: 2 [1000/15584 (6%)]\tLoss: 0.367555\n",
      "Train Epoch: 2 [2000/15584 (13%)]\tLoss: 0.200850\n",
      "Train Epoch: 2 [3000/15584 (19%)]\tLoss: 0.364143\n",
      "Train Epoch: 2 [4000/15584 (26%)]\tLoss: 0.260860\n",
      "Train Epoch: 2 [5000/15584 (32%)]\tLoss: 0.172774\n",
      "Train Epoch: 2 [6000/15584 (38%)]\tLoss: 0.258400\n",
      "Train Epoch: 2 [7000/15584 (45%)]\tLoss: 0.303107\n",
      "Train Epoch: 2 [8000/15584 (51%)]\tLoss: 0.316448\n",
      "Train Epoch: 2 [9000/15584 (58%)]\tLoss: 0.332596\n",
      "Train Epoch: 2 [10000/15584 (64%)]\tLoss: 0.196047\n",
      "Train Epoch: 2 [11000/15584 (71%)]\tLoss: 0.237446\n",
      "Train Epoch: 2 [12000/15584 (77%)]\tLoss: 0.277072\n",
      "Train Epoch: 2 [13000/15584 (83%)]\tLoss: 0.268646\n",
      "Train Epoch: 2 [14000/15584 (90%)]\tLoss: 0.280463\n",
      "Train Epoch: 2 [15000/15584 (96%)]\tLoss: 0.274044\n",
      "Train Epoch: 3 [0/15584 (0%)]\tLoss: 0.169560\n",
      "Train Epoch: 3 [1000/15584 (6%)]\tLoss: 0.256375\n",
      "Train Epoch: 3 [2000/15584 (13%)]\tLoss: 0.322568\n",
      "Train Epoch: 3 [3000/15584 (19%)]\tLoss: 0.173845\n",
      "Train Epoch: 3 [4000/15584 (26%)]\tLoss: 0.274263\n",
      "Train Epoch: 3 [5000/15584 (32%)]\tLoss: 0.201945\n",
      "Train Epoch: 3 [6000/15584 (38%)]\tLoss: 0.168864\n",
      "Train Epoch: 3 [7000/15584 (45%)]\tLoss: 0.329855\n",
      "Train Epoch: 3 [8000/15584 (51%)]\tLoss: 0.319017\n",
      "Train Epoch: 3 [9000/15584 (58%)]\tLoss: 0.330013\n",
      "Train Epoch: 3 [10000/15584 (64%)]\tLoss: 0.319948\n",
      "Train Epoch: 3 [11000/15584 (71%)]\tLoss: 0.276367\n",
      "Train Epoch: 3 [12000/15584 (77%)]\tLoss: 0.230298\n",
      "Train Epoch: 3 [13000/15584 (83%)]\tLoss: 0.297417\n",
      "Train Epoch: 3 [14000/15584 (90%)]\tLoss: 0.394667\n",
      "Train Epoch: 3 [15000/15584 (96%)]\tLoss: 0.226114\n",
      "Train Epoch: 4 [0/15584 (0%)]\tLoss: 0.226750\n",
      "Train Epoch: 4 [1000/15584 (6%)]\tLoss: 0.173119\n",
      "Train Epoch: 4 [2000/15584 (13%)]\tLoss: 0.229496\n",
      "Train Epoch: 4 [3000/15584 (19%)]\tLoss: 0.184888\n",
      "Train Epoch: 4 [4000/15584 (26%)]\tLoss: 0.162954\n",
      "Train Epoch: 4 [5000/15584 (32%)]\tLoss: 0.238889\n",
      "Train Epoch: 4 [6000/15584 (38%)]\tLoss: 0.219215\n",
      "Train Epoch: 4 [7000/15584 (45%)]\tLoss: 0.242328\n",
      "Train Epoch: 4 [8000/15584 (51%)]\tLoss: 0.221338\n",
      "Train Epoch: 4 [9000/15584 (58%)]\tLoss: 0.310560\n",
      "Train Epoch: 4 [10000/15584 (64%)]\tLoss: 0.229680\n",
      "Train Epoch: 4 [11000/15584 (71%)]\tLoss: 0.296801\n",
      "Train Epoch: 4 [12000/15584 (77%)]\tLoss: 0.232810\n",
      "Train Epoch: 4 [13000/15584 (83%)]\tLoss: 0.247851\n",
      "Train Epoch: 4 [14000/15584 (90%)]\tLoss: 0.283770\n",
      "Train Epoch: 4 [15000/15584 (96%)]\tLoss: 0.263797\n",
      "Train Epoch: 5 [0/15584 (0%)]\tLoss: 0.306447\n",
      "Train Epoch: 5 [1000/15584 (6%)]\tLoss: 0.286946\n",
      "Train Epoch: 5 [2000/15584 (13%)]\tLoss: 0.222042\n",
      "Train Epoch: 5 [3000/15584 (19%)]\tLoss: 0.270626\n",
      "Train Epoch: 5 [4000/15584 (26%)]\tLoss: 0.220512\n",
      "Train Epoch: 5 [5000/15584 (32%)]\tLoss: 0.286331\n",
      "Train Epoch: 5 [6000/15584 (38%)]\tLoss: 0.196651\n",
      "Train Epoch: 5 [7000/15584 (45%)]\tLoss: 0.279462\n",
      "Train Epoch: 5 [8000/15584 (51%)]\tLoss: 0.233401\n",
      "Train Epoch: 5 [9000/15584 (58%)]\tLoss: 0.182040\n",
      "Train Epoch: 5 [10000/15584 (64%)]\tLoss: 0.207590\n",
      "Train Epoch: 5 [11000/15584 (71%)]\tLoss: 0.177300\n",
      "Train Epoch: 5 [12000/15584 (77%)]\tLoss: 0.175998\n",
      "Train Epoch: 5 [13000/15584 (83%)]\tLoss: 0.239587\n",
      "Train Epoch: 5 [14000/15584 (90%)]\tLoss: 0.218816\n",
      "Train Epoch: 5 [15000/15584 (96%)]\tLoss: 0.223113\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/12481 (0%)]\tLoss: 0.257094\n",
      "Train Epoch: 1 [1000/12481 (8%)]\tLoss: 0.257896\n",
      "Train Epoch: 1 [2000/12481 (16%)]\tLoss: 0.165932\n",
      "Train Epoch: 1 [3000/12481 (24%)]\tLoss: 0.297717\n",
      "Train Epoch: 1 [4000/12481 (32%)]\tLoss: 0.302200\n",
      "Train Epoch: 1 [5000/12481 (40%)]\tLoss: 0.155875\n",
      "Train Epoch: 1 [6000/12481 (48%)]\tLoss: 0.250353\n",
      "Train Epoch: 1 [7000/12481 (56%)]\tLoss: 0.354683\n",
      "Train Epoch: 1 [8000/12481 (64%)]\tLoss: 0.235153\n",
      "Train Epoch: 1 [9000/12481 (72%)]\tLoss: 0.256884\n",
      "Train Epoch: 1 [10000/12481 (80%)]\tLoss: 0.238070\n",
      "Train Epoch: 1 [11000/12481 (88%)]\tLoss: 0.188045\n",
      "Train Epoch: 1 [12000/12481 (96%)]\tLoss: 0.267881\n",
      "Train Epoch: 2 [0/12481 (0%)]\tLoss: 0.155647\n",
      "Train Epoch: 2 [1000/12481 (8%)]\tLoss: 0.223134\n",
      "Train Epoch: 2 [2000/12481 (16%)]\tLoss: 0.236778\n",
      "Train Epoch: 2 [3000/12481 (24%)]\tLoss: 0.233228\n",
      "Train Epoch: 2 [4000/12481 (32%)]\tLoss: 0.170006\n",
      "Train Epoch: 2 [5000/12481 (40%)]\tLoss: 0.267331\n",
      "Train Epoch: 2 [6000/12481 (48%)]\tLoss: 0.168597\n",
      "Train Epoch: 2 [7000/12481 (56%)]\tLoss: 0.195770\n",
      "Train Epoch: 2 [8000/12481 (64%)]\tLoss: 0.139918\n",
      "Train Epoch: 2 [9000/12481 (72%)]\tLoss: 0.172993\n",
      "Train Epoch: 2 [10000/12481 (80%)]\tLoss: 0.240598\n",
      "Train Epoch: 2 [11000/12481 (88%)]\tLoss: 0.169868\n",
      "Train Epoch: 2 [12000/12481 (96%)]\tLoss: 0.209546\n",
      "Train Epoch: 3 [0/12481 (0%)]\tLoss: 0.163887\n",
      "Train Epoch: 3 [1000/12481 (8%)]\tLoss: 0.274097\n",
      "Train Epoch: 3 [2000/12481 (16%)]\tLoss: 0.261744\n",
      "Train Epoch: 3 [3000/12481 (24%)]\tLoss: 0.281238\n",
      "Train Epoch: 3 [4000/12481 (32%)]\tLoss: 0.118938\n",
      "Train Epoch: 3 [5000/12481 (40%)]\tLoss: 0.161836\n",
      "Train Epoch: 3 [6000/12481 (48%)]\tLoss: 0.200206\n",
      "Train Epoch: 3 [7000/12481 (56%)]\tLoss: 0.285834\n",
      "Train Epoch: 3 [8000/12481 (64%)]\tLoss: 0.242060\n",
      "Train Epoch: 3 [9000/12481 (72%)]\tLoss: 0.155218\n",
      "Train Epoch: 3 [10000/12481 (80%)]\tLoss: 0.201316\n",
      "Train Epoch: 3 [11000/12481 (88%)]\tLoss: 0.429583\n",
      "Train Epoch: 3 [12000/12481 (96%)]\tLoss: 0.162382\n",
      "Train Epoch: 4 [0/12481 (0%)]\tLoss: 0.209463\n",
      "Train Epoch: 4 [1000/12481 (8%)]\tLoss: 0.169048\n",
      "Train Epoch: 4 [2000/12481 (16%)]\tLoss: 0.238486\n",
      "Train Epoch: 4 [3000/12481 (24%)]\tLoss: 0.152067\n",
      "Train Epoch: 4 [4000/12481 (32%)]\tLoss: 0.134020\n",
      "Train Epoch: 4 [5000/12481 (40%)]\tLoss: 0.203044\n",
      "Train Epoch: 4 [6000/12481 (48%)]\tLoss: 0.161694\n",
      "Train Epoch: 4 [7000/12481 (56%)]\tLoss: 0.208713\n",
      "Train Epoch: 4 [8000/12481 (64%)]\tLoss: 0.264967\n",
      "Train Epoch: 4 [9000/12481 (72%)]\tLoss: 0.185165\n",
      "Train Epoch: 4 [10000/12481 (80%)]\tLoss: 0.275432\n",
      "Train Epoch: 4 [11000/12481 (88%)]\tLoss: 0.101462\n",
      "Train Epoch: 4 [12000/12481 (96%)]\tLoss: 0.152492\n",
      "Train Epoch: 5 [0/12481 (0%)]\tLoss: 0.188821\n",
      "Train Epoch: 5 [1000/12481 (8%)]\tLoss: 0.210036\n",
      "Train Epoch: 5 [2000/12481 (16%)]\tLoss: 0.229761\n",
      "Train Epoch: 5 [3000/12481 (24%)]\tLoss: 0.178908\n",
      "Train Epoch: 5 [4000/12481 (32%)]\tLoss: 0.107819\n",
      "Train Epoch: 5 [5000/12481 (40%)]\tLoss: 0.215057\n",
      "Train Epoch: 5 [6000/12481 (48%)]\tLoss: 0.203752\n",
      "Train Epoch: 5 [7000/12481 (56%)]\tLoss: 0.146136\n",
      "Train Epoch: 5 [8000/12481 (64%)]\tLoss: 0.127594\n",
      "Train Epoch: 5 [9000/12481 (72%)]\tLoss: 0.136553\n",
      "Train Epoch: 5 [10000/12481 (80%)]\tLoss: 0.145144\n",
      "Train Epoch: 5 [11000/12481 (88%)]\tLoss: 0.187482\n",
      "Train Epoch: 5 [12000/12481 (96%)]\tLoss: 0.144687\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "4\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8970, Accuracy: 8374/10000 (84%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/23974 (0%)]\tLoss: 0.265561\n",
      "Train Epoch: 1 [1000/23974 (4%)]\tLoss: 0.311531\n",
      "Train Epoch: 1 [2000/23974 (8%)]\tLoss: 0.260392\n",
      "Train Epoch: 1 [3000/23974 (12%)]\tLoss: 0.370714\n",
      "Train Epoch: 1 [4000/23974 (17%)]\tLoss: 0.231457\n",
      "Train Epoch: 1 [5000/23974 (21%)]\tLoss: 0.333606\n",
      "Train Epoch: 1 [6000/23974 (25%)]\tLoss: 0.303775\n",
      "Train Epoch: 1 [7000/23974 (29%)]\tLoss: 0.332374\n",
      "Train Epoch: 1 [8000/23974 (33%)]\tLoss: 0.362698\n",
      "Train Epoch: 1 [9000/23974 (38%)]\tLoss: 0.271287\n",
      "Train Epoch: 1 [10000/23974 (42%)]\tLoss: 0.226849\n",
      "Train Epoch: 1 [11000/23974 (46%)]\tLoss: 0.378040\n",
      "Train Epoch: 1 [12000/23974 (50%)]\tLoss: 0.315148\n",
      "Train Epoch: 1 [13000/23974 (54%)]\tLoss: 0.262760\n",
      "Train Epoch: 1 [14000/23974 (58%)]\tLoss: 0.186896\n",
      "Train Epoch: 1 [15000/23974 (62%)]\tLoss: 0.382936\n",
      "Train Epoch: 1 [16000/23974 (67%)]\tLoss: 0.318832\n",
      "Train Epoch: 1 [17000/23974 (71%)]\tLoss: 0.319935\n",
      "Train Epoch: 1 [18000/23974 (75%)]\tLoss: 0.232731\n",
      "Train Epoch: 1 [19000/23974 (79%)]\tLoss: 0.317306\n",
      "Train Epoch: 1 [20000/23974 (83%)]\tLoss: 0.385373\n",
      "Train Epoch: 1 [21000/23974 (88%)]\tLoss: 0.209336\n",
      "Train Epoch: 1 [22000/23974 (92%)]\tLoss: 0.241741\n",
      "Train Epoch: 1 [23000/23974 (96%)]\tLoss: 0.290476\n",
      "Train Epoch: 2 [0/23974 (0%)]\tLoss: 0.250045\n",
      "Train Epoch: 2 [1000/23974 (4%)]\tLoss: 0.261731\n",
      "Train Epoch: 2 [2000/23974 (8%)]\tLoss: 0.249113\n",
      "Train Epoch: 2 [3000/23974 (12%)]\tLoss: 0.314913\n",
      "Train Epoch: 2 [4000/23974 (17%)]\tLoss: 0.327552\n",
      "Train Epoch: 2 [5000/23974 (21%)]\tLoss: 0.283041\n",
      "Train Epoch: 2 [6000/23974 (25%)]\tLoss: 0.361058\n",
      "Train Epoch: 2 [7000/23974 (29%)]\tLoss: 0.245394\n",
      "Train Epoch: 2 [8000/23974 (33%)]\tLoss: 0.281153\n",
      "Train Epoch: 2 [9000/23974 (38%)]\tLoss: 0.357012\n",
      "Train Epoch: 2 [10000/23974 (42%)]\tLoss: 0.260710\n",
      "Train Epoch: 2 [11000/23974 (46%)]\tLoss: 0.469483\n",
      "Train Epoch: 2 [12000/23974 (50%)]\tLoss: 0.155549\n",
      "Train Epoch: 2 [13000/23974 (54%)]\tLoss: 0.323068\n",
      "Train Epoch: 2 [14000/23974 (58%)]\tLoss: 0.323856\n",
      "Train Epoch: 2 [15000/23974 (62%)]\tLoss: 0.364930\n",
      "Train Epoch: 2 [16000/23974 (67%)]\tLoss: 0.182105\n",
      "Train Epoch: 2 [17000/23974 (71%)]\tLoss: 0.364755\n",
      "Train Epoch: 2 [18000/23974 (75%)]\tLoss: 0.291046\n",
      "Train Epoch: 2 [19000/23974 (79%)]\tLoss: 0.188600\n",
      "Train Epoch: 2 [20000/23974 (83%)]\tLoss: 0.399566\n",
      "Train Epoch: 2 [21000/23974 (88%)]\tLoss: 0.335999\n",
      "Train Epoch: 2 [22000/23974 (92%)]\tLoss: 0.377433\n",
      "Train Epoch: 2 [23000/23974 (96%)]\tLoss: 0.297197\n",
      "Train Epoch: 3 [0/23974 (0%)]\tLoss: 0.261791\n",
      "Train Epoch: 3 [1000/23974 (4%)]\tLoss: 0.228669\n",
      "Train Epoch: 3 [2000/23974 (8%)]\tLoss: 0.210554\n",
      "Train Epoch: 3 [3000/23974 (12%)]\tLoss: 0.307380\n",
      "Train Epoch: 3 [4000/23974 (17%)]\tLoss: 0.266885\n",
      "Train Epoch: 3 [5000/23974 (21%)]\tLoss: 0.221277\n",
      "Train Epoch: 3 [6000/23974 (25%)]\tLoss: 0.318715\n",
      "Train Epoch: 3 [7000/23974 (29%)]\tLoss: 0.285950\n",
      "Train Epoch: 3 [8000/23974 (33%)]\tLoss: 0.354493\n",
      "Train Epoch: 3 [9000/23974 (38%)]\tLoss: 0.266364\n",
      "Train Epoch: 3 [10000/23974 (42%)]\tLoss: 0.282581\n",
      "Train Epoch: 3 [11000/23974 (46%)]\tLoss: 0.320615\n",
      "Train Epoch: 3 [12000/23974 (50%)]\tLoss: 0.288813\n",
      "Train Epoch: 3 [13000/23974 (54%)]\tLoss: 0.344589\n",
      "Train Epoch: 3 [14000/23974 (58%)]\tLoss: 0.208194\n",
      "Train Epoch: 3 [15000/23974 (62%)]\tLoss: 0.359402\n",
      "Train Epoch: 3 [16000/23974 (67%)]\tLoss: 0.241985\n",
      "Train Epoch: 3 [17000/23974 (71%)]\tLoss: 0.266602\n",
      "Train Epoch: 3 [18000/23974 (75%)]\tLoss: 0.149290\n",
      "Train Epoch: 3 [19000/23974 (79%)]\tLoss: 0.189949\n",
      "Train Epoch: 3 [20000/23974 (83%)]\tLoss: 0.252891\n",
      "Train Epoch: 3 [21000/23974 (88%)]\tLoss: 0.293572\n",
      "Train Epoch: 3 [22000/23974 (92%)]\tLoss: 0.220837\n",
      "Train Epoch: 3 [23000/23974 (96%)]\tLoss: 0.170959\n",
      "Train Epoch: 4 [0/23974 (0%)]\tLoss: 0.241349\n",
      "Train Epoch: 4 [1000/23974 (4%)]\tLoss: 0.221796\n",
      "Train Epoch: 4 [2000/23974 (8%)]\tLoss: 0.232311\n",
      "Train Epoch: 4 [3000/23974 (12%)]\tLoss: 0.193844\n",
      "Train Epoch: 4 [4000/23974 (17%)]\tLoss: 0.140762\n",
      "Train Epoch: 4 [5000/23974 (21%)]\tLoss: 0.264194\n",
      "Train Epoch: 4 [6000/23974 (25%)]\tLoss: 0.286201\n",
      "Train Epoch: 4 [7000/23974 (29%)]\tLoss: 0.369983\n",
      "Train Epoch: 4 [8000/23974 (33%)]\tLoss: 0.204705\n",
      "Train Epoch: 4 [9000/23974 (38%)]\tLoss: 0.333321\n",
      "Train Epoch: 4 [10000/23974 (42%)]\tLoss: 0.230303\n",
      "Train Epoch: 4 [11000/23974 (46%)]\tLoss: 0.339818\n",
      "Train Epoch: 4 [12000/23974 (50%)]\tLoss: 0.312149\n",
      "Train Epoch: 4 [13000/23974 (54%)]\tLoss: 0.225422\n",
      "Train Epoch: 4 [14000/23974 (58%)]\tLoss: 0.200217\n",
      "Train Epoch: 4 [15000/23974 (62%)]\tLoss: 0.288239\n",
      "Train Epoch: 4 [16000/23974 (67%)]\tLoss: 0.199452\n",
      "Train Epoch: 4 [17000/23974 (71%)]\tLoss: 0.136356\n",
      "Train Epoch: 4 [18000/23974 (75%)]\tLoss: 0.309799\n",
      "Train Epoch: 4 [19000/23974 (79%)]\tLoss: 0.228431\n",
      "Train Epoch: 4 [20000/23974 (83%)]\tLoss: 0.283847\n",
      "Train Epoch: 4 [21000/23974 (88%)]\tLoss: 0.303755\n",
      "Train Epoch: 4 [22000/23974 (92%)]\tLoss: 0.261146\n",
      "Train Epoch: 4 [23000/23974 (96%)]\tLoss: 0.271458\n",
      "Train Epoch: 5 [0/23974 (0%)]\tLoss: 0.182269\n",
      "Train Epoch: 5 [1000/23974 (4%)]\tLoss: 0.321152\n",
      "Train Epoch: 5 [2000/23974 (8%)]\tLoss: 0.210886\n",
      "Train Epoch: 5 [3000/23974 (12%)]\tLoss: 0.151580\n",
      "Train Epoch: 5 [4000/23974 (17%)]\tLoss: 0.244857\n",
      "Train Epoch: 5 [5000/23974 (21%)]\tLoss: 0.226290\n",
      "Train Epoch: 5 [6000/23974 (25%)]\tLoss: 0.353977\n",
      "Train Epoch: 5 [7000/23974 (29%)]\tLoss: 0.310137\n",
      "Train Epoch: 5 [8000/23974 (33%)]\tLoss: 0.163367\n",
      "Train Epoch: 5 [9000/23974 (38%)]\tLoss: 0.222126\n",
      "Train Epoch: 5 [10000/23974 (42%)]\tLoss: 0.124283\n",
      "Train Epoch: 5 [11000/23974 (46%)]\tLoss: 0.357359\n",
      "Train Epoch: 5 [12000/23974 (50%)]\tLoss: 0.322317\n",
      "Train Epoch: 5 [13000/23974 (54%)]\tLoss: 0.241669\n",
      "Train Epoch: 5 [14000/23974 (58%)]\tLoss: 0.293689\n",
      "Train Epoch: 5 [15000/23974 (62%)]\tLoss: 0.188338\n",
      "Train Epoch: 5 [16000/23974 (67%)]\tLoss: 0.218130\n",
      "Train Epoch: 5 [17000/23974 (71%)]\tLoss: 0.233312\n",
      "Train Epoch: 5 [18000/23974 (75%)]\tLoss: 0.273119\n",
      "Train Epoch: 5 [19000/23974 (79%)]\tLoss: 0.292517\n",
      "Train Epoch: 5 [20000/23974 (83%)]\tLoss: 0.225547\n",
      "Train Epoch: 5 [21000/23974 (88%)]\tLoss: 0.217018\n",
      "Train Epoch: 5 [22000/23974 (92%)]\tLoss: 0.261419\n",
      "Train Epoch: 5 [23000/23974 (96%)]\tLoss: 0.133629\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7961 (0%)]\tLoss: 0.412217\n",
      "Train Epoch: 1 [1000/7961 (12%)]\tLoss: 0.346701\n",
      "Train Epoch: 1 [2000/7961 (25%)]\tLoss: 0.392254\n",
      "Train Epoch: 1 [3000/7961 (38%)]\tLoss: 0.326961\n",
      "Train Epoch: 1 [4000/7961 (50%)]\tLoss: 0.482998\n",
      "Train Epoch: 1 [5000/7961 (62%)]\tLoss: 0.307603\n",
      "Train Epoch: 1 [6000/7961 (75%)]\tLoss: 0.463028\n",
      "Train Epoch: 1 [7000/7961 (88%)]\tLoss: 0.358214\n",
      "Train Epoch: 2 [0/7961 (0%)]\tLoss: 0.222091\n",
      "Train Epoch: 2 [1000/7961 (12%)]\tLoss: 0.314367\n",
      "Train Epoch: 2 [2000/7961 (25%)]\tLoss: 0.345326\n",
      "Train Epoch: 2 [3000/7961 (38%)]\tLoss: 0.313880\n",
      "Train Epoch: 2 [4000/7961 (50%)]\tLoss: 0.294983\n",
      "Train Epoch: 2 [5000/7961 (62%)]\tLoss: 0.376050\n",
      "Train Epoch: 2 [6000/7961 (75%)]\tLoss: 0.399696\n",
      "Train Epoch: 2 [7000/7961 (88%)]\tLoss: 0.410135\n",
      "Train Epoch: 3 [0/7961 (0%)]\tLoss: 0.334055\n",
      "Train Epoch: 3 [1000/7961 (12%)]\tLoss: 0.263780\n",
      "Train Epoch: 3 [2000/7961 (25%)]\tLoss: 0.318593\n",
      "Train Epoch: 3 [3000/7961 (38%)]\tLoss: 0.341917\n",
      "Train Epoch: 3 [4000/7961 (50%)]\tLoss: 0.291627\n",
      "Train Epoch: 3 [5000/7961 (62%)]\tLoss: 0.458596\n",
      "Train Epoch: 3 [6000/7961 (75%)]\tLoss: 0.358750\n",
      "Train Epoch: 3 [7000/7961 (88%)]\tLoss: 0.478788\n",
      "Train Epoch: 4 [0/7961 (0%)]\tLoss: 0.327049\n",
      "Train Epoch: 4 [1000/7961 (12%)]\tLoss: 0.451626\n",
      "Train Epoch: 4 [2000/7961 (25%)]\tLoss: 0.288206\n",
      "Train Epoch: 4 [3000/7961 (38%)]\tLoss: 0.352285\n",
      "Train Epoch: 4 [4000/7961 (50%)]\tLoss: 0.327894\n",
      "Train Epoch: 4 [5000/7961 (62%)]\tLoss: 0.335892\n",
      "Train Epoch: 4 [6000/7961 (75%)]\tLoss: 0.308686\n",
      "Train Epoch: 4 [7000/7961 (88%)]\tLoss: 0.432064\n",
      "Train Epoch: 5 [0/7961 (0%)]\tLoss: 0.461853\n",
      "Train Epoch: 5 [1000/7961 (12%)]\tLoss: 0.249437\n",
      "Train Epoch: 5 [2000/7961 (25%)]\tLoss: 0.310767\n",
      "Train Epoch: 5 [3000/7961 (38%)]\tLoss: 0.358342\n",
      "Train Epoch: 5 [4000/7961 (50%)]\tLoss: 0.418458\n",
      "Train Epoch: 5 [5000/7961 (62%)]\tLoss: 0.345285\n",
      "Train Epoch: 5 [6000/7961 (75%)]\tLoss: 0.184294\n",
      "Train Epoch: 5 [7000/7961 (88%)]\tLoss: 0.345185\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/15584 (0%)]\tLoss: 0.374468\n",
      "Train Epoch: 1 [1000/15584 (6%)]\tLoss: 0.288597\n",
      "Train Epoch: 1 [2000/15584 (13%)]\tLoss: 0.368225\n",
      "Train Epoch: 1 [3000/15584 (19%)]\tLoss: 0.220592\n",
      "Train Epoch: 1 [4000/15584 (26%)]\tLoss: 0.196823\n",
      "Train Epoch: 1 [5000/15584 (32%)]\tLoss: 0.181983\n",
      "Train Epoch: 1 [6000/15584 (38%)]\tLoss: 0.345027\n",
      "Train Epoch: 1 [7000/15584 (45%)]\tLoss: 0.235988\n",
      "Train Epoch: 1 [8000/15584 (51%)]\tLoss: 0.275628\n",
      "Train Epoch: 1 [9000/15584 (58%)]\tLoss: 0.265483\n",
      "Train Epoch: 1 [10000/15584 (64%)]\tLoss: 0.348849\n",
      "Train Epoch: 1 [11000/15584 (71%)]\tLoss: 0.335560\n",
      "Train Epoch: 1 [12000/15584 (77%)]\tLoss: 0.223492\n",
      "Train Epoch: 1 [13000/15584 (83%)]\tLoss: 0.267745\n",
      "Train Epoch: 1 [14000/15584 (90%)]\tLoss: 0.378636\n",
      "Train Epoch: 1 [15000/15584 (96%)]\tLoss: 0.268727\n",
      "Train Epoch: 2 [0/15584 (0%)]\tLoss: 0.249432\n",
      "Train Epoch: 2 [1000/15584 (6%)]\tLoss: 0.217648\n",
      "Train Epoch: 2 [2000/15584 (13%)]\tLoss: 0.310385\n",
      "Train Epoch: 2 [3000/15584 (19%)]\tLoss: 0.256388\n",
      "Train Epoch: 2 [4000/15584 (26%)]\tLoss: 0.194871\n",
      "Train Epoch: 2 [5000/15584 (32%)]\tLoss: 0.260263\n",
      "Train Epoch: 2 [6000/15584 (38%)]\tLoss: 0.232928\n",
      "Train Epoch: 2 [7000/15584 (45%)]\tLoss: 0.229319\n",
      "Train Epoch: 2 [8000/15584 (51%)]\tLoss: 0.232534\n",
      "Train Epoch: 2 [9000/15584 (58%)]\tLoss: 0.201583\n",
      "Train Epoch: 2 [10000/15584 (64%)]\tLoss: 0.149263\n",
      "Train Epoch: 2 [11000/15584 (71%)]\tLoss: 0.382111\n",
      "Train Epoch: 2 [12000/15584 (77%)]\tLoss: 0.316331\n",
      "Train Epoch: 2 [13000/15584 (83%)]\tLoss: 0.251169\n",
      "Train Epoch: 2 [14000/15584 (90%)]\tLoss: 0.416457\n",
      "Train Epoch: 2 [15000/15584 (96%)]\tLoss: 0.215143\n",
      "Train Epoch: 3 [0/15584 (0%)]\tLoss: 0.274002\n",
      "Train Epoch: 3 [1000/15584 (6%)]\tLoss: 0.150499\n",
      "Train Epoch: 3 [2000/15584 (13%)]\tLoss: 0.172141\n",
      "Train Epoch: 3 [3000/15584 (19%)]\tLoss: 0.208270\n",
      "Train Epoch: 3 [4000/15584 (26%)]\tLoss: 0.217497\n",
      "Train Epoch: 3 [5000/15584 (32%)]\tLoss: 0.212043\n",
      "Train Epoch: 3 [6000/15584 (38%)]\tLoss: 0.213062\n",
      "Train Epoch: 3 [7000/15584 (45%)]\tLoss: 0.191852\n",
      "Train Epoch: 3 [8000/15584 (51%)]\tLoss: 0.240868\n",
      "Train Epoch: 3 [9000/15584 (58%)]\tLoss: 0.202178\n",
      "Train Epoch: 3 [10000/15584 (64%)]\tLoss: 0.258804\n",
      "Train Epoch: 3 [11000/15584 (71%)]\tLoss: 0.178665\n",
      "Train Epoch: 3 [12000/15584 (77%)]\tLoss: 0.207601\n",
      "Train Epoch: 3 [13000/15584 (83%)]\tLoss: 0.280499\n",
      "Train Epoch: 3 [14000/15584 (90%)]\tLoss: 0.329346\n",
      "Train Epoch: 3 [15000/15584 (96%)]\tLoss: 0.219303\n",
      "Train Epoch: 4 [0/15584 (0%)]\tLoss: 0.148933\n",
      "Train Epoch: 4 [1000/15584 (6%)]\tLoss: 0.259676\n",
      "Train Epoch: 4 [2000/15584 (13%)]\tLoss: 0.259054\n",
      "Train Epoch: 4 [3000/15584 (19%)]\tLoss: 0.191655\n",
      "Train Epoch: 4 [4000/15584 (26%)]\tLoss: 0.275928\n",
      "Train Epoch: 4 [5000/15584 (32%)]\tLoss: 0.184655\n",
      "Train Epoch: 4 [6000/15584 (38%)]\tLoss: 0.180994\n",
      "Train Epoch: 4 [7000/15584 (45%)]\tLoss: 0.195877\n",
      "Train Epoch: 4 [8000/15584 (51%)]\tLoss: 0.213122\n",
      "Train Epoch: 4 [9000/15584 (58%)]\tLoss: 0.216527\n",
      "Train Epoch: 4 [10000/15584 (64%)]\tLoss: 0.240350\n",
      "Train Epoch: 4 [11000/15584 (71%)]\tLoss: 0.253190\n",
      "Train Epoch: 4 [12000/15584 (77%)]\tLoss: 0.235303\n",
      "Train Epoch: 4 [13000/15584 (83%)]\tLoss: 0.219850\n",
      "Train Epoch: 4 [14000/15584 (90%)]\tLoss: 0.186149\n",
      "Train Epoch: 4 [15000/15584 (96%)]\tLoss: 0.189493\n",
      "Train Epoch: 5 [0/15584 (0%)]\tLoss: 0.188223\n",
      "Train Epoch: 5 [1000/15584 (6%)]\tLoss: 0.168120\n",
      "Train Epoch: 5 [2000/15584 (13%)]\tLoss: 0.201038\n",
      "Train Epoch: 5 [3000/15584 (19%)]\tLoss: 0.217843\n",
      "Train Epoch: 5 [4000/15584 (26%)]\tLoss: 0.163399\n",
      "Train Epoch: 5 [5000/15584 (32%)]\tLoss: 0.232851\n",
      "Train Epoch: 5 [6000/15584 (38%)]\tLoss: 0.328708\n",
      "Train Epoch: 5 [7000/15584 (45%)]\tLoss: 0.143684\n",
      "Train Epoch: 5 [8000/15584 (51%)]\tLoss: 0.287937\n",
      "Train Epoch: 5 [9000/15584 (58%)]\tLoss: 0.169715\n",
      "Train Epoch: 5 [10000/15584 (64%)]\tLoss: 0.226110\n",
      "Train Epoch: 5 [11000/15584 (71%)]\tLoss: 0.279248\n",
      "Train Epoch: 5 [12000/15584 (77%)]\tLoss: 0.227831\n",
      "Train Epoch: 5 [13000/15584 (83%)]\tLoss: 0.224472\n",
      "Train Epoch: 5 [14000/15584 (90%)]\tLoss: 0.306494\n",
      "Train Epoch: 5 [15000/15584 (96%)]\tLoss: 0.215780\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/12481 (0%)]\tLoss: 0.199447\n",
      "Train Epoch: 1 [1000/12481 (8%)]\tLoss: 0.182667\n",
      "Train Epoch: 1 [2000/12481 (16%)]\tLoss: 0.122171\n",
      "Train Epoch: 1 [3000/12481 (24%)]\tLoss: 0.143091\n",
      "Train Epoch: 1 [4000/12481 (32%)]\tLoss: 0.179268\n",
      "Train Epoch: 1 [5000/12481 (40%)]\tLoss: 0.253786\n",
      "Train Epoch: 1 [6000/12481 (48%)]\tLoss: 0.143688\n",
      "Train Epoch: 1 [7000/12481 (56%)]\tLoss: 0.118652\n",
      "Train Epoch: 1 [8000/12481 (64%)]\tLoss: 0.271228\n",
      "Train Epoch: 1 [9000/12481 (72%)]\tLoss: 0.307235\n",
      "Train Epoch: 1 [10000/12481 (80%)]\tLoss: 0.382380\n",
      "Train Epoch: 1 [11000/12481 (88%)]\tLoss: 0.152088\n",
      "Train Epoch: 1 [12000/12481 (96%)]\tLoss: 0.244694\n",
      "Train Epoch: 2 [0/12481 (0%)]\tLoss: 0.127166\n",
      "Train Epoch: 2 [1000/12481 (8%)]\tLoss: 0.298162\n",
      "Train Epoch: 2 [2000/12481 (16%)]\tLoss: 0.170949\n",
      "Train Epoch: 2 [3000/12481 (24%)]\tLoss: 0.219761\n",
      "Train Epoch: 2 [4000/12481 (32%)]\tLoss: 0.192144\n",
      "Train Epoch: 2 [5000/12481 (40%)]\tLoss: 0.177647\n",
      "Train Epoch: 2 [6000/12481 (48%)]\tLoss: 0.165682\n",
      "Train Epoch: 2 [7000/12481 (56%)]\tLoss: 0.177705\n",
      "Train Epoch: 2 [8000/12481 (64%)]\tLoss: 0.099858\n",
      "Train Epoch: 2 [9000/12481 (72%)]\tLoss: 0.218135\n",
      "Train Epoch: 2 [10000/12481 (80%)]\tLoss: 0.134248\n",
      "Train Epoch: 2 [11000/12481 (88%)]\tLoss: 0.237288\n",
      "Train Epoch: 2 [12000/12481 (96%)]\tLoss: 0.115746\n",
      "Train Epoch: 3 [0/12481 (0%)]\tLoss: 0.139583\n",
      "Train Epoch: 3 [1000/12481 (8%)]\tLoss: 0.281874\n",
      "Train Epoch: 3 [2000/12481 (16%)]\tLoss: 0.178867\n",
      "Train Epoch: 3 [3000/12481 (24%)]\tLoss: 0.170848\n",
      "Train Epoch: 3 [4000/12481 (32%)]\tLoss: 0.246848\n",
      "Train Epoch: 3 [5000/12481 (40%)]\tLoss: 0.172880\n",
      "Train Epoch: 3 [6000/12481 (48%)]\tLoss: 0.157981\n",
      "Train Epoch: 3 [7000/12481 (56%)]\tLoss: 0.187960\n",
      "Train Epoch: 3 [8000/12481 (64%)]\tLoss: 0.251372\n",
      "Train Epoch: 3 [9000/12481 (72%)]\tLoss: 0.126616\n",
      "Train Epoch: 3 [10000/12481 (80%)]\tLoss: 0.235368\n",
      "Train Epoch: 3 [11000/12481 (88%)]\tLoss: 0.275182\n",
      "Train Epoch: 3 [12000/12481 (96%)]\tLoss: 0.210734\n",
      "Train Epoch: 4 [0/12481 (0%)]\tLoss: 0.118327\n",
      "Train Epoch: 4 [1000/12481 (8%)]\tLoss: 0.152806\n",
      "Train Epoch: 4 [2000/12481 (16%)]\tLoss: 0.144843\n",
      "Train Epoch: 4 [3000/12481 (24%)]\tLoss: 0.129195\n",
      "Train Epoch: 4 [4000/12481 (32%)]\tLoss: 0.265787\n",
      "Train Epoch: 4 [5000/12481 (40%)]\tLoss: 0.203449\n",
      "Train Epoch: 4 [6000/12481 (48%)]\tLoss: 0.178567\n",
      "Train Epoch: 4 [7000/12481 (56%)]\tLoss: 0.147410\n",
      "Train Epoch: 4 [8000/12481 (64%)]\tLoss: 0.129826\n",
      "Train Epoch: 4 [9000/12481 (72%)]\tLoss: 0.187221\n",
      "Train Epoch: 4 [10000/12481 (80%)]\tLoss: 0.094442\n",
      "Train Epoch: 4 [11000/12481 (88%)]\tLoss: 0.139437\n",
      "Train Epoch: 4 [12000/12481 (96%)]\tLoss: 0.209523\n",
      "Train Epoch: 5 [0/12481 (0%)]\tLoss: 0.204742\n",
      "Train Epoch: 5 [1000/12481 (8%)]\tLoss: 0.185489\n",
      "Train Epoch: 5 [2000/12481 (16%)]\tLoss: 0.257339\n",
      "Train Epoch: 5 [3000/12481 (24%)]\tLoss: 0.156774\n",
      "Train Epoch: 5 [4000/12481 (32%)]\tLoss: 0.123799\n",
      "Train Epoch: 5 [5000/12481 (40%)]\tLoss: 0.092990\n",
      "Train Epoch: 5 [6000/12481 (48%)]\tLoss: 0.196418\n",
      "Train Epoch: 5 [7000/12481 (56%)]\tLoss: 0.214536\n",
      "Train Epoch: 5 [8000/12481 (64%)]\tLoss: 0.141368\n",
      "Train Epoch: 5 [9000/12481 (72%)]\tLoss: 0.154043\n",
      "Train Epoch: 5 [10000/12481 (80%)]\tLoss: 0.145346\n",
      "Train Epoch: 5 [11000/12481 (88%)]\tLoss: 0.125111\n",
      "Train Epoch: 5 [12000/12481 (96%)]\tLoss: 0.150779\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "4\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8510, Accuracy: 8520/10000 (85%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/23974 (0%)]\tLoss: 0.361299\n",
      "Train Epoch: 1 [1000/23974 (4%)]\tLoss: 0.282703\n",
      "Train Epoch: 1 [2000/23974 (8%)]\tLoss: 0.306729\n",
      "Train Epoch: 1 [3000/23974 (12%)]\tLoss: 0.287817\n",
      "Train Epoch: 1 [4000/23974 (17%)]\tLoss: 0.296537\n",
      "Train Epoch: 1 [5000/23974 (21%)]\tLoss: 0.267316\n",
      "Train Epoch: 1 [6000/23974 (25%)]\tLoss: 0.269707\n",
      "Train Epoch: 1 [7000/23974 (29%)]\tLoss: 0.256528\n",
      "Train Epoch: 1 [8000/23974 (33%)]\tLoss: 0.389328\n",
      "Train Epoch: 1 [9000/23974 (38%)]\tLoss: 0.299949\n",
      "Train Epoch: 1 [10000/23974 (42%)]\tLoss: 0.248820\n",
      "Train Epoch: 1 [11000/23974 (46%)]\tLoss: 0.335956\n",
      "Train Epoch: 1 [12000/23974 (50%)]\tLoss: 0.329045\n",
      "Train Epoch: 1 [13000/23974 (54%)]\tLoss: 0.191450\n",
      "Train Epoch: 1 [14000/23974 (58%)]\tLoss: 0.231538\n",
      "Train Epoch: 1 [15000/23974 (62%)]\tLoss: 0.311685\n",
      "Train Epoch: 1 [16000/23974 (67%)]\tLoss: 0.317391\n",
      "Train Epoch: 1 [17000/23974 (71%)]\tLoss: 0.213350\n",
      "Train Epoch: 1 [18000/23974 (75%)]\tLoss: 0.240630\n",
      "Train Epoch: 1 [19000/23974 (79%)]\tLoss: 0.298321\n",
      "Train Epoch: 1 [20000/23974 (83%)]\tLoss: 0.275830\n",
      "Train Epoch: 1 [21000/23974 (88%)]\tLoss: 0.332098\n",
      "Train Epoch: 1 [22000/23974 (92%)]\tLoss: 0.251490\n",
      "Train Epoch: 1 [23000/23974 (96%)]\tLoss: 0.379098\n",
      "Train Epoch: 2 [0/23974 (0%)]\tLoss: 0.249754\n",
      "Train Epoch: 2 [1000/23974 (4%)]\tLoss: 0.318882\n",
      "Train Epoch: 2 [2000/23974 (8%)]\tLoss: 0.262769\n",
      "Train Epoch: 2 [3000/23974 (12%)]\tLoss: 0.450534\n",
      "Train Epoch: 2 [4000/23974 (17%)]\tLoss: 0.307829\n",
      "Train Epoch: 2 [5000/23974 (21%)]\tLoss: 0.225924\n",
      "Train Epoch: 2 [6000/23974 (25%)]\tLoss: 0.100766\n",
      "Train Epoch: 2 [7000/23974 (29%)]\tLoss: 0.297221\n",
      "Train Epoch: 2 [8000/23974 (33%)]\tLoss: 0.190030\n",
      "Train Epoch: 2 [9000/23974 (38%)]\tLoss: 0.444592\n",
      "Train Epoch: 2 [10000/23974 (42%)]\tLoss: 0.340038\n",
      "Train Epoch: 2 [11000/23974 (46%)]\tLoss: 0.386846\n",
      "Train Epoch: 2 [12000/23974 (50%)]\tLoss: 0.291735\n",
      "Train Epoch: 2 [13000/23974 (54%)]\tLoss: 0.305457\n",
      "Train Epoch: 2 [14000/23974 (58%)]\tLoss: 0.372547\n",
      "Train Epoch: 2 [15000/23974 (62%)]\tLoss: 0.207131\n",
      "Train Epoch: 2 [16000/23974 (67%)]\tLoss: 0.543996\n",
      "Train Epoch: 2 [17000/23974 (71%)]\tLoss: 0.216227\n",
      "Train Epoch: 2 [18000/23974 (75%)]\tLoss: 0.245814\n",
      "Train Epoch: 2 [19000/23974 (79%)]\tLoss: 0.363638\n",
      "Train Epoch: 2 [20000/23974 (83%)]\tLoss: 0.337926\n",
      "Train Epoch: 2 [21000/23974 (88%)]\tLoss: 0.401712\n",
      "Train Epoch: 2 [22000/23974 (92%)]\tLoss: 0.149599\n",
      "Train Epoch: 2 [23000/23974 (96%)]\tLoss: 0.169075\n",
      "Train Epoch: 3 [0/23974 (0%)]\tLoss: 0.277559\n",
      "Train Epoch: 3 [1000/23974 (4%)]\tLoss: 0.256044\n",
      "Train Epoch: 3 [2000/23974 (8%)]\tLoss: 0.281190\n",
      "Train Epoch: 3 [3000/23974 (12%)]\tLoss: 0.169648\n",
      "Train Epoch: 3 [4000/23974 (17%)]\tLoss: 0.451276\n",
      "Train Epoch: 3 [5000/23974 (21%)]\tLoss: 0.204773\n",
      "Train Epoch: 3 [6000/23974 (25%)]\tLoss: 0.344818\n",
      "Train Epoch: 3 [7000/23974 (29%)]\tLoss: 0.312085\n",
      "Train Epoch: 3 [8000/23974 (33%)]\tLoss: 0.155751\n",
      "Train Epoch: 3 [9000/23974 (38%)]\tLoss: 0.204411\n",
      "Train Epoch: 3 [10000/23974 (42%)]\tLoss: 0.238618\n",
      "Train Epoch: 3 [11000/23974 (46%)]\tLoss: 0.232472\n",
      "Train Epoch: 3 [12000/23974 (50%)]\tLoss: 0.282789\n",
      "Train Epoch: 3 [13000/23974 (54%)]\tLoss: 0.347171\n",
      "Train Epoch: 3 [14000/23974 (58%)]\tLoss: 0.179917\n",
      "Train Epoch: 3 [15000/23974 (62%)]\tLoss: 0.258687\n",
      "Train Epoch: 3 [16000/23974 (67%)]\tLoss: 0.285744\n",
      "Train Epoch: 3 [17000/23974 (71%)]\tLoss: 0.342871\n",
      "Train Epoch: 3 [18000/23974 (75%)]\tLoss: 0.407714\n",
      "Train Epoch: 3 [19000/23974 (79%)]\tLoss: 0.297413\n",
      "Train Epoch: 3 [20000/23974 (83%)]\tLoss: 0.277935\n",
      "Train Epoch: 3 [21000/23974 (88%)]\tLoss: 0.187300\n",
      "Train Epoch: 3 [22000/23974 (92%)]\tLoss: 0.226709\n",
      "Train Epoch: 3 [23000/23974 (96%)]\tLoss: 0.316722\n",
      "Train Epoch: 4 [0/23974 (0%)]\tLoss: 0.157881\n",
      "Train Epoch: 4 [1000/23974 (4%)]\tLoss: 0.286428\n",
      "Train Epoch: 4 [2000/23974 (8%)]\tLoss: 0.273840\n",
      "Train Epoch: 4 [3000/23974 (12%)]\tLoss: 0.313417\n",
      "Train Epoch: 4 [4000/23974 (17%)]\tLoss: 0.239249\n",
      "Train Epoch: 4 [5000/23974 (21%)]\tLoss: 0.300604\n",
      "Train Epoch: 4 [6000/23974 (25%)]\tLoss: 0.315483\n",
      "Train Epoch: 4 [7000/23974 (29%)]\tLoss: 0.174525\n",
      "Train Epoch: 4 [8000/23974 (33%)]\tLoss: 0.301113\n",
      "Train Epoch: 4 [9000/23974 (38%)]\tLoss: 0.220428\n",
      "Train Epoch: 4 [10000/23974 (42%)]\tLoss: 0.241507\n",
      "Train Epoch: 4 [11000/23974 (46%)]\tLoss: 0.363366\n",
      "Train Epoch: 4 [12000/23974 (50%)]\tLoss: 0.230915\n",
      "Train Epoch: 4 [13000/23974 (54%)]\tLoss: 0.238460\n",
      "Train Epoch: 4 [14000/23974 (58%)]\tLoss: 0.211192\n",
      "Train Epoch: 4 [15000/23974 (62%)]\tLoss: 0.281368\n",
      "Train Epoch: 4 [16000/23974 (67%)]\tLoss: 0.253942\n",
      "Train Epoch: 4 [17000/23974 (71%)]\tLoss: 0.140998\n",
      "Train Epoch: 4 [18000/23974 (75%)]\tLoss: 0.283169\n",
      "Train Epoch: 4 [19000/23974 (79%)]\tLoss: 0.304209\n",
      "Train Epoch: 4 [20000/23974 (83%)]\tLoss: 0.198600\n",
      "Train Epoch: 4 [21000/23974 (88%)]\tLoss: 0.100668\n",
      "Train Epoch: 4 [22000/23974 (92%)]\tLoss: 0.255636\n",
      "Train Epoch: 4 [23000/23974 (96%)]\tLoss: 0.255123\n",
      "Train Epoch: 5 [0/23974 (0%)]\tLoss: 0.260645\n",
      "Train Epoch: 5 [1000/23974 (4%)]\tLoss: 0.267036\n",
      "Train Epoch: 5 [2000/23974 (8%)]\tLoss: 0.174210\n",
      "Train Epoch: 5 [3000/23974 (12%)]\tLoss: 0.249299\n",
      "Train Epoch: 5 [4000/23974 (17%)]\tLoss: 0.221828\n",
      "Train Epoch: 5 [5000/23974 (21%)]\tLoss: 0.399104\n",
      "Train Epoch: 5 [6000/23974 (25%)]\tLoss: 0.269822\n",
      "Train Epoch: 5 [7000/23974 (29%)]\tLoss: 0.183780\n",
      "Train Epoch: 5 [8000/23974 (33%)]\tLoss: 0.124904\n",
      "Train Epoch: 5 [9000/23974 (38%)]\tLoss: 0.307959\n",
      "Train Epoch: 5 [10000/23974 (42%)]\tLoss: 0.176960\n",
      "Train Epoch: 5 [11000/23974 (46%)]\tLoss: 0.360237\n",
      "Train Epoch: 5 [12000/23974 (50%)]\tLoss: 0.303173\n",
      "Train Epoch: 5 [13000/23974 (54%)]\tLoss: 0.203573\n",
      "Train Epoch: 5 [14000/23974 (58%)]\tLoss: 0.246667\n",
      "Train Epoch: 5 [15000/23974 (62%)]\tLoss: 0.191926\n",
      "Train Epoch: 5 [16000/23974 (67%)]\tLoss: 0.267513\n",
      "Train Epoch: 5 [17000/23974 (71%)]\tLoss: 0.261657\n",
      "Train Epoch: 5 [18000/23974 (75%)]\tLoss: 0.290082\n",
      "Train Epoch: 5 [19000/23974 (79%)]\tLoss: 0.328841\n",
      "Train Epoch: 5 [20000/23974 (83%)]\tLoss: 0.148139\n",
      "Train Epoch: 5 [21000/23974 (88%)]\tLoss: 0.303932\n",
      "Train Epoch: 5 [22000/23974 (92%)]\tLoss: 0.252811\n",
      "Train Epoch: 5 [23000/23974 (96%)]\tLoss: 0.289079\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7961 (0%)]\tLoss: 0.378633\n",
      "Train Epoch: 1 [1000/7961 (12%)]\tLoss: 0.344624\n",
      "Train Epoch: 1 [2000/7961 (25%)]\tLoss: 0.467022\n",
      "Train Epoch: 1 [3000/7961 (38%)]\tLoss: 0.426469\n",
      "Train Epoch: 1 [4000/7961 (50%)]\tLoss: 0.334624\n",
      "Train Epoch: 1 [5000/7961 (62%)]\tLoss: 0.366710\n",
      "Train Epoch: 1 [6000/7961 (75%)]\tLoss: 0.361395\n",
      "Train Epoch: 1 [7000/7961 (88%)]\tLoss: 0.335990\n",
      "Train Epoch: 2 [0/7961 (0%)]\tLoss: 0.356710\n",
      "Train Epoch: 2 [1000/7961 (12%)]\tLoss: 0.394901\n",
      "Train Epoch: 2 [2000/7961 (25%)]\tLoss: 0.254928\n",
      "Train Epoch: 2 [3000/7961 (38%)]\tLoss: 0.313508\n",
      "Train Epoch: 2 [4000/7961 (50%)]\tLoss: 0.420584\n",
      "Train Epoch: 2 [5000/7961 (62%)]\tLoss: 0.362091\n",
      "Train Epoch: 2 [6000/7961 (75%)]\tLoss: 0.397192\n",
      "Train Epoch: 2 [7000/7961 (88%)]\tLoss: 0.499545\n",
      "Train Epoch: 3 [0/7961 (0%)]\tLoss: 0.310152\n",
      "Train Epoch: 3 [1000/7961 (12%)]\tLoss: 0.404832\n",
      "Train Epoch: 3 [2000/7961 (25%)]\tLoss: 0.413258\n",
      "Train Epoch: 3 [3000/7961 (38%)]\tLoss: 0.405746\n",
      "Train Epoch: 3 [4000/7961 (50%)]\tLoss: 0.328009\n",
      "Train Epoch: 3 [5000/7961 (62%)]\tLoss: 0.228596\n",
      "Train Epoch: 3 [6000/7961 (75%)]\tLoss: 0.249506\n",
      "Train Epoch: 3 [7000/7961 (88%)]\tLoss: 0.286874\n",
      "Train Epoch: 4 [0/7961 (0%)]\tLoss: 0.271332\n",
      "Train Epoch: 4 [1000/7961 (12%)]\tLoss: 0.427488\n",
      "Train Epoch: 4 [2000/7961 (25%)]\tLoss: 0.452754\n",
      "Train Epoch: 4 [3000/7961 (38%)]\tLoss: 0.253294\n",
      "Train Epoch: 4 [4000/7961 (50%)]\tLoss: 0.450514\n",
      "Train Epoch: 4 [5000/7961 (62%)]\tLoss: 0.233658\n",
      "Train Epoch: 4 [6000/7961 (75%)]\tLoss: 0.367024\n",
      "Train Epoch: 4 [7000/7961 (88%)]\tLoss: 0.472444\n",
      "Train Epoch: 5 [0/7961 (0%)]\tLoss: 0.349454\n",
      "Train Epoch: 5 [1000/7961 (12%)]\tLoss: 0.349489\n",
      "Train Epoch: 5 [2000/7961 (25%)]\tLoss: 0.291309\n",
      "Train Epoch: 5 [3000/7961 (38%)]\tLoss: 0.280082\n",
      "Train Epoch: 5 [4000/7961 (50%)]\tLoss: 0.295617\n",
      "Train Epoch: 5 [5000/7961 (62%)]\tLoss: 0.346890\n",
      "Train Epoch: 5 [6000/7961 (75%)]\tLoss: 0.297945\n",
      "Train Epoch: 5 [7000/7961 (88%)]\tLoss: 0.238966\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/15584 (0%)]\tLoss: 0.411397\n",
      "Train Epoch: 1 [1000/15584 (6%)]\tLoss: 0.447664\n",
      "Train Epoch: 1 [2000/15584 (13%)]\tLoss: 0.213608\n",
      "Train Epoch: 1 [3000/15584 (19%)]\tLoss: 0.309718\n",
      "Train Epoch: 1 [4000/15584 (26%)]\tLoss: 0.231506\n",
      "Train Epoch: 1 [5000/15584 (32%)]\tLoss: 0.237603\n",
      "Train Epoch: 1 [6000/15584 (38%)]\tLoss: 0.296383\n",
      "Train Epoch: 1 [7000/15584 (45%)]\tLoss: 0.188054\n",
      "Train Epoch: 1 [8000/15584 (51%)]\tLoss: 0.303834\n",
      "Train Epoch: 1 [9000/15584 (58%)]\tLoss: 0.400292\n",
      "Train Epoch: 1 [10000/15584 (64%)]\tLoss: 0.266703\n",
      "Train Epoch: 1 [11000/15584 (71%)]\tLoss: 0.250555\n",
      "Train Epoch: 1 [12000/15584 (77%)]\tLoss: 0.168503\n",
      "Train Epoch: 1 [13000/15584 (83%)]\tLoss: 0.278315\n",
      "Train Epoch: 1 [14000/15584 (90%)]\tLoss: 0.237466\n",
      "Train Epoch: 1 [15000/15584 (96%)]\tLoss: 0.347637\n",
      "Train Epoch: 2 [0/15584 (0%)]\tLoss: 0.247081\n",
      "Train Epoch: 2 [1000/15584 (6%)]\tLoss: 0.177144\n",
      "Train Epoch: 2 [2000/15584 (13%)]\tLoss: 0.256616\n",
      "Train Epoch: 2 [3000/15584 (19%)]\tLoss: 0.221730\n",
      "Train Epoch: 2 [4000/15584 (26%)]\tLoss: 0.387204\n",
      "Train Epoch: 2 [5000/15584 (32%)]\tLoss: 0.478691\n",
      "Train Epoch: 2 [6000/15584 (38%)]\tLoss: 0.258081\n",
      "Train Epoch: 2 [7000/15584 (45%)]\tLoss: 0.139276\n",
      "Train Epoch: 2 [8000/15584 (51%)]\tLoss: 0.353680\n",
      "Train Epoch: 2 [9000/15584 (58%)]\tLoss: 0.296731\n",
      "Train Epoch: 2 [10000/15584 (64%)]\tLoss: 0.187396\n",
      "Train Epoch: 2 [11000/15584 (71%)]\tLoss: 0.184500\n",
      "Train Epoch: 2 [12000/15584 (77%)]\tLoss: 0.207578\n",
      "Train Epoch: 2 [13000/15584 (83%)]\tLoss: 0.204323\n",
      "Train Epoch: 2 [14000/15584 (90%)]\tLoss: 0.324374\n",
      "Train Epoch: 2 [15000/15584 (96%)]\tLoss: 0.309893\n",
      "Train Epoch: 3 [0/15584 (0%)]\tLoss: 0.095061\n",
      "Train Epoch: 3 [1000/15584 (6%)]\tLoss: 0.142971\n",
      "Train Epoch: 3 [2000/15584 (13%)]\tLoss: 0.276932\n",
      "Train Epoch: 3 [3000/15584 (19%)]\tLoss: 0.220573\n",
      "Train Epoch: 3 [4000/15584 (26%)]\tLoss: 0.211228\n",
      "Train Epoch: 3 [5000/15584 (32%)]\tLoss: 0.172805\n",
      "Train Epoch: 3 [6000/15584 (38%)]\tLoss: 0.375236\n",
      "Train Epoch: 3 [7000/15584 (45%)]\tLoss: 0.315199\n",
      "Train Epoch: 3 [8000/15584 (51%)]\tLoss: 0.241569\n",
      "Train Epoch: 3 [9000/15584 (58%)]\tLoss: 0.323985\n",
      "Train Epoch: 3 [10000/15584 (64%)]\tLoss: 0.167739\n",
      "Train Epoch: 3 [11000/15584 (71%)]\tLoss: 0.187442\n",
      "Train Epoch: 3 [12000/15584 (77%)]\tLoss: 0.293826\n",
      "Train Epoch: 3 [13000/15584 (83%)]\tLoss: 0.282572\n",
      "Train Epoch: 3 [14000/15584 (90%)]\tLoss: 0.392126\n",
      "Train Epoch: 3 [15000/15584 (96%)]\tLoss: 0.226170\n",
      "Train Epoch: 4 [0/15584 (0%)]\tLoss: 0.203143\n",
      "Train Epoch: 4 [1000/15584 (6%)]\tLoss: 0.222027\n",
      "Train Epoch: 4 [2000/15584 (13%)]\tLoss: 0.331531\n",
      "Train Epoch: 4 [3000/15584 (19%)]\tLoss: 0.308971\n",
      "Train Epoch: 4 [4000/15584 (26%)]\tLoss: 0.225345\n",
      "Train Epoch: 4 [5000/15584 (32%)]\tLoss: 0.175124\n",
      "Train Epoch: 4 [6000/15584 (38%)]\tLoss: 0.231439\n",
      "Train Epoch: 4 [7000/15584 (45%)]\tLoss: 0.242532\n",
      "Train Epoch: 4 [8000/15584 (51%)]\tLoss: 0.173569\n",
      "Train Epoch: 4 [9000/15584 (58%)]\tLoss: 0.337339\n",
      "Train Epoch: 4 [10000/15584 (64%)]\tLoss: 0.288099\n",
      "Train Epoch: 4 [11000/15584 (71%)]\tLoss: 0.304170\n",
      "Train Epoch: 4 [12000/15584 (77%)]\tLoss: 0.165674\n",
      "Train Epoch: 4 [13000/15584 (83%)]\tLoss: 0.270704\n",
      "Train Epoch: 4 [14000/15584 (90%)]\tLoss: 0.224199\n",
      "Train Epoch: 4 [15000/15584 (96%)]\tLoss: 0.318296\n",
      "Train Epoch: 5 [0/15584 (0%)]\tLoss: 0.208042\n",
      "Train Epoch: 5 [1000/15584 (6%)]\tLoss: 0.188340\n",
      "Train Epoch: 5 [2000/15584 (13%)]\tLoss: 0.132758\n",
      "Train Epoch: 5 [3000/15584 (19%)]\tLoss: 0.240462\n",
      "Train Epoch: 5 [4000/15584 (26%)]\tLoss: 0.146508\n",
      "Train Epoch: 5 [5000/15584 (32%)]\tLoss: 0.152207\n",
      "Train Epoch: 5 [6000/15584 (38%)]\tLoss: 0.181402\n",
      "Train Epoch: 5 [7000/15584 (45%)]\tLoss: 0.155283\n",
      "Train Epoch: 5 [8000/15584 (51%)]\tLoss: 0.217525\n",
      "Train Epoch: 5 [9000/15584 (58%)]\tLoss: 0.245372\n",
      "Train Epoch: 5 [10000/15584 (64%)]\tLoss: 0.200262\n",
      "Train Epoch: 5 [11000/15584 (71%)]\tLoss: 0.138636\n",
      "Train Epoch: 5 [12000/15584 (77%)]\tLoss: 0.188958\n",
      "Train Epoch: 5 [13000/15584 (83%)]\tLoss: 0.261996\n",
      "Train Epoch: 5 [14000/15584 (90%)]\tLoss: 0.164666\n",
      "Train Epoch: 5 [15000/15584 (96%)]\tLoss: 0.205686\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/12481 (0%)]\tLoss: 0.215252\n",
      "Train Epoch: 1 [1000/12481 (8%)]\tLoss: 0.160838\n",
      "Train Epoch: 1 [2000/12481 (16%)]\tLoss: 0.298791\n",
      "Train Epoch: 1 [3000/12481 (24%)]\tLoss: 0.230845\n",
      "Train Epoch: 1 [4000/12481 (32%)]\tLoss: 0.162591\n",
      "Train Epoch: 1 [5000/12481 (40%)]\tLoss: 0.096307\n",
      "Train Epoch: 1 [6000/12481 (48%)]\tLoss: 0.191495\n",
      "Train Epoch: 1 [7000/12481 (56%)]\tLoss: 0.258261\n",
      "Train Epoch: 1 [8000/12481 (64%)]\tLoss: 0.171041\n",
      "Train Epoch: 1 [9000/12481 (72%)]\tLoss: 0.059631\n",
      "Train Epoch: 1 [10000/12481 (80%)]\tLoss: 0.193244\n",
      "Train Epoch: 1 [11000/12481 (88%)]\tLoss: 0.216605\n",
      "Train Epoch: 1 [12000/12481 (96%)]\tLoss: 0.079802\n",
      "Train Epoch: 2 [0/12481 (0%)]\tLoss: 0.222962\n",
      "Train Epoch: 2 [1000/12481 (8%)]\tLoss: 0.147106\n",
      "Train Epoch: 2 [2000/12481 (16%)]\tLoss: 0.127628\n",
      "Train Epoch: 2 [3000/12481 (24%)]\tLoss: 0.096215\n",
      "Train Epoch: 2 [4000/12481 (32%)]\tLoss: 0.241801\n",
      "Train Epoch: 2 [5000/12481 (40%)]\tLoss: 0.147655\n",
      "Train Epoch: 2 [6000/12481 (48%)]\tLoss: 0.202323\n",
      "Train Epoch: 2 [7000/12481 (56%)]\tLoss: 0.109896\n",
      "Train Epoch: 2 [8000/12481 (64%)]\tLoss: 0.230177\n",
      "Train Epoch: 2 [9000/12481 (72%)]\tLoss: 0.112726\n",
      "Train Epoch: 2 [10000/12481 (80%)]\tLoss: 0.143073\n",
      "Train Epoch: 2 [11000/12481 (88%)]\tLoss: 0.128701\n",
      "Train Epoch: 2 [12000/12481 (96%)]\tLoss: 0.197278\n",
      "Train Epoch: 3 [0/12481 (0%)]\tLoss: 0.107192\n",
      "Train Epoch: 3 [1000/12481 (8%)]\tLoss: 0.086116\n",
      "Train Epoch: 3 [2000/12481 (16%)]\tLoss: 0.107175\n",
      "Train Epoch: 3 [3000/12481 (24%)]\tLoss: 0.171115\n",
      "Train Epoch: 3 [4000/12481 (32%)]\tLoss: 0.127385\n",
      "Train Epoch: 3 [5000/12481 (40%)]\tLoss: 0.220022\n",
      "Train Epoch: 3 [6000/12481 (48%)]\tLoss: 0.186075\n",
      "Train Epoch: 3 [7000/12481 (56%)]\tLoss: 0.162856\n",
      "Train Epoch: 3 [8000/12481 (64%)]\tLoss: 0.237718\n",
      "Train Epoch: 3 [9000/12481 (72%)]\tLoss: 0.125871\n",
      "Train Epoch: 3 [10000/12481 (80%)]\tLoss: 0.137524\n",
      "Train Epoch: 3 [11000/12481 (88%)]\tLoss: 0.197632\n",
      "Train Epoch: 3 [12000/12481 (96%)]\tLoss: 0.102150\n",
      "Train Epoch: 4 [0/12481 (0%)]\tLoss: 0.092596\n",
      "Train Epoch: 4 [1000/12481 (8%)]\tLoss: 0.155019\n",
      "Train Epoch: 4 [2000/12481 (16%)]\tLoss: 0.097626\n",
      "Train Epoch: 4 [3000/12481 (24%)]\tLoss: 0.196326\n",
      "Train Epoch: 4 [4000/12481 (32%)]\tLoss: 0.159308\n",
      "Train Epoch: 4 [5000/12481 (40%)]\tLoss: 0.174062\n",
      "Train Epoch: 4 [6000/12481 (48%)]\tLoss: 0.128154\n",
      "Train Epoch: 4 [7000/12481 (56%)]\tLoss: 0.091330\n",
      "Train Epoch: 4 [8000/12481 (64%)]\tLoss: 0.131644\n",
      "Train Epoch: 4 [9000/12481 (72%)]\tLoss: 0.073915\n",
      "Train Epoch: 4 [10000/12481 (80%)]\tLoss: 0.116647\n",
      "Train Epoch: 4 [11000/12481 (88%)]\tLoss: 0.118120\n",
      "Train Epoch: 4 [12000/12481 (96%)]\tLoss: 0.098530\n",
      "Train Epoch: 5 [0/12481 (0%)]\tLoss: 0.183281\n",
      "Train Epoch: 5 [1000/12481 (8%)]\tLoss: 0.160381\n",
      "Train Epoch: 5 [2000/12481 (16%)]\tLoss: 0.116872\n",
      "Train Epoch: 5 [3000/12481 (24%)]\tLoss: 0.121417\n",
      "Train Epoch: 5 [4000/12481 (32%)]\tLoss: 0.208528\n",
      "Train Epoch: 5 [5000/12481 (40%)]\tLoss: 0.224417\n",
      "Train Epoch: 5 [6000/12481 (48%)]\tLoss: 0.206228\n",
      "Train Epoch: 5 [7000/12481 (56%)]\tLoss: 0.187903\n",
      "Train Epoch: 5 [8000/12481 (64%)]\tLoss: 0.184227\n",
      "Train Epoch: 5 [9000/12481 (72%)]\tLoss: 0.216283\n",
      "Train Epoch: 5 [10000/12481 (80%)]\tLoss: 0.081361\n",
      "Train Epoch: 5 [11000/12481 (88%)]\tLoss: 0.272189\n",
      "Train Epoch: 5 [12000/12481 (96%)]\tLoss: 0.159796\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "4\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8080, Accuracy: 8462/10000 (85%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/23974 (0%)]\tLoss: 0.332391\n",
      "Train Epoch: 1 [1000/23974 (4%)]\tLoss: 0.301438\n",
      "Train Epoch: 1 [2000/23974 (8%)]\tLoss: 0.440637\n",
      "Train Epoch: 1 [3000/23974 (12%)]\tLoss: 0.226982\n",
      "Train Epoch: 1 [4000/23974 (17%)]\tLoss: 0.397466\n",
      "Train Epoch: 1 [5000/23974 (21%)]\tLoss: 0.314316\n",
      "Train Epoch: 1 [6000/23974 (25%)]\tLoss: 0.318629\n",
      "Train Epoch: 1 [7000/23974 (29%)]\tLoss: 0.302527\n",
      "Train Epoch: 1 [8000/23974 (33%)]\tLoss: 0.291916\n",
      "Train Epoch: 1 [9000/23974 (38%)]\tLoss: 0.187319\n",
      "Train Epoch: 1 [10000/23974 (42%)]\tLoss: 0.212463\n",
      "Train Epoch: 1 [11000/23974 (46%)]\tLoss: 0.197975\n",
      "Train Epoch: 1 [12000/23974 (50%)]\tLoss: 0.333688\n",
      "Train Epoch: 1 [13000/23974 (54%)]\tLoss: 0.187418\n",
      "Train Epoch: 1 [14000/23974 (58%)]\tLoss: 0.360974\n",
      "Train Epoch: 1 [15000/23974 (62%)]\tLoss: 0.326017\n",
      "Train Epoch: 1 [16000/23974 (67%)]\tLoss: 0.336696\n",
      "Train Epoch: 1 [17000/23974 (71%)]\tLoss: 0.188805\n",
      "Train Epoch: 1 [18000/23974 (75%)]\tLoss: 0.227861\n",
      "Train Epoch: 1 [19000/23974 (79%)]\tLoss: 0.304450\n",
      "Train Epoch: 1 [20000/23974 (83%)]\tLoss: 0.387066\n",
      "Train Epoch: 1 [21000/23974 (88%)]\tLoss: 0.248498\n",
      "Train Epoch: 1 [22000/23974 (92%)]\tLoss: 0.199856\n",
      "Train Epoch: 1 [23000/23974 (96%)]\tLoss: 0.220315\n",
      "Train Epoch: 2 [0/23974 (0%)]\tLoss: 0.271718\n",
      "Train Epoch: 2 [1000/23974 (4%)]\tLoss: 0.251461\n",
      "Train Epoch: 2 [2000/23974 (8%)]\tLoss: 0.124015\n",
      "Train Epoch: 2 [3000/23974 (12%)]\tLoss: 0.147310\n",
      "Train Epoch: 2 [4000/23974 (17%)]\tLoss: 0.340220\n",
      "Train Epoch: 2 [5000/23974 (21%)]\tLoss: 0.201971\n",
      "Train Epoch: 2 [6000/23974 (25%)]\tLoss: 0.190683\n",
      "Train Epoch: 2 [7000/23974 (29%)]\tLoss: 0.181845\n",
      "Train Epoch: 2 [8000/23974 (33%)]\tLoss: 0.243139\n",
      "Train Epoch: 2 [9000/23974 (38%)]\tLoss: 0.262172\n",
      "Train Epoch: 2 [10000/23974 (42%)]\tLoss: 0.189421\n",
      "Train Epoch: 2 [11000/23974 (46%)]\tLoss: 0.155009\n",
      "Train Epoch: 2 [12000/23974 (50%)]\tLoss: 0.105241\n",
      "Train Epoch: 2 [13000/23974 (54%)]\tLoss: 0.243466\n",
      "Train Epoch: 2 [14000/23974 (58%)]\tLoss: 0.269281\n",
      "Train Epoch: 2 [15000/23974 (62%)]\tLoss: 0.216612\n",
      "Train Epoch: 2 [16000/23974 (67%)]\tLoss: 0.222997\n",
      "Train Epoch: 2 [17000/23974 (71%)]\tLoss: 0.157463\n",
      "Train Epoch: 2 [18000/23974 (75%)]\tLoss: 0.140087\n",
      "Train Epoch: 2 [19000/23974 (79%)]\tLoss: 0.351676\n",
      "Train Epoch: 2 [20000/23974 (83%)]\tLoss: 0.251663\n",
      "Train Epoch: 2 [21000/23974 (88%)]\tLoss: 0.348645\n",
      "Train Epoch: 2 [22000/23974 (92%)]\tLoss: 0.257554\n",
      "Train Epoch: 2 [23000/23974 (96%)]\tLoss: 0.340759\n",
      "Train Epoch: 3 [0/23974 (0%)]\tLoss: 0.134620\n",
      "Train Epoch: 3 [1000/23974 (4%)]\tLoss: 0.179449\n",
      "Train Epoch: 3 [2000/23974 (8%)]\tLoss: 0.475476\n",
      "Train Epoch: 3 [3000/23974 (12%)]\tLoss: 0.171910\n",
      "Train Epoch: 3 [4000/23974 (17%)]\tLoss: 0.184593\n",
      "Train Epoch: 3 [5000/23974 (21%)]\tLoss: 0.166796\n",
      "Train Epoch: 3 [6000/23974 (25%)]\tLoss: 0.254922\n",
      "Train Epoch: 3 [7000/23974 (29%)]\tLoss: 0.233164\n",
      "Train Epoch: 3 [8000/23974 (33%)]\tLoss: 0.216730\n",
      "Train Epoch: 3 [9000/23974 (38%)]\tLoss: 0.224197\n",
      "Train Epoch: 3 [10000/23974 (42%)]\tLoss: 0.286170\n",
      "Train Epoch: 3 [11000/23974 (46%)]\tLoss: 0.187922\n",
      "Train Epoch: 3 [12000/23974 (50%)]\tLoss: 0.240949\n",
      "Train Epoch: 3 [13000/23974 (54%)]\tLoss: 0.218080\n",
      "Train Epoch: 3 [14000/23974 (58%)]\tLoss: 0.132132\n",
      "Train Epoch: 3 [15000/23974 (62%)]\tLoss: 0.281550\n",
      "Train Epoch: 3 [16000/23974 (67%)]\tLoss: 0.281908\n",
      "Train Epoch: 3 [17000/23974 (71%)]\tLoss: 0.194898\n",
      "Train Epoch: 3 [18000/23974 (75%)]\tLoss: 0.284179\n",
      "Train Epoch: 3 [19000/23974 (79%)]\tLoss: 0.233498\n",
      "Train Epoch: 3 [20000/23974 (83%)]\tLoss: 0.244578\n",
      "Train Epoch: 3 [21000/23974 (88%)]\tLoss: 0.156034\n",
      "Train Epoch: 3 [22000/23974 (92%)]\tLoss: 0.234829\n",
      "Train Epoch: 3 [23000/23974 (96%)]\tLoss: 0.257773\n",
      "Train Epoch: 4 [0/23974 (0%)]\tLoss: 0.266616\n",
      "Train Epoch: 4 [1000/23974 (4%)]\tLoss: 0.243781\n",
      "Train Epoch: 4 [2000/23974 (8%)]\tLoss: 0.330222\n",
      "Train Epoch: 4 [3000/23974 (12%)]\tLoss: 0.145795\n",
      "Train Epoch: 4 [4000/23974 (17%)]\tLoss: 0.202315\n",
      "Train Epoch: 4 [5000/23974 (21%)]\tLoss: 0.250339\n",
      "Train Epoch: 4 [6000/23974 (25%)]\tLoss: 0.188618\n",
      "Train Epoch: 4 [7000/23974 (29%)]\tLoss: 0.337656\n",
      "Train Epoch: 4 [8000/23974 (33%)]\tLoss: 0.169715\n",
      "Train Epoch: 4 [9000/23974 (38%)]\tLoss: 0.185619\n",
      "Train Epoch: 4 [10000/23974 (42%)]\tLoss: 0.185252\n",
      "Train Epoch: 4 [11000/23974 (46%)]\tLoss: 0.164522\n",
      "Train Epoch: 4 [12000/23974 (50%)]\tLoss: 0.134512\n",
      "Train Epoch: 4 [13000/23974 (54%)]\tLoss: 0.183281\n",
      "Train Epoch: 4 [14000/23974 (58%)]\tLoss: 0.231681\n",
      "Train Epoch: 4 [15000/23974 (62%)]\tLoss: 0.193629\n",
      "Train Epoch: 4 [16000/23974 (67%)]\tLoss: 0.266331\n",
      "Train Epoch: 4 [17000/23974 (71%)]\tLoss: 0.254598\n",
      "Train Epoch: 4 [18000/23974 (75%)]\tLoss: 0.288808\n",
      "Train Epoch: 4 [19000/23974 (79%)]\tLoss: 0.215262\n",
      "Train Epoch: 4 [20000/23974 (83%)]\tLoss: 0.304208\n",
      "Train Epoch: 4 [21000/23974 (88%)]\tLoss: 0.298642\n",
      "Train Epoch: 4 [22000/23974 (92%)]\tLoss: 0.208655\n",
      "Train Epoch: 4 [23000/23974 (96%)]\tLoss: 0.285326\n",
      "Train Epoch: 5 [0/23974 (0%)]\tLoss: 0.186177\n",
      "Train Epoch: 5 [1000/23974 (4%)]\tLoss: 0.237307\n",
      "Train Epoch: 5 [2000/23974 (8%)]\tLoss: 0.166357\n",
      "Train Epoch: 5 [3000/23974 (12%)]\tLoss: 0.279195\n",
      "Train Epoch: 5 [4000/23974 (17%)]\tLoss: 0.177914\n",
      "Train Epoch: 5 [5000/23974 (21%)]\tLoss: 0.333356\n",
      "Train Epoch: 5 [6000/23974 (25%)]\tLoss: 0.377869\n",
      "Train Epoch: 5 [7000/23974 (29%)]\tLoss: 0.279506\n",
      "Train Epoch: 5 [8000/23974 (33%)]\tLoss: 0.204303\n",
      "Train Epoch: 5 [9000/23974 (38%)]\tLoss: 0.151981\n",
      "Train Epoch: 5 [10000/23974 (42%)]\tLoss: 0.228208\n",
      "Train Epoch: 5 [11000/23974 (46%)]\tLoss: 0.108235\n",
      "Train Epoch: 5 [12000/23974 (50%)]\tLoss: 0.352192\n",
      "Train Epoch: 5 [13000/23974 (54%)]\tLoss: 0.198143\n",
      "Train Epoch: 5 [14000/23974 (58%)]\tLoss: 0.324260\n",
      "Train Epoch: 5 [15000/23974 (62%)]\tLoss: 0.231249\n",
      "Train Epoch: 5 [16000/23974 (67%)]\tLoss: 0.348047\n",
      "Train Epoch: 5 [17000/23974 (71%)]\tLoss: 0.190515\n",
      "Train Epoch: 5 [18000/23974 (75%)]\tLoss: 0.197005\n",
      "Train Epoch: 5 [19000/23974 (79%)]\tLoss: 0.262540\n",
      "Train Epoch: 5 [20000/23974 (83%)]\tLoss: 0.270303\n",
      "Train Epoch: 5 [21000/23974 (88%)]\tLoss: 0.159195\n",
      "Train Epoch: 5 [22000/23974 (92%)]\tLoss: 0.203739\n",
      "Train Epoch: 5 [23000/23974 (96%)]\tLoss: 0.180671\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7961 (0%)]\tLoss: 0.454855\n",
      "Train Epoch: 1 [1000/7961 (12%)]\tLoss: 0.252956\n",
      "Train Epoch: 1 [2000/7961 (25%)]\tLoss: 0.513099\n",
      "Train Epoch: 1 [3000/7961 (38%)]\tLoss: 0.301818\n",
      "Train Epoch: 1 [4000/7961 (50%)]\tLoss: 0.237851\n",
      "Train Epoch: 1 [5000/7961 (62%)]\tLoss: 0.495206\n",
      "Train Epoch: 1 [6000/7961 (75%)]\tLoss: 0.286226\n",
      "Train Epoch: 1 [7000/7961 (88%)]\tLoss: 0.418614\n",
      "Train Epoch: 2 [0/7961 (0%)]\tLoss: 0.357522\n",
      "Train Epoch: 2 [1000/7961 (12%)]\tLoss: 0.312324\n",
      "Train Epoch: 2 [2000/7961 (25%)]\tLoss: 0.209419\n",
      "Train Epoch: 2 [3000/7961 (38%)]\tLoss: 0.361735\n",
      "Train Epoch: 2 [4000/7961 (50%)]\tLoss: 0.420196\n",
      "Train Epoch: 2 [5000/7961 (62%)]\tLoss: 0.385700\n",
      "Train Epoch: 2 [6000/7961 (75%)]\tLoss: 0.463522\n",
      "Train Epoch: 2 [7000/7961 (88%)]\tLoss: 0.318390\n",
      "Train Epoch: 3 [0/7961 (0%)]\tLoss: 0.195564\n",
      "Train Epoch: 3 [1000/7961 (12%)]\tLoss: 0.223020\n",
      "Train Epoch: 3 [2000/7961 (25%)]\tLoss: 0.333657\n",
      "Train Epoch: 3 [3000/7961 (38%)]\tLoss: 0.300662\n",
      "Train Epoch: 3 [4000/7961 (50%)]\tLoss: 0.452928\n",
      "Train Epoch: 3 [5000/7961 (62%)]\tLoss: 0.412369\n",
      "Train Epoch: 3 [6000/7961 (75%)]\tLoss: 0.235237\n",
      "Train Epoch: 3 [7000/7961 (88%)]\tLoss: 0.304411\n",
      "Train Epoch: 4 [0/7961 (0%)]\tLoss: 0.384895\n",
      "Train Epoch: 4 [1000/7961 (12%)]\tLoss: 0.432481\n",
      "Train Epoch: 4 [2000/7961 (25%)]\tLoss: 0.250247\n",
      "Train Epoch: 4 [3000/7961 (38%)]\tLoss: 0.298259\n",
      "Train Epoch: 4 [4000/7961 (50%)]\tLoss: 0.347863\n",
      "Train Epoch: 4 [5000/7961 (62%)]\tLoss: 0.305654\n",
      "Train Epoch: 4 [6000/7961 (75%)]\tLoss: 0.339597\n",
      "Train Epoch: 4 [7000/7961 (88%)]\tLoss: 0.220963\n",
      "Train Epoch: 5 [0/7961 (0%)]\tLoss: 0.354145\n",
      "Train Epoch: 5 [1000/7961 (12%)]\tLoss: 0.265967\n",
      "Train Epoch: 5 [2000/7961 (25%)]\tLoss: 0.221642\n",
      "Train Epoch: 5 [3000/7961 (38%)]\tLoss: 0.369105\n",
      "Train Epoch: 5 [4000/7961 (50%)]\tLoss: 0.297226\n",
      "Train Epoch: 5 [5000/7961 (62%)]\tLoss: 0.405235\n",
      "Train Epoch: 5 [6000/7961 (75%)]\tLoss: 0.280435\n",
      "Train Epoch: 5 [7000/7961 (88%)]\tLoss: 0.318353\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/15584 (0%)]\tLoss: 0.387888\n",
      "Train Epoch: 1 [1000/15584 (6%)]\tLoss: 0.285771\n",
      "Train Epoch: 1 [2000/15584 (13%)]\tLoss: 0.224143\n",
      "Train Epoch: 1 [3000/15584 (19%)]\tLoss: 0.164036\n",
      "Train Epoch: 1 [4000/15584 (26%)]\tLoss: 0.214453\n",
      "Train Epoch: 1 [5000/15584 (32%)]\tLoss: 0.342274\n",
      "Train Epoch: 1 [6000/15584 (38%)]\tLoss: 0.164462\n",
      "Train Epoch: 1 [7000/15584 (45%)]\tLoss: 0.214885\n",
      "Train Epoch: 1 [8000/15584 (51%)]\tLoss: 0.294217\n",
      "Train Epoch: 1 [9000/15584 (58%)]\tLoss: 0.253314\n",
      "Train Epoch: 1 [10000/15584 (64%)]\tLoss: 0.224314\n",
      "Train Epoch: 1 [11000/15584 (71%)]\tLoss: 0.310522\n",
      "Train Epoch: 1 [12000/15584 (77%)]\tLoss: 0.230248\n",
      "Train Epoch: 1 [13000/15584 (83%)]\tLoss: 0.179320\n",
      "Train Epoch: 1 [14000/15584 (90%)]\tLoss: 0.150699\n",
      "Train Epoch: 1 [15000/15584 (96%)]\tLoss: 0.202997\n",
      "Train Epoch: 2 [0/15584 (0%)]\tLoss: 0.198636\n",
      "Train Epoch: 2 [1000/15584 (6%)]\tLoss: 0.192389\n",
      "Train Epoch: 2 [2000/15584 (13%)]\tLoss: 0.260773\n",
      "Train Epoch: 2 [3000/15584 (19%)]\tLoss: 0.258447\n",
      "Train Epoch: 2 [4000/15584 (26%)]\tLoss: 0.199241\n",
      "Train Epoch: 2 [5000/15584 (32%)]\tLoss: 0.283929\n",
      "Train Epoch: 2 [6000/15584 (38%)]\tLoss: 0.223985\n",
      "Train Epoch: 2 [7000/15584 (45%)]\tLoss: 0.138966\n",
      "Train Epoch: 2 [8000/15584 (51%)]\tLoss: 0.189809\n",
      "Train Epoch: 2 [9000/15584 (58%)]\tLoss: 0.251279\n",
      "Train Epoch: 2 [10000/15584 (64%)]\tLoss: 0.214184\n",
      "Train Epoch: 2 [11000/15584 (71%)]\tLoss: 0.139812\n",
      "Train Epoch: 2 [12000/15584 (77%)]\tLoss: 0.287216\n",
      "Train Epoch: 2 [13000/15584 (83%)]\tLoss: 0.185007\n",
      "Train Epoch: 2 [14000/15584 (90%)]\tLoss: 0.182100\n",
      "Train Epoch: 2 [15000/15584 (96%)]\tLoss: 0.180358\n",
      "Train Epoch: 3 [0/15584 (0%)]\tLoss: 0.293180\n",
      "Train Epoch: 3 [1000/15584 (6%)]\tLoss: 0.126496\n",
      "Train Epoch: 3 [2000/15584 (13%)]\tLoss: 0.204338\n",
      "Train Epoch: 3 [3000/15584 (19%)]\tLoss: 0.245898\n",
      "Train Epoch: 3 [4000/15584 (26%)]\tLoss: 0.247942\n",
      "Train Epoch: 3 [5000/15584 (32%)]\tLoss: 0.287092\n",
      "Train Epoch: 3 [6000/15584 (38%)]\tLoss: 0.236624\n",
      "Train Epoch: 3 [7000/15584 (45%)]\tLoss: 0.185812\n",
      "Train Epoch: 3 [8000/15584 (51%)]\tLoss: 0.285172\n",
      "Train Epoch: 3 [9000/15584 (58%)]\tLoss: 0.338066\n",
      "Train Epoch: 3 [10000/15584 (64%)]\tLoss: 0.096015\n",
      "Train Epoch: 3 [11000/15584 (71%)]\tLoss: 0.312125\n",
      "Train Epoch: 3 [12000/15584 (77%)]\tLoss: 0.205343\n",
      "Train Epoch: 3 [13000/15584 (83%)]\tLoss: 0.243912\n",
      "Train Epoch: 3 [14000/15584 (90%)]\tLoss: 0.196124\n",
      "Train Epoch: 3 [15000/15584 (96%)]\tLoss: 0.155551\n",
      "Train Epoch: 4 [0/15584 (0%)]\tLoss: 0.325388\n",
      "Train Epoch: 4 [1000/15584 (6%)]\tLoss: 0.146338\n",
      "Train Epoch: 4 [2000/15584 (13%)]\tLoss: 0.169837\n",
      "Train Epoch: 4 [3000/15584 (19%)]\tLoss: 0.213454\n",
      "Train Epoch: 4 [4000/15584 (26%)]\tLoss: 0.343667\n",
      "Train Epoch: 4 [5000/15584 (32%)]\tLoss: 0.123353\n",
      "Train Epoch: 4 [6000/15584 (38%)]\tLoss: 0.233061\n",
      "Train Epoch: 4 [7000/15584 (45%)]\tLoss: 0.255706\n",
      "Train Epoch: 4 [8000/15584 (51%)]\tLoss: 0.275814\n",
      "Train Epoch: 4 [9000/15584 (58%)]\tLoss: 0.238840\n",
      "Train Epoch: 4 [10000/15584 (64%)]\tLoss: 0.251928\n",
      "Train Epoch: 4 [11000/15584 (71%)]\tLoss: 0.186656\n",
      "Train Epoch: 4 [12000/15584 (77%)]\tLoss: 0.292383\n",
      "Train Epoch: 4 [13000/15584 (83%)]\tLoss: 0.135913\n",
      "Train Epoch: 4 [14000/15584 (90%)]\tLoss: 0.178598\n",
      "Train Epoch: 4 [15000/15584 (96%)]\tLoss: 0.160527\n",
      "Train Epoch: 5 [0/15584 (0%)]\tLoss: 0.192771\n",
      "Train Epoch: 5 [1000/15584 (6%)]\tLoss: 0.136692\n",
      "Train Epoch: 5 [2000/15584 (13%)]\tLoss: 0.161403\n",
      "Train Epoch: 5 [3000/15584 (19%)]\tLoss: 0.122706\n",
      "Train Epoch: 5 [4000/15584 (26%)]\tLoss: 0.218054\n",
      "Train Epoch: 5 [5000/15584 (32%)]\tLoss: 0.187465\n",
      "Train Epoch: 5 [6000/15584 (38%)]\tLoss: 0.205427\n",
      "Train Epoch: 5 [7000/15584 (45%)]\tLoss: 0.271361\n",
      "Train Epoch: 5 [8000/15584 (51%)]\tLoss: 0.161606\n",
      "Train Epoch: 5 [9000/15584 (58%)]\tLoss: 0.222671\n",
      "Train Epoch: 5 [10000/15584 (64%)]\tLoss: 0.287121\n",
      "Train Epoch: 5 [11000/15584 (71%)]\tLoss: 0.172601\n",
      "Train Epoch: 5 [12000/15584 (77%)]\tLoss: 0.221085\n",
      "Train Epoch: 5 [13000/15584 (83%)]\tLoss: 0.189105\n",
      "Train Epoch: 5 [14000/15584 (90%)]\tLoss: 0.108380\n",
      "Train Epoch: 5 [15000/15584 (96%)]\tLoss: 0.243235\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/12481 (0%)]\tLoss: 0.219296\n",
      "Train Epoch: 1 [1000/12481 (8%)]\tLoss: 0.101464\n",
      "Train Epoch: 1 [2000/12481 (16%)]\tLoss: 0.217658\n",
      "Train Epoch: 1 [3000/12481 (24%)]\tLoss: 0.199425\n",
      "Train Epoch: 1 [4000/12481 (32%)]\tLoss: 0.205665\n",
      "Train Epoch: 1 [5000/12481 (40%)]\tLoss: 0.215236\n",
      "Train Epoch: 1 [6000/12481 (48%)]\tLoss: 0.203987\n",
      "Train Epoch: 1 [7000/12481 (56%)]\tLoss: 0.061745\n",
      "Train Epoch: 1 [8000/12481 (64%)]\tLoss: 0.205122\n",
      "Train Epoch: 1 [9000/12481 (72%)]\tLoss: 0.208924\n",
      "Train Epoch: 1 [10000/12481 (80%)]\tLoss: 0.210646\n",
      "Train Epoch: 1 [11000/12481 (88%)]\tLoss: 0.209400\n",
      "Train Epoch: 1 [12000/12481 (96%)]\tLoss: 0.144393\n",
      "Train Epoch: 2 [0/12481 (0%)]\tLoss: 0.154437\n",
      "Train Epoch: 2 [1000/12481 (8%)]\tLoss: 0.147424\n",
      "Train Epoch: 2 [2000/12481 (16%)]\tLoss: 0.107280\n",
      "Train Epoch: 2 [3000/12481 (24%)]\tLoss: 0.145717\n",
      "Train Epoch: 2 [4000/12481 (32%)]\tLoss: 0.139978\n",
      "Train Epoch: 2 [5000/12481 (40%)]\tLoss: 0.141202\n",
      "Train Epoch: 2 [6000/12481 (48%)]\tLoss: 0.221589\n",
      "Train Epoch: 2 [7000/12481 (56%)]\tLoss: 0.125217\n",
      "Train Epoch: 2 [8000/12481 (64%)]\tLoss: 0.150831\n",
      "Train Epoch: 2 [9000/12481 (72%)]\tLoss: 0.145995\n",
      "Train Epoch: 2 [10000/12481 (80%)]\tLoss: 0.181867\n",
      "Train Epoch: 2 [11000/12481 (88%)]\tLoss: 0.129274\n",
      "Train Epoch: 2 [12000/12481 (96%)]\tLoss: 0.167086\n",
      "Train Epoch: 3 [0/12481 (0%)]\tLoss: 0.160527\n",
      "Train Epoch: 3 [1000/12481 (8%)]\tLoss: 0.095074\n",
      "Train Epoch: 3 [2000/12481 (16%)]\tLoss: 0.153404\n",
      "Train Epoch: 3 [3000/12481 (24%)]\tLoss: 0.181895\n",
      "Train Epoch: 3 [4000/12481 (32%)]\tLoss: 0.110200\n",
      "Train Epoch: 3 [5000/12481 (40%)]\tLoss: 0.105556\n",
      "Train Epoch: 3 [6000/12481 (48%)]\tLoss: 0.119984\n",
      "Train Epoch: 3 [7000/12481 (56%)]\tLoss: 0.204412\n",
      "Train Epoch: 3 [8000/12481 (64%)]\tLoss: 0.145533\n",
      "Train Epoch: 3 [9000/12481 (72%)]\tLoss: 0.152598\n",
      "Train Epoch: 3 [10000/12481 (80%)]\tLoss: 0.164298\n",
      "Train Epoch: 3 [11000/12481 (88%)]\tLoss: 0.106055\n",
      "Train Epoch: 3 [12000/12481 (96%)]\tLoss: 0.056459\n",
      "Train Epoch: 4 [0/12481 (0%)]\tLoss: 0.220128\n",
      "Train Epoch: 4 [1000/12481 (8%)]\tLoss: 0.189620\n",
      "Train Epoch: 4 [2000/12481 (16%)]\tLoss: 0.070092\n",
      "Train Epoch: 4 [3000/12481 (24%)]\tLoss: 0.148658\n",
      "Train Epoch: 4 [4000/12481 (32%)]\tLoss: 0.137145\n",
      "Train Epoch: 4 [5000/12481 (40%)]\tLoss: 0.206104\n",
      "Train Epoch: 4 [6000/12481 (48%)]\tLoss: 0.141648\n",
      "Train Epoch: 4 [7000/12481 (56%)]\tLoss: 0.182231\n",
      "Train Epoch: 4 [8000/12481 (64%)]\tLoss: 0.159649\n",
      "Train Epoch: 4 [9000/12481 (72%)]\tLoss: 0.153151\n",
      "Train Epoch: 4 [10000/12481 (80%)]\tLoss: 0.122054\n",
      "Train Epoch: 4 [11000/12481 (88%)]\tLoss: 0.242278\n",
      "Train Epoch: 4 [12000/12481 (96%)]\tLoss: 0.176538\n",
      "Train Epoch: 5 [0/12481 (0%)]\tLoss: 0.165302\n",
      "Train Epoch: 5 [1000/12481 (8%)]\tLoss: 0.064951\n",
      "Train Epoch: 5 [2000/12481 (16%)]\tLoss: 0.166849\n",
      "Train Epoch: 5 [3000/12481 (24%)]\tLoss: 0.163589\n",
      "Train Epoch: 5 [4000/12481 (32%)]\tLoss: 0.171019\n",
      "Train Epoch: 5 [5000/12481 (40%)]\tLoss: 0.117408\n",
      "Train Epoch: 5 [6000/12481 (48%)]\tLoss: 0.144291\n",
      "Train Epoch: 5 [7000/12481 (56%)]\tLoss: 0.108402\n",
      "Train Epoch: 5 [8000/12481 (64%)]\tLoss: 0.168042\n",
      "Train Epoch: 5 [9000/12481 (72%)]\tLoss: 0.098617\n",
      "Train Epoch: 5 [10000/12481 (80%)]\tLoss: 0.069885\n",
      "Train Epoch: 5 [11000/12481 (88%)]\tLoss: 0.131890\n",
      "Train Epoch: 5 [12000/12481 (96%)]\tLoss: 0.157691\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "4\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.7724, Accuracy: 8606/10000 (86%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/23974 (0%)]\tLoss: 0.435652\n",
      "Train Epoch: 1 [1000/23974 (4%)]\tLoss: 0.362713\n",
      "Train Epoch: 1 [2000/23974 (8%)]\tLoss: 0.293982\n",
      "Train Epoch: 1 [3000/23974 (12%)]\tLoss: 0.167091\n",
      "Train Epoch: 1 [4000/23974 (17%)]\tLoss: 0.338828\n",
      "Train Epoch: 1 [5000/23974 (21%)]\tLoss: 0.267877\n",
      "Train Epoch: 1 [6000/23974 (25%)]\tLoss: 0.238365\n",
      "Train Epoch: 1 [7000/23974 (29%)]\tLoss: 0.171369\n",
      "Train Epoch: 1 [8000/23974 (33%)]\tLoss: 0.165363\n",
      "Train Epoch: 1 [9000/23974 (38%)]\tLoss: 0.267249\n",
      "Train Epoch: 1 [10000/23974 (42%)]\tLoss: 0.215456\n",
      "Train Epoch: 1 [11000/23974 (46%)]\tLoss: 0.229072\n",
      "Train Epoch: 1 [12000/23974 (50%)]\tLoss: 0.329036\n",
      "Train Epoch: 1 [13000/23974 (54%)]\tLoss: 0.327343\n",
      "Train Epoch: 1 [14000/23974 (58%)]\tLoss: 0.293915\n",
      "Train Epoch: 1 [15000/23974 (62%)]\tLoss: 0.361459\n",
      "Train Epoch: 1 [16000/23974 (67%)]\tLoss: 0.352616\n",
      "Train Epoch: 1 [17000/23974 (71%)]\tLoss: 0.198871\n",
      "Train Epoch: 1 [18000/23974 (75%)]\tLoss: 0.160438\n",
      "Train Epoch: 1 [19000/23974 (79%)]\tLoss: 0.328857\n",
      "Train Epoch: 1 [20000/23974 (83%)]\tLoss: 0.248603\n",
      "Train Epoch: 1 [21000/23974 (88%)]\tLoss: 0.227214\n",
      "Train Epoch: 1 [22000/23974 (92%)]\tLoss: 0.127135\n",
      "Train Epoch: 1 [23000/23974 (96%)]\tLoss: 0.211271\n",
      "Train Epoch: 2 [0/23974 (0%)]\tLoss: 0.157468\n",
      "Train Epoch: 2 [1000/23974 (4%)]\tLoss: 0.282633\n",
      "Train Epoch: 2 [2000/23974 (8%)]\tLoss: 0.279357\n",
      "Train Epoch: 2 [3000/23974 (12%)]\tLoss: 0.247692\n",
      "Train Epoch: 2 [4000/23974 (17%)]\tLoss: 0.156156\n",
      "Train Epoch: 2 [5000/23974 (21%)]\tLoss: 0.397764\n",
      "Train Epoch: 2 [6000/23974 (25%)]\tLoss: 0.295015\n",
      "Train Epoch: 2 [7000/23974 (29%)]\tLoss: 0.330875\n",
      "Train Epoch: 2 [8000/23974 (33%)]\tLoss: 0.231776\n",
      "Train Epoch: 2 [9000/23974 (38%)]\tLoss: 0.223572\n",
      "Train Epoch: 2 [10000/23974 (42%)]\tLoss: 0.231390\n",
      "Train Epoch: 2 [11000/23974 (46%)]\tLoss: 0.206773\n",
      "Train Epoch: 2 [12000/23974 (50%)]\tLoss: 0.224620\n",
      "Train Epoch: 2 [13000/23974 (54%)]\tLoss: 0.250678\n",
      "Train Epoch: 2 [14000/23974 (58%)]\tLoss: 0.228165\n",
      "Train Epoch: 2 [15000/23974 (62%)]\tLoss: 0.235197\n",
      "Train Epoch: 2 [16000/23974 (67%)]\tLoss: 0.272419\n",
      "Train Epoch: 2 [17000/23974 (71%)]\tLoss: 0.277042\n",
      "Train Epoch: 2 [18000/23974 (75%)]\tLoss: 0.261769\n",
      "Train Epoch: 2 [19000/23974 (79%)]\tLoss: 0.251081\n",
      "Train Epoch: 2 [20000/23974 (83%)]\tLoss: 0.175971\n",
      "Train Epoch: 2 [21000/23974 (88%)]\tLoss: 0.227726\n",
      "Train Epoch: 2 [22000/23974 (92%)]\tLoss: 0.100788\n",
      "Train Epoch: 2 [23000/23974 (96%)]\tLoss: 0.182495\n",
      "Train Epoch: 3 [0/23974 (0%)]\tLoss: 0.321591\n",
      "Train Epoch: 3 [1000/23974 (4%)]\tLoss: 0.211037\n",
      "Train Epoch: 3 [2000/23974 (8%)]\tLoss: 0.229032\n",
      "Train Epoch: 3 [3000/23974 (12%)]\tLoss: 0.259011\n",
      "Train Epoch: 3 [4000/23974 (17%)]\tLoss: 0.334257\n",
      "Train Epoch: 3 [5000/23974 (21%)]\tLoss: 0.184972\n",
      "Train Epoch: 3 [6000/23974 (25%)]\tLoss: 0.166861\n",
      "Train Epoch: 3 [7000/23974 (29%)]\tLoss: 0.256334\n",
      "Train Epoch: 3 [8000/23974 (33%)]\tLoss: 0.161362\n",
      "Train Epoch: 3 [9000/23974 (38%)]\tLoss: 0.237410\n",
      "Train Epoch: 3 [10000/23974 (42%)]\tLoss: 0.248801\n",
      "Train Epoch: 3 [11000/23974 (46%)]\tLoss: 0.187815\n",
      "Train Epoch: 3 [12000/23974 (50%)]\tLoss: 0.204703\n",
      "Train Epoch: 3 [13000/23974 (54%)]\tLoss: 0.237661\n",
      "Train Epoch: 3 [14000/23974 (58%)]\tLoss: 0.265190\n",
      "Train Epoch: 3 [15000/23974 (62%)]\tLoss: 0.312096\n",
      "Train Epoch: 3 [16000/23974 (67%)]\tLoss: 0.167363\n",
      "Train Epoch: 3 [17000/23974 (71%)]\tLoss: 0.310445\n",
      "Train Epoch: 3 [18000/23974 (75%)]\tLoss: 0.322369\n",
      "Train Epoch: 3 [19000/23974 (79%)]\tLoss: 0.204476\n",
      "Train Epoch: 3 [20000/23974 (83%)]\tLoss: 0.371205\n",
      "Train Epoch: 3 [21000/23974 (88%)]\tLoss: 0.201915\n",
      "Train Epoch: 3 [22000/23974 (92%)]\tLoss: 0.154451\n",
      "Train Epoch: 3 [23000/23974 (96%)]\tLoss: 0.236221\n",
      "Train Epoch: 4 [0/23974 (0%)]\tLoss: 0.222814\n",
      "Train Epoch: 4 [1000/23974 (4%)]\tLoss: 0.150775\n",
      "Train Epoch: 4 [2000/23974 (8%)]\tLoss: 0.255248\n",
      "Train Epoch: 4 [3000/23974 (12%)]\tLoss: 0.267978\n",
      "Train Epoch: 4 [4000/23974 (17%)]\tLoss: 0.163551\n",
      "Train Epoch: 4 [5000/23974 (21%)]\tLoss: 0.191175\n",
      "Train Epoch: 4 [6000/23974 (25%)]\tLoss: 0.197973\n",
      "Train Epoch: 4 [7000/23974 (29%)]\tLoss: 0.232497\n",
      "Train Epoch: 4 [8000/23974 (33%)]\tLoss: 0.149823\n",
      "Train Epoch: 4 [9000/23974 (38%)]\tLoss: 0.238802\n",
      "Train Epoch: 4 [10000/23974 (42%)]\tLoss: 0.211913\n",
      "Train Epoch: 4 [11000/23974 (46%)]\tLoss: 0.228030\n",
      "Train Epoch: 4 [12000/23974 (50%)]\tLoss: 0.178022\n",
      "Train Epoch: 4 [13000/23974 (54%)]\tLoss: 0.191641\n",
      "Train Epoch: 4 [14000/23974 (58%)]\tLoss: 0.296042\n",
      "Train Epoch: 4 [15000/23974 (62%)]\tLoss: 0.253797\n",
      "Train Epoch: 4 [16000/23974 (67%)]\tLoss: 0.262066\n",
      "Train Epoch: 4 [17000/23974 (71%)]\tLoss: 0.107490\n",
      "Train Epoch: 4 [18000/23974 (75%)]\tLoss: 0.236458\n",
      "Train Epoch: 4 [19000/23974 (79%)]\tLoss: 0.238288\n",
      "Train Epoch: 4 [20000/23974 (83%)]\tLoss: 0.168740\n",
      "Train Epoch: 4 [21000/23974 (88%)]\tLoss: 0.209645\n",
      "Train Epoch: 4 [22000/23974 (92%)]\tLoss: 0.192412\n",
      "Train Epoch: 4 [23000/23974 (96%)]\tLoss: 0.248583\n",
      "Train Epoch: 5 [0/23974 (0%)]\tLoss: 0.307761\n",
      "Train Epoch: 5 [1000/23974 (4%)]\tLoss: 0.264015\n",
      "Train Epoch: 5 [2000/23974 (8%)]\tLoss: 0.224211\n",
      "Train Epoch: 5 [3000/23974 (12%)]\tLoss: 0.235976\n",
      "Train Epoch: 5 [4000/23974 (17%)]\tLoss: 0.358552\n",
      "Train Epoch: 5 [5000/23974 (21%)]\tLoss: 0.163483\n",
      "Train Epoch: 5 [6000/23974 (25%)]\tLoss: 0.283890\n",
      "Train Epoch: 5 [7000/23974 (29%)]\tLoss: 0.266795\n",
      "Train Epoch: 5 [8000/23974 (33%)]\tLoss: 0.134255\n",
      "Train Epoch: 5 [9000/23974 (38%)]\tLoss: 0.212981\n",
      "Train Epoch: 5 [10000/23974 (42%)]\tLoss: 0.193834\n",
      "Train Epoch: 5 [11000/23974 (46%)]\tLoss: 0.123831\n",
      "Train Epoch: 5 [12000/23974 (50%)]\tLoss: 0.259995\n",
      "Train Epoch: 5 [13000/23974 (54%)]\tLoss: 0.280190\n",
      "Train Epoch: 5 [14000/23974 (58%)]\tLoss: 0.208238\n",
      "Train Epoch: 5 [15000/23974 (62%)]\tLoss: 0.346715\n",
      "Train Epoch: 5 [16000/23974 (67%)]\tLoss: 0.409824\n",
      "Train Epoch: 5 [17000/23974 (71%)]\tLoss: 0.235530\n",
      "Train Epoch: 5 [18000/23974 (75%)]\tLoss: 0.332570\n",
      "Train Epoch: 5 [19000/23974 (79%)]\tLoss: 0.218705\n",
      "Train Epoch: 5 [20000/23974 (83%)]\tLoss: 0.329075\n",
      "Train Epoch: 5 [21000/23974 (88%)]\tLoss: 0.215082\n",
      "Train Epoch: 5 [22000/23974 (92%)]\tLoss: 0.149411\n",
      "Train Epoch: 5 [23000/23974 (96%)]\tLoss: 0.279451\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7961 (0%)]\tLoss: 0.350652\n",
      "Train Epoch: 1 [1000/7961 (12%)]\tLoss: 0.366645\n",
      "Train Epoch: 1 [2000/7961 (25%)]\tLoss: 0.283154\n",
      "Train Epoch: 1 [3000/7961 (38%)]\tLoss: 0.425751\n",
      "Train Epoch: 1 [4000/7961 (50%)]\tLoss: 0.405517\n",
      "Train Epoch: 1 [5000/7961 (62%)]\tLoss: 0.277019\n",
      "Train Epoch: 1 [6000/7961 (75%)]\tLoss: 0.365531\n",
      "Train Epoch: 1 [7000/7961 (88%)]\tLoss: 0.303635\n",
      "Train Epoch: 2 [0/7961 (0%)]\tLoss: 0.243312\n",
      "Train Epoch: 2 [1000/7961 (12%)]\tLoss: 0.292302\n",
      "Train Epoch: 2 [2000/7961 (25%)]\tLoss: 0.411797\n",
      "Train Epoch: 2 [3000/7961 (38%)]\tLoss: 0.347007\n",
      "Train Epoch: 2 [4000/7961 (50%)]\tLoss: 0.253450\n",
      "Train Epoch: 2 [5000/7961 (62%)]\tLoss: 0.434571\n",
      "Train Epoch: 2 [6000/7961 (75%)]\tLoss: 0.283988\n",
      "Train Epoch: 2 [7000/7961 (88%)]\tLoss: 0.343517\n",
      "Train Epoch: 3 [0/7961 (0%)]\tLoss: 0.142229\n",
      "Train Epoch: 3 [1000/7961 (12%)]\tLoss: 0.218879\n",
      "Train Epoch: 3 [2000/7961 (25%)]\tLoss: 0.409472\n",
      "Train Epoch: 3 [3000/7961 (38%)]\tLoss: 0.288589\n",
      "Train Epoch: 3 [4000/7961 (50%)]\tLoss: 0.323675\n",
      "Train Epoch: 3 [5000/7961 (62%)]\tLoss: 0.231235\n",
      "Train Epoch: 3 [6000/7961 (75%)]\tLoss: 0.258776\n",
      "Train Epoch: 3 [7000/7961 (88%)]\tLoss: 0.226996\n",
      "Train Epoch: 4 [0/7961 (0%)]\tLoss: 0.244696\n",
      "Train Epoch: 4 [1000/7961 (12%)]\tLoss: 0.344862\n",
      "Train Epoch: 4 [2000/7961 (25%)]\tLoss: 0.248711\n",
      "Train Epoch: 4 [3000/7961 (38%)]\tLoss: 0.367080\n",
      "Train Epoch: 4 [4000/7961 (50%)]\tLoss: 0.205092\n",
      "Train Epoch: 4 [5000/7961 (62%)]\tLoss: 0.317598\n",
      "Train Epoch: 4 [6000/7961 (75%)]\tLoss: 0.303651\n",
      "Train Epoch: 4 [7000/7961 (88%)]\tLoss: 0.281957\n",
      "Train Epoch: 5 [0/7961 (0%)]\tLoss: 0.200182\n",
      "Train Epoch: 5 [1000/7961 (12%)]\tLoss: 0.316564\n",
      "Train Epoch: 5 [2000/7961 (25%)]\tLoss: 0.303288\n",
      "Train Epoch: 5 [3000/7961 (38%)]\tLoss: 0.240381\n",
      "Train Epoch: 5 [4000/7961 (50%)]\tLoss: 0.250060\n",
      "Train Epoch: 5 [5000/7961 (62%)]\tLoss: 0.319964\n",
      "Train Epoch: 5 [6000/7961 (75%)]\tLoss: 0.165186\n",
      "Train Epoch: 5 [7000/7961 (88%)]\tLoss: 0.222454\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/15584 (0%)]\tLoss: 0.313159\n",
      "Train Epoch: 1 [1000/15584 (6%)]\tLoss: 0.341729\n",
      "Train Epoch: 1 [2000/15584 (13%)]\tLoss: 0.262912\n",
      "Train Epoch: 1 [3000/15584 (19%)]\tLoss: 0.257944\n",
      "Train Epoch: 1 [4000/15584 (26%)]\tLoss: 0.213822\n",
      "Train Epoch: 1 [5000/15584 (32%)]\tLoss: 0.106301\n",
      "Train Epoch: 1 [6000/15584 (38%)]\tLoss: 0.176128\n",
      "Train Epoch: 1 [7000/15584 (45%)]\tLoss: 0.357952\n",
      "Train Epoch: 1 [8000/15584 (51%)]\tLoss: 0.231318\n",
      "Train Epoch: 1 [9000/15584 (58%)]\tLoss: 0.255046\n",
      "Train Epoch: 1 [10000/15584 (64%)]\tLoss: 0.167512\n",
      "Train Epoch: 1 [11000/15584 (71%)]\tLoss: 0.292580\n",
      "Train Epoch: 1 [12000/15584 (77%)]\tLoss: 0.242708\n",
      "Train Epoch: 1 [13000/15584 (83%)]\tLoss: 0.250153\n",
      "Train Epoch: 1 [14000/15584 (90%)]\tLoss: 0.126504\n",
      "Train Epoch: 1 [15000/15584 (96%)]\tLoss: 0.222748\n",
      "Train Epoch: 2 [0/15584 (0%)]\tLoss: 0.139660\n",
      "Train Epoch: 2 [1000/15584 (6%)]\tLoss: 0.224281\n",
      "Train Epoch: 2 [2000/15584 (13%)]\tLoss: 0.161261\n",
      "Train Epoch: 2 [3000/15584 (19%)]\tLoss: 0.124392\n",
      "Train Epoch: 2 [4000/15584 (26%)]\tLoss: 0.187576\n",
      "Train Epoch: 2 [5000/15584 (32%)]\tLoss: 0.308959\n",
      "Train Epoch: 2 [6000/15584 (38%)]\tLoss: 0.243461\n",
      "Train Epoch: 2 [7000/15584 (45%)]\tLoss: 0.202781\n",
      "Train Epoch: 2 [8000/15584 (51%)]\tLoss: 0.103923\n",
      "Train Epoch: 2 [9000/15584 (58%)]\tLoss: 0.156161\n",
      "Train Epoch: 2 [10000/15584 (64%)]\tLoss: 0.191560\n",
      "Train Epoch: 2 [11000/15584 (71%)]\tLoss: 0.263798\n",
      "Train Epoch: 2 [12000/15584 (77%)]\tLoss: 0.173935\n",
      "Train Epoch: 2 [13000/15584 (83%)]\tLoss: 0.279187\n",
      "Train Epoch: 2 [14000/15584 (90%)]\tLoss: 0.172106\n",
      "Train Epoch: 2 [15000/15584 (96%)]\tLoss: 0.137509\n",
      "Train Epoch: 3 [0/15584 (0%)]\tLoss: 0.209859\n",
      "Train Epoch: 3 [1000/15584 (6%)]\tLoss: 0.206104\n",
      "Train Epoch: 3 [2000/15584 (13%)]\tLoss: 0.185258\n",
      "Train Epoch: 3 [3000/15584 (19%)]\tLoss: 0.231746\n",
      "Train Epoch: 3 [4000/15584 (26%)]\tLoss: 0.262026\n",
      "Train Epoch: 3 [5000/15584 (32%)]\tLoss: 0.180650\n",
      "Train Epoch: 3 [6000/15584 (38%)]\tLoss: 0.180906\n",
      "Train Epoch: 3 [7000/15584 (45%)]\tLoss: 0.258667\n",
      "Train Epoch: 3 [8000/15584 (51%)]\tLoss: 0.210468\n",
      "Train Epoch: 3 [9000/15584 (58%)]\tLoss: 0.198461\n",
      "Train Epoch: 3 [10000/15584 (64%)]\tLoss: 0.115770\n",
      "Train Epoch: 3 [11000/15584 (71%)]\tLoss: 0.134963\n",
      "Train Epoch: 3 [12000/15584 (77%)]\tLoss: 0.206354\n",
      "Train Epoch: 3 [13000/15584 (83%)]\tLoss: 0.274226\n",
      "Train Epoch: 3 [14000/15584 (90%)]\tLoss: 0.289814\n",
      "Train Epoch: 3 [15000/15584 (96%)]\tLoss: 0.201997\n",
      "Train Epoch: 4 [0/15584 (0%)]\tLoss: 0.140765\n",
      "Train Epoch: 4 [1000/15584 (6%)]\tLoss: 0.158589\n",
      "Train Epoch: 4 [2000/15584 (13%)]\tLoss: 0.178971\n",
      "Train Epoch: 4 [3000/15584 (19%)]\tLoss: 0.231858\n",
      "Train Epoch: 4 [4000/15584 (26%)]\tLoss: 0.178792\n",
      "Train Epoch: 4 [5000/15584 (32%)]\tLoss: 0.119750\n",
      "Train Epoch: 4 [6000/15584 (38%)]\tLoss: 0.188817\n",
      "Train Epoch: 4 [7000/15584 (45%)]\tLoss: 0.305773\n",
      "Train Epoch: 4 [8000/15584 (51%)]\tLoss: 0.249073\n",
      "Train Epoch: 4 [9000/15584 (58%)]\tLoss: 0.221408\n",
      "Train Epoch: 4 [10000/15584 (64%)]\tLoss: 0.247693\n",
      "Train Epoch: 4 [11000/15584 (71%)]\tLoss: 0.148816\n",
      "Train Epoch: 4 [12000/15584 (77%)]\tLoss: 0.240408\n",
      "Train Epoch: 4 [13000/15584 (83%)]\tLoss: 0.218243\n",
      "Train Epoch: 4 [14000/15584 (90%)]\tLoss: 0.122016\n",
      "Train Epoch: 4 [15000/15584 (96%)]\tLoss: 0.179692\n",
      "Train Epoch: 5 [0/15584 (0%)]\tLoss: 0.212679\n",
      "Train Epoch: 5 [1000/15584 (6%)]\tLoss: 0.194043\n",
      "Train Epoch: 5 [2000/15584 (13%)]\tLoss: 0.116164\n",
      "Train Epoch: 5 [3000/15584 (19%)]\tLoss: 0.136529\n",
      "Train Epoch: 5 [4000/15584 (26%)]\tLoss: 0.152786\n",
      "Train Epoch: 5 [5000/15584 (32%)]\tLoss: 0.252646\n",
      "Train Epoch: 5 [6000/15584 (38%)]\tLoss: 0.219003\n",
      "Train Epoch: 5 [7000/15584 (45%)]\tLoss: 0.193838\n",
      "Train Epoch: 5 [8000/15584 (51%)]\tLoss: 0.243341\n",
      "Train Epoch: 5 [9000/15584 (58%)]\tLoss: 0.110377\n",
      "Train Epoch: 5 [10000/15584 (64%)]\tLoss: 0.097730\n",
      "Train Epoch: 5 [11000/15584 (71%)]\tLoss: 0.168554\n",
      "Train Epoch: 5 [12000/15584 (77%)]\tLoss: 0.280115\n",
      "Train Epoch: 5 [13000/15584 (83%)]\tLoss: 0.164055\n",
      "Train Epoch: 5 [14000/15584 (90%)]\tLoss: 0.250946\n",
      "Train Epoch: 5 [15000/15584 (96%)]\tLoss: 0.170665\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/12481 (0%)]\tLoss: 0.225784\n",
      "Train Epoch: 1 [1000/12481 (8%)]\tLoss: 0.154006\n",
      "Train Epoch: 1 [2000/12481 (16%)]\tLoss: 0.171615\n",
      "Train Epoch: 1 [3000/12481 (24%)]\tLoss: 0.259121\n",
      "Train Epoch: 1 [4000/12481 (32%)]\tLoss: 0.170253\n",
      "Train Epoch: 1 [5000/12481 (40%)]\tLoss: 0.172993\n",
      "Train Epoch: 1 [6000/12481 (48%)]\tLoss: 0.205436\n",
      "Train Epoch: 1 [7000/12481 (56%)]\tLoss: 0.276446\n",
      "Train Epoch: 1 [8000/12481 (64%)]\tLoss: 0.101618\n",
      "Train Epoch: 1 [9000/12481 (72%)]\tLoss: 0.140587\n",
      "Train Epoch: 1 [10000/12481 (80%)]\tLoss: 0.218879\n",
      "Train Epoch: 1 [11000/12481 (88%)]\tLoss: 0.115711\n",
      "Train Epoch: 1 [12000/12481 (96%)]\tLoss: 0.268728\n",
      "Train Epoch: 2 [0/12481 (0%)]\tLoss: 0.155979\n",
      "Train Epoch: 2 [1000/12481 (8%)]\tLoss: 0.137770\n",
      "Train Epoch: 2 [2000/12481 (16%)]\tLoss: 0.122511\n",
      "Train Epoch: 2 [3000/12481 (24%)]\tLoss: 0.183096\n",
      "Train Epoch: 2 [4000/12481 (32%)]\tLoss: 0.114579\n",
      "Train Epoch: 2 [5000/12481 (40%)]\tLoss: 0.115938\n",
      "Train Epoch: 2 [6000/12481 (48%)]\tLoss: 0.309215\n",
      "Train Epoch: 2 [7000/12481 (56%)]\tLoss: 0.111559\n",
      "Train Epoch: 2 [8000/12481 (64%)]\tLoss: 0.187512\n",
      "Train Epoch: 2 [9000/12481 (72%)]\tLoss: 0.165225\n",
      "Train Epoch: 2 [10000/12481 (80%)]\tLoss: 0.160995\n",
      "Train Epoch: 2 [11000/12481 (88%)]\tLoss: 0.256999\n",
      "Train Epoch: 2 [12000/12481 (96%)]\tLoss: 0.093993\n",
      "Train Epoch: 3 [0/12481 (0%)]\tLoss: 0.032745\n",
      "Train Epoch: 3 [1000/12481 (8%)]\tLoss: 0.139909\n",
      "Train Epoch: 3 [2000/12481 (16%)]\tLoss: 0.139886\n",
      "Train Epoch: 3 [3000/12481 (24%)]\tLoss: 0.050065\n",
      "Train Epoch: 3 [4000/12481 (32%)]\tLoss: 0.143632\n",
      "Train Epoch: 3 [5000/12481 (40%)]\tLoss: 0.167640\n",
      "Train Epoch: 3 [6000/12481 (48%)]\tLoss: 0.094927\n",
      "Train Epoch: 3 [7000/12481 (56%)]\tLoss: 0.169792\n",
      "Train Epoch: 3 [8000/12481 (64%)]\tLoss: 0.052737\n",
      "Train Epoch: 3 [9000/12481 (72%)]\tLoss: 0.087935\n",
      "Train Epoch: 3 [10000/12481 (80%)]\tLoss: 0.191591\n",
      "Train Epoch: 3 [11000/12481 (88%)]\tLoss: 0.101694\n",
      "Train Epoch: 3 [12000/12481 (96%)]\tLoss: 0.236075\n",
      "Train Epoch: 4 [0/12481 (0%)]\tLoss: 0.204579\n",
      "Train Epoch: 4 [1000/12481 (8%)]\tLoss: 0.264998\n",
      "Train Epoch: 4 [2000/12481 (16%)]\tLoss: 0.240722\n",
      "Train Epoch: 4 [3000/12481 (24%)]\tLoss: 0.180425\n",
      "Train Epoch: 4 [4000/12481 (32%)]\tLoss: 0.172145\n",
      "Train Epoch: 4 [5000/12481 (40%)]\tLoss: 0.142515\n",
      "Train Epoch: 4 [6000/12481 (48%)]\tLoss: 0.113130\n",
      "Train Epoch: 4 [7000/12481 (56%)]\tLoss: 0.219123\n",
      "Train Epoch: 4 [8000/12481 (64%)]\tLoss: 0.119993\n",
      "Train Epoch: 4 [9000/12481 (72%)]\tLoss: 0.249866\n",
      "Train Epoch: 4 [10000/12481 (80%)]\tLoss: 0.182845\n",
      "Train Epoch: 4 [11000/12481 (88%)]\tLoss: 0.128944\n",
      "Train Epoch: 4 [12000/12481 (96%)]\tLoss: 0.159208\n",
      "Train Epoch: 5 [0/12481 (0%)]\tLoss: 0.158431\n",
      "Train Epoch: 5 [1000/12481 (8%)]\tLoss: 0.202102\n",
      "Train Epoch: 5 [2000/12481 (16%)]\tLoss: 0.173847\n",
      "Train Epoch: 5 [3000/12481 (24%)]\tLoss: 0.180694\n",
      "Train Epoch: 5 [4000/12481 (32%)]\tLoss: 0.076113\n",
      "Train Epoch: 5 [5000/12481 (40%)]\tLoss: 0.321977\n",
      "Train Epoch: 5 [6000/12481 (48%)]\tLoss: 0.052331\n",
      "Train Epoch: 5 [7000/12481 (56%)]\tLoss: 0.133884\n",
      "Train Epoch: 5 [8000/12481 (64%)]\tLoss: 0.090931\n",
      "Train Epoch: 5 [9000/12481 (72%)]\tLoss: 0.097570\n",
      "Train Epoch: 5 [10000/12481 (80%)]\tLoss: 0.141015\n",
      "Train Epoch: 5 [11000/12481 (88%)]\tLoss: 0.162393\n",
      "Train Epoch: 5 [12000/12481 (96%)]\tLoss: 0.085129\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "4\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.7577, Accuracy: 8641/10000 (86%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/23974 (0%)]\tLoss: 0.256561\n",
      "Train Epoch: 1 [1000/23974 (4%)]\tLoss: 0.336509\n",
      "Train Epoch: 1 [2000/23974 (8%)]\tLoss: 0.371375\n",
      "Train Epoch: 1 [3000/23974 (12%)]\tLoss: 0.404707\n",
      "Train Epoch: 1 [4000/23974 (17%)]\tLoss: 0.312468\n",
      "Train Epoch: 1 [5000/23974 (21%)]\tLoss: 0.243690\n",
      "Train Epoch: 1 [6000/23974 (25%)]\tLoss: 0.135369\n",
      "Train Epoch: 1 [7000/23974 (29%)]\tLoss: 0.191464\n",
      "Train Epoch: 1 [8000/23974 (33%)]\tLoss: 0.235588\n",
      "Train Epoch: 1 [9000/23974 (38%)]\tLoss: 0.231715\n",
      "Train Epoch: 1 [10000/23974 (42%)]\tLoss: 0.188314\n",
      "Train Epoch: 1 [11000/23974 (46%)]\tLoss: 0.163904\n",
      "Train Epoch: 1 [12000/23974 (50%)]\tLoss: 0.190904\n",
      "Train Epoch: 1 [13000/23974 (54%)]\tLoss: 0.248890\n",
      "Train Epoch: 1 [14000/23974 (58%)]\tLoss: 0.437897\n",
      "Train Epoch: 1 [15000/23974 (62%)]\tLoss: 0.257074\n",
      "Train Epoch: 1 [16000/23974 (67%)]\tLoss: 0.295514\n",
      "Train Epoch: 1 [17000/23974 (71%)]\tLoss: 0.235231\n",
      "Train Epoch: 1 [18000/23974 (75%)]\tLoss: 0.303710\n",
      "Train Epoch: 1 [19000/23974 (79%)]\tLoss: 0.365112\n",
      "Train Epoch: 1 [20000/23974 (83%)]\tLoss: 0.150737\n",
      "Train Epoch: 1 [21000/23974 (88%)]\tLoss: 0.286037\n",
      "Train Epoch: 1 [22000/23974 (92%)]\tLoss: 0.307836\n",
      "Train Epoch: 1 [23000/23974 (96%)]\tLoss: 0.195043\n",
      "Train Epoch: 2 [0/23974 (0%)]\tLoss: 0.168718\n",
      "Train Epoch: 2 [1000/23974 (4%)]\tLoss: 0.234596\n",
      "Train Epoch: 2 [2000/23974 (8%)]\tLoss: 0.179126\n",
      "Train Epoch: 2 [3000/23974 (12%)]\tLoss: 0.182646\n",
      "Train Epoch: 2 [4000/23974 (17%)]\tLoss: 0.176515\n",
      "Train Epoch: 2 [5000/23974 (21%)]\tLoss: 0.279008\n",
      "Train Epoch: 2 [6000/23974 (25%)]\tLoss: 0.223250\n",
      "Train Epoch: 2 [7000/23974 (29%)]\tLoss: 0.409157\n",
      "Train Epoch: 2 [8000/23974 (33%)]\tLoss: 0.200357\n",
      "Train Epoch: 2 [9000/23974 (38%)]\tLoss: 0.120022\n",
      "Train Epoch: 2 [10000/23974 (42%)]\tLoss: 0.239497\n",
      "Train Epoch: 2 [11000/23974 (46%)]\tLoss: 0.226755\n",
      "Train Epoch: 2 [12000/23974 (50%)]\tLoss: 0.156077\n",
      "Train Epoch: 2 [13000/23974 (54%)]\tLoss: 0.336256\n",
      "Train Epoch: 2 [14000/23974 (58%)]\tLoss: 0.276343\n",
      "Train Epoch: 2 [15000/23974 (62%)]\tLoss: 0.115275\n",
      "Train Epoch: 2 [16000/23974 (67%)]\tLoss: 0.135887\n",
      "Train Epoch: 2 [17000/23974 (71%)]\tLoss: 0.160321\n",
      "Train Epoch: 2 [18000/23974 (75%)]\tLoss: 0.274389\n",
      "Train Epoch: 2 [19000/23974 (79%)]\tLoss: 0.203992\n",
      "Train Epoch: 2 [20000/23974 (83%)]\tLoss: 0.321517\n",
      "Train Epoch: 2 [21000/23974 (88%)]\tLoss: 0.295183\n",
      "Train Epoch: 2 [22000/23974 (92%)]\tLoss: 0.144300\n",
      "Train Epoch: 2 [23000/23974 (96%)]\tLoss: 0.215711\n",
      "Train Epoch: 3 [0/23974 (0%)]\tLoss: 0.177822\n",
      "Train Epoch: 3 [1000/23974 (4%)]\tLoss: 0.259460\n",
      "Train Epoch: 3 [2000/23974 (8%)]\tLoss: 0.308383\n",
      "Train Epoch: 3 [3000/23974 (12%)]\tLoss: 0.332004\n",
      "Train Epoch: 3 [4000/23974 (17%)]\tLoss: 0.211467\n",
      "Train Epoch: 3 [5000/23974 (21%)]\tLoss: 0.359498\n",
      "Train Epoch: 3 [6000/23974 (25%)]\tLoss: 0.177435\n",
      "Train Epoch: 3 [7000/23974 (29%)]\tLoss: 0.300295\n",
      "Train Epoch: 3 [8000/23974 (33%)]\tLoss: 0.211491\n",
      "Train Epoch: 3 [9000/23974 (38%)]\tLoss: 0.212529\n",
      "Train Epoch: 3 [10000/23974 (42%)]\tLoss: 0.138322\n",
      "Train Epoch: 3 [11000/23974 (46%)]\tLoss: 0.217393\n",
      "Train Epoch: 3 [12000/23974 (50%)]\tLoss: 0.318182\n",
      "Train Epoch: 3 [13000/23974 (54%)]\tLoss: 0.227122\n",
      "Train Epoch: 3 [14000/23974 (58%)]\tLoss: 0.131406\n",
      "Train Epoch: 3 [15000/23974 (62%)]\tLoss: 0.202604\n",
      "Train Epoch: 3 [16000/23974 (67%)]\tLoss: 0.314443\n",
      "Train Epoch: 3 [17000/23974 (71%)]\tLoss: 0.197749\n",
      "Train Epoch: 3 [18000/23974 (75%)]\tLoss: 0.285102\n",
      "Train Epoch: 3 [19000/23974 (79%)]\tLoss: 0.182574\n",
      "Train Epoch: 3 [20000/23974 (83%)]\tLoss: 0.145712\n",
      "Train Epoch: 3 [21000/23974 (88%)]\tLoss: 0.152243\n",
      "Train Epoch: 3 [22000/23974 (92%)]\tLoss: 0.196352\n",
      "Train Epoch: 3 [23000/23974 (96%)]\tLoss: 0.260177\n",
      "Train Epoch: 4 [0/23974 (0%)]\tLoss: 0.177898\n",
      "Train Epoch: 4 [1000/23974 (4%)]\tLoss: 0.259292\n",
      "Train Epoch: 4 [2000/23974 (8%)]\tLoss: 0.189115\n",
      "Train Epoch: 4 [3000/23974 (12%)]\tLoss: 0.164034\n",
      "Train Epoch: 4 [4000/23974 (17%)]\tLoss: 0.226367\n",
      "Train Epoch: 4 [5000/23974 (21%)]\tLoss: 0.146323\n",
      "Train Epoch: 4 [6000/23974 (25%)]\tLoss: 0.231833\n",
      "Train Epoch: 4 [7000/23974 (29%)]\tLoss: 0.233076\n",
      "Train Epoch: 4 [8000/23974 (33%)]\tLoss: 0.195634\n",
      "Train Epoch: 4 [9000/23974 (38%)]\tLoss: 0.213472\n",
      "Train Epoch: 4 [10000/23974 (42%)]\tLoss: 0.262947\n",
      "Train Epoch: 4 [11000/23974 (46%)]\tLoss: 0.274490\n",
      "Train Epoch: 4 [12000/23974 (50%)]\tLoss: 0.297928\n",
      "Train Epoch: 4 [13000/23974 (54%)]\tLoss: 0.156852\n",
      "Train Epoch: 4 [14000/23974 (58%)]\tLoss: 0.181945\n",
      "Train Epoch: 4 [15000/23974 (62%)]\tLoss: 0.225286\n",
      "Train Epoch: 4 [16000/23974 (67%)]\tLoss: 0.256361\n",
      "Train Epoch: 4 [17000/23974 (71%)]\tLoss: 0.204154\n",
      "Train Epoch: 4 [18000/23974 (75%)]\tLoss: 0.224669\n",
      "Train Epoch: 4 [19000/23974 (79%)]\tLoss: 0.134468\n",
      "Train Epoch: 4 [20000/23974 (83%)]\tLoss: 0.254476\n",
      "Train Epoch: 4 [21000/23974 (88%)]\tLoss: 0.176906\n",
      "Train Epoch: 4 [22000/23974 (92%)]\tLoss: 0.237336\n",
      "Train Epoch: 4 [23000/23974 (96%)]\tLoss: 0.113215\n",
      "Train Epoch: 5 [0/23974 (0%)]\tLoss: 0.201885\n",
      "Train Epoch: 5 [1000/23974 (4%)]\tLoss: 0.249021\n",
      "Train Epoch: 5 [2000/23974 (8%)]\tLoss: 0.339069\n",
      "Train Epoch: 5 [3000/23974 (12%)]\tLoss: 0.220116\n",
      "Train Epoch: 5 [4000/23974 (17%)]\tLoss: 0.232003\n",
      "Train Epoch: 5 [5000/23974 (21%)]\tLoss: 0.227017\n",
      "Train Epoch: 5 [6000/23974 (25%)]\tLoss: 0.265592\n",
      "Train Epoch: 5 [7000/23974 (29%)]\tLoss: 0.269432\n",
      "Train Epoch: 5 [8000/23974 (33%)]\tLoss: 0.174685\n",
      "Train Epoch: 5 [9000/23974 (38%)]\tLoss: 0.225095\n",
      "Train Epoch: 5 [10000/23974 (42%)]\tLoss: 0.303084\n",
      "Train Epoch: 5 [11000/23974 (46%)]\tLoss: 0.199652\n",
      "Train Epoch: 5 [12000/23974 (50%)]\tLoss: 0.248991\n",
      "Train Epoch: 5 [13000/23974 (54%)]\tLoss: 0.331415\n",
      "Train Epoch: 5 [14000/23974 (58%)]\tLoss: 0.258893\n",
      "Train Epoch: 5 [15000/23974 (62%)]\tLoss: 0.156502\n",
      "Train Epoch: 5 [16000/23974 (67%)]\tLoss: 0.245301\n",
      "Train Epoch: 5 [17000/23974 (71%)]\tLoss: 0.143192\n",
      "Train Epoch: 5 [18000/23974 (75%)]\tLoss: 0.173794\n",
      "Train Epoch: 5 [19000/23974 (79%)]\tLoss: 0.241836\n",
      "Train Epoch: 5 [20000/23974 (83%)]\tLoss: 0.140899\n",
      "Train Epoch: 5 [21000/23974 (88%)]\tLoss: 0.193769\n",
      "Train Epoch: 5 [22000/23974 (92%)]\tLoss: 0.225491\n",
      "Train Epoch: 5 [23000/23974 (96%)]\tLoss: 0.146708\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7961 (0%)]\tLoss: 0.437543\n",
      "Train Epoch: 1 [1000/7961 (12%)]\tLoss: 0.256370\n",
      "Train Epoch: 1 [2000/7961 (25%)]\tLoss: 0.283253\n",
      "Train Epoch: 1 [3000/7961 (38%)]\tLoss: 0.224296\n",
      "Train Epoch: 1 [4000/7961 (50%)]\tLoss: 0.237979\n",
      "Train Epoch: 1 [5000/7961 (62%)]\tLoss: 0.314269\n",
      "Train Epoch: 1 [6000/7961 (75%)]\tLoss: 0.231909\n",
      "Train Epoch: 1 [7000/7961 (88%)]\tLoss: 0.358328\n",
      "Train Epoch: 2 [0/7961 (0%)]\tLoss: 0.375901\n",
      "Train Epoch: 2 [1000/7961 (12%)]\tLoss: 0.234887\n",
      "Train Epoch: 2 [2000/7961 (25%)]\tLoss: 0.348649\n",
      "Train Epoch: 2 [3000/7961 (38%)]\tLoss: 0.200154\n",
      "Train Epoch: 2 [4000/7961 (50%)]\tLoss: 0.204893\n",
      "Train Epoch: 2 [5000/7961 (62%)]\tLoss: 0.269996\n",
      "Train Epoch: 2 [6000/7961 (75%)]\tLoss: 0.372983\n",
      "Train Epoch: 2 [7000/7961 (88%)]\tLoss: 0.302659\n",
      "Train Epoch: 3 [0/7961 (0%)]\tLoss: 0.190461\n",
      "Train Epoch: 3 [1000/7961 (12%)]\tLoss: 0.391319\n",
      "Train Epoch: 3 [2000/7961 (25%)]\tLoss: 0.253874\n",
      "Train Epoch: 3 [3000/7961 (38%)]\tLoss: 0.291235\n",
      "Train Epoch: 3 [4000/7961 (50%)]\tLoss: 0.405149\n",
      "Train Epoch: 3 [5000/7961 (62%)]\tLoss: 0.364225\n",
      "Train Epoch: 3 [6000/7961 (75%)]\tLoss: 0.323230\n",
      "Train Epoch: 3 [7000/7961 (88%)]\tLoss: 0.199870\n",
      "Train Epoch: 4 [0/7961 (0%)]\tLoss: 0.291286\n",
      "Train Epoch: 4 [1000/7961 (12%)]\tLoss: 0.441366\n",
      "Train Epoch: 4 [2000/7961 (25%)]\tLoss: 0.276694\n",
      "Train Epoch: 4 [3000/7961 (38%)]\tLoss: 0.337373\n",
      "Train Epoch: 4 [4000/7961 (50%)]\tLoss: 0.254955\n",
      "Train Epoch: 4 [5000/7961 (62%)]\tLoss: 0.456168\n",
      "Train Epoch: 4 [6000/7961 (75%)]\tLoss: 0.223242\n",
      "Train Epoch: 4 [7000/7961 (88%)]\tLoss: 0.174043\n",
      "Train Epoch: 5 [0/7961 (0%)]\tLoss: 0.204577\n",
      "Train Epoch: 5 [1000/7961 (12%)]\tLoss: 0.225964\n",
      "Train Epoch: 5 [2000/7961 (25%)]\tLoss: 0.414945\n",
      "Train Epoch: 5 [3000/7961 (38%)]\tLoss: 0.199511\n",
      "Train Epoch: 5 [4000/7961 (50%)]\tLoss: 0.375025\n",
      "Train Epoch: 5 [5000/7961 (62%)]\tLoss: 0.372613\n",
      "Train Epoch: 5 [6000/7961 (75%)]\tLoss: 0.278102\n",
      "Train Epoch: 5 [7000/7961 (88%)]\tLoss: 0.265546\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/15584 (0%)]\tLoss: 0.209564\n",
      "Train Epoch: 1 [1000/15584 (6%)]\tLoss: 0.187658\n",
      "Train Epoch: 1 [2000/15584 (13%)]\tLoss: 0.248818\n",
      "Train Epoch: 1 [3000/15584 (19%)]\tLoss: 0.255967\n",
      "Train Epoch: 1 [4000/15584 (26%)]\tLoss: 0.204097\n",
      "Train Epoch: 1 [5000/15584 (32%)]\tLoss: 0.243660\n",
      "Train Epoch: 1 [6000/15584 (38%)]\tLoss: 0.292059\n",
      "Train Epoch: 1 [7000/15584 (45%)]\tLoss: 0.211248\n",
      "Train Epoch: 1 [8000/15584 (51%)]\tLoss: 0.206615\n",
      "Train Epoch: 1 [9000/15584 (58%)]\tLoss: 0.227123\n",
      "Train Epoch: 1 [10000/15584 (64%)]\tLoss: 0.268842\n",
      "Train Epoch: 1 [11000/15584 (71%)]\tLoss: 0.220995\n",
      "Train Epoch: 1 [12000/15584 (77%)]\tLoss: 0.304098\n",
      "Train Epoch: 1 [13000/15584 (83%)]\tLoss: 0.232661\n",
      "Train Epoch: 1 [14000/15584 (90%)]\tLoss: 0.236140\n",
      "Train Epoch: 1 [15000/15584 (96%)]\tLoss: 0.280121\n",
      "Train Epoch: 2 [0/15584 (0%)]\tLoss: 0.180554\n",
      "Train Epoch: 2 [1000/15584 (6%)]\tLoss: 0.148981\n",
      "Train Epoch: 2 [2000/15584 (13%)]\tLoss: 0.134707\n",
      "Train Epoch: 2 [3000/15584 (19%)]\tLoss: 0.185682\n",
      "Train Epoch: 2 [4000/15584 (26%)]\tLoss: 0.192534\n",
      "Train Epoch: 2 [5000/15584 (32%)]\tLoss: 0.305850\n",
      "Train Epoch: 2 [6000/15584 (38%)]\tLoss: 0.186616\n",
      "Train Epoch: 2 [7000/15584 (45%)]\tLoss: 0.352951\n",
      "Train Epoch: 2 [8000/15584 (51%)]\tLoss: 0.226195\n",
      "Train Epoch: 2 [9000/15584 (58%)]\tLoss: 0.138389\n",
      "Train Epoch: 2 [10000/15584 (64%)]\tLoss: 0.214756\n",
      "Train Epoch: 2 [11000/15584 (71%)]\tLoss: 0.103750\n",
      "Train Epoch: 2 [12000/15584 (77%)]\tLoss: 0.156885\n",
      "Train Epoch: 2 [13000/15584 (83%)]\tLoss: 0.276559\n",
      "Train Epoch: 2 [14000/15584 (90%)]\tLoss: 0.268374\n",
      "Train Epoch: 2 [15000/15584 (96%)]\tLoss: 0.149787\n",
      "Train Epoch: 3 [0/15584 (0%)]\tLoss: 0.221054\n",
      "Train Epoch: 3 [1000/15584 (6%)]\tLoss: 0.171797\n",
      "Train Epoch: 3 [2000/15584 (13%)]\tLoss: 0.167396\n",
      "Train Epoch: 3 [3000/15584 (19%)]\tLoss: 0.244884\n",
      "Train Epoch: 3 [4000/15584 (26%)]\tLoss: 0.201052\n",
      "Train Epoch: 3 [5000/15584 (32%)]\tLoss: 0.106840\n",
      "Train Epoch: 3 [6000/15584 (38%)]\tLoss: 0.119144\n",
      "Train Epoch: 3 [7000/15584 (45%)]\tLoss: 0.298185\n",
      "Train Epoch: 3 [8000/15584 (51%)]\tLoss: 0.243805\n",
      "Train Epoch: 3 [9000/15584 (58%)]\tLoss: 0.236858\n",
      "Train Epoch: 3 [10000/15584 (64%)]\tLoss: 0.170197\n",
      "Train Epoch: 3 [11000/15584 (71%)]\tLoss: 0.246426\n",
      "Train Epoch: 3 [12000/15584 (77%)]\tLoss: 0.343769\n",
      "Train Epoch: 3 [13000/15584 (83%)]\tLoss: 0.175300\n",
      "Train Epoch: 3 [14000/15584 (90%)]\tLoss: 0.289797\n",
      "Train Epoch: 3 [15000/15584 (96%)]\tLoss: 0.227260\n",
      "Train Epoch: 4 [0/15584 (0%)]\tLoss: 0.164655\n",
      "Train Epoch: 4 [1000/15584 (6%)]\tLoss: 0.169618\n",
      "Train Epoch: 4 [2000/15584 (13%)]\tLoss: 0.227921\n",
      "Train Epoch: 4 [3000/15584 (19%)]\tLoss: 0.217863\n",
      "Train Epoch: 4 [4000/15584 (26%)]\tLoss: 0.344280\n",
      "Train Epoch: 4 [5000/15584 (32%)]\tLoss: 0.313869\n",
      "Train Epoch: 4 [6000/15584 (38%)]\tLoss: 0.185124\n",
      "Train Epoch: 4 [7000/15584 (45%)]\tLoss: 0.206091\n",
      "Train Epoch: 4 [8000/15584 (51%)]\tLoss: 0.178970\n",
      "Train Epoch: 4 [9000/15584 (58%)]\tLoss: 0.209410\n",
      "Train Epoch: 4 [10000/15584 (64%)]\tLoss: 0.226632\n",
      "Train Epoch: 4 [11000/15584 (71%)]\tLoss: 0.151607\n",
      "Train Epoch: 4 [12000/15584 (77%)]\tLoss: 0.158687\n",
      "Train Epoch: 4 [13000/15584 (83%)]\tLoss: 0.137845\n",
      "Train Epoch: 4 [14000/15584 (90%)]\tLoss: 0.288316\n",
      "Train Epoch: 4 [15000/15584 (96%)]\tLoss: 0.175257\n",
      "Train Epoch: 5 [0/15584 (0%)]\tLoss: 0.160315\n",
      "Train Epoch: 5 [1000/15584 (6%)]\tLoss: 0.166472\n",
      "Train Epoch: 5 [2000/15584 (13%)]\tLoss: 0.211634\n",
      "Train Epoch: 5 [3000/15584 (19%)]\tLoss: 0.158084\n",
      "Train Epoch: 5 [4000/15584 (26%)]\tLoss: 0.202397\n",
      "Train Epoch: 5 [5000/15584 (32%)]\tLoss: 0.147962\n",
      "Train Epoch: 5 [6000/15584 (38%)]\tLoss: 0.118632\n",
      "Train Epoch: 5 [7000/15584 (45%)]\tLoss: 0.163255\n",
      "Train Epoch: 5 [8000/15584 (51%)]\tLoss: 0.169123\n",
      "Train Epoch: 5 [9000/15584 (58%)]\tLoss: 0.175292\n",
      "Train Epoch: 5 [10000/15584 (64%)]\tLoss: 0.214384\n",
      "Train Epoch: 5 [11000/15584 (71%)]\tLoss: 0.183275\n",
      "Train Epoch: 5 [12000/15584 (77%)]\tLoss: 0.183303\n",
      "Train Epoch: 5 [13000/15584 (83%)]\tLoss: 0.185610\n",
      "Train Epoch: 5 [14000/15584 (90%)]\tLoss: 0.172014\n",
      "Train Epoch: 5 [15000/15584 (96%)]\tLoss: 0.183587\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/12481 (0%)]\tLoss: 0.137948\n",
      "Train Epoch: 1 [1000/12481 (8%)]\tLoss: 0.139700\n",
      "Train Epoch: 1 [2000/12481 (16%)]\tLoss: 0.192048\n",
      "Train Epoch: 1 [3000/12481 (24%)]\tLoss: 0.160769\n",
      "Train Epoch: 1 [4000/12481 (32%)]\tLoss: 0.127953\n",
      "Train Epoch: 1 [5000/12481 (40%)]\tLoss: 0.141275\n",
      "Train Epoch: 1 [6000/12481 (48%)]\tLoss: 0.124602\n",
      "Train Epoch: 1 [7000/12481 (56%)]\tLoss: 0.173355\n",
      "Train Epoch: 1 [8000/12481 (64%)]\tLoss: 0.219183\n",
      "Train Epoch: 1 [9000/12481 (72%)]\tLoss: 0.217870\n",
      "Train Epoch: 1 [10000/12481 (80%)]\tLoss: 0.175756\n",
      "Train Epoch: 1 [11000/12481 (88%)]\tLoss: 0.154732\n",
      "Train Epoch: 1 [12000/12481 (96%)]\tLoss: 0.211218\n",
      "Train Epoch: 2 [0/12481 (0%)]\tLoss: 0.101833\n",
      "Train Epoch: 2 [1000/12481 (8%)]\tLoss: 0.222133\n",
      "Train Epoch: 2 [2000/12481 (16%)]\tLoss: 0.102827\n",
      "Train Epoch: 2 [3000/12481 (24%)]\tLoss: 0.138993\n",
      "Train Epoch: 2 [4000/12481 (32%)]\tLoss: 0.106939\n",
      "Train Epoch: 2 [5000/12481 (40%)]\tLoss: 0.160502\n",
      "Train Epoch: 2 [6000/12481 (48%)]\tLoss: 0.178587\n",
      "Train Epoch: 2 [7000/12481 (56%)]\tLoss: 0.058838\n",
      "Train Epoch: 2 [8000/12481 (64%)]\tLoss: 0.288274\n",
      "Train Epoch: 2 [9000/12481 (72%)]\tLoss: 0.147639\n",
      "Train Epoch: 2 [10000/12481 (80%)]\tLoss: 0.196852\n",
      "Train Epoch: 2 [11000/12481 (88%)]\tLoss: 0.180571\n",
      "Train Epoch: 2 [12000/12481 (96%)]\tLoss: 0.225460\n",
      "Train Epoch: 3 [0/12481 (0%)]\tLoss: 0.148793\n",
      "Train Epoch: 3 [1000/12481 (8%)]\tLoss: 0.164667\n",
      "Train Epoch: 3 [2000/12481 (16%)]\tLoss: 0.192346\n",
      "Train Epoch: 3 [3000/12481 (24%)]\tLoss: 0.268514\n",
      "Train Epoch: 3 [4000/12481 (32%)]\tLoss: 0.103226\n",
      "Train Epoch: 3 [5000/12481 (40%)]\tLoss: 0.168786\n",
      "Train Epoch: 3 [6000/12481 (48%)]\tLoss: 0.128670\n",
      "Train Epoch: 3 [7000/12481 (56%)]\tLoss: 0.132114\n",
      "Train Epoch: 3 [8000/12481 (64%)]\tLoss: 0.122186\n",
      "Train Epoch: 3 [9000/12481 (72%)]\tLoss: 0.097055\n",
      "Train Epoch: 3 [10000/12481 (80%)]\tLoss: 0.106312\n",
      "Train Epoch: 3 [11000/12481 (88%)]\tLoss: 0.122521\n",
      "Train Epoch: 3 [12000/12481 (96%)]\tLoss: 0.090221\n",
      "Train Epoch: 4 [0/12481 (0%)]\tLoss: 0.108986\n",
      "Train Epoch: 4 [1000/12481 (8%)]\tLoss: 0.110621\n",
      "Train Epoch: 4 [2000/12481 (16%)]\tLoss: 0.203184\n",
      "Train Epoch: 4 [3000/12481 (24%)]\tLoss: 0.146627\n",
      "Train Epoch: 4 [4000/12481 (32%)]\tLoss: 0.129179\n",
      "Train Epoch: 4 [5000/12481 (40%)]\tLoss: 0.142567\n",
      "Train Epoch: 4 [6000/12481 (48%)]\tLoss: 0.121284\n",
      "Train Epoch: 4 [7000/12481 (56%)]\tLoss: 0.104790\n",
      "Train Epoch: 4 [8000/12481 (64%)]\tLoss: 0.146589\n",
      "Train Epoch: 4 [9000/12481 (72%)]\tLoss: 0.093916\n",
      "Train Epoch: 4 [10000/12481 (80%)]\tLoss: 0.191048\n",
      "Train Epoch: 4 [11000/12481 (88%)]\tLoss: 0.241686\n",
      "Train Epoch: 4 [12000/12481 (96%)]\tLoss: 0.184135\n",
      "Train Epoch: 5 [0/12481 (0%)]\tLoss: 0.115623\n",
      "Train Epoch: 5 [1000/12481 (8%)]\tLoss: 0.162258\n",
      "Train Epoch: 5 [2000/12481 (16%)]\tLoss: 0.161994\n",
      "Train Epoch: 5 [3000/12481 (24%)]\tLoss: 0.145619\n",
      "Train Epoch: 5 [4000/12481 (32%)]\tLoss: 0.123899\n",
      "Train Epoch: 5 [5000/12481 (40%)]\tLoss: 0.131064\n",
      "Train Epoch: 5 [6000/12481 (48%)]\tLoss: 0.134091\n",
      "Train Epoch: 5 [7000/12481 (56%)]\tLoss: 0.062061\n",
      "Train Epoch: 5 [8000/12481 (64%)]\tLoss: 0.067807\n",
      "Train Epoch: 5 [9000/12481 (72%)]\tLoss: 0.154398\n",
      "Train Epoch: 5 [10000/12481 (80%)]\tLoss: 0.149559\n",
      "Train Epoch: 5 [11000/12481 (88%)]\tLoss: 0.129205\n",
      "Train Epoch: 5 [12000/12481 (96%)]\tLoss: 0.112810\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "4\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.7454, Accuracy: 8566/10000 (86%)\n",
      "\n",
      "Running experiment with 6 partitions...\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.225897\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 0.242969\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 0.287013\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 0.341300\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 0.227292\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 0.266186\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 0.239580\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 0.423355\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.347066\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 0.260021\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.297227\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 0.193890\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.268734\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 0.259110\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 0.187053\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.281163\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.239802\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 0.202710\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 0.292333\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 0.247319\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.322586\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 0.257945\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.250598\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 0.213660\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.207533\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.258063\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.347732\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 0.365895\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.260506\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 0.253227\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.297514\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 0.198108\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.318358\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 0.233876\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.316443\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.207840\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.431157\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 0.199918\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.297016\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 0.285603\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.328884\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 0.175773\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.300146\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 0.232958\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.258631\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.119565\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.358447\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 0.155930\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.143246\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 0.150688\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.255781\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 0.205437\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.259090\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 0.338076\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.270265\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.155040\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.291615\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 0.299264\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.344775\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 0.335041\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.327184\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 0.226683\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.223860\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 0.249379\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.210871\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.307405\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.163199\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 0.415742\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.300621\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 0.208656\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.198141\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 0.280870\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.346597\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 0.266705\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.269202\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.219615\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.264476\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 0.248994\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.336440\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 0.303481\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.207011\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 0.161317\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.181468\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 0.251464\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.331028\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.289619\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.182316\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 0.173528\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.342533\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 0.211884\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.196378\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 0.270591\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.289719\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 0.242036\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.230352\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.142908\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.258598\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 0.189865\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.293121\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 0.219626\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.175442\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 0.392620\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.214120\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 0.306460\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.217648\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.222819\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.195875\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 0.190084\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.270207\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 0.316093\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.253060\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 0.220768\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.138782\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 0.284904\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.296709\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.255165\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.161821\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 0.258090\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.342143\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 0.331074\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.271295\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 0.257912\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.366542\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 0.221775\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.297023\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.266486\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.187915\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 0.162395\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.222953\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 0.174448\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.239063\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 0.311644\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.187917\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 0.232545\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.266405\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.265284\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.229417\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 0.347884\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.245908\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 0.272826\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.263827\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 0.291039\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.190088\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 0.297052\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.315094\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.233641\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.263071\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 0.249980\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.216320\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 0.240327\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.302490\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 0.296988\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.267265\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 0.366116\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.295337\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.144693\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.220486\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 0.261947\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.219916\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 0.233100\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.132101\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 0.289221\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.296825\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 0.309397\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.167850\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.241680\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.200949\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 0.348533\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.316528\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 0.304000\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.126161\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 0.149255\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.223325\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 0.299258\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.253439\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.309249\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.214539\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 0.296871\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.176368\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 0.229717\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.216617\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 0.111689\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.323421\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 0.206082\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.264628\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.228223\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.269641\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 0.291224\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.320044\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 0.169471\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.313190\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 0.214240\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.224647\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 0.182637\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.441906\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.219369\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.232661\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 0.257739\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.235657\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 0.252730\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.234492\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 0.171867\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.304498\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 0.189096\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.323015\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.227608\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.183394\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 0.288215\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.216472\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 0.241911\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.358705\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 0.256431\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.285583\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 0.234671\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.270383\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.420353\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.181852\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 0.346277\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.197643\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 0.354930\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.221659\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 0.228661\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.271822\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 0.285348\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.346360\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.285913\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.314546\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 0.239639\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.274850\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 0.193504\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.191413\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 0.168195\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.224925\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 0.244694\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.156637\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.194545\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.220408\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 0.194848\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.267806\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 0.261058\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.294414\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 0.238913\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.235398\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 0.273792\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.292928\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.228687\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.294686\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 0.238527\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.231346\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 0.125057\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.158601\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 0.262035\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.263133\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 0.272672\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.163061\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.217348\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.251028\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 0.244223\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.228393\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 0.213991\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.400793\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 0.226534\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.218307\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 0.167719\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.216208\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.227977\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.257414\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 0.190313\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.159248\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 0.160320\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.371276\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 0.231228\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.226210\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 0.148142\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.222805\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.373737\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.140503\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 0.303209\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.214608\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 0.195379\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.227539\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 0.252616\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.264135\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 0.168287\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.202808\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.323496\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.249417\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 0.294884\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.239069\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 0.258675\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.207639\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 0.188924\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.168221\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 0.344783\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.178914\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.228285\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.289866\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 0.322988\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.228693\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 0.234232\n",
      "\n",
      "Test set: Avg. loss: 0.2373, Accuracy: 54681/60000 (91%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/8440 (0%)]\tLoss: 0.365869\n",
      "Train Epoch: 1 [1000/8440 (12%)]\tLoss: 0.244058\n",
      "Train Epoch: 1 [2000/8440 (24%)]\tLoss: 0.334181\n",
      "Train Epoch: 1 [3000/8440 (35%)]\tLoss: 0.213297\n",
      "Train Epoch: 1 [4000/8440 (47%)]\tLoss: 0.243583\n",
      "Train Epoch: 1 [5000/8440 (59%)]\tLoss: 0.321682\n",
      "Train Epoch: 1 [6000/8440 (71%)]\tLoss: 0.293520\n",
      "Train Epoch: 1 [7000/8440 (82%)]\tLoss: 0.229633\n",
      "Train Epoch: 1 [8000/8440 (94%)]\tLoss: 0.430917\n",
      "Train Epoch: 2 [0/8440 (0%)]\tLoss: 0.147316\n",
      "Train Epoch: 2 [1000/8440 (12%)]\tLoss: 0.292955\n",
      "Train Epoch: 2 [2000/8440 (24%)]\tLoss: 0.305859\n",
      "Train Epoch: 2 [3000/8440 (35%)]\tLoss: 0.238098\n",
      "Train Epoch: 2 [4000/8440 (47%)]\tLoss: 0.178295\n",
      "Train Epoch: 2 [5000/8440 (59%)]\tLoss: 0.221324\n",
      "Train Epoch: 2 [6000/8440 (71%)]\tLoss: 0.306184\n",
      "Train Epoch: 2 [7000/8440 (82%)]\tLoss: 0.266435\n",
      "Train Epoch: 2 [8000/8440 (94%)]\tLoss: 0.320705\n",
      "Train Epoch: 3 [0/8440 (0%)]\tLoss: 0.235829\n",
      "Train Epoch: 3 [1000/8440 (12%)]\tLoss: 0.225074\n",
      "Train Epoch: 3 [2000/8440 (24%)]\tLoss: 0.308134\n",
      "Train Epoch: 3 [3000/8440 (35%)]\tLoss: 0.195261\n",
      "Train Epoch: 3 [4000/8440 (47%)]\tLoss: 0.218021\n",
      "Train Epoch: 3 [5000/8440 (59%)]\tLoss: 0.192606\n",
      "Train Epoch: 3 [6000/8440 (71%)]\tLoss: 0.363895\n",
      "Train Epoch: 3 [7000/8440 (82%)]\tLoss: 0.133947\n",
      "Train Epoch: 3 [8000/8440 (94%)]\tLoss: 0.291441\n",
      "Train Epoch: 4 [0/8440 (0%)]\tLoss: 0.189042\n",
      "Train Epoch: 4 [1000/8440 (12%)]\tLoss: 0.220752\n",
      "Train Epoch: 4 [2000/8440 (24%)]\tLoss: 0.260621\n",
      "Train Epoch: 4 [3000/8440 (35%)]\tLoss: 0.199769\n",
      "Train Epoch: 4 [4000/8440 (47%)]\tLoss: 0.187475\n",
      "Train Epoch: 4 [5000/8440 (59%)]\tLoss: 0.268521\n",
      "Train Epoch: 4 [6000/8440 (71%)]\tLoss: 0.277111\n",
      "Train Epoch: 4 [7000/8440 (82%)]\tLoss: 0.272962\n",
      "Train Epoch: 4 [8000/8440 (94%)]\tLoss: 0.248692\n",
      "Train Epoch: 5 [0/8440 (0%)]\tLoss: 0.213604\n",
      "Train Epoch: 5 [1000/8440 (12%)]\tLoss: 0.222853\n",
      "Train Epoch: 5 [2000/8440 (24%)]\tLoss: 0.277613\n",
      "Train Epoch: 5 [3000/8440 (35%)]\tLoss: 0.230072\n",
      "Train Epoch: 5 [4000/8440 (47%)]\tLoss: 0.237103\n",
      "Train Epoch: 5 [5000/8440 (59%)]\tLoss: 0.187478\n",
      "Train Epoch: 5 [6000/8440 (71%)]\tLoss: 0.243212\n",
      "Train Epoch: 5 [7000/8440 (82%)]\tLoss: 0.286758\n",
      "Train Epoch: 5 [8000/8440 (94%)]\tLoss: 0.150264\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11811 (0%)]\tLoss: 0.159158\n",
      "Train Epoch: 1 [1000/11811 (8%)]\tLoss: 0.067895\n",
      "Train Epoch: 1 [2000/11811 (17%)]\tLoss: 0.143790\n",
      "Train Epoch: 1 [3000/11811 (25%)]\tLoss: 0.125341\n",
      "Train Epoch: 1 [4000/11811 (34%)]\tLoss: 0.105821\n",
      "Train Epoch: 1 [5000/11811 (42%)]\tLoss: 0.122466\n",
      "Train Epoch: 1 [6000/11811 (50%)]\tLoss: 0.031113\n",
      "Train Epoch: 1 [7000/11811 (59%)]\tLoss: 0.063269\n",
      "Train Epoch: 1 [8000/11811 (67%)]\tLoss: 0.117146\n",
      "Train Epoch: 1 [9000/11811 (76%)]\tLoss: 0.072497\n",
      "Train Epoch: 1 [10000/11811 (84%)]\tLoss: 0.075763\n",
      "Train Epoch: 1 [11000/11811 (92%)]\tLoss: 0.043894\n",
      "Train Epoch: 2 [0/11811 (0%)]\tLoss: 0.102456\n",
      "Train Epoch: 2 [1000/11811 (8%)]\tLoss: 0.047059\n",
      "Train Epoch: 2 [2000/11811 (17%)]\tLoss: 0.096797\n",
      "Train Epoch: 2 [3000/11811 (25%)]\tLoss: 0.094200\n",
      "Train Epoch: 2 [4000/11811 (34%)]\tLoss: 0.116773\n",
      "Train Epoch: 2 [5000/11811 (42%)]\tLoss: 0.184100\n",
      "Train Epoch: 2 [6000/11811 (50%)]\tLoss: 0.053946\n",
      "Train Epoch: 2 [7000/11811 (59%)]\tLoss: 0.102260\n",
      "Train Epoch: 2 [8000/11811 (67%)]\tLoss: 0.129319\n",
      "Train Epoch: 2 [9000/11811 (76%)]\tLoss: 0.356707\n",
      "Train Epoch: 2 [10000/11811 (84%)]\tLoss: 0.084191\n",
      "Train Epoch: 2 [11000/11811 (92%)]\tLoss: 0.160736\n",
      "Train Epoch: 3 [0/11811 (0%)]\tLoss: 0.103522\n",
      "Train Epoch: 3 [1000/11811 (8%)]\tLoss: 0.102059\n",
      "Train Epoch: 3 [2000/11811 (17%)]\tLoss: 0.092564\n",
      "Train Epoch: 3 [3000/11811 (25%)]\tLoss: 0.074302\n",
      "Train Epoch: 3 [4000/11811 (34%)]\tLoss: 0.056542\n",
      "Train Epoch: 3 [5000/11811 (42%)]\tLoss: 0.058205\n",
      "Train Epoch: 3 [6000/11811 (50%)]\tLoss: 0.070198\n",
      "Train Epoch: 3 [7000/11811 (59%)]\tLoss: 0.155196\n",
      "Train Epoch: 3 [8000/11811 (67%)]\tLoss: 0.039908\n",
      "Train Epoch: 3 [9000/11811 (76%)]\tLoss: 0.088914\n",
      "Train Epoch: 3 [10000/11811 (84%)]\tLoss: 0.048152\n",
      "Train Epoch: 3 [11000/11811 (92%)]\tLoss: 0.075514\n",
      "Train Epoch: 4 [0/11811 (0%)]\tLoss: 0.155343\n",
      "Train Epoch: 4 [1000/11811 (8%)]\tLoss: 0.092358\n",
      "Train Epoch: 4 [2000/11811 (17%)]\tLoss: 0.101873\n",
      "Train Epoch: 4 [3000/11811 (25%)]\tLoss: 0.119829\n",
      "Train Epoch: 4 [4000/11811 (34%)]\tLoss: 0.117030\n",
      "Train Epoch: 4 [5000/11811 (42%)]\tLoss: 0.150890\n",
      "Train Epoch: 4 [6000/11811 (50%)]\tLoss: 0.111103\n",
      "Train Epoch: 4 [7000/11811 (59%)]\tLoss: 0.142245\n",
      "Train Epoch: 4 [8000/11811 (67%)]\tLoss: 0.180593\n",
      "Train Epoch: 4 [9000/11811 (76%)]\tLoss: 0.133295\n",
      "Train Epoch: 4 [10000/11811 (84%)]\tLoss: 0.046041\n",
      "Train Epoch: 4 [11000/11811 (92%)]\tLoss: 0.039252\n",
      "Train Epoch: 5 [0/11811 (0%)]\tLoss: 0.174566\n",
      "Train Epoch: 5 [1000/11811 (8%)]\tLoss: 0.063952\n",
      "Train Epoch: 5 [2000/11811 (17%)]\tLoss: 0.124296\n",
      "Train Epoch: 5 [3000/11811 (25%)]\tLoss: 0.064916\n",
      "Train Epoch: 5 [4000/11811 (34%)]\tLoss: 0.045916\n",
      "Train Epoch: 5 [5000/11811 (42%)]\tLoss: 0.137614\n",
      "Train Epoch: 5 [6000/11811 (50%)]\tLoss: 0.169475\n",
      "Train Epoch: 5 [7000/11811 (59%)]\tLoss: 0.103593\n",
      "Train Epoch: 5 [8000/11811 (67%)]\tLoss: 0.136889\n",
      "Train Epoch: 5 [9000/11811 (76%)]\tLoss: 0.115025\n",
      "Train Epoch: 5 [10000/11811 (84%)]\tLoss: 0.082474\n",
      "Train Epoch: 5 [11000/11811 (92%)]\tLoss: 0.056153\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/9726 (0%)]\tLoss: 0.208383\n",
      "Train Epoch: 1 [1000/9726 (10%)]\tLoss: 0.226179\n",
      "Train Epoch: 1 [2000/9726 (20%)]\tLoss: 0.091564\n",
      "Train Epoch: 1 [3000/9726 (31%)]\tLoss: 0.151106\n",
      "Train Epoch: 1 [4000/9726 (41%)]\tLoss: 0.264870\n",
      "Train Epoch: 1 [5000/9726 (51%)]\tLoss: 0.222390\n",
      "Train Epoch: 1 [6000/9726 (61%)]\tLoss: 0.156013\n",
      "Train Epoch: 1 [7000/9726 (71%)]\tLoss: 0.279576\n",
      "Train Epoch: 1 [8000/9726 (82%)]\tLoss: 0.256837\n",
      "Train Epoch: 1 [9000/9726 (92%)]\tLoss: 0.146605\n",
      "Train Epoch: 2 [0/9726 (0%)]\tLoss: 0.181215\n",
      "Train Epoch: 2 [1000/9726 (10%)]\tLoss: 0.193027\n",
      "Train Epoch: 2 [2000/9726 (20%)]\tLoss: 0.267659\n",
      "Train Epoch: 2 [3000/9726 (31%)]\tLoss: 0.212827\n",
      "Train Epoch: 2 [4000/9726 (41%)]\tLoss: 0.229083\n",
      "Train Epoch: 2 [5000/9726 (51%)]\tLoss: 0.169894\n",
      "Train Epoch: 2 [6000/9726 (61%)]\tLoss: 0.221484\n",
      "Train Epoch: 2 [7000/9726 (71%)]\tLoss: 0.163244\n",
      "Train Epoch: 2 [8000/9726 (82%)]\tLoss: 0.119227\n",
      "Train Epoch: 2 [9000/9726 (92%)]\tLoss: 0.179811\n",
      "Train Epoch: 3 [0/9726 (0%)]\tLoss: 0.156286\n",
      "Train Epoch: 3 [1000/9726 (10%)]\tLoss: 0.198008\n",
      "Train Epoch: 3 [2000/9726 (20%)]\tLoss: 0.228193\n",
      "Train Epoch: 3 [3000/9726 (31%)]\tLoss: 0.215048\n",
      "Train Epoch: 3 [4000/9726 (41%)]\tLoss: 0.215683\n",
      "Train Epoch: 3 [5000/9726 (51%)]\tLoss: 0.315394\n",
      "Train Epoch: 3 [6000/9726 (61%)]\tLoss: 0.223193\n",
      "Train Epoch: 3 [7000/9726 (71%)]\tLoss: 0.217144\n",
      "Train Epoch: 3 [8000/9726 (82%)]\tLoss: 0.135407\n",
      "Train Epoch: 3 [9000/9726 (92%)]\tLoss: 0.171927\n",
      "Train Epoch: 4 [0/9726 (0%)]\tLoss: 0.178316\n",
      "Train Epoch: 4 [1000/9726 (10%)]\tLoss: 0.104298\n",
      "Train Epoch: 4 [2000/9726 (20%)]\tLoss: 0.265316\n",
      "Train Epoch: 4 [3000/9726 (31%)]\tLoss: 0.160636\n",
      "Train Epoch: 4 [4000/9726 (41%)]\tLoss: 0.248631\n",
      "Train Epoch: 4 [5000/9726 (51%)]\tLoss: 0.272885\n",
      "Train Epoch: 4 [6000/9726 (61%)]\tLoss: 0.158289\n",
      "Train Epoch: 4 [7000/9726 (71%)]\tLoss: 0.164380\n",
      "Train Epoch: 4 [8000/9726 (82%)]\tLoss: 0.214862\n",
      "Train Epoch: 4 [9000/9726 (92%)]\tLoss: 0.212015\n",
      "Train Epoch: 5 [0/9726 (0%)]\tLoss: 0.120124\n",
      "Train Epoch: 5 [1000/9726 (10%)]\tLoss: 0.137717\n",
      "Train Epoch: 5 [2000/9726 (20%)]\tLoss: 0.148316\n",
      "Train Epoch: 5 [3000/9726 (31%)]\tLoss: 0.128030\n",
      "Train Epoch: 5 [4000/9726 (41%)]\tLoss: 0.158440\n",
      "Train Epoch: 5 [5000/9726 (51%)]\tLoss: 0.237552\n",
      "Train Epoch: 5 [6000/9726 (61%)]\tLoss: 0.123004\n",
      "Train Epoch: 5 [7000/9726 (71%)]\tLoss: 0.179919\n",
      "Train Epoch: 5 [8000/9726 (82%)]\tLoss: 0.264888\n",
      "Train Epoch: 5 [9000/9726 (92%)]\tLoss: 0.287042\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/6491 (0%)]\tLoss: 0.352279\n",
      "Train Epoch: 1 [1000/6491 (15%)]\tLoss: 0.336929\n",
      "Train Epoch: 1 [2000/6491 (31%)]\tLoss: 0.318681\n",
      "Train Epoch: 1 [3000/6491 (46%)]\tLoss: 0.253790\n",
      "Train Epoch: 1 [4000/6491 (62%)]\tLoss: 0.572876\n",
      "Train Epoch: 1 [5000/6491 (77%)]\tLoss: 0.246939\n",
      "Train Epoch: 1 [6000/6491 (92%)]\tLoss: 0.384587\n",
      "Train Epoch: 2 [0/6491 (0%)]\tLoss: 0.213173\n",
      "Train Epoch: 2 [1000/6491 (15%)]\tLoss: 0.243818\n",
      "Train Epoch: 2 [2000/6491 (31%)]\tLoss: 0.285151\n",
      "Train Epoch: 2 [3000/6491 (46%)]\tLoss: 0.328899\n",
      "Train Epoch: 2 [4000/6491 (62%)]\tLoss: 0.222872\n",
      "Train Epoch: 2 [5000/6491 (77%)]\tLoss: 0.214468\n",
      "Train Epoch: 2 [6000/6491 (92%)]\tLoss: 0.346368\n",
      "Train Epoch: 3 [0/6491 (0%)]\tLoss: 0.265256\n",
      "Train Epoch: 3 [1000/6491 (15%)]\tLoss: 0.401107\n",
      "Train Epoch: 3 [2000/6491 (31%)]\tLoss: 0.345700\n",
      "Train Epoch: 3 [3000/6491 (46%)]\tLoss: 0.250376\n",
      "Train Epoch: 3 [4000/6491 (62%)]\tLoss: 0.359111\n",
      "Train Epoch: 3 [5000/6491 (77%)]\tLoss: 0.304075\n",
      "Train Epoch: 3 [6000/6491 (92%)]\tLoss: 0.287496\n",
      "Train Epoch: 4 [0/6491 (0%)]\tLoss: 0.203653\n",
      "Train Epoch: 4 [1000/6491 (15%)]\tLoss: 0.215737\n",
      "Train Epoch: 4 [2000/6491 (31%)]\tLoss: 0.239551\n",
      "Train Epoch: 4 [3000/6491 (46%)]\tLoss: 0.285746\n",
      "Train Epoch: 4 [4000/6491 (62%)]\tLoss: 0.236493\n",
      "Train Epoch: 4 [5000/6491 (77%)]\tLoss: 0.289076\n",
      "Train Epoch: 4 [6000/6491 (92%)]\tLoss: 0.270604\n",
      "Train Epoch: 5 [0/6491 (0%)]\tLoss: 0.276434\n",
      "Train Epoch: 5 [1000/6491 (15%)]\tLoss: 0.153454\n",
      "Train Epoch: 5 [2000/6491 (31%)]\tLoss: 0.255682\n",
      "Train Epoch: 5 [3000/6491 (46%)]\tLoss: 0.238497\n",
      "Train Epoch: 5 [4000/6491 (62%)]\tLoss: 0.177082\n",
      "Train Epoch: 5 [5000/6491 (77%)]\tLoss: 0.185036\n",
      "Train Epoch: 5 [6000/6491 (92%)]\tLoss: 0.279195\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/14118 (0%)]\tLoss: 0.345446\n",
      "Train Epoch: 1 [1000/14118 (7%)]\tLoss: 0.093935\n",
      "Train Epoch: 1 [2000/14118 (14%)]\tLoss: 0.153058\n",
      "Train Epoch: 1 [3000/14118 (21%)]\tLoss: 0.101898\n",
      "Train Epoch: 1 [4000/14118 (28%)]\tLoss: 0.183705\n",
      "Train Epoch: 1 [5000/14118 (35%)]\tLoss: 0.297841\n",
      "Train Epoch: 1 [6000/14118 (42%)]\tLoss: 0.112912\n",
      "Train Epoch: 1 [7000/14118 (49%)]\tLoss: 0.223542\n",
      "Train Epoch: 1 [8000/14118 (56%)]\tLoss: 0.167189\n",
      "Train Epoch: 1 [9000/14118 (63%)]\tLoss: 0.223436\n",
      "Train Epoch: 1 [10000/14118 (70%)]\tLoss: 0.105855\n",
      "Train Epoch: 1 [11000/14118 (77%)]\tLoss: 0.198948\n",
      "Train Epoch: 1 [12000/14118 (85%)]\tLoss: 0.146939\n",
      "Train Epoch: 1 [13000/14118 (92%)]\tLoss: 0.409337\n",
      "Train Epoch: 1 [14000/14118 (99%)]\tLoss: 0.210850\n",
      "Train Epoch: 2 [0/14118 (0%)]\tLoss: 0.328559\n",
      "Train Epoch: 2 [1000/14118 (7%)]\tLoss: 0.135785\n",
      "Train Epoch: 2 [2000/14118 (14%)]\tLoss: 0.125657\n",
      "Train Epoch: 2 [3000/14118 (21%)]\tLoss: 0.205732\n",
      "Train Epoch: 2 [4000/14118 (28%)]\tLoss: 0.142974\n",
      "Train Epoch: 2 [5000/14118 (35%)]\tLoss: 0.256227\n",
      "Train Epoch: 2 [6000/14118 (42%)]\tLoss: 0.262503\n",
      "Train Epoch: 2 [7000/14118 (49%)]\tLoss: 0.169739\n",
      "Train Epoch: 2 [8000/14118 (56%)]\tLoss: 0.226197\n",
      "Train Epoch: 2 [9000/14118 (63%)]\tLoss: 0.104799\n",
      "Train Epoch: 2 [10000/14118 (70%)]\tLoss: 0.228891\n",
      "Train Epoch: 2 [11000/14118 (77%)]\tLoss: 0.188651\n",
      "Train Epoch: 2 [12000/14118 (85%)]\tLoss: 0.161691\n",
      "Train Epoch: 2 [13000/14118 (92%)]\tLoss: 0.105417\n",
      "Train Epoch: 2 [14000/14118 (99%)]\tLoss: 0.214728\n",
      "Train Epoch: 3 [0/14118 (0%)]\tLoss: 0.194179\n",
      "Train Epoch: 3 [1000/14118 (7%)]\tLoss: 0.262089\n",
      "Train Epoch: 3 [2000/14118 (14%)]\tLoss: 0.162369\n",
      "Train Epoch: 3 [3000/14118 (21%)]\tLoss: 0.150877\n",
      "Train Epoch: 3 [4000/14118 (28%)]\tLoss: 0.190062\n",
      "Train Epoch: 3 [5000/14118 (35%)]\tLoss: 0.176413\n",
      "Train Epoch: 3 [6000/14118 (42%)]\tLoss: 0.096180\n",
      "Train Epoch: 3 [7000/14118 (49%)]\tLoss: 0.171431\n",
      "Train Epoch: 3 [8000/14118 (56%)]\tLoss: 0.230337\n",
      "Train Epoch: 3 [9000/14118 (63%)]\tLoss: 0.143688\n",
      "Train Epoch: 3 [10000/14118 (70%)]\tLoss: 0.108719\n",
      "Train Epoch: 3 [11000/14118 (77%)]\tLoss: 0.142705\n",
      "Train Epoch: 3 [12000/14118 (85%)]\tLoss: 0.206078\n",
      "Train Epoch: 3 [13000/14118 (92%)]\tLoss: 0.236798\n",
      "Train Epoch: 3 [14000/14118 (99%)]\tLoss: 0.120913\n",
      "Train Epoch: 4 [0/14118 (0%)]\tLoss: 0.192375\n",
      "Train Epoch: 4 [1000/14118 (7%)]\tLoss: 0.174711\n",
      "Train Epoch: 4 [2000/14118 (14%)]\tLoss: 0.073438\n",
      "Train Epoch: 4 [3000/14118 (21%)]\tLoss: 0.088208\n",
      "Train Epoch: 4 [4000/14118 (28%)]\tLoss: 0.187160\n",
      "Train Epoch: 4 [5000/14118 (35%)]\tLoss: 0.147027\n",
      "Train Epoch: 4 [6000/14118 (42%)]\tLoss: 0.130828\n",
      "Train Epoch: 4 [7000/14118 (49%)]\tLoss: 0.095893\n",
      "Train Epoch: 4 [8000/14118 (56%)]\tLoss: 0.156326\n",
      "Train Epoch: 4 [9000/14118 (63%)]\tLoss: 0.139715\n",
      "Train Epoch: 4 [10000/14118 (70%)]\tLoss: 0.175877\n",
      "Train Epoch: 4 [11000/14118 (77%)]\tLoss: 0.120137\n",
      "Train Epoch: 4 [12000/14118 (85%)]\tLoss: 0.140958\n",
      "Train Epoch: 4 [13000/14118 (92%)]\tLoss: 0.130025\n",
      "Train Epoch: 4 [14000/14118 (99%)]\tLoss: 0.185352\n",
      "Train Epoch: 5 [0/14118 (0%)]\tLoss: 0.246622\n",
      "Train Epoch: 5 [1000/14118 (7%)]\tLoss: 0.139445\n",
      "Train Epoch: 5 [2000/14118 (14%)]\tLoss: 0.113984\n",
      "Train Epoch: 5 [3000/14118 (21%)]\tLoss: 0.309547\n",
      "Train Epoch: 5 [4000/14118 (28%)]\tLoss: 0.150820\n",
      "Train Epoch: 5 [5000/14118 (35%)]\tLoss: 0.075108\n",
      "Train Epoch: 5 [6000/14118 (42%)]\tLoss: 0.258723\n",
      "Train Epoch: 5 [7000/14118 (49%)]\tLoss: 0.068734\n",
      "Train Epoch: 5 [8000/14118 (56%)]\tLoss: 0.163728\n",
      "Train Epoch: 5 [9000/14118 (63%)]\tLoss: 0.091555\n",
      "Train Epoch: 5 [10000/14118 (70%)]\tLoss: 0.129694\n",
      "Train Epoch: 5 [11000/14118 (77%)]\tLoss: 0.221244\n",
      "Train Epoch: 5 [12000/14118 (85%)]\tLoss: 0.249455\n",
      "Train Epoch: 5 [13000/14118 (92%)]\tLoss: 0.162854\n",
      "Train Epoch: 5 [14000/14118 (99%)]\tLoss: 0.249034\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/9414 (0%)]\tLoss: 0.332784\n",
      "Train Epoch: 1 [1000/9414 (11%)]\tLoss: 0.259613\n",
      "Train Epoch: 1 [2000/9414 (21%)]\tLoss: 0.265855\n",
      "Train Epoch: 1 [3000/9414 (32%)]\tLoss: 0.308874\n",
      "Train Epoch: 1 [4000/9414 (42%)]\tLoss: 0.204400\n",
      "Train Epoch: 1 [5000/9414 (53%)]\tLoss: 0.411554\n",
      "Train Epoch: 1 [6000/9414 (63%)]\tLoss: 0.229085\n",
      "Train Epoch: 1 [7000/9414 (74%)]\tLoss: 0.227210\n",
      "Train Epoch: 1 [8000/9414 (84%)]\tLoss: 0.211605\n",
      "Train Epoch: 1 [9000/9414 (95%)]\tLoss: 0.199482\n",
      "Train Epoch: 2 [0/9414 (0%)]\tLoss: 0.204481\n",
      "Train Epoch: 2 [1000/9414 (11%)]\tLoss: 0.257783\n",
      "Train Epoch: 2 [2000/9414 (21%)]\tLoss: 0.186195\n",
      "Train Epoch: 2 [3000/9414 (32%)]\tLoss: 0.161671\n",
      "Train Epoch: 2 [4000/9414 (42%)]\tLoss: 0.356800\n",
      "Train Epoch: 2 [5000/9414 (53%)]\tLoss: 0.209230\n",
      "Train Epoch: 2 [6000/9414 (63%)]\tLoss: 0.180433\n",
      "Train Epoch: 2 [7000/9414 (74%)]\tLoss: 0.239736\n",
      "Train Epoch: 2 [8000/9414 (84%)]\tLoss: 0.206274\n",
      "Train Epoch: 2 [9000/9414 (95%)]\tLoss: 0.194021\n",
      "Train Epoch: 3 [0/9414 (0%)]\tLoss: 0.195712\n",
      "Train Epoch: 3 [1000/9414 (11%)]\tLoss: 0.304421\n",
      "Train Epoch: 3 [2000/9414 (21%)]\tLoss: 0.236319\n",
      "Train Epoch: 3 [3000/9414 (32%)]\tLoss: 0.174293\n",
      "Train Epoch: 3 [4000/9414 (42%)]\tLoss: 0.164608\n",
      "Train Epoch: 3 [5000/9414 (53%)]\tLoss: 0.278231\n",
      "Train Epoch: 3 [6000/9414 (63%)]\tLoss: 0.384450\n",
      "Train Epoch: 3 [7000/9414 (74%)]\tLoss: 0.232463\n",
      "Train Epoch: 3 [8000/9414 (84%)]\tLoss: 0.278161\n",
      "Train Epoch: 3 [9000/9414 (95%)]\tLoss: 0.231674\n",
      "Train Epoch: 4 [0/9414 (0%)]\tLoss: 0.229720\n",
      "Train Epoch: 4 [1000/9414 (11%)]\tLoss: 0.200061\n",
      "Train Epoch: 4 [2000/9414 (21%)]\tLoss: 0.165468\n",
      "Train Epoch: 4 [3000/9414 (32%)]\tLoss: 0.274662\n",
      "Train Epoch: 4 [4000/9414 (42%)]\tLoss: 0.226847\n",
      "Train Epoch: 4 [5000/9414 (53%)]\tLoss: 0.237692\n",
      "Train Epoch: 4 [6000/9414 (63%)]\tLoss: 0.163903\n",
      "Train Epoch: 4 [7000/9414 (74%)]\tLoss: 0.170647\n",
      "Train Epoch: 4 [8000/9414 (84%)]\tLoss: 0.290749\n",
      "Train Epoch: 4 [9000/9414 (95%)]\tLoss: 0.212277\n",
      "Train Epoch: 5 [0/9414 (0%)]\tLoss: 0.276986\n",
      "Train Epoch: 5 [1000/9414 (11%)]\tLoss: 0.208680\n",
      "Train Epoch: 5 [2000/9414 (21%)]\tLoss: 0.206395\n",
      "Train Epoch: 5 [3000/9414 (32%)]\tLoss: 0.185199\n",
      "Train Epoch: 5 [4000/9414 (42%)]\tLoss: 0.124886\n",
      "Train Epoch: 5 [5000/9414 (53%)]\tLoss: 0.216088\n",
      "Train Epoch: 5 [6000/9414 (63%)]\tLoss: 0.227433\n",
      "Train Epoch: 5 [7000/9414 (74%)]\tLoss: 0.190522\n",
      "Train Epoch: 5 [8000/9414 (84%)]\tLoss: 0.102237\n",
      "Train Epoch: 5 [9000/9414 (95%)]\tLoss: 0.162679\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "6\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.7266, Accuracy: 8567/10000 (86%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/8440 (0%)]\tLoss: 0.270125\n",
      "Train Epoch: 1 [1000/8440 (12%)]\tLoss: 0.251588\n",
      "Train Epoch: 1 [2000/8440 (24%)]\tLoss: 0.276681\n",
      "Train Epoch: 1 [3000/8440 (35%)]\tLoss: 0.331316\n",
      "Train Epoch: 1 [4000/8440 (47%)]\tLoss: 0.255023\n",
      "Train Epoch: 1 [5000/8440 (59%)]\tLoss: 0.254751\n",
      "Train Epoch: 1 [6000/8440 (71%)]\tLoss: 0.271360\n",
      "Train Epoch: 1 [7000/8440 (82%)]\tLoss: 0.189553\n",
      "Train Epoch: 1 [8000/8440 (94%)]\tLoss: 0.336974\n",
      "Train Epoch: 2 [0/8440 (0%)]\tLoss: 0.263343\n",
      "Train Epoch: 2 [1000/8440 (12%)]\tLoss: 0.258241\n",
      "Train Epoch: 2 [2000/8440 (24%)]\tLoss: 0.393315\n",
      "Train Epoch: 2 [3000/8440 (35%)]\tLoss: 0.273368\n",
      "Train Epoch: 2 [4000/8440 (47%)]\tLoss: 0.269566\n",
      "Train Epoch: 2 [5000/8440 (59%)]\tLoss: 0.280957\n",
      "Train Epoch: 2 [6000/8440 (71%)]\tLoss: 0.225516\n",
      "Train Epoch: 2 [7000/8440 (82%)]\tLoss: 0.268590\n",
      "Train Epoch: 2 [8000/8440 (94%)]\tLoss: 0.202410\n",
      "Train Epoch: 3 [0/8440 (0%)]\tLoss: 0.257835\n",
      "Train Epoch: 3 [1000/8440 (12%)]\tLoss: 0.255633\n",
      "Train Epoch: 3 [2000/8440 (24%)]\tLoss: 0.260227\n",
      "Train Epoch: 3 [3000/8440 (35%)]\tLoss: 0.215314\n",
      "Train Epoch: 3 [4000/8440 (47%)]\tLoss: 0.124424\n",
      "Train Epoch: 3 [5000/8440 (59%)]\tLoss: 0.210092\n",
      "Train Epoch: 3 [6000/8440 (71%)]\tLoss: 0.247749\n",
      "Train Epoch: 3 [7000/8440 (82%)]\tLoss: 0.256016\n",
      "Train Epoch: 3 [8000/8440 (94%)]\tLoss: 0.251703\n",
      "Train Epoch: 4 [0/8440 (0%)]\tLoss: 0.233743\n",
      "Train Epoch: 4 [1000/8440 (12%)]\tLoss: 0.208879\n",
      "Train Epoch: 4 [2000/8440 (24%)]\tLoss: 0.258141\n",
      "Train Epoch: 4 [3000/8440 (35%)]\tLoss: 0.371803\n",
      "Train Epoch: 4 [4000/8440 (47%)]\tLoss: 0.179479\n",
      "Train Epoch: 4 [5000/8440 (59%)]\tLoss: 0.233905\n",
      "Train Epoch: 4 [6000/8440 (71%)]\tLoss: 0.289950\n",
      "Train Epoch: 4 [7000/8440 (82%)]\tLoss: 0.256827\n",
      "Train Epoch: 4 [8000/8440 (94%)]\tLoss: 0.240187\n",
      "Train Epoch: 5 [0/8440 (0%)]\tLoss: 0.296013\n",
      "Train Epoch: 5 [1000/8440 (12%)]\tLoss: 0.265602\n",
      "Train Epoch: 5 [2000/8440 (24%)]\tLoss: 0.161050\n",
      "Train Epoch: 5 [3000/8440 (35%)]\tLoss: 0.191239\n",
      "Train Epoch: 5 [4000/8440 (47%)]\tLoss: 0.297076\n",
      "Train Epoch: 5 [5000/8440 (59%)]\tLoss: 0.194686\n",
      "Train Epoch: 5 [6000/8440 (71%)]\tLoss: 0.214583\n",
      "Train Epoch: 5 [7000/8440 (82%)]\tLoss: 0.129645\n",
      "Train Epoch: 5 [8000/8440 (94%)]\tLoss: 0.300810\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11811 (0%)]\tLoss: 0.200570\n",
      "Train Epoch: 1 [1000/11811 (8%)]\tLoss: 0.196054\n",
      "Train Epoch: 1 [2000/11811 (17%)]\tLoss: 0.187648\n",
      "Train Epoch: 1 [3000/11811 (25%)]\tLoss: 0.244136\n",
      "Train Epoch: 1 [4000/11811 (34%)]\tLoss: 0.080060\n",
      "Train Epoch: 1 [5000/11811 (42%)]\tLoss: 0.099832\n",
      "Train Epoch: 1 [6000/11811 (50%)]\tLoss: 0.064843\n",
      "Train Epoch: 1 [7000/11811 (59%)]\tLoss: 0.179617\n",
      "Train Epoch: 1 [8000/11811 (67%)]\tLoss: 0.037307\n",
      "Train Epoch: 1 [9000/11811 (76%)]\tLoss: 0.086721\n",
      "Train Epoch: 1 [10000/11811 (84%)]\tLoss: 0.101345\n",
      "Train Epoch: 1 [11000/11811 (92%)]\tLoss: 0.109118\n",
      "Train Epoch: 2 [0/11811 (0%)]\tLoss: 0.293362\n",
      "Train Epoch: 2 [1000/11811 (8%)]\tLoss: 0.113918\n",
      "Train Epoch: 2 [2000/11811 (17%)]\tLoss: 0.114329\n",
      "Train Epoch: 2 [3000/11811 (25%)]\tLoss: 0.028484\n",
      "Train Epoch: 2 [4000/11811 (34%)]\tLoss: 0.153721\n",
      "Train Epoch: 2 [5000/11811 (42%)]\tLoss: 0.078111\n",
      "Train Epoch: 2 [6000/11811 (50%)]\tLoss: 0.148393\n",
      "Train Epoch: 2 [7000/11811 (59%)]\tLoss: 0.157738\n",
      "Train Epoch: 2 [8000/11811 (67%)]\tLoss: 0.137369\n",
      "Train Epoch: 2 [9000/11811 (76%)]\tLoss: 0.102552\n",
      "Train Epoch: 2 [10000/11811 (84%)]\tLoss: 0.103800\n",
      "Train Epoch: 2 [11000/11811 (92%)]\tLoss: 0.097945\n",
      "Train Epoch: 3 [0/11811 (0%)]\tLoss: 0.148818\n",
      "Train Epoch: 3 [1000/11811 (8%)]\tLoss: 0.073195\n",
      "Train Epoch: 3 [2000/11811 (17%)]\tLoss: 0.053557\n",
      "Train Epoch: 3 [3000/11811 (25%)]\tLoss: 0.161644\n",
      "Train Epoch: 3 [4000/11811 (34%)]\tLoss: 0.115882\n",
      "Train Epoch: 3 [5000/11811 (42%)]\tLoss: 0.082124\n",
      "Train Epoch: 3 [6000/11811 (50%)]\tLoss: 0.077127\n",
      "Train Epoch: 3 [7000/11811 (59%)]\tLoss: 0.085751\n",
      "Train Epoch: 3 [8000/11811 (67%)]\tLoss: 0.062847\n",
      "Train Epoch: 3 [9000/11811 (76%)]\tLoss: 0.118334\n",
      "Train Epoch: 3 [10000/11811 (84%)]\tLoss: 0.209856\n",
      "Train Epoch: 3 [11000/11811 (92%)]\tLoss: 0.074379\n",
      "Train Epoch: 4 [0/11811 (0%)]\tLoss: 0.097828\n",
      "Train Epoch: 4 [1000/11811 (8%)]\tLoss: 0.112953\n",
      "Train Epoch: 4 [2000/11811 (17%)]\tLoss: 0.118485\n",
      "Train Epoch: 4 [3000/11811 (25%)]\tLoss: 0.057992\n",
      "Train Epoch: 4 [4000/11811 (34%)]\tLoss: 0.048863\n",
      "Train Epoch: 4 [5000/11811 (42%)]\tLoss: 0.056921\n",
      "Train Epoch: 4 [6000/11811 (50%)]\tLoss: 0.079455\n",
      "Train Epoch: 4 [7000/11811 (59%)]\tLoss: 0.056651\n",
      "Train Epoch: 4 [8000/11811 (67%)]\tLoss: 0.046411\n",
      "Train Epoch: 4 [9000/11811 (76%)]\tLoss: 0.106738\n",
      "Train Epoch: 4 [10000/11811 (84%)]\tLoss: 0.203457\n",
      "Train Epoch: 4 [11000/11811 (92%)]\tLoss: 0.070198\n",
      "Train Epoch: 5 [0/11811 (0%)]\tLoss: 0.087990\n",
      "Train Epoch: 5 [1000/11811 (8%)]\tLoss: 0.068882\n",
      "Train Epoch: 5 [2000/11811 (17%)]\tLoss: 0.040342\n",
      "Train Epoch: 5 [3000/11811 (25%)]\tLoss: 0.159544\n",
      "Train Epoch: 5 [4000/11811 (34%)]\tLoss: 0.163696\n",
      "Train Epoch: 5 [5000/11811 (42%)]\tLoss: 0.084279\n",
      "Train Epoch: 5 [6000/11811 (50%)]\tLoss: 0.099326\n",
      "Train Epoch: 5 [7000/11811 (59%)]\tLoss: 0.024260\n",
      "Train Epoch: 5 [8000/11811 (67%)]\tLoss: 0.097387\n",
      "Train Epoch: 5 [9000/11811 (76%)]\tLoss: 0.120326\n",
      "Train Epoch: 5 [10000/11811 (84%)]\tLoss: 0.109097\n",
      "Train Epoch: 5 [11000/11811 (92%)]\tLoss: 0.027986\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/9726 (0%)]\tLoss: 0.149323\n",
      "Train Epoch: 1 [1000/9726 (10%)]\tLoss: 0.180494\n",
      "Train Epoch: 1 [2000/9726 (20%)]\tLoss: 0.184457\n",
      "Train Epoch: 1 [3000/9726 (31%)]\tLoss: 0.178275\n",
      "Train Epoch: 1 [4000/9726 (41%)]\tLoss: 0.233202\n",
      "Train Epoch: 1 [5000/9726 (51%)]\tLoss: 0.186678\n",
      "Train Epoch: 1 [6000/9726 (61%)]\tLoss: 0.105587\n",
      "Train Epoch: 1 [7000/9726 (71%)]\tLoss: 0.115478\n",
      "Train Epoch: 1 [8000/9726 (82%)]\tLoss: 0.125937\n",
      "Train Epoch: 1 [9000/9726 (92%)]\tLoss: 0.178859\n",
      "Train Epoch: 2 [0/9726 (0%)]\tLoss: 0.173340\n",
      "Train Epoch: 2 [1000/9726 (10%)]\tLoss: 0.153781\n",
      "Train Epoch: 2 [2000/9726 (20%)]\tLoss: 0.300076\n",
      "Train Epoch: 2 [3000/9726 (31%)]\tLoss: 0.187603\n",
      "Train Epoch: 2 [4000/9726 (41%)]\tLoss: 0.207087\n",
      "Train Epoch: 2 [5000/9726 (51%)]\tLoss: 0.275583\n",
      "Train Epoch: 2 [6000/9726 (61%)]\tLoss: 0.247243\n",
      "Train Epoch: 2 [7000/9726 (71%)]\tLoss: 0.134963\n",
      "Train Epoch: 2 [8000/9726 (82%)]\tLoss: 0.143064\n",
      "Train Epoch: 2 [9000/9726 (92%)]\tLoss: 0.244975\n",
      "Train Epoch: 3 [0/9726 (0%)]\tLoss: 0.114558\n",
      "Train Epoch: 3 [1000/9726 (10%)]\tLoss: 0.208833\n",
      "Train Epoch: 3 [2000/9726 (20%)]\tLoss: 0.169748\n",
      "Train Epoch: 3 [3000/9726 (31%)]\tLoss: 0.240393\n",
      "Train Epoch: 3 [4000/9726 (41%)]\tLoss: 0.229504\n",
      "Train Epoch: 3 [5000/9726 (51%)]\tLoss: 0.161234\n",
      "Train Epoch: 3 [6000/9726 (61%)]\tLoss: 0.227506\n",
      "Train Epoch: 3 [7000/9726 (71%)]\tLoss: 0.285772\n",
      "Train Epoch: 3 [8000/9726 (82%)]\tLoss: 0.308203\n",
      "Train Epoch: 3 [9000/9726 (92%)]\tLoss: 0.185795\n",
      "Train Epoch: 4 [0/9726 (0%)]\tLoss: 0.071343\n",
      "Train Epoch: 4 [1000/9726 (10%)]\tLoss: 0.125563\n",
      "Train Epoch: 4 [2000/9726 (20%)]\tLoss: 0.241997\n",
      "Train Epoch: 4 [3000/9726 (31%)]\tLoss: 0.190644\n",
      "Train Epoch: 4 [4000/9726 (41%)]\tLoss: 0.181766\n",
      "Train Epoch: 4 [5000/9726 (51%)]\tLoss: 0.263973\n",
      "Train Epoch: 4 [6000/9726 (61%)]\tLoss: 0.296504\n",
      "Train Epoch: 4 [7000/9726 (71%)]\tLoss: 0.169988\n",
      "Train Epoch: 4 [8000/9726 (82%)]\tLoss: 0.178716\n",
      "Train Epoch: 4 [9000/9726 (92%)]\tLoss: 0.137979\n",
      "Train Epoch: 5 [0/9726 (0%)]\tLoss: 0.185793\n",
      "Train Epoch: 5 [1000/9726 (10%)]\tLoss: 0.229553\n",
      "Train Epoch: 5 [2000/9726 (20%)]\tLoss: 0.104910\n",
      "Train Epoch: 5 [3000/9726 (31%)]\tLoss: 0.171778\n",
      "Train Epoch: 5 [4000/9726 (41%)]\tLoss: 0.260942\n",
      "Train Epoch: 5 [5000/9726 (51%)]\tLoss: 0.172012\n",
      "Train Epoch: 5 [6000/9726 (61%)]\tLoss: 0.290719\n",
      "Train Epoch: 5 [7000/9726 (71%)]\tLoss: 0.165194\n",
      "Train Epoch: 5 [8000/9726 (82%)]\tLoss: 0.175231\n",
      "Train Epoch: 5 [9000/9726 (92%)]\tLoss: 0.161193\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/6491 (0%)]\tLoss: 0.353683\n",
      "Train Epoch: 1 [1000/6491 (15%)]\tLoss: 0.352550\n",
      "Train Epoch: 1 [2000/6491 (31%)]\tLoss: 0.326494\n",
      "Train Epoch: 1 [3000/6491 (46%)]\tLoss: 0.319728\n",
      "Train Epoch: 1 [4000/6491 (62%)]\tLoss: 0.323721\n",
      "Train Epoch: 1 [5000/6491 (77%)]\tLoss: 0.307577\n",
      "Train Epoch: 1 [6000/6491 (92%)]\tLoss: 0.355012\n",
      "Train Epoch: 2 [0/6491 (0%)]\tLoss: 0.242589\n",
      "Train Epoch: 2 [1000/6491 (15%)]\tLoss: 0.335934\n",
      "Train Epoch: 2 [2000/6491 (31%)]\tLoss: 0.193500\n",
      "Train Epoch: 2 [3000/6491 (46%)]\tLoss: 0.330593\n",
      "Train Epoch: 2 [4000/6491 (62%)]\tLoss: 0.366567\n",
      "Train Epoch: 2 [5000/6491 (77%)]\tLoss: 0.328533\n",
      "Train Epoch: 2 [6000/6491 (92%)]\tLoss: 0.385372\n",
      "Train Epoch: 3 [0/6491 (0%)]\tLoss: 0.259814\n",
      "Train Epoch: 3 [1000/6491 (15%)]\tLoss: 0.264463\n",
      "Train Epoch: 3 [2000/6491 (31%)]\tLoss: 0.283844\n",
      "Train Epoch: 3 [3000/6491 (46%)]\tLoss: 0.394724\n",
      "Train Epoch: 3 [4000/6491 (62%)]\tLoss: 0.239058\n",
      "Train Epoch: 3 [5000/6491 (77%)]\tLoss: 0.247300\n",
      "Train Epoch: 3 [6000/6491 (92%)]\tLoss: 0.271043\n",
      "Train Epoch: 4 [0/6491 (0%)]\tLoss: 0.294861\n",
      "Train Epoch: 4 [1000/6491 (15%)]\tLoss: 0.247569\n",
      "Train Epoch: 4 [2000/6491 (31%)]\tLoss: 0.301743\n",
      "Train Epoch: 4 [3000/6491 (46%)]\tLoss: 0.203264\n",
      "Train Epoch: 4 [4000/6491 (62%)]\tLoss: 0.265280\n",
      "Train Epoch: 4 [5000/6491 (77%)]\tLoss: 0.379110\n",
      "Train Epoch: 4 [6000/6491 (92%)]\tLoss: 0.337020\n",
      "Train Epoch: 5 [0/6491 (0%)]\tLoss: 0.177528\n",
      "Train Epoch: 5 [1000/6491 (15%)]\tLoss: 0.191039\n",
      "Train Epoch: 5 [2000/6491 (31%)]\tLoss: 0.292163\n",
      "Train Epoch: 5 [3000/6491 (46%)]\tLoss: 0.278801\n",
      "Train Epoch: 5 [4000/6491 (62%)]\tLoss: 0.321644\n",
      "Train Epoch: 5 [5000/6491 (77%)]\tLoss: 0.258978\n",
      "Train Epoch: 5 [6000/6491 (92%)]\tLoss: 0.199678\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/14118 (0%)]\tLoss: 0.214355\n",
      "Train Epoch: 1 [1000/14118 (7%)]\tLoss: 0.159797\n",
      "Train Epoch: 1 [2000/14118 (14%)]\tLoss: 0.154928\n",
      "Train Epoch: 1 [3000/14118 (21%)]\tLoss: 0.121947\n",
      "Train Epoch: 1 [4000/14118 (28%)]\tLoss: 0.231324\n",
      "Train Epoch: 1 [5000/14118 (35%)]\tLoss: 0.181430\n",
      "Train Epoch: 1 [6000/14118 (42%)]\tLoss: 0.103042\n",
      "Train Epoch: 1 [7000/14118 (49%)]\tLoss: 0.175921\n",
      "Train Epoch: 1 [8000/14118 (56%)]\tLoss: 0.080019\n",
      "Train Epoch: 1 [9000/14118 (63%)]\tLoss: 0.251664\n",
      "Train Epoch: 1 [10000/14118 (70%)]\tLoss: 0.193231\n",
      "Train Epoch: 1 [11000/14118 (77%)]\tLoss: 0.190325\n",
      "Train Epoch: 1 [12000/14118 (85%)]\tLoss: 0.152412\n",
      "Train Epoch: 1 [13000/14118 (92%)]\tLoss: 0.125287\n",
      "Train Epoch: 1 [14000/14118 (99%)]\tLoss: 0.107597\n",
      "Train Epoch: 2 [0/14118 (0%)]\tLoss: 0.197266\n",
      "Train Epoch: 2 [1000/14118 (7%)]\tLoss: 0.233679\n",
      "Train Epoch: 2 [2000/14118 (14%)]\tLoss: 0.098468\n",
      "Train Epoch: 2 [3000/14118 (21%)]\tLoss: 0.162693\n",
      "Train Epoch: 2 [4000/14118 (28%)]\tLoss: 0.148220\n",
      "Train Epoch: 2 [5000/14118 (35%)]\tLoss: 0.167659\n",
      "Train Epoch: 2 [6000/14118 (42%)]\tLoss: 0.203489\n",
      "Train Epoch: 2 [7000/14118 (49%)]\tLoss: 0.171168\n",
      "Train Epoch: 2 [8000/14118 (56%)]\tLoss: 0.215270\n",
      "Train Epoch: 2 [9000/14118 (63%)]\tLoss: 0.282139\n",
      "Train Epoch: 2 [10000/14118 (70%)]\tLoss: 0.118429\n",
      "Train Epoch: 2 [11000/14118 (77%)]\tLoss: 0.235001\n",
      "Train Epoch: 2 [12000/14118 (85%)]\tLoss: 0.167410\n",
      "Train Epoch: 2 [13000/14118 (92%)]\tLoss: 0.447093\n",
      "Train Epoch: 2 [14000/14118 (99%)]\tLoss: 0.107577\n",
      "Train Epoch: 3 [0/14118 (0%)]\tLoss: 0.194184\n",
      "Train Epoch: 3 [1000/14118 (7%)]\tLoss: 0.135147\n",
      "Train Epoch: 3 [2000/14118 (14%)]\tLoss: 0.141211\n",
      "Train Epoch: 3 [3000/14118 (21%)]\tLoss: 0.172731\n",
      "Train Epoch: 3 [4000/14118 (28%)]\tLoss: 0.185856\n",
      "Train Epoch: 3 [5000/14118 (35%)]\tLoss: 0.168251\n",
      "Train Epoch: 3 [6000/14118 (42%)]\tLoss: 0.221593\n",
      "Train Epoch: 3 [7000/14118 (49%)]\tLoss: 0.189646\n",
      "Train Epoch: 3 [8000/14118 (56%)]\tLoss: 0.150217\n",
      "Train Epoch: 3 [9000/14118 (63%)]\tLoss: 0.164955\n",
      "Train Epoch: 3 [10000/14118 (70%)]\tLoss: 0.139403\n",
      "Train Epoch: 3 [11000/14118 (77%)]\tLoss: 0.163080\n",
      "Train Epoch: 3 [12000/14118 (85%)]\tLoss: 0.150243\n",
      "Train Epoch: 3 [13000/14118 (92%)]\tLoss: 0.277006\n",
      "Train Epoch: 3 [14000/14118 (99%)]\tLoss: 0.115925\n",
      "Train Epoch: 4 [0/14118 (0%)]\tLoss: 0.128741\n",
      "Train Epoch: 4 [1000/14118 (7%)]\tLoss: 0.119138\n",
      "Train Epoch: 4 [2000/14118 (14%)]\tLoss: 0.160167\n",
      "Train Epoch: 4 [3000/14118 (21%)]\tLoss: 0.185997\n",
      "Train Epoch: 4 [4000/14118 (28%)]\tLoss: 0.239375\n",
      "Train Epoch: 4 [5000/14118 (35%)]\tLoss: 0.099688\n",
      "Train Epoch: 4 [6000/14118 (42%)]\tLoss: 0.170667\n",
      "Train Epoch: 4 [7000/14118 (49%)]\tLoss: 0.145519\n",
      "Train Epoch: 4 [8000/14118 (56%)]\tLoss: 0.166112\n",
      "Train Epoch: 4 [9000/14118 (63%)]\tLoss: 0.238468\n",
      "Train Epoch: 4 [10000/14118 (70%)]\tLoss: 0.219922\n",
      "Train Epoch: 4 [11000/14118 (77%)]\tLoss: 0.124306\n",
      "Train Epoch: 4 [12000/14118 (85%)]\tLoss: 0.298519\n",
      "Train Epoch: 4 [13000/14118 (92%)]\tLoss: 0.166062\n",
      "Train Epoch: 4 [14000/14118 (99%)]\tLoss: 0.192549\n",
      "Train Epoch: 5 [0/14118 (0%)]\tLoss: 0.220060\n",
      "Train Epoch: 5 [1000/14118 (7%)]\tLoss: 0.178077\n",
      "Train Epoch: 5 [2000/14118 (14%)]\tLoss: 0.099529\n",
      "Train Epoch: 5 [3000/14118 (21%)]\tLoss: 0.116510\n",
      "Train Epoch: 5 [4000/14118 (28%)]\tLoss: 0.227570\n",
      "Train Epoch: 5 [5000/14118 (35%)]\tLoss: 0.104393\n",
      "Train Epoch: 5 [6000/14118 (42%)]\tLoss: 0.123836\n",
      "Train Epoch: 5 [7000/14118 (49%)]\tLoss: 0.107330\n",
      "Train Epoch: 5 [8000/14118 (56%)]\tLoss: 0.159141\n",
      "Train Epoch: 5 [9000/14118 (63%)]\tLoss: 0.079978\n",
      "Train Epoch: 5 [10000/14118 (70%)]\tLoss: 0.275891\n",
      "Train Epoch: 5 [11000/14118 (77%)]\tLoss: 0.114144\n",
      "Train Epoch: 5 [12000/14118 (85%)]\tLoss: 0.083699\n",
      "Train Epoch: 5 [13000/14118 (92%)]\tLoss: 0.258040\n",
      "Train Epoch: 5 [14000/14118 (99%)]\tLoss: 0.084421\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/9414 (0%)]\tLoss: 0.325353\n",
      "Train Epoch: 1 [1000/9414 (11%)]\tLoss: 0.320623\n",
      "Train Epoch: 1 [2000/9414 (21%)]\tLoss: 0.293997\n",
      "Train Epoch: 1 [3000/9414 (32%)]\tLoss: 0.249511\n",
      "Train Epoch: 1 [4000/9414 (42%)]\tLoss: 0.242444\n",
      "Train Epoch: 1 [5000/9414 (53%)]\tLoss: 0.268414\n",
      "Train Epoch: 1 [6000/9414 (63%)]\tLoss: 0.330992\n",
      "Train Epoch: 1 [7000/9414 (74%)]\tLoss: 0.170057\n",
      "Train Epoch: 1 [8000/9414 (84%)]\tLoss: 0.204825\n",
      "Train Epoch: 1 [9000/9414 (95%)]\tLoss: 0.186507\n",
      "Train Epoch: 2 [0/9414 (0%)]\tLoss: 0.113567\n",
      "Train Epoch: 2 [1000/9414 (11%)]\tLoss: 0.118853\n",
      "Train Epoch: 2 [2000/9414 (21%)]\tLoss: 0.182848\n",
      "Train Epoch: 2 [3000/9414 (32%)]\tLoss: 0.135995\n",
      "Train Epoch: 2 [4000/9414 (42%)]\tLoss: 0.198714\n",
      "Train Epoch: 2 [5000/9414 (53%)]\tLoss: 0.233129\n",
      "Train Epoch: 2 [6000/9414 (63%)]\tLoss: 0.154184\n",
      "Train Epoch: 2 [7000/9414 (74%)]\tLoss: 0.276415\n",
      "Train Epoch: 2 [8000/9414 (84%)]\tLoss: 0.261813\n",
      "Train Epoch: 2 [9000/9414 (95%)]\tLoss: 0.238557\n",
      "Train Epoch: 3 [0/9414 (0%)]\tLoss: 0.133328\n",
      "Train Epoch: 3 [1000/9414 (11%)]\tLoss: 0.217693\n",
      "Train Epoch: 3 [2000/9414 (21%)]\tLoss: 0.165062\n",
      "Train Epoch: 3 [3000/9414 (32%)]\tLoss: 0.227246\n",
      "Train Epoch: 3 [4000/9414 (42%)]\tLoss: 0.227632\n",
      "Train Epoch: 3 [5000/9414 (53%)]\tLoss: 0.262635\n",
      "Train Epoch: 3 [6000/9414 (63%)]\tLoss: 0.208263\n",
      "Train Epoch: 3 [7000/9414 (74%)]\tLoss: 0.223756\n",
      "Train Epoch: 3 [8000/9414 (84%)]\tLoss: 0.237193\n",
      "Train Epoch: 3 [9000/9414 (95%)]\tLoss: 0.228598\n",
      "Train Epoch: 4 [0/9414 (0%)]\tLoss: 0.216477\n",
      "Train Epoch: 4 [1000/9414 (11%)]\tLoss: 0.263263\n",
      "Train Epoch: 4 [2000/9414 (21%)]\tLoss: 0.229038\n",
      "Train Epoch: 4 [3000/9414 (32%)]\tLoss: 0.307039\n",
      "Train Epoch: 4 [4000/9414 (42%)]\tLoss: 0.226046\n",
      "Train Epoch: 4 [5000/9414 (53%)]\tLoss: 0.150367\n",
      "Train Epoch: 4 [6000/9414 (63%)]\tLoss: 0.085798\n",
      "Train Epoch: 4 [7000/9414 (74%)]\tLoss: 0.296150\n",
      "Train Epoch: 4 [8000/9414 (84%)]\tLoss: 0.227153\n",
      "Train Epoch: 4 [9000/9414 (95%)]\tLoss: 0.217610\n",
      "Train Epoch: 5 [0/9414 (0%)]\tLoss: 0.237159\n",
      "Train Epoch: 5 [1000/9414 (11%)]\tLoss: 0.189096\n",
      "Train Epoch: 5 [2000/9414 (21%)]\tLoss: 0.289446\n",
      "Train Epoch: 5 [3000/9414 (32%)]\tLoss: 0.153844\n",
      "Train Epoch: 5 [4000/9414 (42%)]\tLoss: 0.182129\n",
      "Train Epoch: 5 [5000/9414 (53%)]\tLoss: 0.235431\n",
      "Train Epoch: 5 [6000/9414 (63%)]\tLoss: 0.193252\n",
      "Train Epoch: 5 [7000/9414 (74%)]\tLoss: 0.261677\n",
      "Train Epoch: 5 [8000/9414 (84%)]\tLoss: 0.152905\n",
      "Train Epoch: 5 [9000/9414 (95%)]\tLoss: 0.178899\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "6\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.7113, Accuracy: 8624/10000 (86%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/8440 (0%)]\tLoss: 0.362941\n",
      "Train Epoch: 1 [1000/8440 (12%)]\tLoss: 0.300595\n",
      "Train Epoch: 1 [2000/8440 (24%)]\tLoss: 0.311388\n",
      "Train Epoch: 1 [3000/8440 (35%)]\tLoss: 0.342308\n",
      "Train Epoch: 1 [4000/8440 (47%)]\tLoss: 0.258164\n",
      "Train Epoch: 1 [5000/8440 (59%)]\tLoss: 0.358519\n",
      "Train Epoch: 1 [6000/8440 (71%)]\tLoss: 0.212276\n",
      "Train Epoch: 1 [7000/8440 (82%)]\tLoss: 0.177620\n",
      "Train Epoch: 1 [8000/8440 (94%)]\tLoss: 0.280547\n",
      "Train Epoch: 2 [0/8440 (0%)]\tLoss: 0.206495\n",
      "Train Epoch: 2 [1000/8440 (12%)]\tLoss: 0.187628\n",
      "Train Epoch: 2 [2000/8440 (24%)]\tLoss: 0.323241\n",
      "Train Epoch: 2 [3000/8440 (35%)]\tLoss: 0.243464\n",
      "Train Epoch: 2 [4000/8440 (47%)]\tLoss: 0.284213\n",
      "Train Epoch: 2 [5000/8440 (59%)]\tLoss: 0.218555\n",
      "Train Epoch: 2 [6000/8440 (71%)]\tLoss: 0.174184\n",
      "Train Epoch: 2 [7000/8440 (82%)]\tLoss: 0.255727\n",
      "Train Epoch: 2 [8000/8440 (94%)]\tLoss: 0.326748\n",
      "Train Epoch: 3 [0/8440 (0%)]\tLoss: 0.202720\n",
      "Train Epoch: 3 [1000/8440 (12%)]\tLoss: 0.302760\n",
      "Train Epoch: 3 [2000/8440 (24%)]\tLoss: 0.225256\n",
      "Train Epoch: 3 [3000/8440 (35%)]\tLoss: 0.178955\n",
      "Train Epoch: 3 [4000/8440 (47%)]\tLoss: 0.310270\n",
      "Train Epoch: 3 [5000/8440 (59%)]\tLoss: 0.191784\n",
      "Train Epoch: 3 [6000/8440 (71%)]\tLoss: 0.241582\n",
      "Train Epoch: 3 [7000/8440 (82%)]\tLoss: 0.323051\n",
      "Train Epoch: 3 [8000/8440 (94%)]\tLoss: 0.267774\n",
      "Train Epoch: 4 [0/8440 (0%)]\tLoss: 0.199019\n",
      "Train Epoch: 4 [1000/8440 (12%)]\tLoss: 0.181432\n",
      "Train Epoch: 4 [2000/8440 (24%)]\tLoss: 0.176974\n",
      "Train Epoch: 4 [3000/8440 (35%)]\tLoss: 0.155839\n",
      "Train Epoch: 4 [4000/8440 (47%)]\tLoss: 0.202785\n",
      "Train Epoch: 4 [5000/8440 (59%)]\tLoss: 0.221090\n",
      "Train Epoch: 4 [6000/8440 (71%)]\tLoss: 0.230181\n",
      "Train Epoch: 4 [7000/8440 (82%)]\tLoss: 0.207055\n",
      "Train Epoch: 4 [8000/8440 (94%)]\tLoss: 0.209444\n",
      "Train Epoch: 5 [0/8440 (0%)]\tLoss: 0.242330\n",
      "Train Epoch: 5 [1000/8440 (12%)]\tLoss: 0.226471\n",
      "Train Epoch: 5 [2000/8440 (24%)]\tLoss: 0.154511\n",
      "Train Epoch: 5 [3000/8440 (35%)]\tLoss: 0.236181\n",
      "Train Epoch: 5 [4000/8440 (47%)]\tLoss: 0.295615\n",
      "Train Epoch: 5 [5000/8440 (59%)]\tLoss: 0.245656\n",
      "Train Epoch: 5 [6000/8440 (71%)]\tLoss: 0.128081\n",
      "Train Epoch: 5 [7000/8440 (82%)]\tLoss: 0.200153\n",
      "Train Epoch: 5 [8000/8440 (94%)]\tLoss: 0.326297\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11811 (0%)]\tLoss: 0.115159\n",
      "Train Epoch: 1 [1000/11811 (8%)]\tLoss: 0.053503\n",
      "Train Epoch: 1 [2000/11811 (17%)]\tLoss: 0.180723\n",
      "Train Epoch: 1 [3000/11811 (25%)]\tLoss: 0.047850\n",
      "Train Epoch: 1 [4000/11811 (34%)]\tLoss: 0.146353\n",
      "Train Epoch: 1 [5000/11811 (42%)]\tLoss: 0.067542\n",
      "Train Epoch: 1 [6000/11811 (50%)]\tLoss: 0.211167\n",
      "Train Epoch: 1 [7000/11811 (59%)]\tLoss: 0.155988\n",
      "Train Epoch: 1 [8000/11811 (67%)]\tLoss: 0.157437\n",
      "Train Epoch: 1 [9000/11811 (76%)]\tLoss: 0.117302\n",
      "Train Epoch: 1 [10000/11811 (84%)]\tLoss: 0.078396\n",
      "Train Epoch: 1 [11000/11811 (92%)]\tLoss: 0.045452\n",
      "Train Epoch: 2 [0/11811 (0%)]\tLoss: 0.104498\n",
      "Train Epoch: 2 [1000/11811 (8%)]\tLoss: 0.094186\n",
      "Train Epoch: 2 [2000/11811 (17%)]\tLoss: 0.077630\n",
      "Train Epoch: 2 [3000/11811 (25%)]\tLoss: 0.116788\n",
      "Train Epoch: 2 [4000/11811 (34%)]\tLoss: 0.118159\n",
      "Train Epoch: 2 [5000/11811 (42%)]\tLoss: 0.189963\n",
      "Train Epoch: 2 [6000/11811 (50%)]\tLoss: 0.080090\n",
      "Train Epoch: 2 [7000/11811 (59%)]\tLoss: 0.237372\n",
      "Train Epoch: 2 [8000/11811 (67%)]\tLoss: 0.096398\n",
      "Train Epoch: 2 [9000/11811 (76%)]\tLoss: 0.041609\n",
      "Train Epoch: 2 [10000/11811 (84%)]\tLoss: 0.161569\n",
      "Train Epoch: 2 [11000/11811 (92%)]\tLoss: 0.223673\n",
      "Train Epoch: 3 [0/11811 (0%)]\tLoss: 0.068561\n",
      "Train Epoch: 3 [1000/11811 (8%)]\tLoss: 0.118404\n",
      "Train Epoch: 3 [2000/11811 (17%)]\tLoss: 0.088327\n",
      "Train Epoch: 3 [3000/11811 (25%)]\tLoss: 0.091421\n",
      "Train Epoch: 3 [4000/11811 (34%)]\tLoss: 0.063837\n",
      "Train Epoch: 3 [5000/11811 (42%)]\tLoss: 0.076746\n",
      "Train Epoch: 3 [6000/11811 (50%)]\tLoss: 0.063329\n",
      "Train Epoch: 3 [7000/11811 (59%)]\tLoss: 0.076293\n",
      "Train Epoch: 3 [8000/11811 (67%)]\tLoss: 0.096383\n",
      "Train Epoch: 3 [9000/11811 (76%)]\tLoss: 0.151944\n",
      "Train Epoch: 3 [10000/11811 (84%)]\tLoss: 0.072045\n",
      "Train Epoch: 3 [11000/11811 (92%)]\tLoss: 0.055892\n",
      "Train Epoch: 4 [0/11811 (0%)]\tLoss: 0.086572\n",
      "Train Epoch: 4 [1000/11811 (8%)]\tLoss: 0.096789\n",
      "Train Epoch: 4 [2000/11811 (17%)]\tLoss: 0.097182\n",
      "Train Epoch: 4 [3000/11811 (25%)]\tLoss: 0.034656\n",
      "Train Epoch: 4 [4000/11811 (34%)]\tLoss: 0.127931\n",
      "Train Epoch: 4 [5000/11811 (42%)]\tLoss: 0.084937\n",
      "Train Epoch: 4 [6000/11811 (50%)]\tLoss: 0.193312\n",
      "Train Epoch: 4 [7000/11811 (59%)]\tLoss: 0.087922\n",
      "Train Epoch: 4 [8000/11811 (67%)]\tLoss: 0.102880\n",
      "Train Epoch: 4 [9000/11811 (76%)]\tLoss: 0.051879\n",
      "Train Epoch: 4 [10000/11811 (84%)]\tLoss: 0.069561\n",
      "Train Epoch: 4 [11000/11811 (92%)]\tLoss: 0.049313\n",
      "Train Epoch: 5 [0/11811 (0%)]\tLoss: 0.029354\n",
      "Train Epoch: 5 [1000/11811 (8%)]\tLoss: 0.036297\n",
      "Train Epoch: 5 [2000/11811 (17%)]\tLoss: 0.050361\n",
      "Train Epoch: 5 [3000/11811 (25%)]\tLoss: 0.180722\n",
      "Train Epoch: 5 [4000/11811 (34%)]\tLoss: 0.104028\n",
      "Train Epoch: 5 [5000/11811 (42%)]\tLoss: 0.067323\n",
      "Train Epoch: 5 [6000/11811 (50%)]\tLoss: 0.189203\n",
      "Train Epoch: 5 [7000/11811 (59%)]\tLoss: 0.046869\n",
      "Train Epoch: 5 [8000/11811 (67%)]\tLoss: 0.048977\n",
      "Train Epoch: 5 [9000/11811 (76%)]\tLoss: 0.060969\n",
      "Train Epoch: 5 [10000/11811 (84%)]\tLoss: 0.048032\n",
      "Train Epoch: 5 [11000/11811 (92%)]\tLoss: 0.033789\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/9726 (0%)]\tLoss: 0.330270\n",
      "Train Epoch: 1 [1000/9726 (10%)]\tLoss: 0.380660\n",
      "Train Epoch: 1 [2000/9726 (20%)]\tLoss: 0.125616\n",
      "Train Epoch: 1 [3000/9726 (31%)]\tLoss: 0.500996\n",
      "Train Epoch: 1 [4000/9726 (41%)]\tLoss: 0.116705\n",
      "Train Epoch: 1 [5000/9726 (51%)]\tLoss: 0.229646\n",
      "Train Epoch: 1 [6000/9726 (61%)]\tLoss: 0.197249\n",
      "Train Epoch: 1 [7000/9726 (71%)]\tLoss: 0.160873\n",
      "Train Epoch: 1 [8000/9726 (82%)]\tLoss: 0.223514\n",
      "Train Epoch: 1 [9000/9726 (92%)]\tLoss: 0.114483\n",
      "Train Epoch: 2 [0/9726 (0%)]\tLoss: 0.208525\n",
      "Train Epoch: 2 [1000/9726 (10%)]\tLoss: 0.181339\n",
      "Train Epoch: 2 [2000/9726 (20%)]\tLoss: 0.236890\n",
      "Train Epoch: 2 [3000/9726 (31%)]\tLoss: 0.164712\n",
      "Train Epoch: 2 [4000/9726 (41%)]\tLoss: 0.171839\n",
      "Train Epoch: 2 [5000/9726 (51%)]\tLoss: 0.224783\n",
      "Train Epoch: 2 [6000/9726 (61%)]\tLoss: 0.099374\n",
      "Train Epoch: 2 [7000/9726 (71%)]\tLoss: 0.171634\n",
      "Train Epoch: 2 [8000/9726 (82%)]\tLoss: 0.209408\n",
      "Train Epoch: 2 [9000/9726 (92%)]\tLoss: 0.214838\n",
      "Train Epoch: 3 [0/9726 (0%)]\tLoss: 0.210312\n",
      "Train Epoch: 3 [1000/9726 (10%)]\tLoss: 0.148665\n",
      "Train Epoch: 3 [2000/9726 (20%)]\tLoss: 0.197183\n",
      "Train Epoch: 3 [3000/9726 (31%)]\tLoss: 0.127344\n",
      "Train Epoch: 3 [4000/9726 (41%)]\tLoss: 0.175500\n",
      "Train Epoch: 3 [5000/9726 (51%)]\tLoss: 0.175615\n",
      "Train Epoch: 3 [6000/9726 (61%)]\tLoss: 0.193498\n",
      "Train Epoch: 3 [7000/9726 (71%)]\tLoss: 0.178324\n",
      "Train Epoch: 3 [8000/9726 (82%)]\tLoss: 0.138182\n",
      "Train Epoch: 3 [9000/9726 (92%)]\tLoss: 0.216475\n",
      "Train Epoch: 4 [0/9726 (0%)]\tLoss: 0.130091\n",
      "Train Epoch: 4 [1000/9726 (10%)]\tLoss: 0.198475\n",
      "Train Epoch: 4 [2000/9726 (20%)]\tLoss: 0.143211\n",
      "Train Epoch: 4 [3000/9726 (31%)]\tLoss: 0.141881\n",
      "Train Epoch: 4 [4000/9726 (41%)]\tLoss: 0.095500\n",
      "Train Epoch: 4 [5000/9726 (51%)]\tLoss: 0.147238\n",
      "Train Epoch: 4 [6000/9726 (61%)]\tLoss: 0.118494\n",
      "Train Epoch: 4 [7000/9726 (71%)]\tLoss: 0.140461\n",
      "Train Epoch: 4 [8000/9726 (82%)]\tLoss: 0.160327\n",
      "Train Epoch: 4 [9000/9726 (92%)]\tLoss: 0.169619\n",
      "Train Epoch: 5 [0/9726 (0%)]\tLoss: 0.104682\n",
      "Train Epoch: 5 [1000/9726 (10%)]\tLoss: 0.201760\n",
      "Train Epoch: 5 [2000/9726 (20%)]\tLoss: 0.173378\n",
      "Train Epoch: 5 [3000/9726 (31%)]\tLoss: 0.127813\n",
      "Train Epoch: 5 [4000/9726 (41%)]\tLoss: 0.185720\n",
      "Train Epoch: 5 [5000/9726 (51%)]\tLoss: 0.196759\n",
      "Train Epoch: 5 [6000/9726 (61%)]\tLoss: 0.222191\n",
      "Train Epoch: 5 [7000/9726 (71%)]\tLoss: 0.137446\n",
      "Train Epoch: 5 [8000/9726 (82%)]\tLoss: 0.218502\n",
      "Train Epoch: 5 [9000/9726 (92%)]\tLoss: 0.152074\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/6491 (0%)]\tLoss: 0.351148\n",
      "Train Epoch: 1 [1000/6491 (15%)]\tLoss: 0.345707\n",
      "Train Epoch: 1 [2000/6491 (31%)]\tLoss: 0.242377\n",
      "Train Epoch: 1 [3000/6491 (46%)]\tLoss: 0.200415\n",
      "Train Epoch: 1 [4000/6491 (62%)]\tLoss: 0.337314\n",
      "Train Epoch: 1 [5000/6491 (77%)]\tLoss: 0.346782\n",
      "Train Epoch: 1 [6000/6491 (92%)]\tLoss: 0.274622\n",
      "Train Epoch: 2 [0/6491 (0%)]\tLoss: 0.269574\n",
      "Train Epoch: 2 [1000/6491 (15%)]\tLoss: 0.252218\n",
      "Train Epoch: 2 [2000/6491 (31%)]\tLoss: 0.303494\n",
      "Train Epoch: 2 [3000/6491 (46%)]\tLoss: 0.183036\n",
      "Train Epoch: 2 [4000/6491 (62%)]\tLoss: 0.182576\n",
      "Train Epoch: 2 [5000/6491 (77%)]\tLoss: 0.366372\n",
      "Train Epoch: 2 [6000/6491 (92%)]\tLoss: 0.256761\n",
      "Train Epoch: 3 [0/6491 (0%)]\tLoss: 0.231673\n",
      "Train Epoch: 3 [1000/6491 (15%)]\tLoss: 0.219749\n",
      "Train Epoch: 3 [2000/6491 (31%)]\tLoss: 0.243562\n",
      "Train Epoch: 3 [3000/6491 (46%)]\tLoss: 0.398680\n",
      "Train Epoch: 3 [4000/6491 (62%)]\tLoss: 0.167527\n",
      "Train Epoch: 3 [5000/6491 (77%)]\tLoss: 0.175764\n",
      "Train Epoch: 3 [6000/6491 (92%)]\tLoss: 0.236968\n",
      "Train Epoch: 4 [0/6491 (0%)]\tLoss: 0.354827\n",
      "Train Epoch: 4 [1000/6491 (15%)]\tLoss: 0.265325\n",
      "Train Epoch: 4 [2000/6491 (31%)]\tLoss: 0.197263\n",
      "Train Epoch: 4 [3000/6491 (46%)]\tLoss: 0.260748\n",
      "Train Epoch: 4 [4000/6491 (62%)]\tLoss: 0.261554\n",
      "Train Epoch: 4 [5000/6491 (77%)]\tLoss: 0.221694\n",
      "Train Epoch: 4 [6000/6491 (92%)]\tLoss: 0.273218\n",
      "Train Epoch: 5 [0/6491 (0%)]\tLoss: 0.144429\n",
      "Train Epoch: 5 [1000/6491 (15%)]\tLoss: 0.251008\n",
      "Train Epoch: 5 [2000/6491 (31%)]\tLoss: 0.227881\n",
      "Train Epoch: 5 [3000/6491 (46%)]\tLoss: 0.240765\n",
      "Train Epoch: 5 [4000/6491 (62%)]\tLoss: 0.265392\n",
      "Train Epoch: 5 [5000/6491 (77%)]\tLoss: 0.232194\n",
      "Train Epoch: 5 [6000/6491 (92%)]\tLoss: 0.220125\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/14118 (0%)]\tLoss: 0.296183\n",
      "Train Epoch: 1 [1000/14118 (7%)]\tLoss: 0.186231\n",
      "Train Epoch: 1 [2000/14118 (14%)]\tLoss: 0.166038\n",
      "Train Epoch: 1 [3000/14118 (21%)]\tLoss: 0.204565\n",
      "Train Epoch: 1 [4000/14118 (28%)]\tLoss: 0.120200\n",
      "Train Epoch: 1 [5000/14118 (35%)]\tLoss: 0.303777\n",
      "Train Epoch: 1 [6000/14118 (42%)]\tLoss: 0.169818\n",
      "Train Epoch: 1 [7000/14118 (49%)]\tLoss: 0.068886\n",
      "Train Epoch: 1 [8000/14118 (56%)]\tLoss: 0.160879\n",
      "Train Epoch: 1 [9000/14118 (63%)]\tLoss: 0.136610\n",
      "Train Epoch: 1 [10000/14118 (70%)]\tLoss: 0.146582\n",
      "Train Epoch: 1 [11000/14118 (77%)]\tLoss: 0.126384\n",
      "Train Epoch: 1 [12000/14118 (85%)]\tLoss: 0.152027\n",
      "Train Epoch: 1 [13000/14118 (92%)]\tLoss: 0.220372\n",
      "Train Epoch: 1 [14000/14118 (99%)]\tLoss: 0.064279\n",
      "Train Epoch: 2 [0/14118 (0%)]\tLoss: 0.150311\n",
      "Train Epoch: 2 [1000/14118 (7%)]\tLoss: 0.190222\n",
      "Train Epoch: 2 [2000/14118 (14%)]\tLoss: 0.217726\n",
      "Train Epoch: 2 [3000/14118 (21%)]\tLoss: 0.143859\n",
      "Train Epoch: 2 [4000/14118 (28%)]\tLoss: 0.261832\n",
      "Train Epoch: 2 [5000/14118 (35%)]\tLoss: 0.191180\n",
      "Train Epoch: 2 [6000/14118 (42%)]\tLoss: 0.233125\n",
      "Train Epoch: 2 [7000/14118 (49%)]\tLoss: 0.175247\n",
      "Train Epoch: 2 [8000/14118 (56%)]\tLoss: 0.159445\n",
      "Train Epoch: 2 [9000/14118 (63%)]\tLoss: 0.137355\n",
      "Train Epoch: 2 [10000/14118 (70%)]\tLoss: 0.225075\n",
      "Train Epoch: 2 [11000/14118 (77%)]\tLoss: 0.085475\n",
      "Train Epoch: 2 [12000/14118 (85%)]\tLoss: 0.130989\n",
      "Train Epoch: 2 [13000/14118 (92%)]\tLoss: 0.128261\n",
      "Train Epoch: 2 [14000/14118 (99%)]\tLoss: 0.258756\n",
      "Train Epoch: 3 [0/14118 (0%)]\tLoss: 0.065915\n",
      "Train Epoch: 3 [1000/14118 (7%)]\tLoss: 0.158090\n",
      "Train Epoch: 3 [2000/14118 (14%)]\tLoss: 0.127642\n",
      "Train Epoch: 3 [3000/14118 (21%)]\tLoss: 0.203391\n",
      "Train Epoch: 3 [4000/14118 (28%)]\tLoss: 0.173031\n",
      "Train Epoch: 3 [5000/14118 (35%)]\tLoss: 0.098817\n",
      "Train Epoch: 3 [6000/14118 (42%)]\tLoss: 0.162238\n",
      "Train Epoch: 3 [7000/14118 (49%)]\tLoss: 0.185512\n",
      "Train Epoch: 3 [8000/14118 (56%)]\tLoss: 0.168475\n",
      "Train Epoch: 3 [9000/14118 (63%)]\tLoss: 0.126093\n",
      "Train Epoch: 3 [10000/14118 (70%)]\tLoss: 0.280815\n",
      "Train Epoch: 3 [11000/14118 (77%)]\tLoss: 0.296869\n",
      "Train Epoch: 3 [12000/14118 (85%)]\tLoss: 0.212110\n",
      "Train Epoch: 3 [13000/14118 (92%)]\tLoss: 0.158365\n",
      "Train Epoch: 3 [14000/14118 (99%)]\tLoss: 0.111878\n",
      "Train Epoch: 4 [0/14118 (0%)]\tLoss: 0.211343\n",
      "Train Epoch: 4 [1000/14118 (7%)]\tLoss: 0.184908\n",
      "Train Epoch: 4 [2000/14118 (14%)]\tLoss: 0.141817\n",
      "Train Epoch: 4 [3000/14118 (21%)]\tLoss: 0.085723\n",
      "Train Epoch: 4 [4000/14118 (28%)]\tLoss: 0.143339\n",
      "Train Epoch: 4 [5000/14118 (35%)]\tLoss: 0.133425\n",
      "Train Epoch: 4 [6000/14118 (42%)]\tLoss: 0.124944\n",
      "Train Epoch: 4 [7000/14118 (49%)]\tLoss: 0.315892\n",
      "Train Epoch: 4 [8000/14118 (56%)]\tLoss: 0.231499\n",
      "Train Epoch: 4 [9000/14118 (63%)]\tLoss: 0.146540\n",
      "Train Epoch: 4 [10000/14118 (70%)]\tLoss: 0.258255\n",
      "Train Epoch: 4 [11000/14118 (77%)]\tLoss: 0.137943\n",
      "Train Epoch: 4 [12000/14118 (85%)]\tLoss: 0.212633\n",
      "Train Epoch: 4 [13000/14118 (92%)]\tLoss: 0.211378\n",
      "Train Epoch: 4 [14000/14118 (99%)]\tLoss: 0.143804\n",
      "Train Epoch: 5 [0/14118 (0%)]\tLoss: 0.205307\n",
      "Train Epoch: 5 [1000/14118 (7%)]\tLoss: 0.111206\n",
      "Train Epoch: 5 [2000/14118 (14%)]\tLoss: 0.135949\n",
      "Train Epoch: 5 [3000/14118 (21%)]\tLoss: 0.229857\n",
      "Train Epoch: 5 [4000/14118 (28%)]\tLoss: 0.253147\n",
      "Train Epoch: 5 [5000/14118 (35%)]\tLoss: 0.238752\n",
      "Train Epoch: 5 [6000/14118 (42%)]\tLoss: 0.095321\n",
      "Train Epoch: 5 [7000/14118 (49%)]\tLoss: 0.217307\n",
      "Train Epoch: 5 [8000/14118 (56%)]\tLoss: 0.157170\n",
      "Train Epoch: 5 [9000/14118 (63%)]\tLoss: 0.077911\n",
      "Train Epoch: 5 [10000/14118 (70%)]\tLoss: 0.138633\n",
      "Train Epoch: 5 [11000/14118 (77%)]\tLoss: 0.168480\n",
      "Train Epoch: 5 [12000/14118 (85%)]\tLoss: 0.202516\n",
      "Train Epoch: 5 [13000/14118 (92%)]\tLoss: 0.107960\n",
      "Train Epoch: 5 [14000/14118 (99%)]\tLoss: 0.062555\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/9414 (0%)]\tLoss: 0.318962\n",
      "Train Epoch: 1 [1000/9414 (11%)]\tLoss: 0.292986\n",
      "Train Epoch: 1 [2000/9414 (21%)]\tLoss: 0.190780\n",
      "Train Epoch: 1 [3000/9414 (32%)]\tLoss: 0.240565\n",
      "Train Epoch: 1 [4000/9414 (42%)]\tLoss: 0.298740\n",
      "Train Epoch: 1 [5000/9414 (53%)]\tLoss: 0.193789\n",
      "Train Epoch: 1 [6000/9414 (63%)]\tLoss: 0.163024\n",
      "Train Epoch: 1 [7000/9414 (74%)]\tLoss: 0.219519\n",
      "Train Epoch: 1 [8000/9414 (84%)]\tLoss: 0.219416\n",
      "Train Epoch: 1 [9000/9414 (95%)]\tLoss: 0.284738\n",
      "Train Epoch: 2 [0/9414 (0%)]\tLoss: 0.137418\n",
      "Train Epoch: 2 [1000/9414 (11%)]\tLoss: 0.211954\n",
      "Train Epoch: 2 [2000/9414 (21%)]\tLoss: 0.224489\n",
      "Train Epoch: 2 [3000/9414 (32%)]\tLoss: 0.212157\n",
      "Train Epoch: 2 [4000/9414 (42%)]\tLoss: 0.263992\n",
      "Train Epoch: 2 [5000/9414 (53%)]\tLoss: 0.174675\n",
      "Train Epoch: 2 [6000/9414 (63%)]\tLoss: 0.209394\n",
      "Train Epoch: 2 [7000/9414 (74%)]\tLoss: 0.148320\n",
      "Train Epoch: 2 [8000/9414 (84%)]\tLoss: 0.202893\n",
      "Train Epoch: 2 [9000/9414 (95%)]\tLoss: 0.214214\n",
      "Train Epoch: 3 [0/9414 (0%)]\tLoss: 0.243763\n",
      "Train Epoch: 3 [1000/9414 (11%)]\tLoss: 0.145438\n",
      "Train Epoch: 3 [2000/9414 (21%)]\tLoss: 0.191113\n",
      "Train Epoch: 3 [3000/9414 (32%)]\tLoss: 0.133487\n",
      "Train Epoch: 3 [4000/9414 (42%)]\tLoss: 0.165201\n",
      "Train Epoch: 3 [5000/9414 (53%)]\tLoss: 0.284136\n",
      "Train Epoch: 3 [6000/9414 (63%)]\tLoss: 0.210880\n",
      "Train Epoch: 3 [7000/9414 (74%)]\tLoss: 0.228119\n",
      "Train Epoch: 3 [8000/9414 (84%)]\tLoss: 0.158378\n",
      "Train Epoch: 3 [9000/9414 (95%)]\tLoss: 0.197553\n",
      "Train Epoch: 4 [0/9414 (0%)]\tLoss: 0.278910\n",
      "Train Epoch: 4 [1000/9414 (11%)]\tLoss: 0.195137\n",
      "Train Epoch: 4 [2000/9414 (21%)]\tLoss: 0.173873\n",
      "Train Epoch: 4 [3000/9414 (32%)]\tLoss: 0.226970\n",
      "Train Epoch: 4 [4000/9414 (42%)]\tLoss: 0.230217\n",
      "Train Epoch: 4 [5000/9414 (53%)]\tLoss: 0.249996\n",
      "Train Epoch: 4 [6000/9414 (63%)]\tLoss: 0.150773\n",
      "Train Epoch: 4 [7000/9414 (74%)]\tLoss: 0.159835\n",
      "Train Epoch: 4 [8000/9414 (84%)]\tLoss: 0.234923\n",
      "Train Epoch: 4 [9000/9414 (95%)]\tLoss: 0.310664\n",
      "Train Epoch: 5 [0/9414 (0%)]\tLoss: 0.111583\n",
      "Train Epoch: 5 [1000/9414 (11%)]\tLoss: 0.186443\n",
      "Train Epoch: 5 [2000/9414 (21%)]\tLoss: 0.246089\n",
      "Train Epoch: 5 [3000/9414 (32%)]\tLoss: 0.223216\n",
      "Train Epoch: 5 [4000/9414 (42%)]\tLoss: 0.274169\n",
      "Train Epoch: 5 [5000/9414 (53%)]\tLoss: 0.092588\n",
      "Train Epoch: 5 [6000/9414 (63%)]\tLoss: 0.245429\n",
      "Train Epoch: 5 [7000/9414 (74%)]\tLoss: 0.255319\n",
      "Train Epoch: 5 [8000/9414 (84%)]\tLoss: 0.247780\n",
      "Train Epoch: 5 [9000/9414 (95%)]\tLoss: 0.208532\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "6\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.7031, Accuracy: 8614/10000 (86%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/8440 (0%)]\tLoss: 0.408179\n",
      "Train Epoch: 1 [1000/8440 (12%)]\tLoss: 0.400983\n",
      "Train Epoch: 1 [2000/8440 (24%)]\tLoss: 0.220802\n",
      "Train Epoch: 1 [3000/8440 (35%)]\tLoss: 0.212363\n",
      "Train Epoch: 1 [4000/8440 (47%)]\tLoss: 0.260193\n",
      "Train Epoch: 1 [5000/8440 (59%)]\tLoss: 0.321086\n",
      "Train Epoch: 1 [6000/8440 (71%)]\tLoss: 0.158011\n",
      "Train Epoch: 1 [7000/8440 (82%)]\tLoss: 0.221997\n",
      "Train Epoch: 1 [8000/8440 (94%)]\tLoss: 0.282425\n",
      "Train Epoch: 2 [0/8440 (0%)]\tLoss: 0.238975\n",
      "Train Epoch: 2 [1000/8440 (12%)]\tLoss: 0.299263\n",
      "Train Epoch: 2 [2000/8440 (24%)]\tLoss: 0.314092\n",
      "Train Epoch: 2 [3000/8440 (35%)]\tLoss: 0.177820\n",
      "Train Epoch: 2 [4000/8440 (47%)]\tLoss: 0.232576\n",
      "Train Epoch: 2 [5000/8440 (59%)]\tLoss: 0.290684\n",
      "Train Epoch: 2 [6000/8440 (71%)]\tLoss: 0.193394\n",
      "Train Epoch: 2 [7000/8440 (82%)]\tLoss: 0.267171\n",
      "Train Epoch: 2 [8000/8440 (94%)]\tLoss: 0.214948\n",
      "Train Epoch: 3 [0/8440 (0%)]\tLoss: 0.230217\n",
      "Train Epoch: 3 [1000/8440 (12%)]\tLoss: 0.154446\n",
      "Train Epoch: 3 [2000/8440 (24%)]\tLoss: 0.181144\n",
      "Train Epoch: 3 [3000/8440 (35%)]\tLoss: 0.162517\n",
      "Train Epoch: 3 [4000/8440 (47%)]\tLoss: 0.197834\n",
      "Train Epoch: 3 [5000/8440 (59%)]\tLoss: 0.177287\n",
      "Train Epoch: 3 [6000/8440 (71%)]\tLoss: 0.508082\n",
      "Train Epoch: 3 [7000/8440 (82%)]\tLoss: 0.337980\n",
      "Train Epoch: 3 [8000/8440 (94%)]\tLoss: 0.092368\n",
      "Train Epoch: 4 [0/8440 (0%)]\tLoss: 0.206197\n",
      "Train Epoch: 4 [1000/8440 (12%)]\tLoss: 0.301079\n",
      "Train Epoch: 4 [2000/8440 (24%)]\tLoss: 0.116464\n",
      "Train Epoch: 4 [3000/8440 (35%)]\tLoss: 0.263140\n",
      "Train Epoch: 4 [4000/8440 (47%)]\tLoss: 0.141212\n",
      "Train Epoch: 4 [5000/8440 (59%)]\tLoss: 0.245916\n",
      "Train Epoch: 4 [6000/8440 (71%)]\tLoss: 0.179114\n",
      "Train Epoch: 4 [7000/8440 (82%)]\tLoss: 0.193618\n",
      "Train Epoch: 4 [8000/8440 (94%)]\tLoss: 0.236399\n",
      "Train Epoch: 5 [0/8440 (0%)]\tLoss: 0.187666\n",
      "Train Epoch: 5 [1000/8440 (12%)]\tLoss: 0.165560\n",
      "Train Epoch: 5 [2000/8440 (24%)]\tLoss: 0.200410\n",
      "Train Epoch: 5 [3000/8440 (35%)]\tLoss: 0.165663\n",
      "Train Epoch: 5 [4000/8440 (47%)]\tLoss: 0.237979\n",
      "Train Epoch: 5 [5000/8440 (59%)]\tLoss: 0.220764\n",
      "Train Epoch: 5 [6000/8440 (71%)]\tLoss: 0.167336\n",
      "Train Epoch: 5 [7000/8440 (82%)]\tLoss: 0.202168\n",
      "Train Epoch: 5 [8000/8440 (94%)]\tLoss: 0.291661\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11811 (0%)]\tLoss: 0.273663\n",
      "Train Epoch: 1 [1000/11811 (8%)]\tLoss: 0.223090\n",
      "Train Epoch: 1 [2000/11811 (17%)]\tLoss: 0.178892\n",
      "Train Epoch: 1 [3000/11811 (25%)]\tLoss: 0.130719\n",
      "Train Epoch: 1 [4000/11811 (34%)]\tLoss: 0.170707\n",
      "Train Epoch: 1 [5000/11811 (42%)]\tLoss: 0.107381\n",
      "Train Epoch: 1 [6000/11811 (50%)]\tLoss: 0.038098\n",
      "Train Epoch: 1 [7000/11811 (59%)]\tLoss: 0.159769\n",
      "Train Epoch: 1 [8000/11811 (67%)]\tLoss: 0.127741\n",
      "Train Epoch: 1 [9000/11811 (76%)]\tLoss: 0.076596\n",
      "Train Epoch: 1 [10000/11811 (84%)]\tLoss: 0.047896\n",
      "Train Epoch: 1 [11000/11811 (92%)]\tLoss: 0.084918\n",
      "Train Epoch: 2 [0/11811 (0%)]\tLoss: 0.100230\n",
      "Train Epoch: 2 [1000/11811 (8%)]\tLoss: 0.049594\n",
      "Train Epoch: 2 [2000/11811 (17%)]\tLoss: 0.087886\n",
      "Train Epoch: 2 [3000/11811 (25%)]\tLoss: 0.083025\n",
      "Train Epoch: 2 [4000/11811 (34%)]\tLoss: 0.060478\n",
      "Train Epoch: 2 [5000/11811 (42%)]\tLoss: 0.100557\n",
      "Train Epoch: 2 [6000/11811 (50%)]\tLoss: 0.056724\n",
      "Train Epoch: 2 [7000/11811 (59%)]\tLoss: 0.104068\n",
      "Train Epoch: 2 [8000/11811 (67%)]\tLoss: 0.085452\n",
      "Train Epoch: 2 [9000/11811 (76%)]\tLoss: 0.132804\n",
      "Train Epoch: 2 [10000/11811 (84%)]\tLoss: 0.084357\n",
      "Train Epoch: 2 [11000/11811 (92%)]\tLoss: 0.202552\n",
      "Train Epoch: 3 [0/11811 (0%)]\tLoss: 0.120943\n",
      "Train Epoch: 3 [1000/11811 (8%)]\tLoss: 0.093858\n",
      "Train Epoch: 3 [2000/11811 (17%)]\tLoss: 0.105088\n",
      "Train Epoch: 3 [3000/11811 (25%)]\tLoss: 0.147381\n",
      "Train Epoch: 3 [4000/11811 (34%)]\tLoss: 0.104703\n",
      "Train Epoch: 3 [5000/11811 (42%)]\tLoss: 0.034460\n",
      "Train Epoch: 3 [6000/11811 (50%)]\tLoss: 0.148285\n",
      "Train Epoch: 3 [7000/11811 (59%)]\tLoss: 0.115439\n",
      "Train Epoch: 3 [8000/11811 (67%)]\tLoss: 0.142220\n",
      "Train Epoch: 3 [9000/11811 (76%)]\tLoss: 0.069121\n",
      "Train Epoch: 3 [10000/11811 (84%)]\tLoss: 0.128379\n",
      "Train Epoch: 3 [11000/11811 (92%)]\tLoss: 0.088079\n",
      "Train Epoch: 4 [0/11811 (0%)]\tLoss: 0.171610\n",
      "Train Epoch: 4 [1000/11811 (8%)]\tLoss: 0.068845\n",
      "Train Epoch: 4 [2000/11811 (17%)]\tLoss: 0.102538\n",
      "Train Epoch: 4 [3000/11811 (25%)]\tLoss: 0.103440\n",
      "Train Epoch: 4 [4000/11811 (34%)]\tLoss: 0.031206\n",
      "Train Epoch: 4 [5000/11811 (42%)]\tLoss: 0.124398\n",
      "Train Epoch: 4 [6000/11811 (50%)]\tLoss: 0.119430\n",
      "Train Epoch: 4 [7000/11811 (59%)]\tLoss: 0.077815\n",
      "Train Epoch: 4 [8000/11811 (67%)]\tLoss: 0.055030\n",
      "Train Epoch: 4 [9000/11811 (76%)]\tLoss: 0.069158\n",
      "Train Epoch: 4 [10000/11811 (84%)]\tLoss: 0.052555\n",
      "Train Epoch: 4 [11000/11811 (92%)]\tLoss: 0.112177\n",
      "Train Epoch: 5 [0/11811 (0%)]\tLoss: 0.117656\n",
      "Train Epoch: 5 [1000/11811 (8%)]\tLoss: 0.066220\n",
      "Train Epoch: 5 [2000/11811 (17%)]\tLoss: 0.024467\n",
      "Train Epoch: 5 [3000/11811 (25%)]\tLoss: 0.098424\n",
      "Train Epoch: 5 [4000/11811 (34%)]\tLoss: 0.129771\n",
      "Train Epoch: 5 [5000/11811 (42%)]\tLoss: 0.067862\n",
      "Train Epoch: 5 [6000/11811 (50%)]\tLoss: 0.039972\n",
      "Train Epoch: 5 [7000/11811 (59%)]\tLoss: 0.040658\n",
      "Train Epoch: 5 [8000/11811 (67%)]\tLoss: 0.080277\n",
      "Train Epoch: 5 [9000/11811 (76%)]\tLoss: 0.036161\n",
      "Train Epoch: 5 [10000/11811 (84%)]\tLoss: 0.066996\n",
      "Train Epoch: 5 [11000/11811 (92%)]\tLoss: 0.061383\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/9726 (0%)]\tLoss: 0.296897\n",
      "Train Epoch: 1 [1000/9726 (10%)]\tLoss: 0.233867\n",
      "Train Epoch: 1 [2000/9726 (20%)]\tLoss: 0.166874\n",
      "Train Epoch: 1 [3000/9726 (31%)]\tLoss: 0.161868\n",
      "Train Epoch: 1 [4000/9726 (41%)]\tLoss: 0.155909\n",
      "Train Epoch: 1 [5000/9726 (51%)]\tLoss: 0.255298\n",
      "Train Epoch: 1 [6000/9726 (61%)]\tLoss: 0.185199\n",
      "Train Epoch: 1 [7000/9726 (71%)]\tLoss: 0.269725\n",
      "Train Epoch: 1 [8000/9726 (82%)]\tLoss: 0.280971\n",
      "Train Epoch: 1 [9000/9726 (92%)]\tLoss: 0.157468\n",
      "Train Epoch: 2 [0/9726 (0%)]\tLoss: 0.229275\n",
      "Train Epoch: 2 [1000/9726 (10%)]\tLoss: 0.132395\n",
      "Train Epoch: 2 [2000/9726 (20%)]\tLoss: 0.186006\n",
      "Train Epoch: 2 [3000/9726 (31%)]\tLoss: 0.220717\n",
      "Train Epoch: 2 [4000/9726 (41%)]\tLoss: 0.155087\n",
      "Train Epoch: 2 [5000/9726 (51%)]\tLoss: 0.227235\n",
      "Train Epoch: 2 [6000/9726 (61%)]\tLoss: 0.188286\n",
      "Train Epoch: 2 [7000/9726 (71%)]\tLoss: 0.166413\n",
      "Train Epoch: 2 [8000/9726 (82%)]\tLoss: 0.179524\n",
      "Train Epoch: 2 [9000/9726 (92%)]\tLoss: 0.146222\n",
      "Train Epoch: 3 [0/9726 (0%)]\tLoss: 0.201036\n",
      "Train Epoch: 3 [1000/9726 (10%)]\tLoss: 0.169037\n",
      "Train Epoch: 3 [2000/9726 (20%)]\tLoss: 0.230592\n",
      "Train Epoch: 3 [3000/9726 (31%)]\tLoss: 0.195425\n",
      "Train Epoch: 3 [4000/9726 (41%)]\tLoss: 0.142170\n",
      "Train Epoch: 3 [5000/9726 (51%)]\tLoss: 0.064275\n",
      "Train Epoch: 3 [6000/9726 (61%)]\tLoss: 0.231705\n",
      "Train Epoch: 3 [7000/9726 (71%)]\tLoss: 0.195997\n",
      "Train Epoch: 3 [8000/9726 (82%)]\tLoss: 0.215546\n",
      "Train Epoch: 3 [9000/9726 (92%)]\tLoss: 0.261978\n",
      "Train Epoch: 4 [0/9726 (0%)]\tLoss: 0.174388\n",
      "Train Epoch: 4 [1000/9726 (10%)]\tLoss: 0.115766\n",
      "Train Epoch: 4 [2000/9726 (20%)]\tLoss: 0.124705\n",
      "Train Epoch: 4 [3000/9726 (31%)]\tLoss: 0.240592\n",
      "Train Epoch: 4 [4000/9726 (41%)]\tLoss: 0.196972\n",
      "Train Epoch: 4 [5000/9726 (51%)]\tLoss: 0.134310\n",
      "Train Epoch: 4 [6000/9726 (61%)]\tLoss: 0.190429\n",
      "Train Epoch: 4 [7000/9726 (71%)]\tLoss: 0.180441\n",
      "Train Epoch: 4 [8000/9726 (82%)]\tLoss: 0.174345\n",
      "Train Epoch: 4 [9000/9726 (92%)]\tLoss: 0.165846\n",
      "Train Epoch: 5 [0/9726 (0%)]\tLoss: 0.095006\n",
      "Train Epoch: 5 [1000/9726 (10%)]\tLoss: 0.116794\n",
      "Train Epoch: 5 [2000/9726 (20%)]\tLoss: 0.138358\n",
      "Train Epoch: 5 [3000/9726 (31%)]\tLoss: 0.134114\n",
      "Train Epoch: 5 [4000/9726 (41%)]\tLoss: 0.171337\n",
      "Train Epoch: 5 [5000/9726 (51%)]\tLoss: 0.067835\n",
      "Train Epoch: 5 [6000/9726 (61%)]\tLoss: 0.120835\n",
      "Train Epoch: 5 [7000/9726 (71%)]\tLoss: 0.093748\n",
      "Train Epoch: 5 [8000/9726 (82%)]\tLoss: 0.204435\n",
      "Train Epoch: 5 [9000/9726 (92%)]\tLoss: 0.131670\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/6491 (0%)]\tLoss: 0.344628\n",
      "Train Epoch: 1 [1000/6491 (15%)]\tLoss: 0.244406\n",
      "Train Epoch: 1 [2000/6491 (31%)]\tLoss: 0.184402\n",
      "Train Epoch: 1 [3000/6491 (46%)]\tLoss: 0.291337\n",
      "Train Epoch: 1 [4000/6491 (62%)]\tLoss: 0.287594\n",
      "Train Epoch: 1 [5000/6491 (77%)]\tLoss: 0.177552\n",
      "Train Epoch: 1 [6000/6491 (92%)]\tLoss: 0.220754\n",
      "Train Epoch: 2 [0/6491 (0%)]\tLoss: 0.195122\n",
      "Train Epoch: 2 [1000/6491 (15%)]\tLoss: 0.297966\n",
      "Train Epoch: 2 [2000/6491 (31%)]\tLoss: 0.279289\n",
      "Train Epoch: 2 [3000/6491 (46%)]\tLoss: 0.200041\n",
      "Train Epoch: 2 [4000/6491 (62%)]\tLoss: 0.262956\n",
      "Train Epoch: 2 [5000/6491 (77%)]\tLoss: 0.261471\n",
      "Train Epoch: 2 [6000/6491 (92%)]\tLoss: 0.208038\n",
      "Train Epoch: 3 [0/6491 (0%)]\tLoss: 0.215432\n",
      "Train Epoch: 3 [1000/6491 (15%)]\tLoss: 0.271725\n",
      "Train Epoch: 3 [2000/6491 (31%)]\tLoss: 0.294410\n",
      "Train Epoch: 3 [3000/6491 (46%)]\tLoss: 0.316511\n",
      "Train Epoch: 3 [4000/6491 (62%)]\tLoss: 0.246130\n",
      "Train Epoch: 3 [5000/6491 (77%)]\tLoss: 0.168868\n",
      "Train Epoch: 3 [6000/6491 (92%)]\tLoss: 0.175173\n",
      "Train Epoch: 4 [0/6491 (0%)]\tLoss: 0.149490\n",
      "Train Epoch: 4 [1000/6491 (15%)]\tLoss: 0.203693\n",
      "Train Epoch: 4 [2000/6491 (31%)]\tLoss: 0.242194\n",
      "Train Epoch: 4 [3000/6491 (46%)]\tLoss: 0.209158\n",
      "Train Epoch: 4 [4000/6491 (62%)]\tLoss: 0.266355\n",
      "Train Epoch: 4 [5000/6491 (77%)]\tLoss: 0.207940\n",
      "Train Epoch: 4 [6000/6491 (92%)]\tLoss: 0.274656\n",
      "Train Epoch: 5 [0/6491 (0%)]\tLoss: 0.255941\n",
      "Train Epoch: 5 [1000/6491 (15%)]\tLoss: 0.155502\n",
      "Train Epoch: 5 [2000/6491 (31%)]\tLoss: 0.335534\n",
      "Train Epoch: 5 [3000/6491 (46%)]\tLoss: 0.268294\n",
      "Train Epoch: 5 [4000/6491 (62%)]\tLoss: 0.210725\n",
      "Train Epoch: 5 [5000/6491 (77%)]\tLoss: 0.270559\n",
      "Train Epoch: 5 [6000/6491 (92%)]\tLoss: 0.245382\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/14118 (0%)]\tLoss: 0.260498\n",
      "Train Epoch: 1 [1000/14118 (7%)]\tLoss: 0.127230\n",
      "Train Epoch: 1 [2000/14118 (14%)]\tLoss: 0.139531\n",
      "Train Epoch: 1 [3000/14118 (21%)]\tLoss: 0.095021\n",
      "Train Epoch: 1 [4000/14118 (28%)]\tLoss: 0.181225\n",
      "Train Epoch: 1 [5000/14118 (35%)]\tLoss: 0.197480\n",
      "Train Epoch: 1 [6000/14118 (42%)]\tLoss: 0.210352\n",
      "Train Epoch: 1 [7000/14118 (49%)]\tLoss: 0.082222\n",
      "Train Epoch: 1 [8000/14118 (56%)]\tLoss: 0.241973\n",
      "Train Epoch: 1 [9000/14118 (63%)]\tLoss: 0.076509\n",
      "Train Epoch: 1 [10000/14118 (70%)]\tLoss: 0.119454\n",
      "Train Epoch: 1 [11000/14118 (77%)]\tLoss: 0.244956\n",
      "Train Epoch: 1 [12000/14118 (85%)]\tLoss: 0.219535\n",
      "Train Epoch: 1 [13000/14118 (92%)]\tLoss: 0.237761\n",
      "Train Epoch: 1 [14000/14118 (99%)]\tLoss: 0.113737\n",
      "Train Epoch: 2 [0/14118 (0%)]\tLoss: 0.189592\n",
      "Train Epoch: 2 [1000/14118 (7%)]\tLoss: 0.229738\n",
      "Train Epoch: 2 [2000/14118 (14%)]\tLoss: 0.100228\n",
      "Train Epoch: 2 [3000/14118 (21%)]\tLoss: 0.235812\n",
      "Train Epoch: 2 [4000/14118 (28%)]\tLoss: 0.101198\n",
      "Train Epoch: 2 [5000/14118 (35%)]\tLoss: 0.108562\n",
      "Train Epoch: 2 [6000/14118 (42%)]\tLoss: 0.231074\n",
      "Train Epoch: 2 [7000/14118 (49%)]\tLoss: 0.095449\n",
      "Train Epoch: 2 [8000/14118 (56%)]\tLoss: 0.276107\n",
      "Train Epoch: 2 [9000/14118 (63%)]\tLoss: 0.112565\n",
      "Train Epoch: 2 [10000/14118 (70%)]\tLoss: 0.199332\n",
      "Train Epoch: 2 [11000/14118 (77%)]\tLoss: 0.159386\n",
      "Train Epoch: 2 [12000/14118 (85%)]\tLoss: 0.230660\n",
      "Train Epoch: 2 [13000/14118 (92%)]\tLoss: 0.188965\n",
      "Train Epoch: 2 [14000/14118 (99%)]\tLoss: 0.212313\n",
      "Train Epoch: 3 [0/14118 (0%)]\tLoss: 0.159109\n",
      "Train Epoch: 3 [1000/14118 (7%)]\tLoss: 0.222661\n",
      "Train Epoch: 3 [2000/14118 (14%)]\tLoss: 0.079971\n",
      "Train Epoch: 3 [3000/14118 (21%)]\tLoss: 0.123928\n",
      "Train Epoch: 3 [4000/14118 (28%)]\tLoss: 0.174926\n",
      "Train Epoch: 3 [5000/14118 (35%)]\tLoss: 0.176642\n",
      "Train Epoch: 3 [6000/14118 (42%)]\tLoss: 0.172308\n",
      "Train Epoch: 3 [7000/14118 (49%)]\tLoss: 0.259677\n",
      "Train Epoch: 3 [8000/14118 (56%)]\tLoss: 0.119285\n",
      "Train Epoch: 3 [9000/14118 (63%)]\tLoss: 0.142541\n",
      "Train Epoch: 3 [10000/14118 (70%)]\tLoss: 0.210527\n",
      "Train Epoch: 3 [11000/14118 (77%)]\tLoss: 0.274626\n",
      "Train Epoch: 3 [12000/14118 (85%)]\tLoss: 0.144453\n",
      "Train Epoch: 3 [13000/14118 (92%)]\tLoss: 0.165198\n",
      "Train Epoch: 3 [14000/14118 (99%)]\tLoss: 0.046332\n",
      "Train Epoch: 4 [0/14118 (0%)]\tLoss: 0.102401\n",
      "Train Epoch: 4 [1000/14118 (7%)]\tLoss: 0.065140\n",
      "Train Epoch: 4 [2000/14118 (14%)]\tLoss: 0.131001\n",
      "Train Epoch: 4 [3000/14118 (21%)]\tLoss: 0.134571\n",
      "Train Epoch: 4 [4000/14118 (28%)]\tLoss: 0.149122\n",
      "Train Epoch: 4 [5000/14118 (35%)]\tLoss: 0.139738\n",
      "Train Epoch: 4 [6000/14118 (42%)]\tLoss: 0.110510\n",
      "Train Epoch: 4 [7000/14118 (49%)]\tLoss: 0.160733\n",
      "Train Epoch: 4 [8000/14118 (56%)]\tLoss: 0.203142\n",
      "Train Epoch: 4 [9000/14118 (63%)]\tLoss: 0.107936\n",
      "Train Epoch: 4 [10000/14118 (70%)]\tLoss: 0.145700\n",
      "Train Epoch: 4 [11000/14118 (77%)]\tLoss: 0.088601\n",
      "Train Epoch: 4 [12000/14118 (85%)]\tLoss: 0.077259\n",
      "Train Epoch: 4 [13000/14118 (92%)]\tLoss: 0.225962\n",
      "Train Epoch: 4 [14000/14118 (99%)]\tLoss: 0.145952\n",
      "Train Epoch: 5 [0/14118 (0%)]\tLoss: 0.223738\n",
      "Train Epoch: 5 [1000/14118 (7%)]\tLoss: 0.137383\n",
      "Train Epoch: 5 [2000/14118 (14%)]\tLoss: 0.077817\n",
      "Train Epoch: 5 [3000/14118 (21%)]\tLoss: 0.093719\n",
      "Train Epoch: 5 [4000/14118 (28%)]\tLoss: 0.199635\n",
      "Train Epoch: 5 [5000/14118 (35%)]\tLoss: 0.148703\n",
      "Train Epoch: 5 [6000/14118 (42%)]\tLoss: 0.209984\n",
      "Train Epoch: 5 [7000/14118 (49%)]\tLoss: 0.244300\n",
      "Train Epoch: 5 [8000/14118 (56%)]\tLoss: 0.096465\n",
      "Train Epoch: 5 [9000/14118 (63%)]\tLoss: 0.279193\n",
      "Train Epoch: 5 [10000/14118 (70%)]\tLoss: 0.080540\n",
      "Train Epoch: 5 [11000/14118 (77%)]\tLoss: 0.137827\n",
      "Train Epoch: 5 [12000/14118 (85%)]\tLoss: 0.134898\n",
      "Train Epoch: 5 [13000/14118 (92%)]\tLoss: 0.159616\n",
      "Train Epoch: 5 [14000/14118 (99%)]\tLoss: 0.166873\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/9414 (0%)]\tLoss: 0.235057\n",
      "Train Epoch: 1 [1000/9414 (11%)]\tLoss: 0.226697\n",
      "Train Epoch: 1 [2000/9414 (21%)]\tLoss: 0.274143\n",
      "Train Epoch: 1 [3000/9414 (32%)]\tLoss: 0.166310\n",
      "Train Epoch: 1 [4000/9414 (42%)]\tLoss: 0.202072\n",
      "Train Epoch: 1 [5000/9414 (53%)]\tLoss: 0.188901\n",
      "Train Epoch: 1 [6000/9414 (63%)]\tLoss: 0.182440\n",
      "Train Epoch: 1 [7000/9414 (74%)]\tLoss: 0.151172\n",
      "Train Epoch: 1 [8000/9414 (84%)]\tLoss: 0.214119\n",
      "Train Epoch: 1 [9000/9414 (95%)]\tLoss: 0.215931\n",
      "Train Epoch: 2 [0/9414 (0%)]\tLoss: 0.167972\n",
      "Train Epoch: 2 [1000/9414 (11%)]\tLoss: 0.234202\n",
      "Train Epoch: 2 [2000/9414 (21%)]\tLoss: 0.389787\n",
      "Train Epoch: 2 [3000/9414 (32%)]\tLoss: 0.179509\n",
      "Train Epoch: 2 [4000/9414 (42%)]\tLoss: 0.258813\n",
      "Train Epoch: 2 [5000/9414 (53%)]\tLoss: 0.122610\n",
      "Train Epoch: 2 [6000/9414 (63%)]\tLoss: 0.358827\n",
      "Train Epoch: 2 [7000/9414 (74%)]\tLoss: 0.155697\n",
      "Train Epoch: 2 [8000/9414 (84%)]\tLoss: 0.099326\n",
      "Train Epoch: 2 [9000/9414 (95%)]\tLoss: 0.179096\n",
      "Train Epoch: 3 [0/9414 (0%)]\tLoss: 0.168585\n",
      "Train Epoch: 3 [1000/9414 (11%)]\tLoss: 0.116696\n",
      "Train Epoch: 3 [2000/9414 (21%)]\tLoss: 0.134751\n",
      "Train Epoch: 3 [3000/9414 (32%)]\tLoss: 0.173421\n",
      "Train Epoch: 3 [4000/9414 (42%)]\tLoss: 0.124811\n",
      "Train Epoch: 3 [5000/9414 (53%)]\tLoss: 0.279538\n",
      "Train Epoch: 3 [6000/9414 (63%)]\tLoss: 0.226350\n",
      "Train Epoch: 3 [7000/9414 (74%)]\tLoss: 0.250614\n",
      "Train Epoch: 3 [8000/9414 (84%)]\tLoss: 0.194929\n",
      "Train Epoch: 3 [9000/9414 (95%)]\tLoss: 0.233819\n",
      "Train Epoch: 4 [0/9414 (0%)]\tLoss: 0.219695\n",
      "Train Epoch: 4 [1000/9414 (11%)]\tLoss: 0.192624\n",
      "Train Epoch: 4 [2000/9414 (21%)]\tLoss: 0.165301\n",
      "Train Epoch: 4 [3000/9414 (32%)]\tLoss: 0.161615\n",
      "Train Epoch: 4 [4000/9414 (42%)]\tLoss: 0.230776\n",
      "Train Epoch: 4 [5000/9414 (53%)]\tLoss: 0.176376\n",
      "Train Epoch: 4 [6000/9414 (63%)]\tLoss: 0.206736\n",
      "Train Epoch: 4 [7000/9414 (74%)]\tLoss: 0.358521\n",
      "Train Epoch: 4 [8000/9414 (84%)]\tLoss: 0.192278\n",
      "Train Epoch: 4 [9000/9414 (95%)]\tLoss: 0.262000\n",
      "Train Epoch: 5 [0/9414 (0%)]\tLoss: 0.251898\n",
      "Train Epoch: 5 [1000/9414 (11%)]\tLoss: 0.276282\n",
      "Train Epoch: 5 [2000/9414 (21%)]\tLoss: 0.145261\n",
      "Train Epoch: 5 [3000/9414 (32%)]\tLoss: 0.185001\n",
      "Train Epoch: 5 [4000/9414 (42%)]\tLoss: 0.267207\n",
      "Train Epoch: 5 [5000/9414 (53%)]\tLoss: 0.185083\n",
      "Train Epoch: 5 [6000/9414 (63%)]\tLoss: 0.190969\n",
      "Train Epoch: 5 [7000/9414 (74%)]\tLoss: 0.170001\n",
      "Train Epoch: 5 [8000/9414 (84%)]\tLoss: 0.172461\n",
      "Train Epoch: 5 [9000/9414 (95%)]\tLoss: 0.141692\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "6\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.6796, Accuracy: 8674/10000 (87%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/8440 (0%)]\tLoss: 0.293965\n",
      "Train Epoch: 1 [1000/8440 (12%)]\tLoss: 0.354523\n",
      "Train Epoch: 1 [2000/8440 (24%)]\tLoss: 0.191145\n",
      "Train Epoch: 1 [3000/8440 (35%)]\tLoss: 0.296287\n",
      "Train Epoch: 1 [4000/8440 (47%)]\tLoss: 0.171728\n",
      "Train Epoch: 1 [5000/8440 (59%)]\tLoss: 0.257542\n",
      "Train Epoch: 1 [6000/8440 (71%)]\tLoss: 0.378368\n",
      "Train Epoch: 1 [7000/8440 (82%)]\tLoss: 0.440469\n",
      "Train Epoch: 1 [8000/8440 (94%)]\tLoss: 0.197700\n",
      "Train Epoch: 2 [0/8440 (0%)]\tLoss: 0.266528\n",
      "Train Epoch: 2 [1000/8440 (12%)]\tLoss: 0.084427\n",
      "Train Epoch: 2 [2000/8440 (24%)]\tLoss: 0.212041\n",
      "Train Epoch: 2 [3000/8440 (35%)]\tLoss: 0.295419\n",
      "Train Epoch: 2 [4000/8440 (47%)]\tLoss: 0.369216\n",
      "Train Epoch: 2 [5000/8440 (59%)]\tLoss: 0.149985\n",
      "Train Epoch: 2 [6000/8440 (71%)]\tLoss: 0.229653\n",
      "Train Epoch: 2 [7000/8440 (82%)]\tLoss: 0.307942\n",
      "Train Epoch: 2 [8000/8440 (94%)]\tLoss: 0.248059\n",
      "Train Epoch: 3 [0/8440 (0%)]\tLoss: 0.168036\n",
      "Train Epoch: 3 [1000/8440 (12%)]\tLoss: 0.259798\n",
      "Train Epoch: 3 [2000/8440 (24%)]\tLoss: 0.166369\n",
      "Train Epoch: 3 [3000/8440 (35%)]\tLoss: 0.340062\n",
      "Train Epoch: 3 [4000/8440 (47%)]\tLoss: 0.190817\n",
      "Train Epoch: 3 [5000/8440 (59%)]\tLoss: 0.205806\n",
      "Train Epoch: 3 [6000/8440 (71%)]\tLoss: 0.369439\n",
      "Train Epoch: 3 [7000/8440 (82%)]\tLoss: 0.241249\n",
      "Train Epoch: 3 [8000/8440 (94%)]\tLoss: 0.180710\n",
      "Train Epoch: 4 [0/8440 (0%)]\tLoss: 0.207692\n",
      "Train Epoch: 4 [1000/8440 (12%)]\tLoss: 0.253573\n",
      "Train Epoch: 4 [2000/8440 (24%)]\tLoss: 0.189546\n",
      "Train Epoch: 4 [3000/8440 (35%)]\tLoss: 0.191235\n",
      "Train Epoch: 4 [4000/8440 (47%)]\tLoss: 0.274946\n",
      "Train Epoch: 4 [5000/8440 (59%)]\tLoss: 0.240179\n",
      "Train Epoch: 4 [6000/8440 (71%)]\tLoss: 0.174883\n",
      "Train Epoch: 4 [7000/8440 (82%)]\tLoss: 0.231933\n",
      "Train Epoch: 4 [8000/8440 (94%)]\tLoss: 0.225747\n",
      "Train Epoch: 5 [0/8440 (0%)]\tLoss: 0.171624\n",
      "Train Epoch: 5 [1000/8440 (12%)]\tLoss: 0.214997\n",
      "Train Epoch: 5 [2000/8440 (24%)]\tLoss: 0.132181\n",
      "Train Epoch: 5 [3000/8440 (35%)]\tLoss: 0.174333\n",
      "Train Epoch: 5 [4000/8440 (47%)]\tLoss: 0.217639\n",
      "Train Epoch: 5 [5000/8440 (59%)]\tLoss: 0.257770\n",
      "Train Epoch: 5 [6000/8440 (71%)]\tLoss: 0.210964\n",
      "Train Epoch: 5 [7000/8440 (82%)]\tLoss: 0.234635\n",
      "Train Epoch: 5 [8000/8440 (94%)]\tLoss: 0.182305\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11811 (0%)]\tLoss: 0.184476\n",
      "Train Epoch: 1 [1000/11811 (8%)]\tLoss: 0.144998\n",
      "Train Epoch: 1 [2000/11811 (17%)]\tLoss: 0.157382\n",
      "Train Epoch: 1 [3000/11811 (25%)]\tLoss: 0.053315\n",
      "Train Epoch: 1 [4000/11811 (34%)]\tLoss: 0.064099\n",
      "Train Epoch: 1 [5000/11811 (42%)]\tLoss: 0.134233\n",
      "Train Epoch: 1 [6000/11811 (50%)]\tLoss: 0.216880\n",
      "Train Epoch: 1 [7000/11811 (59%)]\tLoss: 0.176608\n",
      "Train Epoch: 1 [8000/11811 (67%)]\tLoss: 0.133190\n",
      "Train Epoch: 1 [9000/11811 (76%)]\tLoss: 0.154281\n",
      "Train Epoch: 1 [10000/11811 (84%)]\tLoss: 0.067353\n",
      "Train Epoch: 1 [11000/11811 (92%)]\tLoss: 0.129507\n",
      "Train Epoch: 2 [0/11811 (0%)]\tLoss: 0.037319\n",
      "Train Epoch: 2 [1000/11811 (8%)]\tLoss: 0.141050\n",
      "Train Epoch: 2 [2000/11811 (17%)]\tLoss: 0.064456\n",
      "Train Epoch: 2 [3000/11811 (25%)]\tLoss: 0.081513\n",
      "Train Epoch: 2 [4000/11811 (34%)]\tLoss: 0.105472\n",
      "Train Epoch: 2 [5000/11811 (42%)]\tLoss: 0.028190\n",
      "Train Epoch: 2 [6000/11811 (50%)]\tLoss: 0.132969\n",
      "Train Epoch: 2 [7000/11811 (59%)]\tLoss: 0.067458\n",
      "Train Epoch: 2 [8000/11811 (67%)]\tLoss: 0.061449\n",
      "Train Epoch: 2 [9000/11811 (76%)]\tLoss: 0.060661\n",
      "Train Epoch: 2 [10000/11811 (84%)]\tLoss: 0.091326\n",
      "Train Epoch: 2 [11000/11811 (92%)]\tLoss: 0.059441\n",
      "Train Epoch: 3 [0/11811 (0%)]\tLoss: 0.088398\n",
      "Train Epoch: 3 [1000/11811 (8%)]\tLoss: 0.084364\n",
      "Train Epoch: 3 [2000/11811 (17%)]\tLoss: 0.113886\n",
      "Train Epoch: 3 [3000/11811 (25%)]\tLoss: 0.037355\n",
      "Train Epoch: 3 [4000/11811 (34%)]\tLoss: 0.050697\n",
      "Train Epoch: 3 [5000/11811 (42%)]\tLoss: 0.062919\n",
      "Train Epoch: 3 [6000/11811 (50%)]\tLoss: 0.085341\n",
      "Train Epoch: 3 [7000/11811 (59%)]\tLoss: 0.094725\n",
      "Train Epoch: 3 [8000/11811 (67%)]\tLoss: 0.106119\n",
      "Train Epoch: 3 [9000/11811 (76%)]\tLoss: 0.085767\n",
      "Train Epoch: 3 [10000/11811 (84%)]\tLoss: 0.065174\n",
      "Train Epoch: 3 [11000/11811 (92%)]\tLoss: 0.078910\n",
      "Train Epoch: 4 [0/11811 (0%)]\tLoss: 0.134060\n",
      "Train Epoch: 4 [1000/11811 (8%)]\tLoss: 0.048351\n",
      "Train Epoch: 4 [2000/11811 (17%)]\tLoss: 0.048456\n",
      "Train Epoch: 4 [3000/11811 (25%)]\tLoss: 0.110387\n",
      "Train Epoch: 4 [4000/11811 (34%)]\tLoss: 0.057074\n",
      "Train Epoch: 4 [5000/11811 (42%)]\tLoss: 0.048769\n",
      "Train Epoch: 4 [6000/11811 (50%)]\tLoss: 0.056200\n",
      "Train Epoch: 4 [7000/11811 (59%)]\tLoss: 0.122926\n",
      "Train Epoch: 4 [8000/11811 (67%)]\tLoss: 0.063167\n",
      "Train Epoch: 4 [9000/11811 (76%)]\tLoss: 0.049123\n",
      "Train Epoch: 4 [10000/11811 (84%)]\tLoss: 0.083436\n",
      "Train Epoch: 4 [11000/11811 (92%)]\tLoss: 0.065638\n",
      "Train Epoch: 5 [0/11811 (0%)]\tLoss: 0.052894\n",
      "Train Epoch: 5 [1000/11811 (8%)]\tLoss: 0.052154\n",
      "Train Epoch: 5 [2000/11811 (17%)]\tLoss: 0.055337\n",
      "Train Epoch: 5 [3000/11811 (25%)]\tLoss: 0.162386\n",
      "Train Epoch: 5 [4000/11811 (34%)]\tLoss: 0.117934\n",
      "Train Epoch: 5 [5000/11811 (42%)]\tLoss: 0.040260\n",
      "Train Epoch: 5 [6000/11811 (50%)]\tLoss: 0.061495\n",
      "Train Epoch: 5 [7000/11811 (59%)]\tLoss: 0.069168\n",
      "Train Epoch: 5 [8000/11811 (67%)]\tLoss: 0.045861\n",
      "Train Epoch: 5 [9000/11811 (76%)]\tLoss: 0.108793\n",
      "Train Epoch: 5 [10000/11811 (84%)]\tLoss: 0.024624\n",
      "Train Epoch: 5 [11000/11811 (92%)]\tLoss: 0.060478\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/9726 (0%)]\tLoss: 0.247219\n",
      "Train Epoch: 1 [1000/9726 (10%)]\tLoss: 0.217030\n",
      "Train Epoch: 1 [2000/9726 (20%)]\tLoss: 0.152270\n",
      "Train Epoch: 1 [3000/9726 (31%)]\tLoss: 0.133083\n",
      "Train Epoch: 1 [4000/9726 (41%)]\tLoss: 0.263537\n",
      "Train Epoch: 1 [5000/9726 (51%)]\tLoss: 0.290114\n",
      "Train Epoch: 1 [6000/9726 (61%)]\tLoss: 0.228250\n",
      "Train Epoch: 1 [7000/9726 (71%)]\tLoss: 0.360219\n",
      "Train Epoch: 1 [8000/9726 (82%)]\tLoss: 0.085773\n",
      "Train Epoch: 1 [9000/9726 (92%)]\tLoss: 0.173734\n",
      "Train Epoch: 2 [0/9726 (0%)]\tLoss: 0.197627\n",
      "Train Epoch: 2 [1000/9726 (10%)]\tLoss: 0.321479\n",
      "Train Epoch: 2 [2000/9726 (20%)]\tLoss: 0.277097\n",
      "Train Epoch: 2 [3000/9726 (31%)]\tLoss: 0.221899\n",
      "Train Epoch: 2 [4000/9726 (41%)]\tLoss: 0.194566\n",
      "Train Epoch: 2 [5000/9726 (51%)]\tLoss: 0.119747\n",
      "Train Epoch: 2 [6000/9726 (61%)]\tLoss: 0.204892\n",
      "Train Epoch: 2 [7000/9726 (71%)]\tLoss: 0.237527\n",
      "Train Epoch: 2 [8000/9726 (82%)]\tLoss: 0.284349\n",
      "Train Epoch: 2 [9000/9726 (92%)]\tLoss: 0.221543\n",
      "Train Epoch: 3 [0/9726 (0%)]\tLoss: 0.107237\n",
      "Train Epoch: 3 [1000/9726 (10%)]\tLoss: 0.193235\n",
      "Train Epoch: 3 [2000/9726 (20%)]\tLoss: 0.218062\n",
      "Train Epoch: 3 [3000/9726 (31%)]\tLoss: 0.217821\n",
      "Train Epoch: 3 [4000/9726 (41%)]\tLoss: 0.249694\n",
      "Train Epoch: 3 [5000/9726 (51%)]\tLoss: 0.142720\n",
      "Train Epoch: 3 [6000/9726 (61%)]\tLoss: 0.165062\n",
      "Train Epoch: 3 [7000/9726 (71%)]\tLoss: 0.150714\n",
      "Train Epoch: 3 [8000/9726 (82%)]\tLoss: 0.191253\n",
      "Train Epoch: 3 [9000/9726 (92%)]\tLoss: 0.116021\n",
      "Train Epoch: 4 [0/9726 (0%)]\tLoss: 0.222869\n",
      "Train Epoch: 4 [1000/9726 (10%)]\tLoss: 0.164182\n",
      "Train Epoch: 4 [2000/9726 (20%)]\tLoss: 0.095106\n",
      "Train Epoch: 4 [3000/9726 (31%)]\tLoss: 0.127471\n",
      "Train Epoch: 4 [4000/9726 (41%)]\tLoss: 0.176911\n",
      "Train Epoch: 4 [5000/9726 (51%)]\tLoss: 0.109980\n",
      "Train Epoch: 4 [6000/9726 (61%)]\tLoss: 0.075341\n",
      "Train Epoch: 4 [7000/9726 (71%)]\tLoss: 0.171865\n",
      "Train Epoch: 4 [8000/9726 (82%)]\tLoss: 0.159459\n",
      "Train Epoch: 4 [9000/9726 (92%)]\tLoss: 0.107537\n",
      "Train Epoch: 5 [0/9726 (0%)]\tLoss: 0.082990\n",
      "Train Epoch: 5 [1000/9726 (10%)]\tLoss: 0.101717\n",
      "Train Epoch: 5 [2000/9726 (20%)]\tLoss: 0.239579\n",
      "Train Epoch: 5 [3000/9726 (31%)]\tLoss: 0.181677\n",
      "Train Epoch: 5 [4000/9726 (41%)]\tLoss: 0.192765\n",
      "Train Epoch: 5 [5000/9726 (51%)]\tLoss: 0.134524\n",
      "Train Epoch: 5 [6000/9726 (61%)]\tLoss: 0.127389\n",
      "Train Epoch: 5 [7000/9726 (71%)]\tLoss: 0.188385\n",
      "Train Epoch: 5 [8000/9726 (82%)]\tLoss: 0.125374\n",
      "Train Epoch: 5 [9000/9726 (92%)]\tLoss: 0.182148\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/6491 (0%)]\tLoss: 0.418318\n",
      "Train Epoch: 1 [1000/6491 (15%)]\tLoss: 0.272833\n",
      "Train Epoch: 1 [2000/6491 (31%)]\tLoss: 0.166224\n",
      "Train Epoch: 1 [3000/6491 (46%)]\tLoss: 0.260214\n",
      "Train Epoch: 1 [4000/6491 (62%)]\tLoss: 0.323667\n",
      "Train Epoch: 1 [5000/6491 (77%)]\tLoss: 0.238045\n",
      "Train Epoch: 1 [6000/6491 (92%)]\tLoss: 0.244092\n",
      "Train Epoch: 2 [0/6491 (0%)]\tLoss: 0.201765\n",
      "Train Epoch: 2 [1000/6491 (15%)]\tLoss: 0.245273\n",
      "Train Epoch: 2 [2000/6491 (31%)]\tLoss: 0.243506\n",
      "Train Epoch: 2 [3000/6491 (46%)]\tLoss: 0.211447\n",
      "Train Epoch: 2 [4000/6491 (62%)]\tLoss: 0.273983\n",
      "Train Epoch: 2 [5000/6491 (77%)]\tLoss: 0.197738\n",
      "Train Epoch: 2 [6000/6491 (92%)]\tLoss: 0.228377\n",
      "Train Epoch: 3 [0/6491 (0%)]\tLoss: 0.233906\n",
      "Train Epoch: 3 [1000/6491 (15%)]\tLoss: 0.180538\n",
      "Train Epoch: 3 [2000/6491 (31%)]\tLoss: 0.263165\n",
      "Train Epoch: 3 [3000/6491 (46%)]\tLoss: 0.153407\n",
      "Train Epoch: 3 [4000/6491 (62%)]\tLoss: 0.237238\n",
      "Train Epoch: 3 [5000/6491 (77%)]\tLoss: 0.319683\n",
      "Train Epoch: 3 [6000/6491 (92%)]\tLoss: 0.192152\n",
      "Train Epoch: 4 [0/6491 (0%)]\tLoss: 0.229686\n",
      "Train Epoch: 4 [1000/6491 (15%)]\tLoss: 0.345776\n",
      "Train Epoch: 4 [2000/6491 (31%)]\tLoss: 0.138518\n",
      "Train Epoch: 4 [3000/6491 (46%)]\tLoss: 0.292352\n",
      "Train Epoch: 4 [4000/6491 (62%)]\tLoss: 0.208431\n",
      "Train Epoch: 4 [5000/6491 (77%)]\tLoss: 0.261598\n",
      "Train Epoch: 4 [6000/6491 (92%)]\tLoss: 0.277682\n",
      "Train Epoch: 5 [0/6491 (0%)]\tLoss: 0.250132\n",
      "Train Epoch: 5 [1000/6491 (15%)]\tLoss: 0.106656\n",
      "Train Epoch: 5 [2000/6491 (31%)]\tLoss: 0.272820\n",
      "Train Epoch: 5 [3000/6491 (46%)]\tLoss: 0.334379\n",
      "Train Epoch: 5 [4000/6491 (62%)]\tLoss: 0.217517\n",
      "Train Epoch: 5 [5000/6491 (77%)]\tLoss: 0.184033\n",
      "Train Epoch: 5 [6000/6491 (92%)]\tLoss: 0.310420\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/14118 (0%)]\tLoss: 0.246529\n",
      "Train Epoch: 1 [1000/14118 (7%)]\tLoss: 0.151653\n",
      "Train Epoch: 1 [2000/14118 (14%)]\tLoss: 0.267690\n",
      "Train Epoch: 1 [3000/14118 (21%)]\tLoss: 0.165167\n",
      "Train Epoch: 1 [4000/14118 (28%)]\tLoss: 0.165704\n",
      "Train Epoch: 1 [5000/14118 (35%)]\tLoss: 0.129274\n",
      "Train Epoch: 1 [6000/14118 (42%)]\tLoss: 0.269678\n",
      "Train Epoch: 1 [7000/14118 (49%)]\tLoss: 0.170028\n",
      "Train Epoch: 1 [8000/14118 (56%)]\tLoss: 0.237388\n",
      "Train Epoch: 1 [9000/14118 (63%)]\tLoss: 0.146911\n",
      "Train Epoch: 1 [10000/14118 (70%)]\tLoss: 0.121047\n",
      "Train Epoch: 1 [11000/14118 (77%)]\tLoss: 0.179865\n",
      "Train Epoch: 1 [12000/14118 (85%)]\tLoss: 0.195765\n",
      "Train Epoch: 1 [13000/14118 (92%)]\tLoss: 0.342282\n",
      "Train Epoch: 1 [14000/14118 (99%)]\tLoss: 0.126735\n",
      "Train Epoch: 2 [0/14118 (0%)]\tLoss: 0.176847\n",
      "Train Epoch: 2 [1000/14118 (7%)]\tLoss: 0.236823\n",
      "Train Epoch: 2 [2000/14118 (14%)]\tLoss: 0.148655\n",
      "Train Epoch: 2 [3000/14118 (21%)]\tLoss: 0.105033\n",
      "Train Epoch: 2 [4000/14118 (28%)]\tLoss: 0.135206\n",
      "Train Epoch: 2 [5000/14118 (35%)]\tLoss: 0.163839\n",
      "Train Epoch: 2 [6000/14118 (42%)]\tLoss: 0.129810\n",
      "Train Epoch: 2 [7000/14118 (49%)]\tLoss: 0.219007\n",
      "Train Epoch: 2 [8000/14118 (56%)]\tLoss: 0.115490\n",
      "Train Epoch: 2 [9000/14118 (63%)]\tLoss: 0.203762\n",
      "Train Epoch: 2 [10000/14118 (70%)]\tLoss: 0.150892\n",
      "Train Epoch: 2 [11000/14118 (77%)]\tLoss: 0.213425\n",
      "Train Epoch: 2 [12000/14118 (85%)]\tLoss: 0.232365\n",
      "Train Epoch: 2 [13000/14118 (92%)]\tLoss: 0.156949\n",
      "Train Epoch: 2 [14000/14118 (99%)]\tLoss: 0.117118\n",
      "Train Epoch: 3 [0/14118 (0%)]\tLoss: 0.248757\n",
      "Train Epoch: 3 [1000/14118 (7%)]\tLoss: 0.086424\n",
      "Train Epoch: 3 [2000/14118 (14%)]\tLoss: 0.124343\n",
      "Train Epoch: 3 [3000/14118 (21%)]\tLoss: 0.139579\n",
      "Train Epoch: 3 [4000/14118 (28%)]\tLoss: 0.104194\n",
      "Train Epoch: 3 [5000/14118 (35%)]\tLoss: 0.153110\n",
      "Train Epoch: 3 [6000/14118 (42%)]\tLoss: 0.181959\n",
      "Train Epoch: 3 [7000/14118 (49%)]\tLoss: 0.168231\n",
      "Train Epoch: 3 [8000/14118 (56%)]\tLoss: 0.075891\n",
      "Train Epoch: 3 [9000/14118 (63%)]\tLoss: 0.154465\n",
      "Train Epoch: 3 [10000/14118 (70%)]\tLoss: 0.189716\n",
      "Train Epoch: 3 [11000/14118 (77%)]\tLoss: 0.151474\n",
      "Train Epoch: 3 [12000/14118 (85%)]\tLoss: 0.206437\n",
      "Train Epoch: 3 [13000/14118 (92%)]\tLoss: 0.145331\n",
      "Train Epoch: 3 [14000/14118 (99%)]\tLoss: 0.214432\n",
      "Train Epoch: 4 [0/14118 (0%)]\tLoss: 0.177976\n",
      "Train Epoch: 4 [1000/14118 (7%)]\tLoss: 0.153290\n",
      "Train Epoch: 4 [2000/14118 (14%)]\tLoss: 0.196055\n",
      "Train Epoch: 4 [3000/14118 (21%)]\tLoss: 0.160365\n",
      "Train Epoch: 4 [4000/14118 (28%)]\tLoss: 0.149677\n",
      "Train Epoch: 4 [5000/14118 (35%)]\tLoss: 0.112023\n",
      "Train Epoch: 4 [6000/14118 (42%)]\tLoss: 0.152506\n",
      "Train Epoch: 4 [7000/14118 (49%)]\tLoss: 0.127359\n",
      "Train Epoch: 4 [8000/14118 (56%)]\tLoss: 0.081608\n",
      "Train Epoch: 4 [9000/14118 (63%)]\tLoss: 0.164015\n",
      "Train Epoch: 4 [10000/14118 (70%)]\tLoss: 0.097989\n",
      "Train Epoch: 4 [11000/14118 (77%)]\tLoss: 0.116966\n",
      "Train Epoch: 4 [12000/14118 (85%)]\tLoss: 0.235040\n",
      "Train Epoch: 4 [13000/14118 (92%)]\tLoss: 0.096259\n",
      "Train Epoch: 4 [14000/14118 (99%)]\tLoss: 0.172927\n",
      "Train Epoch: 5 [0/14118 (0%)]\tLoss: 0.107523\n",
      "Train Epoch: 5 [1000/14118 (7%)]\tLoss: 0.165090\n",
      "Train Epoch: 5 [2000/14118 (14%)]\tLoss: 0.155868\n",
      "Train Epoch: 5 [3000/14118 (21%)]\tLoss: 0.171372\n",
      "Train Epoch: 5 [4000/14118 (28%)]\tLoss: 0.105864\n",
      "Train Epoch: 5 [5000/14118 (35%)]\tLoss: 0.162967\n",
      "Train Epoch: 5 [6000/14118 (42%)]\tLoss: 0.137184\n",
      "Train Epoch: 5 [7000/14118 (49%)]\tLoss: 0.182439\n",
      "Train Epoch: 5 [8000/14118 (56%)]\tLoss: 0.124843\n",
      "Train Epoch: 5 [9000/14118 (63%)]\tLoss: 0.108781\n",
      "Train Epoch: 5 [10000/14118 (70%)]\tLoss: 0.081386\n",
      "Train Epoch: 5 [11000/14118 (77%)]\tLoss: 0.323131\n",
      "Train Epoch: 5 [12000/14118 (85%)]\tLoss: 0.144982\n",
      "Train Epoch: 5 [13000/14118 (92%)]\tLoss: 0.171567\n",
      "Train Epoch: 5 [14000/14118 (99%)]\tLoss: 0.117472\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/9414 (0%)]\tLoss: 0.319629\n",
      "Train Epoch: 1 [1000/9414 (11%)]\tLoss: 0.200281\n",
      "Train Epoch: 1 [2000/9414 (21%)]\tLoss: 0.190208\n",
      "Train Epoch: 1 [3000/9414 (32%)]\tLoss: 0.151915\n",
      "Train Epoch: 1 [4000/9414 (42%)]\tLoss: 0.126548\n",
      "Train Epoch: 1 [5000/9414 (53%)]\tLoss: 0.344054\n",
      "Train Epoch: 1 [6000/9414 (63%)]\tLoss: 0.197148\n",
      "Train Epoch: 1 [7000/9414 (74%)]\tLoss: 0.311488\n",
      "Train Epoch: 1 [8000/9414 (84%)]\tLoss: 0.264087\n",
      "Train Epoch: 1 [9000/9414 (95%)]\tLoss: 0.207923\n",
      "Train Epoch: 2 [0/9414 (0%)]\tLoss: 0.153889\n",
      "Train Epoch: 2 [1000/9414 (11%)]\tLoss: 0.243845\n",
      "Train Epoch: 2 [2000/9414 (21%)]\tLoss: 0.202930\n",
      "Train Epoch: 2 [3000/9414 (32%)]\tLoss: 0.181704\n",
      "Train Epoch: 2 [4000/9414 (42%)]\tLoss: 0.199497\n",
      "Train Epoch: 2 [5000/9414 (53%)]\tLoss: 0.173924\n",
      "Train Epoch: 2 [6000/9414 (63%)]\tLoss: 0.220123\n",
      "Train Epoch: 2 [7000/9414 (74%)]\tLoss: 0.287621\n",
      "Train Epoch: 2 [8000/9414 (84%)]\tLoss: 0.237429\n",
      "Train Epoch: 2 [9000/9414 (95%)]\tLoss: 0.308507\n",
      "Train Epoch: 3 [0/9414 (0%)]\tLoss: 0.360532\n",
      "Train Epoch: 3 [1000/9414 (11%)]\tLoss: 0.141381\n",
      "Train Epoch: 3 [2000/9414 (21%)]\tLoss: 0.280168\n",
      "Train Epoch: 3 [3000/9414 (32%)]\tLoss: 0.195064\n",
      "Train Epoch: 3 [4000/9414 (42%)]\tLoss: 0.116624\n",
      "Train Epoch: 3 [5000/9414 (53%)]\tLoss: 0.101819\n",
      "Train Epoch: 3 [6000/9414 (63%)]\tLoss: 0.169911\n",
      "Train Epoch: 3 [7000/9414 (74%)]\tLoss: 0.309218\n",
      "Train Epoch: 3 [8000/9414 (84%)]\tLoss: 0.182560\n",
      "Train Epoch: 3 [9000/9414 (95%)]\tLoss: 0.144409\n",
      "Train Epoch: 4 [0/9414 (0%)]\tLoss: 0.420064\n",
      "Train Epoch: 4 [1000/9414 (11%)]\tLoss: 0.179390\n",
      "Train Epoch: 4 [2000/9414 (21%)]\tLoss: 0.188152\n",
      "Train Epoch: 4 [3000/9414 (32%)]\tLoss: 0.187842\n",
      "Train Epoch: 4 [4000/9414 (42%)]\tLoss: 0.141363\n",
      "Train Epoch: 4 [5000/9414 (53%)]\tLoss: 0.132077\n",
      "Train Epoch: 4 [6000/9414 (63%)]\tLoss: 0.210775\n",
      "Train Epoch: 4 [7000/9414 (74%)]\tLoss: 0.325752\n",
      "Train Epoch: 4 [8000/9414 (84%)]\tLoss: 0.236269\n",
      "Train Epoch: 4 [9000/9414 (95%)]\tLoss: 0.270466\n",
      "Train Epoch: 5 [0/9414 (0%)]\tLoss: 0.323195\n",
      "Train Epoch: 5 [1000/9414 (11%)]\tLoss: 0.143944\n",
      "Train Epoch: 5 [2000/9414 (21%)]\tLoss: 0.194594\n",
      "Train Epoch: 5 [3000/9414 (32%)]\tLoss: 0.165368\n",
      "Train Epoch: 5 [4000/9414 (42%)]\tLoss: 0.117430\n",
      "Train Epoch: 5 [5000/9414 (53%)]\tLoss: 0.192117\n",
      "Train Epoch: 5 [6000/9414 (63%)]\tLoss: 0.114539\n",
      "Train Epoch: 5 [7000/9414 (74%)]\tLoss: 0.178465\n",
      "Train Epoch: 5 [8000/9414 (84%)]\tLoss: 0.168937\n",
      "Train Epoch: 5 [9000/9414 (95%)]\tLoss: 0.253046\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "6\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.6739, Accuracy: 8652/10000 (87%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/8440 (0%)]\tLoss: 0.201362\n",
      "Train Epoch: 1 [1000/8440 (12%)]\tLoss: 0.282859\n",
      "Train Epoch: 1 [2000/8440 (24%)]\tLoss: 0.188680\n",
      "Train Epoch: 1 [3000/8440 (35%)]\tLoss: 0.181497\n",
      "Train Epoch: 1 [4000/8440 (47%)]\tLoss: 0.224056\n",
      "Train Epoch: 1 [5000/8440 (59%)]\tLoss: 0.234196\n",
      "Train Epoch: 1 [6000/8440 (71%)]\tLoss: 0.278705\n",
      "Train Epoch: 1 [7000/8440 (82%)]\tLoss: 0.189274\n",
      "Train Epoch: 1 [8000/8440 (94%)]\tLoss: 0.215654\n",
      "Train Epoch: 2 [0/8440 (0%)]\tLoss: 0.144384\n",
      "Train Epoch: 2 [1000/8440 (12%)]\tLoss: 0.249528\n",
      "Train Epoch: 2 [2000/8440 (24%)]\tLoss: 0.306674\n",
      "Train Epoch: 2 [3000/8440 (35%)]\tLoss: 0.188872\n",
      "Train Epoch: 2 [4000/8440 (47%)]\tLoss: 0.315983\n",
      "Train Epoch: 2 [5000/8440 (59%)]\tLoss: 0.202576\n",
      "Train Epoch: 2 [6000/8440 (71%)]\tLoss: 0.226903\n",
      "Train Epoch: 2 [7000/8440 (82%)]\tLoss: 0.288073\n",
      "Train Epoch: 2 [8000/8440 (94%)]\tLoss: 0.177159\n",
      "Train Epoch: 3 [0/8440 (0%)]\tLoss: 0.189724\n",
      "Train Epoch: 3 [1000/8440 (12%)]\tLoss: 0.247285\n",
      "Train Epoch: 3 [2000/8440 (24%)]\tLoss: 0.236411\n",
      "Train Epoch: 3 [3000/8440 (35%)]\tLoss: 0.235417\n",
      "Train Epoch: 3 [4000/8440 (47%)]\tLoss: 0.257183\n",
      "Train Epoch: 3 [5000/8440 (59%)]\tLoss: 0.252229\n",
      "Train Epoch: 3 [6000/8440 (71%)]\tLoss: 0.179886\n",
      "Train Epoch: 3 [7000/8440 (82%)]\tLoss: 0.226974\n",
      "Train Epoch: 3 [8000/8440 (94%)]\tLoss: 0.161237\n",
      "Train Epoch: 4 [0/8440 (0%)]\tLoss: 0.207359\n",
      "Train Epoch: 4 [1000/8440 (12%)]\tLoss: 0.212243\n",
      "Train Epoch: 4 [2000/8440 (24%)]\tLoss: 0.200855\n",
      "Train Epoch: 4 [3000/8440 (35%)]\tLoss: 0.200245\n",
      "Train Epoch: 4 [4000/8440 (47%)]\tLoss: 0.222203\n",
      "Train Epoch: 4 [5000/8440 (59%)]\tLoss: 0.273611\n",
      "Train Epoch: 4 [6000/8440 (71%)]\tLoss: 0.227317\n",
      "Train Epoch: 4 [7000/8440 (82%)]\tLoss: 0.321889\n",
      "Train Epoch: 4 [8000/8440 (94%)]\tLoss: 0.313945\n",
      "Train Epoch: 5 [0/8440 (0%)]\tLoss: 0.146846\n",
      "Train Epoch: 5 [1000/8440 (12%)]\tLoss: 0.269687\n",
      "Train Epoch: 5 [2000/8440 (24%)]\tLoss: 0.155185\n",
      "Train Epoch: 5 [3000/8440 (35%)]\tLoss: 0.226087\n",
      "Train Epoch: 5 [4000/8440 (47%)]\tLoss: 0.209411\n",
      "Train Epoch: 5 [5000/8440 (59%)]\tLoss: 0.278888\n",
      "Train Epoch: 5 [6000/8440 (71%)]\tLoss: 0.266132\n",
      "Train Epoch: 5 [7000/8440 (82%)]\tLoss: 0.295217\n",
      "Train Epoch: 5 [8000/8440 (94%)]\tLoss: 0.302049\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11811 (0%)]\tLoss: 0.204865\n",
      "Train Epoch: 1 [1000/11811 (8%)]\tLoss: 0.078616\n",
      "Train Epoch: 1 [2000/11811 (17%)]\tLoss: 0.087308\n",
      "Train Epoch: 1 [3000/11811 (25%)]\tLoss: 0.079213\n",
      "Train Epoch: 1 [4000/11811 (34%)]\tLoss: 0.137146\n",
      "Train Epoch: 1 [5000/11811 (42%)]\tLoss: 0.126939\n",
      "Train Epoch: 1 [6000/11811 (50%)]\tLoss: 0.136952\n",
      "Train Epoch: 1 [7000/11811 (59%)]\tLoss: 0.061047\n",
      "Train Epoch: 1 [8000/11811 (67%)]\tLoss: 0.120382\n",
      "Train Epoch: 1 [9000/11811 (76%)]\tLoss: 0.120515\n",
      "Train Epoch: 1 [10000/11811 (84%)]\tLoss: 0.106075\n",
      "Train Epoch: 1 [11000/11811 (92%)]\tLoss: 0.069633\n",
      "Train Epoch: 2 [0/11811 (0%)]\tLoss: 0.123867\n",
      "Train Epoch: 2 [1000/11811 (8%)]\tLoss: 0.098648\n",
      "Train Epoch: 2 [2000/11811 (17%)]\tLoss: 0.073033\n",
      "Train Epoch: 2 [3000/11811 (25%)]\tLoss: 0.109683\n",
      "Train Epoch: 2 [4000/11811 (34%)]\tLoss: 0.068751\n",
      "Train Epoch: 2 [5000/11811 (42%)]\tLoss: 0.135796\n",
      "Train Epoch: 2 [6000/11811 (50%)]\tLoss: 0.078774\n",
      "Train Epoch: 2 [7000/11811 (59%)]\tLoss: 0.152900\n",
      "Train Epoch: 2 [8000/11811 (67%)]\tLoss: 0.157502\n",
      "Train Epoch: 2 [9000/11811 (76%)]\tLoss: 0.105267\n",
      "Train Epoch: 2 [10000/11811 (84%)]\tLoss: 0.078808\n",
      "Train Epoch: 2 [11000/11811 (92%)]\tLoss: 0.069997\n",
      "Train Epoch: 3 [0/11811 (0%)]\tLoss: 0.042753\n",
      "Train Epoch: 3 [1000/11811 (8%)]\tLoss: 0.056470\n",
      "Train Epoch: 3 [2000/11811 (17%)]\tLoss: 0.075724\n",
      "Train Epoch: 3 [3000/11811 (25%)]\tLoss: 0.091706\n",
      "Train Epoch: 3 [4000/11811 (34%)]\tLoss: 0.080239\n",
      "Train Epoch: 3 [5000/11811 (42%)]\tLoss: 0.071021\n",
      "Train Epoch: 3 [6000/11811 (50%)]\tLoss: 0.079018\n",
      "Train Epoch: 3 [7000/11811 (59%)]\tLoss: 0.079376\n",
      "Train Epoch: 3 [8000/11811 (67%)]\tLoss: 0.119669\n",
      "Train Epoch: 3 [9000/11811 (76%)]\tLoss: 0.074174\n",
      "Train Epoch: 3 [10000/11811 (84%)]\tLoss: 0.045813\n",
      "Train Epoch: 3 [11000/11811 (92%)]\tLoss: 0.078624\n",
      "Train Epoch: 4 [0/11811 (0%)]\tLoss: 0.113345\n",
      "Train Epoch: 4 [1000/11811 (8%)]\tLoss: 0.068205\n",
      "Train Epoch: 4 [2000/11811 (17%)]\tLoss: 0.050291\n",
      "Train Epoch: 4 [3000/11811 (25%)]\tLoss: 0.038417\n",
      "Train Epoch: 4 [4000/11811 (34%)]\tLoss: 0.017465\n",
      "Train Epoch: 4 [5000/11811 (42%)]\tLoss: 0.065924\n",
      "Train Epoch: 4 [6000/11811 (50%)]\tLoss: 0.060508\n",
      "Train Epoch: 4 [7000/11811 (59%)]\tLoss: 0.139888\n",
      "Train Epoch: 4 [8000/11811 (67%)]\tLoss: 0.137251\n",
      "Train Epoch: 4 [9000/11811 (76%)]\tLoss: 0.085798\n",
      "Train Epoch: 4 [10000/11811 (84%)]\tLoss: 0.088345\n",
      "Train Epoch: 4 [11000/11811 (92%)]\tLoss: 0.064560\n",
      "Train Epoch: 5 [0/11811 (0%)]\tLoss: 0.068656\n",
      "Train Epoch: 5 [1000/11811 (8%)]\tLoss: 0.085528\n",
      "Train Epoch: 5 [2000/11811 (17%)]\tLoss: 0.033004\n",
      "Train Epoch: 5 [3000/11811 (25%)]\tLoss: 0.100189\n",
      "Train Epoch: 5 [4000/11811 (34%)]\tLoss: 0.032205\n",
      "Train Epoch: 5 [5000/11811 (42%)]\tLoss: 0.129066\n",
      "Train Epoch: 5 [6000/11811 (50%)]\tLoss: 0.026358\n",
      "Train Epoch: 5 [7000/11811 (59%)]\tLoss: 0.069884\n",
      "Train Epoch: 5 [8000/11811 (67%)]\tLoss: 0.041060\n",
      "Train Epoch: 5 [9000/11811 (76%)]\tLoss: 0.163162\n",
      "Train Epoch: 5 [10000/11811 (84%)]\tLoss: 0.156650\n",
      "Train Epoch: 5 [11000/11811 (92%)]\tLoss: 0.142058\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/9726 (0%)]\tLoss: 0.195387\n",
      "Train Epoch: 1 [1000/9726 (10%)]\tLoss: 0.285583\n",
      "Train Epoch: 1 [2000/9726 (20%)]\tLoss: 0.166624\n",
      "Train Epoch: 1 [3000/9726 (31%)]\tLoss: 0.183748\n",
      "Train Epoch: 1 [4000/9726 (41%)]\tLoss: 0.155502\n",
      "Train Epoch: 1 [5000/9726 (51%)]\tLoss: 0.118087\n",
      "Train Epoch: 1 [6000/9726 (61%)]\tLoss: 0.154966\n",
      "Train Epoch: 1 [7000/9726 (71%)]\tLoss: 0.091954\n",
      "Train Epoch: 1 [8000/9726 (82%)]\tLoss: 0.083758\n",
      "Train Epoch: 1 [9000/9726 (92%)]\tLoss: 0.157703\n",
      "Train Epoch: 2 [0/9726 (0%)]\tLoss: 0.251300\n",
      "Train Epoch: 2 [1000/9726 (10%)]\tLoss: 0.200694\n",
      "Train Epoch: 2 [2000/9726 (20%)]\tLoss: 0.162981\n",
      "Train Epoch: 2 [3000/9726 (31%)]\tLoss: 0.215208\n",
      "Train Epoch: 2 [4000/9726 (41%)]\tLoss: 0.125802\n",
      "Train Epoch: 2 [5000/9726 (51%)]\tLoss: 0.157747\n",
      "Train Epoch: 2 [6000/9726 (61%)]\tLoss: 0.186794\n",
      "Train Epoch: 2 [7000/9726 (71%)]\tLoss: 0.237962\n",
      "Train Epoch: 2 [8000/9726 (82%)]\tLoss: 0.208302\n",
      "Train Epoch: 2 [9000/9726 (92%)]\tLoss: 0.133358\n",
      "Train Epoch: 3 [0/9726 (0%)]\tLoss: 0.093009\n",
      "Train Epoch: 3 [1000/9726 (10%)]\tLoss: 0.200979\n",
      "Train Epoch: 3 [2000/9726 (20%)]\tLoss: 0.129831\n",
      "Train Epoch: 3 [3000/9726 (31%)]\tLoss: 0.093192\n",
      "Train Epoch: 3 [4000/9726 (41%)]\tLoss: 0.196769\n",
      "Train Epoch: 3 [5000/9726 (51%)]\tLoss: 0.106960\n",
      "Train Epoch: 3 [6000/9726 (61%)]\tLoss: 0.167995\n",
      "Train Epoch: 3 [7000/9726 (71%)]\tLoss: 0.164961\n",
      "Train Epoch: 3 [8000/9726 (82%)]\tLoss: 0.183245\n",
      "Train Epoch: 3 [9000/9726 (92%)]\tLoss: 0.145559\n",
      "Train Epoch: 4 [0/9726 (0%)]\tLoss: 0.202036\n",
      "Train Epoch: 4 [1000/9726 (10%)]\tLoss: 0.144714\n",
      "Train Epoch: 4 [2000/9726 (20%)]\tLoss: 0.075050\n",
      "Train Epoch: 4 [3000/9726 (31%)]\tLoss: 0.134558\n",
      "Train Epoch: 4 [4000/9726 (41%)]\tLoss: 0.163081\n",
      "Train Epoch: 4 [5000/9726 (51%)]\tLoss: 0.126882\n",
      "Train Epoch: 4 [6000/9726 (61%)]\tLoss: 0.218738\n",
      "Train Epoch: 4 [7000/9726 (71%)]\tLoss: 0.142608\n",
      "Train Epoch: 4 [8000/9726 (82%)]\tLoss: 0.160446\n",
      "Train Epoch: 4 [9000/9726 (92%)]\tLoss: 0.106336\n",
      "Train Epoch: 5 [0/9726 (0%)]\tLoss: 0.152971\n",
      "Train Epoch: 5 [1000/9726 (10%)]\tLoss: 0.106222\n",
      "Train Epoch: 5 [2000/9726 (20%)]\tLoss: 0.166772\n",
      "Train Epoch: 5 [3000/9726 (31%)]\tLoss: 0.156336\n",
      "Train Epoch: 5 [4000/9726 (41%)]\tLoss: 0.102491\n",
      "Train Epoch: 5 [5000/9726 (51%)]\tLoss: 0.146478\n",
      "Train Epoch: 5 [6000/9726 (61%)]\tLoss: 0.111023\n",
      "Train Epoch: 5 [7000/9726 (71%)]\tLoss: 0.219215\n",
      "Train Epoch: 5 [8000/9726 (82%)]\tLoss: 0.131433\n",
      "Train Epoch: 5 [9000/9726 (92%)]\tLoss: 0.095161\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/6491 (0%)]\tLoss: 0.509587\n",
      "Train Epoch: 1 [1000/6491 (15%)]\tLoss: 0.232202\n",
      "Train Epoch: 1 [2000/6491 (31%)]\tLoss: 0.268797\n",
      "Train Epoch: 1 [3000/6491 (46%)]\tLoss: 0.194010\n",
      "Train Epoch: 1 [4000/6491 (62%)]\tLoss: 0.190604\n",
      "Train Epoch: 1 [5000/6491 (77%)]\tLoss: 0.295739\n",
      "Train Epoch: 1 [6000/6491 (92%)]\tLoss: 0.302309\n",
      "Train Epoch: 2 [0/6491 (0%)]\tLoss: 0.237163\n",
      "Train Epoch: 2 [1000/6491 (15%)]\tLoss: 0.347598\n",
      "Train Epoch: 2 [2000/6491 (31%)]\tLoss: 0.320166\n",
      "Train Epoch: 2 [3000/6491 (46%)]\tLoss: 0.335741\n",
      "Train Epoch: 2 [4000/6491 (62%)]\tLoss: 0.271068\n",
      "Train Epoch: 2 [5000/6491 (77%)]\tLoss: 0.344789\n",
      "Train Epoch: 2 [6000/6491 (92%)]\tLoss: 0.233085\n",
      "Train Epoch: 3 [0/6491 (0%)]\tLoss: 0.184237\n",
      "Train Epoch: 3 [1000/6491 (15%)]\tLoss: 0.205854\n",
      "Train Epoch: 3 [2000/6491 (31%)]\tLoss: 0.174740\n",
      "Train Epoch: 3 [3000/6491 (46%)]\tLoss: 0.208676\n",
      "Train Epoch: 3 [4000/6491 (62%)]\tLoss: 0.328797\n",
      "Train Epoch: 3 [5000/6491 (77%)]\tLoss: 0.260942\n",
      "Train Epoch: 3 [6000/6491 (92%)]\tLoss: 0.261832\n",
      "Train Epoch: 4 [0/6491 (0%)]\tLoss: 0.153737\n",
      "Train Epoch: 4 [1000/6491 (15%)]\tLoss: 0.247869\n",
      "Train Epoch: 4 [2000/6491 (31%)]\tLoss: 0.191639\n",
      "Train Epoch: 4 [3000/6491 (46%)]\tLoss: 0.330930\n",
      "Train Epoch: 4 [4000/6491 (62%)]\tLoss: 0.266528\n",
      "Train Epoch: 4 [5000/6491 (77%)]\tLoss: 0.181961\n",
      "Train Epoch: 4 [6000/6491 (92%)]\tLoss: 0.201015\n",
      "Train Epoch: 5 [0/6491 (0%)]\tLoss: 0.461175\n",
      "Train Epoch: 5 [1000/6491 (15%)]\tLoss: 0.226071\n",
      "Train Epoch: 5 [2000/6491 (31%)]\tLoss: 0.230181\n",
      "Train Epoch: 5 [3000/6491 (46%)]\tLoss: 0.270506\n",
      "Train Epoch: 5 [4000/6491 (62%)]\tLoss: 0.167824\n",
      "Train Epoch: 5 [5000/6491 (77%)]\tLoss: 0.242215\n",
      "Train Epoch: 5 [6000/6491 (92%)]\tLoss: 0.238255\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/14118 (0%)]\tLoss: 0.399156\n",
      "Train Epoch: 1 [1000/14118 (7%)]\tLoss: 0.186258\n",
      "Train Epoch: 1 [2000/14118 (14%)]\tLoss: 0.180031\n",
      "Train Epoch: 1 [3000/14118 (21%)]\tLoss: 0.107306\n",
      "Train Epoch: 1 [4000/14118 (28%)]\tLoss: 0.172461\n",
      "Train Epoch: 1 [5000/14118 (35%)]\tLoss: 0.111413\n",
      "Train Epoch: 1 [6000/14118 (42%)]\tLoss: 0.067221\n",
      "Train Epoch: 1 [7000/14118 (49%)]\tLoss: 0.198871\n",
      "Train Epoch: 1 [8000/14118 (56%)]\tLoss: 0.192433\n",
      "Train Epoch: 1 [9000/14118 (63%)]\tLoss: 0.152313\n",
      "Train Epoch: 1 [10000/14118 (70%)]\tLoss: 0.204266\n",
      "Train Epoch: 1 [11000/14118 (77%)]\tLoss: 0.050156\n",
      "Train Epoch: 1 [12000/14118 (85%)]\tLoss: 0.182909\n",
      "Train Epoch: 1 [13000/14118 (92%)]\tLoss: 0.226714\n",
      "Train Epoch: 1 [14000/14118 (99%)]\tLoss: 0.158054\n",
      "Train Epoch: 2 [0/14118 (0%)]\tLoss: 0.077074\n",
      "Train Epoch: 2 [1000/14118 (7%)]\tLoss: 0.053253\n",
      "Train Epoch: 2 [2000/14118 (14%)]\tLoss: 0.258497\n",
      "Train Epoch: 2 [3000/14118 (21%)]\tLoss: 0.194011\n",
      "Train Epoch: 2 [4000/14118 (28%)]\tLoss: 0.228932\n",
      "Train Epoch: 2 [5000/14118 (35%)]\tLoss: 0.121718\n",
      "Train Epoch: 2 [6000/14118 (42%)]\tLoss: 0.169754\n",
      "Train Epoch: 2 [7000/14118 (49%)]\tLoss: 0.316851\n",
      "Train Epoch: 2 [8000/14118 (56%)]\tLoss: 0.072469\n",
      "Train Epoch: 2 [9000/14118 (63%)]\tLoss: 0.105215\n",
      "Train Epoch: 2 [10000/14118 (70%)]\tLoss: 0.155343\n",
      "Train Epoch: 2 [11000/14118 (77%)]\tLoss: 0.219101\n",
      "Train Epoch: 2 [12000/14118 (85%)]\tLoss: 0.120777\n",
      "Train Epoch: 2 [13000/14118 (92%)]\tLoss: 0.198867\n",
      "Train Epoch: 2 [14000/14118 (99%)]\tLoss: 0.132326\n",
      "Train Epoch: 3 [0/14118 (0%)]\tLoss: 0.212496\n",
      "Train Epoch: 3 [1000/14118 (7%)]\tLoss: 0.127003\n",
      "Train Epoch: 3 [2000/14118 (14%)]\tLoss: 0.185135\n",
      "Train Epoch: 3 [3000/14118 (21%)]\tLoss: 0.144296\n",
      "Train Epoch: 3 [4000/14118 (28%)]\tLoss: 0.076565\n",
      "Train Epoch: 3 [5000/14118 (35%)]\tLoss: 0.111941\n",
      "Train Epoch: 3 [6000/14118 (42%)]\tLoss: 0.107471\n",
      "Train Epoch: 3 [7000/14118 (49%)]\tLoss: 0.119188\n",
      "Train Epoch: 3 [8000/14118 (56%)]\tLoss: 0.096146\n",
      "Train Epoch: 3 [9000/14118 (63%)]\tLoss: 0.176457\n",
      "Train Epoch: 3 [10000/14118 (70%)]\tLoss: 0.138160\n",
      "Train Epoch: 3 [11000/14118 (77%)]\tLoss: 0.097072\n",
      "Train Epoch: 3 [12000/14118 (85%)]\tLoss: 0.154837\n",
      "Train Epoch: 3 [13000/14118 (92%)]\tLoss: 0.098032\n",
      "Train Epoch: 3 [14000/14118 (99%)]\tLoss: 0.181768\n",
      "Train Epoch: 4 [0/14118 (0%)]\tLoss: 0.205179\n",
      "Train Epoch: 4 [1000/14118 (7%)]\tLoss: 0.177187\n",
      "Train Epoch: 4 [2000/14118 (14%)]\tLoss: 0.120713\n",
      "Train Epoch: 4 [3000/14118 (21%)]\tLoss: 0.166100\n",
      "Train Epoch: 4 [4000/14118 (28%)]\tLoss: 0.164256\n",
      "Train Epoch: 4 [5000/14118 (35%)]\tLoss: 0.180811\n",
      "Train Epoch: 4 [6000/14118 (42%)]\tLoss: 0.124212\n",
      "Train Epoch: 4 [7000/14118 (49%)]\tLoss: 0.150265\n",
      "Train Epoch: 4 [8000/14118 (56%)]\tLoss: 0.121089\n",
      "Train Epoch: 4 [9000/14118 (63%)]\tLoss: 0.158372\n",
      "Train Epoch: 4 [10000/14118 (70%)]\tLoss: 0.141028\n",
      "Train Epoch: 4 [11000/14118 (77%)]\tLoss: 0.075599\n",
      "Train Epoch: 4 [12000/14118 (85%)]\tLoss: 0.065556\n",
      "Train Epoch: 4 [13000/14118 (92%)]\tLoss: 0.163863\n",
      "Train Epoch: 4 [14000/14118 (99%)]\tLoss: 0.178129\n",
      "Train Epoch: 5 [0/14118 (0%)]\tLoss: 0.130491\n",
      "Train Epoch: 5 [1000/14118 (7%)]\tLoss: 0.127294\n",
      "Train Epoch: 5 [2000/14118 (14%)]\tLoss: 0.171786\n",
      "Train Epoch: 5 [3000/14118 (21%)]\tLoss: 0.189895\n",
      "Train Epoch: 5 [4000/14118 (28%)]\tLoss: 0.242028\n",
      "Train Epoch: 5 [5000/14118 (35%)]\tLoss: 0.131331\n",
      "Train Epoch: 5 [6000/14118 (42%)]\tLoss: 0.083079\n",
      "Train Epoch: 5 [7000/14118 (49%)]\tLoss: 0.228581\n",
      "Train Epoch: 5 [8000/14118 (56%)]\tLoss: 0.109610\n",
      "Train Epoch: 5 [9000/14118 (63%)]\tLoss: 0.172034\n",
      "Train Epoch: 5 [10000/14118 (70%)]\tLoss: 0.129203\n",
      "Train Epoch: 5 [11000/14118 (77%)]\tLoss: 0.081285\n",
      "Train Epoch: 5 [12000/14118 (85%)]\tLoss: 0.135214\n",
      "Train Epoch: 5 [13000/14118 (92%)]\tLoss: 0.124311\n",
      "Train Epoch: 5 [14000/14118 (99%)]\tLoss: 0.111516\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/9414 (0%)]\tLoss: 0.313535\n",
      "Train Epoch: 1 [1000/9414 (11%)]\tLoss: 0.160255\n",
      "Train Epoch: 1 [2000/9414 (21%)]\tLoss: 0.179684\n",
      "Train Epoch: 1 [3000/9414 (32%)]\tLoss: 0.271625\n",
      "Train Epoch: 1 [4000/9414 (42%)]\tLoss: 0.402668\n",
      "Train Epoch: 1 [5000/9414 (53%)]\tLoss: 0.096769\n",
      "Train Epoch: 1 [6000/9414 (63%)]\tLoss: 0.194467\n",
      "Train Epoch: 1 [7000/9414 (74%)]\tLoss: 0.223345\n",
      "Train Epoch: 1 [8000/9414 (84%)]\tLoss: 0.250689\n",
      "Train Epoch: 1 [9000/9414 (95%)]\tLoss: 0.140148\n",
      "Train Epoch: 2 [0/9414 (0%)]\tLoss: 0.225957\n",
      "Train Epoch: 2 [1000/9414 (11%)]\tLoss: 0.197832\n",
      "Train Epoch: 2 [2000/9414 (21%)]\tLoss: 0.150468\n",
      "Train Epoch: 2 [3000/9414 (32%)]\tLoss: 0.316728\n",
      "Train Epoch: 2 [4000/9414 (42%)]\tLoss: 0.190787\n",
      "Train Epoch: 2 [5000/9414 (53%)]\tLoss: 0.235761\n",
      "Train Epoch: 2 [6000/9414 (63%)]\tLoss: 0.285755\n",
      "Train Epoch: 2 [7000/9414 (74%)]\tLoss: 0.205580\n",
      "Train Epoch: 2 [8000/9414 (84%)]\tLoss: 0.187432\n",
      "Train Epoch: 2 [9000/9414 (95%)]\tLoss: 0.201171\n",
      "Train Epoch: 3 [0/9414 (0%)]\tLoss: 0.241106\n",
      "Train Epoch: 3 [1000/9414 (11%)]\tLoss: 0.178449\n",
      "Train Epoch: 3 [2000/9414 (21%)]\tLoss: 0.177489\n",
      "Train Epoch: 3 [3000/9414 (32%)]\tLoss: 0.124831\n",
      "Train Epoch: 3 [4000/9414 (42%)]\tLoss: 0.250350\n",
      "Train Epoch: 3 [5000/9414 (53%)]\tLoss: 0.091647\n",
      "Train Epoch: 3 [6000/9414 (63%)]\tLoss: 0.139567\n",
      "Train Epoch: 3 [7000/9414 (74%)]\tLoss: 0.145289\n",
      "Train Epoch: 3 [8000/9414 (84%)]\tLoss: 0.180907\n",
      "Train Epoch: 3 [9000/9414 (95%)]\tLoss: 0.262148\n",
      "Train Epoch: 4 [0/9414 (0%)]\tLoss: 0.320884\n",
      "Train Epoch: 4 [1000/9414 (11%)]\tLoss: 0.232034\n",
      "Train Epoch: 4 [2000/9414 (21%)]\tLoss: 0.136054\n",
      "Train Epoch: 4 [3000/9414 (32%)]\tLoss: 0.199294\n",
      "Train Epoch: 4 [4000/9414 (42%)]\tLoss: 0.185876\n",
      "Train Epoch: 4 [5000/9414 (53%)]\tLoss: 0.188401\n",
      "Train Epoch: 4 [6000/9414 (63%)]\tLoss: 0.187279\n",
      "Train Epoch: 4 [7000/9414 (74%)]\tLoss: 0.281131\n",
      "Train Epoch: 4 [8000/9414 (84%)]\tLoss: 0.122775\n",
      "Train Epoch: 4 [9000/9414 (95%)]\tLoss: 0.164746\n",
      "Train Epoch: 5 [0/9414 (0%)]\tLoss: 0.233780\n",
      "Train Epoch: 5 [1000/9414 (11%)]\tLoss: 0.231280\n",
      "Train Epoch: 5 [2000/9414 (21%)]\tLoss: 0.105855\n",
      "Train Epoch: 5 [3000/9414 (32%)]\tLoss: 0.193250\n",
      "Train Epoch: 5 [4000/9414 (42%)]\tLoss: 0.255256\n",
      "Train Epoch: 5 [5000/9414 (53%)]\tLoss: 0.137022\n",
      "Train Epoch: 5 [6000/9414 (63%)]\tLoss: 0.176117\n",
      "Train Epoch: 5 [7000/9414 (74%)]\tLoss: 0.153258\n",
      "Train Epoch: 5 [8000/9414 (84%)]\tLoss: 0.165079\n",
      "Train Epoch: 5 [9000/9414 (95%)]\tLoss: 0.161025\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "6\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.6648, Accuracy: 8577/10000 (86%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/8440 (0%)]\tLoss: 0.260963\n",
      "Train Epoch: 1 [1000/8440 (12%)]\tLoss: 0.251410\n",
      "Train Epoch: 1 [2000/8440 (24%)]\tLoss: 0.213291\n",
      "Train Epoch: 1 [3000/8440 (35%)]\tLoss: 0.125895\n",
      "Train Epoch: 1 [4000/8440 (47%)]\tLoss: 0.302091\n",
      "Train Epoch: 1 [5000/8440 (59%)]\tLoss: 0.242248\n",
      "Train Epoch: 1 [6000/8440 (71%)]\tLoss: 0.273701\n",
      "Train Epoch: 1 [7000/8440 (82%)]\tLoss: 0.136510\n",
      "Train Epoch: 1 [8000/8440 (94%)]\tLoss: 0.264901\n",
      "Train Epoch: 2 [0/8440 (0%)]\tLoss: 0.227616\n",
      "Train Epoch: 2 [1000/8440 (12%)]\tLoss: 0.231444\n",
      "Train Epoch: 2 [2000/8440 (24%)]\tLoss: 0.159255\n",
      "Train Epoch: 2 [3000/8440 (35%)]\tLoss: 0.190820\n",
      "Train Epoch: 2 [4000/8440 (47%)]\tLoss: 0.209134\n",
      "Train Epoch: 2 [5000/8440 (59%)]\tLoss: 0.148349\n",
      "Train Epoch: 2 [6000/8440 (71%)]\tLoss: 0.208878\n",
      "Train Epoch: 2 [7000/8440 (82%)]\tLoss: 0.326863\n",
      "Train Epoch: 2 [8000/8440 (94%)]\tLoss: 0.254209\n",
      "Train Epoch: 3 [0/8440 (0%)]\tLoss: 0.167737\n",
      "Train Epoch: 3 [1000/8440 (12%)]\tLoss: 0.156289\n",
      "Train Epoch: 3 [2000/8440 (24%)]\tLoss: 0.287548\n",
      "Train Epoch: 3 [3000/8440 (35%)]\tLoss: 0.311426\n",
      "Train Epoch: 3 [4000/8440 (47%)]\tLoss: 0.235605\n",
      "Train Epoch: 3 [5000/8440 (59%)]\tLoss: 0.181567\n",
      "Train Epoch: 3 [6000/8440 (71%)]\tLoss: 0.167688\n",
      "Train Epoch: 3 [7000/8440 (82%)]\tLoss: 0.211006\n",
      "Train Epoch: 3 [8000/8440 (94%)]\tLoss: 0.173019\n",
      "Train Epoch: 4 [0/8440 (0%)]\tLoss: 0.203950\n",
      "Train Epoch: 4 [1000/8440 (12%)]\tLoss: 0.198352\n",
      "Train Epoch: 4 [2000/8440 (24%)]\tLoss: 0.196392\n",
      "Train Epoch: 4 [3000/8440 (35%)]\tLoss: 0.220646\n",
      "Train Epoch: 4 [4000/8440 (47%)]\tLoss: 0.252135\n",
      "Train Epoch: 4 [5000/8440 (59%)]\tLoss: 0.301902\n",
      "Train Epoch: 4 [6000/8440 (71%)]\tLoss: 0.216733\n",
      "Train Epoch: 4 [7000/8440 (82%)]\tLoss: 0.192255\n",
      "Train Epoch: 4 [8000/8440 (94%)]\tLoss: 0.166484\n",
      "Train Epoch: 5 [0/8440 (0%)]\tLoss: 0.134847\n",
      "Train Epoch: 5 [1000/8440 (12%)]\tLoss: 0.235265\n",
      "Train Epoch: 5 [2000/8440 (24%)]\tLoss: 0.161832\n",
      "Train Epoch: 5 [3000/8440 (35%)]\tLoss: 0.203419\n",
      "Train Epoch: 5 [4000/8440 (47%)]\tLoss: 0.166509\n",
      "Train Epoch: 5 [5000/8440 (59%)]\tLoss: 0.164547\n",
      "Train Epoch: 5 [6000/8440 (71%)]\tLoss: 0.229716\n",
      "Train Epoch: 5 [7000/8440 (82%)]\tLoss: 0.322806\n",
      "Train Epoch: 5 [8000/8440 (94%)]\tLoss: 0.126359\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11811 (0%)]\tLoss: 0.131816\n",
      "Train Epoch: 1 [1000/11811 (8%)]\tLoss: 0.109127\n",
      "Train Epoch: 1 [2000/11811 (17%)]\tLoss: 0.057055\n",
      "Train Epoch: 1 [3000/11811 (25%)]\tLoss: 0.049739\n",
      "Train Epoch: 1 [4000/11811 (34%)]\tLoss: 0.092353\n",
      "Train Epoch: 1 [5000/11811 (42%)]\tLoss: 0.110613\n",
      "Train Epoch: 1 [6000/11811 (50%)]\tLoss: 0.088203\n",
      "Train Epoch: 1 [7000/11811 (59%)]\tLoss: 0.061335\n",
      "Train Epoch: 1 [8000/11811 (67%)]\tLoss: 0.088686\n",
      "Train Epoch: 1 [9000/11811 (76%)]\tLoss: 0.085522\n",
      "Train Epoch: 1 [10000/11811 (84%)]\tLoss: 0.146672\n",
      "Train Epoch: 1 [11000/11811 (92%)]\tLoss: 0.090547\n",
      "Train Epoch: 2 [0/11811 (0%)]\tLoss: 0.120609\n",
      "Train Epoch: 2 [1000/11811 (8%)]\tLoss: 0.068695\n",
      "Train Epoch: 2 [2000/11811 (17%)]\tLoss: 0.067700\n",
      "Train Epoch: 2 [3000/11811 (25%)]\tLoss: 0.072262\n",
      "Train Epoch: 2 [4000/11811 (34%)]\tLoss: 0.041945\n",
      "Train Epoch: 2 [5000/11811 (42%)]\tLoss: 0.097039\n",
      "Train Epoch: 2 [6000/11811 (50%)]\tLoss: 0.078904\n",
      "Train Epoch: 2 [7000/11811 (59%)]\tLoss: 0.048156\n",
      "Train Epoch: 2 [8000/11811 (67%)]\tLoss: 0.223039\n",
      "Train Epoch: 2 [9000/11811 (76%)]\tLoss: 0.025164\n",
      "Train Epoch: 2 [10000/11811 (84%)]\tLoss: 0.062272\n",
      "Train Epoch: 2 [11000/11811 (92%)]\tLoss: 0.030326\n",
      "Train Epoch: 3 [0/11811 (0%)]\tLoss: 0.068436\n",
      "Train Epoch: 3 [1000/11811 (8%)]\tLoss: 0.118856\n",
      "Train Epoch: 3 [2000/11811 (17%)]\tLoss: 0.042764\n",
      "Train Epoch: 3 [3000/11811 (25%)]\tLoss: 0.062464\n",
      "Train Epoch: 3 [4000/11811 (34%)]\tLoss: 0.081703\n",
      "Train Epoch: 3 [5000/11811 (42%)]\tLoss: 0.147823\n",
      "Train Epoch: 3 [6000/11811 (50%)]\tLoss: 0.070575\n",
      "Train Epoch: 3 [7000/11811 (59%)]\tLoss: 0.143969\n",
      "Train Epoch: 3 [8000/11811 (67%)]\tLoss: 0.077181\n",
      "Train Epoch: 3 [9000/11811 (76%)]\tLoss: 0.131214\n",
      "Train Epoch: 3 [10000/11811 (84%)]\tLoss: 0.070084\n",
      "Train Epoch: 3 [11000/11811 (92%)]\tLoss: 0.036149\n",
      "Train Epoch: 4 [0/11811 (0%)]\tLoss: 0.052557\n",
      "Train Epoch: 4 [1000/11811 (8%)]\tLoss: 0.034757\n",
      "Train Epoch: 4 [2000/11811 (17%)]\tLoss: 0.163804\n",
      "Train Epoch: 4 [3000/11811 (25%)]\tLoss: 0.068206\n",
      "Train Epoch: 4 [4000/11811 (34%)]\tLoss: 0.140271\n",
      "Train Epoch: 4 [5000/11811 (42%)]\tLoss: 0.087036\n",
      "Train Epoch: 4 [6000/11811 (50%)]\tLoss: 0.072493\n",
      "Train Epoch: 4 [7000/11811 (59%)]\tLoss: 0.105408\n",
      "Train Epoch: 4 [8000/11811 (67%)]\tLoss: 0.040462\n",
      "Train Epoch: 4 [9000/11811 (76%)]\tLoss: 0.060564\n",
      "Train Epoch: 4 [10000/11811 (84%)]\tLoss: 0.099011\n",
      "Train Epoch: 4 [11000/11811 (92%)]\tLoss: 0.096151\n",
      "Train Epoch: 5 [0/11811 (0%)]\tLoss: 0.074642\n",
      "Train Epoch: 5 [1000/11811 (8%)]\tLoss: 0.060744\n",
      "Train Epoch: 5 [2000/11811 (17%)]\tLoss: 0.099451\n",
      "Train Epoch: 5 [3000/11811 (25%)]\tLoss: 0.045258\n",
      "Train Epoch: 5 [4000/11811 (34%)]\tLoss: 0.068140\n",
      "Train Epoch: 5 [5000/11811 (42%)]\tLoss: 0.129892\n",
      "Train Epoch: 5 [6000/11811 (50%)]\tLoss: 0.065055\n",
      "Train Epoch: 5 [7000/11811 (59%)]\tLoss: 0.061628\n",
      "Train Epoch: 5 [8000/11811 (67%)]\tLoss: 0.050580\n",
      "Train Epoch: 5 [9000/11811 (76%)]\tLoss: 0.081988\n",
      "Train Epoch: 5 [10000/11811 (84%)]\tLoss: 0.079119\n",
      "Train Epoch: 5 [11000/11811 (92%)]\tLoss: 0.085821\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/9726 (0%)]\tLoss: 0.159312\n",
      "Train Epoch: 1 [1000/9726 (10%)]\tLoss: 0.074483\n",
      "Train Epoch: 1 [2000/9726 (20%)]\tLoss: 0.228603\n",
      "Train Epoch: 1 [3000/9726 (31%)]\tLoss: 0.204935\n",
      "Train Epoch: 1 [4000/9726 (41%)]\tLoss: 0.141715\n",
      "Train Epoch: 1 [5000/9726 (51%)]\tLoss: 0.287202\n",
      "Train Epoch: 1 [6000/9726 (61%)]\tLoss: 0.286407\n",
      "Train Epoch: 1 [7000/9726 (71%)]\tLoss: 0.183239\n",
      "Train Epoch: 1 [8000/9726 (82%)]\tLoss: 0.124558\n",
      "Train Epoch: 1 [9000/9726 (92%)]\tLoss: 0.107591\n",
      "Train Epoch: 2 [0/9726 (0%)]\tLoss: 0.229328\n",
      "Train Epoch: 2 [1000/9726 (10%)]\tLoss: 0.179578\n",
      "Train Epoch: 2 [2000/9726 (20%)]\tLoss: 0.172075\n",
      "Train Epoch: 2 [3000/9726 (31%)]\tLoss: 0.147114\n",
      "Train Epoch: 2 [4000/9726 (41%)]\tLoss: 0.116567\n",
      "Train Epoch: 2 [5000/9726 (51%)]\tLoss: 0.314591\n",
      "Train Epoch: 2 [6000/9726 (61%)]\tLoss: 0.227192\n",
      "Train Epoch: 2 [7000/9726 (71%)]\tLoss: 0.151555\n",
      "Train Epoch: 2 [8000/9726 (82%)]\tLoss: 0.092809\n",
      "Train Epoch: 2 [9000/9726 (92%)]\tLoss: 0.167091\n",
      "Train Epoch: 3 [0/9726 (0%)]\tLoss: 0.206178\n",
      "Train Epoch: 3 [1000/9726 (10%)]\tLoss: 0.090093\n",
      "Train Epoch: 3 [2000/9726 (20%)]\tLoss: 0.158588\n",
      "Train Epoch: 3 [3000/9726 (31%)]\tLoss: 0.287694\n",
      "Train Epoch: 3 [4000/9726 (41%)]\tLoss: 0.138744\n",
      "Train Epoch: 3 [5000/9726 (51%)]\tLoss: 0.230068\n",
      "Train Epoch: 3 [6000/9726 (61%)]\tLoss: 0.156237\n",
      "Train Epoch: 3 [7000/9726 (71%)]\tLoss: 0.193582\n",
      "Train Epoch: 3 [8000/9726 (82%)]\tLoss: 0.140634\n",
      "Train Epoch: 3 [9000/9726 (92%)]\tLoss: 0.216858\n",
      "Train Epoch: 4 [0/9726 (0%)]\tLoss: 0.154317\n",
      "Train Epoch: 4 [1000/9726 (10%)]\tLoss: 0.152445\n",
      "Train Epoch: 4 [2000/9726 (20%)]\tLoss: 0.200387\n",
      "Train Epoch: 4 [3000/9726 (31%)]\tLoss: 0.133559\n",
      "Train Epoch: 4 [4000/9726 (41%)]\tLoss: 0.156538\n",
      "Train Epoch: 4 [5000/9726 (51%)]\tLoss: 0.196911\n",
      "Train Epoch: 4 [6000/9726 (61%)]\tLoss: 0.223758\n",
      "Train Epoch: 4 [7000/9726 (71%)]\tLoss: 0.250077\n",
      "Train Epoch: 4 [8000/9726 (82%)]\tLoss: 0.263016\n",
      "Train Epoch: 4 [9000/9726 (92%)]\tLoss: 0.211162\n",
      "Train Epoch: 5 [0/9726 (0%)]\tLoss: 0.112061\n",
      "Train Epoch: 5 [1000/9726 (10%)]\tLoss: 0.158742\n",
      "Train Epoch: 5 [2000/9726 (20%)]\tLoss: 0.140730\n",
      "Train Epoch: 5 [3000/9726 (31%)]\tLoss: 0.175476\n",
      "Train Epoch: 5 [4000/9726 (41%)]\tLoss: 0.192641\n",
      "Train Epoch: 5 [5000/9726 (51%)]\tLoss: 0.168499\n",
      "Train Epoch: 5 [6000/9726 (61%)]\tLoss: 0.152637\n",
      "Train Epoch: 5 [7000/9726 (71%)]\tLoss: 0.187902\n",
      "Train Epoch: 5 [8000/9726 (82%)]\tLoss: 0.196558\n",
      "Train Epoch: 5 [9000/9726 (92%)]\tLoss: 0.165516\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/6491 (0%)]\tLoss: 0.401602\n",
      "Train Epoch: 1 [1000/6491 (15%)]\tLoss: 0.147436\n",
      "Train Epoch: 1 [2000/6491 (31%)]\tLoss: 0.181405\n",
      "Train Epoch: 1 [3000/6491 (46%)]\tLoss: 0.260995\n",
      "Train Epoch: 1 [4000/6491 (62%)]\tLoss: 0.252555\n",
      "Train Epoch: 1 [5000/6491 (77%)]\tLoss: 0.216064\n",
      "Train Epoch: 1 [6000/6491 (92%)]\tLoss: 0.208437\n",
      "Train Epoch: 2 [0/6491 (0%)]\tLoss: 0.274643\n",
      "Train Epoch: 2 [1000/6491 (15%)]\tLoss: 0.224705\n",
      "Train Epoch: 2 [2000/6491 (31%)]\tLoss: 0.259230\n",
      "Train Epoch: 2 [3000/6491 (46%)]\tLoss: 0.225641\n",
      "Train Epoch: 2 [4000/6491 (62%)]\tLoss: 0.188423\n",
      "Train Epoch: 2 [5000/6491 (77%)]\tLoss: 0.233023\n",
      "Train Epoch: 2 [6000/6491 (92%)]\tLoss: 0.209848\n",
      "Train Epoch: 3 [0/6491 (0%)]\tLoss: 0.148229\n",
      "Train Epoch: 3 [1000/6491 (15%)]\tLoss: 0.139581\n",
      "Train Epoch: 3 [2000/6491 (31%)]\tLoss: 0.229097\n",
      "Train Epoch: 3 [3000/6491 (46%)]\tLoss: 0.252230\n",
      "Train Epoch: 3 [4000/6491 (62%)]\tLoss: 0.224047\n",
      "Train Epoch: 3 [5000/6491 (77%)]\tLoss: 0.304031\n",
      "Train Epoch: 3 [6000/6491 (92%)]\tLoss: 0.204922\n",
      "Train Epoch: 4 [0/6491 (0%)]\tLoss: 0.316874\n",
      "Train Epoch: 4 [1000/6491 (15%)]\tLoss: 0.320766\n",
      "Train Epoch: 4 [2000/6491 (31%)]\tLoss: 0.220152\n",
      "Train Epoch: 4 [3000/6491 (46%)]\tLoss: 0.180896\n",
      "Train Epoch: 4 [4000/6491 (62%)]\tLoss: 0.212585\n",
      "Train Epoch: 4 [5000/6491 (77%)]\tLoss: 0.181031\n",
      "Train Epoch: 4 [6000/6491 (92%)]\tLoss: 0.200726\n",
      "Train Epoch: 5 [0/6491 (0%)]\tLoss: 0.199549\n",
      "Train Epoch: 5 [1000/6491 (15%)]\tLoss: 0.182928\n",
      "Train Epoch: 5 [2000/6491 (31%)]\tLoss: 0.335537\n",
      "Train Epoch: 5 [3000/6491 (46%)]\tLoss: 0.186667\n",
      "Train Epoch: 5 [4000/6491 (62%)]\tLoss: 0.178209\n",
      "Train Epoch: 5 [5000/6491 (77%)]\tLoss: 0.322498\n",
      "Train Epoch: 5 [6000/6491 (92%)]\tLoss: 0.206473\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/14118 (0%)]\tLoss: 0.292515\n",
      "Train Epoch: 1 [1000/14118 (7%)]\tLoss: 0.145535\n",
      "Train Epoch: 1 [2000/14118 (14%)]\tLoss: 0.048232\n",
      "Train Epoch: 1 [3000/14118 (21%)]\tLoss: 0.153639\n",
      "Train Epoch: 1 [4000/14118 (28%)]\tLoss: 0.205066\n",
      "Train Epoch: 1 [5000/14118 (35%)]\tLoss: 0.177133\n",
      "Train Epoch: 1 [6000/14118 (42%)]\tLoss: 0.159838\n",
      "Train Epoch: 1 [7000/14118 (49%)]\tLoss: 0.115971\n",
      "Train Epoch: 1 [8000/14118 (56%)]\tLoss: 0.280953\n",
      "Train Epoch: 1 [9000/14118 (63%)]\tLoss: 0.084978\n",
      "Train Epoch: 1 [10000/14118 (70%)]\tLoss: 0.219032\n",
      "Train Epoch: 1 [11000/14118 (77%)]\tLoss: 0.096752\n",
      "Train Epoch: 1 [12000/14118 (85%)]\tLoss: 0.250931\n",
      "Train Epoch: 1 [13000/14118 (92%)]\tLoss: 0.186486\n",
      "Train Epoch: 1 [14000/14118 (99%)]\tLoss: 0.231357\n",
      "Train Epoch: 2 [0/14118 (0%)]\tLoss: 0.183168\n",
      "Train Epoch: 2 [1000/14118 (7%)]\tLoss: 0.092581\n",
      "Train Epoch: 2 [2000/14118 (14%)]\tLoss: 0.109311\n",
      "Train Epoch: 2 [3000/14118 (21%)]\tLoss: 0.178595\n",
      "Train Epoch: 2 [4000/14118 (28%)]\tLoss: 0.088185\n",
      "Train Epoch: 2 [5000/14118 (35%)]\tLoss: 0.226743\n",
      "Train Epoch: 2 [6000/14118 (42%)]\tLoss: 0.236414\n",
      "Train Epoch: 2 [7000/14118 (49%)]\tLoss: 0.189637\n",
      "Train Epoch: 2 [8000/14118 (56%)]\tLoss: 0.123202\n",
      "Train Epoch: 2 [9000/14118 (63%)]\tLoss: 0.181843\n",
      "Train Epoch: 2 [10000/14118 (70%)]\tLoss: 0.113236\n",
      "Train Epoch: 2 [11000/14118 (77%)]\tLoss: 0.139251\n",
      "Train Epoch: 2 [12000/14118 (85%)]\tLoss: 0.190382\n",
      "Train Epoch: 2 [13000/14118 (92%)]\tLoss: 0.139032\n",
      "Train Epoch: 2 [14000/14118 (99%)]\tLoss: 0.130041\n",
      "Train Epoch: 3 [0/14118 (0%)]\tLoss: 0.105554\n",
      "Train Epoch: 3 [1000/14118 (7%)]\tLoss: 0.160614\n",
      "Train Epoch: 3 [2000/14118 (14%)]\tLoss: 0.211366\n",
      "Train Epoch: 3 [3000/14118 (21%)]\tLoss: 0.161971\n",
      "Train Epoch: 3 [4000/14118 (28%)]\tLoss: 0.109390\n",
      "Train Epoch: 3 [5000/14118 (35%)]\tLoss: 0.148404\n",
      "Train Epoch: 3 [6000/14118 (42%)]\tLoss: 0.239057\n",
      "Train Epoch: 3 [7000/14118 (49%)]\tLoss: 0.187032\n",
      "Train Epoch: 3 [8000/14118 (56%)]\tLoss: 0.097190\n",
      "Train Epoch: 3 [9000/14118 (63%)]\tLoss: 0.112479\n",
      "Train Epoch: 3 [10000/14118 (70%)]\tLoss: 0.079523\n",
      "Train Epoch: 3 [11000/14118 (77%)]\tLoss: 0.103738\n",
      "Train Epoch: 3 [12000/14118 (85%)]\tLoss: 0.143449\n",
      "Train Epoch: 3 [13000/14118 (92%)]\tLoss: 0.204468\n",
      "Train Epoch: 3 [14000/14118 (99%)]\tLoss: 0.126417\n",
      "Train Epoch: 4 [0/14118 (0%)]\tLoss: 0.131043\n",
      "Train Epoch: 4 [1000/14118 (7%)]\tLoss: 0.123757\n",
      "Train Epoch: 4 [2000/14118 (14%)]\tLoss: 0.120347\n",
      "Train Epoch: 4 [3000/14118 (21%)]\tLoss: 0.282246\n",
      "Train Epoch: 4 [4000/14118 (28%)]\tLoss: 0.130561\n",
      "Train Epoch: 4 [5000/14118 (35%)]\tLoss: 0.177536\n",
      "Train Epoch: 4 [6000/14118 (42%)]\tLoss: 0.165515\n",
      "Train Epoch: 4 [7000/14118 (49%)]\tLoss: 0.095743\n",
      "Train Epoch: 4 [8000/14118 (56%)]\tLoss: 0.154290\n",
      "Train Epoch: 4 [9000/14118 (63%)]\tLoss: 0.114039\n",
      "Train Epoch: 4 [10000/14118 (70%)]\tLoss: 0.098952\n",
      "Train Epoch: 4 [11000/14118 (77%)]\tLoss: 0.194513\n",
      "Train Epoch: 4 [12000/14118 (85%)]\tLoss: 0.083689\n",
      "Train Epoch: 4 [13000/14118 (92%)]\tLoss: 0.235118\n",
      "Train Epoch: 4 [14000/14118 (99%)]\tLoss: 0.110888\n",
      "Train Epoch: 5 [0/14118 (0%)]\tLoss: 0.120730\n",
      "Train Epoch: 5 [1000/14118 (7%)]\tLoss: 0.077174\n",
      "Train Epoch: 5 [2000/14118 (14%)]\tLoss: 0.039381\n",
      "Train Epoch: 5 [3000/14118 (21%)]\tLoss: 0.071898\n",
      "Train Epoch: 5 [4000/14118 (28%)]\tLoss: 0.121162\n",
      "Train Epoch: 5 [5000/14118 (35%)]\tLoss: 0.129010\n",
      "Train Epoch: 5 [6000/14118 (42%)]\tLoss: 0.217826\n",
      "Train Epoch: 5 [7000/14118 (49%)]\tLoss: 0.127531\n",
      "Train Epoch: 5 [8000/14118 (56%)]\tLoss: 0.076630\n",
      "Train Epoch: 5 [9000/14118 (63%)]\tLoss: 0.111200\n",
      "Train Epoch: 5 [10000/14118 (70%)]\tLoss: 0.111586\n",
      "Train Epoch: 5 [11000/14118 (77%)]\tLoss: 0.109741\n",
      "Train Epoch: 5 [12000/14118 (85%)]\tLoss: 0.149165\n",
      "Train Epoch: 5 [13000/14118 (92%)]\tLoss: 0.123673\n",
      "Train Epoch: 5 [14000/14118 (99%)]\tLoss: 0.089630\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/9414 (0%)]\tLoss: 0.281000\n",
      "Train Epoch: 1 [1000/9414 (11%)]\tLoss: 0.271098\n",
      "Train Epoch: 1 [2000/9414 (21%)]\tLoss: 0.252262\n",
      "Train Epoch: 1 [3000/9414 (32%)]\tLoss: 0.180141\n",
      "Train Epoch: 1 [4000/9414 (42%)]\tLoss: 0.207725\n",
      "Train Epoch: 1 [5000/9414 (53%)]\tLoss: 0.215468\n",
      "Train Epoch: 1 [6000/9414 (63%)]\tLoss: 0.222181\n",
      "Train Epoch: 1 [7000/9414 (74%)]\tLoss: 0.145641\n",
      "Train Epoch: 1 [8000/9414 (84%)]\tLoss: 0.213672\n",
      "Train Epoch: 1 [9000/9414 (95%)]\tLoss: 0.255032\n",
      "Train Epoch: 2 [0/9414 (0%)]\tLoss: 0.252019\n",
      "Train Epoch: 2 [1000/9414 (11%)]\tLoss: 0.185108\n",
      "Train Epoch: 2 [2000/9414 (21%)]\tLoss: 0.316624\n",
      "Train Epoch: 2 [3000/9414 (32%)]\tLoss: 0.081652\n",
      "Train Epoch: 2 [4000/9414 (42%)]\tLoss: 0.167475\n",
      "Train Epoch: 2 [5000/9414 (53%)]\tLoss: 0.168424\n",
      "Train Epoch: 2 [6000/9414 (63%)]\tLoss: 0.182657\n",
      "Train Epoch: 2 [7000/9414 (74%)]\tLoss: 0.122887\n",
      "Train Epoch: 2 [8000/9414 (84%)]\tLoss: 0.198383\n",
      "Train Epoch: 2 [9000/9414 (95%)]\tLoss: 0.163414\n",
      "Train Epoch: 3 [0/9414 (0%)]\tLoss: 0.128817\n",
      "Train Epoch: 3 [1000/9414 (11%)]\tLoss: 0.159907\n",
      "Train Epoch: 3 [2000/9414 (21%)]\tLoss: 0.158461\n",
      "Train Epoch: 3 [3000/9414 (32%)]\tLoss: 0.190268\n",
      "Train Epoch: 3 [4000/9414 (42%)]\tLoss: 0.263057\n",
      "Train Epoch: 3 [5000/9414 (53%)]\tLoss: 0.244300\n",
      "Train Epoch: 3 [6000/9414 (63%)]\tLoss: 0.179476\n",
      "Train Epoch: 3 [7000/9414 (74%)]\tLoss: 0.155141\n",
      "Train Epoch: 3 [8000/9414 (84%)]\tLoss: 0.188940\n",
      "Train Epoch: 3 [9000/9414 (95%)]\tLoss: 0.164752\n",
      "Train Epoch: 4 [0/9414 (0%)]\tLoss: 0.186536\n",
      "Train Epoch: 4 [1000/9414 (11%)]\tLoss: 0.169920\n",
      "Train Epoch: 4 [2000/9414 (21%)]\tLoss: 0.189255\n",
      "Train Epoch: 4 [3000/9414 (32%)]\tLoss: 0.271305\n",
      "Train Epoch: 4 [4000/9414 (42%)]\tLoss: 0.161122\n",
      "Train Epoch: 4 [5000/9414 (53%)]\tLoss: 0.119506\n",
      "Train Epoch: 4 [6000/9414 (63%)]\tLoss: 0.193564\n",
      "Train Epoch: 4 [7000/9414 (74%)]\tLoss: 0.187398\n",
      "Train Epoch: 4 [8000/9414 (84%)]\tLoss: 0.162978\n",
      "Train Epoch: 4 [9000/9414 (95%)]\tLoss: 0.210807\n",
      "Train Epoch: 5 [0/9414 (0%)]\tLoss: 0.196017\n",
      "Train Epoch: 5 [1000/9414 (11%)]\tLoss: 0.107012\n",
      "Train Epoch: 5 [2000/9414 (21%)]\tLoss: 0.144825\n",
      "Train Epoch: 5 [3000/9414 (32%)]\tLoss: 0.195713\n",
      "Train Epoch: 5 [4000/9414 (42%)]\tLoss: 0.205964\n",
      "Train Epoch: 5 [5000/9414 (53%)]\tLoss: 0.218870\n",
      "Train Epoch: 5 [6000/9414 (63%)]\tLoss: 0.167869\n",
      "Train Epoch: 5 [7000/9414 (74%)]\tLoss: 0.178745\n",
      "Train Epoch: 5 [8000/9414 (84%)]\tLoss: 0.164811\n",
      "Train Epoch: 5 [9000/9414 (95%)]\tLoss: 0.194958\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "6\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.6618, Accuracy: 8602/10000 (86%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/8440 (0%)]\tLoss: 0.302344\n",
      "Train Epoch: 1 [1000/8440 (12%)]\tLoss: 0.288533\n",
      "Train Epoch: 1 [2000/8440 (24%)]\tLoss: 0.242541\n",
      "Train Epoch: 1 [3000/8440 (35%)]\tLoss: 0.225789\n",
      "Train Epoch: 1 [4000/8440 (47%)]\tLoss: 0.338491\n",
      "Train Epoch: 1 [5000/8440 (59%)]\tLoss: 0.223791\n",
      "Train Epoch: 1 [6000/8440 (71%)]\tLoss: 0.241278\n",
      "Train Epoch: 1 [7000/8440 (82%)]\tLoss: 0.141443\n",
      "Train Epoch: 1 [8000/8440 (94%)]\tLoss: 0.225789\n",
      "Train Epoch: 2 [0/8440 (0%)]\tLoss: 0.160163\n",
      "Train Epoch: 2 [1000/8440 (12%)]\tLoss: 0.184383\n",
      "Train Epoch: 2 [2000/8440 (24%)]\tLoss: 0.121251\n",
      "Train Epoch: 2 [3000/8440 (35%)]\tLoss: 0.186450\n",
      "Train Epoch: 2 [4000/8440 (47%)]\tLoss: 0.302969\n",
      "Train Epoch: 2 [5000/8440 (59%)]\tLoss: 0.213247\n",
      "Train Epoch: 2 [6000/8440 (71%)]\tLoss: 0.323532\n",
      "Train Epoch: 2 [7000/8440 (82%)]\tLoss: 0.200808\n",
      "Train Epoch: 2 [8000/8440 (94%)]\tLoss: 0.320551\n",
      "Train Epoch: 3 [0/8440 (0%)]\tLoss: 0.141590\n",
      "Train Epoch: 3 [1000/8440 (12%)]\tLoss: 0.161272\n",
      "Train Epoch: 3 [2000/8440 (24%)]\tLoss: 0.182222\n",
      "Train Epoch: 3 [3000/8440 (35%)]\tLoss: 0.194976\n",
      "Train Epoch: 3 [4000/8440 (47%)]\tLoss: 0.243429\n",
      "Train Epoch: 3 [5000/8440 (59%)]\tLoss: 0.216441\n",
      "Train Epoch: 3 [6000/8440 (71%)]\tLoss: 0.220490\n",
      "Train Epoch: 3 [7000/8440 (82%)]\tLoss: 0.186469\n",
      "Train Epoch: 3 [8000/8440 (94%)]\tLoss: 0.315979\n",
      "Train Epoch: 4 [0/8440 (0%)]\tLoss: 0.136009\n",
      "Train Epoch: 4 [1000/8440 (12%)]\tLoss: 0.195974\n",
      "Train Epoch: 4 [2000/8440 (24%)]\tLoss: 0.136952\n",
      "Train Epoch: 4 [3000/8440 (35%)]\tLoss: 0.205599\n",
      "Train Epoch: 4 [4000/8440 (47%)]\tLoss: 0.191806\n",
      "Train Epoch: 4 [5000/8440 (59%)]\tLoss: 0.305750\n",
      "Train Epoch: 4 [6000/8440 (71%)]\tLoss: 0.263044\n",
      "Train Epoch: 4 [7000/8440 (82%)]\tLoss: 0.256431\n",
      "Train Epoch: 4 [8000/8440 (94%)]\tLoss: 0.115640\n",
      "Train Epoch: 5 [0/8440 (0%)]\tLoss: 0.183800\n",
      "Train Epoch: 5 [1000/8440 (12%)]\tLoss: 0.155540\n",
      "Train Epoch: 5 [2000/8440 (24%)]\tLoss: 0.204281\n",
      "Train Epoch: 5 [3000/8440 (35%)]\tLoss: 0.161514\n",
      "Train Epoch: 5 [4000/8440 (47%)]\tLoss: 0.184796\n",
      "Train Epoch: 5 [5000/8440 (59%)]\tLoss: 0.198882\n",
      "Train Epoch: 5 [6000/8440 (71%)]\tLoss: 0.277279\n",
      "Train Epoch: 5 [7000/8440 (82%)]\tLoss: 0.185211\n",
      "Train Epoch: 5 [8000/8440 (94%)]\tLoss: 0.373764\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11811 (0%)]\tLoss: 0.152345\n",
      "Train Epoch: 1 [1000/11811 (8%)]\tLoss: 0.038865\n",
      "Train Epoch: 1 [2000/11811 (17%)]\tLoss: 0.085181\n",
      "Train Epoch: 1 [3000/11811 (25%)]\tLoss: 0.127923\n",
      "Train Epoch: 1 [4000/11811 (34%)]\tLoss: 0.084603\n",
      "Train Epoch: 1 [5000/11811 (42%)]\tLoss: 0.082302\n",
      "Train Epoch: 1 [6000/11811 (50%)]\tLoss: 0.098777\n",
      "Train Epoch: 1 [7000/11811 (59%)]\tLoss: 0.043029\n",
      "Train Epoch: 1 [8000/11811 (67%)]\tLoss: 0.085600\n",
      "Train Epoch: 1 [9000/11811 (76%)]\tLoss: 0.108937\n",
      "Train Epoch: 1 [10000/11811 (84%)]\tLoss: 0.170650\n",
      "Train Epoch: 1 [11000/11811 (92%)]\tLoss: 0.089330\n",
      "Train Epoch: 2 [0/11811 (0%)]\tLoss: 0.199308\n",
      "Train Epoch: 2 [1000/11811 (8%)]\tLoss: 0.175681\n",
      "Train Epoch: 2 [2000/11811 (17%)]\tLoss: 0.108712\n",
      "Train Epoch: 2 [3000/11811 (25%)]\tLoss: 0.075487\n",
      "Train Epoch: 2 [4000/11811 (34%)]\tLoss: 0.099652\n",
      "Train Epoch: 2 [5000/11811 (42%)]\tLoss: 0.054700\n",
      "Train Epoch: 2 [6000/11811 (50%)]\tLoss: 0.055138\n",
      "Train Epoch: 2 [7000/11811 (59%)]\tLoss: 0.054176\n",
      "Train Epoch: 2 [8000/11811 (67%)]\tLoss: 0.154149\n",
      "Train Epoch: 2 [9000/11811 (76%)]\tLoss: 0.058155\n",
      "Train Epoch: 2 [10000/11811 (84%)]\tLoss: 0.063864\n",
      "Train Epoch: 2 [11000/11811 (92%)]\tLoss: 0.108660\n",
      "Train Epoch: 3 [0/11811 (0%)]\tLoss: 0.110747\n",
      "Train Epoch: 3 [1000/11811 (8%)]\tLoss: 0.103329\n",
      "Train Epoch: 3 [2000/11811 (17%)]\tLoss: 0.045013\n",
      "Train Epoch: 3 [3000/11811 (25%)]\tLoss: 0.031511\n",
      "Train Epoch: 3 [4000/11811 (34%)]\tLoss: 0.050662\n",
      "Train Epoch: 3 [5000/11811 (42%)]\tLoss: 0.067860\n",
      "Train Epoch: 3 [6000/11811 (50%)]\tLoss: 0.049497\n",
      "Train Epoch: 3 [7000/11811 (59%)]\tLoss: 0.056257\n",
      "Train Epoch: 3 [8000/11811 (67%)]\tLoss: 0.073414\n",
      "Train Epoch: 3 [9000/11811 (76%)]\tLoss: 0.057848\n",
      "Train Epoch: 3 [10000/11811 (84%)]\tLoss: 0.063662\n",
      "Train Epoch: 3 [11000/11811 (92%)]\tLoss: 0.024460\n",
      "Train Epoch: 4 [0/11811 (0%)]\tLoss: 0.192284\n",
      "Train Epoch: 4 [1000/11811 (8%)]\tLoss: 0.081259\n",
      "Train Epoch: 4 [2000/11811 (17%)]\tLoss: 0.115741\n",
      "Train Epoch: 4 [3000/11811 (25%)]\tLoss: 0.029507\n",
      "Train Epoch: 4 [4000/11811 (34%)]\tLoss: 0.106746\n",
      "Train Epoch: 4 [5000/11811 (42%)]\tLoss: 0.133023\n",
      "Train Epoch: 4 [6000/11811 (50%)]\tLoss: 0.049047\n",
      "Train Epoch: 4 [7000/11811 (59%)]\tLoss: 0.139872\n",
      "Train Epoch: 4 [8000/11811 (67%)]\tLoss: 0.033625\n",
      "Train Epoch: 4 [9000/11811 (76%)]\tLoss: 0.068741\n",
      "Train Epoch: 4 [10000/11811 (84%)]\tLoss: 0.039361\n",
      "Train Epoch: 4 [11000/11811 (92%)]\tLoss: 0.018413\n",
      "Train Epoch: 5 [0/11811 (0%)]\tLoss: 0.057396\n",
      "Train Epoch: 5 [1000/11811 (8%)]\tLoss: 0.069574\n",
      "Train Epoch: 5 [2000/11811 (17%)]\tLoss: 0.028446\n",
      "Train Epoch: 5 [3000/11811 (25%)]\tLoss: 0.056528\n",
      "Train Epoch: 5 [4000/11811 (34%)]\tLoss: 0.041300\n",
      "Train Epoch: 5 [5000/11811 (42%)]\tLoss: 0.117051\n",
      "Train Epoch: 5 [6000/11811 (50%)]\tLoss: 0.046817\n",
      "Train Epoch: 5 [7000/11811 (59%)]\tLoss: 0.024850\n",
      "Train Epoch: 5 [8000/11811 (67%)]\tLoss: 0.036752\n",
      "Train Epoch: 5 [9000/11811 (76%)]\tLoss: 0.089719\n",
      "Train Epoch: 5 [10000/11811 (84%)]\tLoss: 0.047432\n",
      "Train Epoch: 5 [11000/11811 (92%)]\tLoss: 0.041859\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/9726 (0%)]\tLoss: 0.132422\n",
      "Train Epoch: 1 [1000/9726 (10%)]\tLoss: 0.209505\n",
      "Train Epoch: 1 [2000/9726 (20%)]\tLoss: 0.206721\n",
      "Train Epoch: 1 [3000/9726 (31%)]\tLoss: 0.208607\n",
      "Train Epoch: 1 [4000/9726 (41%)]\tLoss: 0.155502\n",
      "Train Epoch: 1 [5000/9726 (51%)]\tLoss: 0.100623\n",
      "Train Epoch: 1 [6000/9726 (61%)]\tLoss: 0.124545\n",
      "Train Epoch: 1 [7000/9726 (71%)]\tLoss: 0.261850\n",
      "Train Epoch: 1 [8000/9726 (82%)]\tLoss: 0.222658\n",
      "Train Epoch: 1 [9000/9726 (92%)]\tLoss: 0.116094\n",
      "Train Epoch: 2 [0/9726 (0%)]\tLoss: 0.203717\n",
      "Train Epoch: 2 [1000/9726 (10%)]\tLoss: 0.136564\n",
      "Train Epoch: 2 [2000/9726 (20%)]\tLoss: 0.374068\n",
      "Train Epoch: 2 [3000/9726 (31%)]\tLoss: 0.208500\n",
      "Train Epoch: 2 [4000/9726 (41%)]\tLoss: 0.167339\n",
      "Train Epoch: 2 [5000/9726 (51%)]\tLoss: 0.141782\n",
      "Train Epoch: 2 [6000/9726 (61%)]\tLoss: 0.178192\n",
      "Train Epoch: 2 [7000/9726 (71%)]\tLoss: 0.140050\n",
      "Train Epoch: 2 [8000/9726 (82%)]\tLoss: 0.214258\n",
      "Train Epoch: 2 [9000/9726 (92%)]\tLoss: 0.183186\n",
      "Train Epoch: 3 [0/9726 (0%)]\tLoss: 0.170593\n",
      "Train Epoch: 3 [1000/9726 (10%)]\tLoss: 0.158926\n",
      "Train Epoch: 3 [2000/9726 (20%)]\tLoss: 0.191258\n",
      "Train Epoch: 3 [3000/9726 (31%)]\tLoss: 0.204409\n",
      "Train Epoch: 3 [4000/9726 (41%)]\tLoss: 0.104160\n",
      "Train Epoch: 3 [5000/9726 (51%)]\tLoss: 0.158854\n",
      "Train Epoch: 3 [6000/9726 (61%)]\tLoss: 0.162602\n",
      "Train Epoch: 3 [7000/9726 (71%)]\tLoss: 0.129852\n",
      "Train Epoch: 3 [8000/9726 (82%)]\tLoss: 0.098699\n",
      "Train Epoch: 3 [9000/9726 (92%)]\tLoss: 0.074817\n",
      "Train Epoch: 4 [0/9726 (0%)]\tLoss: 0.073560\n",
      "Train Epoch: 4 [1000/9726 (10%)]\tLoss: 0.195018\n",
      "Train Epoch: 4 [2000/9726 (20%)]\tLoss: 0.138031\n",
      "Train Epoch: 4 [3000/9726 (31%)]\tLoss: 0.172352\n",
      "Train Epoch: 4 [4000/9726 (41%)]\tLoss: 0.235736\n",
      "Train Epoch: 4 [5000/9726 (51%)]\tLoss: 0.056473\n",
      "Train Epoch: 4 [6000/9726 (61%)]\tLoss: 0.128279\n",
      "Train Epoch: 4 [7000/9726 (71%)]\tLoss: 0.065947\n",
      "Train Epoch: 4 [8000/9726 (82%)]\tLoss: 0.127648\n",
      "Train Epoch: 4 [9000/9726 (92%)]\tLoss: 0.145883\n",
      "Train Epoch: 5 [0/9726 (0%)]\tLoss: 0.087132\n",
      "Train Epoch: 5 [1000/9726 (10%)]\tLoss: 0.135113\n",
      "Train Epoch: 5 [2000/9726 (20%)]\tLoss: 0.172827\n",
      "Train Epoch: 5 [3000/9726 (31%)]\tLoss: 0.096627\n",
      "Train Epoch: 5 [4000/9726 (41%)]\tLoss: 0.138260\n",
      "Train Epoch: 5 [5000/9726 (51%)]\tLoss: 0.193726\n",
      "Train Epoch: 5 [6000/9726 (61%)]\tLoss: 0.161650\n",
      "Train Epoch: 5 [7000/9726 (71%)]\tLoss: 0.209946\n",
      "Train Epoch: 5 [8000/9726 (82%)]\tLoss: 0.154247\n",
      "Train Epoch: 5 [9000/9726 (92%)]\tLoss: 0.094818\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/6491 (0%)]\tLoss: 0.322504\n",
      "Train Epoch: 1 [1000/6491 (15%)]\tLoss: 0.255041\n",
      "Train Epoch: 1 [2000/6491 (31%)]\tLoss: 0.311767\n",
      "Train Epoch: 1 [3000/6491 (46%)]\tLoss: 0.212709\n",
      "Train Epoch: 1 [4000/6491 (62%)]\tLoss: 0.241826\n",
      "Train Epoch: 1 [5000/6491 (77%)]\tLoss: 0.149880\n",
      "Train Epoch: 1 [6000/6491 (92%)]\tLoss: 0.237801\n",
      "Train Epoch: 2 [0/6491 (0%)]\tLoss: 0.267018\n",
      "Train Epoch: 2 [1000/6491 (15%)]\tLoss: 0.219362\n",
      "Train Epoch: 2 [2000/6491 (31%)]\tLoss: 0.246557\n",
      "Train Epoch: 2 [3000/6491 (46%)]\tLoss: 0.246727\n",
      "Train Epoch: 2 [4000/6491 (62%)]\tLoss: 0.287403\n",
      "Train Epoch: 2 [5000/6491 (77%)]\tLoss: 0.292113\n",
      "Train Epoch: 2 [6000/6491 (92%)]\tLoss: 0.290391\n",
      "Train Epoch: 3 [0/6491 (0%)]\tLoss: 0.113675\n",
      "Train Epoch: 3 [1000/6491 (15%)]\tLoss: 0.231050\n",
      "Train Epoch: 3 [2000/6491 (31%)]\tLoss: 0.254361\n",
      "Train Epoch: 3 [3000/6491 (46%)]\tLoss: 0.190234\n",
      "Train Epoch: 3 [4000/6491 (62%)]\tLoss: 0.306987\n",
      "Train Epoch: 3 [5000/6491 (77%)]\tLoss: 0.241209\n",
      "Train Epoch: 3 [6000/6491 (92%)]\tLoss: 0.236139\n",
      "Train Epoch: 4 [0/6491 (0%)]\tLoss: 0.186605\n",
      "Train Epoch: 4 [1000/6491 (15%)]\tLoss: 0.315947\n",
      "Train Epoch: 4 [2000/6491 (31%)]\tLoss: 0.208287\n",
      "Train Epoch: 4 [3000/6491 (46%)]\tLoss: 0.190140\n",
      "Train Epoch: 4 [4000/6491 (62%)]\tLoss: 0.304077\n",
      "Train Epoch: 4 [5000/6491 (77%)]\tLoss: 0.240542\n",
      "Train Epoch: 4 [6000/6491 (92%)]\tLoss: 0.249174\n",
      "Train Epoch: 5 [0/6491 (0%)]\tLoss: 0.234122\n",
      "Train Epoch: 5 [1000/6491 (15%)]\tLoss: 0.177180\n",
      "Train Epoch: 5 [2000/6491 (31%)]\tLoss: 0.171492\n",
      "Train Epoch: 5 [3000/6491 (46%)]\tLoss: 0.197359\n",
      "Train Epoch: 5 [4000/6491 (62%)]\tLoss: 0.257043\n",
      "Train Epoch: 5 [5000/6491 (77%)]\tLoss: 0.168653\n",
      "Train Epoch: 5 [6000/6491 (92%)]\tLoss: 0.150051\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/14118 (0%)]\tLoss: 0.323226\n",
      "Train Epoch: 1 [1000/14118 (7%)]\tLoss: 0.116575\n",
      "Train Epoch: 1 [2000/14118 (14%)]\tLoss: 0.137225\n",
      "Train Epoch: 1 [3000/14118 (21%)]\tLoss: 0.198775\n",
      "Train Epoch: 1 [4000/14118 (28%)]\tLoss: 0.133888\n",
      "Train Epoch: 1 [5000/14118 (35%)]\tLoss: 0.169938\n",
      "Train Epoch: 1 [6000/14118 (42%)]\tLoss: 0.284879\n",
      "Train Epoch: 1 [7000/14118 (49%)]\tLoss: 0.115283\n",
      "Train Epoch: 1 [8000/14118 (56%)]\tLoss: 0.097860\n",
      "Train Epoch: 1 [9000/14118 (63%)]\tLoss: 0.104866\n",
      "Train Epoch: 1 [10000/14118 (70%)]\tLoss: 0.142595\n",
      "Train Epoch: 1 [11000/14118 (77%)]\tLoss: 0.156706\n",
      "Train Epoch: 1 [12000/14118 (85%)]\tLoss: 0.154439\n",
      "Train Epoch: 1 [13000/14118 (92%)]\tLoss: 0.181621\n",
      "Train Epoch: 1 [14000/14118 (99%)]\tLoss: 0.227660\n",
      "Train Epoch: 2 [0/14118 (0%)]\tLoss: 0.128774\n",
      "Train Epoch: 2 [1000/14118 (7%)]\tLoss: 0.171708\n",
      "Train Epoch: 2 [2000/14118 (14%)]\tLoss: 0.086159\n",
      "Train Epoch: 2 [3000/14118 (21%)]\tLoss: 0.134612\n",
      "Train Epoch: 2 [4000/14118 (28%)]\tLoss: 0.113366\n",
      "Train Epoch: 2 [5000/14118 (35%)]\tLoss: 0.095287\n",
      "Train Epoch: 2 [6000/14118 (42%)]\tLoss: 0.087919\n",
      "Train Epoch: 2 [7000/14118 (49%)]\tLoss: 0.122464\n",
      "Train Epoch: 2 [8000/14118 (56%)]\tLoss: 0.214294\n",
      "Train Epoch: 2 [9000/14118 (63%)]\tLoss: 0.069175\n",
      "Train Epoch: 2 [10000/14118 (70%)]\tLoss: 0.192011\n",
      "Train Epoch: 2 [11000/14118 (77%)]\tLoss: 0.153274\n",
      "Train Epoch: 2 [12000/14118 (85%)]\tLoss: 0.136039\n",
      "Train Epoch: 2 [13000/14118 (92%)]\tLoss: 0.133926\n",
      "Train Epoch: 2 [14000/14118 (99%)]\tLoss: 0.059333\n",
      "Train Epoch: 3 [0/14118 (0%)]\tLoss: 0.090649\n",
      "Train Epoch: 3 [1000/14118 (7%)]\tLoss: 0.147331\n",
      "Train Epoch: 3 [2000/14118 (14%)]\tLoss: 0.106284\n",
      "Train Epoch: 3 [3000/14118 (21%)]\tLoss: 0.085584\n",
      "Train Epoch: 3 [4000/14118 (28%)]\tLoss: 0.114647\n",
      "Train Epoch: 3 [5000/14118 (35%)]\tLoss: 0.108443\n",
      "Train Epoch: 3 [6000/14118 (42%)]\tLoss: 0.145812\n",
      "Train Epoch: 3 [7000/14118 (49%)]\tLoss: 0.105972\n",
      "Train Epoch: 3 [8000/14118 (56%)]\tLoss: 0.164071\n",
      "Train Epoch: 3 [9000/14118 (63%)]\tLoss: 0.221180\n",
      "Train Epoch: 3 [10000/14118 (70%)]\tLoss: 0.237044\n",
      "Train Epoch: 3 [11000/14118 (77%)]\tLoss: 0.109457\n",
      "Train Epoch: 3 [12000/14118 (85%)]\tLoss: 0.068711\n",
      "Train Epoch: 3 [13000/14118 (92%)]\tLoss: 0.122954\n",
      "Train Epoch: 3 [14000/14118 (99%)]\tLoss: 0.123898\n",
      "Train Epoch: 4 [0/14118 (0%)]\tLoss: 0.091370\n",
      "Train Epoch: 4 [1000/14118 (7%)]\tLoss: 0.100771\n",
      "Train Epoch: 4 [2000/14118 (14%)]\tLoss: 0.249603\n",
      "Train Epoch: 4 [3000/14118 (21%)]\tLoss: 0.140169\n",
      "Train Epoch: 4 [4000/14118 (28%)]\tLoss: 0.127250\n",
      "Train Epoch: 4 [5000/14118 (35%)]\tLoss: 0.114726\n",
      "Train Epoch: 4 [6000/14118 (42%)]\tLoss: 0.117803\n",
      "Train Epoch: 4 [7000/14118 (49%)]\tLoss: 0.215079\n",
      "Train Epoch: 4 [8000/14118 (56%)]\tLoss: 0.085824\n",
      "Train Epoch: 4 [9000/14118 (63%)]\tLoss: 0.166202\n",
      "Train Epoch: 4 [10000/14118 (70%)]\tLoss: 0.090435\n",
      "Train Epoch: 4 [11000/14118 (77%)]\tLoss: 0.088700\n",
      "Train Epoch: 4 [12000/14118 (85%)]\tLoss: 0.105158\n",
      "Train Epoch: 4 [13000/14118 (92%)]\tLoss: 0.080688\n",
      "Train Epoch: 4 [14000/14118 (99%)]\tLoss: 0.193319\n",
      "Train Epoch: 5 [0/14118 (0%)]\tLoss: 0.114118\n",
      "Train Epoch: 5 [1000/14118 (7%)]\tLoss: 0.097892\n",
      "Train Epoch: 5 [2000/14118 (14%)]\tLoss: 0.151047\n",
      "Train Epoch: 5 [3000/14118 (21%)]\tLoss: 0.082646\n",
      "Train Epoch: 5 [4000/14118 (28%)]\tLoss: 0.207746\n",
      "Train Epoch: 5 [5000/14118 (35%)]\tLoss: 0.180758\n",
      "Train Epoch: 5 [6000/14118 (42%)]\tLoss: 0.204563\n",
      "Train Epoch: 5 [7000/14118 (49%)]\tLoss: 0.127828\n",
      "Train Epoch: 5 [8000/14118 (56%)]\tLoss: 0.105289\n",
      "Train Epoch: 5 [9000/14118 (63%)]\tLoss: 0.107516\n",
      "Train Epoch: 5 [10000/14118 (70%)]\tLoss: 0.120501\n",
      "Train Epoch: 5 [11000/14118 (77%)]\tLoss: 0.123701\n",
      "Train Epoch: 5 [12000/14118 (85%)]\tLoss: 0.072914\n",
      "Train Epoch: 5 [13000/14118 (92%)]\tLoss: 0.160010\n",
      "Train Epoch: 5 [14000/14118 (99%)]\tLoss: 0.099572\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/9414 (0%)]\tLoss: 0.456091\n",
      "Train Epoch: 1 [1000/9414 (11%)]\tLoss: 0.103615\n",
      "Train Epoch: 1 [2000/9414 (21%)]\tLoss: 0.320477\n",
      "Train Epoch: 1 [3000/9414 (32%)]\tLoss: 0.173166\n",
      "Train Epoch: 1 [4000/9414 (42%)]\tLoss: 0.290019\n",
      "Train Epoch: 1 [5000/9414 (53%)]\tLoss: 0.142600\n",
      "Train Epoch: 1 [6000/9414 (63%)]\tLoss: 0.237118\n",
      "Train Epoch: 1 [7000/9414 (74%)]\tLoss: 0.274590\n",
      "Train Epoch: 1 [8000/9414 (84%)]\tLoss: 0.293480\n",
      "Train Epoch: 1 [9000/9414 (95%)]\tLoss: 0.265297\n",
      "Train Epoch: 2 [0/9414 (0%)]\tLoss: 0.198958\n",
      "Train Epoch: 2 [1000/9414 (11%)]\tLoss: 0.118538\n",
      "Train Epoch: 2 [2000/9414 (21%)]\tLoss: 0.255612\n",
      "Train Epoch: 2 [3000/9414 (32%)]\tLoss: 0.224011\n",
      "Train Epoch: 2 [4000/9414 (42%)]\tLoss: 0.116773\n",
      "Train Epoch: 2 [5000/9414 (53%)]\tLoss: 0.242279\n",
      "Train Epoch: 2 [6000/9414 (63%)]\tLoss: 0.222726\n",
      "Train Epoch: 2 [7000/9414 (74%)]\tLoss: 0.236087\n",
      "Train Epoch: 2 [8000/9414 (84%)]\tLoss: 0.203057\n",
      "Train Epoch: 2 [9000/9414 (95%)]\tLoss: 0.139075\n",
      "Train Epoch: 3 [0/9414 (0%)]\tLoss: 0.196390\n",
      "Train Epoch: 3 [1000/9414 (11%)]\tLoss: 0.206498\n",
      "Train Epoch: 3 [2000/9414 (21%)]\tLoss: 0.118616\n",
      "Train Epoch: 3 [3000/9414 (32%)]\tLoss: 0.169718\n",
      "Train Epoch: 3 [4000/9414 (42%)]\tLoss: 0.246833\n",
      "Train Epoch: 3 [5000/9414 (53%)]\tLoss: 0.255394\n",
      "Train Epoch: 3 [6000/9414 (63%)]\tLoss: 0.151473\n",
      "Train Epoch: 3 [7000/9414 (74%)]\tLoss: 0.135524\n",
      "Train Epoch: 3 [8000/9414 (84%)]\tLoss: 0.127318\n",
      "Train Epoch: 3 [9000/9414 (95%)]\tLoss: 0.206275\n",
      "Train Epoch: 4 [0/9414 (0%)]\tLoss: 0.163383\n",
      "Train Epoch: 4 [1000/9414 (11%)]\tLoss: 0.142503\n",
      "Train Epoch: 4 [2000/9414 (21%)]\tLoss: 0.235399\n",
      "Train Epoch: 4 [3000/9414 (32%)]\tLoss: 0.153046\n",
      "Train Epoch: 4 [4000/9414 (42%)]\tLoss: 0.185111\n",
      "Train Epoch: 4 [5000/9414 (53%)]\tLoss: 0.242346\n",
      "Train Epoch: 4 [6000/9414 (63%)]\tLoss: 0.097582\n",
      "Train Epoch: 4 [7000/9414 (74%)]\tLoss: 0.212724\n",
      "Train Epoch: 4 [8000/9414 (84%)]\tLoss: 0.134533\n",
      "Train Epoch: 4 [9000/9414 (95%)]\tLoss: 0.176354\n",
      "Train Epoch: 5 [0/9414 (0%)]\tLoss: 0.107336\n",
      "Train Epoch: 5 [1000/9414 (11%)]\tLoss: 0.140341\n",
      "Train Epoch: 5 [2000/9414 (21%)]\tLoss: 0.177498\n",
      "Train Epoch: 5 [3000/9414 (32%)]\tLoss: 0.234553\n",
      "Train Epoch: 5 [4000/9414 (42%)]\tLoss: 0.136516\n",
      "Train Epoch: 5 [5000/9414 (53%)]\tLoss: 0.129713\n",
      "Train Epoch: 5 [6000/9414 (63%)]\tLoss: 0.213041\n",
      "Train Epoch: 5 [7000/9414 (74%)]\tLoss: 0.169775\n",
      "Train Epoch: 5 [8000/9414 (84%)]\tLoss: 0.313283\n",
      "Train Epoch: 5 [9000/9414 (95%)]\tLoss: 0.153187\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "6\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.6516, Accuracy: 8624/10000 (86%)\n",
      "\n",
      "Running experiment with 8 partitions...\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.252080\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 0.275335\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 0.209201\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 0.190728\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 0.223593\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 0.173134\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 0.321130\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 0.193119\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.243760\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 0.216396\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.326289\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 0.164535\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.156111\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 0.238286\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 0.205345\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.351150\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.334897\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 0.330497\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 0.226685\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 0.255032\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.249408\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 0.307223\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.236007\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 0.263124\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.179730\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.118324\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.248318\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 0.147250\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.295578\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 0.237688\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.182139\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 0.376527\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.311956\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 0.287434\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.150951\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.233359\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.246092\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 0.221166\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.244713\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 0.281511\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.211731\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 0.281093\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.417360\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 0.214531\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.201328\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.263536\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.226023\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 0.188813\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.273792\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 0.213526\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.174508\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 0.301329\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.303500\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 0.193833\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.126405\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.248291\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.136877\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 0.401581\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.191777\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 0.194640\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.332662\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 0.217712\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.275928\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 0.167700\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.176472\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.192362\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.159213\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 0.164680\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.186390\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 0.094990\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.234726\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 0.212616\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.223629\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 0.165411\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.160901\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.337547\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.298821\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 0.136379\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.199985\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 0.230167\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.098877\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 0.173495\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.374752\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 0.172701\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.351013\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.185041\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.282692\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 0.226055\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.236488\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 0.158802\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.269483\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 0.205083\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.259488\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 0.120168\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.239751\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.144250\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.229590\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 0.252239\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.233742\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 0.280933\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.232236\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 0.184976\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.287325\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 0.287986\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.101877\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.181091\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.199395\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 0.225017\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.233906\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 0.228165\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.172319\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 0.276070\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.223392\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 0.224359\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.175460\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.249514\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.290525\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 0.210730\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.202487\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 0.203344\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.201731\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 0.229196\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.144676\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 0.212409\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.331992\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.303363\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.283683\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 0.176699\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.176450\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 0.309905\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.130208\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 0.391286\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.214288\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 0.268872\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.262620\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.319782\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.188454\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 0.181082\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.284932\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 0.302500\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.198791\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 0.202978\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.137940\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 0.214464\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.121902\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.247456\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.216216\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 0.277535\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.239836\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 0.268550\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.161179\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 0.224134\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.230435\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 0.142731\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.283208\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.234962\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.162177\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 0.270943\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.308906\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 0.294631\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.154066\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 0.183641\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.178507\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 0.084817\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.303170\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.219608\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.282783\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 0.252605\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.205118\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 0.331203\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.187361\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 0.167351\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.212017\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 0.305679\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.271131\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.251927\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.284104\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 0.222061\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.155881\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 0.238574\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.296608\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 0.214127\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.253369\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 0.187384\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.142756\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.225069\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.163385\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 0.157902\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.228429\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 0.390737\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.267979\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 0.184815\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.223301\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 0.223054\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.209473\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.259401\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.289535\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 0.241208\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.248480\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 0.217762\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.190924\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 0.207868\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.241691\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 0.253875\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.256273\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.181805\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.171406\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 0.220614\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.380639\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 0.140276\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.179632\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 0.187684\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.232897\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 0.142027\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.266310\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.177120\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.261122\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 0.293595\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.294167\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 0.153340\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.295272\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 0.197756\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.194521\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 0.233846\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.140137\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.266634\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.251568\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 0.146570\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.184069\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 0.255032\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.315693\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 0.197374\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.325716\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 0.188318\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.254286\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.260309\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.221644\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 0.197774\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.140016\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 0.309884\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.206516\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 0.317455\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.214431\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 0.173945\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.206186\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.294019\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.273178\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 0.231182\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.270124\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 0.191511\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.227859\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 0.108453\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.201536\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 0.212699\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.192410\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.226419\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.262103\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 0.113384\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.273206\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 0.130153\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.235026\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 0.224510\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.206338\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 0.126408\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.271642\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.229461\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.210290\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 0.276040\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.297571\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 0.208547\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.332414\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 0.201854\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.154940\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 0.410574\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.198068\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.250415\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.221035\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 0.390882\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.209450\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 0.260615\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.162474\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 0.218340\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.161664\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 0.264048\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.179314\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.235946\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.179940\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 0.336437\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.244138\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 0.224957\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.206530\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 0.221772\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.121116\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 0.334099\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.293397\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.133166\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.235740\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 0.148964\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.219602\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 0.191081\n",
      "\n",
      "Test set: Avg. loss: 0.2222, Accuracy: 54986/60000 (92%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/7731 (0%)]\tLoss: 0.170528\n",
      "Train Epoch: 1 [1000/7731 (13%)]\tLoss: 0.145672\n",
      "Train Epoch: 1 [2000/7731 (26%)]\tLoss: 0.164080\n",
      "Train Epoch: 1 [3000/7731 (38%)]\tLoss: 0.152233\n",
      "Train Epoch: 1 [4000/7731 (51%)]\tLoss: 0.106963\n",
      "Train Epoch: 1 [5000/7731 (64%)]\tLoss: 0.215484\n",
      "Train Epoch: 1 [6000/7731 (77%)]\tLoss: 0.152116\n",
      "Train Epoch: 1 [7000/7731 (90%)]\tLoss: 0.260534\n",
      "Train Epoch: 2 [0/7731 (0%)]\tLoss: 0.218313\n",
      "Train Epoch: 2 [1000/7731 (13%)]\tLoss: 0.185245\n",
      "Train Epoch: 2 [2000/7731 (26%)]\tLoss: 0.114123\n",
      "Train Epoch: 2 [3000/7731 (38%)]\tLoss: 0.111541\n",
      "Train Epoch: 2 [4000/7731 (51%)]\tLoss: 0.231865\n",
      "Train Epoch: 2 [5000/7731 (64%)]\tLoss: 0.039458\n",
      "Train Epoch: 2 [6000/7731 (77%)]\tLoss: 0.170750\n",
      "Train Epoch: 2 [7000/7731 (90%)]\tLoss: 0.194379\n",
      "Train Epoch: 3 [0/7731 (0%)]\tLoss: 0.111292\n",
      "Train Epoch: 3 [1000/7731 (13%)]\tLoss: 0.108155\n",
      "Train Epoch: 3 [2000/7731 (26%)]\tLoss: 0.187437\n",
      "Train Epoch: 3 [3000/7731 (38%)]\tLoss: 0.080501\n",
      "Train Epoch: 3 [4000/7731 (51%)]\tLoss: 0.093254\n",
      "Train Epoch: 3 [5000/7731 (64%)]\tLoss: 0.138778\n",
      "Train Epoch: 3 [6000/7731 (77%)]\tLoss: 0.130847\n",
      "Train Epoch: 3 [7000/7731 (90%)]\tLoss: 0.068731\n",
      "Train Epoch: 4 [0/7731 (0%)]\tLoss: 0.232113\n",
      "Train Epoch: 4 [1000/7731 (13%)]\tLoss: 0.080298\n",
      "Train Epoch: 4 [2000/7731 (26%)]\tLoss: 0.113563\n",
      "Train Epoch: 4 [3000/7731 (38%)]\tLoss: 0.158293\n",
      "Train Epoch: 4 [4000/7731 (51%)]\tLoss: 0.123218\n",
      "Train Epoch: 4 [5000/7731 (64%)]\tLoss: 0.130786\n",
      "Train Epoch: 4 [6000/7731 (77%)]\tLoss: 0.055431\n",
      "Train Epoch: 4 [7000/7731 (90%)]\tLoss: 0.076767\n",
      "Train Epoch: 5 [0/7731 (0%)]\tLoss: 0.094760\n",
      "Train Epoch: 5 [1000/7731 (13%)]\tLoss: 0.098639\n",
      "Train Epoch: 5 [2000/7731 (26%)]\tLoss: 0.143497\n",
      "Train Epoch: 5 [3000/7731 (38%)]\tLoss: 0.057056\n",
      "Train Epoch: 5 [4000/7731 (51%)]\tLoss: 0.103247\n",
      "Train Epoch: 5 [5000/7731 (64%)]\tLoss: 0.197497\n",
      "Train Epoch: 5 [6000/7731 (77%)]\tLoss: 0.178084\n",
      "Train Epoch: 5 [7000/7731 (90%)]\tLoss: 0.169447\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11194 (0%)]\tLoss: 0.189370\n",
      "Train Epoch: 1 [1000/11194 (9%)]\tLoss: 0.096662\n",
      "Train Epoch: 1 [2000/11194 (18%)]\tLoss: 0.238145\n",
      "Train Epoch: 1 [3000/11194 (27%)]\tLoss: 0.149049\n",
      "Train Epoch: 1 [4000/11194 (36%)]\tLoss: 0.173020\n",
      "Train Epoch: 1 [5000/11194 (45%)]\tLoss: 0.152267\n",
      "Train Epoch: 1 [6000/11194 (54%)]\tLoss: 0.115847\n",
      "Train Epoch: 1 [7000/11194 (62%)]\tLoss: 0.246956\n",
      "Train Epoch: 1 [8000/11194 (71%)]\tLoss: 0.128263\n",
      "Train Epoch: 1 [9000/11194 (80%)]\tLoss: 0.141138\n",
      "Train Epoch: 1 [10000/11194 (89%)]\tLoss: 0.317302\n",
      "Train Epoch: 1 [11000/11194 (98%)]\tLoss: 0.243810\n",
      "Train Epoch: 2 [0/11194 (0%)]\tLoss: 0.163686\n",
      "Train Epoch: 2 [1000/11194 (9%)]\tLoss: 0.125825\n",
      "Train Epoch: 2 [2000/11194 (18%)]\tLoss: 0.160214\n",
      "Train Epoch: 2 [3000/11194 (27%)]\tLoss: 0.130908\n",
      "Train Epoch: 2 [4000/11194 (36%)]\tLoss: 0.143751\n",
      "Train Epoch: 2 [5000/11194 (45%)]\tLoss: 0.090336\n",
      "Train Epoch: 2 [6000/11194 (54%)]\tLoss: 0.249347\n",
      "Train Epoch: 2 [7000/11194 (62%)]\tLoss: 0.118553\n",
      "Train Epoch: 2 [8000/11194 (71%)]\tLoss: 0.151009\n",
      "Train Epoch: 2 [9000/11194 (80%)]\tLoss: 0.252706\n",
      "Train Epoch: 2 [10000/11194 (89%)]\tLoss: 0.135854\n",
      "Train Epoch: 2 [11000/11194 (98%)]\tLoss: 0.113194\n",
      "Train Epoch: 3 [0/11194 (0%)]\tLoss: 0.136733\n",
      "Train Epoch: 3 [1000/11194 (9%)]\tLoss: 0.131520\n",
      "Train Epoch: 3 [2000/11194 (18%)]\tLoss: 0.150242\n",
      "Train Epoch: 3 [3000/11194 (27%)]\tLoss: 0.175328\n",
      "Train Epoch: 3 [4000/11194 (36%)]\tLoss: 0.120129\n",
      "Train Epoch: 3 [5000/11194 (45%)]\tLoss: 0.257453\n",
      "Train Epoch: 3 [6000/11194 (54%)]\tLoss: 0.232413\n",
      "Train Epoch: 3 [7000/11194 (62%)]\tLoss: 0.106094\n",
      "Train Epoch: 3 [8000/11194 (71%)]\tLoss: 0.131445\n",
      "Train Epoch: 3 [9000/11194 (80%)]\tLoss: 0.190143\n",
      "Train Epoch: 3 [10000/11194 (89%)]\tLoss: 0.149491\n",
      "Train Epoch: 3 [11000/11194 (98%)]\tLoss: 0.154257\n",
      "Train Epoch: 4 [0/11194 (0%)]\tLoss: 0.108754\n",
      "Train Epoch: 4 [1000/11194 (9%)]\tLoss: 0.122318\n",
      "Train Epoch: 4 [2000/11194 (18%)]\tLoss: 0.160965\n",
      "Train Epoch: 4 [3000/11194 (27%)]\tLoss: 0.195084\n",
      "Train Epoch: 4 [4000/11194 (36%)]\tLoss: 0.187589\n",
      "Train Epoch: 4 [5000/11194 (45%)]\tLoss: 0.124251\n",
      "Train Epoch: 4 [6000/11194 (54%)]\tLoss: 0.192120\n",
      "Train Epoch: 4 [7000/11194 (62%)]\tLoss: 0.113809\n",
      "Train Epoch: 4 [8000/11194 (71%)]\tLoss: 0.101842\n",
      "Train Epoch: 4 [9000/11194 (80%)]\tLoss: 0.153040\n",
      "Train Epoch: 4 [10000/11194 (89%)]\tLoss: 0.159327\n",
      "Train Epoch: 4 [11000/11194 (98%)]\tLoss: 0.157975\n",
      "Train Epoch: 5 [0/11194 (0%)]\tLoss: 0.144726\n",
      "Train Epoch: 5 [1000/11194 (9%)]\tLoss: 0.214494\n",
      "Train Epoch: 5 [2000/11194 (18%)]\tLoss: 0.063567\n",
      "Train Epoch: 5 [3000/11194 (27%)]\tLoss: 0.126172\n",
      "Train Epoch: 5 [4000/11194 (36%)]\tLoss: 0.179374\n",
      "Train Epoch: 5 [5000/11194 (45%)]\tLoss: 0.182668\n",
      "Train Epoch: 5 [6000/11194 (54%)]\tLoss: 0.147044\n",
      "Train Epoch: 5 [7000/11194 (62%)]\tLoss: 0.163133\n",
      "Train Epoch: 5 [8000/11194 (71%)]\tLoss: 0.114163\n",
      "Train Epoch: 5 [9000/11194 (80%)]\tLoss: 0.085092\n",
      "Train Epoch: 5 [10000/11194 (89%)]\tLoss: 0.176187\n",
      "Train Epoch: 5 [11000/11194 (98%)]\tLoss: 0.135567\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/7891 (0%)]\tLoss: 0.237452\n",
      "Train Epoch: 1 [1000/7891 (13%)]\tLoss: 0.079044\n",
      "Train Epoch: 1 [2000/7891 (25%)]\tLoss: 0.074186\n",
      "Train Epoch: 1 [3000/7891 (38%)]\tLoss: 0.172822\n",
      "Train Epoch: 1 [4000/7891 (51%)]\tLoss: 0.085197\n",
      "Train Epoch: 1 [5000/7891 (63%)]\tLoss: 0.185252\n",
      "Train Epoch: 1 [6000/7891 (76%)]\tLoss: 0.087090\n",
      "Train Epoch: 1 [7000/7891 (89%)]\tLoss: 0.097979\n",
      "Train Epoch: 2 [0/7891 (0%)]\tLoss: 0.173776\n",
      "Train Epoch: 2 [1000/7891 (13%)]\tLoss: 0.156132\n",
      "Train Epoch: 2 [2000/7891 (25%)]\tLoss: 0.084434\n",
      "Train Epoch: 2 [3000/7891 (38%)]\tLoss: 0.098632\n",
      "Train Epoch: 2 [4000/7891 (51%)]\tLoss: 0.138341\n",
      "Train Epoch: 2 [5000/7891 (63%)]\tLoss: 0.176716\n",
      "Train Epoch: 2 [6000/7891 (76%)]\tLoss: 0.042287\n",
      "Train Epoch: 2 [7000/7891 (89%)]\tLoss: 0.136542\n",
      "Train Epoch: 3 [0/7891 (0%)]\tLoss: 0.092714\n",
      "Train Epoch: 3 [1000/7891 (13%)]\tLoss: 0.139096\n",
      "Train Epoch: 3 [2000/7891 (25%)]\tLoss: 0.099847\n",
      "Train Epoch: 3 [3000/7891 (38%)]\tLoss: 0.057330\n",
      "Train Epoch: 3 [4000/7891 (51%)]\tLoss: 0.068187\n",
      "Train Epoch: 3 [5000/7891 (63%)]\tLoss: 0.154426\n",
      "Train Epoch: 3 [6000/7891 (76%)]\tLoss: 0.065433\n",
      "Train Epoch: 3 [7000/7891 (89%)]\tLoss: 0.145863\n",
      "Train Epoch: 4 [0/7891 (0%)]\tLoss: 0.121522\n",
      "Train Epoch: 4 [1000/7891 (13%)]\tLoss: 0.116329\n",
      "Train Epoch: 4 [2000/7891 (25%)]\tLoss: 0.060054\n",
      "Train Epoch: 4 [3000/7891 (38%)]\tLoss: 0.103730\n",
      "Train Epoch: 4 [4000/7891 (51%)]\tLoss: 0.088612\n",
      "Train Epoch: 4 [5000/7891 (63%)]\tLoss: 0.098663\n",
      "Train Epoch: 4 [6000/7891 (76%)]\tLoss: 0.112578\n",
      "Train Epoch: 4 [7000/7891 (89%)]\tLoss: 0.083099\n",
      "Train Epoch: 5 [0/7891 (0%)]\tLoss: 0.064854\n",
      "Train Epoch: 5 [1000/7891 (13%)]\tLoss: 0.117509\n",
      "Train Epoch: 5 [2000/7891 (25%)]\tLoss: 0.059164\n",
      "Train Epoch: 5 [3000/7891 (38%)]\tLoss: 0.066051\n",
      "Train Epoch: 5 [4000/7891 (51%)]\tLoss: 0.078851\n",
      "Train Epoch: 5 [5000/7891 (63%)]\tLoss: 0.128692\n",
      "Train Epoch: 5 [6000/7891 (76%)]\tLoss: 0.073260\n",
      "Train Epoch: 5 [7000/7891 (89%)]\tLoss: 0.069178\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/3053 (0%)]\tLoss: 0.138425\n",
      "Train Epoch: 1 [1000/3053 (32%)]\tLoss: 0.122223\n",
      "Train Epoch: 1 [2000/3053 (65%)]\tLoss: 0.066493\n",
      "Train Epoch: 1 [1590/3053 (97%)]\tLoss: 0.120166\n",
      "Train Epoch: 2 [0/3053 (0%)]\tLoss: 0.092379\n",
      "Train Epoch: 2 [1000/3053 (32%)]\tLoss: 0.120547\n",
      "Train Epoch: 2 [2000/3053 (65%)]\tLoss: 0.102072\n",
      "Train Epoch: 2 [1590/3053 (97%)]\tLoss: 0.230388\n",
      "Train Epoch: 3 [0/3053 (0%)]\tLoss: 0.124422\n",
      "Train Epoch: 3 [1000/3053 (32%)]\tLoss: 0.122740\n",
      "Train Epoch: 3 [2000/3053 (65%)]\tLoss: 0.149195\n",
      "Train Epoch: 3 [1590/3053 (97%)]\tLoss: 0.197501\n",
      "Train Epoch: 4 [0/3053 (0%)]\tLoss: 0.081668\n",
      "Train Epoch: 4 [1000/3053 (32%)]\tLoss: 0.031577\n",
      "Train Epoch: 4 [2000/3053 (65%)]\tLoss: 0.107270\n",
      "Train Epoch: 4 [1590/3053 (97%)]\tLoss: 0.037739\n",
      "Train Epoch: 5 [0/3053 (0%)]\tLoss: 0.031488\n",
      "Train Epoch: 5 [1000/3053 (32%)]\tLoss: 0.104286\n",
      "Train Epoch: 5 [2000/3053 (65%)]\tLoss: 0.098184\n",
      "Train Epoch: 5 [1590/3053 (97%)]\tLoss: 0.040752\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/9145 (0%)]\tLoss: 0.402292\n",
      "Train Epoch: 1 [1000/9145 (11%)]\tLoss: 0.288504\n",
      "Train Epoch: 1 [2000/9145 (22%)]\tLoss: 0.282616\n",
      "Train Epoch: 1 [3000/9145 (33%)]\tLoss: 0.328415\n",
      "Train Epoch: 1 [4000/9145 (43%)]\tLoss: 0.260322\n",
      "Train Epoch: 1 [5000/9145 (54%)]\tLoss: 0.277021\n",
      "Train Epoch: 1 [6000/9145 (65%)]\tLoss: 0.261740\n",
      "Train Epoch: 1 [7000/9145 (76%)]\tLoss: 0.214043\n",
      "Train Epoch: 1 [8000/9145 (87%)]\tLoss: 0.221027\n",
      "Train Epoch: 1 [9000/9145 (98%)]\tLoss: 0.394441\n",
      "Train Epoch: 2 [0/9145 (0%)]\tLoss: 0.142278\n",
      "Train Epoch: 2 [1000/9145 (11%)]\tLoss: 0.233049\n",
      "Train Epoch: 2 [2000/9145 (22%)]\tLoss: 0.281353\n",
      "Train Epoch: 2 [3000/9145 (33%)]\tLoss: 0.136797\n",
      "Train Epoch: 2 [4000/9145 (43%)]\tLoss: 0.220229\n",
      "Train Epoch: 2 [5000/9145 (54%)]\tLoss: 0.311302\n",
      "Train Epoch: 2 [6000/9145 (65%)]\tLoss: 0.139970\n",
      "Train Epoch: 2 [7000/9145 (76%)]\tLoss: 0.181558\n",
      "Train Epoch: 2 [8000/9145 (87%)]\tLoss: 0.244097\n",
      "Train Epoch: 2 [9000/9145 (98%)]\tLoss: 0.193598\n",
      "Train Epoch: 3 [0/9145 (0%)]\tLoss: 0.201798\n",
      "Train Epoch: 3 [1000/9145 (11%)]\tLoss: 0.179801\n",
      "Train Epoch: 3 [2000/9145 (22%)]\tLoss: 0.221510\n",
      "Train Epoch: 3 [3000/9145 (33%)]\tLoss: 0.204388\n",
      "Train Epoch: 3 [4000/9145 (43%)]\tLoss: 0.225957\n",
      "Train Epoch: 3 [5000/9145 (54%)]\tLoss: 0.250341\n",
      "Train Epoch: 3 [6000/9145 (65%)]\tLoss: 0.270199\n",
      "Train Epoch: 3 [7000/9145 (76%)]\tLoss: 0.150410\n",
      "Train Epoch: 3 [8000/9145 (87%)]\tLoss: 0.172484\n",
      "Train Epoch: 3 [9000/9145 (98%)]\tLoss: 0.272147\n",
      "Train Epoch: 4 [0/9145 (0%)]\tLoss: 0.157537\n",
      "Train Epoch: 4 [1000/9145 (11%)]\tLoss: 0.089951\n",
      "Train Epoch: 4 [2000/9145 (22%)]\tLoss: 0.197097\n",
      "Train Epoch: 4 [3000/9145 (33%)]\tLoss: 0.244564\n",
      "Train Epoch: 4 [4000/9145 (43%)]\tLoss: 0.226487\n",
      "Train Epoch: 4 [5000/9145 (54%)]\tLoss: 0.226772\n",
      "Train Epoch: 4 [6000/9145 (65%)]\tLoss: 0.215697\n",
      "Train Epoch: 4 [7000/9145 (76%)]\tLoss: 0.242073\n",
      "Train Epoch: 4 [8000/9145 (87%)]\tLoss: 0.307190\n",
      "Train Epoch: 4 [9000/9145 (98%)]\tLoss: 0.205549\n",
      "Train Epoch: 5 [0/9145 (0%)]\tLoss: 0.211218\n",
      "Train Epoch: 5 [1000/9145 (11%)]\tLoss: 0.169373\n",
      "Train Epoch: 5 [2000/9145 (22%)]\tLoss: 0.155095\n",
      "Train Epoch: 5 [3000/9145 (33%)]\tLoss: 0.214212\n",
      "Train Epoch: 5 [4000/9145 (43%)]\tLoss: 0.196672\n",
      "Train Epoch: 5 [5000/9145 (54%)]\tLoss: 0.162910\n",
      "Train Epoch: 5 [6000/9145 (65%)]\tLoss: 0.119331\n",
      "Train Epoch: 5 [7000/9145 (76%)]\tLoss: 0.185586\n",
      "Train Epoch: 5 [8000/9145 (87%)]\tLoss: 0.312189\n",
      "Train Epoch: 5 [9000/9145 (98%)]\tLoss: 0.125608\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3021 (0%)]\tLoss: 0.144814\n",
      "Train Epoch: 1 [1000/3021 (32%)]\tLoss: 0.159106\n",
      "Train Epoch: 1 [2000/3021 (65%)]\tLoss: 0.247155\n",
      "Train Epoch: 1 [630/3021 (97%)]\tLoss: 0.105661\n",
      "Train Epoch: 2 [0/3021 (0%)]\tLoss: 0.117058\n",
      "Train Epoch: 2 [1000/3021 (32%)]\tLoss: 0.190849\n",
      "Train Epoch: 2 [2000/3021 (65%)]\tLoss: 0.221860\n",
      "Train Epoch: 2 [630/3021 (97%)]\tLoss: 0.147836\n",
      "Train Epoch: 3 [0/3021 (0%)]\tLoss: 0.168064\n",
      "Train Epoch: 3 [1000/3021 (32%)]\tLoss: 0.140682\n",
      "Train Epoch: 3 [2000/3021 (65%)]\tLoss: 0.104606\n",
      "Train Epoch: 3 [630/3021 (97%)]\tLoss: 0.144778\n",
      "Train Epoch: 4 [0/3021 (0%)]\tLoss: 0.097740\n",
      "Train Epoch: 4 [1000/3021 (32%)]\tLoss: 0.137617\n",
      "Train Epoch: 4 [2000/3021 (65%)]\tLoss: 0.073419\n",
      "Train Epoch: 4 [630/3021 (97%)]\tLoss: 0.182729\n",
      "Train Epoch: 5 [0/3021 (0%)]\tLoss: 0.215610\n",
      "Train Epoch: 5 [1000/3021 (32%)]\tLoss: 0.073565\n",
      "Train Epoch: 5 [2000/3021 (65%)]\tLoss: 0.167822\n",
      "Train Epoch: 5 [630/3021 (97%)]\tLoss: 0.192388\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/7953 (0%)]\tLoss: 0.309944\n",
      "Train Epoch: 1 [1000/7953 (12%)]\tLoss: 0.347825\n",
      "Train Epoch: 1 [2000/7953 (25%)]\tLoss: 0.193386\n",
      "Train Epoch: 1 [3000/7953 (38%)]\tLoss: 0.406852\n",
      "Train Epoch: 1 [4000/7953 (50%)]\tLoss: 0.399766\n",
      "Train Epoch: 1 [5000/7953 (62%)]\tLoss: 0.391029\n",
      "Train Epoch: 1 [6000/7953 (75%)]\tLoss: 0.432810\n",
      "Train Epoch: 1 [7000/7953 (88%)]\tLoss: 0.376725\n",
      "Train Epoch: 2 [0/7953 (0%)]\tLoss: 0.341823\n",
      "Train Epoch: 2 [1000/7953 (12%)]\tLoss: 0.358577\n",
      "Train Epoch: 2 [2000/7953 (25%)]\tLoss: 0.260060\n",
      "Train Epoch: 2 [3000/7953 (38%)]\tLoss: 0.381731\n",
      "Train Epoch: 2 [4000/7953 (50%)]\tLoss: 0.297429\n",
      "Train Epoch: 2 [5000/7953 (62%)]\tLoss: 0.275788\n",
      "Train Epoch: 2 [6000/7953 (75%)]\tLoss: 0.445476\n",
      "Train Epoch: 2 [7000/7953 (88%)]\tLoss: 0.262821\n",
      "Train Epoch: 3 [0/7953 (0%)]\tLoss: 0.362879\n",
      "Train Epoch: 3 [1000/7953 (12%)]\tLoss: 0.488769\n",
      "Train Epoch: 3 [2000/7953 (25%)]\tLoss: 0.286928\n",
      "Train Epoch: 3 [3000/7953 (38%)]\tLoss: 0.387711\n",
      "Train Epoch: 3 [4000/7953 (50%)]\tLoss: 0.418289\n",
      "Train Epoch: 3 [5000/7953 (62%)]\tLoss: 0.388678\n",
      "Train Epoch: 3 [6000/7953 (75%)]\tLoss: 0.357622\n",
      "Train Epoch: 3 [7000/7953 (88%)]\tLoss: 0.490128\n",
      "Train Epoch: 4 [0/7953 (0%)]\tLoss: 0.323349\n",
      "Train Epoch: 4 [1000/7953 (12%)]\tLoss: 0.318411\n",
      "Train Epoch: 4 [2000/7953 (25%)]\tLoss: 0.332022\n",
      "Train Epoch: 4 [3000/7953 (38%)]\tLoss: 0.493288\n",
      "Train Epoch: 4 [4000/7953 (50%)]\tLoss: 0.379807\n",
      "Train Epoch: 4 [5000/7953 (62%)]\tLoss: 0.300506\n",
      "Train Epoch: 4 [6000/7953 (75%)]\tLoss: 0.304521\n",
      "Train Epoch: 4 [7000/7953 (88%)]\tLoss: 0.335606\n",
      "Train Epoch: 5 [0/7953 (0%)]\tLoss: 0.366013\n",
      "Train Epoch: 5 [1000/7953 (12%)]\tLoss: 0.282985\n",
      "Train Epoch: 5 [2000/7953 (25%)]\tLoss: 0.385869\n",
      "Train Epoch: 5 [3000/7953 (38%)]\tLoss: 0.311682\n",
      "Train Epoch: 5 [4000/7953 (50%)]\tLoss: 0.278154\n",
      "Train Epoch: 5 [5000/7953 (62%)]\tLoss: 0.406139\n",
      "Train Epoch: 5 [6000/7953 (75%)]\tLoss: 0.346157\n",
      "Train Epoch: 5 [7000/7953 (88%)]\tLoss: 0.308454\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/10012 (0%)]\tLoss: 0.357542\n",
      "Train Epoch: 1 [1000/10012 (10%)]\tLoss: 0.160232\n",
      "Train Epoch: 1 [2000/10012 (20%)]\tLoss: 0.048263\n",
      "Train Epoch: 1 [3000/10012 (30%)]\tLoss: 0.033931\n",
      "Train Epoch: 1 [4000/10012 (40%)]\tLoss: 0.163666\n",
      "Train Epoch: 1 [5000/10012 (50%)]\tLoss: 0.155461\n",
      "Train Epoch: 1 [6000/10012 (59%)]\tLoss: 0.183705\n",
      "Train Epoch: 1 [7000/10012 (69%)]\tLoss: 0.125465\n",
      "Train Epoch: 1 [8000/10012 (79%)]\tLoss: 0.100387\n",
      "Train Epoch: 1 [9000/10012 (89%)]\tLoss: 0.070654\n",
      "Train Epoch: 1 [1200/10012 (99%)]\tLoss: 0.239807\n",
      "Train Epoch: 2 [0/10012 (0%)]\tLoss: 0.159642\n",
      "Train Epoch: 2 [1000/10012 (10%)]\tLoss: 0.126703\n",
      "Train Epoch: 2 [2000/10012 (20%)]\tLoss: 0.068901\n",
      "Train Epoch: 2 [3000/10012 (30%)]\tLoss: 0.063799\n",
      "Train Epoch: 2 [4000/10012 (40%)]\tLoss: 0.082865\n",
      "Train Epoch: 2 [5000/10012 (50%)]\tLoss: 0.197505\n",
      "Train Epoch: 2 [6000/10012 (59%)]\tLoss: 0.119915\n",
      "Train Epoch: 2 [7000/10012 (69%)]\tLoss: 0.106507\n",
      "Train Epoch: 2 [8000/10012 (79%)]\tLoss: 0.068456\n",
      "Train Epoch: 2 [9000/10012 (89%)]\tLoss: 0.110651\n",
      "Train Epoch: 2 [1200/10012 (99%)]\tLoss: 0.017672\n",
      "Train Epoch: 3 [0/10012 (0%)]\tLoss: 0.134944\n",
      "Train Epoch: 3 [1000/10012 (10%)]\tLoss: 0.105722\n",
      "Train Epoch: 3 [2000/10012 (20%)]\tLoss: 0.250265\n",
      "Train Epoch: 3 [3000/10012 (30%)]\tLoss: 0.094820\n",
      "Train Epoch: 3 [4000/10012 (40%)]\tLoss: 0.258989\n",
      "Train Epoch: 3 [5000/10012 (50%)]\tLoss: 0.078491\n",
      "Train Epoch: 3 [6000/10012 (59%)]\tLoss: 0.039430\n",
      "Train Epoch: 3 [7000/10012 (69%)]\tLoss: 0.156543\n",
      "Train Epoch: 3 [8000/10012 (79%)]\tLoss: 0.164839\n",
      "Train Epoch: 3 [9000/10012 (89%)]\tLoss: 0.160579\n",
      "Train Epoch: 3 [1200/10012 (99%)]\tLoss: 0.046467\n",
      "Train Epoch: 4 [0/10012 (0%)]\tLoss: 0.056924\n",
      "Train Epoch: 4 [1000/10012 (10%)]\tLoss: 0.133539\n",
      "Train Epoch: 4 [2000/10012 (20%)]\tLoss: 0.244071\n",
      "Train Epoch: 4 [3000/10012 (30%)]\tLoss: 0.205443\n",
      "Train Epoch: 4 [4000/10012 (40%)]\tLoss: 0.244345\n",
      "Train Epoch: 4 [5000/10012 (50%)]\tLoss: 0.093124\n",
      "Train Epoch: 4 [6000/10012 (59%)]\tLoss: 0.096923\n",
      "Train Epoch: 4 [7000/10012 (69%)]\tLoss: 0.095948\n",
      "Train Epoch: 4 [8000/10012 (79%)]\tLoss: 0.073107\n",
      "Train Epoch: 4 [9000/10012 (89%)]\tLoss: 0.113228\n",
      "Train Epoch: 4 [1200/10012 (99%)]\tLoss: 0.559738\n",
      "Train Epoch: 5 [0/10012 (0%)]\tLoss: 0.200938\n",
      "Train Epoch: 5 [1000/10012 (10%)]\tLoss: 0.065395\n",
      "Train Epoch: 5 [2000/10012 (20%)]\tLoss: 0.070848\n",
      "Train Epoch: 5 [3000/10012 (30%)]\tLoss: 0.128296\n",
      "Train Epoch: 5 [4000/10012 (40%)]\tLoss: 0.111972\n",
      "Train Epoch: 5 [5000/10012 (50%)]\tLoss: 0.175660\n",
      "Train Epoch: 5 [6000/10012 (59%)]\tLoss: 0.138701\n",
      "Train Epoch: 5 [7000/10012 (69%)]\tLoss: 0.099949\n",
      "Train Epoch: 5 [8000/10012 (79%)]\tLoss: 0.189391\n",
      "Train Epoch: 5 [9000/10012 (89%)]\tLoss: 0.067747\n",
      "Train Epoch: 5 [1200/10012 (99%)]\tLoss: 0.045057\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "8\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.6413, Accuracy: 8704/10000 (87%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/7731 (0%)]\tLoss: 0.223493\n",
      "Train Epoch: 1 [1000/7731 (13%)]\tLoss: 0.185898\n",
      "Train Epoch: 1 [2000/7731 (26%)]\tLoss: 0.166462\n",
      "Train Epoch: 1 [3000/7731 (38%)]\tLoss: 0.165397\n",
      "Train Epoch: 1 [4000/7731 (51%)]\tLoss: 0.124583\n",
      "Train Epoch: 1 [5000/7731 (64%)]\tLoss: 0.157095\n",
      "Train Epoch: 1 [6000/7731 (77%)]\tLoss: 0.211668\n",
      "Train Epoch: 1 [7000/7731 (90%)]\tLoss: 0.170161\n",
      "Train Epoch: 2 [0/7731 (0%)]\tLoss: 0.156331\n",
      "Train Epoch: 2 [1000/7731 (13%)]\tLoss: 0.175541\n",
      "Train Epoch: 2 [2000/7731 (26%)]\tLoss: 0.150885\n",
      "Train Epoch: 2 [3000/7731 (38%)]\tLoss: 0.104170\n",
      "Train Epoch: 2 [4000/7731 (51%)]\tLoss: 0.220503\n",
      "Train Epoch: 2 [5000/7731 (64%)]\tLoss: 0.204756\n",
      "Train Epoch: 2 [6000/7731 (77%)]\tLoss: 0.101826\n",
      "Train Epoch: 2 [7000/7731 (90%)]\tLoss: 0.151261\n",
      "Train Epoch: 3 [0/7731 (0%)]\tLoss: 0.216937\n",
      "Train Epoch: 3 [1000/7731 (13%)]\tLoss: 0.105843\n",
      "Train Epoch: 3 [2000/7731 (26%)]\tLoss: 0.178205\n",
      "Train Epoch: 3 [3000/7731 (38%)]\tLoss: 0.057928\n",
      "Train Epoch: 3 [4000/7731 (51%)]\tLoss: 0.098678\n",
      "Train Epoch: 3 [5000/7731 (64%)]\tLoss: 0.183199\n",
      "Train Epoch: 3 [6000/7731 (77%)]\tLoss: 0.153462\n",
      "Train Epoch: 3 [7000/7731 (90%)]\tLoss: 0.116759\n",
      "Train Epoch: 4 [0/7731 (0%)]\tLoss: 0.134700\n",
      "Train Epoch: 4 [1000/7731 (13%)]\tLoss: 0.184222\n",
      "Train Epoch: 4 [2000/7731 (26%)]\tLoss: 0.077117\n",
      "Train Epoch: 4 [3000/7731 (38%)]\tLoss: 0.151844\n",
      "Train Epoch: 4 [4000/7731 (51%)]\tLoss: 0.147321\n",
      "Train Epoch: 4 [5000/7731 (64%)]\tLoss: 0.058133\n",
      "Train Epoch: 4 [6000/7731 (77%)]\tLoss: 0.184974\n",
      "Train Epoch: 4 [7000/7731 (90%)]\tLoss: 0.208836\n",
      "Train Epoch: 5 [0/7731 (0%)]\tLoss: 0.114331\n",
      "Train Epoch: 5 [1000/7731 (13%)]\tLoss: 0.115941\n",
      "Train Epoch: 5 [2000/7731 (26%)]\tLoss: 0.109738\n",
      "Train Epoch: 5 [3000/7731 (38%)]\tLoss: 0.065389\n",
      "Train Epoch: 5 [4000/7731 (51%)]\tLoss: 0.122183\n",
      "Train Epoch: 5 [5000/7731 (64%)]\tLoss: 0.135574\n",
      "Train Epoch: 5 [6000/7731 (77%)]\tLoss: 0.155908\n",
      "Train Epoch: 5 [7000/7731 (90%)]\tLoss: 0.102007\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11194 (0%)]\tLoss: 0.425942\n",
      "Train Epoch: 1 [1000/11194 (9%)]\tLoss: 0.137758\n",
      "Train Epoch: 1 [2000/11194 (18%)]\tLoss: 0.181137\n",
      "Train Epoch: 1 [3000/11194 (27%)]\tLoss: 0.256711\n",
      "Train Epoch: 1 [4000/11194 (36%)]\tLoss: 0.185111\n",
      "Train Epoch: 1 [5000/11194 (45%)]\tLoss: 0.239787\n",
      "Train Epoch: 1 [6000/11194 (54%)]\tLoss: 0.196974\n",
      "Train Epoch: 1 [7000/11194 (62%)]\tLoss: 0.157997\n",
      "Train Epoch: 1 [8000/11194 (71%)]\tLoss: 0.244738\n",
      "Train Epoch: 1 [9000/11194 (80%)]\tLoss: 0.175428\n",
      "Train Epoch: 1 [10000/11194 (89%)]\tLoss: 0.252682\n",
      "Train Epoch: 1 [11000/11194 (98%)]\tLoss: 0.126675\n",
      "Train Epoch: 2 [0/11194 (0%)]\tLoss: 0.124034\n",
      "Train Epoch: 2 [1000/11194 (9%)]\tLoss: 0.156469\n",
      "Train Epoch: 2 [2000/11194 (18%)]\tLoss: 0.177831\n",
      "Train Epoch: 2 [3000/11194 (27%)]\tLoss: 0.131759\n",
      "Train Epoch: 2 [4000/11194 (36%)]\tLoss: 0.108048\n",
      "Train Epoch: 2 [5000/11194 (45%)]\tLoss: 0.128189\n",
      "Train Epoch: 2 [6000/11194 (54%)]\tLoss: 0.265821\n",
      "Train Epoch: 2 [7000/11194 (62%)]\tLoss: 0.146482\n",
      "Train Epoch: 2 [8000/11194 (71%)]\tLoss: 0.231956\n",
      "Train Epoch: 2 [9000/11194 (80%)]\tLoss: 0.105472\n",
      "Train Epoch: 2 [10000/11194 (89%)]\tLoss: 0.204703\n",
      "Train Epoch: 2 [11000/11194 (98%)]\tLoss: 0.133403\n",
      "Train Epoch: 3 [0/11194 (0%)]\tLoss: 0.156325\n",
      "Train Epoch: 3 [1000/11194 (9%)]\tLoss: 0.227734\n",
      "Train Epoch: 3 [2000/11194 (18%)]\tLoss: 0.131952\n",
      "Train Epoch: 3 [3000/11194 (27%)]\tLoss: 0.129171\n",
      "Train Epoch: 3 [4000/11194 (36%)]\tLoss: 0.259580\n",
      "Train Epoch: 3 [5000/11194 (45%)]\tLoss: 0.166680\n",
      "Train Epoch: 3 [6000/11194 (54%)]\tLoss: 0.119553\n",
      "Train Epoch: 3 [7000/11194 (62%)]\tLoss: 0.174875\n",
      "Train Epoch: 3 [8000/11194 (71%)]\tLoss: 0.212908\n",
      "Train Epoch: 3 [9000/11194 (80%)]\tLoss: 0.216512\n",
      "Train Epoch: 3 [10000/11194 (89%)]\tLoss: 0.198694\n",
      "Train Epoch: 3 [11000/11194 (98%)]\tLoss: 0.175796\n",
      "Train Epoch: 4 [0/11194 (0%)]\tLoss: 0.179268\n",
      "Train Epoch: 4 [1000/11194 (9%)]\tLoss: 0.156116\n",
      "Train Epoch: 4 [2000/11194 (18%)]\tLoss: 0.156673\n",
      "Train Epoch: 4 [3000/11194 (27%)]\tLoss: 0.111884\n",
      "Train Epoch: 4 [4000/11194 (36%)]\tLoss: 0.177159\n",
      "Train Epoch: 4 [5000/11194 (45%)]\tLoss: 0.134347\n",
      "Train Epoch: 4 [6000/11194 (54%)]\tLoss: 0.111169\n",
      "Train Epoch: 4 [7000/11194 (62%)]\tLoss: 0.169895\n",
      "Train Epoch: 4 [8000/11194 (71%)]\tLoss: 0.077124\n",
      "Train Epoch: 4 [9000/11194 (80%)]\tLoss: 0.164268\n",
      "Train Epoch: 4 [10000/11194 (89%)]\tLoss: 0.198534\n",
      "Train Epoch: 4 [11000/11194 (98%)]\tLoss: 0.188008\n",
      "Train Epoch: 5 [0/11194 (0%)]\tLoss: 0.105180\n",
      "Train Epoch: 5 [1000/11194 (9%)]\tLoss: 0.155391\n",
      "Train Epoch: 5 [2000/11194 (18%)]\tLoss: 0.147053\n",
      "Train Epoch: 5 [3000/11194 (27%)]\tLoss: 0.101564\n",
      "Train Epoch: 5 [4000/11194 (36%)]\tLoss: 0.063998\n",
      "Train Epoch: 5 [5000/11194 (45%)]\tLoss: 0.145746\n",
      "Train Epoch: 5 [6000/11194 (54%)]\tLoss: 0.174426\n",
      "Train Epoch: 5 [7000/11194 (62%)]\tLoss: 0.126972\n",
      "Train Epoch: 5 [8000/11194 (71%)]\tLoss: 0.159204\n",
      "Train Epoch: 5 [9000/11194 (80%)]\tLoss: 0.082151\n",
      "Train Epoch: 5 [10000/11194 (89%)]\tLoss: 0.090865\n",
      "Train Epoch: 5 [11000/11194 (98%)]\tLoss: 0.156921\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/7891 (0%)]\tLoss: 0.143019\n",
      "Train Epoch: 1 [1000/7891 (13%)]\tLoss: 0.147212\n",
      "Train Epoch: 1 [2000/7891 (25%)]\tLoss: 0.072623\n",
      "Train Epoch: 1 [3000/7891 (38%)]\tLoss: 0.074421\n",
      "Train Epoch: 1 [4000/7891 (51%)]\tLoss: 0.141572\n",
      "Train Epoch: 1 [5000/7891 (63%)]\tLoss: 0.243246\n",
      "Train Epoch: 1 [6000/7891 (76%)]\tLoss: 0.201786\n",
      "Train Epoch: 1 [7000/7891 (89%)]\tLoss: 0.148860\n",
      "Train Epoch: 2 [0/7891 (0%)]\tLoss: 0.184830\n",
      "Train Epoch: 2 [1000/7891 (13%)]\tLoss: 0.082493\n",
      "Train Epoch: 2 [2000/7891 (25%)]\tLoss: 0.068915\n",
      "Train Epoch: 2 [3000/7891 (38%)]\tLoss: 0.194947\n",
      "Train Epoch: 2 [4000/7891 (51%)]\tLoss: 0.098289\n",
      "Train Epoch: 2 [5000/7891 (63%)]\tLoss: 0.057544\n",
      "Train Epoch: 2 [6000/7891 (76%)]\tLoss: 0.094553\n",
      "Train Epoch: 2 [7000/7891 (89%)]\tLoss: 0.082686\n",
      "Train Epoch: 3 [0/7891 (0%)]\tLoss: 0.102917\n",
      "Train Epoch: 3 [1000/7891 (13%)]\tLoss: 0.065587\n",
      "Train Epoch: 3 [2000/7891 (25%)]\tLoss: 0.086942\n",
      "Train Epoch: 3 [3000/7891 (38%)]\tLoss: 0.154504\n",
      "Train Epoch: 3 [4000/7891 (51%)]\tLoss: 0.057728\n",
      "Train Epoch: 3 [5000/7891 (63%)]\tLoss: 0.170641\n",
      "Train Epoch: 3 [6000/7891 (76%)]\tLoss: 0.095647\n",
      "Train Epoch: 3 [7000/7891 (89%)]\tLoss: 0.067027\n",
      "Train Epoch: 4 [0/7891 (0%)]\tLoss: 0.078364\n",
      "Train Epoch: 4 [1000/7891 (13%)]\tLoss: 0.058729\n",
      "Train Epoch: 4 [2000/7891 (25%)]\tLoss: 0.079188\n",
      "Train Epoch: 4 [3000/7891 (38%)]\tLoss: 0.067478\n",
      "Train Epoch: 4 [4000/7891 (51%)]\tLoss: 0.107144\n",
      "Train Epoch: 4 [5000/7891 (63%)]\tLoss: 0.096643\n",
      "Train Epoch: 4 [6000/7891 (76%)]\tLoss: 0.027069\n",
      "Train Epoch: 4 [7000/7891 (89%)]\tLoss: 0.087768\n",
      "Train Epoch: 5 [0/7891 (0%)]\tLoss: 0.066498\n",
      "Train Epoch: 5 [1000/7891 (13%)]\tLoss: 0.088798\n",
      "Train Epoch: 5 [2000/7891 (25%)]\tLoss: 0.108727\n",
      "Train Epoch: 5 [3000/7891 (38%)]\tLoss: 0.142126\n",
      "Train Epoch: 5 [4000/7891 (51%)]\tLoss: 0.083207\n",
      "Train Epoch: 5 [5000/7891 (63%)]\tLoss: 0.069170\n",
      "Train Epoch: 5 [6000/7891 (76%)]\tLoss: 0.163906\n",
      "Train Epoch: 5 [7000/7891 (89%)]\tLoss: 0.151383\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/3053 (0%)]\tLoss: 0.205807\n",
      "Train Epoch: 1 [1000/3053 (32%)]\tLoss: 0.098458\n",
      "Train Epoch: 1 [2000/3053 (65%)]\tLoss: 0.094601\n",
      "Train Epoch: 1 [1590/3053 (97%)]\tLoss: 0.243522\n",
      "Train Epoch: 2 [0/3053 (0%)]\tLoss: 0.151210\n",
      "Train Epoch: 2 [1000/3053 (32%)]\tLoss: 0.113633\n",
      "Train Epoch: 2 [2000/3053 (65%)]\tLoss: 0.114634\n",
      "Train Epoch: 2 [1590/3053 (97%)]\tLoss: 0.160433\n",
      "Train Epoch: 3 [0/3053 (0%)]\tLoss: 0.116532\n",
      "Train Epoch: 3 [1000/3053 (32%)]\tLoss: 0.091652\n",
      "Train Epoch: 3 [2000/3053 (65%)]\tLoss: 0.157856\n",
      "Train Epoch: 3 [1590/3053 (97%)]\tLoss: 0.082591\n",
      "Train Epoch: 4 [0/3053 (0%)]\tLoss: 0.099166\n",
      "Train Epoch: 4 [1000/3053 (32%)]\tLoss: 0.119652\n",
      "Train Epoch: 4 [2000/3053 (65%)]\tLoss: 0.074124\n",
      "Train Epoch: 4 [1590/3053 (97%)]\tLoss: 0.073211\n",
      "Train Epoch: 5 [0/3053 (0%)]\tLoss: 0.041625\n",
      "Train Epoch: 5 [1000/3053 (32%)]\tLoss: 0.066465\n",
      "Train Epoch: 5 [2000/3053 (65%)]\tLoss: 0.055899\n",
      "Train Epoch: 5 [1590/3053 (97%)]\tLoss: 0.053929\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/9145 (0%)]\tLoss: 0.260225\n",
      "Train Epoch: 1 [1000/9145 (11%)]\tLoss: 0.346019\n",
      "Train Epoch: 1 [2000/9145 (22%)]\tLoss: 0.206034\n",
      "Train Epoch: 1 [3000/9145 (33%)]\tLoss: 0.232556\n",
      "Train Epoch: 1 [4000/9145 (43%)]\tLoss: 0.161605\n",
      "Train Epoch: 1 [5000/9145 (54%)]\tLoss: 0.248939\n",
      "Train Epoch: 1 [6000/9145 (65%)]\tLoss: 0.157671\n",
      "Train Epoch: 1 [7000/9145 (76%)]\tLoss: 0.215139\n",
      "Train Epoch: 1 [8000/9145 (87%)]\tLoss: 0.207217\n",
      "Train Epoch: 1 [9000/9145 (98%)]\tLoss: 0.250716\n",
      "Train Epoch: 2 [0/9145 (0%)]\tLoss: 0.184960\n",
      "Train Epoch: 2 [1000/9145 (11%)]\tLoss: 0.194405\n",
      "Train Epoch: 2 [2000/9145 (22%)]\tLoss: 0.201339\n",
      "Train Epoch: 2 [3000/9145 (33%)]\tLoss: 0.243145\n",
      "Train Epoch: 2 [4000/9145 (43%)]\tLoss: 0.285680\n",
      "Train Epoch: 2 [5000/9145 (54%)]\tLoss: 0.121024\n",
      "Train Epoch: 2 [6000/9145 (65%)]\tLoss: 0.438760\n",
      "Train Epoch: 2 [7000/9145 (76%)]\tLoss: 0.212561\n",
      "Train Epoch: 2 [8000/9145 (87%)]\tLoss: 0.262120\n",
      "Train Epoch: 2 [9000/9145 (98%)]\tLoss: 0.253692\n",
      "Train Epoch: 3 [0/9145 (0%)]\tLoss: 0.169186\n",
      "Train Epoch: 3 [1000/9145 (11%)]\tLoss: 0.260590\n",
      "Train Epoch: 3 [2000/9145 (22%)]\tLoss: 0.161552\n",
      "Train Epoch: 3 [3000/9145 (33%)]\tLoss: 0.252571\n",
      "Train Epoch: 3 [4000/9145 (43%)]\tLoss: 0.141059\n",
      "Train Epoch: 3 [5000/9145 (54%)]\tLoss: 0.261174\n",
      "Train Epoch: 3 [6000/9145 (65%)]\tLoss: 0.167097\n",
      "Train Epoch: 3 [7000/9145 (76%)]\tLoss: 0.239703\n",
      "Train Epoch: 3 [8000/9145 (87%)]\tLoss: 0.178584\n",
      "Train Epoch: 3 [9000/9145 (98%)]\tLoss: 0.177059\n",
      "Train Epoch: 4 [0/9145 (0%)]\tLoss: 0.133287\n",
      "Train Epoch: 4 [1000/9145 (11%)]\tLoss: 0.238472\n",
      "Train Epoch: 4 [2000/9145 (22%)]\tLoss: 0.241418\n",
      "Train Epoch: 4 [3000/9145 (33%)]\tLoss: 0.157005\n",
      "Train Epoch: 4 [4000/9145 (43%)]\tLoss: 0.213297\n",
      "Train Epoch: 4 [5000/9145 (54%)]\tLoss: 0.155518\n",
      "Train Epoch: 4 [6000/9145 (65%)]\tLoss: 0.160307\n",
      "Train Epoch: 4 [7000/9145 (76%)]\tLoss: 0.100001\n",
      "Train Epoch: 4 [8000/9145 (87%)]\tLoss: 0.168114\n",
      "Train Epoch: 4 [9000/9145 (98%)]\tLoss: 0.330331\n",
      "Train Epoch: 5 [0/9145 (0%)]\tLoss: 0.200502\n",
      "Train Epoch: 5 [1000/9145 (11%)]\tLoss: 0.199342\n",
      "Train Epoch: 5 [2000/9145 (22%)]\tLoss: 0.170792\n",
      "Train Epoch: 5 [3000/9145 (33%)]\tLoss: 0.264098\n",
      "Train Epoch: 5 [4000/9145 (43%)]\tLoss: 0.155039\n",
      "Train Epoch: 5 [5000/9145 (54%)]\tLoss: 0.313607\n",
      "Train Epoch: 5 [6000/9145 (65%)]\tLoss: 0.124233\n",
      "Train Epoch: 5 [7000/9145 (76%)]\tLoss: 0.163793\n",
      "Train Epoch: 5 [8000/9145 (87%)]\tLoss: 0.158146\n",
      "Train Epoch: 5 [9000/9145 (98%)]\tLoss: 0.280411\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3021 (0%)]\tLoss: 0.284197\n",
      "Train Epoch: 1 [1000/3021 (32%)]\tLoss: 0.146465\n",
      "Train Epoch: 1 [2000/3021 (65%)]\tLoss: 0.213835\n",
      "Train Epoch: 1 [630/3021 (97%)]\tLoss: 0.096398\n",
      "Train Epoch: 2 [0/3021 (0%)]\tLoss: 0.223800\n",
      "Train Epoch: 2 [1000/3021 (32%)]\tLoss: 0.193367\n",
      "Train Epoch: 2 [2000/3021 (65%)]\tLoss: 0.158575\n",
      "Train Epoch: 2 [630/3021 (97%)]\tLoss: 0.376509\n",
      "Train Epoch: 3 [0/3021 (0%)]\tLoss: 0.122397\n",
      "Train Epoch: 3 [1000/3021 (32%)]\tLoss: 0.193600\n",
      "Train Epoch: 3 [2000/3021 (65%)]\tLoss: 0.155959\n",
      "Train Epoch: 3 [630/3021 (97%)]\tLoss: 0.098295\n",
      "Train Epoch: 4 [0/3021 (0%)]\tLoss: 0.148146\n",
      "Train Epoch: 4 [1000/3021 (32%)]\tLoss: 0.134054\n",
      "Train Epoch: 4 [2000/3021 (65%)]\tLoss: 0.095207\n",
      "Train Epoch: 4 [630/3021 (97%)]\tLoss: 0.056136\n",
      "Train Epoch: 5 [0/3021 (0%)]\tLoss: 0.092505\n",
      "Train Epoch: 5 [1000/3021 (32%)]\tLoss: 0.131173\n",
      "Train Epoch: 5 [2000/3021 (65%)]\tLoss: 0.102462\n",
      "Train Epoch: 5 [630/3021 (97%)]\tLoss: 0.060661\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/7953 (0%)]\tLoss: 0.461744\n",
      "Train Epoch: 1 [1000/7953 (12%)]\tLoss: 0.464817\n",
      "Train Epoch: 1 [2000/7953 (25%)]\tLoss: 0.339125\n",
      "Train Epoch: 1 [3000/7953 (38%)]\tLoss: 0.464648\n",
      "Train Epoch: 1 [4000/7953 (50%)]\tLoss: 0.365256\n",
      "Train Epoch: 1 [5000/7953 (62%)]\tLoss: 0.313896\n",
      "Train Epoch: 1 [6000/7953 (75%)]\tLoss: 0.387508\n",
      "Train Epoch: 1 [7000/7953 (88%)]\tLoss: 0.307812\n",
      "Train Epoch: 2 [0/7953 (0%)]\tLoss: 0.241490\n",
      "Train Epoch: 2 [1000/7953 (12%)]\tLoss: 0.259785\n",
      "Train Epoch: 2 [2000/7953 (25%)]\tLoss: 0.283849\n",
      "Train Epoch: 2 [3000/7953 (38%)]\tLoss: 0.289019\n",
      "Train Epoch: 2 [4000/7953 (50%)]\tLoss: 0.345042\n",
      "Train Epoch: 2 [5000/7953 (62%)]\tLoss: 0.289840\n",
      "Train Epoch: 2 [6000/7953 (75%)]\tLoss: 0.357788\n",
      "Train Epoch: 2 [7000/7953 (88%)]\tLoss: 0.301700\n",
      "Train Epoch: 3 [0/7953 (0%)]\tLoss: 0.353306\n",
      "Train Epoch: 3 [1000/7953 (12%)]\tLoss: 0.241617\n",
      "Train Epoch: 3 [2000/7953 (25%)]\tLoss: 0.428832\n",
      "Train Epoch: 3 [3000/7953 (38%)]\tLoss: 0.268195\n",
      "Train Epoch: 3 [4000/7953 (50%)]\tLoss: 0.318459\n",
      "Train Epoch: 3 [5000/7953 (62%)]\tLoss: 0.378454\n",
      "Train Epoch: 3 [6000/7953 (75%)]\tLoss: 0.375357\n",
      "Train Epoch: 3 [7000/7953 (88%)]\tLoss: 0.471141\n",
      "Train Epoch: 4 [0/7953 (0%)]\tLoss: 0.262210\n",
      "Train Epoch: 4 [1000/7953 (12%)]\tLoss: 0.250926\n",
      "Train Epoch: 4 [2000/7953 (25%)]\tLoss: 0.436726\n",
      "Train Epoch: 4 [3000/7953 (38%)]\tLoss: 0.299714\n",
      "Train Epoch: 4 [4000/7953 (50%)]\tLoss: 0.291091\n",
      "Train Epoch: 4 [5000/7953 (62%)]\tLoss: 0.370026\n",
      "Train Epoch: 4 [6000/7953 (75%)]\tLoss: 0.257000\n",
      "Train Epoch: 4 [7000/7953 (88%)]\tLoss: 0.316845\n",
      "Train Epoch: 5 [0/7953 (0%)]\tLoss: 0.361495\n",
      "Train Epoch: 5 [1000/7953 (12%)]\tLoss: 0.181066\n",
      "Train Epoch: 5 [2000/7953 (25%)]\tLoss: 0.337480\n",
      "Train Epoch: 5 [3000/7953 (38%)]\tLoss: 0.366730\n",
      "Train Epoch: 5 [4000/7953 (50%)]\tLoss: 0.283296\n",
      "Train Epoch: 5 [5000/7953 (62%)]\tLoss: 0.472892\n",
      "Train Epoch: 5 [6000/7953 (75%)]\tLoss: 0.354776\n",
      "Train Epoch: 5 [7000/7953 (88%)]\tLoss: 0.328909\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/10012 (0%)]\tLoss: 0.328488\n",
      "Train Epoch: 1 [1000/10012 (10%)]\tLoss: 0.198476\n",
      "Train Epoch: 1 [2000/10012 (20%)]\tLoss: 0.093786\n",
      "Train Epoch: 1 [3000/10012 (30%)]\tLoss: 0.128491\n",
      "Train Epoch: 1 [4000/10012 (40%)]\tLoss: 0.161148\n",
      "Train Epoch: 1 [5000/10012 (50%)]\tLoss: 0.086122\n",
      "Train Epoch: 1 [6000/10012 (59%)]\tLoss: 0.334392\n",
      "Train Epoch: 1 [7000/10012 (69%)]\tLoss: 0.176298\n",
      "Train Epoch: 1 [8000/10012 (79%)]\tLoss: 0.042815\n",
      "Train Epoch: 1 [9000/10012 (89%)]\tLoss: 0.103608\n",
      "Train Epoch: 1 [1200/10012 (99%)]\tLoss: 0.252452\n",
      "Train Epoch: 2 [0/10012 (0%)]\tLoss: 0.283546\n",
      "Train Epoch: 2 [1000/10012 (10%)]\tLoss: 0.098863\n",
      "Train Epoch: 2 [2000/10012 (20%)]\tLoss: 0.124270\n",
      "Train Epoch: 2 [3000/10012 (30%)]\tLoss: 0.127442\n",
      "Train Epoch: 2 [4000/10012 (40%)]\tLoss: 0.025117\n",
      "Train Epoch: 2 [5000/10012 (50%)]\tLoss: 0.132290\n",
      "Train Epoch: 2 [6000/10012 (59%)]\tLoss: 0.115606\n",
      "Train Epoch: 2 [7000/10012 (69%)]\tLoss: 0.138470\n",
      "Train Epoch: 2 [8000/10012 (79%)]\tLoss: 0.103811\n",
      "Train Epoch: 2 [9000/10012 (89%)]\tLoss: 0.142412\n",
      "Train Epoch: 2 [1200/10012 (99%)]\tLoss: 0.014757\n",
      "Train Epoch: 3 [0/10012 (0%)]\tLoss: 0.100925\n",
      "Train Epoch: 3 [1000/10012 (10%)]\tLoss: 0.034479\n",
      "Train Epoch: 3 [2000/10012 (20%)]\tLoss: 0.176062\n",
      "Train Epoch: 3 [3000/10012 (30%)]\tLoss: 0.047244\n",
      "Train Epoch: 3 [4000/10012 (40%)]\tLoss: 0.161059\n",
      "Train Epoch: 3 [5000/10012 (50%)]\tLoss: 0.102757\n",
      "Train Epoch: 3 [6000/10012 (59%)]\tLoss: 0.130310\n",
      "Train Epoch: 3 [7000/10012 (69%)]\tLoss: 0.051196\n",
      "Train Epoch: 3 [8000/10012 (79%)]\tLoss: 0.114372\n",
      "Train Epoch: 3 [9000/10012 (89%)]\tLoss: 0.057443\n",
      "Train Epoch: 3 [1200/10012 (99%)]\tLoss: 0.019245\n",
      "Train Epoch: 4 [0/10012 (0%)]\tLoss: 0.208359\n",
      "Train Epoch: 4 [1000/10012 (10%)]\tLoss: 0.064119\n",
      "Train Epoch: 4 [2000/10012 (20%)]\tLoss: 0.114863\n",
      "Train Epoch: 4 [3000/10012 (30%)]\tLoss: 0.082370\n",
      "Train Epoch: 4 [4000/10012 (40%)]\tLoss: 0.105697\n",
      "Train Epoch: 4 [5000/10012 (50%)]\tLoss: 0.067061\n",
      "Train Epoch: 4 [6000/10012 (59%)]\tLoss: 0.075567\n",
      "Train Epoch: 4 [7000/10012 (69%)]\tLoss: 0.116312\n",
      "Train Epoch: 4 [8000/10012 (79%)]\tLoss: 0.132387\n",
      "Train Epoch: 4 [9000/10012 (89%)]\tLoss: 0.088434\n",
      "Train Epoch: 4 [1200/10012 (99%)]\tLoss: 0.070611\n",
      "Train Epoch: 5 [0/10012 (0%)]\tLoss: 0.158910\n",
      "Train Epoch: 5 [1000/10012 (10%)]\tLoss: 0.024412\n",
      "Train Epoch: 5 [2000/10012 (20%)]\tLoss: 0.113945\n",
      "Train Epoch: 5 [3000/10012 (30%)]\tLoss: 0.042910\n",
      "Train Epoch: 5 [4000/10012 (40%)]\tLoss: 0.052733\n",
      "Train Epoch: 5 [5000/10012 (50%)]\tLoss: 0.063350\n",
      "Train Epoch: 5 [6000/10012 (59%)]\tLoss: 0.094523\n",
      "Train Epoch: 5 [7000/10012 (69%)]\tLoss: 0.088442\n",
      "Train Epoch: 5 [8000/10012 (79%)]\tLoss: 0.100534\n",
      "Train Epoch: 5 [9000/10012 (89%)]\tLoss: 0.070583\n",
      "Train Epoch: 5 [1200/10012 (99%)]\tLoss: 0.002476\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "8\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.6277, Accuracy: 8702/10000 (87%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/7731 (0%)]\tLoss: 0.157363\n",
      "Train Epoch: 1 [1000/7731 (13%)]\tLoss: 0.198619\n",
      "Train Epoch: 1 [2000/7731 (26%)]\tLoss: 0.171723\n",
      "Train Epoch: 1 [3000/7731 (38%)]\tLoss: 0.201722\n",
      "Train Epoch: 1 [4000/7731 (51%)]\tLoss: 0.140865\n",
      "Train Epoch: 1 [5000/7731 (64%)]\tLoss: 0.214422\n",
      "Train Epoch: 1 [6000/7731 (77%)]\tLoss: 0.243702\n",
      "Train Epoch: 1 [7000/7731 (90%)]\tLoss: 0.170490\n",
      "Train Epoch: 2 [0/7731 (0%)]\tLoss: 0.180791\n",
      "Train Epoch: 2 [1000/7731 (13%)]\tLoss: 0.147691\n",
      "Train Epoch: 2 [2000/7731 (26%)]\tLoss: 0.133815\n",
      "Train Epoch: 2 [3000/7731 (38%)]\tLoss: 0.140100\n",
      "Train Epoch: 2 [4000/7731 (51%)]\tLoss: 0.233032\n",
      "Train Epoch: 2 [5000/7731 (64%)]\tLoss: 0.154758\n",
      "Train Epoch: 2 [6000/7731 (77%)]\tLoss: 0.158662\n",
      "Train Epoch: 2 [7000/7731 (90%)]\tLoss: 0.055661\n",
      "Train Epoch: 3 [0/7731 (0%)]\tLoss: 0.150929\n",
      "Train Epoch: 3 [1000/7731 (13%)]\tLoss: 0.090662\n",
      "Train Epoch: 3 [2000/7731 (26%)]\tLoss: 0.160681\n",
      "Train Epoch: 3 [3000/7731 (38%)]\tLoss: 0.134061\n",
      "Train Epoch: 3 [4000/7731 (51%)]\tLoss: 0.070731\n",
      "Train Epoch: 3 [5000/7731 (64%)]\tLoss: 0.107770\n",
      "Train Epoch: 3 [6000/7731 (77%)]\tLoss: 0.104403\n",
      "Train Epoch: 3 [7000/7731 (90%)]\tLoss: 0.095233\n",
      "Train Epoch: 4 [0/7731 (0%)]\tLoss: 0.098655\n",
      "Train Epoch: 4 [1000/7731 (13%)]\tLoss: 0.102100\n",
      "Train Epoch: 4 [2000/7731 (26%)]\tLoss: 0.112598\n",
      "Train Epoch: 4 [3000/7731 (38%)]\tLoss: 0.140888\n",
      "Train Epoch: 4 [4000/7731 (51%)]\tLoss: 0.152493\n",
      "Train Epoch: 4 [5000/7731 (64%)]\tLoss: 0.187308\n",
      "Train Epoch: 4 [6000/7731 (77%)]\tLoss: 0.124019\n",
      "Train Epoch: 4 [7000/7731 (90%)]\tLoss: 0.100511\n",
      "Train Epoch: 5 [0/7731 (0%)]\tLoss: 0.129091\n",
      "Train Epoch: 5 [1000/7731 (13%)]\tLoss: 0.057703\n",
      "Train Epoch: 5 [2000/7731 (26%)]\tLoss: 0.078413\n",
      "Train Epoch: 5 [3000/7731 (38%)]\tLoss: 0.154181\n",
      "Train Epoch: 5 [4000/7731 (51%)]\tLoss: 0.183318\n",
      "Train Epoch: 5 [5000/7731 (64%)]\tLoss: 0.095076\n",
      "Train Epoch: 5 [6000/7731 (77%)]\tLoss: 0.100047\n",
      "Train Epoch: 5 [7000/7731 (90%)]\tLoss: 0.057326\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11194 (0%)]\tLoss: 0.210254\n",
      "Train Epoch: 1 [1000/11194 (9%)]\tLoss: 0.193766\n",
      "Train Epoch: 1 [2000/11194 (18%)]\tLoss: 0.102898\n",
      "Train Epoch: 1 [3000/11194 (27%)]\tLoss: 0.102801\n",
      "Train Epoch: 1 [4000/11194 (36%)]\tLoss: 0.330920\n",
      "Train Epoch: 1 [5000/11194 (45%)]\tLoss: 0.147179\n",
      "Train Epoch: 1 [6000/11194 (54%)]\tLoss: 0.173676\n",
      "Train Epoch: 1 [7000/11194 (62%)]\tLoss: 0.135392\n",
      "Train Epoch: 1 [8000/11194 (71%)]\tLoss: 0.156795\n",
      "Train Epoch: 1 [9000/11194 (80%)]\tLoss: 0.187670\n",
      "Train Epoch: 1 [10000/11194 (89%)]\tLoss: 0.324828\n",
      "Train Epoch: 1 [11000/11194 (98%)]\tLoss: 0.169340\n",
      "Train Epoch: 2 [0/11194 (0%)]\tLoss: 0.256402\n",
      "Train Epoch: 2 [1000/11194 (9%)]\tLoss: 0.176738\n",
      "Train Epoch: 2 [2000/11194 (18%)]\tLoss: 0.092762\n",
      "Train Epoch: 2 [3000/11194 (27%)]\tLoss: 0.131998\n",
      "Train Epoch: 2 [4000/11194 (36%)]\tLoss: 0.248236\n",
      "Train Epoch: 2 [5000/11194 (45%)]\tLoss: 0.125162\n",
      "Train Epoch: 2 [6000/11194 (54%)]\tLoss: 0.197962\n",
      "Train Epoch: 2 [7000/11194 (62%)]\tLoss: 0.218833\n",
      "Train Epoch: 2 [8000/11194 (71%)]\tLoss: 0.167367\n",
      "Train Epoch: 2 [9000/11194 (80%)]\tLoss: 0.125148\n",
      "Train Epoch: 2 [10000/11194 (89%)]\tLoss: 0.099009\n",
      "Train Epoch: 2 [11000/11194 (98%)]\tLoss: 0.104651\n",
      "Train Epoch: 3 [0/11194 (0%)]\tLoss: 0.258278\n",
      "Train Epoch: 3 [1000/11194 (9%)]\tLoss: 0.154215\n",
      "Train Epoch: 3 [2000/11194 (18%)]\tLoss: 0.143818\n",
      "Train Epoch: 3 [3000/11194 (27%)]\tLoss: 0.136994\n",
      "Train Epoch: 3 [4000/11194 (36%)]\tLoss: 0.192430\n",
      "Train Epoch: 3 [5000/11194 (45%)]\tLoss: 0.078868\n",
      "Train Epoch: 3 [6000/11194 (54%)]\tLoss: 0.097504\n",
      "Train Epoch: 3 [7000/11194 (62%)]\tLoss: 0.116704\n",
      "Train Epoch: 3 [8000/11194 (71%)]\tLoss: 0.178906\n",
      "Train Epoch: 3 [9000/11194 (80%)]\tLoss: 0.218843\n",
      "Train Epoch: 3 [10000/11194 (89%)]\tLoss: 0.224556\n",
      "Train Epoch: 3 [11000/11194 (98%)]\tLoss: 0.257826\n",
      "Train Epoch: 4 [0/11194 (0%)]\tLoss: 0.123723\n",
      "Train Epoch: 4 [1000/11194 (9%)]\tLoss: 0.175441\n",
      "Train Epoch: 4 [2000/11194 (18%)]\tLoss: 0.128413\n",
      "Train Epoch: 4 [3000/11194 (27%)]\tLoss: 0.112110\n",
      "Train Epoch: 4 [4000/11194 (36%)]\tLoss: 0.151887\n",
      "Train Epoch: 4 [5000/11194 (45%)]\tLoss: 0.080532\n",
      "Train Epoch: 4 [6000/11194 (54%)]\tLoss: 0.185642\n",
      "Train Epoch: 4 [7000/11194 (62%)]\tLoss: 0.145245\n",
      "Train Epoch: 4 [8000/11194 (71%)]\tLoss: 0.094071\n",
      "Train Epoch: 4 [9000/11194 (80%)]\tLoss: 0.129391\n",
      "Train Epoch: 4 [10000/11194 (89%)]\tLoss: 0.167213\n",
      "Train Epoch: 4 [11000/11194 (98%)]\tLoss: 0.154283\n",
      "Train Epoch: 5 [0/11194 (0%)]\tLoss: 0.227584\n",
      "Train Epoch: 5 [1000/11194 (9%)]\tLoss: 0.170776\n",
      "Train Epoch: 5 [2000/11194 (18%)]\tLoss: 0.161213\n",
      "Train Epoch: 5 [3000/11194 (27%)]\tLoss: 0.093416\n",
      "Train Epoch: 5 [4000/11194 (36%)]\tLoss: 0.111682\n",
      "Train Epoch: 5 [5000/11194 (45%)]\tLoss: 0.180948\n",
      "Train Epoch: 5 [6000/11194 (54%)]\tLoss: 0.141069\n",
      "Train Epoch: 5 [7000/11194 (62%)]\tLoss: 0.157116\n",
      "Train Epoch: 5 [8000/11194 (71%)]\tLoss: 0.197406\n",
      "Train Epoch: 5 [9000/11194 (80%)]\tLoss: 0.301615\n",
      "Train Epoch: 5 [10000/11194 (89%)]\tLoss: 0.097042\n",
      "Train Epoch: 5 [11000/11194 (98%)]\tLoss: 0.086403\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/7891 (0%)]\tLoss: 0.156715\n",
      "Train Epoch: 1 [1000/7891 (13%)]\tLoss: 0.137106\n",
      "Train Epoch: 1 [2000/7891 (25%)]\tLoss: 0.063201\n",
      "Train Epoch: 1 [3000/7891 (38%)]\tLoss: 0.107392\n",
      "Train Epoch: 1 [4000/7891 (51%)]\tLoss: 0.139023\n",
      "Train Epoch: 1 [5000/7891 (63%)]\tLoss: 0.164455\n",
      "Train Epoch: 1 [6000/7891 (76%)]\tLoss: 0.051115\n",
      "Train Epoch: 1 [7000/7891 (89%)]\tLoss: 0.129868\n",
      "Train Epoch: 2 [0/7891 (0%)]\tLoss: 0.110353\n",
      "Train Epoch: 2 [1000/7891 (13%)]\tLoss: 0.110971\n",
      "Train Epoch: 2 [2000/7891 (25%)]\tLoss: 0.120349\n",
      "Train Epoch: 2 [3000/7891 (38%)]\tLoss: 0.158438\n",
      "Train Epoch: 2 [4000/7891 (51%)]\tLoss: 0.056793\n",
      "Train Epoch: 2 [5000/7891 (63%)]\tLoss: 0.135109\n",
      "Train Epoch: 2 [6000/7891 (76%)]\tLoss: 0.111779\n",
      "Train Epoch: 2 [7000/7891 (89%)]\tLoss: 0.070912\n",
      "Train Epoch: 3 [0/7891 (0%)]\tLoss: 0.133701\n",
      "Train Epoch: 3 [1000/7891 (13%)]\tLoss: 0.078009\n",
      "Train Epoch: 3 [2000/7891 (25%)]\tLoss: 0.032938\n",
      "Train Epoch: 3 [3000/7891 (38%)]\tLoss: 0.133626\n",
      "Train Epoch: 3 [4000/7891 (51%)]\tLoss: 0.080079\n",
      "Train Epoch: 3 [5000/7891 (63%)]\tLoss: 0.062731\n",
      "Train Epoch: 3 [6000/7891 (76%)]\tLoss: 0.243306\n",
      "Train Epoch: 3 [7000/7891 (89%)]\tLoss: 0.101727\n",
      "Train Epoch: 4 [0/7891 (0%)]\tLoss: 0.172835\n",
      "Train Epoch: 4 [1000/7891 (13%)]\tLoss: 0.165020\n",
      "Train Epoch: 4 [2000/7891 (25%)]\tLoss: 0.079008\n",
      "Train Epoch: 4 [3000/7891 (38%)]\tLoss: 0.100796\n",
      "Train Epoch: 4 [4000/7891 (51%)]\tLoss: 0.078150\n",
      "Train Epoch: 4 [5000/7891 (63%)]\tLoss: 0.090558\n",
      "Train Epoch: 4 [6000/7891 (76%)]\tLoss: 0.122326\n",
      "Train Epoch: 4 [7000/7891 (89%)]\tLoss: 0.067427\n",
      "Train Epoch: 5 [0/7891 (0%)]\tLoss: 0.084181\n",
      "Train Epoch: 5 [1000/7891 (13%)]\tLoss: 0.067106\n",
      "Train Epoch: 5 [2000/7891 (25%)]\tLoss: 0.089287\n",
      "Train Epoch: 5 [3000/7891 (38%)]\tLoss: 0.069393\n",
      "Train Epoch: 5 [4000/7891 (51%)]\tLoss: 0.083843\n",
      "Train Epoch: 5 [5000/7891 (63%)]\tLoss: 0.104468\n",
      "Train Epoch: 5 [6000/7891 (76%)]\tLoss: 0.104455\n",
      "Train Epoch: 5 [7000/7891 (89%)]\tLoss: 0.067425\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/3053 (0%)]\tLoss: 0.082683\n",
      "Train Epoch: 1 [1000/3053 (32%)]\tLoss: 0.113807\n",
      "Train Epoch: 1 [2000/3053 (65%)]\tLoss: 0.029003\n",
      "Train Epoch: 1 [1590/3053 (97%)]\tLoss: 0.024063\n",
      "Train Epoch: 2 [0/3053 (0%)]\tLoss: 0.095884\n",
      "Train Epoch: 2 [1000/3053 (32%)]\tLoss: 0.358629\n",
      "Train Epoch: 2 [2000/3053 (65%)]\tLoss: 0.130382\n",
      "Train Epoch: 2 [1590/3053 (97%)]\tLoss: 0.118000\n",
      "Train Epoch: 3 [0/3053 (0%)]\tLoss: 0.143839\n",
      "Train Epoch: 3 [1000/3053 (32%)]\tLoss: 0.086086\n",
      "Train Epoch: 3 [2000/3053 (65%)]\tLoss: 0.151148\n",
      "Train Epoch: 3 [1590/3053 (97%)]\tLoss: 0.039601\n",
      "Train Epoch: 4 [0/3053 (0%)]\tLoss: 0.053181\n",
      "Train Epoch: 4 [1000/3053 (32%)]\tLoss: 0.107542\n",
      "Train Epoch: 4 [2000/3053 (65%)]\tLoss: 0.038922\n",
      "Train Epoch: 4 [1590/3053 (97%)]\tLoss: 0.037566\n",
      "Train Epoch: 5 [0/3053 (0%)]\tLoss: 0.034398\n",
      "Train Epoch: 5 [1000/3053 (32%)]\tLoss: 0.034291\n",
      "Train Epoch: 5 [2000/3053 (65%)]\tLoss: 0.053753\n",
      "Train Epoch: 5 [1590/3053 (97%)]\tLoss: 0.029757\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/9145 (0%)]\tLoss: 0.222728\n",
      "Train Epoch: 1 [1000/9145 (11%)]\tLoss: 0.087367\n",
      "Train Epoch: 1 [2000/9145 (22%)]\tLoss: 0.221934\n",
      "Train Epoch: 1 [3000/9145 (33%)]\tLoss: 0.157437\n",
      "Train Epoch: 1 [4000/9145 (43%)]\tLoss: 0.184951\n",
      "Train Epoch: 1 [5000/9145 (54%)]\tLoss: 0.206222\n",
      "Train Epoch: 1 [6000/9145 (65%)]\tLoss: 0.499459\n",
      "Train Epoch: 1 [7000/9145 (76%)]\tLoss: 0.327638\n",
      "Train Epoch: 1 [8000/9145 (87%)]\tLoss: 0.229690\n",
      "Train Epoch: 1 [9000/9145 (98%)]\tLoss: 0.279713\n",
      "Train Epoch: 2 [0/9145 (0%)]\tLoss: 0.232710\n",
      "Train Epoch: 2 [1000/9145 (11%)]\tLoss: 0.330202\n",
      "Train Epoch: 2 [2000/9145 (22%)]\tLoss: 0.279317\n",
      "Train Epoch: 2 [3000/9145 (33%)]\tLoss: 0.218752\n",
      "Train Epoch: 2 [4000/9145 (43%)]\tLoss: 0.277240\n",
      "Train Epoch: 2 [5000/9145 (54%)]\tLoss: 0.127477\n",
      "Train Epoch: 2 [6000/9145 (65%)]\tLoss: 0.167029\n",
      "Train Epoch: 2 [7000/9145 (76%)]\tLoss: 0.275990\n",
      "Train Epoch: 2 [8000/9145 (87%)]\tLoss: 0.142842\n",
      "Train Epoch: 2 [9000/9145 (98%)]\tLoss: 0.209377\n",
      "Train Epoch: 3 [0/9145 (0%)]\tLoss: 0.270136\n",
      "Train Epoch: 3 [1000/9145 (11%)]\tLoss: 0.208025\n",
      "Train Epoch: 3 [2000/9145 (22%)]\tLoss: 0.174023\n",
      "Train Epoch: 3 [3000/9145 (33%)]\tLoss: 0.179503\n",
      "Train Epoch: 3 [4000/9145 (43%)]\tLoss: 0.215982\n",
      "Train Epoch: 3 [5000/9145 (54%)]\tLoss: 0.210235\n",
      "Train Epoch: 3 [6000/9145 (65%)]\tLoss: 0.226565\n",
      "Train Epoch: 3 [7000/9145 (76%)]\tLoss: 0.171883\n",
      "Train Epoch: 3 [8000/9145 (87%)]\tLoss: 0.208744\n",
      "Train Epoch: 3 [9000/9145 (98%)]\tLoss: 0.197125\n",
      "Train Epoch: 4 [0/9145 (0%)]\tLoss: 0.236564\n",
      "Train Epoch: 4 [1000/9145 (11%)]\tLoss: 0.143752\n",
      "Train Epoch: 4 [2000/9145 (22%)]\tLoss: 0.169907\n",
      "Train Epoch: 4 [3000/9145 (33%)]\tLoss: 0.180134\n",
      "Train Epoch: 4 [4000/9145 (43%)]\tLoss: 0.188456\n",
      "Train Epoch: 4 [5000/9145 (54%)]\tLoss: 0.219292\n",
      "Train Epoch: 4 [6000/9145 (65%)]\tLoss: 0.280499\n",
      "Train Epoch: 4 [7000/9145 (76%)]\tLoss: 0.194511\n",
      "Train Epoch: 4 [8000/9145 (87%)]\tLoss: 0.172103\n",
      "Train Epoch: 4 [9000/9145 (98%)]\tLoss: 0.196325\n",
      "Train Epoch: 5 [0/9145 (0%)]\tLoss: 0.283011\n",
      "Train Epoch: 5 [1000/9145 (11%)]\tLoss: 0.195877\n",
      "Train Epoch: 5 [2000/9145 (22%)]\tLoss: 0.201290\n",
      "Train Epoch: 5 [3000/9145 (33%)]\tLoss: 0.109029\n",
      "Train Epoch: 5 [4000/9145 (43%)]\tLoss: 0.192437\n",
      "Train Epoch: 5 [5000/9145 (54%)]\tLoss: 0.215005\n",
      "Train Epoch: 5 [6000/9145 (65%)]\tLoss: 0.116252\n",
      "Train Epoch: 5 [7000/9145 (76%)]\tLoss: 0.194273\n",
      "Train Epoch: 5 [8000/9145 (87%)]\tLoss: 0.153448\n",
      "Train Epoch: 5 [9000/9145 (98%)]\tLoss: 0.179122\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3021 (0%)]\tLoss: 0.136054\n",
      "Train Epoch: 1 [1000/3021 (32%)]\tLoss: 0.164132\n",
      "Train Epoch: 1 [2000/3021 (65%)]\tLoss: 0.234379\n",
      "Train Epoch: 1 [630/3021 (97%)]\tLoss: 0.108673\n",
      "Train Epoch: 2 [0/3021 (0%)]\tLoss: 0.177623\n",
      "Train Epoch: 2 [1000/3021 (32%)]\tLoss: 0.113758\n",
      "Train Epoch: 2 [2000/3021 (65%)]\tLoss: 0.144718\n",
      "Train Epoch: 2 [630/3021 (97%)]\tLoss: 0.080666\n",
      "Train Epoch: 3 [0/3021 (0%)]\tLoss: 0.164415\n",
      "Train Epoch: 3 [1000/3021 (32%)]\tLoss: 0.135884\n",
      "Train Epoch: 3 [2000/3021 (65%)]\tLoss: 0.150930\n",
      "Train Epoch: 3 [630/3021 (97%)]\tLoss: 0.145429\n",
      "Train Epoch: 4 [0/3021 (0%)]\tLoss: 0.128930\n",
      "Train Epoch: 4 [1000/3021 (32%)]\tLoss: 0.142517\n",
      "Train Epoch: 4 [2000/3021 (65%)]\tLoss: 0.090738\n",
      "Train Epoch: 4 [630/3021 (97%)]\tLoss: 0.164947\n",
      "Train Epoch: 5 [0/3021 (0%)]\tLoss: 0.140545\n",
      "Train Epoch: 5 [1000/3021 (32%)]\tLoss: 0.136061\n",
      "Train Epoch: 5 [2000/3021 (65%)]\tLoss: 0.107858\n",
      "Train Epoch: 5 [630/3021 (97%)]\tLoss: 0.129963\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/7953 (0%)]\tLoss: 0.453590\n",
      "Train Epoch: 1 [1000/7953 (12%)]\tLoss: 0.316001\n",
      "Train Epoch: 1 [2000/7953 (25%)]\tLoss: 0.529251\n",
      "Train Epoch: 1 [3000/7953 (38%)]\tLoss: 0.435553\n",
      "Train Epoch: 1 [4000/7953 (50%)]\tLoss: 0.373523\n",
      "Train Epoch: 1 [5000/7953 (62%)]\tLoss: 0.376920\n",
      "Train Epoch: 1 [6000/7953 (75%)]\tLoss: 0.276122\n",
      "Train Epoch: 1 [7000/7953 (88%)]\tLoss: 0.357900\n",
      "Train Epoch: 2 [0/7953 (0%)]\tLoss: 0.372438\n",
      "Train Epoch: 2 [1000/7953 (12%)]\tLoss: 0.361600\n",
      "Train Epoch: 2 [2000/7953 (25%)]\tLoss: 0.282851\n",
      "Train Epoch: 2 [3000/7953 (38%)]\tLoss: 0.265633\n",
      "Train Epoch: 2 [4000/7953 (50%)]\tLoss: 0.299807\n",
      "Train Epoch: 2 [5000/7953 (62%)]\tLoss: 0.378399\n",
      "Train Epoch: 2 [6000/7953 (75%)]\tLoss: 0.463838\n",
      "Train Epoch: 2 [7000/7953 (88%)]\tLoss: 0.353978\n",
      "Train Epoch: 3 [0/7953 (0%)]\tLoss: 0.340288\n",
      "Train Epoch: 3 [1000/7953 (12%)]\tLoss: 0.283605\n",
      "Train Epoch: 3 [2000/7953 (25%)]\tLoss: 0.238181\n",
      "Train Epoch: 3 [3000/7953 (38%)]\tLoss: 0.337283\n",
      "Train Epoch: 3 [4000/7953 (50%)]\tLoss: 0.367692\n",
      "Train Epoch: 3 [5000/7953 (62%)]\tLoss: 0.320597\n",
      "Train Epoch: 3 [6000/7953 (75%)]\tLoss: 0.296775\n",
      "Train Epoch: 3 [7000/7953 (88%)]\tLoss: 0.270176\n",
      "Train Epoch: 4 [0/7953 (0%)]\tLoss: 0.267069\n",
      "Train Epoch: 4 [1000/7953 (12%)]\tLoss: 0.417309\n",
      "Train Epoch: 4 [2000/7953 (25%)]\tLoss: 0.248765\n",
      "Train Epoch: 4 [3000/7953 (38%)]\tLoss: 0.307687\n",
      "Train Epoch: 4 [4000/7953 (50%)]\tLoss: 0.309754\n",
      "Train Epoch: 4 [5000/7953 (62%)]\tLoss: 0.365665\n",
      "Train Epoch: 4 [6000/7953 (75%)]\tLoss: 0.380871\n",
      "Train Epoch: 4 [7000/7953 (88%)]\tLoss: 0.319220\n",
      "Train Epoch: 5 [0/7953 (0%)]\tLoss: 0.291640\n",
      "Train Epoch: 5 [1000/7953 (12%)]\tLoss: 0.381412\n",
      "Train Epoch: 5 [2000/7953 (25%)]\tLoss: 0.260289\n",
      "Train Epoch: 5 [3000/7953 (38%)]\tLoss: 0.317978\n",
      "Train Epoch: 5 [4000/7953 (50%)]\tLoss: 0.214157\n",
      "Train Epoch: 5 [5000/7953 (62%)]\tLoss: 0.331475\n",
      "Train Epoch: 5 [6000/7953 (75%)]\tLoss: 0.412667\n",
      "Train Epoch: 5 [7000/7953 (88%)]\tLoss: 0.264226\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/10012 (0%)]\tLoss: 0.178395\n",
      "Train Epoch: 1 [1000/10012 (10%)]\tLoss: 0.119273\n",
      "Train Epoch: 1 [2000/10012 (20%)]\tLoss: 0.030869\n",
      "Train Epoch: 1 [3000/10012 (30%)]\tLoss: 0.094487\n",
      "Train Epoch: 1 [4000/10012 (40%)]\tLoss: 0.136202\n",
      "Train Epoch: 1 [5000/10012 (50%)]\tLoss: 0.127767\n",
      "Train Epoch: 1 [6000/10012 (59%)]\tLoss: 0.099183\n",
      "Train Epoch: 1 [7000/10012 (69%)]\tLoss: 0.113788\n",
      "Train Epoch: 1 [8000/10012 (79%)]\tLoss: 0.062930\n",
      "Train Epoch: 1 [9000/10012 (89%)]\tLoss: 0.110865\n",
      "Train Epoch: 1 [1200/10012 (99%)]\tLoss: 0.238174\n",
      "Train Epoch: 2 [0/10012 (0%)]\tLoss: 0.089060\n",
      "Train Epoch: 2 [1000/10012 (10%)]\tLoss: 0.134359\n",
      "Train Epoch: 2 [2000/10012 (20%)]\tLoss: 0.122100\n",
      "Train Epoch: 2 [3000/10012 (30%)]\tLoss: 0.165637\n",
      "Train Epoch: 2 [4000/10012 (40%)]\tLoss: 0.057930\n",
      "Train Epoch: 2 [5000/10012 (50%)]\tLoss: 0.046776\n",
      "Train Epoch: 2 [6000/10012 (59%)]\tLoss: 0.122247\n",
      "Train Epoch: 2 [7000/10012 (69%)]\tLoss: 0.056098\n",
      "Train Epoch: 2 [8000/10012 (79%)]\tLoss: 0.060888\n",
      "Train Epoch: 2 [9000/10012 (89%)]\tLoss: 0.140737\n",
      "Train Epoch: 2 [1200/10012 (99%)]\tLoss: 0.019902\n",
      "Train Epoch: 3 [0/10012 (0%)]\tLoss: 0.081144\n",
      "Train Epoch: 3 [1000/10012 (10%)]\tLoss: 0.071428\n",
      "Train Epoch: 3 [2000/10012 (20%)]\tLoss: 0.038985\n",
      "Train Epoch: 3 [3000/10012 (30%)]\tLoss: 0.091884\n",
      "Train Epoch: 3 [4000/10012 (40%)]\tLoss: 0.149073\n",
      "Train Epoch: 3 [5000/10012 (50%)]\tLoss: 0.116226\n",
      "Train Epoch: 3 [6000/10012 (59%)]\tLoss: 0.146533\n",
      "Train Epoch: 3 [7000/10012 (69%)]\tLoss: 0.082184\n",
      "Train Epoch: 3 [8000/10012 (79%)]\tLoss: 0.086548\n",
      "Train Epoch: 3 [9000/10012 (89%)]\tLoss: 0.071204\n",
      "Train Epoch: 3 [1200/10012 (99%)]\tLoss: 0.019202\n",
      "Train Epoch: 4 [0/10012 (0%)]\tLoss: 0.075530\n",
      "Train Epoch: 4 [1000/10012 (10%)]\tLoss: 0.113376\n",
      "Train Epoch: 4 [2000/10012 (20%)]\tLoss: 0.025235\n",
      "Train Epoch: 4 [3000/10012 (30%)]\tLoss: 0.111742\n",
      "Train Epoch: 4 [4000/10012 (40%)]\tLoss: 0.042320\n",
      "Train Epoch: 4 [5000/10012 (50%)]\tLoss: 0.152815\n",
      "Train Epoch: 4 [6000/10012 (59%)]\tLoss: 0.122856\n",
      "Train Epoch: 4 [7000/10012 (69%)]\tLoss: 0.078855\n",
      "Train Epoch: 4 [8000/10012 (79%)]\tLoss: 0.111005\n",
      "Train Epoch: 4 [9000/10012 (89%)]\tLoss: 0.134379\n",
      "Train Epoch: 4 [1200/10012 (99%)]\tLoss: 0.172432\n",
      "Train Epoch: 5 [0/10012 (0%)]\tLoss: 0.269736\n",
      "Train Epoch: 5 [1000/10012 (10%)]\tLoss: 0.028294\n",
      "Train Epoch: 5 [2000/10012 (20%)]\tLoss: 0.110373\n",
      "Train Epoch: 5 [3000/10012 (30%)]\tLoss: 0.090949\n",
      "Train Epoch: 5 [4000/10012 (40%)]\tLoss: 0.069080\n",
      "Train Epoch: 5 [5000/10012 (50%)]\tLoss: 0.109616\n",
      "Train Epoch: 5 [6000/10012 (59%)]\tLoss: 0.107312\n",
      "Train Epoch: 5 [7000/10012 (69%)]\tLoss: 0.038428\n",
      "Train Epoch: 5 [8000/10012 (79%)]\tLoss: 0.071483\n",
      "Train Epoch: 5 [9000/10012 (89%)]\tLoss: 0.113049\n",
      "Train Epoch: 5 [1200/10012 (99%)]\tLoss: 0.094354\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "8\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.6226, Accuracy: 8653/10000 (87%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/7731 (0%)]\tLoss: 0.187449\n",
      "Train Epoch: 1 [1000/7731 (13%)]\tLoss: 0.091210\n",
      "Train Epoch: 1 [2000/7731 (26%)]\tLoss: 0.120634\n",
      "Train Epoch: 1 [3000/7731 (38%)]\tLoss: 0.160309\n",
      "Train Epoch: 1 [4000/7731 (51%)]\tLoss: 0.184527\n",
      "Train Epoch: 1 [5000/7731 (64%)]\tLoss: 0.218539\n",
      "Train Epoch: 1 [6000/7731 (77%)]\tLoss: 0.156075\n",
      "Train Epoch: 1 [7000/7731 (90%)]\tLoss: 0.205699\n",
      "Train Epoch: 2 [0/7731 (0%)]\tLoss: 0.170300\n",
      "Train Epoch: 2 [1000/7731 (13%)]\tLoss: 0.076523\n",
      "Train Epoch: 2 [2000/7731 (26%)]\tLoss: 0.059026\n",
      "Train Epoch: 2 [3000/7731 (38%)]\tLoss: 0.169495\n",
      "Train Epoch: 2 [4000/7731 (51%)]\tLoss: 0.103288\n",
      "Train Epoch: 2 [5000/7731 (64%)]\tLoss: 0.197680\n",
      "Train Epoch: 2 [6000/7731 (77%)]\tLoss: 0.158524\n",
      "Train Epoch: 2 [7000/7731 (90%)]\tLoss: 0.152293\n",
      "Train Epoch: 3 [0/7731 (0%)]\tLoss: 0.159291\n",
      "Train Epoch: 3 [1000/7731 (13%)]\tLoss: 0.105695\n",
      "Train Epoch: 3 [2000/7731 (26%)]\tLoss: 0.104462\n",
      "Train Epoch: 3 [3000/7731 (38%)]\tLoss: 0.139303\n",
      "Train Epoch: 3 [4000/7731 (51%)]\tLoss: 0.195046\n",
      "Train Epoch: 3 [5000/7731 (64%)]\tLoss: 0.114748\n",
      "Train Epoch: 3 [6000/7731 (77%)]\tLoss: 0.183755\n",
      "Train Epoch: 3 [7000/7731 (90%)]\tLoss: 0.192954\n",
      "Train Epoch: 4 [0/7731 (0%)]\tLoss: 0.133807\n",
      "Train Epoch: 4 [1000/7731 (13%)]\tLoss: 0.141100\n",
      "Train Epoch: 4 [2000/7731 (26%)]\tLoss: 0.096092\n",
      "Train Epoch: 4 [3000/7731 (38%)]\tLoss: 0.049243\n",
      "Train Epoch: 4 [4000/7731 (51%)]\tLoss: 0.142137\n",
      "Train Epoch: 4 [5000/7731 (64%)]\tLoss: 0.173221\n",
      "Train Epoch: 4 [6000/7731 (77%)]\tLoss: 0.088920\n",
      "Train Epoch: 4 [7000/7731 (90%)]\tLoss: 0.128660\n",
      "Train Epoch: 5 [0/7731 (0%)]\tLoss: 0.096578\n",
      "Train Epoch: 5 [1000/7731 (13%)]\tLoss: 0.185621\n",
      "Train Epoch: 5 [2000/7731 (26%)]\tLoss: 0.066309\n",
      "Train Epoch: 5 [3000/7731 (38%)]\tLoss: 0.141261\n",
      "Train Epoch: 5 [4000/7731 (51%)]\tLoss: 0.086222\n",
      "Train Epoch: 5 [5000/7731 (64%)]\tLoss: 0.085432\n",
      "Train Epoch: 5 [6000/7731 (77%)]\tLoss: 0.155242\n",
      "Train Epoch: 5 [7000/7731 (90%)]\tLoss: 0.156202\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11194 (0%)]\tLoss: 0.379865\n",
      "Train Epoch: 1 [1000/11194 (9%)]\tLoss: 0.145823\n",
      "Train Epoch: 1 [2000/11194 (18%)]\tLoss: 0.212403\n",
      "Train Epoch: 1 [3000/11194 (27%)]\tLoss: 0.197964\n",
      "Train Epoch: 1 [4000/11194 (36%)]\tLoss: 0.065474\n",
      "Train Epoch: 1 [5000/11194 (45%)]\tLoss: 0.197521\n",
      "Train Epoch: 1 [6000/11194 (54%)]\tLoss: 0.273583\n",
      "Train Epoch: 1 [7000/11194 (62%)]\tLoss: 0.244849\n",
      "Train Epoch: 1 [8000/11194 (71%)]\tLoss: 0.103820\n",
      "Train Epoch: 1 [9000/11194 (80%)]\tLoss: 0.178978\n",
      "Train Epoch: 1 [10000/11194 (89%)]\tLoss: 0.211745\n",
      "Train Epoch: 1 [11000/11194 (98%)]\tLoss: 0.181935\n",
      "Train Epoch: 2 [0/11194 (0%)]\tLoss: 0.242175\n",
      "Train Epoch: 2 [1000/11194 (9%)]\tLoss: 0.217568\n",
      "Train Epoch: 2 [2000/11194 (18%)]\tLoss: 0.140213\n",
      "Train Epoch: 2 [3000/11194 (27%)]\tLoss: 0.264380\n",
      "Train Epoch: 2 [4000/11194 (36%)]\tLoss: 0.157217\n",
      "Train Epoch: 2 [5000/11194 (45%)]\tLoss: 0.331625\n",
      "Train Epoch: 2 [6000/11194 (54%)]\tLoss: 0.094785\n",
      "Train Epoch: 2 [7000/11194 (62%)]\tLoss: 0.132469\n",
      "Train Epoch: 2 [8000/11194 (71%)]\tLoss: 0.314927\n",
      "Train Epoch: 2 [9000/11194 (80%)]\tLoss: 0.248227\n",
      "Train Epoch: 2 [10000/11194 (89%)]\tLoss: 0.204839\n",
      "Train Epoch: 2 [11000/11194 (98%)]\tLoss: 0.138637\n",
      "Train Epoch: 3 [0/11194 (0%)]\tLoss: 0.183086\n",
      "Train Epoch: 3 [1000/11194 (9%)]\tLoss: 0.096806\n",
      "Train Epoch: 3 [2000/11194 (18%)]\tLoss: 0.121387\n",
      "Train Epoch: 3 [3000/11194 (27%)]\tLoss: 0.166156\n",
      "Train Epoch: 3 [4000/11194 (36%)]\tLoss: 0.250332\n",
      "Train Epoch: 3 [5000/11194 (45%)]\tLoss: 0.201663\n",
      "Train Epoch: 3 [6000/11194 (54%)]\tLoss: 0.126668\n",
      "Train Epoch: 3 [7000/11194 (62%)]\tLoss: 0.149901\n",
      "Train Epoch: 3 [8000/11194 (71%)]\tLoss: 0.137137\n",
      "Train Epoch: 3 [9000/11194 (80%)]\tLoss: 0.142685\n",
      "Train Epoch: 3 [10000/11194 (89%)]\tLoss: 0.092019\n",
      "Train Epoch: 3 [11000/11194 (98%)]\tLoss: 0.308928\n",
      "Train Epoch: 4 [0/11194 (0%)]\tLoss: 0.208292\n",
      "Train Epoch: 4 [1000/11194 (9%)]\tLoss: 0.087996\n",
      "Train Epoch: 4 [2000/11194 (18%)]\tLoss: 0.106145\n",
      "Train Epoch: 4 [3000/11194 (27%)]\tLoss: 0.140184\n",
      "Train Epoch: 4 [4000/11194 (36%)]\tLoss: 0.142420\n",
      "Train Epoch: 4 [5000/11194 (45%)]\tLoss: 0.130857\n",
      "Train Epoch: 4 [6000/11194 (54%)]\tLoss: 0.232739\n",
      "Train Epoch: 4 [7000/11194 (62%)]\tLoss: 0.186901\n",
      "Train Epoch: 4 [8000/11194 (71%)]\tLoss: 0.094177\n",
      "Train Epoch: 4 [9000/11194 (80%)]\tLoss: 0.121848\n",
      "Train Epoch: 4 [10000/11194 (89%)]\tLoss: 0.142223\n",
      "Train Epoch: 4 [11000/11194 (98%)]\tLoss: 0.101010\n",
      "Train Epoch: 5 [0/11194 (0%)]\tLoss: 0.128653\n",
      "Train Epoch: 5 [1000/11194 (9%)]\tLoss: 0.108206\n",
      "Train Epoch: 5 [2000/11194 (18%)]\tLoss: 0.172133\n",
      "Train Epoch: 5 [3000/11194 (27%)]\tLoss: 0.183267\n",
      "Train Epoch: 5 [4000/11194 (36%)]\tLoss: 0.110942\n",
      "Train Epoch: 5 [5000/11194 (45%)]\tLoss: 0.133115\n",
      "Train Epoch: 5 [6000/11194 (54%)]\tLoss: 0.073208\n",
      "Train Epoch: 5 [7000/11194 (62%)]\tLoss: 0.175976\n",
      "Train Epoch: 5 [8000/11194 (71%)]\tLoss: 0.159851\n",
      "Train Epoch: 5 [9000/11194 (80%)]\tLoss: 0.156585\n",
      "Train Epoch: 5 [10000/11194 (89%)]\tLoss: 0.170622\n",
      "Train Epoch: 5 [11000/11194 (98%)]\tLoss: 0.141984\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/7891 (0%)]\tLoss: 0.134348\n",
      "Train Epoch: 1 [1000/7891 (13%)]\tLoss: 0.231697\n",
      "Train Epoch: 1 [2000/7891 (25%)]\tLoss: 0.183830\n",
      "Train Epoch: 1 [3000/7891 (38%)]\tLoss: 0.179518\n",
      "Train Epoch: 1 [4000/7891 (51%)]\tLoss: 0.168010\n",
      "Train Epoch: 1 [5000/7891 (63%)]\tLoss: 0.081066\n",
      "Train Epoch: 1 [6000/7891 (76%)]\tLoss: 0.194602\n",
      "Train Epoch: 1 [7000/7891 (89%)]\tLoss: 0.139711\n",
      "Train Epoch: 2 [0/7891 (0%)]\tLoss: 0.122051\n",
      "Train Epoch: 2 [1000/7891 (13%)]\tLoss: 0.066494\n",
      "Train Epoch: 2 [2000/7891 (25%)]\tLoss: 0.119828\n",
      "Train Epoch: 2 [3000/7891 (38%)]\tLoss: 0.060412\n",
      "Train Epoch: 2 [4000/7891 (51%)]\tLoss: 0.139509\n",
      "Train Epoch: 2 [5000/7891 (63%)]\tLoss: 0.159581\n",
      "Train Epoch: 2 [6000/7891 (76%)]\tLoss: 0.070279\n",
      "Train Epoch: 2 [7000/7891 (89%)]\tLoss: 0.222863\n",
      "Train Epoch: 3 [0/7891 (0%)]\tLoss: 0.105993\n",
      "Train Epoch: 3 [1000/7891 (13%)]\tLoss: 0.085703\n",
      "Train Epoch: 3 [2000/7891 (25%)]\tLoss: 0.084572\n",
      "Train Epoch: 3 [3000/7891 (38%)]\tLoss: 0.119863\n",
      "Train Epoch: 3 [4000/7891 (51%)]\tLoss: 0.099979\n",
      "Train Epoch: 3 [5000/7891 (63%)]\tLoss: 0.041707\n",
      "Train Epoch: 3 [6000/7891 (76%)]\tLoss: 0.185821\n",
      "Train Epoch: 3 [7000/7891 (89%)]\tLoss: 0.118606\n",
      "Train Epoch: 4 [0/7891 (0%)]\tLoss: 0.111460\n",
      "Train Epoch: 4 [1000/7891 (13%)]\tLoss: 0.076440\n",
      "Train Epoch: 4 [2000/7891 (25%)]\tLoss: 0.099370\n",
      "Train Epoch: 4 [3000/7891 (38%)]\tLoss: 0.045030\n",
      "Train Epoch: 4 [4000/7891 (51%)]\tLoss: 0.078945\n",
      "Train Epoch: 4 [5000/7891 (63%)]\tLoss: 0.090672\n",
      "Train Epoch: 4 [6000/7891 (76%)]\tLoss: 0.067090\n",
      "Train Epoch: 4 [7000/7891 (89%)]\tLoss: 0.064962\n",
      "Train Epoch: 5 [0/7891 (0%)]\tLoss: 0.045519\n",
      "Train Epoch: 5 [1000/7891 (13%)]\tLoss: 0.073409\n",
      "Train Epoch: 5 [2000/7891 (25%)]\tLoss: 0.049474\n",
      "Train Epoch: 5 [3000/7891 (38%)]\tLoss: 0.037536\n",
      "Train Epoch: 5 [4000/7891 (51%)]\tLoss: 0.051596\n",
      "Train Epoch: 5 [5000/7891 (63%)]\tLoss: 0.135115\n",
      "Train Epoch: 5 [6000/7891 (76%)]\tLoss: 0.070383\n",
      "Train Epoch: 5 [7000/7891 (89%)]\tLoss: 0.090442\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/3053 (0%)]\tLoss: 0.112812\n",
      "Train Epoch: 1 [1000/3053 (32%)]\tLoss: 0.122596\n",
      "Train Epoch: 1 [2000/3053 (65%)]\tLoss: 0.129876\n",
      "Train Epoch: 1 [1590/3053 (97%)]\tLoss: 0.044885\n",
      "Train Epoch: 2 [0/3053 (0%)]\tLoss: 0.051928\n",
      "Train Epoch: 2 [1000/3053 (32%)]\tLoss: 0.042669\n",
      "Train Epoch: 2 [2000/3053 (65%)]\tLoss: 0.054727\n",
      "Train Epoch: 2 [1590/3053 (97%)]\tLoss: 0.108394\n",
      "Train Epoch: 3 [0/3053 (0%)]\tLoss: 0.155410\n",
      "Train Epoch: 3 [1000/3053 (32%)]\tLoss: 0.057492\n",
      "Train Epoch: 3 [2000/3053 (65%)]\tLoss: 0.032680\n",
      "Train Epoch: 3 [1590/3053 (97%)]\tLoss: 0.075457\n",
      "Train Epoch: 4 [0/3053 (0%)]\tLoss: 0.079025\n",
      "Train Epoch: 4 [1000/3053 (32%)]\tLoss: 0.062284\n",
      "Train Epoch: 4 [2000/3053 (65%)]\tLoss: 0.105622\n",
      "Train Epoch: 4 [1590/3053 (97%)]\tLoss: 0.089964\n",
      "Train Epoch: 5 [0/3053 (0%)]\tLoss: 0.053478\n",
      "Train Epoch: 5 [1000/3053 (32%)]\tLoss: 0.067682\n",
      "Train Epoch: 5 [2000/3053 (65%)]\tLoss: 0.072078\n",
      "Train Epoch: 5 [1590/3053 (97%)]\tLoss: 0.052600\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/9145 (0%)]\tLoss: 0.285398\n",
      "Train Epoch: 1 [1000/9145 (11%)]\tLoss: 0.339331\n",
      "Train Epoch: 1 [2000/9145 (22%)]\tLoss: 0.192485\n",
      "Train Epoch: 1 [3000/9145 (33%)]\tLoss: 0.221596\n",
      "Train Epoch: 1 [4000/9145 (43%)]\tLoss: 0.153446\n",
      "Train Epoch: 1 [5000/9145 (54%)]\tLoss: 0.215011\n",
      "Train Epoch: 1 [6000/9145 (65%)]\tLoss: 0.304983\n",
      "Train Epoch: 1 [7000/9145 (76%)]\tLoss: 0.238883\n",
      "Train Epoch: 1 [8000/9145 (87%)]\tLoss: 0.173103\n",
      "Train Epoch: 1 [9000/9145 (98%)]\tLoss: 0.266422\n",
      "Train Epoch: 2 [0/9145 (0%)]\tLoss: 0.143678\n",
      "Train Epoch: 2 [1000/9145 (11%)]\tLoss: 0.131407\n",
      "Train Epoch: 2 [2000/9145 (22%)]\tLoss: 0.188119\n",
      "Train Epoch: 2 [3000/9145 (33%)]\tLoss: 0.225045\n",
      "Train Epoch: 2 [4000/9145 (43%)]\tLoss: 0.246838\n",
      "Train Epoch: 2 [5000/9145 (54%)]\tLoss: 0.305483\n",
      "Train Epoch: 2 [6000/9145 (65%)]\tLoss: 0.255950\n",
      "Train Epoch: 2 [7000/9145 (76%)]\tLoss: 0.172295\n",
      "Train Epoch: 2 [8000/9145 (87%)]\tLoss: 0.233405\n",
      "Train Epoch: 2 [9000/9145 (98%)]\tLoss: 0.216453\n",
      "Train Epoch: 3 [0/9145 (0%)]\tLoss: 0.199665\n",
      "Train Epoch: 3 [1000/9145 (11%)]\tLoss: 0.169718\n",
      "Train Epoch: 3 [2000/9145 (22%)]\tLoss: 0.318081\n",
      "Train Epoch: 3 [3000/9145 (33%)]\tLoss: 0.131175\n",
      "Train Epoch: 3 [4000/9145 (43%)]\tLoss: 0.282544\n",
      "Train Epoch: 3 [5000/9145 (54%)]\tLoss: 0.254635\n",
      "Train Epoch: 3 [6000/9145 (65%)]\tLoss: 0.316558\n",
      "Train Epoch: 3 [7000/9145 (76%)]\tLoss: 0.271250\n",
      "Train Epoch: 3 [8000/9145 (87%)]\tLoss: 0.168325\n",
      "Train Epoch: 3 [9000/9145 (98%)]\tLoss: 0.117342\n",
      "Train Epoch: 4 [0/9145 (0%)]\tLoss: 0.175723\n",
      "Train Epoch: 4 [1000/9145 (11%)]\tLoss: 0.135622\n",
      "Train Epoch: 4 [2000/9145 (22%)]\tLoss: 0.227762\n",
      "Train Epoch: 4 [3000/9145 (33%)]\tLoss: 0.160612\n",
      "Train Epoch: 4 [4000/9145 (43%)]\tLoss: 0.227396\n",
      "Train Epoch: 4 [5000/9145 (54%)]\tLoss: 0.148543\n",
      "Train Epoch: 4 [6000/9145 (65%)]\tLoss: 0.207319\n",
      "Train Epoch: 4 [7000/9145 (76%)]\tLoss: 0.161121\n",
      "Train Epoch: 4 [8000/9145 (87%)]\tLoss: 0.196752\n",
      "Train Epoch: 4 [9000/9145 (98%)]\tLoss: 0.162527\n",
      "Train Epoch: 5 [0/9145 (0%)]\tLoss: 0.171260\n",
      "Train Epoch: 5 [1000/9145 (11%)]\tLoss: 0.227260\n",
      "Train Epoch: 5 [2000/9145 (22%)]\tLoss: 0.188254\n",
      "Train Epoch: 5 [3000/9145 (33%)]\tLoss: 0.203063\n",
      "Train Epoch: 5 [4000/9145 (43%)]\tLoss: 0.178580\n",
      "Train Epoch: 5 [5000/9145 (54%)]\tLoss: 0.209737\n",
      "Train Epoch: 5 [6000/9145 (65%)]\tLoss: 0.243598\n",
      "Train Epoch: 5 [7000/9145 (76%)]\tLoss: 0.139585\n",
      "Train Epoch: 5 [8000/9145 (87%)]\tLoss: 0.194339\n",
      "Train Epoch: 5 [9000/9145 (98%)]\tLoss: 0.157003\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3021 (0%)]\tLoss: 0.198731\n",
      "Train Epoch: 1 [1000/3021 (32%)]\tLoss: 0.228106\n",
      "Train Epoch: 1 [2000/3021 (65%)]\tLoss: 0.195271\n",
      "Train Epoch: 1 [630/3021 (97%)]\tLoss: 0.129081\n",
      "Train Epoch: 2 [0/3021 (0%)]\tLoss: 0.091436\n",
      "Train Epoch: 2 [1000/3021 (32%)]\tLoss: 0.095906\n",
      "Train Epoch: 2 [2000/3021 (65%)]\tLoss: 0.122430\n",
      "Train Epoch: 2 [630/3021 (97%)]\tLoss: 0.130792\n",
      "Train Epoch: 3 [0/3021 (0%)]\tLoss: 0.161090\n",
      "Train Epoch: 3 [1000/3021 (32%)]\tLoss: 0.095481\n",
      "Train Epoch: 3 [2000/3021 (65%)]\tLoss: 0.096457\n",
      "Train Epoch: 3 [630/3021 (97%)]\tLoss: 0.357207\n",
      "Train Epoch: 4 [0/3021 (0%)]\tLoss: 0.109416\n",
      "Train Epoch: 4 [1000/3021 (32%)]\tLoss: 0.171064\n",
      "Train Epoch: 4 [2000/3021 (65%)]\tLoss: 0.138258\n",
      "Train Epoch: 4 [630/3021 (97%)]\tLoss: 0.163080\n",
      "Train Epoch: 5 [0/3021 (0%)]\tLoss: 0.207701\n",
      "Train Epoch: 5 [1000/3021 (32%)]\tLoss: 0.129943\n",
      "Train Epoch: 5 [2000/3021 (65%)]\tLoss: 0.170595\n",
      "Train Epoch: 5 [630/3021 (97%)]\tLoss: 0.078881\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/7953 (0%)]\tLoss: 0.356595\n",
      "Train Epoch: 1 [1000/7953 (12%)]\tLoss: 0.254706\n",
      "Train Epoch: 1 [2000/7953 (25%)]\tLoss: 0.336970\n",
      "Train Epoch: 1 [3000/7953 (38%)]\tLoss: 0.260661\n",
      "Train Epoch: 1 [4000/7953 (50%)]\tLoss: 0.379814\n",
      "Train Epoch: 1 [5000/7953 (62%)]\tLoss: 0.432893\n",
      "Train Epoch: 1 [6000/7953 (75%)]\tLoss: 0.387948\n",
      "Train Epoch: 1 [7000/7953 (88%)]\tLoss: 0.361548\n",
      "Train Epoch: 2 [0/7953 (0%)]\tLoss: 0.222075\n",
      "Train Epoch: 2 [1000/7953 (12%)]\tLoss: 0.280828\n",
      "Train Epoch: 2 [2000/7953 (25%)]\tLoss: 0.361767\n",
      "Train Epoch: 2 [3000/7953 (38%)]\tLoss: 0.371765\n",
      "Train Epoch: 2 [4000/7953 (50%)]\tLoss: 0.250344\n",
      "Train Epoch: 2 [5000/7953 (62%)]\tLoss: 0.422633\n",
      "Train Epoch: 2 [6000/7953 (75%)]\tLoss: 0.375261\n",
      "Train Epoch: 2 [7000/7953 (88%)]\tLoss: 0.361123\n",
      "Train Epoch: 3 [0/7953 (0%)]\tLoss: 0.319443\n",
      "Train Epoch: 3 [1000/7953 (12%)]\tLoss: 0.253103\n",
      "Train Epoch: 3 [2000/7953 (25%)]\tLoss: 0.339912\n",
      "Train Epoch: 3 [3000/7953 (38%)]\tLoss: 0.403447\n",
      "Train Epoch: 3 [4000/7953 (50%)]\tLoss: 0.344826\n",
      "Train Epoch: 3 [5000/7953 (62%)]\tLoss: 0.374120\n",
      "Train Epoch: 3 [6000/7953 (75%)]\tLoss: 0.361916\n",
      "Train Epoch: 3 [7000/7953 (88%)]\tLoss: 0.310519\n",
      "Train Epoch: 4 [0/7953 (0%)]\tLoss: 0.384222\n",
      "Train Epoch: 4 [1000/7953 (12%)]\tLoss: 0.357908\n",
      "Train Epoch: 4 [2000/7953 (25%)]\tLoss: 0.400255\n",
      "Train Epoch: 4 [3000/7953 (38%)]\tLoss: 0.262145\n",
      "Train Epoch: 4 [4000/7953 (50%)]\tLoss: 0.281558\n",
      "Train Epoch: 4 [5000/7953 (62%)]\tLoss: 0.248413\n",
      "Train Epoch: 4 [6000/7953 (75%)]\tLoss: 0.267041\n",
      "Train Epoch: 4 [7000/7953 (88%)]\tLoss: 0.184893\n",
      "Train Epoch: 5 [0/7953 (0%)]\tLoss: 0.264441\n",
      "Train Epoch: 5 [1000/7953 (12%)]\tLoss: 0.351018\n",
      "Train Epoch: 5 [2000/7953 (25%)]\tLoss: 0.195254\n",
      "Train Epoch: 5 [3000/7953 (38%)]\tLoss: 0.325198\n",
      "Train Epoch: 5 [4000/7953 (50%)]\tLoss: 0.359466\n",
      "Train Epoch: 5 [5000/7953 (62%)]\tLoss: 0.226414\n",
      "Train Epoch: 5 [6000/7953 (75%)]\tLoss: 0.372445\n",
      "Train Epoch: 5 [7000/7953 (88%)]\tLoss: 0.246229\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/10012 (0%)]\tLoss: 0.188855\n",
      "Train Epoch: 1 [1000/10012 (10%)]\tLoss: 0.112432\n",
      "Train Epoch: 1 [2000/10012 (20%)]\tLoss: 0.095897\n",
      "Train Epoch: 1 [3000/10012 (30%)]\tLoss: 0.197038\n",
      "Train Epoch: 1 [4000/10012 (40%)]\tLoss: 0.108804\n",
      "Train Epoch: 1 [5000/10012 (50%)]\tLoss: 0.042998\n",
      "Train Epoch: 1 [6000/10012 (59%)]\tLoss: 0.143066\n",
      "Train Epoch: 1 [7000/10012 (69%)]\tLoss: 0.065527\n",
      "Train Epoch: 1 [8000/10012 (79%)]\tLoss: 0.074700\n",
      "Train Epoch: 1 [9000/10012 (89%)]\tLoss: 0.170623\n",
      "Train Epoch: 1 [1200/10012 (99%)]\tLoss: 0.009124\n",
      "Train Epoch: 2 [0/10012 (0%)]\tLoss: 0.136093\n",
      "Train Epoch: 2 [1000/10012 (10%)]\tLoss: 0.160985\n",
      "Train Epoch: 2 [2000/10012 (20%)]\tLoss: 0.116704\n",
      "Train Epoch: 2 [3000/10012 (30%)]\tLoss: 0.083962\n",
      "Train Epoch: 2 [4000/10012 (40%)]\tLoss: 0.154442\n",
      "Train Epoch: 2 [5000/10012 (50%)]\tLoss: 0.044745\n",
      "Train Epoch: 2 [6000/10012 (59%)]\tLoss: 0.155976\n",
      "Train Epoch: 2 [7000/10012 (69%)]\tLoss: 0.126217\n",
      "Train Epoch: 2 [8000/10012 (79%)]\tLoss: 0.110134\n",
      "Train Epoch: 2 [9000/10012 (89%)]\tLoss: 0.095337\n",
      "Train Epoch: 2 [1200/10012 (99%)]\tLoss: 0.046339\n",
      "Train Epoch: 3 [0/10012 (0%)]\tLoss: 0.067192\n",
      "Train Epoch: 3 [1000/10012 (10%)]\tLoss: 0.074288\n",
      "Train Epoch: 3 [2000/10012 (20%)]\tLoss: 0.082533\n",
      "Train Epoch: 3 [3000/10012 (30%)]\tLoss: 0.112774\n",
      "Train Epoch: 3 [4000/10012 (40%)]\tLoss: 0.123680\n",
      "Train Epoch: 3 [5000/10012 (50%)]\tLoss: 0.168273\n",
      "Train Epoch: 3 [6000/10012 (59%)]\tLoss: 0.073545\n",
      "Train Epoch: 3 [7000/10012 (69%)]\tLoss: 0.072152\n",
      "Train Epoch: 3 [8000/10012 (79%)]\tLoss: 0.094990\n",
      "Train Epoch: 3 [9000/10012 (89%)]\tLoss: 0.142965\n",
      "Train Epoch: 3 [1200/10012 (99%)]\tLoss: 0.041394\n",
      "Train Epoch: 4 [0/10012 (0%)]\tLoss: 0.101720\n",
      "Train Epoch: 4 [1000/10012 (10%)]\tLoss: 0.077480\n",
      "Train Epoch: 4 [2000/10012 (20%)]\tLoss: 0.090233\n",
      "Train Epoch: 4 [3000/10012 (30%)]\tLoss: 0.060947\n",
      "Train Epoch: 4 [4000/10012 (40%)]\tLoss: 0.089501\n",
      "Train Epoch: 4 [5000/10012 (50%)]\tLoss: 0.040193\n",
      "Train Epoch: 4 [6000/10012 (59%)]\tLoss: 0.069800\n",
      "Train Epoch: 4 [7000/10012 (69%)]\tLoss: 0.063425\n",
      "Train Epoch: 4 [8000/10012 (79%)]\tLoss: 0.048211\n",
      "Train Epoch: 4 [9000/10012 (89%)]\tLoss: 0.086311\n",
      "Train Epoch: 4 [1200/10012 (99%)]\tLoss: 0.059546\n",
      "Train Epoch: 5 [0/10012 (0%)]\tLoss: 0.058425\n",
      "Train Epoch: 5 [1000/10012 (10%)]\tLoss: 0.135767\n",
      "Train Epoch: 5 [2000/10012 (20%)]\tLoss: 0.111550\n",
      "Train Epoch: 5 [3000/10012 (30%)]\tLoss: 0.035316\n",
      "Train Epoch: 5 [4000/10012 (40%)]\tLoss: 0.097191\n",
      "Train Epoch: 5 [5000/10012 (50%)]\tLoss: 0.176809\n",
      "Train Epoch: 5 [6000/10012 (59%)]\tLoss: 0.076124\n",
      "Train Epoch: 5 [7000/10012 (69%)]\tLoss: 0.072522\n",
      "Train Epoch: 5 [8000/10012 (79%)]\tLoss: 0.072301\n",
      "Train Epoch: 5 [9000/10012 (89%)]\tLoss: 0.082478\n",
      "Train Epoch: 5 [1200/10012 (99%)]\tLoss: 0.090948\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "8\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.6193, Accuracy: 8687/10000 (87%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/7731 (0%)]\tLoss: 0.381633\n",
      "Train Epoch: 1 [1000/7731 (13%)]\tLoss: 0.175849\n",
      "Train Epoch: 1 [2000/7731 (26%)]\tLoss: 0.148260\n",
      "Train Epoch: 1 [3000/7731 (38%)]\tLoss: 0.111002\n",
      "Train Epoch: 1 [4000/7731 (51%)]\tLoss: 0.075604\n",
      "Train Epoch: 1 [5000/7731 (64%)]\tLoss: 0.197001\n",
      "Train Epoch: 1 [6000/7731 (77%)]\tLoss: 0.155640\n",
      "Train Epoch: 1 [7000/7731 (90%)]\tLoss: 0.193906\n",
      "Train Epoch: 2 [0/7731 (0%)]\tLoss: 0.081468\n",
      "Train Epoch: 2 [1000/7731 (13%)]\tLoss: 0.171392\n",
      "Train Epoch: 2 [2000/7731 (26%)]\tLoss: 0.233510\n",
      "Train Epoch: 2 [3000/7731 (38%)]\tLoss: 0.239794\n",
      "Train Epoch: 2 [4000/7731 (51%)]\tLoss: 0.108315\n",
      "Train Epoch: 2 [5000/7731 (64%)]\tLoss: 0.185075\n",
      "Train Epoch: 2 [6000/7731 (77%)]\tLoss: 0.119009\n",
      "Train Epoch: 2 [7000/7731 (90%)]\tLoss: 0.091861\n",
      "Train Epoch: 3 [0/7731 (0%)]\tLoss: 0.083222\n",
      "Train Epoch: 3 [1000/7731 (13%)]\tLoss: 0.147212\n",
      "Train Epoch: 3 [2000/7731 (26%)]\tLoss: 0.146064\n",
      "Train Epoch: 3 [3000/7731 (38%)]\tLoss: 0.249140\n",
      "Train Epoch: 3 [4000/7731 (51%)]\tLoss: 0.210381\n",
      "Train Epoch: 3 [5000/7731 (64%)]\tLoss: 0.117854\n",
      "Train Epoch: 3 [6000/7731 (77%)]\tLoss: 0.124049\n",
      "Train Epoch: 3 [7000/7731 (90%)]\tLoss: 0.155931\n",
      "Train Epoch: 4 [0/7731 (0%)]\tLoss: 0.144389\n",
      "Train Epoch: 4 [1000/7731 (13%)]\tLoss: 0.097143\n",
      "Train Epoch: 4 [2000/7731 (26%)]\tLoss: 0.241013\n",
      "Train Epoch: 4 [3000/7731 (38%)]\tLoss: 0.139375\n",
      "Train Epoch: 4 [4000/7731 (51%)]\tLoss: 0.117287\n",
      "Train Epoch: 4 [5000/7731 (64%)]\tLoss: 0.200850\n",
      "Train Epoch: 4 [6000/7731 (77%)]\tLoss: 0.113546\n",
      "Train Epoch: 4 [7000/7731 (90%)]\tLoss: 0.148570\n",
      "Train Epoch: 5 [0/7731 (0%)]\tLoss: 0.213358\n",
      "Train Epoch: 5 [1000/7731 (13%)]\tLoss: 0.105634\n",
      "Train Epoch: 5 [2000/7731 (26%)]\tLoss: 0.117136\n",
      "Train Epoch: 5 [3000/7731 (38%)]\tLoss: 0.096633\n",
      "Train Epoch: 5 [4000/7731 (51%)]\tLoss: 0.050154\n",
      "Train Epoch: 5 [5000/7731 (64%)]\tLoss: 0.112558\n",
      "Train Epoch: 5 [6000/7731 (77%)]\tLoss: 0.077935\n",
      "Train Epoch: 5 [7000/7731 (90%)]\tLoss: 0.161422\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11194 (0%)]\tLoss: 0.254037\n",
      "Train Epoch: 1 [1000/11194 (9%)]\tLoss: 0.165494\n",
      "Train Epoch: 1 [2000/11194 (18%)]\tLoss: 0.105362\n",
      "Train Epoch: 1 [3000/11194 (27%)]\tLoss: 0.212866\n",
      "Train Epoch: 1 [4000/11194 (36%)]\tLoss: 0.129565\n",
      "Train Epoch: 1 [5000/11194 (45%)]\tLoss: 0.181384\n",
      "Train Epoch: 1 [6000/11194 (54%)]\tLoss: 0.141221\n",
      "Train Epoch: 1 [7000/11194 (62%)]\tLoss: 0.160519\n",
      "Train Epoch: 1 [8000/11194 (71%)]\tLoss: 0.095118\n",
      "Train Epoch: 1 [9000/11194 (80%)]\tLoss: 0.199041\n",
      "Train Epoch: 1 [10000/11194 (89%)]\tLoss: 0.108246\n",
      "Train Epoch: 1 [11000/11194 (98%)]\tLoss: 0.244381\n",
      "Train Epoch: 2 [0/11194 (0%)]\tLoss: 0.153878\n",
      "Train Epoch: 2 [1000/11194 (9%)]\tLoss: 0.207823\n",
      "Train Epoch: 2 [2000/11194 (18%)]\tLoss: 0.285070\n",
      "Train Epoch: 2 [3000/11194 (27%)]\tLoss: 0.160234\n",
      "Train Epoch: 2 [4000/11194 (36%)]\tLoss: 0.156450\n",
      "Train Epoch: 2 [5000/11194 (45%)]\tLoss: 0.235973\n",
      "Train Epoch: 2 [6000/11194 (54%)]\tLoss: 0.102768\n",
      "Train Epoch: 2 [7000/11194 (62%)]\tLoss: 0.150629\n",
      "Train Epoch: 2 [8000/11194 (71%)]\tLoss: 0.145385\n",
      "Train Epoch: 2 [9000/11194 (80%)]\tLoss: 0.170054\n",
      "Train Epoch: 2 [10000/11194 (89%)]\tLoss: 0.113964\n",
      "Train Epoch: 2 [11000/11194 (98%)]\tLoss: 0.077990\n",
      "Train Epoch: 3 [0/11194 (0%)]\tLoss: 0.101479\n",
      "Train Epoch: 3 [1000/11194 (9%)]\tLoss: 0.092690\n",
      "Train Epoch: 3 [2000/11194 (18%)]\tLoss: 0.248416\n",
      "Train Epoch: 3 [3000/11194 (27%)]\tLoss: 0.092765\n",
      "Train Epoch: 3 [4000/11194 (36%)]\tLoss: 0.165210\n",
      "Train Epoch: 3 [5000/11194 (45%)]\tLoss: 0.162315\n",
      "Train Epoch: 3 [6000/11194 (54%)]\tLoss: 0.087479\n",
      "Train Epoch: 3 [7000/11194 (62%)]\tLoss: 0.136263\n",
      "Train Epoch: 3 [8000/11194 (71%)]\tLoss: 0.114963\n",
      "Train Epoch: 3 [9000/11194 (80%)]\tLoss: 0.098766\n",
      "Train Epoch: 3 [10000/11194 (89%)]\tLoss: 0.172939\n",
      "Train Epoch: 3 [11000/11194 (98%)]\tLoss: 0.180581\n",
      "Train Epoch: 4 [0/11194 (0%)]\tLoss: 0.100351\n",
      "Train Epoch: 4 [1000/11194 (9%)]\tLoss: 0.116442\n",
      "Train Epoch: 4 [2000/11194 (18%)]\tLoss: 0.215173\n",
      "Train Epoch: 4 [3000/11194 (27%)]\tLoss: 0.181386\n",
      "Train Epoch: 4 [4000/11194 (36%)]\tLoss: 0.106732\n",
      "Train Epoch: 4 [5000/11194 (45%)]\tLoss: 0.111637\n",
      "Train Epoch: 4 [6000/11194 (54%)]\tLoss: 0.201858\n",
      "Train Epoch: 4 [7000/11194 (62%)]\tLoss: 0.225171\n",
      "Train Epoch: 4 [8000/11194 (71%)]\tLoss: 0.124374\n",
      "Train Epoch: 4 [9000/11194 (80%)]\tLoss: 0.129028\n",
      "Train Epoch: 4 [10000/11194 (89%)]\tLoss: 0.200868\n",
      "Train Epoch: 4 [11000/11194 (98%)]\tLoss: 0.121276\n",
      "Train Epoch: 5 [0/11194 (0%)]\tLoss: 0.166221\n",
      "Train Epoch: 5 [1000/11194 (9%)]\tLoss: 0.094547\n",
      "Train Epoch: 5 [2000/11194 (18%)]\tLoss: 0.199212\n",
      "Train Epoch: 5 [3000/11194 (27%)]\tLoss: 0.099453\n",
      "Train Epoch: 5 [4000/11194 (36%)]\tLoss: 0.151680\n",
      "Train Epoch: 5 [5000/11194 (45%)]\tLoss: 0.122778\n",
      "Train Epoch: 5 [6000/11194 (54%)]\tLoss: 0.160683\n",
      "Train Epoch: 5 [7000/11194 (62%)]\tLoss: 0.117160\n",
      "Train Epoch: 5 [8000/11194 (71%)]\tLoss: 0.120368\n",
      "Train Epoch: 5 [9000/11194 (80%)]\tLoss: 0.130971\n",
      "Train Epoch: 5 [10000/11194 (89%)]\tLoss: 0.175294\n",
      "Train Epoch: 5 [11000/11194 (98%)]\tLoss: 0.103165\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/7891 (0%)]\tLoss: 0.213230\n",
      "Train Epoch: 1 [1000/7891 (13%)]\tLoss: 0.091149\n",
      "Train Epoch: 1 [2000/7891 (25%)]\tLoss: 0.144196\n",
      "Train Epoch: 1 [3000/7891 (38%)]\tLoss: 0.092990\n",
      "Train Epoch: 1 [4000/7891 (51%)]\tLoss: 0.122255\n",
      "Train Epoch: 1 [5000/7891 (63%)]\tLoss: 0.110165\n",
      "Train Epoch: 1 [6000/7891 (76%)]\tLoss: 0.127047\n",
      "Train Epoch: 1 [7000/7891 (89%)]\tLoss: 0.125195\n",
      "Train Epoch: 2 [0/7891 (0%)]\tLoss: 0.129780\n",
      "Train Epoch: 2 [1000/7891 (13%)]\tLoss: 0.059553\n",
      "Train Epoch: 2 [2000/7891 (25%)]\tLoss: 0.129415\n",
      "Train Epoch: 2 [3000/7891 (38%)]\tLoss: 0.065613\n",
      "Train Epoch: 2 [4000/7891 (51%)]\tLoss: 0.136167\n",
      "Train Epoch: 2 [5000/7891 (63%)]\tLoss: 0.154384\n",
      "Train Epoch: 2 [6000/7891 (76%)]\tLoss: 0.165722\n",
      "Train Epoch: 2 [7000/7891 (89%)]\tLoss: 0.116131\n",
      "Train Epoch: 3 [0/7891 (0%)]\tLoss: 0.083687\n",
      "Train Epoch: 3 [1000/7891 (13%)]\tLoss: 0.089867\n",
      "Train Epoch: 3 [2000/7891 (25%)]\tLoss: 0.090697\n",
      "Train Epoch: 3 [3000/7891 (38%)]\tLoss: 0.060518\n",
      "Train Epoch: 3 [4000/7891 (51%)]\tLoss: 0.071031\n",
      "Train Epoch: 3 [5000/7891 (63%)]\tLoss: 0.161531\n",
      "Train Epoch: 3 [6000/7891 (76%)]\tLoss: 0.151491\n",
      "Train Epoch: 3 [7000/7891 (89%)]\tLoss: 0.094350\n",
      "Train Epoch: 4 [0/7891 (0%)]\tLoss: 0.063066\n",
      "Train Epoch: 4 [1000/7891 (13%)]\tLoss: 0.154789\n",
      "Train Epoch: 4 [2000/7891 (25%)]\tLoss: 0.074132\n",
      "Train Epoch: 4 [3000/7891 (38%)]\tLoss: 0.108950\n",
      "Train Epoch: 4 [4000/7891 (51%)]\tLoss: 0.078367\n",
      "Train Epoch: 4 [5000/7891 (63%)]\tLoss: 0.106019\n",
      "Train Epoch: 4 [6000/7891 (76%)]\tLoss: 0.119975\n",
      "Train Epoch: 4 [7000/7891 (89%)]\tLoss: 0.072133\n",
      "Train Epoch: 5 [0/7891 (0%)]\tLoss: 0.091063\n",
      "Train Epoch: 5 [1000/7891 (13%)]\tLoss: 0.076763\n",
      "Train Epoch: 5 [2000/7891 (25%)]\tLoss: 0.093342\n",
      "Train Epoch: 5 [3000/7891 (38%)]\tLoss: 0.035461\n",
      "Train Epoch: 5 [4000/7891 (51%)]\tLoss: 0.115030\n",
      "Train Epoch: 5 [5000/7891 (63%)]\tLoss: 0.073980\n",
      "Train Epoch: 5 [6000/7891 (76%)]\tLoss: 0.079137\n",
      "Train Epoch: 5 [7000/7891 (89%)]\tLoss: 0.092883\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/3053 (0%)]\tLoss: 0.183794\n",
      "Train Epoch: 1 [1000/3053 (32%)]\tLoss: 0.170100\n",
      "Train Epoch: 1 [2000/3053 (65%)]\tLoss: 0.100664\n",
      "Train Epoch: 1 [1590/3053 (97%)]\tLoss: 0.045242\n",
      "Train Epoch: 2 [0/3053 (0%)]\tLoss: 0.068372\n",
      "Train Epoch: 2 [1000/3053 (32%)]\tLoss: 0.094495\n",
      "Train Epoch: 2 [2000/3053 (65%)]\tLoss: 0.110775\n",
      "Train Epoch: 2 [1590/3053 (97%)]\tLoss: 0.104212\n",
      "Train Epoch: 3 [0/3053 (0%)]\tLoss: 0.069763\n",
      "Train Epoch: 3 [1000/3053 (32%)]\tLoss: 0.100873\n",
      "Train Epoch: 3 [2000/3053 (65%)]\tLoss: 0.077410\n",
      "Train Epoch: 3 [1590/3053 (97%)]\tLoss: 0.047521\n",
      "Train Epoch: 4 [0/3053 (0%)]\tLoss: 0.062044\n",
      "Train Epoch: 4 [1000/3053 (32%)]\tLoss: 0.047720\n",
      "Train Epoch: 4 [2000/3053 (65%)]\tLoss: 0.094164\n",
      "Train Epoch: 4 [1590/3053 (97%)]\tLoss: 0.104772\n",
      "Train Epoch: 5 [0/3053 (0%)]\tLoss: 0.049653\n",
      "Train Epoch: 5 [1000/3053 (32%)]\tLoss: 0.210150\n",
      "Train Epoch: 5 [2000/3053 (65%)]\tLoss: 0.085990\n",
      "Train Epoch: 5 [1590/3053 (97%)]\tLoss: 0.039651\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/9145 (0%)]\tLoss: 0.170334\n",
      "Train Epoch: 1 [1000/9145 (11%)]\tLoss: 0.277649\n",
      "Train Epoch: 1 [2000/9145 (22%)]\tLoss: 0.212491\n",
      "Train Epoch: 1 [3000/9145 (33%)]\tLoss: 0.146589\n",
      "Train Epoch: 1 [4000/9145 (43%)]\tLoss: 0.188346\n",
      "Train Epoch: 1 [5000/9145 (54%)]\tLoss: 0.249003\n",
      "Train Epoch: 1 [6000/9145 (65%)]\tLoss: 0.272058\n",
      "Train Epoch: 1 [7000/9145 (76%)]\tLoss: 0.220754\n",
      "Train Epoch: 1 [8000/9145 (87%)]\tLoss: 0.341577\n",
      "Train Epoch: 1 [9000/9145 (98%)]\tLoss: 0.185007\n",
      "Train Epoch: 2 [0/9145 (0%)]\tLoss: 0.186133\n",
      "Train Epoch: 2 [1000/9145 (11%)]\tLoss: 0.219388\n",
      "Train Epoch: 2 [2000/9145 (22%)]\tLoss: 0.202670\n",
      "Train Epoch: 2 [3000/9145 (33%)]\tLoss: 0.167927\n",
      "Train Epoch: 2 [4000/9145 (43%)]\tLoss: 0.228782\n",
      "Train Epoch: 2 [5000/9145 (54%)]\tLoss: 0.253184\n",
      "Train Epoch: 2 [6000/9145 (65%)]\tLoss: 0.299167\n",
      "Train Epoch: 2 [7000/9145 (76%)]\tLoss: 0.079999\n",
      "Train Epoch: 2 [8000/9145 (87%)]\tLoss: 0.368762\n",
      "Train Epoch: 2 [9000/9145 (98%)]\tLoss: 0.176766\n",
      "Train Epoch: 3 [0/9145 (0%)]\tLoss: 0.226967\n",
      "Train Epoch: 3 [1000/9145 (11%)]\tLoss: 0.237393\n",
      "Train Epoch: 3 [2000/9145 (22%)]\tLoss: 0.214719\n",
      "Train Epoch: 3 [3000/9145 (33%)]\tLoss: 0.173603\n",
      "Train Epoch: 3 [4000/9145 (43%)]\tLoss: 0.285725\n",
      "Train Epoch: 3 [5000/9145 (54%)]\tLoss: 0.201660\n",
      "Train Epoch: 3 [6000/9145 (65%)]\tLoss: 0.202522\n",
      "Train Epoch: 3 [7000/9145 (76%)]\tLoss: 0.144031\n",
      "Train Epoch: 3 [8000/9145 (87%)]\tLoss: 0.201343\n",
      "Train Epoch: 3 [9000/9145 (98%)]\tLoss: 0.174741\n",
      "Train Epoch: 4 [0/9145 (0%)]\tLoss: 0.134708\n",
      "Train Epoch: 4 [1000/9145 (11%)]\tLoss: 0.104557\n",
      "Train Epoch: 4 [2000/9145 (22%)]\tLoss: 0.156604\n",
      "Train Epoch: 4 [3000/9145 (33%)]\tLoss: 0.206963\n",
      "Train Epoch: 4 [4000/9145 (43%)]\tLoss: 0.143944\n",
      "Train Epoch: 4 [5000/9145 (54%)]\tLoss: 0.137605\n",
      "Train Epoch: 4 [6000/9145 (65%)]\tLoss: 0.189601\n",
      "Train Epoch: 4 [7000/9145 (76%)]\tLoss: 0.131495\n",
      "Train Epoch: 4 [8000/9145 (87%)]\tLoss: 0.318914\n",
      "Train Epoch: 4 [9000/9145 (98%)]\tLoss: 0.260293\n",
      "Train Epoch: 5 [0/9145 (0%)]\tLoss: 0.198383\n",
      "Train Epoch: 5 [1000/9145 (11%)]\tLoss: 0.096065\n",
      "Train Epoch: 5 [2000/9145 (22%)]\tLoss: 0.098186\n",
      "Train Epoch: 5 [3000/9145 (33%)]\tLoss: 0.155161\n",
      "Train Epoch: 5 [4000/9145 (43%)]\tLoss: 0.124661\n",
      "Train Epoch: 5 [5000/9145 (54%)]\tLoss: 0.214841\n",
      "Train Epoch: 5 [6000/9145 (65%)]\tLoss: 0.175477\n",
      "Train Epoch: 5 [7000/9145 (76%)]\tLoss: 0.137288\n",
      "Train Epoch: 5 [8000/9145 (87%)]\tLoss: 0.164645\n",
      "Train Epoch: 5 [9000/9145 (98%)]\tLoss: 0.234285\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3021 (0%)]\tLoss: 0.130443\n",
      "Train Epoch: 1 [1000/3021 (32%)]\tLoss: 0.186400\n",
      "Train Epoch: 1 [2000/3021 (65%)]\tLoss: 0.109022\n",
      "Train Epoch: 1 [630/3021 (97%)]\tLoss: 0.315106\n",
      "Train Epoch: 2 [0/3021 (0%)]\tLoss: 0.153792\n",
      "Train Epoch: 2 [1000/3021 (32%)]\tLoss: 0.108866\n",
      "Train Epoch: 2 [2000/3021 (65%)]\tLoss: 0.117127\n",
      "Train Epoch: 2 [630/3021 (97%)]\tLoss: 0.260059\n",
      "Train Epoch: 3 [0/3021 (0%)]\tLoss: 0.238287\n",
      "Train Epoch: 3 [1000/3021 (32%)]\tLoss: 0.112238\n",
      "Train Epoch: 3 [2000/3021 (65%)]\tLoss: 0.176267\n",
      "Train Epoch: 3 [630/3021 (97%)]\tLoss: 0.166174\n",
      "Train Epoch: 4 [0/3021 (0%)]\tLoss: 0.153502\n",
      "Train Epoch: 4 [1000/3021 (32%)]\tLoss: 0.097765\n",
      "Train Epoch: 4 [2000/3021 (65%)]\tLoss: 0.160751\n",
      "Train Epoch: 4 [630/3021 (97%)]\tLoss: 0.052084\n",
      "Train Epoch: 5 [0/3021 (0%)]\tLoss: 0.159877\n",
      "Train Epoch: 5 [1000/3021 (32%)]\tLoss: 0.171441\n",
      "Train Epoch: 5 [2000/3021 (65%)]\tLoss: 0.077014\n",
      "Train Epoch: 5 [630/3021 (97%)]\tLoss: 0.152339\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/7953 (0%)]\tLoss: 0.473334\n",
      "Train Epoch: 1 [1000/7953 (12%)]\tLoss: 0.359330\n",
      "Train Epoch: 1 [2000/7953 (25%)]\tLoss: 0.399976\n",
      "Train Epoch: 1 [3000/7953 (38%)]\tLoss: 0.303919\n",
      "Train Epoch: 1 [4000/7953 (50%)]\tLoss: 0.221645\n",
      "Train Epoch: 1 [5000/7953 (62%)]\tLoss: 0.250662\n",
      "Train Epoch: 1 [6000/7953 (75%)]\tLoss: 0.431096\n",
      "Train Epoch: 1 [7000/7953 (88%)]\tLoss: 0.355157\n",
      "Train Epoch: 2 [0/7953 (0%)]\tLoss: 0.309046\n",
      "Train Epoch: 2 [1000/7953 (12%)]\tLoss: 0.318354\n",
      "Train Epoch: 2 [2000/7953 (25%)]\tLoss: 0.227460\n",
      "Train Epoch: 2 [3000/7953 (38%)]\tLoss: 0.292522\n",
      "Train Epoch: 2 [4000/7953 (50%)]\tLoss: 0.297420\n",
      "Train Epoch: 2 [5000/7953 (62%)]\tLoss: 0.393250\n",
      "Train Epoch: 2 [6000/7953 (75%)]\tLoss: 0.135930\n",
      "Train Epoch: 2 [7000/7953 (88%)]\tLoss: 0.258419\n",
      "Train Epoch: 3 [0/7953 (0%)]\tLoss: 0.290800\n",
      "Train Epoch: 3 [1000/7953 (12%)]\tLoss: 0.277120\n",
      "Train Epoch: 3 [2000/7953 (25%)]\tLoss: 0.424740\n",
      "Train Epoch: 3 [3000/7953 (38%)]\tLoss: 0.405677\n",
      "Train Epoch: 3 [4000/7953 (50%)]\tLoss: 0.273959\n",
      "Train Epoch: 3 [5000/7953 (62%)]\tLoss: 0.251789\n",
      "Train Epoch: 3 [6000/7953 (75%)]\tLoss: 0.381792\n",
      "Train Epoch: 3 [7000/7953 (88%)]\tLoss: 0.337516\n",
      "Train Epoch: 4 [0/7953 (0%)]\tLoss: 0.260193\n",
      "Train Epoch: 4 [1000/7953 (12%)]\tLoss: 0.369154\n",
      "Train Epoch: 4 [2000/7953 (25%)]\tLoss: 0.275943\n",
      "Train Epoch: 4 [3000/7953 (38%)]\tLoss: 0.288947\n",
      "Train Epoch: 4 [4000/7953 (50%)]\tLoss: 0.410559\n",
      "Train Epoch: 4 [5000/7953 (62%)]\tLoss: 0.198498\n",
      "Train Epoch: 4 [6000/7953 (75%)]\tLoss: 0.401298\n",
      "Train Epoch: 4 [7000/7953 (88%)]\tLoss: 0.171079\n",
      "Train Epoch: 5 [0/7953 (0%)]\tLoss: 0.298702\n",
      "Train Epoch: 5 [1000/7953 (12%)]\tLoss: 0.345762\n",
      "Train Epoch: 5 [2000/7953 (25%)]\tLoss: 0.342612\n",
      "Train Epoch: 5 [3000/7953 (38%)]\tLoss: 0.321194\n",
      "Train Epoch: 5 [4000/7953 (50%)]\tLoss: 0.431798\n",
      "Train Epoch: 5 [5000/7953 (62%)]\tLoss: 0.169177\n",
      "Train Epoch: 5 [6000/7953 (75%)]\tLoss: 0.219689\n",
      "Train Epoch: 5 [7000/7953 (88%)]\tLoss: 0.231577\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/10012 (0%)]\tLoss: 0.176898\n",
      "Train Epoch: 1 [1000/10012 (10%)]\tLoss: 0.087470\n",
      "Train Epoch: 1 [2000/10012 (20%)]\tLoss: 0.115590\n",
      "Train Epoch: 1 [3000/10012 (30%)]\tLoss: 0.113660\n",
      "Train Epoch: 1 [4000/10012 (40%)]\tLoss: 0.082564\n",
      "Train Epoch: 1 [5000/10012 (50%)]\tLoss: 0.109822\n",
      "Train Epoch: 1 [6000/10012 (59%)]\tLoss: 0.094053\n",
      "Train Epoch: 1 [7000/10012 (69%)]\tLoss: 0.055693\n",
      "Train Epoch: 1 [8000/10012 (79%)]\tLoss: 0.142650\n",
      "Train Epoch: 1 [9000/10012 (89%)]\tLoss: 0.105894\n",
      "Train Epoch: 1 [1200/10012 (99%)]\tLoss: 0.007932\n",
      "Train Epoch: 2 [0/10012 (0%)]\tLoss: 0.091223\n",
      "Train Epoch: 2 [1000/10012 (10%)]\tLoss: 0.129497\n",
      "Train Epoch: 2 [2000/10012 (20%)]\tLoss: 0.117201\n",
      "Train Epoch: 2 [3000/10012 (30%)]\tLoss: 0.041536\n",
      "Train Epoch: 2 [4000/10012 (40%)]\tLoss: 0.031102\n",
      "Train Epoch: 2 [5000/10012 (50%)]\tLoss: 0.108556\n",
      "Train Epoch: 2 [6000/10012 (59%)]\tLoss: 0.044358\n",
      "Train Epoch: 2 [7000/10012 (69%)]\tLoss: 0.065250\n",
      "Train Epoch: 2 [8000/10012 (79%)]\tLoss: 0.082623\n",
      "Train Epoch: 2 [9000/10012 (89%)]\tLoss: 0.134563\n",
      "Train Epoch: 2 [1200/10012 (99%)]\tLoss: 0.170639\n",
      "Train Epoch: 3 [0/10012 (0%)]\tLoss: 0.221995\n",
      "Train Epoch: 3 [1000/10012 (10%)]\tLoss: 0.032186\n",
      "Train Epoch: 3 [2000/10012 (20%)]\tLoss: 0.077747\n",
      "Train Epoch: 3 [3000/10012 (30%)]\tLoss: 0.085333\n",
      "Train Epoch: 3 [4000/10012 (40%)]\tLoss: 0.089145\n",
      "Train Epoch: 3 [5000/10012 (50%)]\tLoss: 0.074258\n",
      "Train Epoch: 3 [6000/10012 (59%)]\tLoss: 0.127609\n",
      "Train Epoch: 3 [7000/10012 (69%)]\tLoss: 0.174739\n",
      "Train Epoch: 3 [8000/10012 (79%)]\tLoss: 0.154723\n",
      "Train Epoch: 3 [9000/10012 (89%)]\tLoss: 0.069503\n",
      "Train Epoch: 3 [1200/10012 (99%)]\tLoss: 0.133544\n",
      "Train Epoch: 4 [0/10012 (0%)]\tLoss: 0.163844\n",
      "Train Epoch: 4 [1000/10012 (10%)]\tLoss: 0.131953\n",
      "Train Epoch: 4 [2000/10012 (20%)]\tLoss: 0.072623\n",
      "Train Epoch: 4 [3000/10012 (30%)]\tLoss: 0.069260\n",
      "Train Epoch: 4 [4000/10012 (40%)]\tLoss: 0.100463\n",
      "Train Epoch: 4 [5000/10012 (50%)]\tLoss: 0.080412\n",
      "Train Epoch: 4 [6000/10012 (59%)]\tLoss: 0.148504\n",
      "Train Epoch: 4 [7000/10012 (69%)]\tLoss: 0.086743\n",
      "Train Epoch: 4 [8000/10012 (79%)]\tLoss: 0.086190\n",
      "Train Epoch: 4 [9000/10012 (89%)]\tLoss: 0.034127\n",
      "Train Epoch: 4 [1200/10012 (99%)]\tLoss: 0.144316\n",
      "Train Epoch: 5 [0/10012 (0%)]\tLoss: 0.140059\n",
      "Train Epoch: 5 [1000/10012 (10%)]\tLoss: 0.080925\n",
      "Train Epoch: 5 [2000/10012 (20%)]\tLoss: 0.131082\n",
      "Train Epoch: 5 [3000/10012 (30%)]\tLoss: 0.068802\n",
      "Train Epoch: 5 [4000/10012 (40%)]\tLoss: 0.094479\n",
      "Train Epoch: 5 [5000/10012 (50%)]\tLoss: 0.131604\n",
      "Train Epoch: 5 [6000/10012 (59%)]\tLoss: 0.057148\n",
      "Train Epoch: 5 [7000/10012 (69%)]\tLoss: 0.099374\n",
      "Train Epoch: 5 [8000/10012 (79%)]\tLoss: 0.060654\n",
      "Train Epoch: 5 [9000/10012 (89%)]\tLoss: 0.100314\n",
      "Train Epoch: 5 [1200/10012 (99%)]\tLoss: 0.060333\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "8\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.6120, Accuracy: 8690/10000 (87%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/7731 (0%)]\tLoss: 0.243093\n",
      "Train Epoch: 1 [1000/7731 (13%)]\tLoss: 0.197653\n",
      "Train Epoch: 1 [2000/7731 (26%)]\tLoss: 0.169970\n",
      "Train Epoch: 1 [3000/7731 (38%)]\tLoss: 0.169634\n",
      "Train Epoch: 1 [4000/7731 (51%)]\tLoss: 0.216077\n",
      "Train Epoch: 1 [5000/7731 (64%)]\tLoss: 0.300967\n",
      "Train Epoch: 1 [6000/7731 (77%)]\tLoss: 0.044871\n",
      "Train Epoch: 1 [7000/7731 (90%)]\tLoss: 0.036212\n",
      "Train Epoch: 2 [0/7731 (0%)]\tLoss: 0.128234\n",
      "Train Epoch: 2 [1000/7731 (13%)]\tLoss: 0.109195\n",
      "Train Epoch: 2 [2000/7731 (26%)]\tLoss: 0.182412\n",
      "Train Epoch: 2 [3000/7731 (38%)]\tLoss: 0.087291\n",
      "Train Epoch: 2 [4000/7731 (51%)]\tLoss: 0.091134\n",
      "Train Epoch: 2 [5000/7731 (64%)]\tLoss: 0.108173\n",
      "Train Epoch: 2 [6000/7731 (77%)]\tLoss: 0.159533\n",
      "Train Epoch: 2 [7000/7731 (90%)]\tLoss: 0.146038\n",
      "Train Epoch: 3 [0/7731 (0%)]\tLoss: 0.151980\n",
      "Train Epoch: 3 [1000/7731 (13%)]\tLoss: 0.139419\n",
      "Train Epoch: 3 [2000/7731 (26%)]\tLoss: 0.149972\n",
      "Train Epoch: 3 [3000/7731 (38%)]\tLoss: 0.149532\n",
      "Train Epoch: 3 [4000/7731 (51%)]\tLoss: 0.175138\n",
      "Train Epoch: 3 [5000/7731 (64%)]\tLoss: 0.078903\n",
      "Train Epoch: 3 [6000/7731 (77%)]\tLoss: 0.127902\n",
      "Train Epoch: 3 [7000/7731 (90%)]\tLoss: 0.139447\n",
      "Train Epoch: 4 [0/7731 (0%)]\tLoss: 0.071789\n",
      "Train Epoch: 4 [1000/7731 (13%)]\tLoss: 0.136922\n",
      "Train Epoch: 4 [2000/7731 (26%)]\tLoss: 0.119879\n",
      "Train Epoch: 4 [3000/7731 (38%)]\tLoss: 0.146294\n",
      "Train Epoch: 4 [4000/7731 (51%)]\tLoss: 0.105115\n",
      "Train Epoch: 4 [5000/7731 (64%)]\tLoss: 0.149580\n",
      "Train Epoch: 4 [6000/7731 (77%)]\tLoss: 0.111428\n",
      "Train Epoch: 4 [7000/7731 (90%)]\tLoss: 0.149465\n",
      "Train Epoch: 5 [0/7731 (0%)]\tLoss: 0.085024\n",
      "Train Epoch: 5 [1000/7731 (13%)]\tLoss: 0.080074\n",
      "Train Epoch: 5 [2000/7731 (26%)]\tLoss: 0.085791\n",
      "Train Epoch: 5 [3000/7731 (38%)]\tLoss: 0.195735\n",
      "Train Epoch: 5 [4000/7731 (51%)]\tLoss: 0.089409\n",
      "Train Epoch: 5 [5000/7731 (64%)]\tLoss: 0.103633\n",
      "Train Epoch: 5 [6000/7731 (77%)]\tLoss: 0.115327\n",
      "Train Epoch: 5 [7000/7731 (90%)]\tLoss: 0.091201\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11194 (0%)]\tLoss: 0.211884\n",
      "Train Epoch: 1 [1000/11194 (9%)]\tLoss: 0.156654\n",
      "Train Epoch: 1 [2000/11194 (18%)]\tLoss: 0.177730\n",
      "Train Epoch: 1 [3000/11194 (27%)]\tLoss: 0.223166\n",
      "Train Epoch: 1 [4000/11194 (36%)]\tLoss: 0.218819\n",
      "Train Epoch: 1 [5000/11194 (45%)]\tLoss: 0.229973\n",
      "Train Epoch: 1 [6000/11194 (54%)]\tLoss: 0.146228\n",
      "Train Epoch: 1 [7000/11194 (62%)]\tLoss: 0.084303\n",
      "Train Epoch: 1 [8000/11194 (71%)]\tLoss: 0.131979\n",
      "Train Epoch: 1 [9000/11194 (80%)]\tLoss: 0.187379\n",
      "Train Epoch: 1 [10000/11194 (89%)]\tLoss: 0.195859\n",
      "Train Epoch: 1 [11000/11194 (98%)]\tLoss: 0.193501\n",
      "Train Epoch: 2 [0/11194 (0%)]\tLoss: 0.221631\n",
      "Train Epoch: 2 [1000/11194 (9%)]\tLoss: 0.092474\n",
      "Train Epoch: 2 [2000/11194 (18%)]\tLoss: 0.096004\n",
      "Train Epoch: 2 [3000/11194 (27%)]\tLoss: 0.184749\n",
      "Train Epoch: 2 [4000/11194 (36%)]\tLoss: 0.125959\n",
      "Train Epoch: 2 [5000/11194 (45%)]\tLoss: 0.073628\n",
      "Train Epoch: 2 [6000/11194 (54%)]\tLoss: 0.166383\n",
      "Train Epoch: 2 [7000/11194 (62%)]\tLoss: 0.180970\n",
      "Train Epoch: 2 [8000/11194 (71%)]\tLoss: 0.124933\n",
      "Train Epoch: 2 [9000/11194 (80%)]\tLoss: 0.137574\n",
      "Train Epoch: 2 [10000/11194 (89%)]\tLoss: 0.124939\n",
      "Train Epoch: 2 [11000/11194 (98%)]\tLoss: 0.169762\n",
      "Train Epoch: 3 [0/11194 (0%)]\tLoss: 0.179935\n",
      "Train Epoch: 3 [1000/11194 (9%)]\tLoss: 0.186459\n",
      "Train Epoch: 3 [2000/11194 (18%)]\tLoss: 0.230628\n",
      "Train Epoch: 3 [3000/11194 (27%)]\tLoss: 0.079596\n",
      "Train Epoch: 3 [4000/11194 (36%)]\tLoss: 0.077713\n",
      "Train Epoch: 3 [5000/11194 (45%)]\tLoss: 0.078604\n",
      "Train Epoch: 3 [6000/11194 (54%)]\tLoss: 0.126664\n",
      "Train Epoch: 3 [7000/11194 (62%)]\tLoss: 0.107765\n",
      "Train Epoch: 3 [8000/11194 (71%)]\tLoss: 0.185701\n",
      "Train Epoch: 3 [9000/11194 (80%)]\tLoss: 0.113969\n",
      "Train Epoch: 3 [10000/11194 (89%)]\tLoss: 0.098441\n",
      "Train Epoch: 3 [11000/11194 (98%)]\tLoss: 0.191698\n",
      "Train Epoch: 4 [0/11194 (0%)]\tLoss: 0.053970\n",
      "Train Epoch: 4 [1000/11194 (9%)]\tLoss: 0.105379\n",
      "Train Epoch: 4 [2000/11194 (18%)]\tLoss: 0.156400\n",
      "Train Epoch: 4 [3000/11194 (27%)]\tLoss: 0.133762\n",
      "Train Epoch: 4 [4000/11194 (36%)]\tLoss: 0.194629\n",
      "Train Epoch: 4 [5000/11194 (45%)]\tLoss: 0.121757\n",
      "Train Epoch: 4 [6000/11194 (54%)]\tLoss: 0.142712\n",
      "Train Epoch: 4 [7000/11194 (62%)]\tLoss: 0.140522\n",
      "Train Epoch: 4 [8000/11194 (71%)]\tLoss: 0.252488\n",
      "Train Epoch: 4 [9000/11194 (80%)]\tLoss: 0.304422\n",
      "Train Epoch: 4 [10000/11194 (89%)]\tLoss: 0.129247\n",
      "Train Epoch: 4 [11000/11194 (98%)]\tLoss: 0.089330\n",
      "Train Epoch: 5 [0/11194 (0%)]\tLoss: 0.142685\n",
      "Train Epoch: 5 [1000/11194 (9%)]\tLoss: 0.121609\n",
      "Train Epoch: 5 [2000/11194 (18%)]\tLoss: 0.090384\n",
      "Train Epoch: 5 [3000/11194 (27%)]\tLoss: 0.161958\n",
      "Train Epoch: 5 [4000/11194 (36%)]\tLoss: 0.155342\n",
      "Train Epoch: 5 [5000/11194 (45%)]\tLoss: 0.087133\n",
      "Train Epoch: 5 [6000/11194 (54%)]\tLoss: 0.161793\n",
      "Train Epoch: 5 [7000/11194 (62%)]\tLoss: 0.094207\n",
      "Train Epoch: 5 [8000/11194 (71%)]\tLoss: 0.060079\n",
      "Train Epoch: 5 [9000/11194 (80%)]\tLoss: 0.123189\n",
      "Train Epoch: 5 [10000/11194 (89%)]\tLoss: 0.114868\n",
      "Train Epoch: 5 [11000/11194 (98%)]\tLoss: 0.134730\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/7891 (0%)]\tLoss: 0.170587\n",
      "Train Epoch: 1 [1000/7891 (13%)]\tLoss: 0.106610\n",
      "Train Epoch: 1 [2000/7891 (25%)]\tLoss: 0.177841\n",
      "Train Epoch: 1 [3000/7891 (38%)]\tLoss: 0.125897\n",
      "Train Epoch: 1 [4000/7891 (51%)]\tLoss: 0.117800\n",
      "Train Epoch: 1 [5000/7891 (63%)]\tLoss: 0.125262\n",
      "Train Epoch: 1 [6000/7891 (76%)]\tLoss: 0.098583\n",
      "Train Epoch: 1 [7000/7891 (89%)]\tLoss: 0.079821\n",
      "Train Epoch: 2 [0/7891 (0%)]\tLoss: 0.086127\n",
      "Train Epoch: 2 [1000/7891 (13%)]\tLoss: 0.063265\n",
      "Train Epoch: 2 [2000/7891 (25%)]\tLoss: 0.053444\n",
      "Train Epoch: 2 [3000/7891 (38%)]\tLoss: 0.194403\n",
      "Train Epoch: 2 [4000/7891 (51%)]\tLoss: 0.083944\n",
      "Train Epoch: 2 [5000/7891 (63%)]\tLoss: 0.087653\n",
      "Train Epoch: 2 [6000/7891 (76%)]\tLoss: 0.150216\n",
      "Train Epoch: 2 [7000/7891 (89%)]\tLoss: 0.108336\n",
      "Train Epoch: 3 [0/7891 (0%)]\tLoss: 0.056922\n",
      "Train Epoch: 3 [1000/7891 (13%)]\tLoss: 0.079975\n",
      "Train Epoch: 3 [2000/7891 (25%)]\tLoss: 0.105899\n",
      "Train Epoch: 3 [3000/7891 (38%)]\tLoss: 0.094617\n",
      "Train Epoch: 3 [4000/7891 (51%)]\tLoss: 0.075717\n",
      "Train Epoch: 3 [5000/7891 (63%)]\tLoss: 0.048528\n",
      "Train Epoch: 3 [6000/7891 (76%)]\tLoss: 0.085407\n",
      "Train Epoch: 3 [7000/7891 (89%)]\tLoss: 0.157180\n",
      "Train Epoch: 4 [0/7891 (0%)]\tLoss: 0.062082\n",
      "Train Epoch: 4 [1000/7891 (13%)]\tLoss: 0.145464\n",
      "Train Epoch: 4 [2000/7891 (25%)]\tLoss: 0.060435\n",
      "Train Epoch: 4 [3000/7891 (38%)]\tLoss: 0.141606\n",
      "Train Epoch: 4 [4000/7891 (51%)]\tLoss: 0.069567\n",
      "Train Epoch: 4 [5000/7891 (63%)]\tLoss: 0.083098\n",
      "Train Epoch: 4 [6000/7891 (76%)]\tLoss: 0.028523\n",
      "Train Epoch: 4 [7000/7891 (89%)]\tLoss: 0.046616\n",
      "Train Epoch: 5 [0/7891 (0%)]\tLoss: 0.038526\n",
      "Train Epoch: 5 [1000/7891 (13%)]\tLoss: 0.046870\n",
      "Train Epoch: 5 [2000/7891 (25%)]\tLoss: 0.159170\n",
      "Train Epoch: 5 [3000/7891 (38%)]\tLoss: 0.067972\n",
      "Train Epoch: 5 [4000/7891 (51%)]\tLoss: 0.080898\n",
      "Train Epoch: 5 [5000/7891 (63%)]\tLoss: 0.065688\n",
      "Train Epoch: 5 [6000/7891 (76%)]\tLoss: 0.049539\n",
      "Train Epoch: 5 [7000/7891 (89%)]\tLoss: 0.066097\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/3053 (0%)]\tLoss: 0.112653\n",
      "Train Epoch: 1 [1000/3053 (32%)]\tLoss: 0.077473\n",
      "Train Epoch: 1 [2000/3053 (65%)]\tLoss: 0.216270\n",
      "Train Epoch: 1 [1590/3053 (97%)]\tLoss: 0.113990\n",
      "Train Epoch: 2 [0/3053 (0%)]\tLoss: 0.097582\n",
      "Train Epoch: 2 [1000/3053 (32%)]\tLoss: 0.059439\n",
      "Train Epoch: 2 [2000/3053 (65%)]\tLoss: 0.049479\n",
      "Train Epoch: 2 [1590/3053 (97%)]\tLoss: 0.139857\n",
      "Train Epoch: 3 [0/3053 (0%)]\tLoss: 0.078748\n",
      "Train Epoch: 3 [1000/3053 (32%)]\tLoss: 0.046179\n",
      "Train Epoch: 3 [2000/3053 (65%)]\tLoss: 0.120585\n",
      "Train Epoch: 3 [1590/3053 (97%)]\tLoss: 0.150384\n",
      "Train Epoch: 4 [0/3053 (0%)]\tLoss: 0.089111\n",
      "Train Epoch: 4 [1000/3053 (32%)]\tLoss: 0.081729\n",
      "Train Epoch: 4 [2000/3053 (65%)]\tLoss: 0.081614\n",
      "Train Epoch: 4 [1590/3053 (97%)]\tLoss: 0.021773\n",
      "Train Epoch: 5 [0/3053 (0%)]\tLoss: 0.051631\n",
      "Train Epoch: 5 [1000/3053 (32%)]\tLoss: 0.070638\n",
      "Train Epoch: 5 [2000/3053 (65%)]\tLoss: 0.032029\n",
      "Train Epoch: 5 [1590/3053 (97%)]\tLoss: 0.014520\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/9145 (0%)]\tLoss: 0.209795\n",
      "Train Epoch: 1 [1000/9145 (11%)]\tLoss: 0.354922\n",
      "Train Epoch: 1 [2000/9145 (22%)]\tLoss: 0.180292\n",
      "Train Epoch: 1 [3000/9145 (33%)]\tLoss: 0.161407\n",
      "Train Epoch: 1 [4000/9145 (43%)]\tLoss: 0.271124\n",
      "Train Epoch: 1 [5000/9145 (54%)]\tLoss: 0.193337\n",
      "Train Epoch: 1 [6000/9145 (65%)]\tLoss: 0.192123\n",
      "Train Epoch: 1 [7000/9145 (76%)]\tLoss: 0.155177\n",
      "Train Epoch: 1 [8000/9145 (87%)]\tLoss: 0.162792\n",
      "Train Epoch: 1 [9000/9145 (98%)]\tLoss: 0.226549\n",
      "Train Epoch: 2 [0/9145 (0%)]\tLoss: 0.232072\n",
      "Train Epoch: 2 [1000/9145 (11%)]\tLoss: 0.096973\n",
      "Train Epoch: 2 [2000/9145 (22%)]\tLoss: 0.212633\n",
      "Train Epoch: 2 [3000/9145 (33%)]\tLoss: 0.243807\n",
      "Train Epoch: 2 [4000/9145 (43%)]\tLoss: 0.220042\n",
      "Train Epoch: 2 [5000/9145 (54%)]\tLoss: 0.137718\n",
      "Train Epoch: 2 [6000/9145 (65%)]\tLoss: 0.157171\n",
      "Train Epoch: 2 [7000/9145 (76%)]\tLoss: 0.168831\n",
      "Train Epoch: 2 [8000/9145 (87%)]\tLoss: 0.248301\n",
      "Train Epoch: 2 [9000/9145 (98%)]\tLoss: 0.223305\n",
      "Train Epoch: 3 [0/9145 (0%)]\tLoss: 0.146331\n",
      "Train Epoch: 3 [1000/9145 (11%)]\tLoss: 0.180147\n",
      "Train Epoch: 3 [2000/9145 (22%)]\tLoss: 0.227254\n",
      "Train Epoch: 3 [3000/9145 (33%)]\tLoss: 0.167475\n",
      "Train Epoch: 3 [4000/9145 (43%)]\tLoss: 0.230349\n",
      "Train Epoch: 3 [5000/9145 (54%)]\tLoss: 0.211307\n",
      "Train Epoch: 3 [6000/9145 (65%)]\tLoss: 0.167206\n",
      "Train Epoch: 3 [7000/9145 (76%)]\tLoss: 0.230069\n",
      "Train Epoch: 3 [8000/9145 (87%)]\tLoss: 0.190846\n",
      "Train Epoch: 3 [9000/9145 (98%)]\tLoss: 0.135753\n",
      "Train Epoch: 4 [0/9145 (0%)]\tLoss: 0.179071\n",
      "Train Epoch: 4 [1000/9145 (11%)]\tLoss: 0.156481\n",
      "Train Epoch: 4 [2000/9145 (22%)]\tLoss: 0.222047\n",
      "Train Epoch: 4 [3000/9145 (33%)]\tLoss: 0.130641\n",
      "Train Epoch: 4 [4000/9145 (43%)]\tLoss: 0.119869\n",
      "Train Epoch: 4 [5000/9145 (54%)]\tLoss: 0.165864\n",
      "Train Epoch: 4 [6000/9145 (65%)]\tLoss: 0.184996\n",
      "Train Epoch: 4 [7000/9145 (76%)]\tLoss: 0.109705\n",
      "Train Epoch: 4 [8000/9145 (87%)]\tLoss: 0.150546\n",
      "Train Epoch: 4 [9000/9145 (98%)]\tLoss: 0.260671\n",
      "Train Epoch: 5 [0/9145 (0%)]\tLoss: 0.266076\n",
      "Train Epoch: 5 [1000/9145 (11%)]\tLoss: 0.154784\n",
      "Train Epoch: 5 [2000/9145 (22%)]\tLoss: 0.187262\n",
      "Train Epoch: 5 [3000/9145 (33%)]\tLoss: 0.107846\n",
      "Train Epoch: 5 [4000/9145 (43%)]\tLoss: 0.201171\n",
      "Train Epoch: 5 [5000/9145 (54%)]\tLoss: 0.236777\n",
      "Train Epoch: 5 [6000/9145 (65%)]\tLoss: 0.116186\n",
      "Train Epoch: 5 [7000/9145 (76%)]\tLoss: 0.160982\n",
      "Train Epoch: 5 [8000/9145 (87%)]\tLoss: 0.215895\n",
      "Train Epoch: 5 [9000/9145 (98%)]\tLoss: 0.132322\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3021 (0%)]\tLoss: 0.274167\n",
      "Train Epoch: 1 [1000/3021 (32%)]\tLoss: 0.165644\n",
      "Train Epoch: 1 [2000/3021 (65%)]\tLoss: 0.164701\n",
      "Train Epoch: 1 [630/3021 (97%)]\tLoss: 0.441147\n",
      "Train Epoch: 2 [0/3021 (0%)]\tLoss: 0.152744\n",
      "Train Epoch: 2 [1000/3021 (32%)]\tLoss: 0.144620\n",
      "Train Epoch: 2 [2000/3021 (65%)]\tLoss: 0.142557\n",
      "Train Epoch: 2 [630/3021 (97%)]\tLoss: 0.058713\n",
      "Train Epoch: 3 [0/3021 (0%)]\tLoss: 0.198846\n",
      "Train Epoch: 3 [1000/3021 (32%)]\tLoss: 0.141807\n",
      "Train Epoch: 3 [2000/3021 (65%)]\tLoss: 0.136371\n",
      "Train Epoch: 3 [630/3021 (97%)]\tLoss: 0.055416\n",
      "Train Epoch: 4 [0/3021 (0%)]\tLoss: 0.169413\n",
      "Train Epoch: 4 [1000/3021 (32%)]\tLoss: 0.081837\n",
      "Train Epoch: 4 [2000/3021 (65%)]\tLoss: 0.139295\n",
      "Train Epoch: 4 [630/3021 (97%)]\tLoss: 0.161400\n",
      "Train Epoch: 5 [0/3021 (0%)]\tLoss: 0.155130\n",
      "Train Epoch: 5 [1000/3021 (32%)]\tLoss: 0.132172\n",
      "Train Epoch: 5 [2000/3021 (65%)]\tLoss: 0.106535\n",
      "Train Epoch: 5 [630/3021 (97%)]\tLoss: 0.079470\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/7953 (0%)]\tLoss: 0.369555\n",
      "Train Epoch: 1 [1000/7953 (12%)]\tLoss: 0.277596\n",
      "Train Epoch: 1 [2000/7953 (25%)]\tLoss: 0.324014\n",
      "Train Epoch: 1 [3000/7953 (38%)]\tLoss: 0.322934\n",
      "Train Epoch: 1 [4000/7953 (50%)]\tLoss: 0.354063\n",
      "Train Epoch: 1 [5000/7953 (62%)]\tLoss: 0.235173\n",
      "Train Epoch: 1 [6000/7953 (75%)]\tLoss: 0.315143\n",
      "Train Epoch: 1 [7000/7953 (88%)]\tLoss: 0.333508\n",
      "Train Epoch: 2 [0/7953 (0%)]\tLoss: 0.380108\n",
      "Train Epoch: 2 [1000/7953 (12%)]\tLoss: 0.180717\n",
      "Train Epoch: 2 [2000/7953 (25%)]\tLoss: 0.275003\n",
      "Train Epoch: 2 [3000/7953 (38%)]\tLoss: 0.254369\n",
      "Train Epoch: 2 [4000/7953 (50%)]\tLoss: 0.390766\n",
      "Train Epoch: 2 [5000/7953 (62%)]\tLoss: 0.365312\n",
      "Train Epoch: 2 [6000/7953 (75%)]\tLoss: 0.284938\n",
      "Train Epoch: 2 [7000/7953 (88%)]\tLoss: 0.351034\n",
      "Train Epoch: 3 [0/7953 (0%)]\tLoss: 0.356664\n",
      "Train Epoch: 3 [1000/7953 (12%)]\tLoss: 0.351658\n",
      "Train Epoch: 3 [2000/7953 (25%)]\tLoss: 0.212454\n",
      "Train Epoch: 3 [3000/7953 (38%)]\tLoss: 0.351660\n",
      "Train Epoch: 3 [4000/7953 (50%)]\tLoss: 0.348623\n",
      "Train Epoch: 3 [5000/7953 (62%)]\tLoss: 0.348158\n",
      "Train Epoch: 3 [6000/7953 (75%)]\tLoss: 0.423175\n",
      "Train Epoch: 3 [7000/7953 (88%)]\tLoss: 0.245499\n",
      "Train Epoch: 4 [0/7953 (0%)]\tLoss: 0.188853\n",
      "Train Epoch: 4 [1000/7953 (12%)]\tLoss: 0.312451\n",
      "Train Epoch: 4 [2000/7953 (25%)]\tLoss: 0.393961\n",
      "Train Epoch: 4 [3000/7953 (38%)]\tLoss: 0.249088\n",
      "Train Epoch: 4 [4000/7953 (50%)]\tLoss: 0.320196\n",
      "Train Epoch: 4 [5000/7953 (62%)]\tLoss: 0.261419\n",
      "Train Epoch: 4 [6000/7953 (75%)]\tLoss: 0.332379\n",
      "Train Epoch: 4 [7000/7953 (88%)]\tLoss: 0.273495\n",
      "Train Epoch: 5 [0/7953 (0%)]\tLoss: 0.349057\n",
      "Train Epoch: 5 [1000/7953 (12%)]\tLoss: 0.405345\n",
      "Train Epoch: 5 [2000/7953 (25%)]\tLoss: 0.291751\n",
      "Train Epoch: 5 [3000/7953 (38%)]\tLoss: 0.229597\n",
      "Train Epoch: 5 [4000/7953 (50%)]\tLoss: 0.378855\n",
      "Train Epoch: 5 [5000/7953 (62%)]\tLoss: 0.226245\n",
      "Train Epoch: 5 [6000/7953 (75%)]\tLoss: 0.226398\n",
      "Train Epoch: 5 [7000/7953 (88%)]\tLoss: 0.141135\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/10012 (0%)]\tLoss: 0.167343\n",
      "Train Epoch: 1 [1000/10012 (10%)]\tLoss: 0.091543\n",
      "Train Epoch: 1 [2000/10012 (20%)]\tLoss: 0.063678\n",
      "Train Epoch: 1 [3000/10012 (30%)]\tLoss: 0.180799\n",
      "Train Epoch: 1 [4000/10012 (40%)]\tLoss: 0.150228\n",
      "Train Epoch: 1 [5000/10012 (50%)]\tLoss: 0.103540\n",
      "Train Epoch: 1 [6000/10012 (59%)]\tLoss: 0.172538\n",
      "Train Epoch: 1 [7000/10012 (69%)]\tLoss: 0.118613\n",
      "Train Epoch: 1 [8000/10012 (79%)]\tLoss: 0.155106\n",
      "Train Epoch: 1 [9000/10012 (89%)]\tLoss: 0.138971\n",
      "Train Epoch: 1 [1200/10012 (99%)]\tLoss: 0.066375\n",
      "Train Epoch: 2 [0/10012 (0%)]\tLoss: 0.079057\n",
      "Train Epoch: 2 [1000/10012 (10%)]\tLoss: 0.053864\n",
      "Train Epoch: 2 [2000/10012 (20%)]\tLoss: 0.125851\n",
      "Train Epoch: 2 [3000/10012 (30%)]\tLoss: 0.057797\n",
      "Train Epoch: 2 [4000/10012 (40%)]\tLoss: 0.094933\n",
      "Train Epoch: 2 [5000/10012 (50%)]\tLoss: 0.220772\n",
      "Train Epoch: 2 [6000/10012 (59%)]\tLoss: 0.099923\n",
      "Train Epoch: 2 [7000/10012 (69%)]\tLoss: 0.055715\n",
      "Train Epoch: 2 [8000/10012 (79%)]\tLoss: 0.146830\n",
      "Train Epoch: 2 [9000/10012 (89%)]\tLoss: 0.156674\n",
      "Train Epoch: 2 [1200/10012 (99%)]\tLoss: 0.097126\n",
      "Train Epoch: 3 [0/10012 (0%)]\tLoss: 0.063797\n",
      "Train Epoch: 3 [1000/10012 (10%)]\tLoss: 0.136971\n",
      "Train Epoch: 3 [2000/10012 (20%)]\tLoss: 0.054977\n",
      "Train Epoch: 3 [3000/10012 (30%)]\tLoss: 0.110614\n",
      "Train Epoch: 3 [4000/10012 (40%)]\tLoss: 0.073457\n",
      "Train Epoch: 3 [5000/10012 (50%)]\tLoss: 0.112971\n",
      "Train Epoch: 3 [6000/10012 (59%)]\tLoss: 0.055416\n",
      "Train Epoch: 3 [7000/10012 (69%)]\tLoss: 0.125554\n",
      "Train Epoch: 3 [8000/10012 (79%)]\tLoss: 0.119803\n",
      "Train Epoch: 3 [9000/10012 (89%)]\tLoss: 0.166556\n",
      "Train Epoch: 3 [1200/10012 (99%)]\tLoss: 0.003693\n",
      "Train Epoch: 4 [0/10012 (0%)]\tLoss: 0.060467\n",
      "Train Epoch: 4 [1000/10012 (10%)]\tLoss: 0.140435\n",
      "Train Epoch: 4 [2000/10012 (20%)]\tLoss: 0.085318\n",
      "Train Epoch: 4 [3000/10012 (30%)]\tLoss: 0.147624\n",
      "Train Epoch: 4 [4000/10012 (40%)]\tLoss: 0.096048\n",
      "Train Epoch: 4 [5000/10012 (50%)]\tLoss: 0.049461\n",
      "Train Epoch: 4 [6000/10012 (59%)]\tLoss: 0.159775\n",
      "Train Epoch: 4 [7000/10012 (69%)]\tLoss: 0.098134\n",
      "Train Epoch: 4 [8000/10012 (79%)]\tLoss: 0.067352\n",
      "Train Epoch: 4 [9000/10012 (89%)]\tLoss: 0.120518\n",
      "Train Epoch: 4 [1200/10012 (99%)]\tLoss: 0.024877\n",
      "Train Epoch: 5 [0/10012 (0%)]\tLoss: 0.059557\n",
      "Train Epoch: 5 [1000/10012 (10%)]\tLoss: 0.118370\n",
      "Train Epoch: 5 [2000/10012 (20%)]\tLoss: 0.110661\n",
      "Train Epoch: 5 [3000/10012 (30%)]\tLoss: 0.095769\n",
      "Train Epoch: 5 [4000/10012 (40%)]\tLoss: 0.095833\n",
      "Train Epoch: 5 [5000/10012 (50%)]\tLoss: 0.031341\n",
      "Train Epoch: 5 [6000/10012 (59%)]\tLoss: 0.070462\n",
      "Train Epoch: 5 [7000/10012 (69%)]\tLoss: 0.122908\n",
      "Train Epoch: 5 [8000/10012 (79%)]\tLoss: 0.168214\n",
      "Train Epoch: 5 [9000/10012 (89%)]\tLoss: 0.097719\n",
      "Train Epoch: 5 [1200/10012 (99%)]\tLoss: 0.129675\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "8\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.5993, Accuracy: 8690/10000 (87%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/7731 (0%)]\tLoss: 0.223509\n",
      "Train Epoch: 1 [1000/7731 (13%)]\tLoss: 0.089462\n",
      "Train Epoch: 1 [2000/7731 (26%)]\tLoss: 0.226321\n",
      "Train Epoch: 1 [3000/7731 (38%)]\tLoss: 0.148369\n",
      "Train Epoch: 1 [4000/7731 (51%)]\tLoss: 0.150591\n",
      "Train Epoch: 1 [5000/7731 (64%)]\tLoss: 0.061100\n",
      "Train Epoch: 1 [6000/7731 (77%)]\tLoss: 0.139745\n",
      "Train Epoch: 1 [7000/7731 (90%)]\tLoss: 0.115071\n",
      "Train Epoch: 2 [0/7731 (0%)]\tLoss: 0.151098\n",
      "Train Epoch: 2 [1000/7731 (13%)]\tLoss: 0.113703\n",
      "Train Epoch: 2 [2000/7731 (26%)]\tLoss: 0.108523\n",
      "Train Epoch: 2 [3000/7731 (38%)]\tLoss: 0.163903\n",
      "Train Epoch: 2 [4000/7731 (51%)]\tLoss: 0.156616\n",
      "Train Epoch: 2 [5000/7731 (64%)]\tLoss: 0.100581\n",
      "Train Epoch: 2 [6000/7731 (77%)]\tLoss: 0.065921\n",
      "Train Epoch: 2 [7000/7731 (90%)]\tLoss: 0.105076\n",
      "Train Epoch: 3 [0/7731 (0%)]\tLoss: 0.110888\n",
      "Train Epoch: 3 [1000/7731 (13%)]\tLoss: 0.116344\n",
      "Train Epoch: 3 [2000/7731 (26%)]\tLoss: 0.139114\n",
      "Train Epoch: 3 [3000/7731 (38%)]\tLoss: 0.153123\n",
      "Train Epoch: 3 [4000/7731 (51%)]\tLoss: 0.116451\n",
      "Train Epoch: 3 [5000/7731 (64%)]\tLoss: 0.093876\n",
      "Train Epoch: 3 [6000/7731 (77%)]\tLoss: 0.157690\n",
      "Train Epoch: 3 [7000/7731 (90%)]\tLoss: 0.149661\n",
      "Train Epoch: 4 [0/7731 (0%)]\tLoss: 0.124703\n",
      "Train Epoch: 4 [1000/7731 (13%)]\tLoss: 0.095255\n",
      "Train Epoch: 4 [2000/7731 (26%)]\tLoss: 0.104533\n",
      "Train Epoch: 4 [3000/7731 (38%)]\tLoss: 0.153530\n",
      "Train Epoch: 4 [4000/7731 (51%)]\tLoss: 0.196745\n",
      "Train Epoch: 4 [5000/7731 (64%)]\tLoss: 0.062495\n",
      "Train Epoch: 4 [6000/7731 (77%)]\tLoss: 0.041085\n",
      "Train Epoch: 4 [7000/7731 (90%)]\tLoss: 0.115794\n",
      "Train Epoch: 5 [0/7731 (0%)]\tLoss: 0.082124\n",
      "Train Epoch: 5 [1000/7731 (13%)]\tLoss: 0.096609\n",
      "Train Epoch: 5 [2000/7731 (26%)]\tLoss: 0.044684\n",
      "Train Epoch: 5 [3000/7731 (38%)]\tLoss: 0.177992\n",
      "Train Epoch: 5 [4000/7731 (51%)]\tLoss: 0.127529\n",
      "Train Epoch: 5 [5000/7731 (64%)]\tLoss: 0.087882\n",
      "Train Epoch: 5 [6000/7731 (77%)]\tLoss: 0.091909\n",
      "Train Epoch: 5 [7000/7731 (90%)]\tLoss: 0.087688\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11194 (0%)]\tLoss: 0.230427\n",
      "Train Epoch: 1 [1000/11194 (9%)]\tLoss: 0.172809\n",
      "Train Epoch: 1 [2000/11194 (18%)]\tLoss: 0.097981\n",
      "Train Epoch: 1 [3000/11194 (27%)]\tLoss: 0.227443\n",
      "Train Epoch: 1 [4000/11194 (36%)]\tLoss: 0.160304\n",
      "Train Epoch: 1 [5000/11194 (45%)]\tLoss: 0.176774\n",
      "Train Epoch: 1 [6000/11194 (54%)]\tLoss: 0.163172\n",
      "Train Epoch: 1 [7000/11194 (62%)]\tLoss: 0.257268\n",
      "Train Epoch: 1 [8000/11194 (71%)]\tLoss: 0.122715\n",
      "Train Epoch: 1 [9000/11194 (80%)]\tLoss: 0.203333\n",
      "Train Epoch: 1 [10000/11194 (89%)]\tLoss: 0.286114\n",
      "Train Epoch: 1 [11000/11194 (98%)]\tLoss: 0.172390\n",
      "Train Epoch: 2 [0/11194 (0%)]\tLoss: 0.077730\n",
      "Train Epoch: 2 [1000/11194 (9%)]\tLoss: 0.140417\n",
      "Train Epoch: 2 [2000/11194 (18%)]\tLoss: 0.233919\n",
      "Train Epoch: 2 [3000/11194 (27%)]\tLoss: 0.181450\n",
      "Train Epoch: 2 [4000/11194 (36%)]\tLoss: 0.095686\n",
      "Train Epoch: 2 [5000/11194 (45%)]\tLoss: 0.173228\n",
      "Train Epoch: 2 [6000/11194 (54%)]\tLoss: 0.151064\n",
      "Train Epoch: 2 [7000/11194 (62%)]\tLoss: 0.094016\n",
      "Train Epoch: 2 [8000/11194 (71%)]\tLoss: 0.163487\n",
      "Train Epoch: 2 [9000/11194 (80%)]\tLoss: 0.153800\n",
      "Train Epoch: 2 [10000/11194 (89%)]\tLoss: 0.119325\n",
      "Train Epoch: 2 [11000/11194 (98%)]\tLoss: 0.266124\n",
      "Train Epoch: 3 [0/11194 (0%)]\tLoss: 0.155727\n",
      "Train Epoch: 3 [1000/11194 (9%)]\tLoss: 0.122978\n",
      "Train Epoch: 3 [2000/11194 (18%)]\tLoss: 0.101177\n",
      "Train Epoch: 3 [3000/11194 (27%)]\tLoss: 0.214591\n",
      "Train Epoch: 3 [4000/11194 (36%)]\tLoss: 0.089224\n",
      "Train Epoch: 3 [5000/11194 (45%)]\tLoss: 0.122205\n",
      "Train Epoch: 3 [6000/11194 (54%)]\tLoss: 0.165342\n",
      "Train Epoch: 3 [7000/11194 (62%)]\tLoss: 0.151821\n",
      "Train Epoch: 3 [8000/11194 (71%)]\tLoss: 0.121487\n",
      "Train Epoch: 3 [9000/11194 (80%)]\tLoss: 0.147714\n",
      "Train Epoch: 3 [10000/11194 (89%)]\tLoss: 0.237683\n",
      "Train Epoch: 3 [11000/11194 (98%)]\tLoss: 0.183189\n",
      "Train Epoch: 4 [0/11194 (0%)]\tLoss: 0.150943\n",
      "Train Epoch: 4 [1000/11194 (9%)]\tLoss: 0.099658\n",
      "Train Epoch: 4 [2000/11194 (18%)]\tLoss: 0.132042\n",
      "Train Epoch: 4 [3000/11194 (27%)]\tLoss: 0.110619\n",
      "Train Epoch: 4 [4000/11194 (36%)]\tLoss: 0.193811\n",
      "Train Epoch: 4 [5000/11194 (45%)]\tLoss: 0.143685\n",
      "Train Epoch: 4 [6000/11194 (54%)]\tLoss: 0.132621\n",
      "Train Epoch: 4 [7000/11194 (62%)]\tLoss: 0.079985\n",
      "Train Epoch: 4 [8000/11194 (71%)]\tLoss: 0.244222\n",
      "Train Epoch: 4 [9000/11194 (80%)]\tLoss: 0.161056\n",
      "Train Epoch: 4 [10000/11194 (89%)]\tLoss: 0.159228\n",
      "Train Epoch: 4 [11000/11194 (98%)]\tLoss: 0.138267\n",
      "Train Epoch: 5 [0/11194 (0%)]\tLoss: 0.130189\n",
      "Train Epoch: 5 [1000/11194 (9%)]\tLoss: 0.116676\n",
      "Train Epoch: 5 [2000/11194 (18%)]\tLoss: 0.217356\n",
      "Train Epoch: 5 [3000/11194 (27%)]\tLoss: 0.117266\n",
      "Train Epoch: 5 [4000/11194 (36%)]\tLoss: 0.082896\n",
      "Train Epoch: 5 [5000/11194 (45%)]\tLoss: 0.162158\n",
      "Train Epoch: 5 [6000/11194 (54%)]\tLoss: 0.142002\n",
      "Train Epoch: 5 [7000/11194 (62%)]\tLoss: 0.083305\n",
      "Train Epoch: 5 [8000/11194 (71%)]\tLoss: 0.107066\n",
      "Train Epoch: 5 [9000/11194 (80%)]\tLoss: 0.098921\n",
      "Train Epoch: 5 [10000/11194 (89%)]\tLoss: 0.095904\n",
      "Train Epoch: 5 [11000/11194 (98%)]\tLoss: 0.168255\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/7891 (0%)]\tLoss: 0.233879\n",
      "Train Epoch: 1 [1000/7891 (13%)]\tLoss: 0.184639\n",
      "Train Epoch: 1 [2000/7891 (25%)]\tLoss: 0.180180\n",
      "Train Epoch: 1 [3000/7891 (38%)]\tLoss: 0.139643\n",
      "Train Epoch: 1 [4000/7891 (51%)]\tLoss: 0.090509\n",
      "Train Epoch: 1 [5000/7891 (63%)]\tLoss: 0.092462\n",
      "Train Epoch: 1 [6000/7891 (76%)]\tLoss: 0.099644\n",
      "Train Epoch: 1 [7000/7891 (89%)]\tLoss: 0.139433\n",
      "Train Epoch: 2 [0/7891 (0%)]\tLoss: 0.110900\n",
      "Train Epoch: 2 [1000/7891 (13%)]\tLoss: 0.111701\n",
      "Train Epoch: 2 [2000/7891 (25%)]\tLoss: 0.069364\n",
      "Train Epoch: 2 [3000/7891 (38%)]\tLoss: 0.161571\n",
      "Train Epoch: 2 [4000/7891 (51%)]\tLoss: 0.087318\n",
      "Train Epoch: 2 [5000/7891 (63%)]\tLoss: 0.128368\n",
      "Train Epoch: 2 [6000/7891 (76%)]\tLoss: 0.181157\n",
      "Train Epoch: 2 [7000/7891 (89%)]\tLoss: 0.089110\n",
      "Train Epoch: 3 [0/7891 (0%)]\tLoss: 0.095067\n",
      "Train Epoch: 3 [1000/7891 (13%)]\tLoss: 0.063833\n",
      "Train Epoch: 3 [2000/7891 (25%)]\tLoss: 0.110819\n",
      "Train Epoch: 3 [3000/7891 (38%)]\tLoss: 0.141357\n",
      "Train Epoch: 3 [4000/7891 (51%)]\tLoss: 0.093303\n",
      "Train Epoch: 3 [5000/7891 (63%)]\tLoss: 0.082905\n",
      "Train Epoch: 3 [6000/7891 (76%)]\tLoss: 0.116193\n",
      "Train Epoch: 3 [7000/7891 (89%)]\tLoss: 0.062400\n",
      "Train Epoch: 4 [0/7891 (0%)]\tLoss: 0.104788\n",
      "Train Epoch: 4 [1000/7891 (13%)]\tLoss: 0.062374\n",
      "Train Epoch: 4 [2000/7891 (25%)]\tLoss: 0.113592\n",
      "Train Epoch: 4 [3000/7891 (38%)]\tLoss: 0.071663\n",
      "Train Epoch: 4 [4000/7891 (51%)]\tLoss: 0.077082\n",
      "Train Epoch: 4 [5000/7891 (63%)]\tLoss: 0.071241\n",
      "Train Epoch: 4 [6000/7891 (76%)]\tLoss: 0.079203\n",
      "Train Epoch: 4 [7000/7891 (89%)]\tLoss: 0.062782\n",
      "Train Epoch: 5 [0/7891 (0%)]\tLoss: 0.044188\n",
      "Train Epoch: 5 [1000/7891 (13%)]\tLoss: 0.071317\n",
      "Train Epoch: 5 [2000/7891 (25%)]\tLoss: 0.069056\n",
      "Train Epoch: 5 [3000/7891 (38%)]\tLoss: 0.067968\n",
      "Train Epoch: 5 [4000/7891 (51%)]\tLoss: 0.049358\n",
      "Train Epoch: 5 [5000/7891 (63%)]\tLoss: 0.033396\n",
      "Train Epoch: 5 [6000/7891 (76%)]\tLoss: 0.058106\n",
      "Train Epoch: 5 [7000/7891 (89%)]\tLoss: 0.118631\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/3053 (0%)]\tLoss: 0.118857\n",
      "Train Epoch: 1 [1000/3053 (32%)]\tLoss: 0.096341\n",
      "Train Epoch: 1 [2000/3053 (65%)]\tLoss: 0.050119\n",
      "Train Epoch: 1 [1590/3053 (97%)]\tLoss: 0.026855\n",
      "Train Epoch: 2 [0/3053 (0%)]\tLoss: 0.067121\n",
      "Train Epoch: 2 [1000/3053 (32%)]\tLoss: 0.058921\n",
      "Train Epoch: 2 [2000/3053 (65%)]\tLoss: 0.078018\n",
      "Train Epoch: 2 [1590/3053 (97%)]\tLoss: 0.074447\n",
      "Train Epoch: 3 [0/3053 (0%)]\tLoss: 0.042622\n",
      "Train Epoch: 3 [1000/3053 (32%)]\tLoss: 0.043004\n",
      "Train Epoch: 3 [2000/3053 (65%)]\tLoss: 0.100388\n",
      "Train Epoch: 3 [1590/3053 (97%)]\tLoss: 0.042249\n",
      "Train Epoch: 4 [0/3053 (0%)]\tLoss: 0.051089\n",
      "Train Epoch: 4 [1000/3053 (32%)]\tLoss: 0.083596\n",
      "Train Epoch: 4 [2000/3053 (65%)]\tLoss: 0.058263\n",
      "Train Epoch: 4 [1590/3053 (97%)]\tLoss: 0.061397\n",
      "Train Epoch: 5 [0/3053 (0%)]\tLoss: 0.045871\n",
      "Train Epoch: 5 [1000/3053 (32%)]\tLoss: 0.037623\n",
      "Train Epoch: 5 [2000/3053 (65%)]\tLoss: 0.044707\n",
      "Train Epoch: 5 [1590/3053 (97%)]\tLoss: 0.037947\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/9145 (0%)]\tLoss: 0.234918\n",
      "Train Epoch: 1 [1000/9145 (11%)]\tLoss: 0.159872\n",
      "Train Epoch: 1 [2000/9145 (22%)]\tLoss: 0.203199\n",
      "Train Epoch: 1 [3000/9145 (33%)]\tLoss: 0.096670\n",
      "Train Epoch: 1 [4000/9145 (43%)]\tLoss: 0.164096\n",
      "Train Epoch: 1 [5000/9145 (54%)]\tLoss: 0.248231\n",
      "Train Epoch: 1 [6000/9145 (65%)]\tLoss: 0.237844\n",
      "Train Epoch: 1 [7000/9145 (76%)]\tLoss: 0.282289\n",
      "Train Epoch: 1 [8000/9145 (87%)]\tLoss: 0.244763\n",
      "Train Epoch: 1 [9000/9145 (98%)]\tLoss: 0.186613\n",
      "Train Epoch: 2 [0/9145 (0%)]\tLoss: 0.140629\n",
      "Train Epoch: 2 [1000/9145 (11%)]\tLoss: 0.223667\n",
      "Train Epoch: 2 [2000/9145 (22%)]\tLoss: 0.208211\n",
      "Train Epoch: 2 [3000/9145 (33%)]\tLoss: 0.135037\n",
      "Train Epoch: 2 [4000/9145 (43%)]\tLoss: 0.255334\n",
      "Train Epoch: 2 [5000/9145 (54%)]\tLoss: 0.235327\n",
      "Train Epoch: 2 [6000/9145 (65%)]\tLoss: 0.134636\n",
      "Train Epoch: 2 [7000/9145 (76%)]\tLoss: 0.137572\n",
      "Train Epoch: 2 [8000/9145 (87%)]\tLoss: 0.192666\n",
      "Train Epoch: 2 [9000/9145 (98%)]\tLoss: 0.154870\n",
      "Train Epoch: 3 [0/9145 (0%)]\tLoss: 0.147878\n",
      "Train Epoch: 3 [1000/9145 (11%)]\tLoss: 0.112515\n",
      "Train Epoch: 3 [2000/9145 (22%)]\tLoss: 0.152078\n",
      "Train Epoch: 3 [3000/9145 (33%)]\tLoss: 0.185539\n",
      "Train Epoch: 3 [4000/9145 (43%)]\tLoss: 0.168228\n",
      "Train Epoch: 3 [5000/9145 (54%)]\tLoss: 0.138339\n",
      "Train Epoch: 3 [6000/9145 (65%)]\tLoss: 0.176957\n",
      "Train Epoch: 3 [7000/9145 (76%)]\tLoss: 0.218542\n",
      "Train Epoch: 3 [8000/9145 (87%)]\tLoss: 0.145348\n",
      "Train Epoch: 3 [9000/9145 (98%)]\tLoss: 0.167482\n",
      "Train Epoch: 4 [0/9145 (0%)]\tLoss: 0.104812\n",
      "Train Epoch: 4 [1000/9145 (11%)]\tLoss: 0.147384\n",
      "Train Epoch: 4 [2000/9145 (22%)]\tLoss: 0.126446\n",
      "Train Epoch: 4 [3000/9145 (33%)]\tLoss: 0.141496\n",
      "Train Epoch: 4 [4000/9145 (43%)]\tLoss: 0.200845\n",
      "Train Epoch: 4 [5000/9145 (54%)]\tLoss: 0.112726\n",
      "Train Epoch: 4 [6000/9145 (65%)]\tLoss: 0.235833\n",
      "Train Epoch: 4 [7000/9145 (76%)]\tLoss: 0.212732\n",
      "Train Epoch: 4 [8000/9145 (87%)]\tLoss: 0.246576\n",
      "Train Epoch: 4 [9000/9145 (98%)]\tLoss: 0.124602\n",
      "Train Epoch: 5 [0/9145 (0%)]\tLoss: 0.186415\n",
      "Train Epoch: 5 [1000/9145 (11%)]\tLoss: 0.239446\n",
      "Train Epoch: 5 [2000/9145 (22%)]\tLoss: 0.191790\n",
      "Train Epoch: 5 [3000/9145 (33%)]\tLoss: 0.114710\n",
      "Train Epoch: 5 [4000/9145 (43%)]\tLoss: 0.173209\n",
      "Train Epoch: 5 [5000/9145 (54%)]\tLoss: 0.137967\n",
      "Train Epoch: 5 [6000/9145 (65%)]\tLoss: 0.222343\n",
      "Train Epoch: 5 [7000/9145 (76%)]\tLoss: 0.206226\n",
      "Train Epoch: 5 [8000/9145 (87%)]\tLoss: 0.179928\n",
      "Train Epoch: 5 [9000/9145 (98%)]\tLoss: 0.215863\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3021 (0%)]\tLoss: 0.129208\n",
      "Train Epoch: 1 [1000/3021 (32%)]\tLoss: 0.098045\n",
      "Train Epoch: 1 [2000/3021 (65%)]\tLoss: 0.151116\n",
      "Train Epoch: 1 [630/3021 (97%)]\tLoss: 0.235768\n",
      "Train Epoch: 2 [0/3021 (0%)]\tLoss: 0.127297\n",
      "Train Epoch: 2 [1000/3021 (32%)]\tLoss: 0.150401\n",
      "Train Epoch: 2 [2000/3021 (65%)]\tLoss: 0.192086\n",
      "Train Epoch: 2 [630/3021 (97%)]\tLoss: 0.137091\n",
      "Train Epoch: 3 [0/3021 (0%)]\tLoss: 0.141010\n",
      "Train Epoch: 3 [1000/3021 (32%)]\tLoss: 0.079521\n",
      "Train Epoch: 3 [2000/3021 (65%)]\tLoss: 0.124682\n",
      "Train Epoch: 3 [630/3021 (97%)]\tLoss: 0.137167\n",
      "Train Epoch: 4 [0/3021 (0%)]\tLoss: 0.079227\n",
      "Train Epoch: 4 [1000/3021 (32%)]\tLoss: 0.117041\n",
      "Train Epoch: 4 [2000/3021 (65%)]\tLoss: 0.099951\n",
      "Train Epoch: 4 [630/3021 (97%)]\tLoss: 0.109896\n",
      "Train Epoch: 5 [0/3021 (0%)]\tLoss: 0.085306\n",
      "Train Epoch: 5 [1000/3021 (32%)]\tLoss: 0.117868\n",
      "Train Epoch: 5 [2000/3021 (65%)]\tLoss: 0.091993\n",
      "Train Epoch: 5 [630/3021 (97%)]\tLoss: 0.094742\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/7953 (0%)]\tLoss: 0.368855\n",
      "Train Epoch: 1 [1000/7953 (12%)]\tLoss: 0.293791\n",
      "Train Epoch: 1 [2000/7953 (25%)]\tLoss: 0.321632\n",
      "Train Epoch: 1 [3000/7953 (38%)]\tLoss: 0.403655\n",
      "Train Epoch: 1 [4000/7953 (50%)]\tLoss: 0.505609\n",
      "Train Epoch: 1 [5000/7953 (62%)]\tLoss: 0.298480\n",
      "Train Epoch: 1 [6000/7953 (75%)]\tLoss: 0.290558\n",
      "Train Epoch: 1 [7000/7953 (88%)]\tLoss: 0.465407\n",
      "Train Epoch: 2 [0/7953 (0%)]\tLoss: 0.223392\n",
      "Train Epoch: 2 [1000/7953 (12%)]\tLoss: 0.410999\n",
      "Train Epoch: 2 [2000/7953 (25%)]\tLoss: 0.180116\n",
      "Train Epoch: 2 [3000/7953 (38%)]\tLoss: 0.293705\n",
      "Train Epoch: 2 [4000/7953 (50%)]\tLoss: 0.372692\n",
      "Train Epoch: 2 [5000/7953 (62%)]\tLoss: 0.288152\n",
      "Train Epoch: 2 [6000/7953 (75%)]\tLoss: 0.260213\n",
      "Train Epoch: 2 [7000/7953 (88%)]\tLoss: 0.316635\n",
      "Train Epoch: 3 [0/7953 (0%)]\tLoss: 0.310610\n",
      "Train Epoch: 3 [1000/7953 (12%)]\tLoss: 0.343129\n",
      "Train Epoch: 3 [2000/7953 (25%)]\tLoss: 0.258791\n",
      "Train Epoch: 3 [3000/7953 (38%)]\tLoss: 0.273608\n",
      "Train Epoch: 3 [4000/7953 (50%)]\tLoss: 0.392273\n",
      "Train Epoch: 3 [5000/7953 (62%)]\tLoss: 0.247920\n",
      "Train Epoch: 3 [6000/7953 (75%)]\tLoss: 0.263246\n",
      "Train Epoch: 3 [7000/7953 (88%)]\tLoss: 0.319925\n",
      "Train Epoch: 4 [0/7953 (0%)]\tLoss: 0.278073\n",
      "Train Epoch: 4 [1000/7953 (12%)]\tLoss: 0.312344\n",
      "Train Epoch: 4 [2000/7953 (25%)]\tLoss: 0.353156\n",
      "Train Epoch: 4 [3000/7953 (38%)]\tLoss: 0.282067\n",
      "Train Epoch: 4 [4000/7953 (50%)]\tLoss: 0.276968\n",
      "Train Epoch: 4 [5000/7953 (62%)]\tLoss: 0.332298\n",
      "Train Epoch: 4 [6000/7953 (75%)]\tLoss: 0.252452\n",
      "Train Epoch: 4 [7000/7953 (88%)]\tLoss: 0.400099\n",
      "Train Epoch: 5 [0/7953 (0%)]\tLoss: 0.300785\n",
      "Train Epoch: 5 [1000/7953 (12%)]\tLoss: 0.237054\n",
      "Train Epoch: 5 [2000/7953 (25%)]\tLoss: 0.330757\n",
      "Train Epoch: 5 [3000/7953 (38%)]\tLoss: 0.437201\n",
      "Train Epoch: 5 [4000/7953 (50%)]\tLoss: 0.236622\n",
      "Train Epoch: 5 [5000/7953 (62%)]\tLoss: 0.252521\n",
      "Train Epoch: 5 [6000/7953 (75%)]\tLoss: 0.257758\n",
      "Train Epoch: 5 [7000/7953 (88%)]\tLoss: 0.461382\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/10012 (0%)]\tLoss: 0.232543\n",
      "Train Epoch: 1 [1000/10012 (10%)]\tLoss: 0.096835\n",
      "Train Epoch: 1 [2000/10012 (20%)]\tLoss: 0.073400\n",
      "Train Epoch: 1 [3000/10012 (30%)]\tLoss: 0.078327\n",
      "Train Epoch: 1 [4000/10012 (40%)]\tLoss: 0.045069\n",
      "Train Epoch: 1 [5000/10012 (50%)]\tLoss: 0.072122\n",
      "Train Epoch: 1 [6000/10012 (59%)]\tLoss: 0.089944\n",
      "Train Epoch: 1 [7000/10012 (69%)]\tLoss: 0.111798\n",
      "Train Epoch: 1 [8000/10012 (79%)]\tLoss: 0.070563\n",
      "Train Epoch: 1 [9000/10012 (89%)]\tLoss: 0.067598\n",
      "Train Epoch: 1 [1200/10012 (99%)]\tLoss: 0.035554\n",
      "Train Epoch: 2 [0/10012 (0%)]\tLoss: 0.129285\n",
      "Train Epoch: 2 [1000/10012 (10%)]\tLoss: 0.037770\n",
      "Train Epoch: 2 [2000/10012 (20%)]\tLoss: 0.090864\n",
      "Train Epoch: 2 [3000/10012 (30%)]\tLoss: 0.115184\n",
      "Train Epoch: 2 [4000/10012 (40%)]\tLoss: 0.092470\n",
      "Train Epoch: 2 [5000/10012 (50%)]\tLoss: 0.085733\n",
      "Train Epoch: 2 [6000/10012 (59%)]\tLoss: 0.050966\n",
      "Train Epoch: 2 [7000/10012 (69%)]\tLoss: 0.036308\n",
      "Train Epoch: 2 [8000/10012 (79%)]\tLoss: 0.165916\n",
      "Train Epoch: 2 [9000/10012 (89%)]\tLoss: 0.064260\n",
      "Train Epoch: 2 [1200/10012 (99%)]\tLoss: 0.102694\n",
      "Train Epoch: 3 [0/10012 (0%)]\tLoss: 0.119111\n",
      "Train Epoch: 3 [1000/10012 (10%)]\tLoss: 0.060629\n",
      "Train Epoch: 3 [2000/10012 (20%)]\tLoss: 0.098958\n",
      "Train Epoch: 3 [3000/10012 (30%)]\tLoss: 0.049825\n",
      "Train Epoch: 3 [4000/10012 (40%)]\tLoss: 0.070808\n",
      "Train Epoch: 3 [5000/10012 (50%)]\tLoss: 0.049426\n",
      "Train Epoch: 3 [6000/10012 (59%)]\tLoss: 0.241262\n",
      "Train Epoch: 3 [7000/10012 (69%)]\tLoss: 0.045673\n",
      "Train Epoch: 3 [8000/10012 (79%)]\tLoss: 0.089438\n",
      "Train Epoch: 3 [9000/10012 (89%)]\tLoss: 0.131052\n",
      "Train Epoch: 3 [1200/10012 (99%)]\tLoss: 0.075468\n",
      "Train Epoch: 4 [0/10012 (0%)]\tLoss: 0.127514\n",
      "Train Epoch: 4 [1000/10012 (10%)]\tLoss: 0.059051\n",
      "Train Epoch: 4 [2000/10012 (20%)]\tLoss: 0.059257\n",
      "Train Epoch: 4 [3000/10012 (30%)]\tLoss: 0.173536\n",
      "Train Epoch: 4 [4000/10012 (40%)]\tLoss: 0.094296\n",
      "Train Epoch: 4 [5000/10012 (50%)]\tLoss: 0.067910\n",
      "Train Epoch: 4 [6000/10012 (59%)]\tLoss: 0.050436\n",
      "Train Epoch: 4 [7000/10012 (69%)]\tLoss: 0.107770\n",
      "Train Epoch: 4 [8000/10012 (79%)]\tLoss: 0.080206\n",
      "Train Epoch: 4 [9000/10012 (89%)]\tLoss: 0.077722\n",
      "Train Epoch: 4 [1200/10012 (99%)]\tLoss: 0.016473\n",
      "Train Epoch: 5 [0/10012 (0%)]\tLoss: 0.083816\n",
      "Train Epoch: 5 [1000/10012 (10%)]\tLoss: 0.040394\n",
      "Train Epoch: 5 [2000/10012 (20%)]\tLoss: 0.073574\n",
      "Train Epoch: 5 [3000/10012 (30%)]\tLoss: 0.095470\n",
      "Train Epoch: 5 [4000/10012 (40%)]\tLoss: 0.063546\n",
      "Train Epoch: 5 [5000/10012 (50%)]\tLoss: 0.129563\n",
      "Train Epoch: 5 [6000/10012 (59%)]\tLoss: 0.025539\n",
      "Train Epoch: 5 [7000/10012 (69%)]\tLoss: 0.090399\n",
      "Train Epoch: 5 [8000/10012 (79%)]\tLoss: 0.131768\n",
      "Train Epoch: 5 [9000/10012 (89%)]\tLoss: 0.142989\n",
      "Train Epoch: 5 [1200/10012 (99%)]\tLoss: 0.218597\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "8\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.5925, Accuracy: 8692/10000 (87%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/7731 (0%)]\tLoss: 0.266281\n",
      "Train Epoch: 1 [1000/7731 (13%)]\tLoss: 0.152850\n",
      "Train Epoch: 1 [2000/7731 (26%)]\tLoss: 0.177163\n",
      "Train Epoch: 1 [3000/7731 (38%)]\tLoss: 0.139995\n",
      "Train Epoch: 1 [4000/7731 (51%)]\tLoss: 0.166505\n",
      "Train Epoch: 1 [5000/7731 (64%)]\tLoss: 0.056834\n",
      "Train Epoch: 1 [6000/7731 (77%)]\tLoss: 0.107376\n",
      "Train Epoch: 1 [7000/7731 (90%)]\tLoss: 0.158644\n",
      "Train Epoch: 2 [0/7731 (0%)]\tLoss: 0.060785\n",
      "Train Epoch: 2 [1000/7731 (13%)]\tLoss: 0.135899\n",
      "Train Epoch: 2 [2000/7731 (26%)]\tLoss: 0.184758\n",
      "Train Epoch: 2 [3000/7731 (38%)]\tLoss: 0.094819\n",
      "Train Epoch: 2 [4000/7731 (51%)]\tLoss: 0.207958\n",
      "Train Epoch: 2 [5000/7731 (64%)]\tLoss: 0.120628\n",
      "Train Epoch: 2 [6000/7731 (77%)]\tLoss: 0.110952\n",
      "Train Epoch: 2 [7000/7731 (90%)]\tLoss: 0.079920\n",
      "Train Epoch: 3 [0/7731 (0%)]\tLoss: 0.165890\n",
      "Train Epoch: 3 [1000/7731 (13%)]\tLoss: 0.081668\n",
      "Train Epoch: 3 [2000/7731 (26%)]\tLoss: 0.032937\n",
      "Train Epoch: 3 [3000/7731 (38%)]\tLoss: 0.143272\n",
      "Train Epoch: 3 [4000/7731 (51%)]\tLoss: 0.128206\n",
      "Train Epoch: 3 [5000/7731 (64%)]\tLoss: 0.147207\n",
      "Train Epoch: 3 [6000/7731 (77%)]\tLoss: 0.078197\n",
      "Train Epoch: 3 [7000/7731 (90%)]\tLoss: 0.142394\n",
      "Train Epoch: 4 [0/7731 (0%)]\tLoss: 0.096155\n",
      "Train Epoch: 4 [1000/7731 (13%)]\tLoss: 0.116124\n",
      "Train Epoch: 4 [2000/7731 (26%)]\tLoss: 0.059246\n",
      "Train Epoch: 4 [3000/7731 (38%)]\tLoss: 0.114913\n",
      "Train Epoch: 4 [4000/7731 (51%)]\tLoss: 0.060744\n",
      "Train Epoch: 4 [5000/7731 (64%)]\tLoss: 0.149646\n",
      "Train Epoch: 4 [6000/7731 (77%)]\tLoss: 0.115450\n",
      "Train Epoch: 4 [7000/7731 (90%)]\tLoss: 0.107346\n",
      "Train Epoch: 5 [0/7731 (0%)]\tLoss: 0.115785\n",
      "Train Epoch: 5 [1000/7731 (13%)]\tLoss: 0.141012\n",
      "Train Epoch: 5 [2000/7731 (26%)]\tLoss: 0.087904\n",
      "Train Epoch: 5 [3000/7731 (38%)]\tLoss: 0.096481\n",
      "Train Epoch: 5 [4000/7731 (51%)]\tLoss: 0.065285\n",
      "Train Epoch: 5 [5000/7731 (64%)]\tLoss: 0.100145\n",
      "Train Epoch: 5 [6000/7731 (77%)]\tLoss: 0.150141\n",
      "Train Epoch: 5 [7000/7731 (90%)]\tLoss: 0.054250\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11194 (0%)]\tLoss: 0.261313\n",
      "Train Epoch: 1 [1000/11194 (9%)]\tLoss: 0.142746\n",
      "Train Epoch: 1 [2000/11194 (18%)]\tLoss: 0.220457\n",
      "Train Epoch: 1 [3000/11194 (27%)]\tLoss: 0.094997\n",
      "Train Epoch: 1 [4000/11194 (36%)]\tLoss: 0.140932\n",
      "Train Epoch: 1 [5000/11194 (45%)]\tLoss: 0.162821\n",
      "Train Epoch: 1 [6000/11194 (54%)]\tLoss: 0.124702\n",
      "Train Epoch: 1 [7000/11194 (62%)]\tLoss: 0.133587\n",
      "Train Epoch: 1 [8000/11194 (71%)]\tLoss: 0.269992\n",
      "Train Epoch: 1 [9000/11194 (80%)]\tLoss: 0.156874\n",
      "Train Epoch: 1 [10000/11194 (89%)]\tLoss: 0.179924\n",
      "Train Epoch: 1 [11000/11194 (98%)]\tLoss: 0.176955\n",
      "Train Epoch: 2 [0/11194 (0%)]\tLoss: 0.168760\n",
      "Train Epoch: 2 [1000/11194 (9%)]\tLoss: 0.275420\n",
      "Train Epoch: 2 [2000/11194 (18%)]\tLoss: 0.139022\n",
      "Train Epoch: 2 [3000/11194 (27%)]\tLoss: 0.142308\n",
      "Train Epoch: 2 [4000/11194 (36%)]\tLoss: 0.210923\n",
      "Train Epoch: 2 [5000/11194 (45%)]\tLoss: 0.150151\n",
      "Train Epoch: 2 [6000/11194 (54%)]\tLoss: 0.144635\n",
      "Train Epoch: 2 [7000/11194 (62%)]\tLoss: 0.217221\n",
      "Train Epoch: 2 [8000/11194 (71%)]\tLoss: 0.061009\n",
      "Train Epoch: 2 [9000/11194 (80%)]\tLoss: 0.138390\n",
      "Train Epoch: 2 [10000/11194 (89%)]\tLoss: 0.199187\n",
      "Train Epoch: 2 [11000/11194 (98%)]\tLoss: 0.205445\n",
      "Train Epoch: 3 [0/11194 (0%)]\tLoss: 0.129050\n",
      "Train Epoch: 3 [1000/11194 (9%)]\tLoss: 0.109469\n",
      "Train Epoch: 3 [2000/11194 (18%)]\tLoss: 0.079126\n",
      "Train Epoch: 3 [3000/11194 (27%)]\tLoss: 0.199786\n",
      "Train Epoch: 3 [4000/11194 (36%)]\tLoss: 0.156666\n",
      "Train Epoch: 3 [5000/11194 (45%)]\tLoss: 0.168048\n",
      "Train Epoch: 3 [6000/11194 (54%)]\tLoss: 0.152936\n",
      "Train Epoch: 3 [7000/11194 (62%)]\tLoss: 0.199048\n",
      "Train Epoch: 3 [8000/11194 (71%)]\tLoss: 0.092716\n",
      "Train Epoch: 3 [9000/11194 (80%)]\tLoss: 0.138505\n",
      "Train Epoch: 3 [10000/11194 (89%)]\tLoss: 0.315017\n",
      "Train Epoch: 3 [11000/11194 (98%)]\tLoss: 0.149321\n",
      "Train Epoch: 4 [0/11194 (0%)]\tLoss: 0.128458\n",
      "Train Epoch: 4 [1000/11194 (9%)]\tLoss: 0.098425\n",
      "Train Epoch: 4 [2000/11194 (18%)]\tLoss: 0.140342\n",
      "Train Epoch: 4 [3000/11194 (27%)]\tLoss: 0.115317\n",
      "Train Epoch: 4 [4000/11194 (36%)]\tLoss: 0.067121\n",
      "Train Epoch: 4 [5000/11194 (45%)]\tLoss: 0.105424\n",
      "Train Epoch: 4 [6000/11194 (54%)]\tLoss: 0.158801\n",
      "Train Epoch: 4 [7000/11194 (62%)]\tLoss: 0.097309\n",
      "Train Epoch: 4 [8000/11194 (71%)]\tLoss: 0.101325\n",
      "Train Epoch: 4 [9000/11194 (80%)]\tLoss: 0.215920\n",
      "Train Epoch: 4 [10000/11194 (89%)]\tLoss: 0.102606\n",
      "Train Epoch: 4 [11000/11194 (98%)]\tLoss: 0.169661\n",
      "Train Epoch: 5 [0/11194 (0%)]\tLoss: 0.086607\n",
      "Train Epoch: 5 [1000/11194 (9%)]\tLoss: 0.227476\n",
      "Train Epoch: 5 [2000/11194 (18%)]\tLoss: 0.129677\n",
      "Train Epoch: 5 [3000/11194 (27%)]\tLoss: 0.107452\n",
      "Train Epoch: 5 [4000/11194 (36%)]\tLoss: 0.088042\n",
      "Train Epoch: 5 [5000/11194 (45%)]\tLoss: 0.143056\n",
      "Train Epoch: 5 [6000/11194 (54%)]\tLoss: 0.109516\n",
      "Train Epoch: 5 [7000/11194 (62%)]\tLoss: 0.039949\n",
      "Train Epoch: 5 [8000/11194 (71%)]\tLoss: 0.187919\n",
      "Train Epoch: 5 [9000/11194 (80%)]\tLoss: 0.131435\n",
      "Train Epoch: 5 [10000/11194 (89%)]\tLoss: 0.093083\n",
      "Train Epoch: 5 [11000/11194 (98%)]\tLoss: 0.078746\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/7891 (0%)]\tLoss: 0.167310\n",
      "Train Epoch: 1 [1000/7891 (13%)]\tLoss: 0.081237\n",
      "Train Epoch: 1 [2000/7891 (25%)]\tLoss: 0.058676\n",
      "Train Epoch: 1 [3000/7891 (38%)]\tLoss: 0.059059\n",
      "Train Epoch: 1 [4000/7891 (51%)]\tLoss: 0.095945\n",
      "Train Epoch: 1 [5000/7891 (63%)]\tLoss: 0.067484\n",
      "Train Epoch: 1 [6000/7891 (76%)]\tLoss: 0.040522\n",
      "Train Epoch: 1 [7000/7891 (89%)]\tLoss: 0.096543\n",
      "Train Epoch: 2 [0/7891 (0%)]\tLoss: 0.079723\n",
      "Train Epoch: 2 [1000/7891 (13%)]\tLoss: 0.156004\n",
      "Train Epoch: 2 [2000/7891 (25%)]\tLoss: 0.119981\n",
      "Train Epoch: 2 [3000/7891 (38%)]\tLoss: 0.074076\n",
      "Train Epoch: 2 [4000/7891 (51%)]\tLoss: 0.079910\n",
      "Train Epoch: 2 [5000/7891 (63%)]\tLoss: 0.078148\n",
      "Train Epoch: 2 [6000/7891 (76%)]\tLoss: 0.062345\n",
      "Train Epoch: 2 [7000/7891 (89%)]\tLoss: 0.168853\n",
      "Train Epoch: 3 [0/7891 (0%)]\tLoss: 0.099218\n",
      "Train Epoch: 3 [1000/7891 (13%)]\tLoss: 0.082922\n",
      "Train Epoch: 3 [2000/7891 (25%)]\tLoss: 0.076811\n",
      "Train Epoch: 3 [3000/7891 (38%)]\tLoss: 0.175349\n",
      "Train Epoch: 3 [4000/7891 (51%)]\tLoss: 0.101485\n",
      "Train Epoch: 3 [5000/7891 (63%)]\tLoss: 0.195125\n",
      "Train Epoch: 3 [6000/7891 (76%)]\tLoss: 0.074688\n",
      "Train Epoch: 3 [7000/7891 (89%)]\tLoss: 0.141418\n",
      "Train Epoch: 4 [0/7891 (0%)]\tLoss: 0.087498\n",
      "Train Epoch: 4 [1000/7891 (13%)]\tLoss: 0.120181\n",
      "Train Epoch: 4 [2000/7891 (25%)]\tLoss: 0.100141\n",
      "Train Epoch: 4 [3000/7891 (38%)]\tLoss: 0.135941\n",
      "Train Epoch: 4 [4000/7891 (51%)]\tLoss: 0.075226\n",
      "Train Epoch: 4 [5000/7891 (63%)]\tLoss: 0.048289\n",
      "Train Epoch: 4 [6000/7891 (76%)]\tLoss: 0.035220\n",
      "Train Epoch: 4 [7000/7891 (89%)]\tLoss: 0.075681\n",
      "Train Epoch: 5 [0/7891 (0%)]\tLoss: 0.026889\n",
      "Train Epoch: 5 [1000/7891 (13%)]\tLoss: 0.078290\n",
      "Train Epoch: 5 [2000/7891 (25%)]\tLoss: 0.039736\n",
      "Train Epoch: 5 [3000/7891 (38%)]\tLoss: 0.066150\n",
      "Train Epoch: 5 [4000/7891 (51%)]\tLoss: 0.067057\n",
      "Train Epoch: 5 [5000/7891 (63%)]\tLoss: 0.141736\n",
      "Train Epoch: 5 [6000/7891 (76%)]\tLoss: 0.067017\n",
      "Train Epoch: 5 [7000/7891 (89%)]\tLoss: 0.087760\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/3053 (0%)]\tLoss: 0.071033\n",
      "Train Epoch: 1 [1000/3053 (32%)]\tLoss: 0.083196\n",
      "Train Epoch: 1 [2000/3053 (65%)]\tLoss: 0.086599\n",
      "Train Epoch: 1 [1590/3053 (97%)]\tLoss: 0.061719\n",
      "Train Epoch: 2 [0/3053 (0%)]\tLoss: 0.127155\n",
      "Train Epoch: 2 [1000/3053 (32%)]\tLoss: 0.070675\n",
      "Train Epoch: 2 [2000/3053 (65%)]\tLoss: 0.055966\n",
      "Train Epoch: 2 [1590/3053 (97%)]\tLoss: 0.120340\n",
      "Train Epoch: 3 [0/3053 (0%)]\tLoss: 0.028735\n",
      "Train Epoch: 3 [1000/3053 (32%)]\tLoss: 0.090622\n",
      "Train Epoch: 3 [2000/3053 (65%)]\tLoss: 0.087747\n",
      "Train Epoch: 3 [1590/3053 (97%)]\tLoss: 0.060345\n",
      "Train Epoch: 4 [0/3053 (0%)]\tLoss: 0.027822\n",
      "Train Epoch: 4 [1000/3053 (32%)]\tLoss: 0.054477\n",
      "Train Epoch: 4 [2000/3053 (65%)]\tLoss: 0.103951\n",
      "Train Epoch: 4 [1590/3053 (97%)]\tLoss: 0.065038\n",
      "Train Epoch: 5 [0/3053 (0%)]\tLoss: 0.034606\n",
      "Train Epoch: 5 [1000/3053 (32%)]\tLoss: 0.036963\n",
      "Train Epoch: 5 [2000/3053 (65%)]\tLoss: 0.074597\n",
      "Train Epoch: 5 [1590/3053 (97%)]\tLoss: 0.063773\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/9145 (0%)]\tLoss: 0.174098\n",
      "Train Epoch: 1 [1000/9145 (11%)]\tLoss: 0.215542\n",
      "Train Epoch: 1 [2000/9145 (22%)]\tLoss: 0.333022\n",
      "Train Epoch: 1 [3000/9145 (33%)]\tLoss: 0.140101\n",
      "Train Epoch: 1 [4000/9145 (43%)]\tLoss: 0.180853\n",
      "Train Epoch: 1 [5000/9145 (54%)]\tLoss: 0.214602\n",
      "Train Epoch: 1 [6000/9145 (65%)]\tLoss: 0.215583\n",
      "Train Epoch: 1 [7000/9145 (76%)]\tLoss: 0.146255\n",
      "Train Epoch: 1 [8000/9145 (87%)]\tLoss: 0.186425\n",
      "Train Epoch: 1 [9000/9145 (98%)]\tLoss: 0.204828\n",
      "Train Epoch: 2 [0/9145 (0%)]\tLoss: 0.114022\n",
      "Train Epoch: 2 [1000/9145 (11%)]\tLoss: 0.161292\n",
      "Train Epoch: 2 [2000/9145 (22%)]\tLoss: 0.295942\n",
      "Train Epoch: 2 [3000/9145 (33%)]\tLoss: 0.138829\n",
      "Train Epoch: 2 [4000/9145 (43%)]\tLoss: 0.134450\n",
      "Train Epoch: 2 [5000/9145 (54%)]\tLoss: 0.155033\n",
      "Train Epoch: 2 [6000/9145 (65%)]\tLoss: 0.160155\n",
      "Train Epoch: 2 [7000/9145 (76%)]\tLoss: 0.137328\n",
      "Train Epoch: 2 [8000/9145 (87%)]\tLoss: 0.219251\n",
      "Train Epoch: 2 [9000/9145 (98%)]\tLoss: 0.217533\n",
      "Train Epoch: 3 [0/9145 (0%)]\tLoss: 0.107826\n",
      "Train Epoch: 3 [1000/9145 (11%)]\tLoss: 0.177551\n",
      "Train Epoch: 3 [2000/9145 (22%)]\tLoss: 0.141485\n",
      "Train Epoch: 3 [3000/9145 (33%)]\tLoss: 0.170498\n",
      "Train Epoch: 3 [4000/9145 (43%)]\tLoss: 0.187661\n",
      "Train Epoch: 3 [5000/9145 (54%)]\tLoss: 0.234510\n",
      "Train Epoch: 3 [6000/9145 (65%)]\tLoss: 0.195293\n",
      "Train Epoch: 3 [7000/9145 (76%)]\tLoss: 0.134755\n",
      "Train Epoch: 3 [8000/9145 (87%)]\tLoss: 0.304082\n",
      "Train Epoch: 3 [9000/9145 (98%)]\tLoss: 0.135136\n",
      "Train Epoch: 4 [0/9145 (0%)]\tLoss: 0.197587\n",
      "Train Epoch: 4 [1000/9145 (11%)]\tLoss: 0.152509\n",
      "Train Epoch: 4 [2000/9145 (22%)]\tLoss: 0.129853\n",
      "Train Epoch: 4 [3000/9145 (33%)]\tLoss: 0.181143\n",
      "Train Epoch: 4 [4000/9145 (43%)]\tLoss: 0.222870\n",
      "Train Epoch: 4 [5000/9145 (54%)]\tLoss: 0.222980\n",
      "Train Epoch: 4 [6000/9145 (65%)]\tLoss: 0.190657\n",
      "Train Epoch: 4 [7000/9145 (76%)]\tLoss: 0.294691\n",
      "Train Epoch: 4 [8000/9145 (87%)]\tLoss: 0.189821\n",
      "Train Epoch: 4 [9000/9145 (98%)]\tLoss: 0.122906\n",
      "Train Epoch: 5 [0/9145 (0%)]\tLoss: 0.174762\n",
      "Train Epoch: 5 [1000/9145 (11%)]\tLoss: 0.230007\n",
      "Train Epoch: 5 [2000/9145 (22%)]\tLoss: 0.195977\n",
      "Train Epoch: 5 [3000/9145 (33%)]\tLoss: 0.161913\n",
      "Train Epoch: 5 [4000/9145 (43%)]\tLoss: 0.195443\n",
      "Train Epoch: 5 [5000/9145 (54%)]\tLoss: 0.197915\n",
      "Train Epoch: 5 [6000/9145 (65%)]\tLoss: 0.211550\n",
      "Train Epoch: 5 [7000/9145 (76%)]\tLoss: 0.170523\n",
      "Train Epoch: 5 [8000/9145 (87%)]\tLoss: 0.235940\n",
      "Train Epoch: 5 [9000/9145 (98%)]\tLoss: 0.114657\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3021 (0%)]\tLoss: 0.146598\n",
      "Train Epoch: 1 [1000/3021 (32%)]\tLoss: 0.100829\n",
      "Train Epoch: 1 [2000/3021 (65%)]\tLoss: 0.120285\n",
      "Train Epoch: 1 [630/3021 (97%)]\tLoss: 0.268887\n",
      "Train Epoch: 2 [0/3021 (0%)]\tLoss: 0.146996\n",
      "Train Epoch: 2 [1000/3021 (32%)]\tLoss: 0.166621\n",
      "Train Epoch: 2 [2000/3021 (65%)]\tLoss: 0.168898\n",
      "Train Epoch: 2 [630/3021 (97%)]\tLoss: 0.101868\n",
      "Train Epoch: 3 [0/3021 (0%)]\tLoss: 0.173224\n",
      "Train Epoch: 3 [1000/3021 (32%)]\tLoss: 0.065063\n",
      "Train Epoch: 3 [2000/3021 (65%)]\tLoss: 0.126486\n",
      "Train Epoch: 3 [630/3021 (97%)]\tLoss: 0.287638\n",
      "Train Epoch: 4 [0/3021 (0%)]\tLoss: 0.107068\n",
      "Train Epoch: 4 [1000/3021 (32%)]\tLoss: 0.144668\n",
      "Train Epoch: 4 [2000/3021 (65%)]\tLoss: 0.115045\n",
      "Train Epoch: 4 [630/3021 (97%)]\tLoss: 0.055924\n",
      "Train Epoch: 5 [0/3021 (0%)]\tLoss: 0.067634\n",
      "Train Epoch: 5 [1000/3021 (32%)]\tLoss: 0.074103\n",
      "Train Epoch: 5 [2000/3021 (65%)]\tLoss: 0.076920\n",
      "Train Epoch: 5 [630/3021 (97%)]\tLoss: 0.080010\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/7953 (0%)]\tLoss: 0.410655\n",
      "Train Epoch: 1 [1000/7953 (12%)]\tLoss: 0.187067\n",
      "Train Epoch: 1 [2000/7953 (25%)]\tLoss: 0.322298\n",
      "Train Epoch: 1 [3000/7953 (38%)]\tLoss: 0.297395\n",
      "Train Epoch: 1 [4000/7953 (50%)]\tLoss: 0.455677\n",
      "Train Epoch: 1 [5000/7953 (62%)]\tLoss: 0.422184\n",
      "Train Epoch: 1 [6000/7953 (75%)]\tLoss: 0.486326\n",
      "Train Epoch: 1 [7000/7953 (88%)]\tLoss: 0.498453\n",
      "Train Epoch: 2 [0/7953 (0%)]\tLoss: 0.424116\n",
      "Train Epoch: 2 [1000/7953 (12%)]\tLoss: 0.312030\n",
      "Train Epoch: 2 [2000/7953 (25%)]\tLoss: 0.361508\n",
      "Train Epoch: 2 [3000/7953 (38%)]\tLoss: 0.333693\n",
      "Train Epoch: 2 [4000/7953 (50%)]\tLoss: 0.349914\n",
      "Train Epoch: 2 [5000/7953 (62%)]\tLoss: 0.413068\n",
      "Train Epoch: 2 [6000/7953 (75%)]\tLoss: 0.406834\n",
      "Train Epoch: 2 [7000/7953 (88%)]\tLoss: 0.226224\n",
      "Train Epoch: 3 [0/7953 (0%)]\tLoss: 0.275303\n",
      "Train Epoch: 3 [1000/7953 (12%)]\tLoss: 0.346792\n",
      "Train Epoch: 3 [2000/7953 (25%)]\tLoss: 0.274709\n",
      "Train Epoch: 3 [3000/7953 (38%)]\tLoss: 0.254220\n",
      "Train Epoch: 3 [4000/7953 (50%)]\tLoss: 0.221093\n",
      "Train Epoch: 3 [5000/7953 (62%)]\tLoss: 0.374544\n",
      "Train Epoch: 3 [6000/7953 (75%)]\tLoss: 0.288991\n",
      "Train Epoch: 3 [7000/7953 (88%)]\tLoss: 0.237368\n",
      "Train Epoch: 4 [0/7953 (0%)]\tLoss: 0.251986\n",
      "Train Epoch: 4 [1000/7953 (12%)]\tLoss: 0.269754\n",
      "Train Epoch: 4 [2000/7953 (25%)]\tLoss: 0.278726\n",
      "Train Epoch: 4 [3000/7953 (38%)]\tLoss: 0.231524\n",
      "Train Epoch: 4 [4000/7953 (50%)]\tLoss: 0.225547\n",
      "Train Epoch: 4 [5000/7953 (62%)]\tLoss: 0.360397\n",
      "Train Epoch: 4 [6000/7953 (75%)]\tLoss: 0.189763\n",
      "Train Epoch: 4 [7000/7953 (88%)]\tLoss: 0.327534\n",
      "Train Epoch: 5 [0/7953 (0%)]\tLoss: 0.217250\n",
      "Train Epoch: 5 [1000/7953 (12%)]\tLoss: 0.325353\n",
      "Train Epoch: 5 [2000/7953 (25%)]\tLoss: 0.215043\n",
      "Train Epoch: 5 [3000/7953 (38%)]\tLoss: 0.262775\n",
      "Train Epoch: 5 [4000/7953 (50%)]\tLoss: 0.230218\n",
      "Train Epoch: 5 [5000/7953 (62%)]\tLoss: 0.262438\n",
      "Train Epoch: 5 [6000/7953 (75%)]\tLoss: 0.251923\n",
      "Train Epoch: 5 [7000/7953 (88%)]\tLoss: 0.422542\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/10012 (0%)]\tLoss: 0.317006\n",
      "Train Epoch: 1 [1000/10012 (10%)]\tLoss: 0.112725\n",
      "Train Epoch: 1 [2000/10012 (20%)]\tLoss: 0.115146\n",
      "Train Epoch: 1 [3000/10012 (30%)]\tLoss: 0.196736\n",
      "Train Epoch: 1 [4000/10012 (40%)]\tLoss: 0.100773\n",
      "Train Epoch: 1 [5000/10012 (50%)]\tLoss: 0.132687\n",
      "Train Epoch: 1 [6000/10012 (59%)]\tLoss: 0.075983\n",
      "Train Epoch: 1 [7000/10012 (69%)]\tLoss: 0.073822\n",
      "Train Epoch: 1 [8000/10012 (79%)]\tLoss: 0.186894\n",
      "Train Epoch: 1 [9000/10012 (89%)]\tLoss: 0.099716\n",
      "Train Epoch: 1 [1200/10012 (99%)]\tLoss: 0.003520\n",
      "Train Epoch: 2 [0/10012 (0%)]\tLoss: 0.059132\n",
      "Train Epoch: 2 [1000/10012 (10%)]\tLoss: 0.080018\n",
      "Train Epoch: 2 [2000/10012 (20%)]\tLoss: 0.068626\n",
      "Train Epoch: 2 [3000/10012 (30%)]\tLoss: 0.085177\n",
      "Train Epoch: 2 [4000/10012 (40%)]\tLoss: 0.187139\n",
      "Train Epoch: 2 [5000/10012 (50%)]\tLoss: 0.087850\n",
      "Train Epoch: 2 [6000/10012 (59%)]\tLoss: 0.172503\n",
      "Train Epoch: 2 [7000/10012 (69%)]\tLoss: 0.045668\n",
      "Train Epoch: 2 [8000/10012 (79%)]\tLoss: 0.100326\n",
      "Train Epoch: 2 [9000/10012 (89%)]\tLoss: 0.114294\n",
      "Train Epoch: 2 [1200/10012 (99%)]\tLoss: 0.012694\n",
      "Train Epoch: 3 [0/10012 (0%)]\tLoss: 0.108382\n",
      "Train Epoch: 3 [1000/10012 (10%)]\tLoss: 0.050206\n",
      "Train Epoch: 3 [2000/10012 (20%)]\tLoss: 0.092110\n",
      "Train Epoch: 3 [3000/10012 (30%)]\tLoss: 0.053127\n",
      "Train Epoch: 3 [4000/10012 (40%)]\tLoss: 0.077326\n",
      "Train Epoch: 3 [5000/10012 (50%)]\tLoss: 0.048871\n",
      "Train Epoch: 3 [6000/10012 (59%)]\tLoss: 0.188492\n",
      "Train Epoch: 3 [7000/10012 (69%)]\tLoss: 0.050248\n",
      "Train Epoch: 3 [8000/10012 (79%)]\tLoss: 0.057406\n",
      "Train Epoch: 3 [9000/10012 (89%)]\tLoss: 0.058899\n",
      "Train Epoch: 3 [1200/10012 (99%)]\tLoss: 0.181424\n",
      "Train Epoch: 4 [0/10012 (0%)]\tLoss: 0.148278\n",
      "Train Epoch: 4 [1000/10012 (10%)]\tLoss: 0.098327\n",
      "Train Epoch: 4 [2000/10012 (20%)]\tLoss: 0.097486\n",
      "Train Epoch: 4 [3000/10012 (30%)]\tLoss: 0.094389\n",
      "Train Epoch: 4 [4000/10012 (40%)]\tLoss: 0.085256\n",
      "Train Epoch: 4 [5000/10012 (50%)]\tLoss: 0.073607\n",
      "Train Epoch: 4 [6000/10012 (59%)]\tLoss: 0.117428\n",
      "Train Epoch: 4 [7000/10012 (69%)]\tLoss: 0.086028\n",
      "Train Epoch: 4 [8000/10012 (79%)]\tLoss: 0.100084\n",
      "Train Epoch: 4 [9000/10012 (89%)]\tLoss: 0.123660\n",
      "Train Epoch: 4 [1200/10012 (99%)]\tLoss: 0.067646\n",
      "Train Epoch: 5 [0/10012 (0%)]\tLoss: 0.108542\n",
      "Train Epoch: 5 [1000/10012 (10%)]\tLoss: 0.072518\n",
      "Train Epoch: 5 [2000/10012 (20%)]\tLoss: 0.077469\n",
      "Train Epoch: 5 [3000/10012 (30%)]\tLoss: 0.072488\n",
      "Train Epoch: 5 [4000/10012 (40%)]\tLoss: 0.045391\n",
      "Train Epoch: 5 [5000/10012 (50%)]\tLoss: 0.136180\n",
      "Train Epoch: 5 [6000/10012 (59%)]\tLoss: 0.067614\n",
      "Train Epoch: 5 [7000/10012 (69%)]\tLoss: 0.136379\n",
      "Train Epoch: 5 [8000/10012 (79%)]\tLoss: 0.168758\n",
      "Train Epoch: 5 [9000/10012 (89%)]\tLoss: 0.081796\n",
      "Train Epoch: 5 [1200/10012 (99%)]\tLoss: 0.037124\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "8\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.5917, Accuracy: 8674/10000 (87%)\n",
      "\n",
      "Running experiment with 10 partitions...\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.240240\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 0.151237\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 0.160082\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 0.176772\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 0.261167\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 0.256646\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 0.313215\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 0.300369\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.186684\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 0.229600\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.346513\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 0.174069\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.157507\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 0.245652\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 0.198885\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.197011\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.221954\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 0.162778\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 0.180205\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 0.141058\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.290584\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 0.261541\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.174763\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 0.230437\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.203994\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.201681\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.180982\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 0.196065\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.288542\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 0.227492\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.256070\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 0.188404\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.208781\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 0.255206\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.255110\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.159842\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.223618\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 0.194683\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.170407\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 0.198017\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.150494\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 0.294165\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.184427\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 0.311464\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.303627\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.199763\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.238002\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 0.211963\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.268495\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 0.272596\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.135072\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 0.194905\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.242328\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 0.274065\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.296884\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.207076\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.218595\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 0.244551\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.214906\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 0.254929\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.275058\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 0.276331\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.255409\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 0.272783\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.161505\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.215643\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.201662\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 0.358671\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.155348\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 0.181077\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.151988\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 0.250959\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.122292\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 0.256703\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.210216\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.269338\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.210503\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 0.280566\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.256187\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 0.190127\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.315519\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 0.306516\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.287135\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 0.254043\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.182715\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.100414\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.291435\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 0.163552\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.167166\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 0.218511\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.148657\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 0.293036\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.218280\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 0.293636\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.344932\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.310592\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.296312\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 0.163911\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.190738\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 0.201607\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.260464\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 0.301562\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.176329\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 0.271756\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.243426\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.209489\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.147410\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 0.229008\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.227732\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 0.240582\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.254919\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 0.149371\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.141256\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 0.177439\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.187977\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.279377\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.308614\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 0.214280\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.277457\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 0.269201\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.185735\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 0.190300\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.176568\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 0.217680\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.189970\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.161914\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.204607\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 0.110915\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.272277\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 0.284138\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.241135\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 0.207678\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.313928\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 0.311404\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.237992\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.204564\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.217804\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 0.206341\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.172643\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 0.178316\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.190420\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 0.276988\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.229282\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 0.223988\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.293458\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.220020\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.305420\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 0.165676\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.267681\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 0.275559\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.151863\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 0.151667\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.362349\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 0.393133\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.251759\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.242810\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.138170\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 0.284297\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.179765\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 0.116696\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.245772\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 0.270492\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.176282\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 0.208345\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.212689\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.254925\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.247829\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 0.245933\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.170868\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 0.204132\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.207623\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 0.211186\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.223185\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 0.364725\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.154101\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.185918\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.165508\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 0.164455\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.163266\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 0.193115\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.147704\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 0.106309\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.245611\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 0.147040\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.128682\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.286179\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.227285\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 0.097516\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.183629\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 0.235681\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.228922\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 0.111045\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.187158\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 0.218401\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.179811\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.226483\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.206734\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 0.199504\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.218809\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 0.225520\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.268213\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 0.189274\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.265160\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 0.198309\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.210233\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.246195\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.180997\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 0.196236\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.342372\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 0.129645\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.250736\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 0.275694\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.325848\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 0.175251\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.208383\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.233143\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.229614\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 0.273217\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.262026\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 0.216381\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.196363\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 0.172966\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.164205\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 0.148751\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.269470\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.217183\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.282688\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 0.246862\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.162716\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 0.189603\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.249119\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 0.220109\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.246279\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 0.291185\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.130459\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.201959\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.216405\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 0.172517\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.279879\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 0.308883\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.179297\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 0.152734\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.307341\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 0.293287\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.167581\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.312042\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.265254\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 0.138566\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.371123\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 0.217073\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.159581\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 0.129327\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.282535\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 0.186235\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.272333\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.124254\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.242999\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 0.282337\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.130455\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 0.261594\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.265553\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 0.148109\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.254886\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 0.153099\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.212711\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.381709\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.317830\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 0.238437\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.219804\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 0.234005\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.194324\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 0.148847\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.222921\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 0.169200\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.229714\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.215351\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.147312\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 0.244541\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.238927\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 0.104375\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.240873\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 0.224769\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.199282\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 0.208184\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.174036\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.229631\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.138309\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 0.325509\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.204104\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 0.223118\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.251110\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 0.346484\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.201792\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 0.146799\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.179555\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.216681\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.176341\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 0.168454\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.186196\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 0.191895\n",
      "\n",
      "Test set: Avg. loss: 0.2002, Accuracy: 55548/60000 (93%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.366265\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.332941\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.380637\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.264414\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.303032\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.268355\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.270833\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.143363\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.261856\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.240814\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.182226\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.297900\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.211294\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.317932\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.280884\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.201420\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.109421\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.052735\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.058826\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.063813\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.013117\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.066525\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.051297\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.077338\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.160136\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.055892\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.077541\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.142274\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.080317\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.076334\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.102796\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.021969\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.079076\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.058524\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.063176\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.039157\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.020471\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.065599\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.071829\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.069806\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.039027\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.031780\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.027861\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.069840\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.106213\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.057944\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.037541\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.087399\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.082427\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.072701\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.095948\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.030470\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.040498\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.065458\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.075297\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.187402\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.125817\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.096587\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.206419\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.125009\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.063476\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.070248\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.226134\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.089395\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.052972\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.042280\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.109625\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.041090\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.144098\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.071448\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.124615\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.136565\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.071051\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.025354\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.080913\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.138798\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.116767\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.111285\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.051207\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.136144\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.055203\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.099166\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.178855\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.067607\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.065269\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.092604\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.052963\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.077065\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.060800\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.170437\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.099844\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.045271\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.109100\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.218505\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.146099\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.122464\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.157329\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.184348\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.101119\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.079060\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.130444\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.157749\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.080530\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.091158\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.106434\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.208155\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.157001\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.112499\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.159340\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.107812\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.060406\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.099377\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.098313\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.172756\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.081444\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.125668\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.145034\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.119766\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.158058\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.183303\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.239914\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.258698\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.138926\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.269647\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.223597\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.216265\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.194222\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.113537\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.130175\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.138155\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.097340\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.171985\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.081620\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.170456\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.212853\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.142267\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.087017\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.190001\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.218013\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.070077\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.081046\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.141715\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.096750\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.161970\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.239339\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.159412\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.036426\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.155339\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.165605\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.194861\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.357930\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.195544\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.218783\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.253262\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.252314\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.215600\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.157038\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.245644\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.200501\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.194679\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.179343\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.210636\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.179247\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.134046\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.169440\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.157019\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.150919\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.110475\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.156442\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.141569\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.296163\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.242841\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.232147\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.165896\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.243745\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.271269\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.203601\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.238438\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.212854\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.139643\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.208810\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.277374\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.190258\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.278368\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.256433\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.110805\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.247665\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.276451\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.182066\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.298585\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.278213\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.170361\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.215174\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.178365\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.171905\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.156048\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.216419\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.195024\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.225029\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.165557\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.190662\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.199554\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.185433\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.179542\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.232430\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.197271\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.147543\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.202600\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.203244\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.213984\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.168350\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.218388\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.139816\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.233422\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.209928\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.195248\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.175346\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.264431\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.185411\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.231923\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.209209\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.144787\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.083401\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.142554\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.070960\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.178324\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.139461\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.191610\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.109521\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.090747\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.065606\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.093756\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.067747\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.191708\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.105373\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.115963\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.148715\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.037668\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.088579\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.093306\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.120472\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.120755\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.056749\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.067595\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.113779\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.071121\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.100997\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.149776\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.061333\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.058440\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.086856\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.078461\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.065707\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.148548\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.097741\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.221962\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.233717\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.267213\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.127202\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.135599\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.258145\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.114845\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.144053\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.319398\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.180746\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.215790\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.092453\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.121917\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.153247\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.185399\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.143173\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.207887\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.146408\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.104338\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.121933\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.170297\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.155220\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.196232\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.111897\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.158593\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.152916\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.218870\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.110341\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.105528\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.099630\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.197483\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.142482\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.134560\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.069253\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.198516\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.207519\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.075151\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.094747\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.175046\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.065070\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.152081\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.100739\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.085790\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.126292\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.126791\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.175642\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.070639\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.095024\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.212142\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.073944\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.072431\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.098549\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.126193\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.067467\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.097553\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.068976\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.105826\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.056133\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.031877\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.114792\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.163965\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.128117\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.081106\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.096305\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.116461\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.131201\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.079233\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.057063\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.091957\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.176025\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.5939, Accuracy: 8756/10000 (88%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.320598\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.420505\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.340733\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.248388\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.322421\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.234732\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.221552\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.247412\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.240116\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.145988\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.224863\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.307771\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.238994\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.150838\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.229045\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.367840\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.085462\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.047769\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.139715\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.032736\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.069604\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.152674\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.053318\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.108962\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.039423\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.061348\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.048897\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.042656\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.055444\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.047662\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.048013\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.039813\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.060193\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.101302\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.051101\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.104245\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.133353\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.139463\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.039462\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.090876\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.064900\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.107224\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.113636\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.072063\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.031088\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.101107\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.080020\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.137410\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.050285\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.052493\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.053393\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.076858\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.053739\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.055729\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.040470\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.238040\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.069182\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.067833\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.086587\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.065279\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.161486\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.122549\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.064354\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.168936\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.094381\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.054327\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.140170\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.119842\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.105379\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.119111\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.084034\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.092454\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.054160\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.036188\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.107089\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.138589\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.239501\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.098292\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.119847\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.047089\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.091072\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.040960\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.079751\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.153051\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.073127\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.037047\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.102290\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.057136\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.080127\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.104051\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.189648\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.190771\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.194323\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.134895\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.231286\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.155101\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.104136\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.125764\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.050542\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.135017\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.091191\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.078153\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.119114\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.101013\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.191218\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.154092\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.072347\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.098932\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.109905\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.113828\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.078032\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.148022\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.139279\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.113081\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.082095\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.086325\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.109070\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.124448\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.059943\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.146538\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.198718\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.151043\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.259528\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.231631\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.132241\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.168428\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.190743\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.112859\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.165404\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.172225\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.085450\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.128901\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.191217\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.227768\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.149641\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.197205\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.195459\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.102472\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.196859\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.196572\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.132660\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.110048\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.148800\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.182521\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.062065\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.144010\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.114268\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.129151\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.144861\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.083258\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.312666\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.160785\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.164109\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.229361\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.126958\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.195110\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.175978\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.240019\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.269124\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.143798\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.146070\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.304920\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.196062\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.224709\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.140258\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.140326\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.106894\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.141954\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.153309\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.133491\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.176026\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.172980\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.196567\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.188711\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.270079\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.189069\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.355824\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.246775\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.153699\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.225483\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.225122\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.171429\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.149446\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.239235\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.187725\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.187850\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.136509\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.256099\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.173473\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.132880\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.263216\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.184645\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.173753\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.191499\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.168013\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.259303\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.348333\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.229342\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.242247\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.217008\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.285005\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.185585\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.207835\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.177095\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.202940\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.175027\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.398870\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.222510\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.253489\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.154989\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.211032\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.142284\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.189499\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.222056\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.205177\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.155062\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.231155\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.157616\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.119337\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.131720\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.307608\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.046809\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.122317\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.301756\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.219832\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.138427\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.119743\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.125724\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.115831\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.066524\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.060904\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.040990\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.175805\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.144145\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.124097\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.080854\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.085758\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.092551\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.048870\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.126929\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.071457\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.089055\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.076425\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.083047\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.038297\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.108953\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.065737\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.083732\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.036870\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.089611\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.089980\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.058570\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.122665\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.043656\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.063766\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.346685\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.266481\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.187827\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.161251\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.401886\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.122164\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.200246\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.224586\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.188906\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.215518\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.098553\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.152627\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.156583\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.183646\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.120521\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.147776\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.101808\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.183433\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.242694\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.133308\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.188879\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.092476\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.111780\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.182483\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.178213\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.187899\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.107213\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.116602\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.062616\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.072219\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.136995\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.169939\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.199057\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.198552\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.158270\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.147882\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.092381\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.115753\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.276278\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.166499\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.122219\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.112140\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.043619\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.145229\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.112372\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.069595\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.084991\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.154251\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.101926\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.198778\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.116894\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.096512\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.102178\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.148080\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.151421\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.062656\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.179109\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.131920\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.097624\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.106240\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.074440\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.127488\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.068399\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.110932\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.125131\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.055080\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.084327\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.099747\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.109070\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.076645\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.5915, Accuracy: 8776/10000 (88%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.296089\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.257443\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.255420\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.282289\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.146232\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.254781\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.262797\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.217464\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.204718\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.188587\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.208976\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.205010\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.211850\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.150314\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.190457\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.262343\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.046108\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.051879\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.047092\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.074381\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.152663\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.099392\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.095280\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.069214\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.090364\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.089365\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.101156\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.040498\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.124700\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.066969\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.073007\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.053334\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.055997\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.043969\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.096784\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.053077\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.073235\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.187227\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.065052\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.061103\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.057332\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.055780\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.073799\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.064385\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.025358\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.124557\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.054305\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.016687\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.062593\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.072452\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.065949\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.048832\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.092343\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.074802\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.076585\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.206408\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.150228\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.084501\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.162146\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.107668\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.130428\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.235919\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.036091\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.147597\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.096718\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.086443\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.171126\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.033174\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.122597\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.173659\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.046769\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.026717\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.095839\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.172252\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.068844\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.068944\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.158465\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.100574\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.089350\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.110364\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.100027\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.048413\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.097108\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.104924\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.036848\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.116999\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.066988\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.052797\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.161399\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.059329\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.284902\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.198175\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.166112\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.184121\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.156647\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.264778\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.108792\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.125371\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.072086\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.183666\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.278942\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.085678\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.180506\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.137484\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.184299\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.095110\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.122322\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.048100\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.102379\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.084526\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.171197\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.084780\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.137990\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.114488\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.231553\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.043539\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.075883\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.092528\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.141229\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.096096\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.185215\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.206777\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.203932\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.166176\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.109808\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.097625\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.068304\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.150878\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.182110\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.152938\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.210593\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.130060\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.110470\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.123233\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.116919\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.116783\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.104512\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.157936\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.326817\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.123810\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.104519\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.096041\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.170661\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.112954\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.112763\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.104242\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.169417\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.098438\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.107003\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.093562\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.172352\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.194023\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.298379\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.131323\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.078411\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.206226\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.193348\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.305348\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.172570\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.187024\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.098094\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.118315\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.157085\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.147400\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.149848\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.138062\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.109915\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.115418\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.121816\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.244404\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.203897\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.156105\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.248572\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.304845\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.146164\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.291228\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.140895\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.281211\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.248121\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.207609\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.201616\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.135253\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.151277\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.218910\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.166228\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.235188\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.175703\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.263001\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.222678\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.213400\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.227977\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.285795\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.213829\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.326125\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.173908\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.170042\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.184094\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.250532\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.107349\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.076305\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.219389\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.143709\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.329477\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.183544\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.127601\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.176878\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.189382\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.300715\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.207692\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.239104\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.126881\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.333555\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.210006\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.162934\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.221076\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.203731\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.183440\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.183006\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.210423\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.210323\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.293419\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.173993\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.089691\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.143796\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.100563\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.082737\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.262901\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.176898\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.073958\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.173378\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.095532\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.035241\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.139999\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.091739\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.088047\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.107752\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.131793\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.190922\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.181062\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.065287\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.095218\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.091192\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.082809\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.118887\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.160689\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.159487\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.076687\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.072609\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.115720\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.041347\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.046704\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.053215\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.173120\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.146470\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.063860\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.184258\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.165572\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.229238\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.169413\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.202627\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.193486\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.213391\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.120329\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.144162\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.223338\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.154043\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.234731\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.122112\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.140558\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.120214\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.103103\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.141233\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.132851\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.081094\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.074932\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.135975\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.134357\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.105667\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.075568\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.122845\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.172590\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.092230\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.105198\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.152335\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.053649\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.072462\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.078032\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.208151\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.179745\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.173636\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.151851\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.110480\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.106317\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.061443\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.090681\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.156907\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.063990\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.117928\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.061725\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.243395\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.073243\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.159184\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.071125\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.039015\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.115161\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.135508\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.080458\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.130277\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.113489\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.183747\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.072695\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.043243\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.066096\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.089324\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.111375\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.061717\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.087259\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.113369\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.159584\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.095064\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.061382\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.042157\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.226716\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.066808\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.082025\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.5884, Accuracy: 8753/10000 (88%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.263431\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.232745\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.218661\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.248664\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.181782\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.240229\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.189768\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.181379\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.210037\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.277111\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.122270\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.291107\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.147373\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.196866\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.223076\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.195422\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.111341\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.087917\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.108058\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.057366\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.057936\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.122374\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.102798\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.148631\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.035487\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.070425\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.067611\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.048173\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.085723\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.117794\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.064243\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.044673\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.069272\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.090428\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.120536\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.046242\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.054681\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.085097\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.049075\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.024890\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.055916\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.060803\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.032543\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.067884\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.048116\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.070385\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.042322\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.120498\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.046434\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.095800\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.092506\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.055553\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.034377\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.051787\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.039695\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.273799\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.114394\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.111918\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.080398\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.076950\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.129612\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.219677\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.070135\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.073540\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.116938\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.069808\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.058710\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.161025\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.146316\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.073751\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.101134\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.086931\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.133157\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.127432\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.077091\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.054766\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.121755\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.122848\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.104481\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.148005\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.113683\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.087506\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.013432\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.074762\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.087760\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.074027\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.062088\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.044588\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.065064\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.077038\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.166688\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.177986\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.184145\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.135168\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.226129\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.211512\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.171928\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.118075\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.150340\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.143705\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.261162\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.136327\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.074642\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.066631\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.130139\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.129759\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.210287\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.143462\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.221862\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.158666\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.070191\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.074644\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.092831\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.171836\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.124260\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.071325\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.170170\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.035024\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.061359\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.080891\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.223753\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.112416\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.231996\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.119980\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.148323\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.268535\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.169052\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.182847\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.227542\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.185439\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.239353\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.107049\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.145787\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.091194\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.187882\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.107571\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.122836\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.242196\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.113313\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.213355\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.143372\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.136660\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.094644\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.052778\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.264647\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.099199\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.109619\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.070645\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.092794\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.153963\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.248579\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.162418\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.175104\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.297772\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.143988\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.213804\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.169893\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.166560\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.114637\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.142267\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.168610\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.206445\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.178742\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.108481\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.130408\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.206799\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.180609\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.123465\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.164267\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.149840\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.223453\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.171717\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.273035\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.293329\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.358282\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.177506\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.232143\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.325748\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.227312\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.214511\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.159193\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.156641\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.183199\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.135314\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.236872\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.323093\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.191703\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.207770\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.177253\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.244384\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.211502\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.227514\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.243420\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.136955\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.231963\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.231721\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.249219\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.199736\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.231776\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.184268\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.342024\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.146972\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.168467\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.200317\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.273381\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.154361\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.192119\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.267672\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.239509\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.180330\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.130850\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.296051\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.094738\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.137326\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.181366\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.306202\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.155552\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.102513\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.254023\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.196065\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.532489\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.115046\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.071925\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.074294\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.036819\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.189623\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.160593\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.088836\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.143900\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.118338\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.134450\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.176348\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.085429\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.022663\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.073784\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.035706\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.035731\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.131052\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.049686\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.125941\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.215250\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.113277\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.049093\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.091800\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.067309\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.169052\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.039621\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.085247\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.056824\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.046424\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.089055\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.053086\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.129566\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.168002\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.043334\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.180127\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.136881\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.166275\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.155263\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.135489\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.162581\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.164126\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.058105\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.207742\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.138040\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.099598\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.069214\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.191576\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.124096\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.118478\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.209977\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.146143\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.221691\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.159855\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.222485\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.082564\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.180769\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.142296\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.168611\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.171318\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.186266\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.100684\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.197615\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.115856\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.167879\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.110128\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.120451\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.129035\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.065129\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.131235\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.125318\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.076644\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.064381\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.112030\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.073787\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.093534\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.150753\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.131985\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.066431\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.069818\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.154699\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.151785\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.050826\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.113291\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.079661\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.165832\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.076533\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.043593\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.130459\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.039281\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.090739\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.134048\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.112418\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.137525\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.165869\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.056390\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.273487\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.081754\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.168143\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.109157\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.120337\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.051301\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.125396\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.049774\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.165109\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.5807, Accuracy: 8758/10000 (88%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.247226\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.250327\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.226711\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.175672\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.173274\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.188000\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.252848\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.257664\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.123773\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.174063\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.211300\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.239157\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.200331\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.272518\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.205956\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.279170\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.038332\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.032331\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.150253\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.232585\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.177521\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.075916\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.054092\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.040941\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.086378\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.133968\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.039000\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.102946\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.043790\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.068249\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.045540\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.159161\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.076791\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.074811\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.025931\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.076144\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.081203\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.084734\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.101167\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.066842\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.045860\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.021404\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.050074\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.058842\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.071682\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.054462\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.038194\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.045670\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.027955\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.039851\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.055459\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.041092\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.040416\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.087938\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.088133\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.121216\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.061009\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.066251\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.058339\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.117112\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.069314\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.103916\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.137239\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.088045\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.148852\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.181000\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.124703\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.112751\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.055429\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.259381\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.151777\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.093128\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.034338\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.100700\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.070820\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.136683\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.035640\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.066559\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.026832\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.079710\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.134293\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.052792\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.063452\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.110291\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.060424\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.024494\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.093837\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.038873\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.080748\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.099474\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.204301\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.173801\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.195448\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.216005\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.120033\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.155558\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.045587\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.104793\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.131341\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.119968\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.091367\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.156015\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.114548\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.059582\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.171794\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.228805\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.130127\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.074670\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.095892\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.081108\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.106877\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.051830\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.106834\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.050287\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.098517\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.136796\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.078928\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.087458\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.077550\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.098089\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.223761\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.121268\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.095338\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.214285\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.122768\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.179934\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.235445\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.141304\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.238949\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.130284\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.115894\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.104696\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.157352\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.143830\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.180071\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.129160\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.095940\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.105652\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.349011\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.107630\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.185749\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.125192\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.195038\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.110616\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.082618\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.136377\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.119963\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.150598\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.116429\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.149718\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.241891\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.257171\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.193870\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.244498\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.148841\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.197588\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.136420\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.302093\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.185519\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.135569\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.122802\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.116553\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.091915\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.086589\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.172288\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.189053\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.153392\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.150697\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.177430\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.125823\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.174096\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.209354\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.175350\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.267548\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.277018\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.388869\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.197367\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.304274\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.166892\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.162301\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.300286\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.171176\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.307747\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.270955\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.223549\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.321489\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.239443\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.206754\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.172930\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.304336\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.165652\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.213241\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.249308\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.200248\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.225131\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.186587\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.149602\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.198204\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.236771\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.195448\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.198739\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.161977\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.118589\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.233274\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.173852\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.177699\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.142261\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.159885\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.170247\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.286884\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.201866\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.168565\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.092510\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.147392\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.131174\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.204066\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.101360\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.149800\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.164586\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.222264\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.323228\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.085284\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.138539\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.043976\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.057969\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.090094\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.204800\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.076973\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.079767\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.124600\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.081705\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.090446\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.039012\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.078879\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.146561\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.052453\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.065281\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.105702\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.074060\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.067170\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.116531\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.079376\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.073110\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.046043\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.141612\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.121685\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.068831\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.043647\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.102436\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.072689\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.116113\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.121193\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.144924\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.092673\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.070175\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.142799\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.178172\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.151256\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.130417\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.165354\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.169389\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.223081\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.112704\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.074569\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.082550\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.151380\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.146474\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.226852\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.158781\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.164686\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.150259\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.079979\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.156003\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.172047\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.148000\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.136009\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.112819\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.124825\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.141665\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.158164\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.164455\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.118022\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.118868\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.059281\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.122159\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.142674\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.108520\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.128330\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.156270\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.150317\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.255999\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.133289\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.198263\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.123952\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.231794\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.089069\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.111951\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.085071\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.088551\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.119475\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.124682\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.081842\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.112813\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.123453\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.042476\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.040374\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.146733\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.088427\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.053502\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.070480\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.078773\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.145955\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.141200\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.065892\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.068946\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.129143\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.122747\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.072844\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.094500\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.069913\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.052735\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.061202\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.037171\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.126120\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.092719\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.5778, Accuracy: 8790/10000 (88%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.330780\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.316899\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.204526\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.167735\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.160907\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.268790\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.175005\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.245923\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.114668\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.150624\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.199141\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.167310\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.245776\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.115346\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.126549\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.291505\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.072260\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.064227\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.076658\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.183098\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.024588\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.034891\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.097124\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.064463\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.071685\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.058976\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.040696\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.070971\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.032455\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.047261\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.068116\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.048590\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.065672\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.024495\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.062994\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.109848\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.029955\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.095191\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.068588\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.042649\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.080626\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.122760\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.079630\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.054813\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.037426\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.039344\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.018031\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.051748\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.045736\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.016568\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.044539\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.031415\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.048530\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.051688\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.074984\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.321767\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.063385\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.090589\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.053537\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.120525\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.127091\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.115536\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.076076\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.061798\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.134469\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.118481\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.152162\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.079598\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.087173\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.112189\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.051318\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.030091\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.105469\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.049005\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.070891\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.060297\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.069664\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.125690\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.084904\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.074171\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.071392\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.058035\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.073022\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.085180\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.091508\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.044889\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.030049\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.084248\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.136095\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.054183\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.185824\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.168842\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.096649\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.082026\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.108435\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.090249\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.058914\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.089808\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.057315\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.112699\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.072321\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.116199\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.084737\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.127235\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.134569\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.118462\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.215638\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.119187\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.157997\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.114860\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.100719\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.057052\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.076813\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.085553\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.048011\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.067179\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.086498\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.126819\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.151103\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.135729\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.184820\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.136879\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.153448\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.235103\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.181638\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.178419\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.575452\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.170765\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.084162\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.227497\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.171286\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.167749\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.188213\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.082737\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.197393\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.149717\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.128493\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.098716\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.178286\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.094004\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.099472\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.160906\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.101117\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.105919\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.176920\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.122486\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.130875\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.101129\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.110609\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.125107\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.265796\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.171414\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.218629\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.234999\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.171229\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.170650\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.355238\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.179988\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.132617\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.238266\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.111990\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.146004\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.191030\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.143063\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.212438\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.120904\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.071523\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.169989\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.120638\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.125623\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.181628\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.209865\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.213544\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.241506\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.188428\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.295922\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.333857\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.148574\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.236894\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.264248\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.167792\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.176379\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.205105\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.205269\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.201898\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.149917\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.205205\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.145164\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.162185\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.251913\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.152641\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.206296\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.248932\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.160817\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.094185\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.260290\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.156972\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.162156\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.147027\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.114646\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.166236\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.193661\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.222715\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.127190\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.179584\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.226987\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.200675\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.262580\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.270749\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.244696\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.183300\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.160154\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.166915\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.168515\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.119558\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.181892\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.229192\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.139910\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.147136\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.122249\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.230676\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.215311\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.105825\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.139560\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.096163\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.223987\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.117742\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.093763\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.117326\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.090060\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.086455\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.053469\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.179277\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.133847\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.099261\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.179362\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.085587\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.219396\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.072336\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.070233\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.130182\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.044883\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.054015\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.059395\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.042389\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.090240\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.080345\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.082810\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.089732\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.070984\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.122728\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.044743\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.137156\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.023357\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.038700\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.168266\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.285662\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.233986\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.178523\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.097243\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.140161\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.190759\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.088146\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.212381\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.115222\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.129139\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.178058\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.098552\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.117822\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.106109\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.167577\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.051384\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.136664\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.099237\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.202537\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.145004\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.100178\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.164066\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.128344\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.131851\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.114552\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.190143\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.128721\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.152188\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.188640\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.086135\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.134723\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.105296\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.140655\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.060328\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.161203\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.096619\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.127065\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.097814\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.054401\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.139592\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.061595\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.084440\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.129278\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.055630\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.119895\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.051037\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.132906\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.131476\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.101952\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.080258\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.100517\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.105745\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.094012\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.064191\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.196260\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.227217\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.083197\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.049789\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.100236\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.142737\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.120895\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.098397\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.187904\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.139604\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.074297\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.045906\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.099745\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.093495\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.099869\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.5767, Accuracy: 8777/10000 (88%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.307364\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.218104\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.301605\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.192700\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.208886\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.280768\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.229900\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.209124\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.203589\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.106268\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.165580\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.175196\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.127196\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.154487\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.219783\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.243669\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.083741\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.119127\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.150658\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.062136\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.109199\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.082578\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.025813\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.027511\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.067944\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.085072\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.053126\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.098418\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.080328\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.054402\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.076702\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.126152\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.040704\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.048635\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.046332\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.033390\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.020232\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.030015\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.063506\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.093824\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.023373\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.107094\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.069769\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.027274\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.049407\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.076886\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.048340\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.015475\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.026258\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.042975\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.021795\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.093098\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.038865\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.048782\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.043460\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.094569\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.215374\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.141235\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.139509\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.053893\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.061450\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.045901\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.132382\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.092470\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.057072\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.121271\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.121813\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.123799\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.135126\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.040384\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.039357\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.114704\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.087120\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.049777\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.036495\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.092388\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.147010\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.136679\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.098745\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.031925\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.048659\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.045912\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.038084\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.104268\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.043143\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.058817\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.086624\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.041400\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.074074\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.035084\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.102684\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.115286\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.226523\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.193248\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.231842\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.217028\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.085705\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.185998\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.107760\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.072249\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.099839\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.107312\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.081820\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.083417\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.097243\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.096487\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.085141\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.064779\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.142371\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.065808\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.056337\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.080369\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.143338\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.092820\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.029576\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.062596\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.047306\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.057963\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.090669\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.126924\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.287160\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.140127\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.140531\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.168824\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.099250\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.178443\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.137144\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.141622\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.103613\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.135641\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.133968\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.203659\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.351240\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.119996\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.190058\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.126205\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.143022\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.081926\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.089475\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.076876\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.101027\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.060820\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.065789\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.130816\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.089646\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.139553\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.108065\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.049201\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.119452\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.052666\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.140147\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.355140\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.198359\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.134765\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.122431\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.206993\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.178673\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.180886\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.155323\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.120652\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.188238\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.215364\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.163443\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.157652\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.162479\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.135879\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.067292\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.089084\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.149686\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.115220\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.138610\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.194964\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.089286\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.282363\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.174000\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.225260\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.151773\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.270926\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.170302\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.205242\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.259378\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.149602\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.230546\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.237464\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.215282\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.238230\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.312049\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.255992\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.197970\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.148829\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.209875\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.145935\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.271854\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.221038\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.238459\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.183198\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.088907\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.162715\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.206264\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.177737\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.199102\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.231502\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.163068\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.153549\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.194097\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.194551\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.234619\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.170377\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.128470\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.401376\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.173863\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.118548\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.193052\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.191267\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.229892\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.150116\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.159471\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.139609\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.184247\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.221219\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.354301\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.108507\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.284155\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.063396\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.149848\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.127253\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.067527\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.111522\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.152830\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.086975\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.091297\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.181068\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.115261\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.048304\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.047237\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.091618\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.120918\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.121418\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.064650\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.049965\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.082956\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.081391\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.083587\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.081087\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.106965\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.040450\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.073606\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.104280\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.098338\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.078694\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.112888\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.075250\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.048162\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.103223\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.110465\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.135057\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.250559\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.105189\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.157565\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.153925\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.216860\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.229928\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.178986\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.190204\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.140090\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.211571\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.214583\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.135242\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.129741\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.105553\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.099186\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.098751\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.089323\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.164750\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.228985\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.158604\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.081400\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.101140\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.077878\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.141970\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.109658\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.155062\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.063078\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.094664\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.087430\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.064141\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.149988\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.085935\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.106973\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.120169\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.129841\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.211046\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.088168\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.120703\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.101596\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.139820\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.142515\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.263839\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.184990\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.119238\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.093727\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.149865\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.085776\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.054741\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.105552\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.083461\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.065128\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.103516\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.133954\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.053423\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.123630\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.143622\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.213611\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.111213\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.091818\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.049343\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.073144\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.094506\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.073270\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.107217\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.104885\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.034472\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.060397\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.050014\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.125130\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.5687, Accuracy: 8788/10000 (88%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.307148\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.279923\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.273168\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.302685\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.150790\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.247277\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.316952\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.158781\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.133100\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.178912\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.113574\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.118016\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.373388\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.234532\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.134566\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.234409\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.038651\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.073110\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.027664\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.036343\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.030569\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.045674\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.135228\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.076477\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.028888\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.064735\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.067456\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.071885\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.044710\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.057104\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.097766\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.047508\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.056443\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.064903\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.083864\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.058541\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.144165\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.108377\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.035005\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.045034\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.034777\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.158910\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.049561\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.064700\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.059516\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.109302\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.037465\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.061442\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.096412\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.031659\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.036211\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.037433\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.069774\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.071555\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.015042\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.309525\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.108299\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.065205\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.200720\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.106117\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.086233\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.033573\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.154753\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.081507\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.046958\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.076422\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.052650\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.119286\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.060772\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.158143\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.049123\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.047306\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.123537\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.037230\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.043117\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.053243\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.076001\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.117486\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.043950\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.056602\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.075264\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.112789\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.066735\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.036470\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.087764\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.022691\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.099258\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.057781\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.109704\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.057065\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.331482\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.111820\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.127312\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.155178\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.164809\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.108252\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.168400\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.053420\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.123564\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.077145\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.105112\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.071669\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.039205\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.058835\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.064466\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.080290\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.094389\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.047453\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.090320\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.059242\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.128161\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.134939\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.086907\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.087675\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.105712\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.114415\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.079597\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.063901\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.101171\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.134205\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.195271\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.198871\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.116880\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.240035\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.185660\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.179561\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.128151\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.115958\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.129291\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.119995\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.116589\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.110620\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.118432\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.185325\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.257553\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.097893\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.184828\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.105825\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.073838\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.076006\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.069469\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.102671\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.116680\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.056933\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.122867\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.120696\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.110908\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.096380\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.047937\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.119582\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.249545\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.158025\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.202739\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.166436\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.132232\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.071115\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.248395\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.169918\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.115862\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.108662\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.159070\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.178139\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.105667\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.114877\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.195520\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.131479\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.141087\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.196606\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.123410\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.143047\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.318259\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.180803\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.183509\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.184555\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.177642\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.265979\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.189299\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.195393\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.212876\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.284661\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.222149\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.199327\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.128569\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.150260\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.249484\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.169721\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.181276\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.307518\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.227418\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.202015\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.218188\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.117581\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.145249\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.105342\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.253788\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.147924\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.215361\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.259876\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.228959\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.246840\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.250313\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.126595\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.186494\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.200150\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.214719\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.134440\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.224780\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.231708\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.235564\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.086848\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.186786\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.182964\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.126050\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.334987\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.108113\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.221053\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.123866\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.216657\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.185748\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.280374\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.214896\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.149409\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.125808\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.137983\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.116053\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.148665\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.117916\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.132900\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.084994\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.046553\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.093993\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.119279\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.203738\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.073768\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.071678\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.097328\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.059420\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.074208\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.112565\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.151842\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.024112\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.104723\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.033643\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.027072\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.066530\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.032948\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.116066\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.097701\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.070287\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.084612\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.091776\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.052918\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.072791\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.099153\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.104370\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.216581\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.137005\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.194934\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.136870\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.200213\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.221096\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.177287\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.089266\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.103106\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.164562\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.106438\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.094580\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.252023\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.195544\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.118939\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.133255\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.125318\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.092950\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.063657\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.147551\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.188406\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.115211\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.127809\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.141728\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.120151\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.072930\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.160715\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.151828\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.059981\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.115739\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.144730\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.072017\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.064404\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.098486\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.198396\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.145783\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.055063\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.053716\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.180754\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.111343\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.170552\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.111276\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.109491\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.123679\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.094928\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.129474\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.082998\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.136390\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.144376\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.035817\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.029066\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.093843\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.060532\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.115439\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.163070\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.072147\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.106124\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.098351\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.060198\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.074102\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.031452\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.052511\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.142690\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.079138\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.072613\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.030115\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.051413\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.107894\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.061481\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.074927\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.5647, Accuracy: 8772/10000 (88%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for partitions_number in numberOfPartitions:\n",
    "    print(f\"Running experiment with {partitions_number} partitions...\")\n",
    "\n",
    "    partitioned_data_pca = partition.balanced_dirichlet_partition(trainingset_pca, partitions_number=partitions_number, alpha=0.5)\n",
    "    pca_client_loaders = [\n",
    "        DataLoader(Subset(trainingset_pca, indices), batch_size=batch_size_train, shuffle=True)\n",
    "        for indices in partitioned_data_pca.values()\n",
    "    ]\n",
    "\n",
    "    num_clients = partitions_number\n",
    "    local_models_pca_strong = [copy.deepcopy(global_model_pca_strong) for _ in range(num_clients)]\n",
    "\n",
    "  # Pca strong\n",
    "    optimizer = optim.SGD(trial_model_pca_strong.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "    \n",
    "    train_losses = []\n",
    "    train_counter = []\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):  \n",
    "        train_fashion(epoch, trial_model_pca_strong, train_loader_reduced_pca, optimizer, log_interval, train_losses, train_counter)\n",
    "    \n",
    "\n",
    "    \n",
    "    test_losses_pca_strong = []\n",
    "    test_fashion(trial_model_pca_strong,train_loader_reduced_pca,test_losses_pca_strong)\n",
    "    \n",
    "    rounds_pca = 4\n",
    "    for round_idx in range(rounds_pca):\n",
    "        \n",
    "        print(f\"Round {round_idx + 1}/{rounds_pca}\")\n",
    "    \n",
    "        local_weights_pca = []\n",
    "        for client_idx, client_model in enumerate(local_models_pca_strong):\n",
    "            print(f\"Training client {client_idx + 1}\")\n",
    "            \n",
    "            optimizer = optim.SGD(client_model.parameters(), lr=learning_rate,\n",
    "                          momentum=momentum)\n",
    "    \n",
    "            train_losses = []\n",
    "            train_counter = []\n",
    "    \n",
    "    \n",
    "            for epoch in range(1, n_epochs + 1):  \n",
    "                train_fashion(epoch, client_model, pca_client_loaders[client_idx], optimizer, log_interval, train_losses, train_counter)\n",
    "            \n",
    "            client_weights = [param.data.numpy() for param in client_model.parameters()]\n",
    "            local_weights_pca.append(client_weights)\n",
    "            \n",
    "    \n",
    "        global_weights_pca = federated_averaging(local_weights_pca)\n",
    "    \n",
    "        distribute_global_model(global_weights_pca,local_models_pca_strong,single=False)\n",
    "    \n",
    "        distribute_global_model(global_weights_pca,global_model_pca_strong,single=True)\n",
    "        test_losses = []\n",
    "        test_fashion(global_model_pca_strong,test_loader_pca,test_losses)\n",
    "    \n",
    "        test_accuracies_classic = []\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader_pca:\n",
    "                output = global_model_classic(data)\n",
    "                pred = output.data.max(1, keepdim=True)[1]\n",
    "                correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "        accuracy = 100. * correct / len(test_loader_pca.dataset)\n",
    "        test_accuracies_classic.append(accuracy)\n",
    "    \n",
    "        # Save results for non-clustered classic\n",
    "        if partitions_number not in results[\"pca\"]:\n",
    "            results[\"pca\"][partitions_number] = {\"losses\": [], \"accuracy\": []}\n",
    "    \n",
    "        results[\"pca\"][partitions_number][\"losses\"].extend(test_losses)\n",
    "        results[\"pca\"][partitions_number][\"accuracy\"].extend(test_accuracies_classic)\n",
    "\n",
    "    ######################\n",
    "    import cluster\n",
    "    cluster = cluster.Cluster(num_clusters=4)\n",
    "    \n",
    "    targets = trainingset_pca.targets\n",
    "    num_classes = len(set(targets)) \n",
    "    clustered_data = cluster.apply_clustering(partitioned_data_pca, targets, num_classes)\n",
    "    \n",
    "    partitioned_data_pca_clustered = clustered_data\n",
    "\n",
    "    pca_client_loaders_clustered = [\n",
    "        DataLoader(Subset(trainingset_pca, indices), batch_size=batch_size_train, shuffle=True)\n",
    "        for indices in partitioned_data_pca_clustered.values()\n",
    "    ]\n",
    "\n",
    "    for round_idx in range(rounds_classic):\n",
    "        print(f\"Round {round_idx + 1}/{rounds_classic}\")\n",
    "\n",
    "        local_weights_pca = []\n",
    "        for client_idx, client_model in enumerate(local_models_pca_strong[0:num_clusters]):\n",
    "            print(f\"Training client {client_idx + 1}\")\n",
    "            \n",
    "            optimizer = optim.SGD(client_model.parameters(), lr=learning_rate,\n",
    "                          momentum=momentum)\n",
    "    \n",
    "            train_losses = []\n",
    "            train_counter = []\n",
    "    \n",
    "    \n",
    "            for epoch in range(1, n_epochs + 1):  \n",
    "                train_fashion(epoch, client_model, pca_client_loaders[client_idx], optimizer, log_interval, train_losses, train_counter)\n",
    "            \n",
    "            client_weights = [param.data.numpy() for param in client_model.parameters()]\n",
    "            local_weights_pca.append(client_weights)\n",
    "            \n",
    "    \n",
    "        global_weights_pca = federated_averaging(local_weights_pca)\n",
    "    \n",
    "        distribute_global_model(global_weights_pca,local_models_pca_strong,single=False)\n",
    "    \n",
    "        distribute_global_model(global_weights_pca,global_model_pca_strong,single=True)\n",
    "        test_losses = []\n",
    "        test_fashion(global_model_pca_strong,test_loader_pca,test_losses)\n",
    "    \n",
    "        test_accuracies_classic = []\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader_pca:\n",
    "                output = global_model_classic(data)\n",
    "                pred = output.data.max(1, keepdim=True)[1]\n",
    "                correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "        accuracy = 100. * correct / len(test_loader_pca.dataset)\n",
    "        test_accuracies_classic.append(accuracy)\n",
    "\n",
    "        # Save results for clustered classic\n",
    "        if partitions_number not in clusteredResults[\"pca\"]:\n",
    "            clusteredResults[\"pca\"][partitions_number] = {\"losses\": [], \"accuracy\": []}\n",
    "\n",
    "        clusteredResults[\"pca\"][partitions_number][\"losses\"].extend(test_losses)\n",
    "        clusteredResults[\"pca\"][partitions_number][\"accuracy\"].extend(test_accuracies_classic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results (Non-Clustered): {'classic': {4: {'losses': [0.6815479064941407, 0.49938775939941404, 0.46115848693847655, 0.4383513153076172], 'accuracy': [10.29, 10.05, 10.41, 10.14]}, 6: {'losses': [0.382756201171875, 0.38323160400390627, 0.3741429901123047, 0.36963440551757815], 'accuracy': [10.28, 10.22, 10.08, 10.48]}, 8: {'losses': [0.36661693725585937, 0.3617134796142578, 0.3648541442871094, 0.3626453094482422], 'accuracy': [10.42, 10.1, 10.52, 10.87]}, 10: {'losses': [0.3590808044433594, 0.3577126373291016, 0.35142200622558595, 0.3532148468017578], 'accuracy': [10.6, 9.53, 10.48, 9.72]}}, 'pca': {4: {'losses': [1.1178964111328125, 0.9523929016113282, 0.8969520141601562, 0.851038330078125], 'accuracy': [9.98, 10.22, 9.72, 10.25]}, 6: {'losses': [0.7265787658691406, 0.7113021057128907, 0.7031130065917969, 0.6795821533203125], 'accuracy': [10.22, 10.22, 9.68, 9.8]}, 8: {'losses': [0.6413265014648437, 0.6276532104492187, 0.6225778503417969, 0.6192710388183593], 'accuracy': [10.47, 10.23, 10.37, 10.12]}, 10: {'losses': [0.5939065734863281, 0.5915477111816406, 0.5883621154785156, 0.5806868286132812], 'accuracy': [10.25, 9.73, 10.24, 10.1]}}, 'autoencoder': {}}\n",
      "Final Results (Clustered): {'classic': {4: {'losses': [0.43703709716796874, 0.4280464233398438, 0.41145969848632813, 0.42101661376953126], 'accuracy': [10.17, 9.97, 10.26, 9.91]}, 6: {'losses': [0.3982194122314453, 0.395793017578125, 0.38184085693359376, 0.4105090576171875], 'accuracy': [9.9, 10.49, 10.04, 10.6]}, 8: {'losses': [0.40630611267089844, 0.43011572265625, 0.41488186645507813, 0.41762550048828123], 'accuracy': [10.14, 9.79, 9.97, 9.88]}, 10: {'losses': [0.42335987243652345, 0.43057445068359373, 0.4588637054443359, 0.4647010650634766], 'accuracy': [10.01, 10.33, 9.53, 9.97]}}, 'pca': {4: {'losses': [0.8079928405761718, 0.7724112243652344, 0.7576869506835937, 0.7453690246582031], 'accuracy': [10.01, 10.26, 10.32, 9.98]}, 6: {'losses': [0.6738732360839844, 0.6647598022460938, 0.6618483276367187, 0.6516339904785157], 'accuracy': [9.71, 9.8, 9.88, 10.21]}, 8: {'losses': [0.6119742736816406, 0.5993320007324219, 0.5925026550292969, 0.5916678833007812], 'accuracy': [10.34, 9.91, 9.61, 9.75]}, 10: {'losses': [0.5778182800292969, 0.5766717102050781, 0.5687302124023438, 0.564671142578125], 'accuracy': [10.43, 10.19, 10.06, 10.33]}}, 'autoencoder': {}}\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Results (Non-Clustered):\", results)\n",
    "print(\"Final Results (Clustered):\", clusteredResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder\n",
    "trainingset_auto = reduced_train_loader_auto.dataset\n",
    "trial_model_auto_strong = MultilayerPerceptron()\n",
    "global_model_auto_strong = MultilayerPerceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment with 4 partitions...\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.305623\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 2.285260\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.243470\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 2.215178\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 2.189984\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 2.149446\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 2.093956\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 2.045938\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 1.963553\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 1.930868\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 1.807138\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 1.812732\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 1.700588\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 1.644588\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 1.510034\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 1.431245\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.373331\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 1.308747\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 1.205835\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 1.221359\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 1.287130\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 1.249497\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 1.195723\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 1.061455\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 1.111764\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 1.048091\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 1.074982\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 1.075244\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 1.054406\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 1.026562\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 1.070561\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 1.020532\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.874660\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 0.799676\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.962271\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.778025\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.892540\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 0.960833\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.921042\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 0.957603\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 1.013607\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 0.903953\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 1.188197\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 0.882749\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.853341\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.609738\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.870133\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 0.906311\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.917742\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 0.624094\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.824442\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 0.811852\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.702677\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 0.895635\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.853636\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.806489\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.897616\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 0.762143\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.760305\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 0.838451\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.746447\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 0.729351\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.907385\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 0.757813\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.769012\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.819672\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.715137\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 0.755348\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.952395\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 0.722765\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.693037\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 1.003059\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.749189\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 0.674007\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.713164\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.887231\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.900026\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 0.741862\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.707743\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 0.741940\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.638554\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 0.790293\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.646757\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 0.730298\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.660082\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.604474\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.577710\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 0.717986\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.764400\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 0.680168\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.719793\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 0.620245\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.587301\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 0.644262\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.615960\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.718819\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.740230\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 0.652231\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.647861\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 0.639955\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.715560\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 0.696888\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.567605\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 0.557864\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.594705\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.683400\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.643939\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 0.585662\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.571824\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 0.670907\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.726442\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 0.617337\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.778220\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 0.741685\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.562745\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.656597\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.791925\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 0.648253\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.686026\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 0.739661\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.770406\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 0.608173\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.516234\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 0.678533\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.676388\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.616783\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.571708\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 0.757029\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.714731\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 0.672696\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.645976\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 0.790845\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.487021\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 0.588879\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.742141\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.865739\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.684825\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 0.516858\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.644211\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 0.657631\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.609271\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 0.690501\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.648565\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 0.712209\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.520336\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.636222\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.538596\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 0.738988\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.578170\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 0.668673\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.555066\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 0.694112\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.573918\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 0.782806\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.560060\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.560477\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.383929\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 0.609130\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.708394\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 0.678216\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.665215\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 0.704617\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.534947\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 0.550140\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.743606\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.624184\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.726487\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 0.644344\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.594077\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 0.587714\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.531475\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 0.585626\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.479359\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 0.611030\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.474313\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.519337\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.560814\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 0.516692\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.600148\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 0.439426\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.573198\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 0.476883\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.609691\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 0.548169\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.606311\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.592024\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.576579\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 0.524396\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.669360\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 0.690327\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.404924\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 0.685744\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.878359\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 0.778573\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.619709\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.550442\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.683426\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 0.637364\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.551059\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 0.575519\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.589048\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 0.681942\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.564750\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 0.634734\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.537818\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.758485\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.732683\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 0.672281\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.503376\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 0.758677\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.572665\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 0.756332\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.630457\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 0.553525\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.535239\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.710735\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.517398\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 0.518434\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.663229\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 0.535142\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.644023\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 0.508641\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.631787\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 0.602658\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.547028\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.593982\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.497657\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 0.488520\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.702511\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 0.654185\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.540472\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 0.467970\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.498000\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 0.543186\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.648355\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.553810\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.739888\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 0.655017\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.694288\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 0.475826\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.660057\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 0.349010\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.453427\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 0.644678\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.561129\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.528367\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.476209\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 0.758832\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.437555\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 0.538120\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.622558\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 0.632234\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.563674\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 0.543679\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.577335\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.675743\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.759968\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 0.468619\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.401797\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 0.675795\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.654217\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 0.647530\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.514856\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 0.464384\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.507234\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.544295\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.519969\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 0.559328\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.412134\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 0.541147\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.651755\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 0.616875\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.441850\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 0.531724\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.535177\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.604550\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.531890\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 0.675466\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.576035\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 0.618630\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.578892\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 0.742898\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.379317\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 0.532746\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.565214\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.550672\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.523178\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 0.517782\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.490451\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 0.560603\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.416274\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 0.448901\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.661578\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 0.567617\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.645884\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.357107\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.580361\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 0.486256\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.467083\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 0.586706\n",
      "\n",
      "Test set: Avg. loss: 0.5459, Accuracy: 48366/60000 (81%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/23974 (0%)]\tLoss: 2.272871\n",
      "Train Epoch: 1 [1000/23974 (4%)]\tLoss: 2.183159\n",
      "Train Epoch: 1 [2000/23974 (8%)]\tLoss: 2.103994\n",
      "Train Epoch: 1 [3000/23974 (12%)]\tLoss: 1.992606\n",
      "Train Epoch: 1 [4000/23974 (17%)]\tLoss: 1.882282\n",
      "Train Epoch: 1 [5000/23974 (21%)]\tLoss: 1.952309\n",
      "Train Epoch: 1 [6000/23974 (25%)]\tLoss: 1.883049\n",
      "Train Epoch: 1 [7000/23974 (29%)]\tLoss: 1.768557\n",
      "Train Epoch: 1 [8000/23974 (33%)]\tLoss: 1.787241\n",
      "Train Epoch: 1 [9000/23974 (38%)]\tLoss: 1.588431\n",
      "Train Epoch: 1 [10000/23974 (42%)]\tLoss: 1.616940\n",
      "Train Epoch: 1 [11000/23974 (46%)]\tLoss: 1.510664\n",
      "Train Epoch: 1 [12000/23974 (50%)]\tLoss: 1.358329\n",
      "Train Epoch: 1 [13000/23974 (54%)]\tLoss: 1.428405\n",
      "Train Epoch: 1 [14000/23974 (58%)]\tLoss: 1.171079\n",
      "Train Epoch: 1 [15000/23974 (62%)]\tLoss: 1.268985\n",
      "Train Epoch: 1 [16000/23974 (67%)]\tLoss: 1.157420\n",
      "Train Epoch: 1 [17000/23974 (71%)]\tLoss: 1.043982\n",
      "Train Epoch: 1 [18000/23974 (75%)]\tLoss: 1.119510\n",
      "Train Epoch: 1 [19000/23974 (79%)]\tLoss: 0.996156\n",
      "Train Epoch: 1 [20000/23974 (83%)]\tLoss: 0.917649\n",
      "Train Epoch: 1 [21000/23974 (88%)]\tLoss: 1.012133\n",
      "Train Epoch: 1 [22000/23974 (92%)]\tLoss: 1.039341\n",
      "Train Epoch: 1 [23000/23974 (96%)]\tLoss: 0.870579\n",
      "Train Epoch: 2 [0/23974 (0%)]\tLoss: 1.092656\n",
      "Train Epoch: 2 [1000/23974 (4%)]\tLoss: 0.940651\n",
      "Train Epoch: 2 [2000/23974 (8%)]\tLoss: 0.892506\n",
      "Train Epoch: 2 [3000/23974 (12%)]\tLoss: 0.697032\n",
      "Train Epoch: 2 [4000/23974 (17%)]\tLoss: 0.754172\n",
      "Train Epoch: 2 [5000/23974 (21%)]\tLoss: 0.949882\n",
      "Train Epoch: 2 [6000/23974 (25%)]\tLoss: 0.756424\n",
      "Train Epoch: 2 [7000/23974 (29%)]\tLoss: 0.726088\n",
      "Train Epoch: 2 [8000/23974 (33%)]\tLoss: 0.788599\n",
      "Train Epoch: 2 [9000/23974 (38%)]\tLoss: 0.697510\n",
      "Train Epoch: 2 [10000/23974 (42%)]\tLoss: 0.733283\n",
      "Train Epoch: 2 [11000/23974 (46%)]\tLoss: 0.802241\n",
      "Train Epoch: 2 [12000/23974 (50%)]\tLoss: 0.887237\n",
      "Train Epoch: 2 [13000/23974 (54%)]\tLoss: 0.727387\n",
      "Train Epoch: 2 [14000/23974 (58%)]\tLoss: 0.732638\n",
      "Train Epoch: 2 [15000/23974 (62%)]\tLoss: 0.793189\n",
      "Train Epoch: 2 [16000/23974 (67%)]\tLoss: 0.709033\n",
      "Train Epoch: 2 [17000/23974 (71%)]\tLoss: 0.844709\n",
      "Train Epoch: 2 [18000/23974 (75%)]\tLoss: 0.784611\n",
      "Train Epoch: 2 [19000/23974 (79%)]\tLoss: 0.744415\n",
      "Train Epoch: 2 [20000/23974 (83%)]\tLoss: 0.640123\n",
      "Train Epoch: 2 [21000/23974 (88%)]\tLoss: 0.595621\n",
      "Train Epoch: 2 [22000/23974 (92%)]\tLoss: 0.681056\n",
      "Train Epoch: 2 [23000/23974 (96%)]\tLoss: 0.707815\n",
      "Train Epoch: 3 [0/23974 (0%)]\tLoss: 0.770938\n",
      "Train Epoch: 3 [1000/23974 (4%)]\tLoss: 0.737339\n",
      "Train Epoch: 3 [2000/23974 (8%)]\tLoss: 0.619292\n",
      "Train Epoch: 3 [3000/23974 (12%)]\tLoss: 0.626415\n",
      "Train Epoch: 3 [4000/23974 (17%)]\tLoss: 0.637007\n",
      "Train Epoch: 3 [5000/23974 (21%)]\tLoss: 0.518825\n",
      "Train Epoch: 3 [6000/23974 (25%)]\tLoss: 0.592189\n",
      "Train Epoch: 3 [7000/23974 (29%)]\tLoss: 0.710971\n",
      "Train Epoch: 3 [8000/23974 (33%)]\tLoss: 0.545548\n",
      "Train Epoch: 3 [9000/23974 (38%)]\tLoss: 0.796914\n",
      "Train Epoch: 3 [10000/23974 (42%)]\tLoss: 0.678905\n",
      "Train Epoch: 3 [11000/23974 (46%)]\tLoss: 0.622134\n",
      "Train Epoch: 3 [12000/23974 (50%)]\tLoss: 0.600559\n",
      "Train Epoch: 3 [13000/23974 (54%)]\tLoss: 0.591802\n",
      "Train Epoch: 3 [14000/23974 (58%)]\tLoss: 0.625407\n",
      "Train Epoch: 3 [15000/23974 (62%)]\tLoss: 0.592336\n",
      "Train Epoch: 3 [16000/23974 (67%)]\tLoss: 0.608730\n",
      "Train Epoch: 3 [17000/23974 (71%)]\tLoss: 0.559561\n",
      "Train Epoch: 3 [18000/23974 (75%)]\tLoss: 0.727246\n",
      "Train Epoch: 3 [19000/23974 (79%)]\tLoss: 0.500687\n",
      "Train Epoch: 3 [20000/23974 (83%)]\tLoss: 0.612507\n",
      "Train Epoch: 3 [21000/23974 (88%)]\tLoss: 0.646828\n",
      "Train Epoch: 3 [22000/23974 (92%)]\tLoss: 0.653128\n",
      "Train Epoch: 3 [23000/23974 (96%)]\tLoss: 0.643478\n",
      "Train Epoch: 4 [0/23974 (0%)]\tLoss: 0.614137\n",
      "Train Epoch: 4 [1000/23974 (4%)]\tLoss: 0.567563\n",
      "Train Epoch: 4 [2000/23974 (8%)]\tLoss: 0.546637\n",
      "Train Epoch: 4 [3000/23974 (12%)]\tLoss: 0.570457\n",
      "Train Epoch: 4 [4000/23974 (17%)]\tLoss: 0.372575\n",
      "Train Epoch: 4 [5000/23974 (21%)]\tLoss: 0.568518\n",
      "Train Epoch: 4 [6000/23974 (25%)]\tLoss: 0.538734\n",
      "Train Epoch: 4 [7000/23974 (29%)]\tLoss: 0.659333\n",
      "Train Epoch: 4 [8000/23974 (33%)]\tLoss: 0.516908\n",
      "Train Epoch: 4 [9000/23974 (38%)]\tLoss: 0.621769\n",
      "Train Epoch: 4 [10000/23974 (42%)]\tLoss: 0.547986\n",
      "Train Epoch: 4 [11000/23974 (46%)]\tLoss: 0.612034\n",
      "Train Epoch: 4 [12000/23974 (50%)]\tLoss: 0.460556\n",
      "Train Epoch: 4 [13000/23974 (54%)]\tLoss: 0.448603\n",
      "Train Epoch: 4 [14000/23974 (58%)]\tLoss: 0.510500\n",
      "Train Epoch: 4 [15000/23974 (62%)]\tLoss: 0.711830\n",
      "Train Epoch: 4 [16000/23974 (67%)]\tLoss: 0.433041\n",
      "Train Epoch: 4 [17000/23974 (71%)]\tLoss: 0.566975\n",
      "Train Epoch: 4 [18000/23974 (75%)]\tLoss: 0.496814\n",
      "Train Epoch: 4 [19000/23974 (79%)]\tLoss: 0.386036\n",
      "Train Epoch: 4 [20000/23974 (83%)]\tLoss: 0.682404\n",
      "Train Epoch: 4 [21000/23974 (88%)]\tLoss: 0.537917\n",
      "Train Epoch: 4 [22000/23974 (92%)]\tLoss: 0.632629\n",
      "Train Epoch: 4 [23000/23974 (96%)]\tLoss: 0.384048\n",
      "Train Epoch: 5 [0/23974 (0%)]\tLoss: 0.536736\n",
      "Train Epoch: 5 [1000/23974 (4%)]\tLoss: 0.626855\n",
      "Train Epoch: 5 [2000/23974 (8%)]\tLoss: 0.627106\n",
      "Train Epoch: 5 [3000/23974 (12%)]\tLoss: 0.763804\n",
      "Train Epoch: 5 [4000/23974 (17%)]\tLoss: 0.707774\n",
      "Train Epoch: 5 [5000/23974 (21%)]\tLoss: 0.588916\n",
      "Train Epoch: 5 [6000/23974 (25%)]\tLoss: 0.583848\n",
      "Train Epoch: 5 [7000/23974 (29%)]\tLoss: 0.482912\n",
      "Train Epoch: 5 [8000/23974 (33%)]\tLoss: 0.638480\n",
      "Train Epoch: 5 [9000/23974 (38%)]\tLoss: 0.753703\n",
      "Train Epoch: 5 [10000/23974 (42%)]\tLoss: 0.503883\n",
      "Train Epoch: 5 [11000/23974 (46%)]\tLoss: 0.522698\n",
      "Train Epoch: 5 [12000/23974 (50%)]\tLoss: 0.395364\n",
      "Train Epoch: 5 [13000/23974 (54%)]\tLoss: 0.432702\n",
      "Train Epoch: 5 [14000/23974 (58%)]\tLoss: 0.405062\n",
      "Train Epoch: 5 [15000/23974 (62%)]\tLoss: 0.486650\n",
      "Train Epoch: 5 [16000/23974 (67%)]\tLoss: 0.718647\n",
      "Train Epoch: 5 [17000/23974 (71%)]\tLoss: 0.645377\n",
      "Train Epoch: 5 [18000/23974 (75%)]\tLoss: 0.535689\n",
      "Train Epoch: 5 [19000/23974 (79%)]\tLoss: 0.546149\n",
      "Train Epoch: 5 [20000/23974 (83%)]\tLoss: 0.486026\n",
      "Train Epoch: 5 [21000/23974 (88%)]\tLoss: 0.573789\n",
      "Train Epoch: 5 [22000/23974 (92%)]\tLoss: 0.669480\n",
      "Train Epoch: 5 [23000/23974 (96%)]\tLoss: 0.535616\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7961 (0%)]\tLoss: 2.299603\n",
      "Train Epoch: 1 [1000/7961 (12%)]\tLoss: 2.194627\n",
      "Train Epoch: 1 [2000/7961 (25%)]\tLoss: 1.994055\n",
      "Train Epoch: 1 [3000/7961 (38%)]\tLoss: 1.948582\n",
      "Train Epoch: 1 [4000/7961 (50%)]\tLoss: 1.808883\n",
      "Train Epoch: 1 [5000/7961 (62%)]\tLoss: 1.959624\n",
      "Train Epoch: 1 [6000/7961 (75%)]\tLoss: 1.731048\n",
      "Train Epoch: 1 [7000/7961 (88%)]\tLoss: 1.705873\n",
      "Train Epoch: 2 [0/7961 (0%)]\tLoss: 1.660342\n",
      "Train Epoch: 2 [1000/7961 (12%)]\tLoss: 1.570957\n",
      "Train Epoch: 2 [2000/7961 (25%)]\tLoss: 1.354983\n",
      "Train Epoch: 2 [3000/7961 (38%)]\tLoss: 1.535405\n",
      "Train Epoch: 2 [4000/7961 (50%)]\tLoss: 1.482971\n",
      "Train Epoch: 2 [5000/7961 (62%)]\tLoss: 1.445386\n",
      "Train Epoch: 2 [6000/7961 (75%)]\tLoss: 1.406336\n",
      "Train Epoch: 2 [7000/7961 (88%)]\tLoss: 1.341734\n",
      "Train Epoch: 3 [0/7961 (0%)]\tLoss: 1.494335\n",
      "Train Epoch: 3 [1000/7961 (12%)]\tLoss: 1.377780\n",
      "Train Epoch: 3 [2000/7961 (25%)]\tLoss: 1.345264\n",
      "Train Epoch: 3 [3000/7961 (38%)]\tLoss: 1.295511\n",
      "Train Epoch: 3 [4000/7961 (50%)]\tLoss: 1.268608\n",
      "Train Epoch: 3 [5000/7961 (62%)]\tLoss: 1.225969\n",
      "Train Epoch: 3 [6000/7961 (75%)]\tLoss: 1.093071\n",
      "Train Epoch: 3 [7000/7961 (88%)]\tLoss: 1.081300\n",
      "Train Epoch: 4 [0/7961 (0%)]\tLoss: 1.281799\n",
      "Train Epoch: 4 [1000/7961 (12%)]\tLoss: 1.237918\n",
      "Train Epoch: 4 [2000/7961 (25%)]\tLoss: 1.192278\n",
      "Train Epoch: 4 [3000/7961 (38%)]\tLoss: 0.923240\n",
      "Train Epoch: 4 [4000/7961 (50%)]\tLoss: 0.995044\n",
      "Train Epoch: 4 [5000/7961 (62%)]\tLoss: 1.017201\n",
      "Train Epoch: 4 [6000/7961 (75%)]\tLoss: 1.182285\n",
      "Train Epoch: 4 [7000/7961 (88%)]\tLoss: 1.106509\n",
      "Train Epoch: 5 [0/7961 (0%)]\tLoss: 1.079140\n",
      "Train Epoch: 5 [1000/7961 (12%)]\tLoss: 0.998589\n",
      "Train Epoch: 5 [2000/7961 (25%)]\tLoss: 0.875268\n",
      "Train Epoch: 5 [3000/7961 (38%)]\tLoss: 0.889908\n",
      "Train Epoch: 5 [4000/7961 (50%)]\tLoss: 1.152429\n",
      "Train Epoch: 5 [5000/7961 (62%)]\tLoss: 0.955137\n",
      "Train Epoch: 5 [6000/7961 (75%)]\tLoss: 1.030313\n",
      "Train Epoch: 5 [7000/7961 (88%)]\tLoss: 0.774727\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/15584 (0%)]\tLoss: 2.327156\n",
      "Train Epoch: 1 [1000/15584 (6%)]\tLoss: 2.252644\n",
      "Train Epoch: 1 [2000/15584 (13%)]\tLoss: 2.238243\n",
      "Train Epoch: 1 [3000/15584 (19%)]\tLoss: 2.137995\n",
      "Train Epoch: 1 [4000/15584 (26%)]\tLoss: 2.068346\n",
      "Train Epoch: 1 [5000/15584 (32%)]\tLoss: 1.994355\n",
      "Train Epoch: 1 [6000/15584 (38%)]\tLoss: 1.989188\n",
      "Train Epoch: 1 [7000/15584 (45%)]\tLoss: 1.881437\n",
      "Train Epoch: 1 [8000/15584 (51%)]\tLoss: 1.865100\n",
      "Train Epoch: 1 [9000/15584 (58%)]\tLoss: 1.795082\n",
      "Train Epoch: 1 [10000/15584 (64%)]\tLoss: 1.600489\n",
      "Train Epoch: 1 [11000/15584 (71%)]\tLoss: 1.518416\n",
      "Train Epoch: 1 [12000/15584 (77%)]\tLoss: 1.517083\n",
      "Train Epoch: 1 [13000/15584 (83%)]\tLoss: 1.471505\n",
      "Train Epoch: 1 [14000/15584 (90%)]\tLoss: 1.388708\n",
      "Train Epoch: 1 [15000/15584 (96%)]\tLoss: 1.199559\n",
      "Train Epoch: 2 [0/15584 (0%)]\tLoss: 1.252663\n",
      "Train Epoch: 2 [1000/15584 (6%)]\tLoss: 1.315376\n",
      "Train Epoch: 2 [2000/15584 (13%)]\tLoss: 1.212289\n",
      "Train Epoch: 2 [3000/15584 (19%)]\tLoss: 1.316055\n",
      "Train Epoch: 2 [4000/15584 (26%)]\tLoss: 1.000174\n",
      "Train Epoch: 2 [5000/15584 (32%)]\tLoss: 1.112994\n",
      "Train Epoch: 2 [6000/15584 (38%)]\tLoss: 0.966787\n",
      "Train Epoch: 2 [7000/15584 (45%)]\tLoss: 0.913587\n",
      "Train Epoch: 2 [8000/15584 (51%)]\tLoss: 0.885165\n",
      "Train Epoch: 2 [9000/15584 (58%)]\tLoss: 1.113304\n",
      "Train Epoch: 2 [10000/15584 (64%)]\tLoss: 1.017603\n",
      "Train Epoch: 2 [11000/15584 (71%)]\tLoss: 0.986278\n",
      "Train Epoch: 2 [12000/15584 (77%)]\tLoss: 0.817531\n",
      "Train Epoch: 2 [13000/15584 (83%)]\tLoss: 0.850704\n",
      "Train Epoch: 2 [14000/15584 (90%)]\tLoss: 0.841539\n",
      "Train Epoch: 2 [15000/15584 (96%)]\tLoss: 0.849480\n",
      "Train Epoch: 3 [0/15584 (0%)]\tLoss: 0.713166\n",
      "Train Epoch: 3 [1000/15584 (6%)]\tLoss: 0.762881\n",
      "Train Epoch: 3 [2000/15584 (13%)]\tLoss: 0.729854\n",
      "Train Epoch: 3 [3000/15584 (19%)]\tLoss: 0.897407\n",
      "Train Epoch: 3 [4000/15584 (26%)]\tLoss: 0.720548\n",
      "Train Epoch: 3 [5000/15584 (32%)]\tLoss: 0.752227\n",
      "Train Epoch: 3 [6000/15584 (38%)]\tLoss: 0.647443\n",
      "Train Epoch: 3 [7000/15584 (45%)]\tLoss: 0.758175\n",
      "Train Epoch: 3 [8000/15584 (51%)]\tLoss: 0.726032\n",
      "Train Epoch: 3 [9000/15584 (58%)]\tLoss: 0.726791\n",
      "Train Epoch: 3 [10000/15584 (64%)]\tLoss: 0.828104\n",
      "Train Epoch: 3 [11000/15584 (71%)]\tLoss: 0.697173\n",
      "Train Epoch: 3 [12000/15584 (77%)]\tLoss: 0.751864\n",
      "Train Epoch: 3 [13000/15584 (83%)]\tLoss: 0.807205\n",
      "Train Epoch: 3 [14000/15584 (90%)]\tLoss: 0.778319\n",
      "Train Epoch: 3 [15000/15584 (96%)]\tLoss: 0.655098\n",
      "Train Epoch: 4 [0/15584 (0%)]\tLoss: 0.736055\n",
      "Train Epoch: 4 [1000/15584 (6%)]\tLoss: 0.668293\n",
      "Train Epoch: 4 [2000/15584 (13%)]\tLoss: 0.701047\n",
      "Train Epoch: 4 [3000/15584 (19%)]\tLoss: 0.647617\n",
      "Train Epoch: 4 [4000/15584 (26%)]\tLoss: 0.598125\n",
      "Train Epoch: 4 [5000/15584 (32%)]\tLoss: 0.544271\n",
      "Train Epoch: 4 [6000/15584 (38%)]\tLoss: 0.526752\n",
      "Train Epoch: 4 [7000/15584 (45%)]\tLoss: 0.619912\n",
      "Train Epoch: 4 [8000/15584 (51%)]\tLoss: 0.711638\n",
      "Train Epoch: 4 [9000/15584 (58%)]\tLoss: 0.646322\n",
      "Train Epoch: 4 [10000/15584 (64%)]\tLoss: 0.630708\n",
      "Train Epoch: 4 [11000/15584 (71%)]\tLoss: 0.721910\n",
      "Train Epoch: 4 [12000/15584 (77%)]\tLoss: 0.700518\n",
      "Train Epoch: 4 [13000/15584 (83%)]\tLoss: 0.504276\n",
      "Train Epoch: 4 [14000/15584 (90%)]\tLoss: 0.663552\n",
      "Train Epoch: 4 [15000/15584 (96%)]\tLoss: 0.579137\n",
      "Train Epoch: 5 [0/15584 (0%)]\tLoss: 0.588650\n",
      "Train Epoch: 5 [1000/15584 (6%)]\tLoss: 0.448343\n",
      "Train Epoch: 5 [2000/15584 (13%)]\tLoss: 0.642944\n",
      "Train Epoch: 5 [3000/15584 (19%)]\tLoss: 0.407656\n",
      "Train Epoch: 5 [4000/15584 (26%)]\tLoss: 0.373092\n",
      "Train Epoch: 5 [5000/15584 (32%)]\tLoss: 0.556239\n",
      "Train Epoch: 5 [6000/15584 (38%)]\tLoss: 0.497561\n",
      "Train Epoch: 5 [7000/15584 (45%)]\tLoss: 0.516383\n",
      "Train Epoch: 5 [8000/15584 (51%)]\tLoss: 0.518870\n",
      "Train Epoch: 5 [9000/15584 (58%)]\tLoss: 0.631768\n",
      "Train Epoch: 5 [10000/15584 (64%)]\tLoss: 0.565870\n",
      "Train Epoch: 5 [11000/15584 (71%)]\tLoss: 0.490436\n",
      "Train Epoch: 5 [12000/15584 (77%)]\tLoss: 0.504429\n",
      "Train Epoch: 5 [13000/15584 (83%)]\tLoss: 0.447646\n",
      "Train Epoch: 5 [14000/15584 (90%)]\tLoss: 0.607834\n",
      "Train Epoch: 5 [15000/15584 (96%)]\tLoss: 0.527658\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/12481 (0%)]\tLoss: 2.360551\n",
      "Train Epoch: 1 [1000/12481 (8%)]\tLoss: 2.237914\n",
      "Train Epoch: 1 [2000/12481 (16%)]\tLoss: 2.156360\n",
      "Train Epoch: 1 [3000/12481 (24%)]\tLoss: 1.956609\n",
      "Train Epoch: 1 [4000/12481 (32%)]\tLoss: 1.879652\n",
      "Train Epoch: 1 [5000/12481 (40%)]\tLoss: 1.519962\n",
      "Train Epoch: 1 [6000/12481 (48%)]\tLoss: 1.621477\n",
      "Train Epoch: 1 [7000/12481 (56%)]\tLoss: 1.316814\n",
      "Train Epoch: 1 [8000/12481 (64%)]\tLoss: 1.218271\n",
      "Train Epoch: 1 [9000/12481 (72%)]\tLoss: 1.033250\n",
      "Train Epoch: 1 [10000/12481 (80%)]\tLoss: 1.145903\n",
      "Train Epoch: 1 [11000/12481 (88%)]\tLoss: 1.184095\n",
      "Train Epoch: 1 [12000/12481 (96%)]\tLoss: 0.877380\n",
      "Train Epoch: 2 [0/12481 (0%)]\tLoss: 0.898748\n",
      "Train Epoch: 2 [1000/12481 (8%)]\tLoss: 1.016695\n",
      "Train Epoch: 2 [2000/12481 (16%)]\tLoss: 0.891030\n",
      "Train Epoch: 2 [3000/12481 (24%)]\tLoss: 0.690468\n",
      "Train Epoch: 2 [4000/12481 (32%)]\tLoss: 0.856666\n",
      "Train Epoch: 2 [5000/12481 (40%)]\tLoss: 0.786836\n",
      "Train Epoch: 2 [6000/12481 (48%)]\tLoss: 0.582671\n",
      "Train Epoch: 2 [7000/12481 (56%)]\tLoss: 0.687785\n",
      "Train Epoch: 2 [8000/12481 (64%)]\tLoss: 0.695760\n",
      "Train Epoch: 2 [9000/12481 (72%)]\tLoss: 0.701528\n",
      "Train Epoch: 2 [10000/12481 (80%)]\tLoss: 0.556220\n",
      "Train Epoch: 2 [11000/12481 (88%)]\tLoss: 0.544515\n",
      "Train Epoch: 2 [12000/12481 (96%)]\tLoss: 0.634951\n",
      "Train Epoch: 3 [0/12481 (0%)]\tLoss: 0.776422\n",
      "Train Epoch: 3 [1000/12481 (8%)]\tLoss: 0.636394\n",
      "Train Epoch: 3 [2000/12481 (16%)]\tLoss: 0.528363\n",
      "Train Epoch: 3 [3000/12481 (24%)]\tLoss: 0.498001\n",
      "Train Epoch: 3 [4000/12481 (32%)]\tLoss: 0.569503\n",
      "Train Epoch: 3 [5000/12481 (40%)]\tLoss: 0.718921\n",
      "Train Epoch: 3 [6000/12481 (48%)]\tLoss: 0.540907\n",
      "Train Epoch: 3 [7000/12481 (56%)]\tLoss: 0.463449\n",
      "Train Epoch: 3 [8000/12481 (64%)]\tLoss: 0.577653\n",
      "Train Epoch: 3 [9000/12481 (72%)]\tLoss: 0.466807\n",
      "Train Epoch: 3 [10000/12481 (80%)]\tLoss: 0.566418\n",
      "Train Epoch: 3 [11000/12481 (88%)]\tLoss: 0.561847\n",
      "Train Epoch: 3 [12000/12481 (96%)]\tLoss: 0.468327\n",
      "Train Epoch: 4 [0/12481 (0%)]\tLoss: 0.514345\n",
      "Train Epoch: 4 [1000/12481 (8%)]\tLoss: 0.349969\n",
      "Train Epoch: 4 [2000/12481 (16%)]\tLoss: 0.655894\n",
      "Train Epoch: 4 [3000/12481 (24%)]\tLoss: 0.641085\n",
      "Train Epoch: 4 [4000/12481 (32%)]\tLoss: 0.450280\n",
      "Train Epoch: 4 [5000/12481 (40%)]\tLoss: 0.453171\n",
      "Train Epoch: 4 [6000/12481 (48%)]\tLoss: 0.455500\n",
      "Train Epoch: 4 [7000/12481 (56%)]\tLoss: 0.509102\n",
      "Train Epoch: 4 [8000/12481 (64%)]\tLoss: 0.584322\n",
      "Train Epoch: 4 [9000/12481 (72%)]\tLoss: 0.351811\n",
      "Train Epoch: 4 [10000/12481 (80%)]\tLoss: 0.486411\n",
      "Train Epoch: 4 [11000/12481 (88%)]\tLoss: 0.457662\n",
      "Train Epoch: 4 [12000/12481 (96%)]\tLoss: 0.511469\n",
      "Train Epoch: 5 [0/12481 (0%)]\tLoss: 0.626730\n",
      "Train Epoch: 5 [1000/12481 (8%)]\tLoss: 0.407294\n",
      "Train Epoch: 5 [2000/12481 (16%)]\tLoss: 0.323150\n",
      "Train Epoch: 5 [3000/12481 (24%)]\tLoss: 0.391109\n",
      "Train Epoch: 5 [4000/12481 (32%)]\tLoss: 0.490274\n",
      "Train Epoch: 5 [5000/12481 (40%)]\tLoss: 0.537207\n",
      "Train Epoch: 5 [6000/12481 (48%)]\tLoss: 0.458696\n",
      "Train Epoch: 5 [7000/12481 (56%)]\tLoss: 0.378660\n",
      "Train Epoch: 5 [8000/12481 (64%)]\tLoss: 0.491842\n",
      "Train Epoch: 5 [9000/12481 (72%)]\tLoss: 0.508473\n",
      "Train Epoch: 5 [10000/12481 (80%)]\tLoss: 0.453862\n",
      "Train Epoch: 5 [11000/12481 (88%)]\tLoss: 0.536252\n",
      "Train Epoch: 5 [12000/12481 (96%)]\tLoss: 0.528297\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "4\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.2434, Accuracy: 5584/10000 (56%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/23974 (0%)]\tLoss: 1.080750\n",
      "Train Epoch: 1 [1000/23974 (4%)]\tLoss: 0.797888\n",
      "Train Epoch: 1 [2000/23974 (8%)]\tLoss: 0.730218\n",
      "Train Epoch: 1 [3000/23974 (12%)]\tLoss: 0.841231\n",
      "Train Epoch: 1 [4000/23974 (17%)]\tLoss: 0.760786\n",
      "Train Epoch: 1 [5000/23974 (21%)]\tLoss: 0.676739\n",
      "Train Epoch: 1 [6000/23974 (25%)]\tLoss: 0.690967\n",
      "Train Epoch: 1 [7000/23974 (29%)]\tLoss: 0.625190\n",
      "Train Epoch: 1 [8000/23974 (33%)]\tLoss: 0.663520\n",
      "Train Epoch: 1 [9000/23974 (38%)]\tLoss: 0.719047\n",
      "Train Epoch: 1 [10000/23974 (42%)]\tLoss: 0.696351\n",
      "Train Epoch: 1 [11000/23974 (46%)]\tLoss: 0.651784\n",
      "Train Epoch: 1 [12000/23974 (50%)]\tLoss: 0.736313\n",
      "Train Epoch: 1 [13000/23974 (54%)]\tLoss: 0.581275\n",
      "Train Epoch: 1 [14000/23974 (58%)]\tLoss: 0.602189\n",
      "Train Epoch: 1 [15000/23974 (62%)]\tLoss: 0.737482\n",
      "Train Epoch: 1 [16000/23974 (67%)]\tLoss: 0.673510\n",
      "Train Epoch: 1 [17000/23974 (71%)]\tLoss: 0.529375\n",
      "Train Epoch: 1 [18000/23974 (75%)]\tLoss: 0.506206\n",
      "Train Epoch: 1 [19000/23974 (79%)]\tLoss: 0.654358\n",
      "Train Epoch: 1 [20000/23974 (83%)]\tLoss: 0.671328\n",
      "Train Epoch: 1 [21000/23974 (88%)]\tLoss: 0.473589\n",
      "Train Epoch: 1 [22000/23974 (92%)]\tLoss: 0.562238\n",
      "Train Epoch: 1 [23000/23974 (96%)]\tLoss: 0.585874\n",
      "Train Epoch: 2 [0/23974 (0%)]\tLoss: 0.830982\n",
      "Train Epoch: 2 [1000/23974 (4%)]\tLoss: 0.644283\n",
      "Train Epoch: 2 [2000/23974 (8%)]\tLoss: 0.559590\n",
      "Train Epoch: 2 [3000/23974 (12%)]\tLoss: 0.521639\n",
      "Train Epoch: 2 [4000/23974 (17%)]\tLoss: 0.521185\n",
      "Train Epoch: 2 [5000/23974 (21%)]\tLoss: 0.638784\n",
      "Train Epoch: 2 [6000/23974 (25%)]\tLoss: 0.487069\n",
      "Train Epoch: 2 [7000/23974 (29%)]\tLoss: 0.401419\n",
      "Train Epoch: 2 [8000/23974 (33%)]\tLoss: 0.632105\n",
      "Train Epoch: 2 [9000/23974 (38%)]\tLoss: 0.594290\n",
      "Train Epoch: 2 [10000/23974 (42%)]\tLoss: 0.668042\n",
      "Train Epoch: 2 [11000/23974 (46%)]\tLoss: 0.478271\n",
      "Train Epoch: 2 [12000/23974 (50%)]\tLoss: 0.548178\n",
      "Train Epoch: 2 [13000/23974 (54%)]\tLoss: 0.557021\n",
      "Train Epoch: 2 [14000/23974 (58%)]\tLoss: 0.516343\n",
      "Train Epoch: 2 [15000/23974 (62%)]\tLoss: 0.453628\n",
      "Train Epoch: 2 [16000/23974 (67%)]\tLoss: 0.403677\n",
      "Train Epoch: 2 [17000/23974 (71%)]\tLoss: 0.620372\n",
      "Train Epoch: 2 [18000/23974 (75%)]\tLoss: 0.592424\n",
      "Train Epoch: 2 [19000/23974 (79%)]\tLoss: 0.422112\n",
      "Train Epoch: 2 [20000/23974 (83%)]\tLoss: 0.484014\n",
      "Train Epoch: 2 [21000/23974 (88%)]\tLoss: 0.508799\n",
      "Train Epoch: 2 [22000/23974 (92%)]\tLoss: 0.658292\n",
      "Train Epoch: 2 [23000/23974 (96%)]\tLoss: 0.507905\n",
      "Train Epoch: 3 [0/23974 (0%)]\tLoss: 0.529145\n",
      "Train Epoch: 3 [1000/23974 (4%)]\tLoss: 0.514983\n",
      "Train Epoch: 3 [2000/23974 (8%)]\tLoss: 0.463672\n",
      "Train Epoch: 3 [3000/23974 (12%)]\tLoss: 0.688082\n",
      "Train Epoch: 3 [4000/23974 (17%)]\tLoss: 0.495097\n",
      "Train Epoch: 3 [5000/23974 (21%)]\tLoss: 0.436332\n",
      "Train Epoch: 3 [6000/23974 (25%)]\tLoss: 0.606552\n",
      "Train Epoch: 3 [7000/23974 (29%)]\tLoss: 0.573820\n",
      "Train Epoch: 3 [8000/23974 (33%)]\tLoss: 0.409718\n",
      "Train Epoch: 3 [9000/23974 (38%)]\tLoss: 0.515420\n",
      "Train Epoch: 3 [10000/23974 (42%)]\tLoss: 0.442766\n",
      "Train Epoch: 3 [11000/23974 (46%)]\tLoss: 0.489086\n",
      "Train Epoch: 3 [12000/23974 (50%)]\tLoss: 0.430823\n",
      "Train Epoch: 3 [13000/23974 (54%)]\tLoss: 0.586965\n",
      "Train Epoch: 3 [14000/23974 (58%)]\tLoss: 0.630368\n",
      "Train Epoch: 3 [15000/23974 (62%)]\tLoss: 0.567333\n",
      "Train Epoch: 3 [16000/23974 (67%)]\tLoss: 0.496057\n",
      "Train Epoch: 3 [17000/23974 (71%)]\tLoss: 0.669390\n",
      "Train Epoch: 3 [18000/23974 (75%)]\tLoss: 0.664575\n",
      "Train Epoch: 3 [19000/23974 (79%)]\tLoss: 0.414786\n",
      "Train Epoch: 3 [20000/23974 (83%)]\tLoss: 0.461750\n",
      "Train Epoch: 3 [21000/23974 (88%)]\tLoss: 0.505841\n",
      "Train Epoch: 3 [22000/23974 (92%)]\tLoss: 0.485871\n",
      "Train Epoch: 3 [23000/23974 (96%)]\tLoss: 0.578947\n",
      "Train Epoch: 4 [0/23974 (0%)]\tLoss: 0.377583\n",
      "Train Epoch: 4 [1000/23974 (4%)]\tLoss: 0.397503\n",
      "Train Epoch: 4 [2000/23974 (8%)]\tLoss: 0.506907\n",
      "Train Epoch: 4 [3000/23974 (12%)]\tLoss: 0.552841\n",
      "Train Epoch: 4 [4000/23974 (17%)]\tLoss: 0.532519\n",
      "Train Epoch: 4 [5000/23974 (21%)]\tLoss: 0.540205\n",
      "Train Epoch: 4 [6000/23974 (25%)]\tLoss: 0.550665\n",
      "Train Epoch: 4 [7000/23974 (29%)]\tLoss: 0.610090\n",
      "Train Epoch: 4 [8000/23974 (33%)]\tLoss: 0.499094\n",
      "Train Epoch: 4 [9000/23974 (38%)]\tLoss: 0.504263\n",
      "Train Epoch: 4 [10000/23974 (42%)]\tLoss: 0.608084\n",
      "Train Epoch: 4 [11000/23974 (46%)]\tLoss: 0.480985\n",
      "Train Epoch: 4 [12000/23974 (50%)]\tLoss: 0.504896\n",
      "Train Epoch: 4 [13000/23974 (54%)]\tLoss: 0.524305\n",
      "Train Epoch: 4 [14000/23974 (58%)]\tLoss: 0.605181\n",
      "Train Epoch: 4 [15000/23974 (62%)]\tLoss: 0.719020\n",
      "Train Epoch: 4 [16000/23974 (67%)]\tLoss: 0.686889\n",
      "Train Epoch: 4 [17000/23974 (71%)]\tLoss: 0.597864\n",
      "Train Epoch: 4 [18000/23974 (75%)]\tLoss: 0.427616\n",
      "Train Epoch: 4 [19000/23974 (79%)]\tLoss: 0.507570\n",
      "Train Epoch: 4 [20000/23974 (83%)]\tLoss: 0.515725\n",
      "Train Epoch: 4 [21000/23974 (88%)]\tLoss: 0.403300\n",
      "Train Epoch: 4 [22000/23974 (92%)]\tLoss: 0.424784\n",
      "Train Epoch: 4 [23000/23974 (96%)]\tLoss: 0.420766\n",
      "Train Epoch: 5 [0/23974 (0%)]\tLoss: 0.421034\n",
      "Train Epoch: 5 [1000/23974 (4%)]\tLoss: 0.531738\n",
      "Train Epoch: 5 [2000/23974 (8%)]\tLoss: 0.462131\n",
      "Train Epoch: 5 [3000/23974 (12%)]\tLoss: 0.491881\n",
      "Train Epoch: 5 [4000/23974 (17%)]\tLoss: 0.550393\n",
      "Train Epoch: 5 [5000/23974 (21%)]\tLoss: 0.372282\n",
      "Train Epoch: 5 [6000/23974 (25%)]\tLoss: 0.500606\n",
      "Train Epoch: 5 [7000/23974 (29%)]\tLoss: 0.556072\n",
      "Train Epoch: 5 [8000/23974 (33%)]\tLoss: 0.454321\n",
      "Train Epoch: 5 [9000/23974 (38%)]\tLoss: 0.363306\n",
      "Train Epoch: 5 [10000/23974 (42%)]\tLoss: 0.642785\n",
      "Train Epoch: 5 [11000/23974 (46%)]\tLoss: 0.425657\n",
      "Train Epoch: 5 [12000/23974 (50%)]\tLoss: 0.522999\n",
      "Train Epoch: 5 [13000/23974 (54%)]\tLoss: 0.571797\n",
      "Train Epoch: 5 [14000/23974 (58%)]\tLoss: 0.583541\n",
      "Train Epoch: 5 [15000/23974 (62%)]\tLoss: 0.362876\n",
      "Train Epoch: 5 [16000/23974 (67%)]\tLoss: 0.440130\n",
      "Train Epoch: 5 [17000/23974 (71%)]\tLoss: 0.456888\n",
      "Train Epoch: 5 [18000/23974 (75%)]\tLoss: 0.473750\n",
      "Train Epoch: 5 [19000/23974 (79%)]\tLoss: 0.582656\n",
      "Train Epoch: 5 [20000/23974 (83%)]\tLoss: 0.500561\n",
      "Train Epoch: 5 [21000/23974 (88%)]\tLoss: 0.543975\n",
      "Train Epoch: 5 [22000/23974 (92%)]\tLoss: 0.409167\n",
      "Train Epoch: 5 [23000/23974 (96%)]\tLoss: 0.442941\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7961 (0%)]\tLoss: 0.958229\n",
      "Train Epoch: 1 [1000/7961 (12%)]\tLoss: 0.827575\n",
      "Train Epoch: 1 [2000/7961 (25%)]\tLoss: 0.842651\n",
      "Train Epoch: 1 [3000/7961 (38%)]\tLoss: 0.863160\n",
      "Train Epoch: 1 [4000/7961 (50%)]\tLoss: 0.927951\n",
      "Train Epoch: 1 [5000/7961 (62%)]\tLoss: 0.847708\n",
      "Train Epoch: 1 [6000/7961 (75%)]\tLoss: 0.808048\n",
      "Train Epoch: 1 [7000/7961 (88%)]\tLoss: 0.854572\n",
      "Train Epoch: 2 [0/7961 (0%)]\tLoss: 0.860618\n",
      "Train Epoch: 2 [1000/7961 (12%)]\tLoss: 0.909794\n",
      "Train Epoch: 2 [2000/7961 (25%)]\tLoss: 0.852921\n",
      "Train Epoch: 2 [3000/7961 (38%)]\tLoss: 0.781505\n",
      "Train Epoch: 2 [4000/7961 (50%)]\tLoss: 0.799519\n",
      "Train Epoch: 2 [5000/7961 (62%)]\tLoss: 0.818315\n",
      "Train Epoch: 2 [6000/7961 (75%)]\tLoss: 0.980793\n",
      "Train Epoch: 2 [7000/7961 (88%)]\tLoss: 0.872248\n",
      "Train Epoch: 3 [0/7961 (0%)]\tLoss: 0.816602\n",
      "Train Epoch: 3 [1000/7961 (12%)]\tLoss: 0.789453\n",
      "Train Epoch: 3 [2000/7961 (25%)]\tLoss: 0.722188\n",
      "Train Epoch: 3 [3000/7961 (38%)]\tLoss: 0.756874\n",
      "Train Epoch: 3 [4000/7961 (50%)]\tLoss: 0.636593\n",
      "Train Epoch: 3 [5000/7961 (62%)]\tLoss: 0.784267\n",
      "Train Epoch: 3 [6000/7961 (75%)]\tLoss: 0.780294\n",
      "Train Epoch: 3 [7000/7961 (88%)]\tLoss: 0.684713\n",
      "Train Epoch: 4 [0/7961 (0%)]\tLoss: 0.697367\n",
      "Train Epoch: 4 [1000/7961 (12%)]\tLoss: 0.640764\n",
      "Train Epoch: 4 [2000/7961 (25%)]\tLoss: 0.768042\n",
      "Train Epoch: 4 [3000/7961 (38%)]\tLoss: 0.684817\n",
      "Train Epoch: 4 [4000/7961 (50%)]\tLoss: 0.694245\n",
      "Train Epoch: 4 [5000/7961 (62%)]\tLoss: 0.760699\n",
      "Train Epoch: 4 [6000/7961 (75%)]\tLoss: 0.693025\n",
      "Train Epoch: 4 [7000/7961 (88%)]\tLoss: 0.752791\n",
      "Train Epoch: 5 [0/7961 (0%)]\tLoss: 0.768604\n",
      "Train Epoch: 5 [1000/7961 (12%)]\tLoss: 0.662127\n",
      "Train Epoch: 5 [2000/7961 (25%)]\tLoss: 0.737046\n",
      "Train Epoch: 5 [3000/7961 (38%)]\tLoss: 0.775695\n",
      "Train Epoch: 5 [4000/7961 (50%)]\tLoss: 0.777323\n",
      "Train Epoch: 5 [5000/7961 (62%)]\tLoss: 0.842067\n",
      "Train Epoch: 5 [6000/7961 (75%)]\tLoss: 0.771262\n",
      "Train Epoch: 5 [7000/7961 (88%)]\tLoss: 0.638326\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/15584 (0%)]\tLoss: 1.406834\n",
      "Train Epoch: 1 [1000/15584 (6%)]\tLoss: 0.882708\n",
      "Train Epoch: 1 [2000/15584 (13%)]\tLoss: 0.857831\n",
      "Train Epoch: 1 [3000/15584 (19%)]\tLoss: 0.791406\n",
      "Train Epoch: 1 [4000/15584 (26%)]\tLoss: 0.782644\n",
      "Train Epoch: 1 [5000/15584 (32%)]\tLoss: 0.806346\n",
      "Train Epoch: 1 [6000/15584 (38%)]\tLoss: 0.749509\n",
      "Train Epoch: 1 [7000/15584 (45%)]\tLoss: 0.732492\n",
      "Train Epoch: 1 [8000/15584 (51%)]\tLoss: 0.582982\n",
      "Train Epoch: 1 [9000/15584 (58%)]\tLoss: 0.745735\n",
      "Train Epoch: 1 [10000/15584 (64%)]\tLoss: 0.610058\n",
      "Train Epoch: 1 [11000/15584 (71%)]\tLoss: 0.686545\n",
      "Train Epoch: 1 [12000/15584 (77%)]\tLoss: 0.734515\n",
      "Train Epoch: 1 [13000/15584 (83%)]\tLoss: 0.574524\n",
      "Train Epoch: 1 [14000/15584 (90%)]\tLoss: 0.633788\n",
      "Train Epoch: 1 [15000/15584 (96%)]\tLoss: 0.626264\n",
      "Train Epoch: 2 [0/15584 (0%)]\tLoss: 0.556996\n",
      "Train Epoch: 2 [1000/15584 (6%)]\tLoss: 0.646030\n",
      "Train Epoch: 2 [2000/15584 (13%)]\tLoss: 0.650355\n",
      "Train Epoch: 2 [3000/15584 (19%)]\tLoss: 0.635763\n",
      "Train Epoch: 2 [4000/15584 (26%)]\tLoss: 0.629761\n",
      "Train Epoch: 2 [5000/15584 (32%)]\tLoss: 0.565035\n",
      "Train Epoch: 2 [6000/15584 (38%)]\tLoss: 0.590798\n",
      "Train Epoch: 2 [7000/15584 (45%)]\tLoss: 0.550033\n",
      "Train Epoch: 2 [8000/15584 (51%)]\tLoss: 0.565363\n",
      "Train Epoch: 2 [9000/15584 (58%)]\tLoss: 0.557913\n",
      "Train Epoch: 2 [10000/15584 (64%)]\tLoss: 0.463278\n",
      "Train Epoch: 2 [11000/15584 (71%)]\tLoss: 0.625421\n",
      "Train Epoch: 2 [12000/15584 (77%)]\tLoss: 0.539506\n",
      "Train Epoch: 2 [13000/15584 (83%)]\tLoss: 0.499649\n",
      "Train Epoch: 2 [14000/15584 (90%)]\tLoss: 0.542912\n",
      "Train Epoch: 2 [15000/15584 (96%)]\tLoss: 0.459493\n",
      "Train Epoch: 3 [0/15584 (0%)]\tLoss: 0.514935\n",
      "Train Epoch: 3 [1000/15584 (6%)]\tLoss: 0.419815\n",
      "Train Epoch: 3 [2000/15584 (13%)]\tLoss: 0.583492\n",
      "Train Epoch: 3 [3000/15584 (19%)]\tLoss: 0.460376\n",
      "Train Epoch: 3 [4000/15584 (26%)]\tLoss: 0.664049\n",
      "Train Epoch: 3 [5000/15584 (32%)]\tLoss: 0.518546\n",
      "Train Epoch: 3 [6000/15584 (38%)]\tLoss: 0.559650\n",
      "Train Epoch: 3 [7000/15584 (45%)]\tLoss: 0.411142\n",
      "Train Epoch: 3 [8000/15584 (51%)]\tLoss: 0.448558\n",
      "Train Epoch: 3 [9000/15584 (58%)]\tLoss: 0.537537\n",
      "Train Epoch: 3 [10000/15584 (64%)]\tLoss: 0.459346\n",
      "Train Epoch: 3 [11000/15584 (71%)]\tLoss: 0.509561\n",
      "Train Epoch: 3 [12000/15584 (77%)]\tLoss: 0.429010\n",
      "Train Epoch: 3 [13000/15584 (83%)]\tLoss: 0.372185\n",
      "Train Epoch: 3 [14000/15584 (90%)]\tLoss: 0.421612\n",
      "Train Epoch: 3 [15000/15584 (96%)]\tLoss: 0.567436\n",
      "Train Epoch: 4 [0/15584 (0%)]\tLoss: 0.541651\n",
      "Train Epoch: 4 [1000/15584 (6%)]\tLoss: 0.351654\n",
      "Train Epoch: 4 [2000/15584 (13%)]\tLoss: 0.444681\n",
      "Train Epoch: 4 [3000/15584 (19%)]\tLoss: 0.618472\n",
      "Train Epoch: 4 [4000/15584 (26%)]\tLoss: 0.497342\n",
      "Train Epoch: 4 [5000/15584 (32%)]\tLoss: 0.442748\n",
      "Train Epoch: 4 [6000/15584 (38%)]\tLoss: 0.427577\n",
      "Train Epoch: 4 [7000/15584 (45%)]\tLoss: 0.504939\n",
      "Train Epoch: 4 [8000/15584 (51%)]\tLoss: 0.411506\n",
      "Train Epoch: 4 [9000/15584 (58%)]\tLoss: 0.458298\n",
      "Train Epoch: 4 [10000/15584 (64%)]\tLoss: 0.482324\n",
      "Train Epoch: 4 [11000/15584 (71%)]\tLoss: 0.426402\n",
      "Train Epoch: 4 [12000/15584 (77%)]\tLoss: 0.518412\n",
      "Train Epoch: 4 [13000/15584 (83%)]\tLoss: 0.623058\n",
      "Train Epoch: 4 [14000/15584 (90%)]\tLoss: 0.515714\n",
      "Train Epoch: 4 [15000/15584 (96%)]\tLoss: 0.453572\n",
      "Train Epoch: 5 [0/15584 (0%)]\tLoss: 0.476316\n",
      "Train Epoch: 5 [1000/15584 (6%)]\tLoss: 0.444753\n",
      "Train Epoch: 5 [2000/15584 (13%)]\tLoss: 0.407881\n",
      "Train Epoch: 5 [3000/15584 (19%)]\tLoss: 0.380115\n",
      "Train Epoch: 5 [4000/15584 (26%)]\tLoss: 0.518420\n",
      "Train Epoch: 5 [5000/15584 (32%)]\tLoss: 0.384575\n",
      "Train Epoch: 5 [6000/15584 (38%)]\tLoss: 0.379092\n",
      "Train Epoch: 5 [7000/15584 (45%)]\tLoss: 0.409691\n",
      "Train Epoch: 5 [8000/15584 (51%)]\tLoss: 0.612678\n",
      "Train Epoch: 5 [9000/15584 (58%)]\tLoss: 0.399264\n",
      "Train Epoch: 5 [10000/15584 (64%)]\tLoss: 0.465719\n",
      "Train Epoch: 5 [11000/15584 (71%)]\tLoss: 0.461082\n",
      "Train Epoch: 5 [12000/15584 (77%)]\tLoss: 0.485602\n",
      "Train Epoch: 5 [13000/15584 (83%)]\tLoss: 0.471722\n",
      "Train Epoch: 5 [14000/15584 (90%)]\tLoss: 0.401686\n",
      "Train Epoch: 5 [15000/15584 (96%)]\tLoss: 0.451181\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/12481 (0%)]\tLoss: 0.737246\n",
      "Train Epoch: 1 [1000/12481 (8%)]\tLoss: 0.470401\n",
      "Train Epoch: 1 [2000/12481 (16%)]\tLoss: 0.445194\n",
      "Train Epoch: 1 [3000/12481 (24%)]\tLoss: 0.458309\n",
      "Train Epoch: 1 [4000/12481 (32%)]\tLoss: 0.625960\n",
      "Train Epoch: 1 [5000/12481 (40%)]\tLoss: 0.426737\n",
      "Train Epoch: 1 [6000/12481 (48%)]\tLoss: 0.406838\n",
      "Train Epoch: 1 [7000/12481 (56%)]\tLoss: 0.416872\n",
      "Train Epoch: 1 [8000/12481 (64%)]\tLoss: 0.494659\n",
      "Train Epoch: 1 [9000/12481 (72%)]\tLoss: 0.469693\n",
      "Train Epoch: 1 [10000/12481 (80%)]\tLoss: 0.427786\n",
      "Train Epoch: 1 [11000/12481 (88%)]\tLoss: 0.388590\n",
      "Train Epoch: 1 [12000/12481 (96%)]\tLoss: 0.632269\n",
      "Train Epoch: 2 [0/12481 (0%)]\tLoss: 0.391927\n",
      "Train Epoch: 2 [1000/12481 (8%)]\tLoss: 0.479531\n",
      "Train Epoch: 2 [2000/12481 (16%)]\tLoss: 0.342725\n",
      "Train Epoch: 2 [3000/12481 (24%)]\tLoss: 0.466978\n",
      "Train Epoch: 2 [4000/12481 (32%)]\tLoss: 0.504775\n",
      "Train Epoch: 2 [5000/12481 (40%)]\tLoss: 0.348090\n",
      "Train Epoch: 2 [6000/12481 (48%)]\tLoss: 0.377221\n",
      "Train Epoch: 2 [7000/12481 (56%)]\tLoss: 0.439503\n",
      "Train Epoch: 2 [8000/12481 (64%)]\tLoss: 0.324378\n",
      "Train Epoch: 2 [9000/12481 (72%)]\tLoss: 0.516931\n",
      "Train Epoch: 2 [10000/12481 (80%)]\tLoss: 0.457890\n",
      "Train Epoch: 2 [11000/12481 (88%)]\tLoss: 0.460187\n",
      "Train Epoch: 2 [12000/12481 (96%)]\tLoss: 0.507499\n",
      "Train Epoch: 3 [0/12481 (0%)]\tLoss: 0.309241\n",
      "Train Epoch: 3 [1000/12481 (8%)]\tLoss: 0.443332\n",
      "Train Epoch: 3 [2000/12481 (16%)]\tLoss: 0.371876\n",
      "Train Epoch: 3 [3000/12481 (24%)]\tLoss: 0.423286\n",
      "Train Epoch: 3 [4000/12481 (32%)]\tLoss: 0.352508\n",
      "Train Epoch: 3 [5000/12481 (40%)]\tLoss: 0.356152\n",
      "Train Epoch: 3 [6000/12481 (48%)]\tLoss: 0.355125\n",
      "Train Epoch: 3 [7000/12481 (56%)]\tLoss: 0.550744\n",
      "Train Epoch: 3 [8000/12481 (64%)]\tLoss: 0.460183\n",
      "Train Epoch: 3 [9000/12481 (72%)]\tLoss: 0.398927\n",
      "Train Epoch: 3 [10000/12481 (80%)]\tLoss: 0.512822\n",
      "Train Epoch: 3 [11000/12481 (88%)]\tLoss: 0.425155\n",
      "Train Epoch: 3 [12000/12481 (96%)]\tLoss: 0.363387\n",
      "Train Epoch: 4 [0/12481 (0%)]\tLoss: 0.415989\n",
      "Train Epoch: 4 [1000/12481 (8%)]\tLoss: 0.292970\n",
      "Train Epoch: 4 [2000/12481 (16%)]\tLoss: 0.238452\n",
      "Train Epoch: 4 [3000/12481 (24%)]\tLoss: 0.482127\n",
      "Train Epoch: 4 [4000/12481 (32%)]\tLoss: 0.429443\n",
      "Train Epoch: 4 [5000/12481 (40%)]\tLoss: 0.361118\n",
      "Train Epoch: 4 [6000/12481 (48%)]\tLoss: 0.266419\n",
      "Train Epoch: 4 [7000/12481 (56%)]\tLoss: 0.249871\n",
      "Train Epoch: 4 [8000/12481 (64%)]\tLoss: 0.493788\n",
      "Train Epoch: 4 [9000/12481 (72%)]\tLoss: 0.379663\n",
      "Train Epoch: 4 [10000/12481 (80%)]\tLoss: 0.404638\n",
      "Train Epoch: 4 [11000/12481 (88%)]\tLoss: 0.350209\n",
      "Train Epoch: 4 [12000/12481 (96%)]\tLoss: 0.532715\n",
      "Train Epoch: 5 [0/12481 (0%)]\tLoss: 0.342694\n",
      "Train Epoch: 5 [1000/12481 (8%)]\tLoss: 0.353037\n",
      "Train Epoch: 5 [2000/12481 (16%)]\tLoss: 0.291207\n",
      "Train Epoch: 5 [3000/12481 (24%)]\tLoss: 0.544181\n",
      "Train Epoch: 5 [4000/12481 (32%)]\tLoss: 0.331793\n",
      "Train Epoch: 5 [5000/12481 (40%)]\tLoss: 0.405845\n",
      "Train Epoch: 5 [6000/12481 (48%)]\tLoss: 0.356993\n",
      "Train Epoch: 5 [7000/12481 (56%)]\tLoss: 0.477082\n",
      "Train Epoch: 5 [8000/12481 (64%)]\tLoss: 0.316836\n",
      "Train Epoch: 5 [9000/12481 (72%)]\tLoss: 0.458061\n",
      "Train Epoch: 5 [10000/12481 (80%)]\tLoss: 0.359027\n",
      "Train Epoch: 5 [11000/12481 (88%)]\tLoss: 0.419980\n",
      "Train Epoch: 5 [12000/12481 (96%)]\tLoss: 0.380355\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "4\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.1041, Accuracy: 6670/10000 (67%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/23974 (0%)]\tLoss: 0.859268\n",
      "Train Epoch: 1 [1000/23974 (4%)]\tLoss: 0.546879\n",
      "Train Epoch: 1 [2000/23974 (8%)]\tLoss: 0.408615\n",
      "Train Epoch: 1 [3000/23974 (12%)]\tLoss: 0.521570\n",
      "Train Epoch: 1 [4000/23974 (17%)]\tLoss: 0.677781\n",
      "Train Epoch: 1 [5000/23974 (21%)]\tLoss: 0.644109\n",
      "Train Epoch: 1 [6000/23974 (25%)]\tLoss: 0.474255\n",
      "Train Epoch: 1 [7000/23974 (29%)]\tLoss: 0.769135\n",
      "Train Epoch: 1 [8000/23974 (33%)]\tLoss: 0.498700\n",
      "Train Epoch: 1 [9000/23974 (38%)]\tLoss: 0.475477\n",
      "Train Epoch: 1 [10000/23974 (42%)]\tLoss: 0.469031\n",
      "Train Epoch: 1 [11000/23974 (46%)]\tLoss: 0.538701\n",
      "Train Epoch: 1 [12000/23974 (50%)]\tLoss: 0.679403\n",
      "Train Epoch: 1 [13000/23974 (54%)]\tLoss: 0.779953\n",
      "Train Epoch: 1 [14000/23974 (58%)]\tLoss: 0.576915\n",
      "Train Epoch: 1 [15000/23974 (62%)]\tLoss: 0.448321\n",
      "Train Epoch: 1 [16000/23974 (67%)]\tLoss: 0.519895\n",
      "Train Epoch: 1 [17000/23974 (71%)]\tLoss: 0.421385\n",
      "Train Epoch: 1 [18000/23974 (75%)]\tLoss: 0.524227\n",
      "Train Epoch: 1 [19000/23974 (79%)]\tLoss: 0.567823\n",
      "Train Epoch: 1 [20000/23974 (83%)]\tLoss: 0.381969\n",
      "Train Epoch: 1 [21000/23974 (88%)]\tLoss: 0.520630\n",
      "Train Epoch: 1 [22000/23974 (92%)]\tLoss: 0.620354\n",
      "Train Epoch: 1 [23000/23974 (96%)]\tLoss: 0.500980\n",
      "Train Epoch: 2 [0/23974 (0%)]\tLoss: 0.451348\n",
      "Train Epoch: 2 [1000/23974 (4%)]\tLoss: 0.692829\n",
      "Train Epoch: 2 [2000/23974 (8%)]\tLoss: 0.544083\n",
      "Train Epoch: 2 [3000/23974 (12%)]\tLoss: 0.583181\n",
      "Train Epoch: 2 [4000/23974 (17%)]\tLoss: 0.480942\n",
      "Train Epoch: 2 [5000/23974 (21%)]\tLoss: 0.551144\n",
      "Train Epoch: 2 [6000/23974 (25%)]\tLoss: 0.400064\n",
      "Train Epoch: 2 [7000/23974 (29%)]\tLoss: 0.531046\n",
      "Train Epoch: 2 [8000/23974 (33%)]\tLoss: 0.502473\n",
      "Train Epoch: 2 [9000/23974 (38%)]\tLoss: 0.689541\n",
      "Train Epoch: 2 [10000/23974 (42%)]\tLoss: 0.409319\n",
      "Train Epoch: 2 [11000/23974 (46%)]\tLoss: 0.554781\n",
      "Train Epoch: 2 [12000/23974 (50%)]\tLoss: 0.594024\n",
      "Train Epoch: 2 [13000/23974 (54%)]\tLoss: 0.332727\n",
      "Train Epoch: 2 [14000/23974 (58%)]\tLoss: 0.651378\n",
      "Train Epoch: 2 [15000/23974 (62%)]\tLoss: 0.547787\n",
      "Train Epoch: 2 [16000/23974 (67%)]\tLoss: 0.551129\n",
      "Train Epoch: 2 [17000/23974 (71%)]\tLoss: 0.456134\n",
      "Train Epoch: 2 [18000/23974 (75%)]\tLoss: 0.548383\n",
      "Train Epoch: 2 [19000/23974 (79%)]\tLoss: 0.490278\n",
      "Train Epoch: 2 [20000/23974 (83%)]\tLoss: 0.521512\n",
      "Train Epoch: 2 [21000/23974 (88%)]\tLoss: 0.435909\n",
      "Train Epoch: 2 [22000/23974 (92%)]\tLoss: 0.418469\n",
      "Train Epoch: 2 [23000/23974 (96%)]\tLoss: 0.457190\n",
      "Train Epoch: 3 [0/23974 (0%)]\tLoss: 0.529159\n",
      "Train Epoch: 3 [1000/23974 (4%)]\tLoss: 0.530376\n",
      "Train Epoch: 3 [2000/23974 (8%)]\tLoss: 0.600442\n",
      "Train Epoch: 3 [3000/23974 (12%)]\tLoss: 0.559704\n",
      "Train Epoch: 3 [4000/23974 (17%)]\tLoss: 0.467390\n",
      "Train Epoch: 3 [5000/23974 (21%)]\tLoss: 0.519782\n",
      "Train Epoch: 3 [6000/23974 (25%)]\tLoss: 0.430084\n",
      "Train Epoch: 3 [7000/23974 (29%)]\tLoss: 0.408527\n",
      "Train Epoch: 3 [8000/23974 (33%)]\tLoss: 0.521901\n",
      "Train Epoch: 3 [9000/23974 (38%)]\tLoss: 0.479149\n",
      "Train Epoch: 3 [10000/23974 (42%)]\tLoss: 0.504151\n",
      "Train Epoch: 3 [11000/23974 (46%)]\tLoss: 0.395100\n",
      "Train Epoch: 3 [12000/23974 (50%)]\tLoss: 0.366325\n",
      "Train Epoch: 3 [13000/23974 (54%)]\tLoss: 0.539365\n",
      "Train Epoch: 3 [14000/23974 (58%)]\tLoss: 0.479027\n",
      "Train Epoch: 3 [15000/23974 (62%)]\tLoss: 0.411529\n",
      "Train Epoch: 3 [16000/23974 (67%)]\tLoss: 0.436749\n",
      "Train Epoch: 3 [17000/23974 (71%)]\tLoss: 0.491680\n",
      "Train Epoch: 3 [18000/23974 (75%)]\tLoss: 0.426856\n",
      "Train Epoch: 3 [19000/23974 (79%)]\tLoss: 0.505517\n",
      "Train Epoch: 3 [20000/23974 (83%)]\tLoss: 0.515305\n",
      "Train Epoch: 3 [21000/23974 (88%)]\tLoss: 0.481046\n",
      "Train Epoch: 3 [22000/23974 (92%)]\tLoss: 0.476386\n",
      "Train Epoch: 3 [23000/23974 (96%)]\tLoss: 0.412214\n",
      "Train Epoch: 4 [0/23974 (0%)]\tLoss: 0.456273\n",
      "Train Epoch: 4 [1000/23974 (4%)]\tLoss: 0.383550\n",
      "Train Epoch: 4 [2000/23974 (8%)]\tLoss: 0.599855\n",
      "Train Epoch: 4 [3000/23974 (12%)]\tLoss: 0.490837\n",
      "Train Epoch: 4 [4000/23974 (17%)]\tLoss: 0.415291\n",
      "Train Epoch: 4 [5000/23974 (21%)]\tLoss: 0.407596\n",
      "Train Epoch: 4 [6000/23974 (25%)]\tLoss: 0.476621\n",
      "Train Epoch: 4 [7000/23974 (29%)]\tLoss: 0.553186\n",
      "Train Epoch: 4 [8000/23974 (33%)]\tLoss: 0.496913\n",
      "Train Epoch: 4 [9000/23974 (38%)]\tLoss: 0.519647\n",
      "Train Epoch: 4 [10000/23974 (42%)]\tLoss: 0.518027\n",
      "Train Epoch: 4 [11000/23974 (46%)]\tLoss: 0.437129\n",
      "Train Epoch: 4 [12000/23974 (50%)]\tLoss: 0.396734\n",
      "Train Epoch: 4 [13000/23974 (54%)]\tLoss: 0.491735\n",
      "Train Epoch: 4 [14000/23974 (58%)]\tLoss: 0.356913\n",
      "Train Epoch: 4 [15000/23974 (62%)]\tLoss: 0.349064\n",
      "Train Epoch: 4 [16000/23974 (67%)]\tLoss: 0.465658\n",
      "Train Epoch: 4 [17000/23974 (71%)]\tLoss: 0.346183\n",
      "Train Epoch: 4 [18000/23974 (75%)]\tLoss: 0.448260\n",
      "Train Epoch: 4 [19000/23974 (79%)]\tLoss: 0.547833\n",
      "Train Epoch: 4 [20000/23974 (83%)]\tLoss: 0.389911\n",
      "Train Epoch: 4 [21000/23974 (88%)]\tLoss: 0.328212\n",
      "Train Epoch: 4 [22000/23974 (92%)]\tLoss: 0.354592\n",
      "Train Epoch: 4 [23000/23974 (96%)]\tLoss: 0.483591\n",
      "Train Epoch: 5 [0/23974 (0%)]\tLoss: 0.435836\n",
      "Train Epoch: 5 [1000/23974 (4%)]\tLoss: 0.459728\n",
      "Train Epoch: 5 [2000/23974 (8%)]\tLoss: 0.486679\n",
      "Train Epoch: 5 [3000/23974 (12%)]\tLoss: 0.426729\n",
      "Train Epoch: 5 [4000/23974 (17%)]\tLoss: 0.453046\n",
      "Train Epoch: 5 [5000/23974 (21%)]\tLoss: 0.496461\n",
      "Train Epoch: 5 [6000/23974 (25%)]\tLoss: 0.408257\n",
      "Train Epoch: 5 [7000/23974 (29%)]\tLoss: 0.354434\n",
      "Train Epoch: 5 [8000/23974 (33%)]\tLoss: 0.431249\n",
      "Train Epoch: 5 [9000/23974 (38%)]\tLoss: 0.457993\n",
      "Train Epoch: 5 [10000/23974 (42%)]\tLoss: 0.345785\n",
      "Train Epoch: 5 [11000/23974 (46%)]\tLoss: 0.406513\n",
      "Train Epoch: 5 [12000/23974 (50%)]\tLoss: 0.453374\n",
      "Train Epoch: 5 [13000/23974 (54%)]\tLoss: 0.459867\n",
      "Train Epoch: 5 [14000/23974 (58%)]\tLoss: 0.370900\n",
      "Train Epoch: 5 [15000/23974 (62%)]\tLoss: 0.409628\n",
      "Train Epoch: 5 [16000/23974 (67%)]\tLoss: 0.416705\n",
      "Train Epoch: 5 [17000/23974 (71%)]\tLoss: 0.453557\n",
      "Train Epoch: 5 [18000/23974 (75%)]\tLoss: 0.542054\n",
      "Train Epoch: 5 [19000/23974 (79%)]\tLoss: 0.475470\n",
      "Train Epoch: 5 [20000/23974 (83%)]\tLoss: 0.519089\n",
      "Train Epoch: 5 [21000/23974 (88%)]\tLoss: 0.523958\n",
      "Train Epoch: 5 [22000/23974 (92%)]\tLoss: 0.409243\n",
      "Train Epoch: 5 [23000/23974 (96%)]\tLoss: 0.397664\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7961 (0%)]\tLoss: 0.823791\n",
      "Train Epoch: 1 [1000/7961 (12%)]\tLoss: 0.724427\n",
      "Train Epoch: 1 [2000/7961 (25%)]\tLoss: 0.616705\n",
      "Train Epoch: 1 [3000/7961 (38%)]\tLoss: 0.492535\n",
      "Train Epoch: 1 [4000/7961 (50%)]\tLoss: 0.664108\n",
      "Train Epoch: 1 [5000/7961 (62%)]\tLoss: 0.708802\n",
      "Train Epoch: 1 [6000/7961 (75%)]\tLoss: 0.668419\n",
      "Train Epoch: 1 [7000/7961 (88%)]\tLoss: 0.678495\n",
      "Train Epoch: 2 [0/7961 (0%)]\tLoss: 0.736354\n",
      "Train Epoch: 2 [1000/7961 (12%)]\tLoss: 0.608338\n",
      "Train Epoch: 2 [2000/7961 (25%)]\tLoss: 0.730539\n",
      "Train Epoch: 2 [3000/7961 (38%)]\tLoss: 0.665959\n",
      "Train Epoch: 2 [4000/7961 (50%)]\tLoss: 0.856578\n",
      "Train Epoch: 2 [5000/7961 (62%)]\tLoss: 0.818353\n",
      "Train Epoch: 2 [6000/7961 (75%)]\tLoss: 0.787377\n",
      "Train Epoch: 2 [7000/7961 (88%)]\tLoss: 0.620201\n",
      "Train Epoch: 3 [0/7961 (0%)]\tLoss: 0.777813\n",
      "Train Epoch: 3 [1000/7961 (12%)]\tLoss: 0.655259\n",
      "Train Epoch: 3 [2000/7961 (25%)]\tLoss: 0.696815\n",
      "Train Epoch: 3 [3000/7961 (38%)]\tLoss: 0.841366\n",
      "Train Epoch: 3 [4000/7961 (50%)]\tLoss: 0.712019\n",
      "Train Epoch: 3 [5000/7961 (62%)]\tLoss: 0.717659\n",
      "Train Epoch: 3 [6000/7961 (75%)]\tLoss: 0.658653\n",
      "Train Epoch: 3 [7000/7961 (88%)]\tLoss: 0.839768\n",
      "Train Epoch: 4 [0/7961 (0%)]\tLoss: 0.691381\n",
      "Train Epoch: 4 [1000/7961 (12%)]\tLoss: 0.577515\n",
      "Train Epoch: 4 [2000/7961 (25%)]\tLoss: 0.588111\n",
      "Train Epoch: 4 [3000/7961 (38%)]\tLoss: 0.800564\n",
      "Train Epoch: 4 [4000/7961 (50%)]\tLoss: 0.718451\n",
      "Train Epoch: 4 [5000/7961 (62%)]\tLoss: 0.810977\n",
      "Train Epoch: 4 [6000/7961 (75%)]\tLoss: 0.592020\n",
      "Train Epoch: 4 [7000/7961 (88%)]\tLoss: 0.768367\n",
      "Train Epoch: 5 [0/7961 (0%)]\tLoss: 0.697559\n",
      "Train Epoch: 5 [1000/7961 (12%)]\tLoss: 0.511535\n",
      "Train Epoch: 5 [2000/7961 (25%)]\tLoss: 0.596036\n",
      "Train Epoch: 5 [3000/7961 (38%)]\tLoss: 0.595513\n",
      "Train Epoch: 5 [4000/7961 (50%)]\tLoss: 0.555547\n",
      "Train Epoch: 5 [5000/7961 (62%)]\tLoss: 0.676242\n",
      "Train Epoch: 5 [6000/7961 (75%)]\tLoss: 0.658346\n",
      "Train Epoch: 5 [7000/7961 (88%)]\tLoss: 0.662154\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/15584 (0%)]\tLoss: 0.858103\n",
      "Train Epoch: 1 [1000/15584 (6%)]\tLoss: 0.596037\n",
      "Train Epoch: 1 [2000/15584 (13%)]\tLoss: 0.596878\n",
      "Train Epoch: 1 [3000/15584 (19%)]\tLoss: 0.563157\n",
      "Train Epoch: 1 [4000/15584 (26%)]\tLoss: 0.596537\n",
      "Train Epoch: 1 [5000/15584 (32%)]\tLoss: 0.628591\n",
      "Train Epoch: 1 [6000/15584 (38%)]\tLoss: 0.680263\n",
      "Train Epoch: 1 [7000/15584 (45%)]\tLoss: 0.511695\n",
      "Train Epoch: 1 [8000/15584 (51%)]\tLoss: 0.634935\n",
      "Train Epoch: 1 [9000/15584 (58%)]\tLoss: 0.592831\n",
      "Train Epoch: 1 [10000/15584 (64%)]\tLoss: 0.561765\n",
      "Train Epoch: 1 [11000/15584 (71%)]\tLoss: 0.491179\n",
      "Train Epoch: 1 [12000/15584 (77%)]\tLoss: 0.513032\n",
      "Train Epoch: 1 [13000/15584 (83%)]\tLoss: 0.488600\n",
      "Train Epoch: 1 [14000/15584 (90%)]\tLoss: 0.518345\n",
      "Train Epoch: 1 [15000/15584 (96%)]\tLoss: 0.453992\n",
      "Train Epoch: 2 [0/15584 (0%)]\tLoss: 0.614709\n",
      "Train Epoch: 2 [1000/15584 (6%)]\tLoss: 0.416079\n",
      "Train Epoch: 2 [2000/15584 (13%)]\tLoss: 0.444258\n",
      "Train Epoch: 2 [3000/15584 (19%)]\tLoss: 0.391808\n",
      "Train Epoch: 2 [4000/15584 (26%)]\tLoss: 0.435642\n",
      "Train Epoch: 2 [5000/15584 (32%)]\tLoss: 0.500823\n",
      "Train Epoch: 2 [6000/15584 (38%)]\tLoss: 0.447382\n",
      "Train Epoch: 2 [7000/15584 (45%)]\tLoss: 0.419151\n",
      "Train Epoch: 2 [8000/15584 (51%)]\tLoss: 0.413915\n",
      "Train Epoch: 2 [9000/15584 (58%)]\tLoss: 0.534167\n",
      "Train Epoch: 2 [10000/15584 (64%)]\tLoss: 0.528004\n",
      "Train Epoch: 2 [11000/15584 (71%)]\tLoss: 0.439515\n",
      "Train Epoch: 2 [12000/15584 (77%)]\tLoss: 0.431777\n",
      "Train Epoch: 2 [13000/15584 (83%)]\tLoss: 0.525637\n",
      "Train Epoch: 2 [14000/15584 (90%)]\tLoss: 0.540545\n",
      "Train Epoch: 2 [15000/15584 (96%)]\tLoss: 0.534889\n",
      "Train Epoch: 3 [0/15584 (0%)]\tLoss: 0.512986\n",
      "Train Epoch: 3 [1000/15584 (6%)]\tLoss: 0.478336\n",
      "Train Epoch: 3 [2000/15584 (13%)]\tLoss: 0.469605\n",
      "Train Epoch: 3 [3000/15584 (19%)]\tLoss: 0.490870\n",
      "Train Epoch: 3 [4000/15584 (26%)]\tLoss: 0.488080\n",
      "Train Epoch: 3 [5000/15584 (32%)]\tLoss: 0.640187\n",
      "Train Epoch: 3 [6000/15584 (38%)]\tLoss: 0.336385\n",
      "Train Epoch: 3 [7000/15584 (45%)]\tLoss: 0.503814\n",
      "Train Epoch: 3 [8000/15584 (51%)]\tLoss: 0.553528\n",
      "Train Epoch: 3 [9000/15584 (58%)]\tLoss: 0.445076\n",
      "Train Epoch: 3 [10000/15584 (64%)]\tLoss: 0.561292\n",
      "Train Epoch: 3 [11000/15584 (71%)]\tLoss: 0.420670\n",
      "Train Epoch: 3 [12000/15584 (77%)]\tLoss: 0.309163\n",
      "Train Epoch: 3 [13000/15584 (83%)]\tLoss: 0.363008\n",
      "Train Epoch: 3 [14000/15584 (90%)]\tLoss: 0.485849\n",
      "Train Epoch: 3 [15000/15584 (96%)]\tLoss: 0.538043\n",
      "Train Epoch: 4 [0/15584 (0%)]\tLoss: 0.377138\n",
      "Train Epoch: 4 [1000/15584 (6%)]\tLoss: 0.393388\n",
      "Train Epoch: 4 [2000/15584 (13%)]\tLoss: 0.459862\n",
      "Train Epoch: 4 [3000/15584 (19%)]\tLoss: 0.390414\n",
      "Train Epoch: 4 [4000/15584 (26%)]\tLoss: 0.398046\n",
      "Train Epoch: 4 [5000/15584 (32%)]\tLoss: 0.337418\n",
      "Train Epoch: 4 [6000/15584 (38%)]\tLoss: 0.426809\n",
      "Train Epoch: 4 [7000/15584 (45%)]\tLoss: 0.427440\n",
      "Train Epoch: 4 [8000/15584 (51%)]\tLoss: 0.429486\n",
      "Train Epoch: 4 [9000/15584 (58%)]\tLoss: 0.453674\n",
      "Train Epoch: 4 [10000/15584 (64%)]\tLoss: 0.350556\n",
      "Train Epoch: 4 [11000/15584 (71%)]\tLoss: 0.484207\n",
      "Train Epoch: 4 [12000/15584 (77%)]\tLoss: 0.311896\n",
      "Train Epoch: 4 [13000/15584 (83%)]\tLoss: 0.364164\n",
      "Train Epoch: 4 [14000/15584 (90%)]\tLoss: 0.433345\n",
      "Train Epoch: 4 [15000/15584 (96%)]\tLoss: 0.393106\n",
      "Train Epoch: 5 [0/15584 (0%)]\tLoss: 0.384407\n",
      "Train Epoch: 5 [1000/15584 (6%)]\tLoss: 0.393639\n",
      "Train Epoch: 5 [2000/15584 (13%)]\tLoss: 0.443419\n",
      "Train Epoch: 5 [3000/15584 (19%)]\tLoss: 0.339957\n",
      "Train Epoch: 5 [4000/15584 (26%)]\tLoss: 0.509913\n",
      "Train Epoch: 5 [5000/15584 (32%)]\tLoss: 0.384702\n",
      "Train Epoch: 5 [6000/15584 (38%)]\tLoss: 0.402062\n",
      "Train Epoch: 5 [7000/15584 (45%)]\tLoss: 0.422584\n",
      "Train Epoch: 5 [8000/15584 (51%)]\tLoss: 0.422841\n",
      "Train Epoch: 5 [9000/15584 (58%)]\tLoss: 0.368528\n",
      "Train Epoch: 5 [10000/15584 (64%)]\tLoss: 0.357823\n",
      "Train Epoch: 5 [11000/15584 (71%)]\tLoss: 0.467669\n",
      "Train Epoch: 5 [12000/15584 (77%)]\tLoss: 0.225724\n",
      "Train Epoch: 5 [13000/15584 (83%)]\tLoss: 0.527487\n",
      "Train Epoch: 5 [14000/15584 (90%)]\tLoss: 0.496592\n",
      "Train Epoch: 5 [15000/15584 (96%)]\tLoss: 0.425106\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/12481 (0%)]\tLoss: 0.434101\n",
      "Train Epoch: 1 [1000/12481 (8%)]\tLoss: 0.487029\n",
      "Train Epoch: 1 [2000/12481 (16%)]\tLoss: 0.405411\n",
      "Train Epoch: 1 [3000/12481 (24%)]\tLoss: 0.320085\n",
      "Train Epoch: 1 [4000/12481 (32%)]\tLoss: 0.434413\n",
      "Train Epoch: 1 [5000/12481 (40%)]\tLoss: 0.580836\n",
      "Train Epoch: 1 [6000/12481 (48%)]\tLoss: 0.520994\n",
      "Train Epoch: 1 [7000/12481 (56%)]\tLoss: 0.358507\n",
      "Train Epoch: 1 [8000/12481 (64%)]\tLoss: 0.365504\n",
      "Train Epoch: 1 [9000/12481 (72%)]\tLoss: 0.478621\n",
      "Train Epoch: 1 [10000/12481 (80%)]\tLoss: 0.420967\n",
      "Train Epoch: 1 [11000/12481 (88%)]\tLoss: 0.493129\n",
      "Train Epoch: 1 [12000/12481 (96%)]\tLoss: 0.359729\n",
      "Train Epoch: 2 [0/12481 (0%)]\tLoss: 0.367133\n",
      "Train Epoch: 2 [1000/12481 (8%)]\tLoss: 0.237661\n",
      "Train Epoch: 2 [2000/12481 (16%)]\tLoss: 0.242595\n",
      "Train Epoch: 2 [3000/12481 (24%)]\tLoss: 0.310696\n",
      "Train Epoch: 2 [4000/12481 (32%)]\tLoss: 0.377954\n",
      "Train Epoch: 2 [5000/12481 (40%)]\tLoss: 0.391372\n",
      "Train Epoch: 2 [6000/12481 (48%)]\tLoss: 0.226949\n",
      "Train Epoch: 2 [7000/12481 (56%)]\tLoss: 0.516214\n",
      "Train Epoch: 2 [8000/12481 (64%)]\tLoss: 0.377775\n",
      "Train Epoch: 2 [9000/12481 (72%)]\tLoss: 0.350069\n",
      "Train Epoch: 2 [10000/12481 (80%)]\tLoss: 0.339222\n",
      "Train Epoch: 2 [11000/12481 (88%)]\tLoss: 0.424917\n",
      "Train Epoch: 2 [12000/12481 (96%)]\tLoss: 0.376368\n",
      "Train Epoch: 3 [0/12481 (0%)]\tLoss: 0.324652\n",
      "Train Epoch: 3 [1000/12481 (8%)]\tLoss: 0.342698\n",
      "Train Epoch: 3 [2000/12481 (16%)]\tLoss: 0.266683\n",
      "Train Epoch: 3 [3000/12481 (24%)]\tLoss: 0.256264\n",
      "Train Epoch: 3 [4000/12481 (32%)]\tLoss: 0.281866\n",
      "Train Epoch: 3 [5000/12481 (40%)]\tLoss: 0.359360\n",
      "Train Epoch: 3 [6000/12481 (48%)]\tLoss: 0.528432\n",
      "Train Epoch: 3 [7000/12481 (56%)]\tLoss: 0.290207\n",
      "Train Epoch: 3 [8000/12481 (64%)]\tLoss: 0.298840\n",
      "Train Epoch: 3 [9000/12481 (72%)]\tLoss: 0.426083\n",
      "Train Epoch: 3 [10000/12481 (80%)]\tLoss: 0.270761\n",
      "Train Epoch: 3 [11000/12481 (88%)]\tLoss: 0.243410\n",
      "Train Epoch: 3 [12000/12481 (96%)]\tLoss: 0.251726\n",
      "Train Epoch: 4 [0/12481 (0%)]\tLoss: 0.418142\n",
      "Train Epoch: 4 [1000/12481 (8%)]\tLoss: 0.250892\n",
      "Train Epoch: 4 [2000/12481 (16%)]\tLoss: 0.371341\n",
      "Train Epoch: 4 [3000/12481 (24%)]\tLoss: 0.219577\n",
      "Train Epoch: 4 [4000/12481 (32%)]\tLoss: 0.291324\n",
      "Train Epoch: 4 [5000/12481 (40%)]\tLoss: 0.248622\n",
      "Train Epoch: 4 [6000/12481 (48%)]\tLoss: 0.411913\n",
      "Train Epoch: 4 [7000/12481 (56%)]\tLoss: 0.377477\n",
      "Train Epoch: 4 [8000/12481 (64%)]\tLoss: 0.328090\n",
      "Train Epoch: 4 [9000/12481 (72%)]\tLoss: 0.427054\n",
      "Train Epoch: 4 [10000/12481 (80%)]\tLoss: 0.461420\n",
      "Train Epoch: 4 [11000/12481 (88%)]\tLoss: 0.458915\n",
      "Train Epoch: 4 [12000/12481 (96%)]\tLoss: 0.298267\n",
      "Train Epoch: 5 [0/12481 (0%)]\tLoss: 0.406697\n",
      "Train Epoch: 5 [1000/12481 (8%)]\tLoss: 0.295854\n",
      "Train Epoch: 5 [2000/12481 (16%)]\tLoss: 0.370638\n",
      "Train Epoch: 5 [3000/12481 (24%)]\tLoss: 0.294195\n",
      "Train Epoch: 5 [4000/12481 (32%)]\tLoss: 0.192475\n",
      "Train Epoch: 5 [5000/12481 (40%)]\tLoss: 0.474325\n",
      "Train Epoch: 5 [6000/12481 (48%)]\tLoss: 0.263278\n",
      "Train Epoch: 5 [7000/12481 (56%)]\tLoss: 0.559812\n",
      "Train Epoch: 5 [8000/12481 (64%)]\tLoss: 0.309114\n",
      "Train Epoch: 5 [9000/12481 (72%)]\tLoss: 0.512727\n",
      "Train Epoch: 5 [10000/12481 (80%)]\tLoss: 0.336467\n",
      "Train Epoch: 5 [11000/12481 (88%)]\tLoss: 0.409823\n",
      "Train Epoch: 5 [12000/12481 (96%)]\tLoss: 0.265971\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "4\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9885, Accuracy: 7136/10000 (71%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/23974 (0%)]\tLoss: 0.594304\n",
      "Train Epoch: 1 [1000/23974 (4%)]\tLoss: 0.507473\n",
      "Train Epoch: 1 [2000/23974 (8%)]\tLoss: 0.585541\n",
      "Train Epoch: 1 [3000/23974 (12%)]\tLoss: 0.560310\n",
      "Train Epoch: 1 [4000/23974 (17%)]\tLoss: 0.431699\n",
      "Train Epoch: 1 [5000/23974 (21%)]\tLoss: 0.405056\n",
      "Train Epoch: 1 [6000/23974 (25%)]\tLoss: 0.445215\n",
      "Train Epoch: 1 [7000/23974 (29%)]\tLoss: 0.528166\n",
      "Train Epoch: 1 [8000/23974 (33%)]\tLoss: 0.459513\n",
      "Train Epoch: 1 [9000/23974 (38%)]\tLoss: 0.458129\n",
      "Train Epoch: 1 [10000/23974 (42%)]\tLoss: 0.594676\n",
      "Train Epoch: 1 [11000/23974 (46%)]\tLoss: 0.384900\n",
      "Train Epoch: 1 [12000/23974 (50%)]\tLoss: 0.615400\n",
      "Train Epoch: 1 [13000/23974 (54%)]\tLoss: 0.495460\n",
      "Train Epoch: 1 [14000/23974 (58%)]\tLoss: 0.521456\n",
      "Train Epoch: 1 [15000/23974 (62%)]\tLoss: 0.496465\n",
      "Train Epoch: 1 [16000/23974 (67%)]\tLoss: 0.574385\n",
      "Train Epoch: 1 [17000/23974 (71%)]\tLoss: 0.504201\n",
      "Train Epoch: 1 [18000/23974 (75%)]\tLoss: 0.560439\n",
      "Train Epoch: 1 [19000/23974 (79%)]\tLoss: 0.523085\n",
      "Train Epoch: 1 [20000/23974 (83%)]\tLoss: 0.547781\n",
      "Train Epoch: 1 [21000/23974 (88%)]\tLoss: 0.355382\n",
      "Train Epoch: 1 [22000/23974 (92%)]\tLoss: 0.339837\n",
      "Train Epoch: 1 [23000/23974 (96%)]\tLoss: 0.514542\n",
      "Train Epoch: 2 [0/23974 (0%)]\tLoss: 0.433985\n",
      "Train Epoch: 2 [1000/23974 (4%)]\tLoss: 0.459081\n",
      "Train Epoch: 2 [2000/23974 (8%)]\tLoss: 0.424900\n",
      "Train Epoch: 2 [3000/23974 (12%)]\tLoss: 0.407910\n",
      "Train Epoch: 2 [4000/23974 (17%)]\tLoss: 0.592728\n",
      "Train Epoch: 2 [5000/23974 (21%)]\tLoss: 0.498415\n",
      "Train Epoch: 2 [6000/23974 (25%)]\tLoss: 0.401794\n",
      "Train Epoch: 2 [7000/23974 (29%)]\tLoss: 0.571151\n",
      "Train Epoch: 2 [8000/23974 (33%)]\tLoss: 0.601872\n",
      "Train Epoch: 2 [9000/23974 (38%)]\tLoss: 0.510056\n",
      "Train Epoch: 2 [10000/23974 (42%)]\tLoss: 0.575077\n",
      "Train Epoch: 2 [11000/23974 (46%)]\tLoss: 0.579125\n",
      "Train Epoch: 2 [12000/23974 (50%)]\tLoss: 0.345619\n",
      "Train Epoch: 2 [13000/23974 (54%)]\tLoss: 0.435785\n",
      "Train Epoch: 2 [14000/23974 (58%)]\tLoss: 0.534798\n",
      "Train Epoch: 2 [15000/23974 (62%)]\tLoss: 0.466607\n",
      "Train Epoch: 2 [16000/23974 (67%)]\tLoss: 0.399255\n",
      "Train Epoch: 2 [17000/23974 (71%)]\tLoss: 0.421308\n",
      "Train Epoch: 2 [18000/23974 (75%)]\tLoss: 0.427234\n",
      "Train Epoch: 2 [19000/23974 (79%)]\tLoss: 0.394724\n",
      "Train Epoch: 2 [20000/23974 (83%)]\tLoss: 0.498320\n",
      "Train Epoch: 2 [21000/23974 (88%)]\tLoss: 0.542148\n",
      "Train Epoch: 2 [22000/23974 (92%)]\tLoss: 0.426457\n",
      "Train Epoch: 2 [23000/23974 (96%)]\tLoss: 0.557209\n",
      "Train Epoch: 3 [0/23974 (0%)]\tLoss: 0.662262\n",
      "Train Epoch: 3 [1000/23974 (4%)]\tLoss: 0.439971\n",
      "Train Epoch: 3 [2000/23974 (8%)]\tLoss: 0.483594\n",
      "Train Epoch: 3 [3000/23974 (12%)]\tLoss: 0.515503\n",
      "Train Epoch: 3 [4000/23974 (17%)]\tLoss: 0.504120\n",
      "Train Epoch: 3 [5000/23974 (21%)]\tLoss: 0.577823\n",
      "Train Epoch: 3 [6000/23974 (25%)]\tLoss: 0.425634\n",
      "Train Epoch: 3 [7000/23974 (29%)]\tLoss: 0.530557\n",
      "Train Epoch: 3 [8000/23974 (33%)]\tLoss: 0.537280\n",
      "Train Epoch: 3 [9000/23974 (38%)]\tLoss: 0.523174\n",
      "Train Epoch: 3 [10000/23974 (42%)]\tLoss: 0.477104\n",
      "Train Epoch: 3 [11000/23974 (46%)]\tLoss: 0.448018\n",
      "Train Epoch: 3 [12000/23974 (50%)]\tLoss: 0.547217\n",
      "Train Epoch: 3 [13000/23974 (54%)]\tLoss: 0.481627\n",
      "Train Epoch: 3 [14000/23974 (58%)]\tLoss: 0.334500\n",
      "Train Epoch: 3 [15000/23974 (62%)]\tLoss: 0.415056\n",
      "Train Epoch: 3 [16000/23974 (67%)]\tLoss: 0.539936\n",
      "Train Epoch: 3 [17000/23974 (71%)]\tLoss: 0.529253\n",
      "Train Epoch: 3 [18000/23974 (75%)]\tLoss: 0.436826\n",
      "Train Epoch: 3 [19000/23974 (79%)]\tLoss: 0.566045\n",
      "Train Epoch: 3 [20000/23974 (83%)]\tLoss: 0.436078\n",
      "Train Epoch: 3 [21000/23974 (88%)]\tLoss: 0.365598\n",
      "Train Epoch: 3 [22000/23974 (92%)]\tLoss: 0.403639\n",
      "Train Epoch: 3 [23000/23974 (96%)]\tLoss: 0.322970\n",
      "Train Epoch: 4 [0/23974 (0%)]\tLoss: 0.426617\n",
      "Train Epoch: 4 [1000/23974 (4%)]\tLoss: 0.458922\n",
      "Train Epoch: 4 [2000/23974 (8%)]\tLoss: 0.449387\n",
      "Train Epoch: 4 [3000/23974 (12%)]\tLoss: 0.437034\n",
      "Train Epoch: 4 [4000/23974 (17%)]\tLoss: 0.513328\n",
      "Train Epoch: 4 [5000/23974 (21%)]\tLoss: 0.358425\n",
      "Train Epoch: 4 [6000/23974 (25%)]\tLoss: 0.485817\n",
      "Train Epoch: 4 [7000/23974 (29%)]\tLoss: 0.471514\n",
      "Train Epoch: 4 [8000/23974 (33%)]\tLoss: 0.616417\n",
      "Train Epoch: 4 [9000/23974 (38%)]\tLoss: 0.568124\n",
      "Train Epoch: 4 [10000/23974 (42%)]\tLoss: 0.508501\n",
      "Train Epoch: 4 [11000/23974 (46%)]\tLoss: 0.507549\n",
      "Train Epoch: 4 [12000/23974 (50%)]\tLoss: 0.516296\n",
      "Train Epoch: 4 [13000/23974 (54%)]\tLoss: 0.320847\n",
      "Train Epoch: 4 [14000/23974 (58%)]\tLoss: 0.519547\n",
      "Train Epoch: 4 [15000/23974 (62%)]\tLoss: 0.557207\n",
      "Train Epoch: 4 [16000/23974 (67%)]\tLoss: 0.437235\n",
      "Train Epoch: 4 [17000/23974 (71%)]\tLoss: 0.420428\n",
      "Train Epoch: 4 [18000/23974 (75%)]\tLoss: 0.489578\n",
      "Train Epoch: 4 [19000/23974 (79%)]\tLoss: 0.446350\n",
      "Train Epoch: 4 [20000/23974 (83%)]\tLoss: 0.457748\n",
      "Train Epoch: 4 [21000/23974 (88%)]\tLoss: 0.460167\n",
      "Train Epoch: 4 [22000/23974 (92%)]\tLoss: 0.551384\n",
      "Train Epoch: 4 [23000/23974 (96%)]\tLoss: 0.448416\n",
      "Train Epoch: 5 [0/23974 (0%)]\tLoss: 0.496461\n",
      "Train Epoch: 5 [1000/23974 (4%)]\tLoss: 0.380687\n",
      "Train Epoch: 5 [2000/23974 (8%)]\tLoss: 0.432185\n",
      "Train Epoch: 5 [3000/23974 (12%)]\tLoss: 0.546242\n",
      "Train Epoch: 5 [4000/23974 (17%)]\tLoss: 0.419726\n",
      "Train Epoch: 5 [5000/23974 (21%)]\tLoss: 0.510567\n",
      "Train Epoch: 5 [6000/23974 (25%)]\tLoss: 0.464941\n",
      "Train Epoch: 5 [7000/23974 (29%)]\tLoss: 0.416866\n",
      "Train Epoch: 5 [8000/23974 (33%)]\tLoss: 0.444020\n",
      "Train Epoch: 5 [9000/23974 (38%)]\tLoss: 0.402958\n",
      "Train Epoch: 5 [10000/23974 (42%)]\tLoss: 0.354489\n",
      "Train Epoch: 5 [11000/23974 (46%)]\tLoss: 0.448117\n",
      "Train Epoch: 5 [12000/23974 (50%)]\tLoss: 0.486158\n",
      "Train Epoch: 5 [13000/23974 (54%)]\tLoss: 0.474352\n",
      "Train Epoch: 5 [14000/23974 (58%)]\tLoss: 0.484344\n",
      "Train Epoch: 5 [15000/23974 (62%)]\tLoss: 0.557612\n",
      "Train Epoch: 5 [16000/23974 (67%)]\tLoss: 0.426060\n",
      "Train Epoch: 5 [17000/23974 (71%)]\tLoss: 0.452282\n",
      "Train Epoch: 5 [18000/23974 (75%)]\tLoss: 0.419262\n",
      "Train Epoch: 5 [19000/23974 (79%)]\tLoss: 0.456996\n",
      "Train Epoch: 5 [20000/23974 (83%)]\tLoss: 0.406562\n",
      "Train Epoch: 5 [21000/23974 (88%)]\tLoss: 0.448783\n",
      "Train Epoch: 5 [22000/23974 (92%)]\tLoss: 0.449675\n",
      "Train Epoch: 5 [23000/23974 (96%)]\tLoss: 0.458615\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7961 (0%)]\tLoss: 0.761872\n",
      "Train Epoch: 1 [1000/7961 (12%)]\tLoss: 0.482198\n",
      "Train Epoch: 1 [2000/7961 (25%)]\tLoss: 0.552559\n",
      "Train Epoch: 1 [3000/7961 (38%)]\tLoss: 0.621415\n",
      "Train Epoch: 1 [4000/7961 (50%)]\tLoss: 0.683353\n",
      "Train Epoch: 1 [5000/7961 (62%)]\tLoss: 0.651343\n",
      "Train Epoch: 1 [6000/7961 (75%)]\tLoss: 0.517991\n",
      "Train Epoch: 1 [7000/7961 (88%)]\tLoss: 0.648656\n",
      "Train Epoch: 2 [0/7961 (0%)]\tLoss: 0.641659\n",
      "Train Epoch: 2 [1000/7961 (12%)]\tLoss: 0.644066\n",
      "Train Epoch: 2 [2000/7961 (25%)]\tLoss: 0.700037\n",
      "Train Epoch: 2 [3000/7961 (38%)]\tLoss: 0.613760\n",
      "Train Epoch: 2 [4000/7961 (50%)]\tLoss: 0.501647\n",
      "Train Epoch: 2 [5000/7961 (62%)]\tLoss: 0.568669\n",
      "Train Epoch: 2 [6000/7961 (75%)]\tLoss: 0.734789\n",
      "Train Epoch: 2 [7000/7961 (88%)]\tLoss: 0.527568\n",
      "Train Epoch: 3 [0/7961 (0%)]\tLoss: 0.558999\n",
      "Train Epoch: 3 [1000/7961 (12%)]\tLoss: 0.570457\n",
      "Train Epoch: 3 [2000/7961 (25%)]\tLoss: 0.734614\n",
      "Train Epoch: 3 [3000/7961 (38%)]\tLoss: 0.628487\n",
      "Train Epoch: 3 [4000/7961 (50%)]\tLoss: 0.522300\n",
      "Train Epoch: 3 [5000/7961 (62%)]\tLoss: 0.680531\n",
      "Train Epoch: 3 [6000/7961 (75%)]\tLoss: 0.709743\n",
      "Train Epoch: 3 [7000/7961 (88%)]\tLoss: 0.571653\n",
      "Train Epoch: 4 [0/7961 (0%)]\tLoss: 0.720869\n",
      "Train Epoch: 4 [1000/7961 (12%)]\tLoss: 0.523876\n",
      "Train Epoch: 4 [2000/7961 (25%)]\tLoss: 0.464765\n",
      "Train Epoch: 4 [3000/7961 (38%)]\tLoss: 0.645738\n",
      "Train Epoch: 4 [4000/7961 (50%)]\tLoss: 0.513891\n",
      "Train Epoch: 4 [5000/7961 (62%)]\tLoss: 0.545912\n",
      "Train Epoch: 4 [6000/7961 (75%)]\tLoss: 0.639373\n",
      "Train Epoch: 4 [7000/7961 (88%)]\tLoss: 0.556013\n",
      "Train Epoch: 5 [0/7961 (0%)]\tLoss: 0.549631\n",
      "Train Epoch: 5 [1000/7961 (12%)]\tLoss: 0.566014\n",
      "Train Epoch: 5 [2000/7961 (25%)]\tLoss: 0.706482\n",
      "Train Epoch: 5 [3000/7961 (38%)]\tLoss: 0.693416\n",
      "Train Epoch: 5 [4000/7961 (50%)]\tLoss: 0.582505\n",
      "Train Epoch: 5 [5000/7961 (62%)]\tLoss: 0.555524\n",
      "Train Epoch: 5 [6000/7961 (75%)]\tLoss: 0.570971\n",
      "Train Epoch: 5 [7000/7961 (88%)]\tLoss: 0.471811\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/15584 (0%)]\tLoss: 0.882508\n",
      "Train Epoch: 1 [1000/15584 (6%)]\tLoss: 0.539378\n",
      "Train Epoch: 1 [2000/15584 (13%)]\tLoss: 0.399288\n",
      "Train Epoch: 1 [3000/15584 (19%)]\tLoss: 0.678923\n",
      "Train Epoch: 1 [4000/15584 (26%)]\tLoss: 0.473849\n",
      "Train Epoch: 1 [5000/15584 (32%)]\tLoss: 0.405026\n",
      "Train Epoch: 1 [6000/15584 (38%)]\tLoss: 0.454073\n",
      "Train Epoch: 1 [7000/15584 (45%)]\tLoss: 0.444967\n",
      "Train Epoch: 1 [8000/15584 (51%)]\tLoss: 0.389006\n",
      "Train Epoch: 1 [9000/15584 (58%)]\tLoss: 0.417466\n",
      "Train Epoch: 1 [10000/15584 (64%)]\tLoss: 0.584911\n",
      "Train Epoch: 1 [11000/15584 (71%)]\tLoss: 0.381987\n",
      "Train Epoch: 1 [12000/15584 (77%)]\tLoss: 0.402791\n",
      "Train Epoch: 1 [13000/15584 (83%)]\tLoss: 0.369319\n",
      "Train Epoch: 1 [14000/15584 (90%)]\tLoss: 0.414972\n",
      "Train Epoch: 1 [15000/15584 (96%)]\tLoss: 0.628428\n",
      "Train Epoch: 2 [0/15584 (0%)]\tLoss: 0.535804\n",
      "Train Epoch: 2 [1000/15584 (6%)]\tLoss: 0.522872\n",
      "Train Epoch: 2 [2000/15584 (13%)]\tLoss: 0.448441\n",
      "Train Epoch: 2 [3000/15584 (19%)]\tLoss: 0.569903\n",
      "Train Epoch: 2 [4000/15584 (26%)]\tLoss: 0.481941\n",
      "Train Epoch: 2 [5000/15584 (32%)]\tLoss: 0.463311\n",
      "Train Epoch: 2 [6000/15584 (38%)]\tLoss: 0.422031\n",
      "Train Epoch: 2 [7000/15584 (45%)]\tLoss: 0.516398\n",
      "Train Epoch: 2 [8000/15584 (51%)]\tLoss: 0.385331\n",
      "Train Epoch: 2 [9000/15584 (58%)]\tLoss: 0.476814\n",
      "Train Epoch: 2 [10000/15584 (64%)]\tLoss: 0.412040\n",
      "Train Epoch: 2 [11000/15584 (71%)]\tLoss: 0.384136\n",
      "Train Epoch: 2 [12000/15584 (77%)]\tLoss: 0.359654\n",
      "Train Epoch: 2 [13000/15584 (83%)]\tLoss: 0.525760\n",
      "Train Epoch: 2 [14000/15584 (90%)]\tLoss: 0.447803\n",
      "Train Epoch: 2 [15000/15584 (96%)]\tLoss: 0.420316\n",
      "Train Epoch: 3 [0/15584 (0%)]\tLoss: 0.372999\n",
      "Train Epoch: 3 [1000/15584 (6%)]\tLoss: 0.481597\n",
      "Train Epoch: 3 [2000/15584 (13%)]\tLoss: 0.310669\n",
      "Train Epoch: 3 [3000/15584 (19%)]\tLoss: 0.267290\n",
      "Train Epoch: 3 [4000/15584 (26%)]\tLoss: 0.320882\n",
      "Train Epoch: 3 [5000/15584 (32%)]\tLoss: 0.385265\n",
      "Train Epoch: 3 [6000/15584 (38%)]\tLoss: 0.527084\n",
      "Train Epoch: 3 [7000/15584 (45%)]\tLoss: 0.333035\n",
      "Train Epoch: 3 [8000/15584 (51%)]\tLoss: 0.452800\n",
      "Train Epoch: 3 [9000/15584 (58%)]\tLoss: 0.465971\n",
      "Train Epoch: 3 [10000/15584 (64%)]\tLoss: 0.306339\n",
      "Train Epoch: 3 [11000/15584 (71%)]\tLoss: 0.389804\n",
      "Train Epoch: 3 [12000/15584 (77%)]\tLoss: 0.376782\n",
      "Train Epoch: 3 [13000/15584 (83%)]\tLoss: 0.355440\n",
      "Train Epoch: 3 [14000/15584 (90%)]\tLoss: 0.337346\n",
      "Train Epoch: 3 [15000/15584 (96%)]\tLoss: 0.400739\n",
      "Train Epoch: 4 [0/15584 (0%)]\tLoss: 0.352402\n",
      "Train Epoch: 4 [1000/15584 (6%)]\tLoss: 0.514899\n",
      "Train Epoch: 4 [2000/15584 (13%)]\tLoss: 0.375488\n",
      "Train Epoch: 4 [3000/15584 (19%)]\tLoss: 0.396022\n",
      "Train Epoch: 4 [4000/15584 (26%)]\tLoss: 0.330311\n",
      "Train Epoch: 4 [5000/15584 (32%)]\tLoss: 0.348676\n",
      "Train Epoch: 4 [6000/15584 (38%)]\tLoss: 0.364918\n",
      "Train Epoch: 4 [7000/15584 (45%)]\tLoss: 0.435391\n",
      "Train Epoch: 4 [8000/15584 (51%)]\tLoss: 0.389208\n",
      "Train Epoch: 4 [9000/15584 (58%)]\tLoss: 0.356972\n",
      "Train Epoch: 4 [10000/15584 (64%)]\tLoss: 0.433668\n",
      "Train Epoch: 4 [11000/15584 (71%)]\tLoss: 0.418022\n",
      "Train Epoch: 4 [12000/15584 (77%)]\tLoss: 0.396784\n",
      "Train Epoch: 4 [13000/15584 (83%)]\tLoss: 0.327869\n",
      "Train Epoch: 4 [14000/15584 (90%)]\tLoss: 0.457422\n",
      "Train Epoch: 4 [15000/15584 (96%)]\tLoss: 0.261010\n",
      "Train Epoch: 5 [0/15584 (0%)]\tLoss: 0.362613\n",
      "Train Epoch: 5 [1000/15584 (6%)]\tLoss: 0.644128\n",
      "Train Epoch: 5 [2000/15584 (13%)]\tLoss: 0.416127\n",
      "Train Epoch: 5 [3000/15584 (19%)]\tLoss: 0.389813\n",
      "Train Epoch: 5 [4000/15584 (26%)]\tLoss: 0.271341\n",
      "Train Epoch: 5 [5000/15584 (32%)]\tLoss: 0.299678\n",
      "Train Epoch: 5 [6000/15584 (38%)]\tLoss: 0.366258\n",
      "Train Epoch: 5 [7000/15584 (45%)]\tLoss: 0.428318\n",
      "Train Epoch: 5 [8000/15584 (51%)]\tLoss: 0.485762\n",
      "Train Epoch: 5 [9000/15584 (58%)]\tLoss: 0.418077\n",
      "Train Epoch: 5 [10000/15584 (64%)]\tLoss: 0.596501\n",
      "Train Epoch: 5 [11000/15584 (71%)]\tLoss: 0.361070\n",
      "Train Epoch: 5 [12000/15584 (77%)]\tLoss: 0.358384\n",
      "Train Epoch: 5 [13000/15584 (83%)]\tLoss: 0.349792\n",
      "Train Epoch: 5 [14000/15584 (90%)]\tLoss: 0.293268\n",
      "Train Epoch: 5 [15000/15584 (96%)]\tLoss: 0.340169\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/12481 (0%)]\tLoss: 0.334636\n",
      "Train Epoch: 1 [1000/12481 (8%)]\tLoss: 0.439668\n",
      "Train Epoch: 1 [2000/12481 (16%)]\tLoss: 0.334925\n",
      "Train Epoch: 1 [3000/12481 (24%)]\tLoss: 0.324199\n",
      "Train Epoch: 1 [4000/12481 (32%)]\tLoss: 0.279774\n",
      "Train Epoch: 1 [5000/12481 (40%)]\tLoss: 0.295896\n",
      "Train Epoch: 1 [6000/12481 (48%)]\tLoss: 0.343496\n",
      "Train Epoch: 1 [7000/12481 (56%)]\tLoss: 0.303906\n",
      "Train Epoch: 1 [8000/12481 (64%)]\tLoss: 0.471131\n",
      "Train Epoch: 1 [9000/12481 (72%)]\tLoss: 0.351912\n",
      "Train Epoch: 1 [10000/12481 (80%)]\tLoss: 0.376101\n",
      "Train Epoch: 1 [11000/12481 (88%)]\tLoss: 0.246503\n",
      "Train Epoch: 1 [12000/12481 (96%)]\tLoss: 0.331665\n",
      "Train Epoch: 2 [0/12481 (0%)]\tLoss: 0.478654\n",
      "Train Epoch: 2 [1000/12481 (8%)]\tLoss: 0.211191\n",
      "Train Epoch: 2 [2000/12481 (16%)]\tLoss: 0.339149\n",
      "Train Epoch: 2 [3000/12481 (24%)]\tLoss: 0.422547\n",
      "Train Epoch: 2 [4000/12481 (32%)]\tLoss: 0.280525\n",
      "Train Epoch: 2 [5000/12481 (40%)]\tLoss: 0.298577\n",
      "Train Epoch: 2 [6000/12481 (48%)]\tLoss: 0.405989\n",
      "Train Epoch: 2 [7000/12481 (56%)]\tLoss: 0.403390\n",
      "Train Epoch: 2 [8000/12481 (64%)]\tLoss: 0.315826\n",
      "Train Epoch: 2 [9000/12481 (72%)]\tLoss: 0.360034\n",
      "Train Epoch: 2 [10000/12481 (80%)]\tLoss: 0.223543\n",
      "Train Epoch: 2 [11000/12481 (88%)]\tLoss: 0.440814\n",
      "Train Epoch: 2 [12000/12481 (96%)]\tLoss: 0.298393\n",
      "Train Epoch: 3 [0/12481 (0%)]\tLoss: 0.293074\n",
      "Train Epoch: 3 [1000/12481 (8%)]\tLoss: 0.301483\n",
      "Train Epoch: 3 [2000/12481 (16%)]\tLoss: 0.422932\n",
      "Train Epoch: 3 [3000/12481 (24%)]\tLoss: 0.294035\n",
      "Train Epoch: 3 [4000/12481 (32%)]\tLoss: 0.444641\n",
      "Train Epoch: 3 [5000/12481 (40%)]\tLoss: 0.251950\n",
      "Train Epoch: 3 [6000/12481 (48%)]\tLoss: 0.204951\n",
      "Train Epoch: 3 [7000/12481 (56%)]\tLoss: 0.420883\n",
      "Train Epoch: 3 [8000/12481 (64%)]\tLoss: 0.411682\n",
      "Train Epoch: 3 [9000/12481 (72%)]\tLoss: 0.206897\n",
      "Train Epoch: 3 [10000/12481 (80%)]\tLoss: 0.475180\n",
      "Train Epoch: 3 [11000/12481 (88%)]\tLoss: 0.266569\n",
      "Train Epoch: 3 [12000/12481 (96%)]\tLoss: 0.293707\n",
      "Train Epoch: 4 [0/12481 (0%)]\tLoss: 0.341303\n",
      "Train Epoch: 4 [1000/12481 (8%)]\tLoss: 0.370041\n",
      "Train Epoch: 4 [2000/12481 (16%)]\tLoss: 0.463775\n",
      "Train Epoch: 4 [3000/12481 (24%)]\tLoss: 0.294854\n",
      "Train Epoch: 4 [4000/12481 (32%)]\tLoss: 0.159870\n",
      "Train Epoch: 4 [5000/12481 (40%)]\tLoss: 0.259937\n",
      "Train Epoch: 4 [6000/12481 (48%)]\tLoss: 0.400753\n",
      "Train Epoch: 4 [7000/12481 (56%)]\tLoss: 0.561154\n",
      "Train Epoch: 4 [8000/12481 (64%)]\tLoss: 0.245773\n",
      "Train Epoch: 4 [9000/12481 (72%)]\tLoss: 0.266283\n",
      "Train Epoch: 4 [10000/12481 (80%)]\tLoss: 0.464190\n",
      "Train Epoch: 4 [11000/12481 (88%)]\tLoss: 0.273516\n",
      "Train Epoch: 4 [12000/12481 (96%)]\tLoss: 0.237881\n",
      "Train Epoch: 5 [0/12481 (0%)]\tLoss: 0.250914\n",
      "Train Epoch: 5 [1000/12481 (8%)]\tLoss: 0.278008\n",
      "Train Epoch: 5 [2000/12481 (16%)]\tLoss: 0.464015\n",
      "Train Epoch: 5 [3000/12481 (24%)]\tLoss: 0.290573\n",
      "Train Epoch: 5 [4000/12481 (32%)]\tLoss: 0.271709\n",
      "Train Epoch: 5 [5000/12481 (40%)]\tLoss: 0.334555\n",
      "Train Epoch: 5 [6000/12481 (48%)]\tLoss: 0.362910\n",
      "Train Epoch: 5 [7000/12481 (56%)]\tLoss: 0.273651\n",
      "Train Epoch: 5 [8000/12481 (64%)]\tLoss: 0.366966\n",
      "Train Epoch: 5 [9000/12481 (72%)]\tLoss: 0.396205\n",
      "Train Epoch: 5 [10000/12481 (80%)]\tLoss: 0.369902\n",
      "Train Epoch: 5 [11000/12481 (88%)]\tLoss: 0.325656\n",
      "Train Epoch: 5 [12000/12481 (96%)]\tLoss: 0.208844\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "4\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9420, Accuracy: 7326/10000 (73%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/23974 (0%)]\tLoss: 0.737166\n",
      "Train Epoch: 1 [1000/23974 (4%)]\tLoss: 0.616724\n",
      "Train Epoch: 1 [2000/23974 (8%)]\tLoss: 0.650802\n",
      "Train Epoch: 1 [3000/23974 (12%)]\tLoss: 0.490918\n",
      "Train Epoch: 1 [4000/23974 (17%)]\tLoss: 0.491129\n",
      "Train Epoch: 1 [5000/23974 (21%)]\tLoss: 0.437152\n",
      "Train Epoch: 1 [6000/23974 (25%)]\tLoss: 0.566952\n",
      "Train Epoch: 1 [7000/23974 (29%)]\tLoss: 0.494616\n",
      "Train Epoch: 1 [8000/23974 (33%)]\tLoss: 0.574499\n",
      "Train Epoch: 1 [9000/23974 (38%)]\tLoss: 0.472320\n",
      "Train Epoch: 1 [10000/23974 (42%)]\tLoss: 0.354183\n",
      "Train Epoch: 1 [11000/23974 (46%)]\tLoss: 0.545010\n",
      "Train Epoch: 1 [12000/23974 (50%)]\tLoss: 0.426150\n",
      "Train Epoch: 1 [13000/23974 (54%)]\tLoss: 0.339669\n",
      "Train Epoch: 1 [14000/23974 (58%)]\tLoss: 0.351052\n",
      "Train Epoch: 1 [15000/23974 (62%)]\tLoss: 0.430141\n",
      "Train Epoch: 1 [16000/23974 (67%)]\tLoss: 0.435058\n",
      "Train Epoch: 1 [17000/23974 (71%)]\tLoss: 0.464964\n",
      "Train Epoch: 1 [18000/23974 (75%)]\tLoss: 0.544123\n",
      "Train Epoch: 1 [19000/23974 (79%)]\tLoss: 0.645361\n",
      "Train Epoch: 1 [20000/23974 (83%)]\tLoss: 0.539378\n",
      "Train Epoch: 1 [21000/23974 (88%)]\tLoss: 0.371654\n",
      "Train Epoch: 1 [22000/23974 (92%)]\tLoss: 0.453683\n",
      "Train Epoch: 1 [23000/23974 (96%)]\tLoss: 0.492661\n",
      "Train Epoch: 2 [0/23974 (0%)]\tLoss: 0.572777\n",
      "Train Epoch: 2 [1000/23974 (4%)]\tLoss: 0.340768\n",
      "Train Epoch: 2 [2000/23974 (8%)]\tLoss: 0.394963\n",
      "Train Epoch: 2 [3000/23974 (12%)]\tLoss: 0.510376\n",
      "Train Epoch: 2 [4000/23974 (17%)]\tLoss: 0.564489\n",
      "Train Epoch: 2 [5000/23974 (21%)]\tLoss: 0.630053\n",
      "Train Epoch: 2 [6000/23974 (25%)]\tLoss: 0.637771\n",
      "Train Epoch: 2 [7000/23974 (29%)]\tLoss: 0.474195\n",
      "Train Epoch: 2 [8000/23974 (33%)]\tLoss: 0.496790\n",
      "Train Epoch: 2 [9000/23974 (38%)]\tLoss: 0.495804\n",
      "Train Epoch: 2 [10000/23974 (42%)]\tLoss: 0.513100\n",
      "Train Epoch: 2 [11000/23974 (46%)]\tLoss: 0.585218\n",
      "Train Epoch: 2 [12000/23974 (50%)]\tLoss: 0.490608\n",
      "Train Epoch: 2 [13000/23974 (54%)]\tLoss: 0.486742\n",
      "Train Epoch: 2 [14000/23974 (58%)]\tLoss: 0.406106\n",
      "Train Epoch: 2 [15000/23974 (62%)]\tLoss: 0.411425\n",
      "Train Epoch: 2 [16000/23974 (67%)]\tLoss: 0.446459\n",
      "Train Epoch: 2 [17000/23974 (71%)]\tLoss: 0.389837\n",
      "Train Epoch: 2 [18000/23974 (75%)]\tLoss: 0.397327\n",
      "Train Epoch: 2 [19000/23974 (79%)]\tLoss: 0.442231\n",
      "Train Epoch: 2 [20000/23974 (83%)]\tLoss: 0.531953\n",
      "Train Epoch: 2 [21000/23974 (88%)]\tLoss: 0.469627\n",
      "Train Epoch: 2 [22000/23974 (92%)]\tLoss: 0.385236\n",
      "Train Epoch: 2 [23000/23974 (96%)]\tLoss: 0.424786\n",
      "Train Epoch: 3 [0/23974 (0%)]\tLoss: 0.463495\n",
      "Train Epoch: 3 [1000/23974 (4%)]\tLoss: 0.488545\n",
      "Train Epoch: 3 [2000/23974 (8%)]\tLoss: 0.671507\n",
      "Train Epoch: 3 [3000/23974 (12%)]\tLoss: 0.475135\n",
      "Train Epoch: 3 [4000/23974 (17%)]\tLoss: 0.537283\n",
      "Train Epoch: 3 [5000/23974 (21%)]\tLoss: 0.488650\n",
      "Train Epoch: 3 [6000/23974 (25%)]\tLoss: 0.616006\n",
      "Train Epoch: 3 [7000/23974 (29%)]\tLoss: 0.493212\n",
      "Train Epoch: 3 [8000/23974 (33%)]\tLoss: 0.359716\n",
      "Train Epoch: 3 [9000/23974 (38%)]\tLoss: 0.363045\n",
      "Train Epoch: 3 [10000/23974 (42%)]\tLoss: 0.599893\n",
      "Train Epoch: 3 [11000/23974 (46%)]\tLoss: 0.536913\n",
      "Train Epoch: 3 [12000/23974 (50%)]\tLoss: 0.444182\n",
      "Train Epoch: 3 [13000/23974 (54%)]\tLoss: 0.582402\n",
      "Train Epoch: 3 [14000/23974 (58%)]\tLoss: 0.430836\n",
      "Train Epoch: 3 [15000/23974 (62%)]\tLoss: 0.522579\n",
      "Train Epoch: 3 [16000/23974 (67%)]\tLoss: 0.508634\n",
      "Train Epoch: 3 [17000/23974 (71%)]\tLoss: 0.408000\n",
      "Train Epoch: 3 [18000/23974 (75%)]\tLoss: 0.501860\n",
      "Train Epoch: 3 [19000/23974 (79%)]\tLoss: 0.512820\n",
      "Train Epoch: 3 [20000/23974 (83%)]\tLoss: 0.496673\n",
      "Train Epoch: 3 [21000/23974 (88%)]\tLoss: 0.320059\n",
      "Train Epoch: 3 [22000/23974 (92%)]\tLoss: 0.378559\n",
      "Train Epoch: 3 [23000/23974 (96%)]\tLoss: 0.435676\n",
      "Train Epoch: 4 [0/23974 (0%)]\tLoss: 0.383638\n",
      "Train Epoch: 4 [1000/23974 (4%)]\tLoss: 0.447957\n",
      "Train Epoch: 4 [2000/23974 (8%)]\tLoss: 0.436360\n",
      "Train Epoch: 4 [3000/23974 (12%)]\tLoss: 0.628523\n",
      "Train Epoch: 4 [4000/23974 (17%)]\tLoss: 0.427172\n",
      "Train Epoch: 4 [5000/23974 (21%)]\tLoss: 0.601353\n",
      "Train Epoch: 4 [6000/23974 (25%)]\tLoss: 0.524796\n",
      "Train Epoch: 4 [7000/23974 (29%)]\tLoss: 0.554362\n",
      "Train Epoch: 4 [8000/23974 (33%)]\tLoss: 0.417396\n",
      "Train Epoch: 4 [9000/23974 (38%)]\tLoss: 0.559184\n",
      "Train Epoch: 4 [10000/23974 (42%)]\tLoss: 0.475490\n",
      "Train Epoch: 4 [11000/23974 (46%)]\tLoss: 0.429558\n",
      "Train Epoch: 4 [12000/23974 (50%)]\tLoss: 0.524331\n",
      "Train Epoch: 4 [13000/23974 (54%)]\tLoss: 0.470087\n",
      "Train Epoch: 4 [14000/23974 (58%)]\tLoss: 0.370695\n",
      "Train Epoch: 4 [15000/23974 (62%)]\tLoss: 0.503576\n",
      "Train Epoch: 4 [16000/23974 (67%)]\tLoss: 0.404035\n",
      "Train Epoch: 4 [17000/23974 (71%)]\tLoss: 0.325288\n",
      "Train Epoch: 4 [18000/23974 (75%)]\tLoss: 0.406814\n",
      "Train Epoch: 4 [19000/23974 (79%)]\tLoss: 0.452020\n",
      "Train Epoch: 4 [20000/23974 (83%)]\tLoss: 0.340035\n",
      "Train Epoch: 4 [21000/23974 (88%)]\tLoss: 0.449159\n",
      "Train Epoch: 4 [22000/23974 (92%)]\tLoss: 0.489094\n",
      "Train Epoch: 4 [23000/23974 (96%)]\tLoss: 0.468058\n",
      "Train Epoch: 5 [0/23974 (0%)]\tLoss: 0.491243\n",
      "Train Epoch: 5 [1000/23974 (4%)]\tLoss: 0.266959\n",
      "Train Epoch: 5 [2000/23974 (8%)]\tLoss: 0.405275\n",
      "Train Epoch: 5 [3000/23974 (12%)]\tLoss: 0.570749\n",
      "Train Epoch: 5 [4000/23974 (17%)]\tLoss: 0.301468\n",
      "Train Epoch: 5 [5000/23974 (21%)]\tLoss: 0.453918\n",
      "Train Epoch: 5 [6000/23974 (25%)]\tLoss: 0.491631\n",
      "Train Epoch: 5 [7000/23974 (29%)]\tLoss: 0.479353\n",
      "Train Epoch: 5 [8000/23974 (33%)]\tLoss: 0.476755\n",
      "Train Epoch: 5 [9000/23974 (38%)]\tLoss: 0.479100\n",
      "Train Epoch: 5 [10000/23974 (42%)]\tLoss: 0.264695\n",
      "Train Epoch: 5 [11000/23974 (46%)]\tLoss: 0.581964\n",
      "Train Epoch: 5 [12000/23974 (50%)]\tLoss: 0.388429\n",
      "Train Epoch: 5 [13000/23974 (54%)]\tLoss: 0.695278\n",
      "Train Epoch: 5 [14000/23974 (58%)]\tLoss: 0.555525\n",
      "Train Epoch: 5 [15000/23974 (62%)]\tLoss: 0.584483\n",
      "Train Epoch: 5 [16000/23974 (67%)]\tLoss: 0.321233\n",
      "Train Epoch: 5 [17000/23974 (71%)]\tLoss: 0.428787\n",
      "Train Epoch: 5 [18000/23974 (75%)]\tLoss: 0.344397\n",
      "Train Epoch: 5 [19000/23974 (79%)]\tLoss: 0.325616\n",
      "Train Epoch: 5 [20000/23974 (83%)]\tLoss: 0.462925\n",
      "Train Epoch: 5 [21000/23974 (88%)]\tLoss: 0.446503\n",
      "Train Epoch: 5 [22000/23974 (92%)]\tLoss: 0.355414\n",
      "Train Epoch: 5 [23000/23974 (96%)]\tLoss: 0.410025\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7961 (0%)]\tLoss: 0.877475\n",
      "Train Epoch: 1 [1000/7961 (12%)]\tLoss: 0.664645\n",
      "Train Epoch: 1 [2000/7961 (25%)]\tLoss: 0.562089\n",
      "Train Epoch: 1 [3000/7961 (38%)]\tLoss: 0.706341\n",
      "Train Epoch: 1 [4000/7961 (50%)]\tLoss: 0.537634\n",
      "Train Epoch: 1 [5000/7961 (62%)]\tLoss: 0.726081\n",
      "Train Epoch: 1 [6000/7961 (75%)]\tLoss: 0.602794\n",
      "Train Epoch: 1 [7000/7961 (88%)]\tLoss: 0.586672\n",
      "Train Epoch: 2 [0/7961 (0%)]\tLoss: 0.521249\n",
      "Train Epoch: 2 [1000/7961 (12%)]\tLoss: 0.598539\n",
      "Train Epoch: 2 [2000/7961 (25%)]\tLoss: 0.709725\n",
      "Train Epoch: 2 [3000/7961 (38%)]\tLoss: 0.764758\n",
      "Train Epoch: 2 [4000/7961 (50%)]\tLoss: 0.796241\n",
      "Train Epoch: 2 [5000/7961 (62%)]\tLoss: 0.519693\n",
      "Train Epoch: 2 [6000/7961 (75%)]\tLoss: 0.865133\n",
      "Train Epoch: 2 [7000/7961 (88%)]\tLoss: 0.479889\n",
      "Train Epoch: 3 [0/7961 (0%)]\tLoss: 0.578857\n",
      "Train Epoch: 3 [1000/7961 (12%)]\tLoss: 0.732702\n",
      "Train Epoch: 3 [2000/7961 (25%)]\tLoss: 0.455652\n",
      "Train Epoch: 3 [3000/7961 (38%)]\tLoss: 0.691838\n",
      "Train Epoch: 3 [4000/7961 (50%)]\tLoss: 0.396101\n",
      "Train Epoch: 3 [5000/7961 (62%)]\tLoss: 0.430823\n",
      "Train Epoch: 3 [6000/7961 (75%)]\tLoss: 0.660069\n",
      "Train Epoch: 3 [7000/7961 (88%)]\tLoss: 0.593689\n",
      "Train Epoch: 4 [0/7961 (0%)]\tLoss: 0.675919\n",
      "Train Epoch: 4 [1000/7961 (12%)]\tLoss: 0.687561\n",
      "Train Epoch: 4 [2000/7961 (25%)]\tLoss: 0.612905\n",
      "Train Epoch: 4 [3000/7961 (38%)]\tLoss: 0.548669\n",
      "Train Epoch: 4 [4000/7961 (50%)]\tLoss: 0.633036\n",
      "Train Epoch: 4 [5000/7961 (62%)]\tLoss: 0.472304\n",
      "Train Epoch: 4 [6000/7961 (75%)]\tLoss: 0.573245\n",
      "Train Epoch: 4 [7000/7961 (88%)]\tLoss: 0.505485\n",
      "Train Epoch: 5 [0/7961 (0%)]\tLoss: 0.885385\n",
      "Train Epoch: 5 [1000/7961 (12%)]\tLoss: 0.610699\n",
      "Train Epoch: 5 [2000/7961 (25%)]\tLoss: 0.621027\n",
      "Train Epoch: 5 [3000/7961 (38%)]\tLoss: 0.666164\n",
      "Train Epoch: 5 [4000/7961 (50%)]\tLoss: 0.558461\n",
      "Train Epoch: 5 [5000/7961 (62%)]\tLoss: 0.479147\n",
      "Train Epoch: 5 [6000/7961 (75%)]\tLoss: 0.604814\n",
      "Train Epoch: 5 [7000/7961 (88%)]\tLoss: 0.455659\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "4\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9563, Accuracy: 7428/10000 (74%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/23974 (0%)]\tLoss: 0.332838\n",
      "Train Epoch: 1 [1000/23974 (4%)]\tLoss: 0.437916\n",
      "Train Epoch: 1 [2000/23974 (8%)]\tLoss: 0.475254\n",
      "Train Epoch: 1 [3000/23974 (12%)]\tLoss: 0.407162\n",
      "Train Epoch: 1 [4000/23974 (17%)]\tLoss: 0.400785\n",
      "Train Epoch: 1 [5000/23974 (21%)]\tLoss: 0.433807\n",
      "Train Epoch: 1 [6000/23974 (25%)]\tLoss: 0.516395\n",
      "Train Epoch: 1 [7000/23974 (29%)]\tLoss: 0.478826\n",
      "Train Epoch: 1 [8000/23974 (33%)]\tLoss: 0.550400\n",
      "Train Epoch: 1 [9000/23974 (38%)]\tLoss: 0.359965\n",
      "Train Epoch: 1 [10000/23974 (42%)]\tLoss: 0.431808\n",
      "Train Epoch: 1 [11000/23974 (46%)]\tLoss: 0.571034\n",
      "Train Epoch: 1 [12000/23974 (50%)]\tLoss: 0.545933\n",
      "Train Epoch: 1 [13000/23974 (54%)]\tLoss: 0.449970\n",
      "Train Epoch: 1 [14000/23974 (58%)]\tLoss: 0.357186\n",
      "Train Epoch: 1 [15000/23974 (62%)]\tLoss: 0.445110\n",
      "Train Epoch: 1 [16000/23974 (67%)]\tLoss: 0.468452\n",
      "Train Epoch: 1 [17000/23974 (71%)]\tLoss: 0.496526\n",
      "Train Epoch: 1 [18000/23974 (75%)]\tLoss: 0.651642\n",
      "Train Epoch: 1 [19000/23974 (79%)]\tLoss: 0.486360\n",
      "Train Epoch: 1 [20000/23974 (83%)]\tLoss: 0.483636\n",
      "Train Epoch: 1 [21000/23974 (88%)]\tLoss: 0.488029\n",
      "Train Epoch: 1 [22000/23974 (92%)]\tLoss: 0.401464\n",
      "Train Epoch: 1 [23000/23974 (96%)]\tLoss: 0.457813\n",
      "Train Epoch: 2 [0/23974 (0%)]\tLoss: 0.481543\n",
      "Train Epoch: 2 [1000/23974 (4%)]\tLoss: 0.447662\n",
      "Train Epoch: 2 [2000/23974 (8%)]\tLoss: 0.476072\n",
      "Train Epoch: 2 [3000/23974 (12%)]\tLoss: 0.455869\n",
      "Train Epoch: 2 [4000/23974 (17%)]\tLoss: 0.661564\n",
      "Train Epoch: 2 [5000/23974 (21%)]\tLoss: 0.583039\n",
      "Train Epoch: 2 [6000/23974 (25%)]\tLoss: 0.442385\n",
      "Train Epoch: 2 [7000/23974 (29%)]\tLoss: 0.463774\n",
      "Train Epoch: 2 [8000/23974 (33%)]\tLoss: 0.523479\n",
      "Train Epoch: 2 [9000/23974 (38%)]\tLoss: 0.359680\n",
      "Train Epoch: 2 [10000/23974 (42%)]\tLoss: 0.416875\n",
      "Train Epoch: 2 [11000/23974 (46%)]\tLoss: 0.461336\n",
      "Train Epoch: 2 [12000/23974 (50%)]\tLoss: 0.423269\n",
      "Train Epoch: 2 [13000/23974 (54%)]\tLoss: 0.413327\n",
      "Train Epoch: 2 [14000/23974 (58%)]\tLoss: 0.402841\n",
      "Train Epoch: 2 [15000/23974 (62%)]\tLoss: 0.526427\n",
      "Train Epoch: 2 [16000/23974 (67%)]\tLoss: 0.548963\n",
      "Train Epoch: 2 [17000/23974 (71%)]\tLoss: 0.291482\n",
      "Train Epoch: 2 [18000/23974 (75%)]\tLoss: 0.240728\n",
      "Train Epoch: 2 [19000/23974 (79%)]\tLoss: 0.431606\n",
      "Train Epoch: 2 [20000/23974 (83%)]\tLoss: 0.423064\n",
      "Train Epoch: 2 [21000/23974 (88%)]\tLoss: 0.512947\n",
      "Train Epoch: 2 [22000/23974 (92%)]\tLoss: 0.326436\n",
      "Train Epoch: 2 [23000/23974 (96%)]\tLoss: 0.460726\n",
      "Train Epoch: 3 [0/23974 (0%)]\tLoss: 0.437537\n",
      "Train Epoch: 3 [1000/23974 (4%)]\tLoss: 0.462955\n",
      "Train Epoch: 3 [2000/23974 (8%)]\tLoss: 0.454124\n",
      "Train Epoch: 3 [3000/23974 (12%)]\tLoss: 0.306701\n",
      "Train Epoch: 3 [4000/23974 (17%)]\tLoss: 0.664374\n",
      "Train Epoch: 3 [5000/23974 (21%)]\tLoss: 0.486999\n",
      "Train Epoch: 3 [6000/23974 (25%)]\tLoss: 0.580770\n",
      "Train Epoch: 3 [7000/23974 (29%)]\tLoss: 0.458621\n",
      "Train Epoch: 3 [8000/23974 (33%)]\tLoss: 0.487858\n",
      "Train Epoch: 3 [9000/23974 (38%)]\tLoss: 0.300285\n",
      "Train Epoch: 3 [10000/23974 (42%)]\tLoss: 0.453869\n",
      "Train Epoch: 3 [11000/23974 (46%)]\tLoss: 0.339552\n",
      "Train Epoch: 3 [12000/23974 (50%)]\tLoss: 0.371642\n",
      "Train Epoch: 3 [13000/23974 (54%)]\tLoss: 0.448583\n",
      "Train Epoch: 3 [14000/23974 (58%)]\tLoss: 0.414551\n",
      "Train Epoch: 3 [15000/23974 (62%)]\tLoss: 0.342144\n",
      "Train Epoch: 3 [16000/23974 (67%)]\tLoss: 0.430373\n",
      "Train Epoch: 3 [17000/23974 (71%)]\tLoss: 0.501266\n",
      "Train Epoch: 3 [18000/23974 (75%)]\tLoss: 0.364671\n",
      "Train Epoch: 3 [19000/23974 (79%)]\tLoss: 0.440373\n",
      "Train Epoch: 3 [20000/23974 (83%)]\tLoss: 0.431685\n",
      "Train Epoch: 3 [21000/23974 (88%)]\tLoss: 0.574217\n",
      "Train Epoch: 3 [22000/23974 (92%)]\tLoss: 0.524624\n",
      "Train Epoch: 3 [23000/23974 (96%)]\tLoss: 0.392068\n",
      "Train Epoch: 4 [0/23974 (0%)]\tLoss: 0.621748\n",
      "Train Epoch: 4 [1000/23974 (4%)]\tLoss: 0.371000\n",
      "Train Epoch: 4 [2000/23974 (8%)]\tLoss: 0.489811\n",
      "Train Epoch: 4 [3000/23974 (12%)]\tLoss: 0.377652\n",
      "Train Epoch: 4 [4000/23974 (17%)]\tLoss: 0.407210\n",
      "Train Epoch: 4 [5000/23974 (21%)]\tLoss: 0.502800\n",
      "Train Epoch: 4 [6000/23974 (25%)]\tLoss: 0.511794\n",
      "Train Epoch: 4 [7000/23974 (29%)]\tLoss: 0.320206\n",
      "Train Epoch: 4 [8000/23974 (33%)]\tLoss: 0.366702\n",
      "Train Epoch: 4 [9000/23974 (38%)]\tLoss: 0.341965\n",
      "Train Epoch: 4 [10000/23974 (42%)]\tLoss: 0.416717\n",
      "Train Epoch: 4 [11000/23974 (46%)]\tLoss: 0.394977\n",
      "Train Epoch: 4 [12000/23974 (50%)]\tLoss: 0.335627\n",
      "Train Epoch: 4 [13000/23974 (54%)]\tLoss: 0.601810\n",
      "Train Epoch: 4 [14000/23974 (58%)]\tLoss: 0.455050\n",
      "Train Epoch: 4 [15000/23974 (62%)]\tLoss: 0.429918\n",
      "Train Epoch: 4 [16000/23974 (67%)]\tLoss: 0.496024\n",
      "Train Epoch: 4 [17000/23974 (71%)]\tLoss: 0.342761\n",
      "Train Epoch: 4 [18000/23974 (75%)]\tLoss: 0.381960\n",
      "Train Epoch: 4 [19000/23974 (79%)]\tLoss: 0.583406\n",
      "Train Epoch: 4 [20000/23974 (83%)]\tLoss: 0.395091\n",
      "Train Epoch: 4 [21000/23974 (88%)]\tLoss: 0.493315\n",
      "Train Epoch: 4 [22000/23974 (92%)]\tLoss: 0.422103\n",
      "Train Epoch: 4 [23000/23974 (96%)]\tLoss: 0.458879\n",
      "Train Epoch: 5 [0/23974 (0%)]\tLoss: 0.521362\n",
      "Train Epoch: 5 [1000/23974 (4%)]\tLoss: 0.456410\n",
      "Train Epoch: 5 [2000/23974 (8%)]\tLoss: 0.370245\n",
      "Train Epoch: 5 [3000/23974 (12%)]\tLoss: 0.444410\n",
      "Train Epoch: 5 [4000/23974 (17%)]\tLoss: 0.335615\n",
      "Train Epoch: 5 [5000/23974 (21%)]\tLoss: 0.352486\n",
      "Train Epoch: 5 [6000/23974 (25%)]\tLoss: 0.404434\n",
      "Train Epoch: 5 [7000/23974 (29%)]\tLoss: 0.431316\n",
      "Train Epoch: 5 [8000/23974 (33%)]\tLoss: 0.548054\n",
      "Train Epoch: 5 [9000/23974 (38%)]\tLoss: 0.386400\n",
      "Train Epoch: 5 [10000/23974 (42%)]\tLoss: 0.582319\n",
      "Train Epoch: 5 [11000/23974 (46%)]\tLoss: 0.481186\n",
      "Train Epoch: 5 [12000/23974 (50%)]\tLoss: 0.389713\n",
      "Train Epoch: 5 [13000/23974 (54%)]\tLoss: 0.753602\n",
      "Train Epoch: 5 [14000/23974 (58%)]\tLoss: 0.417577\n",
      "Train Epoch: 5 [15000/23974 (62%)]\tLoss: 0.430837\n",
      "Train Epoch: 5 [16000/23974 (67%)]\tLoss: 0.313346\n",
      "Train Epoch: 5 [17000/23974 (71%)]\tLoss: 0.506545\n",
      "Train Epoch: 5 [18000/23974 (75%)]\tLoss: 0.544306\n",
      "Train Epoch: 5 [19000/23974 (79%)]\tLoss: 0.529263\n",
      "Train Epoch: 5 [20000/23974 (83%)]\tLoss: 0.332167\n",
      "Train Epoch: 5 [21000/23974 (88%)]\tLoss: 0.469858\n",
      "Train Epoch: 5 [22000/23974 (92%)]\tLoss: 0.587079\n",
      "Train Epoch: 5 [23000/23974 (96%)]\tLoss: 0.512849\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7961 (0%)]\tLoss: 0.983911\n",
      "Train Epoch: 1 [1000/7961 (12%)]\tLoss: 0.517962\n",
      "Train Epoch: 1 [2000/7961 (25%)]\tLoss: 0.530731\n",
      "Train Epoch: 1 [3000/7961 (38%)]\tLoss: 0.466879\n",
      "Train Epoch: 1 [4000/7961 (50%)]\tLoss: 0.521376\n",
      "Train Epoch: 1 [5000/7961 (62%)]\tLoss: 0.624850\n",
      "Train Epoch: 1 [6000/7961 (75%)]\tLoss: 0.423517\n",
      "Train Epoch: 1 [7000/7961 (88%)]\tLoss: 0.556262\n",
      "Train Epoch: 2 [0/7961 (0%)]\tLoss: 0.542780\n",
      "Train Epoch: 2 [1000/7961 (12%)]\tLoss: 0.466420\n",
      "Train Epoch: 2 [2000/7961 (25%)]\tLoss: 0.531442\n",
      "Train Epoch: 2 [3000/7961 (38%)]\tLoss: 0.539237\n",
      "Train Epoch: 2 [4000/7961 (50%)]\tLoss: 0.659788\n",
      "Train Epoch: 2 [5000/7961 (62%)]\tLoss: 0.556151\n",
      "Train Epoch: 2 [6000/7961 (75%)]\tLoss: 0.647195\n",
      "Train Epoch: 2 [7000/7961 (88%)]\tLoss: 0.543243\n",
      "Train Epoch: 3 [0/7961 (0%)]\tLoss: 0.555201\n",
      "Train Epoch: 3 [1000/7961 (12%)]\tLoss: 0.588062\n",
      "Train Epoch: 3 [2000/7961 (25%)]\tLoss: 0.493293\n",
      "Train Epoch: 3 [3000/7961 (38%)]\tLoss: 0.640113\n",
      "Train Epoch: 3 [4000/7961 (50%)]\tLoss: 0.651935\n",
      "Train Epoch: 3 [5000/7961 (62%)]\tLoss: 0.411954\n",
      "Train Epoch: 3 [6000/7961 (75%)]\tLoss: 0.482386\n",
      "Train Epoch: 3 [7000/7961 (88%)]\tLoss: 0.504665\n",
      "Train Epoch: 4 [0/7961 (0%)]\tLoss: 0.564119\n",
      "Train Epoch: 4 [1000/7961 (12%)]\tLoss: 0.488322\n",
      "Train Epoch: 4 [2000/7961 (25%)]\tLoss: 0.532533\n",
      "Train Epoch: 4 [3000/7961 (38%)]\tLoss: 0.481533\n",
      "Train Epoch: 4 [4000/7961 (50%)]\tLoss: 0.554857\n",
      "Train Epoch: 4 [5000/7961 (62%)]\tLoss: 0.617133\n",
      "Train Epoch: 4 [6000/7961 (75%)]\tLoss: 0.569267\n",
      "Train Epoch: 4 [7000/7961 (88%)]\tLoss: 0.469862\n",
      "Train Epoch: 5 [0/7961 (0%)]\tLoss: 0.468533\n",
      "Train Epoch: 5 [1000/7961 (12%)]\tLoss: 0.635826\n",
      "Train Epoch: 5 [2000/7961 (25%)]\tLoss: 0.476438\n",
      "Train Epoch: 5 [3000/7961 (38%)]\tLoss: 0.505267\n",
      "Train Epoch: 5 [4000/7961 (50%)]\tLoss: 0.592789\n",
      "Train Epoch: 5 [5000/7961 (62%)]\tLoss: 0.678725\n",
      "Train Epoch: 5 [6000/7961 (75%)]\tLoss: 0.510217\n",
      "Train Epoch: 5 [7000/7961 (88%)]\tLoss: 0.779507\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "4\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8634, Accuracy: 7589/10000 (76%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/23974 (0%)]\tLoss: 0.532494\n",
      "Train Epoch: 1 [1000/23974 (4%)]\tLoss: 0.393528\n",
      "Train Epoch: 1 [2000/23974 (8%)]\tLoss: 0.440117\n",
      "Train Epoch: 1 [3000/23974 (12%)]\tLoss: 0.411377\n",
      "Train Epoch: 1 [4000/23974 (17%)]\tLoss: 0.551540\n",
      "Train Epoch: 1 [5000/23974 (21%)]\tLoss: 0.557240\n",
      "Train Epoch: 1 [6000/23974 (25%)]\tLoss: 0.506572\n",
      "Train Epoch: 1 [7000/23974 (29%)]\tLoss: 0.606997\n",
      "Train Epoch: 1 [8000/23974 (33%)]\tLoss: 0.241972\n",
      "Train Epoch: 1 [9000/23974 (38%)]\tLoss: 0.395899\n",
      "Train Epoch: 1 [10000/23974 (42%)]\tLoss: 0.471211\n",
      "Train Epoch: 1 [11000/23974 (46%)]\tLoss: 0.388153\n",
      "Train Epoch: 1 [12000/23974 (50%)]\tLoss: 0.502086\n",
      "Train Epoch: 1 [13000/23974 (54%)]\tLoss: 0.486582\n",
      "Train Epoch: 1 [14000/23974 (58%)]\tLoss: 0.265089\n",
      "Train Epoch: 1 [15000/23974 (62%)]\tLoss: 0.426982\n",
      "Train Epoch: 1 [16000/23974 (67%)]\tLoss: 0.543897\n",
      "Train Epoch: 1 [17000/23974 (71%)]\tLoss: 0.527017\n",
      "Train Epoch: 1 [18000/23974 (75%)]\tLoss: 0.439573\n",
      "Train Epoch: 1 [19000/23974 (79%)]\tLoss: 0.389716\n",
      "Train Epoch: 1 [20000/23974 (83%)]\tLoss: 0.443207\n",
      "Train Epoch: 1 [21000/23974 (88%)]\tLoss: 0.504386\n",
      "Train Epoch: 1 [22000/23974 (92%)]\tLoss: 0.649769\n",
      "Train Epoch: 1 [23000/23974 (96%)]\tLoss: 0.495361\n",
      "Train Epoch: 2 [0/23974 (0%)]\tLoss: 0.511912\n",
      "Train Epoch: 2 [1000/23974 (4%)]\tLoss: 0.558330\n",
      "Train Epoch: 2 [2000/23974 (8%)]\tLoss: 0.351686\n",
      "Train Epoch: 2 [3000/23974 (12%)]\tLoss: 0.583798\n",
      "Train Epoch: 2 [4000/23974 (17%)]\tLoss: 0.462162\n",
      "Train Epoch: 2 [5000/23974 (21%)]\tLoss: 0.360672\n",
      "Train Epoch: 2 [6000/23974 (25%)]\tLoss: 0.529511\n",
      "Train Epoch: 2 [7000/23974 (29%)]\tLoss: 0.511469\n",
      "Train Epoch: 2 [8000/23974 (33%)]\tLoss: 0.502974\n",
      "Train Epoch: 2 [9000/23974 (38%)]\tLoss: 0.434492\n",
      "Train Epoch: 2 [10000/23974 (42%)]\tLoss: 0.273137\n",
      "Train Epoch: 2 [11000/23974 (46%)]\tLoss: 0.393661\n",
      "Train Epoch: 2 [12000/23974 (50%)]\tLoss: 0.613850\n",
      "Train Epoch: 2 [13000/23974 (54%)]\tLoss: 0.483857\n",
      "Train Epoch: 2 [14000/23974 (58%)]\tLoss: 0.497960\n",
      "Train Epoch: 2 [15000/23974 (62%)]\tLoss: 0.303618\n",
      "Train Epoch: 2 [16000/23974 (67%)]\tLoss: 0.509892\n",
      "Train Epoch: 2 [17000/23974 (71%)]\tLoss: 0.414340\n",
      "Train Epoch: 2 [18000/23974 (75%)]\tLoss: 0.546563\n",
      "Train Epoch: 2 [19000/23974 (79%)]\tLoss: 0.477288\n",
      "Train Epoch: 2 [20000/23974 (83%)]\tLoss: 0.415141\n",
      "Train Epoch: 2 [21000/23974 (88%)]\tLoss: 0.556799\n",
      "Train Epoch: 2 [22000/23974 (92%)]\tLoss: 0.330682\n",
      "Train Epoch: 2 [23000/23974 (96%)]\tLoss: 0.439137\n",
      "Train Epoch: 3 [0/23974 (0%)]\tLoss: 0.425776\n",
      "Train Epoch: 3 [1000/23974 (4%)]\tLoss: 0.341576\n",
      "Train Epoch: 3 [2000/23974 (8%)]\tLoss: 0.404518\n",
      "Train Epoch: 3 [3000/23974 (12%)]\tLoss: 0.419426\n",
      "Train Epoch: 3 [4000/23974 (17%)]\tLoss: 0.380352\n",
      "Train Epoch: 3 [5000/23974 (21%)]\tLoss: 0.428624\n",
      "Train Epoch: 3 [6000/23974 (25%)]\tLoss: 0.462110\n",
      "Train Epoch: 3 [7000/23974 (29%)]\tLoss: 0.460039\n",
      "Train Epoch: 3 [8000/23974 (33%)]\tLoss: 0.429304\n",
      "Train Epoch: 3 [9000/23974 (38%)]\tLoss: 0.402994\n",
      "Train Epoch: 3 [10000/23974 (42%)]\tLoss: 0.402518\n",
      "Train Epoch: 3 [11000/23974 (46%)]\tLoss: 0.426976\n",
      "Train Epoch: 3 [12000/23974 (50%)]\tLoss: 0.393628\n",
      "Train Epoch: 3 [13000/23974 (54%)]\tLoss: 0.376189\n",
      "Train Epoch: 3 [14000/23974 (58%)]\tLoss: 0.583732\n",
      "Train Epoch: 3 [15000/23974 (62%)]\tLoss: 0.590752\n",
      "Train Epoch: 3 [16000/23974 (67%)]\tLoss: 0.599717\n",
      "Train Epoch: 3 [17000/23974 (71%)]\tLoss: 0.312416\n",
      "Train Epoch: 3 [18000/23974 (75%)]\tLoss: 0.361200\n",
      "Train Epoch: 3 [19000/23974 (79%)]\tLoss: 0.506026\n",
      "Train Epoch: 3 [20000/23974 (83%)]\tLoss: 0.390347\n",
      "Train Epoch: 3 [21000/23974 (88%)]\tLoss: 0.461245\n",
      "Train Epoch: 3 [22000/23974 (92%)]\tLoss: 0.492663\n",
      "Train Epoch: 3 [23000/23974 (96%)]\tLoss: 0.321390\n",
      "Train Epoch: 4 [0/23974 (0%)]\tLoss: 0.422768\n",
      "Train Epoch: 4 [1000/23974 (4%)]\tLoss: 0.441016\n",
      "Train Epoch: 4 [2000/23974 (8%)]\tLoss: 0.368103\n",
      "Train Epoch: 4 [3000/23974 (12%)]\tLoss: 0.295491\n",
      "Train Epoch: 4 [4000/23974 (17%)]\tLoss: 0.309391\n",
      "Train Epoch: 4 [5000/23974 (21%)]\tLoss: 0.398288\n",
      "Train Epoch: 4 [6000/23974 (25%)]\tLoss: 0.423005\n",
      "Train Epoch: 4 [7000/23974 (29%)]\tLoss: 0.412239\n",
      "Train Epoch: 4 [8000/23974 (33%)]\tLoss: 0.332967\n",
      "Train Epoch: 4 [9000/23974 (38%)]\tLoss: 0.439023\n",
      "Train Epoch: 4 [10000/23974 (42%)]\tLoss: 0.248154\n",
      "Train Epoch: 4 [11000/23974 (46%)]\tLoss: 0.366664\n",
      "Train Epoch: 4 [12000/23974 (50%)]\tLoss: 0.397911\n",
      "Train Epoch: 4 [13000/23974 (54%)]\tLoss: 0.481860\n",
      "Train Epoch: 4 [14000/23974 (58%)]\tLoss: 0.268801\n",
      "Train Epoch: 4 [15000/23974 (62%)]\tLoss: 0.482240\n",
      "Train Epoch: 4 [16000/23974 (67%)]\tLoss: 0.305655\n",
      "Train Epoch: 4 [17000/23974 (71%)]\tLoss: 0.425741\n",
      "Train Epoch: 4 [18000/23974 (75%)]\tLoss: 0.394518\n",
      "Train Epoch: 4 [19000/23974 (79%)]\tLoss: 0.387815\n",
      "Train Epoch: 4 [20000/23974 (83%)]\tLoss: 0.363639\n",
      "Train Epoch: 4 [21000/23974 (88%)]\tLoss: 0.333000\n",
      "Train Epoch: 4 [22000/23974 (92%)]\tLoss: 0.450649\n",
      "Train Epoch: 4 [23000/23974 (96%)]\tLoss: 0.429549\n",
      "Train Epoch: 5 [0/23974 (0%)]\tLoss: 0.466552\n",
      "Train Epoch: 5 [1000/23974 (4%)]\tLoss: 0.450851\n",
      "Train Epoch: 5 [2000/23974 (8%)]\tLoss: 0.287193\n",
      "Train Epoch: 5 [3000/23974 (12%)]\tLoss: 0.262059\n",
      "Train Epoch: 5 [4000/23974 (17%)]\tLoss: 0.337490\n",
      "Train Epoch: 5 [5000/23974 (21%)]\tLoss: 0.330631\n",
      "Train Epoch: 5 [6000/23974 (25%)]\tLoss: 0.499744\n",
      "Train Epoch: 5 [7000/23974 (29%)]\tLoss: 0.525495\n",
      "Train Epoch: 5 [8000/23974 (33%)]\tLoss: 0.563923\n",
      "Train Epoch: 5 [9000/23974 (38%)]\tLoss: 0.306504\n",
      "Train Epoch: 5 [10000/23974 (42%)]\tLoss: 0.421454\n",
      "Train Epoch: 5 [11000/23974 (46%)]\tLoss: 0.463118\n",
      "Train Epoch: 5 [12000/23974 (50%)]\tLoss: 0.489371\n",
      "Train Epoch: 5 [13000/23974 (54%)]\tLoss: 0.296876\n",
      "Train Epoch: 5 [14000/23974 (58%)]\tLoss: 0.254954\n",
      "Train Epoch: 5 [15000/23974 (62%)]\tLoss: 0.303783\n",
      "Train Epoch: 5 [16000/23974 (67%)]\tLoss: 0.483733\n",
      "Train Epoch: 5 [17000/23974 (71%)]\tLoss: 0.447879\n",
      "Train Epoch: 5 [18000/23974 (75%)]\tLoss: 0.448454\n",
      "Train Epoch: 5 [19000/23974 (79%)]\tLoss: 0.396051\n",
      "Train Epoch: 5 [20000/23974 (83%)]\tLoss: 0.270364\n",
      "Train Epoch: 5 [21000/23974 (88%)]\tLoss: 0.317192\n",
      "Train Epoch: 5 [22000/23974 (92%)]\tLoss: 0.407846\n",
      "Train Epoch: 5 [23000/23974 (96%)]\tLoss: 0.302929\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7961 (0%)]\tLoss: 0.940701\n",
      "Train Epoch: 1 [1000/7961 (12%)]\tLoss: 0.621279\n",
      "Train Epoch: 1 [2000/7961 (25%)]\tLoss: 0.667182\n",
      "Train Epoch: 1 [3000/7961 (38%)]\tLoss: 0.544352\n",
      "Train Epoch: 1 [4000/7961 (50%)]\tLoss: 0.543720\n",
      "Train Epoch: 1 [5000/7961 (62%)]\tLoss: 0.470560\n",
      "Train Epoch: 1 [6000/7961 (75%)]\tLoss: 0.547045\n",
      "Train Epoch: 1 [7000/7961 (88%)]\tLoss: 0.526328\n",
      "Train Epoch: 2 [0/7961 (0%)]\tLoss: 0.662083\n",
      "Train Epoch: 2 [1000/7961 (12%)]\tLoss: 0.515542\n",
      "Train Epoch: 2 [2000/7961 (25%)]\tLoss: 0.712771\n",
      "Train Epoch: 2 [3000/7961 (38%)]\tLoss: 0.633977\n",
      "Train Epoch: 2 [4000/7961 (50%)]\tLoss: 0.724264\n",
      "Train Epoch: 2 [5000/7961 (62%)]\tLoss: 0.549112\n",
      "Train Epoch: 2 [6000/7961 (75%)]\tLoss: 0.550434\n",
      "Train Epoch: 2 [7000/7961 (88%)]\tLoss: 0.624106\n",
      "Train Epoch: 3 [0/7961 (0%)]\tLoss: 0.557002\n",
      "Train Epoch: 3 [1000/7961 (12%)]\tLoss: 0.472523\n",
      "Train Epoch: 3 [2000/7961 (25%)]\tLoss: 0.502570\n",
      "Train Epoch: 3 [3000/7961 (38%)]\tLoss: 0.505810\n",
      "Train Epoch: 3 [4000/7961 (50%)]\tLoss: 0.565666\n",
      "Train Epoch: 3 [5000/7961 (62%)]\tLoss: 0.398811\n",
      "Train Epoch: 3 [6000/7961 (75%)]\tLoss: 0.674896\n",
      "Train Epoch: 3 [7000/7961 (88%)]\tLoss: 0.516522\n",
      "Train Epoch: 4 [0/7961 (0%)]\tLoss: 0.620473\n",
      "Train Epoch: 4 [1000/7961 (12%)]\tLoss: 0.617634\n",
      "Train Epoch: 4 [2000/7961 (25%)]\tLoss: 0.684298\n",
      "Train Epoch: 4 [3000/7961 (38%)]\tLoss: 0.518250\n",
      "Train Epoch: 4 [4000/7961 (50%)]\tLoss: 0.511415\n",
      "Train Epoch: 4 [5000/7961 (62%)]\tLoss: 0.612002\n",
      "Train Epoch: 4 [6000/7961 (75%)]\tLoss: 0.601264\n",
      "Train Epoch: 4 [7000/7961 (88%)]\tLoss: 0.553504\n",
      "Train Epoch: 5 [0/7961 (0%)]\tLoss: 0.552413\n",
      "Train Epoch: 5 [1000/7961 (12%)]\tLoss: 0.466134\n",
      "Train Epoch: 5 [2000/7961 (25%)]\tLoss: 0.530468\n",
      "Train Epoch: 5 [3000/7961 (38%)]\tLoss: 0.516615\n",
      "Train Epoch: 5 [4000/7961 (50%)]\tLoss: 0.451123\n",
      "Train Epoch: 5 [5000/7961 (62%)]\tLoss: 0.471901\n",
      "Train Epoch: 5 [6000/7961 (75%)]\tLoss: 0.560371\n",
      "Train Epoch: 5 [7000/7961 (88%)]\tLoss: 0.441968\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "4\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8196, Accuracy: 7707/10000 (77%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/23974 (0%)]\tLoss: 0.493648\n",
      "Train Epoch: 1 [1000/23974 (4%)]\tLoss: 0.431575\n",
      "Train Epoch: 1 [2000/23974 (8%)]\tLoss: 0.503367\n",
      "Train Epoch: 1 [3000/23974 (12%)]\tLoss: 0.363553\n",
      "Train Epoch: 1 [4000/23974 (17%)]\tLoss: 0.325456\n",
      "Train Epoch: 1 [5000/23974 (21%)]\tLoss: 0.357910\n",
      "Train Epoch: 1 [6000/23974 (25%)]\tLoss: 0.447869\n",
      "Train Epoch: 1 [7000/23974 (29%)]\tLoss: 0.426918\n",
      "Train Epoch: 1 [8000/23974 (33%)]\tLoss: 0.520995\n",
      "Train Epoch: 1 [9000/23974 (38%)]\tLoss: 0.409360\n",
      "Train Epoch: 1 [10000/23974 (42%)]\tLoss: 0.438186\n",
      "Train Epoch: 1 [11000/23974 (46%)]\tLoss: 0.318552\n",
      "Train Epoch: 1 [12000/23974 (50%)]\tLoss: 0.550790\n",
      "Train Epoch: 1 [13000/23974 (54%)]\tLoss: 0.328569\n",
      "Train Epoch: 1 [14000/23974 (58%)]\tLoss: 0.419943\n",
      "Train Epoch: 1 [15000/23974 (62%)]\tLoss: 0.405447\n",
      "Train Epoch: 1 [16000/23974 (67%)]\tLoss: 0.415243\n",
      "Train Epoch: 1 [17000/23974 (71%)]\tLoss: 0.471724\n",
      "Train Epoch: 1 [18000/23974 (75%)]\tLoss: 0.425104\n",
      "Train Epoch: 1 [19000/23974 (79%)]\tLoss: 0.323040\n",
      "Train Epoch: 1 [20000/23974 (83%)]\tLoss: 0.341500\n",
      "Train Epoch: 1 [21000/23974 (88%)]\tLoss: 0.370801\n",
      "Train Epoch: 1 [22000/23974 (92%)]\tLoss: 0.287713\n",
      "Train Epoch: 1 [23000/23974 (96%)]\tLoss: 0.467211\n",
      "Train Epoch: 2 [0/23974 (0%)]\tLoss: 0.446689\n",
      "Train Epoch: 2 [1000/23974 (4%)]\tLoss: 0.454567\n",
      "Train Epoch: 2 [2000/23974 (8%)]\tLoss: 0.367429\n",
      "Train Epoch: 2 [3000/23974 (12%)]\tLoss: 0.403419\n",
      "Train Epoch: 2 [4000/23974 (17%)]\tLoss: 0.419564\n",
      "Train Epoch: 2 [5000/23974 (21%)]\tLoss: 0.339943\n",
      "Train Epoch: 2 [6000/23974 (25%)]\tLoss: 0.442434\n",
      "Train Epoch: 2 [7000/23974 (29%)]\tLoss: 0.385382\n",
      "Train Epoch: 2 [8000/23974 (33%)]\tLoss: 0.296151\n",
      "Train Epoch: 2 [9000/23974 (38%)]\tLoss: 0.402693\n",
      "Train Epoch: 2 [10000/23974 (42%)]\tLoss: 0.447138\n",
      "Train Epoch: 2 [11000/23974 (46%)]\tLoss: 0.393452\n",
      "Train Epoch: 2 [12000/23974 (50%)]\tLoss: 0.393457\n",
      "Train Epoch: 2 [13000/23974 (54%)]\tLoss: 0.330039\n",
      "Train Epoch: 2 [14000/23974 (58%)]\tLoss: 0.436296\n",
      "Train Epoch: 2 [15000/23974 (62%)]\tLoss: 0.416326\n",
      "Train Epoch: 2 [16000/23974 (67%)]\tLoss: 0.382226\n",
      "Train Epoch: 2 [17000/23974 (71%)]\tLoss: 0.516976\n",
      "Train Epoch: 2 [18000/23974 (75%)]\tLoss: 0.362068\n",
      "Train Epoch: 2 [19000/23974 (79%)]\tLoss: 0.470617\n",
      "Train Epoch: 2 [20000/23974 (83%)]\tLoss: 0.414296\n",
      "Train Epoch: 2 [21000/23974 (88%)]\tLoss: 0.350380\n",
      "Train Epoch: 2 [22000/23974 (92%)]\tLoss: 0.575679\n",
      "Train Epoch: 2 [23000/23974 (96%)]\tLoss: 0.401235\n",
      "Train Epoch: 3 [0/23974 (0%)]\tLoss: 0.381649\n",
      "Train Epoch: 3 [1000/23974 (4%)]\tLoss: 0.304592\n",
      "Train Epoch: 3 [2000/23974 (8%)]\tLoss: 0.411171\n",
      "Train Epoch: 3 [3000/23974 (12%)]\tLoss: 0.302825\n",
      "Train Epoch: 3 [4000/23974 (17%)]\tLoss: 0.392357\n",
      "Train Epoch: 3 [5000/23974 (21%)]\tLoss: 0.339454\n",
      "Train Epoch: 3 [6000/23974 (25%)]\tLoss: 0.368841\n",
      "Train Epoch: 3 [7000/23974 (29%)]\tLoss: 0.366497\n",
      "Train Epoch: 3 [8000/23974 (33%)]\tLoss: 0.464025\n",
      "Train Epoch: 3 [9000/23974 (38%)]\tLoss: 0.502892\n",
      "Train Epoch: 3 [10000/23974 (42%)]\tLoss: 0.520385\n",
      "Train Epoch: 3 [11000/23974 (46%)]\tLoss: 0.395649\n",
      "Train Epoch: 3 [12000/23974 (50%)]\tLoss: 0.219280\n",
      "Train Epoch: 3 [13000/23974 (54%)]\tLoss: 0.606852\n",
      "Train Epoch: 3 [14000/23974 (58%)]\tLoss: 0.336753\n",
      "Train Epoch: 3 [15000/23974 (62%)]\tLoss: 0.311632\n",
      "Train Epoch: 3 [16000/23974 (67%)]\tLoss: 0.314688\n",
      "Train Epoch: 3 [17000/23974 (71%)]\tLoss: 0.363440\n",
      "Train Epoch: 3 [18000/23974 (75%)]\tLoss: 0.426529\n",
      "Train Epoch: 3 [19000/23974 (79%)]\tLoss: 0.429618\n",
      "Train Epoch: 3 [20000/23974 (83%)]\tLoss: 0.323359\n",
      "Train Epoch: 3 [21000/23974 (88%)]\tLoss: 0.616990\n",
      "Train Epoch: 3 [22000/23974 (92%)]\tLoss: 0.497148\n",
      "Train Epoch: 3 [23000/23974 (96%)]\tLoss: 0.412604\n",
      "Train Epoch: 4 [0/23974 (0%)]\tLoss: 0.524000\n",
      "Train Epoch: 4 [1000/23974 (4%)]\tLoss: 0.451708\n",
      "Train Epoch: 4 [2000/23974 (8%)]\tLoss: 0.441970\n",
      "Train Epoch: 4 [3000/23974 (12%)]\tLoss: 0.465470\n",
      "Train Epoch: 4 [4000/23974 (17%)]\tLoss: 0.466722\n",
      "Train Epoch: 4 [5000/23974 (21%)]\tLoss: 0.470725\n",
      "Train Epoch: 4 [6000/23974 (25%)]\tLoss: 0.336178\n",
      "Train Epoch: 4 [7000/23974 (29%)]\tLoss: 0.319758\n",
      "Train Epoch: 4 [8000/23974 (33%)]\tLoss: 0.313588\n",
      "Train Epoch: 4 [9000/23974 (38%)]\tLoss: 0.339128\n",
      "Train Epoch: 4 [10000/23974 (42%)]\tLoss: 0.335267\n",
      "Train Epoch: 4 [11000/23974 (46%)]\tLoss: 0.461109\n",
      "Train Epoch: 4 [12000/23974 (50%)]\tLoss: 0.479545\n",
      "Train Epoch: 4 [13000/23974 (54%)]\tLoss: 0.306862\n",
      "Train Epoch: 4 [14000/23974 (58%)]\tLoss: 0.396932\n",
      "Train Epoch: 4 [15000/23974 (62%)]\tLoss: 0.409597\n",
      "Train Epoch: 4 [16000/23974 (67%)]\tLoss: 0.414771\n",
      "Train Epoch: 4 [17000/23974 (71%)]\tLoss: 0.638820\n",
      "Train Epoch: 4 [18000/23974 (75%)]\tLoss: 0.469003\n",
      "Train Epoch: 4 [19000/23974 (79%)]\tLoss: 0.484932\n",
      "Train Epoch: 4 [20000/23974 (83%)]\tLoss: 0.565197\n",
      "Train Epoch: 4 [21000/23974 (88%)]\tLoss: 0.308751\n",
      "Train Epoch: 4 [22000/23974 (92%)]\tLoss: 0.397321\n",
      "Train Epoch: 4 [23000/23974 (96%)]\tLoss: 0.486767\n",
      "Train Epoch: 5 [0/23974 (0%)]\tLoss: 0.517590\n",
      "Train Epoch: 5 [1000/23974 (4%)]\tLoss: 0.342467\n",
      "Train Epoch: 5 [2000/23974 (8%)]\tLoss: 0.334955\n",
      "Train Epoch: 5 [3000/23974 (12%)]\tLoss: 0.414852\n",
      "Train Epoch: 5 [4000/23974 (17%)]\tLoss: 0.422229\n",
      "Train Epoch: 5 [5000/23974 (21%)]\tLoss: 0.326542\n",
      "Train Epoch: 5 [6000/23974 (25%)]\tLoss: 0.332950\n",
      "Train Epoch: 5 [7000/23974 (29%)]\tLoss: 0.414074\n",
      "Train Epoch: 5 [8000/23974 (33%)]\tLoss: 0.337111\n",
      "Train Epoch: 5 [9000/23974 (38%)]\tLoss: 0.340011\n",
      "Train Epoch: 5 [10000/23974 (42%)]\tLoss: 0.360012\n",
      "Train Epoch: 5 [11000/23974 (46%)]\tLoss: 0.370621\n",
      "Train Epoch: 5 [12000/23974 (50%)]\tLoss: 0.307283\n",
      "Train Epoch: 5 [13000/23974 (54%)]\tLoss: 0.250338\n",
      "Train Epoch: 5 [14000/23974 (58%)]\tLoss: 0.506966\n",
      "Train Epoch: 5 [15000/23974 (62%)]\tLoss: 0.371669\n",
      "Train Epoch: 5 [16000/23974 (67%)]\tLoss: 0.433611\n",
      "Train Epoch: 5 [17000/23974 (71%)]\tLoss: 0.366496\n",
      "Train Epoch: 5 [18000/23974 (75%)]\tLoss: 0.394166\n",
      "Train Epoch: 5 [19000/23974 (79%)]\tLoss: 0.459581\n",
      "Train Epoch: 5 [20000/23974 (83%)]\tLoss: 0.434179\n",
      "Train Epoch: 5 [21000/23974 (88%)]\tLoss: 0.356454\n",
      "Train Epoch: 5 [22000/23974 (92%)]\tLoss: 0.428124\n",
      "Train Epoch: 5 [23000/23974 (96%)]\tLoss: 0.487996\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7961 (0%)]\tLoss: 0.828429\n",
      "Train Epoch: 1 [1000/7961 (12%)]\tLoss: 0.595873\n",
      "Train Epoch: 1 [2000/7961 (25%)]\tLoss: 0.623536\n",
      "Train Epoch: 1 [3000/7961 (38%)]\tLoss: 0.706927\n",
      "Train Epoch: 1 [4000/7961 (50%)]\tLoss: 0.563138\n",
      "Train Epoch: 1 [5000/7961 (62%)]\tLoss: 0.490923\n",
      "Train Epoch: 1 [6000/7961 (75%)]\tLoss: 0.643745\n",
      "Train Epoch: 1 [7000/7961 (88%)]\tLoss: 0.643902\n",
      "Train Epoch: 2 [0/7961 (0%)]\tLoss: 0.446115\n",
      "Train Epoch: 2 [1000/7961 (12%)]\tLoss: 0.387616\n",
      "Train Epoch: 2 [2000/7961 (25%)]\tLoss: 0.420812\n",
      "Train Epoch: 2 [3000/7961 (38%)]\tLoss: 0.502657\n",
      "Train Epoch: 2 [4000/7961 (50%)]\tLoss: 0.527116\n",
      "Train Epoch: 2 [5000/7961 (62%)]\tLoss: 0.564465\n",
      "Train Epoch: 2 [6000/7961 (75%)]\tLoss: 0.696674\n",
      "Train Epoch: 2 [7000/7961 (88%)]\tLoss: 0.571851\n",
      "Train Epoch: 3 [0/7961 (0%)]\tLoss: 0.522139\n",
      "Train Epoch: 3 [1000/7961 (12%)]\tLoss: 0.513004\n",
      "Train Epoch: 3 [2000/7961 (25%)]\tLoss: 0.811936\n",
      "Train Epoch: 3 [3000/7961 (38%)]\tLoss: 0.383707\n",
      "Train Epoch: 3 [4000/7961 (50%)]\tLoss: 0.539526\n",
      "Train Epoch: 3 [5000/7961 (62%)]\tLoss: 0.522974\n",
      "Train Epoch: 3 [6000/7961 (75%)]\tLoss: 0.530618\n",
      "Train Epoch: 3 [7000/7961 (88%)]\tLoss: 0.368269\n",
      "Train Epoch: 4 [0/7961 (0%)]\tLoss: 0.587160\n",
      "Train Epoch: 4 [1000/7961 (12%)]\tLoss: 0.511618\n",
      "Train Epoch: 4 [2000/7961 (25%)]\tLoss: 0.700320\n",
      "Train Epoch: 4 [3000/7961 (38%)]\tLoss: 0.639018\n",
      "Train Epoch: 4 [4000/7961 (50%)]\tLoss: 0.576581\n",
      "Train Epoch: 4 [5000/7961 (62%)]\tLoss: 0.455401\n",
      "Train Epoch: 4 [6000/7961 (75%)]\tLoss: 0.564228\n",
      "Train Epoch: 4 [7000/7961 (88%)]\tLoss: 0.623962\n",
      "Train Epoch: 5 [0/7961 (0%)]\tLoss: 0.511473\n",
      "Train Epoch: 5 [1000/7961 (12%)]\tLoss: 0.492663\n",
      "Train Epoch: 5 [2000/7961 (25%)]\tLoss: 0.671586\n",
      "Train Epoch: 5 [3000/7961 (38%)]\tLoss: 0.468449\n",
      "Train Epoch: 5 [4000/7961 (50%)]\tLoss: 0.500246\n",
      "Train Epoch: 5 [5000/7961 (62%)]\tLoss: 0.527686\n",
      "Train Epoch: 5 [6000/7961 (75%)]\tLoss: 0.353052\n",
      "Train Epoch: 5 [7000/7961 (88%)]\tLoss: 0.571006\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "4\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9050, Accuracy: 7649/10000 (76%)\n",
      "\n",
      "Running experiment with 6 partitions...\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.555689\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 0.453633\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 0.755491\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 0.628540\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 0.627586\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 0.590343\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 0.388203\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 0.658929\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.630301\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 0.440106\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.578051\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 0.376341\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.455258\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 0.560512\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 0.701611\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.488190\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.453044\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 0.522737\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 0.533712\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 0.568113\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.517065\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 0.490390\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.429932\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 0.442022\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.524435\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.647018\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.611684\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 0.597555\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.589922\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 0.466309\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.549714\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 0.363931\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.565687\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 0.670137\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.547273\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.606120\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.500803\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 0.523145\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.628581\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 0.499116\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.398044\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 0.500730\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.525249\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 0.506634\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.413644\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.593103\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.362676\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 0.781855\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.503682\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 0.507581\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.616632\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 0.612414\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.683647\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 0.674952\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.487750\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.541443\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.462446\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 0.596810\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.544904\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 0.591398\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.619966\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 0.473904\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.468869\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 0.439734\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.452875\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.620152\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.545939\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 0.577216\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.622012\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 0.574022\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.366167\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 0.500374\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.686698\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 0.608784\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.493532\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.594611\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.665264\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 0.640963\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.442146\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 0.484007\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.711040\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 0.471316\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.477504\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 0.496116\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.579789\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.706943\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.372077\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 0.502432\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.415602\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 0.459148\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.635355\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 0.518704\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.592491\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 0.345479\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.595797\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.546291\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.443928\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 0.594205\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.546250\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 0.383145\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.632126\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 0.606487\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.649938\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 0.527936\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.582114\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.514291\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.588254\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 0.525955\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.586321\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 0.640371\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.487090\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 0.498614\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.493694\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 0.430128\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.558160\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.560375\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.575095\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 0.516508\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.489037\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 0.697203\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.602080\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 0.591182\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.600326\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 0.559272\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.549213\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.543850\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.531943\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 0.576168\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.515877\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 0.556988\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.533335\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 0.459105\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.553045\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 0.595400\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.396083\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.471714\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.433539\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 0.481082\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.442186\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 0.440209\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.378716\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 0.562919\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.477452\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 0.445447\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.418061\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.544941\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.475470\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 0.463205\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.742049\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 0.586413\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.499513\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 0.554832\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.559565\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 0.564783\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.524342\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.655988\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.478387\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 0.400916\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.565998\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 0.447224\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.570101\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 0.467614\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.583262\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 0.621193\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.402039\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.494923\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.452651\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 0.476742\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.573409\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 0.527223\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.515312\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 0.630955\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.469636\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 0.575003\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.483986\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.525671\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.513128\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 0.553890\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.507637\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 0.530582\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.530118\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 0.377658\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.424332\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 0.503317\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.502551\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.523840\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.495758\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 0.668105\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.499177\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 0.568195\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.411539\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 0.526996\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.531564\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 0.636721\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.473051\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.452085\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.400090\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 0.332289\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.539646\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 0.417937\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.554345\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 0.485402\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.495910\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 0.724906\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.457359\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.490598\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.395647\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 0.463185\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.418858\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 0.493023\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.413577\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 0.498796\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.533558\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 0.532112\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.482441\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.510839\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.483471\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 0.482590\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.338798\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 0.443455\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.404954\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 0.563778\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.401149\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 0.402867\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.588259\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.395621\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.514873\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 0.455971\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.529869\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 0.588109\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.531138\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 0.599243\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.494717\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 0.414019\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.317330\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.461244\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.519333\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 0.536788\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.376918\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 0.485487\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.524042\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 0.390799\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.452311\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 0.640258\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.495843\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.308716\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.585615\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 0.461266\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.518140\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 0.475316\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.589976\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 0.450693\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.515141\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 0.341990\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.411053\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.535914\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.430630\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 0.630304\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.416114\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 0.570709\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.547748\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 0.483153\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.454155\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 0.480129\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.487043\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.560987\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.512690\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 0.411180\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.448597\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 0.447836\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.355323\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 0.425299\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.412055\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 0.437123\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.503277\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.486534\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.265423\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 0.504055\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.706559\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 0.522834\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.609344\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 0.432172\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.517006\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 0.315841\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.505640\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.527753\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.508926\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 0.504410\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.502950\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 0.456561\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.505913\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 0.419675\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.383089\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 0.471443\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.354571\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.464880\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.482764\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 0.387268\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.500969\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 0.438374\n",
      "\n",
      "Test set: Avg. loss: 0.4847, Accuracy: 49619/60000 (83%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/8440 (0%)]\tLoss: 0.645551\n",
      "Train Epoch: 1 [1000/8440 (12%)]\tLoss: 0.553470\n",
      "Train Epoch: 1 [2000/8440 (24%)]\tLoss: 0.489464\n",
      "Train Epoch: 1 [3000/8440 (35%)]\tLoss: 0.453210\n",
      "Train Epoch: 1 [4000/8440 (47%)]\tLoss: 0.403600\n",
      "Train Epoch: 1 [5000/8440 (59%)]\tLoss: 0.592152\n",
      "Train Epoch: 1 [6000/8440 (71%)]\tLoss: 0.493260\n",
      "Train Epoch: 1 [7000/8440 (82%)]\tLoss: 0.500078\n",
      "Train Epoch: 1 [8000/8440 (94%)]\tLoss: 0.507279\n",
      "Train Epoch: 2 [0/8440 (0%)]\tLoss: 0.480303\n",
      "Train Epoch: 2 [1000/8440 (12%)]\tLoss: 0.503022\n",
      "Train Epoch: 2 [2000/8440 (24%)]\tLoss: 0.373956\n",
      "Train Epoch: 2 [3000/8440 (35%)]\tLoss: 0.479442\n",
      "Train Epoch: 2 [4000/8440 (47%)]\tLoss: 0.565897\n",
      "Train Epoch: 2 [5000/8440 (59%)]\tLoss: 0.623469\n",
      "Train Epoch: 2 [6000/8440 (71%)]\tLoss: 0.521522\n",
      "Train Epoch: 2 [7000/8440 (82%)]\tLoss: 0.273522\n",
      "Train Epoch: 2 [8000/8440 (94%)]\tLoss: 0.412567\n",
      "Train Epoch: 3 [0/8440 (0%)]\tLoss: 0.485477\n",
      "Train Epoch: 3 [1000/8440 (12%)]\tLoss: 0.494591\n",
      "Train Epoch: 3 [2000/8440 (24%)]\tLoss: 0.371341\n",
      "Train Epoch: 3 [3000/8440 (35%)]\tLoss: 0.329662\n",
      "Train Epoch: 3 [4000/8440 (47%)]\tLoss: 0.494383\n",
      "Train Epoch: 3 [5000/8440 (59%)]\tLoss: 0.408436\n",
      "Train Epoch: 3 [6000/8440 (71%)]\tLoss: 0.509740\n",
      "Train Epoch: 3 [7000/8440 (82%)]\tLoss: 0.481776\n",
      "Train Epoch: 3 [8000/8440 (94%)]\tLoss: 0.428652\n",
      "Train Epoch: 4 [0/8440 (0%)]\tLoss: 0.334995\n",
      "Train Epoch: 4 [1000/8440 (12%)]\tLoss: 0.416484\n",
      "Train Epoch: 4 [2000/8440 (24%)]\tLoss: 0.370381\n",
      "Train Epoch: 4 [3000/8440 (35%)]\tLoss: 0.403706\n",
      "Train Epoch: 4 [4000/8440 (47%)]\tLoss: 0.536143\n",
      "Train Epoch: 4 [5000/8440 (59%)]\tLoss: 0.478600\n",
      "Train Epoch: 4 [6000/8440 (71%)]\tLoss: 0.461050\n",
      "Train Epoch: 4 [7000/8440 (82%)]\tLoss: 0.302394\n",
      "Train Epoch: 4 [8000/8440 (94%)]\tLoss: 0.389853\n",
      "Train Epoch: 5 [0/8440 (0%)]\tLoss: 0.319444\n",
      "Train Epoch: 5 [1000/8440 (12%)]\tLoss: 0.372055\n",
      "Train Epoch: 5 [2000/8440 (24%)]\tLoss: 0.376647\n",
      "Train Epoch: 5 [3000/8440 (35%)]\tLoss: 0.359165\n",
      "Train Epoch: 5 [4000/8440 (47%)]\tLoss: 0.310465\n",
      "Train Epoch: 5 [5000/8440 (59%)]\tLoss: 0.432916\n",
      "Train Epoch: 5 [6000/8440 (71%)]\tLoss: 0.407757\n",
      "Train Epoch: 5 [7000/8440 (82%)]\tLoss: 0.346547\n",
      "Train Epoch: 5 [8000/8440 (94%)]\tLoss: 0.338671\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11811 (0%)]\tLoss: 0.310321\n",
      "Train Epoch: 1 [1000/11811 (8%)]\tLoss: 0.206782\n",
      "Train Epoch: 1 [2000/11811 (17%)]\tLoss: 0.240368\n",
      "Train Epoch: 1 [3000/11811 (25%)]\tLoss: 0.167172\n",
      "Train Epoch: 1 [4000/11811 (34%)]\tLoss: 0.224609\n",
      "Train Epoch: 1 [5000/11811 (42%)]\tLoss: 0.298623\n",
      "Train Epoch: 1 [6000/11811 (50%)]\tLoss: 0.351656\n",
      "Train Epoch: 1 [7000/11811 (59%)]\tLoss: 0.321700\n",
      "Train Epoch: 1 [8000/11811 (67%)]\tLoss: 0.235333\n",
      "Train Epoch: 1 [9000/11811 (76%)]\tLoss: 0.251310\n",
      "Train Epoch: 1 [10000/11811 (84%)]\tLoss: 0.233120\n",
      "Train Epoch: 1 [11000/11811 (92%)]\tLoss: 0.310203\n",
      "Train Epoch: 2 [0/11811 (0%)]\tLoss: 0.143975\n",
      "Train Epoch: 2 [1000/11811 (8%)]\tLoss: 0.215748\n",
      "Train Epoch: 2 [2000/11811 (17%)]\tLoss: 0.371725\n",
      "Train Epoch: 2 [3000/11811 (25%)]\tLoss: 0.295652\n",
      "Train Epoch: 2 [4000/11811 (34%)]\tLoss: 0.176962\n",
      "Train Epoch: 2 [5000/11811 (42%)]\tLoss: 0.296489\n",
      "Train Epoch: 2 [6000/11811 (50%)]\tLoss: 0.274617\n",
      "Train Epoch: 2 [7000/11811 (59%)]\tLoss: 0.135379\n",
      "Train Epoch: 2 [8000/11811 (67%)]\tLoss: 0.178138\n",
      "Train Epoch: 2 [9000/11811 (76%)]\tLoss: 0.169701\n",
      "Train Epoch: 2 [10000/11811 (84%)]\tLoss: 0.230020\n",
      "Train Epoch: 2 [11000/11811 (92%)]\tLoss: 0.153335\n",
      "Train Epoch: 3 [0/11811 (0%)]\tLoss: 0.260988\n",
      "Train Epoch: 3 [1000/11811 (8%)]\tLoss: 0.151902\n",
      "Train Epoch: 3 [2000/11811 (17%)]\tLoss: 0.241642\n",
      "Train Epoch: 3 [3000/11811 (25%)]\tLoss: 0.342745\n",
      "Train Epoch: 3 [4000/11811 (34%)]\tLoss: 0.228041\n",
      "Train Epoch: 3 [5000/11811 (42%)]\tLoss: 0.181860\n",
      "Train Epoch: 3 [6000/11811 (50%)]\tLoss: 0.095500\n",
      "Train Epoch: 3 [7000/11811 (59%)]\tLoss: 0.269920\n",
      "Train Epoch: 3 [8000/11811 (67%)]\tLoss: 0.129206\n",
      "Train Epoch: 3 [9000/11811 (76%)]\tLoss: 0.190172\n",
      "Train Epoch: 3 [10000/11811 (84%)]\tLoss: 0.304438\n",
      "Train Epoch: 3 [11000/11811 (92%)]\tLoss: 0.116504\n",
      "Train Epoch: 4 [0/11811 (0%)]\tLoss: 0.200307\n",
      "Train Epoch: 4 [1000/11811 (8%)]\tLoss: 0.171372\n",
      "Train Epoch: 4 [2000/11811 (17%)]\tLoss: 0.189325\n",
      "Train Epoch: 4 [3000/11811 (25%)]\tLoss: 0.143784\n",
      "Train Epoch: 4 [4000/11811 (34%)]\tLoss: 0.232961\n",
      "Train Epoch: 4 [5000/11811 (42%)]\tLoss: 0.172634\n",
      "Train Epoch: 4 [6000/11811 (50%)]\tLoss: 0.152865\n",
      "Train Epoch: 4 [7000/11811 (59%)]\tLoss: 0.154833\n",
      "Train Epoch: 4 [8000/11811 (67%)]\tLoss: 0.200795\n",
      "Train Epoch: 4 [9000/11811 (76%)]\tLoss: 0.243369\n",
      "Train Epoch: 4 [10000/11811 (84%)]\tLoss: 0.259001\n",
      "Train Epoch: 4 [11000/11811 (92%)]\tLoss: 0.257002\n",
      "Train Epoch: 5 [0/11811 (0%)]\tLoss: 0.188829\n",
      "Train Epoch: 5 [1000/11811 (8%)]\tLoss: 0.148233\n",
      "Train Epoch: 5 [2000/11811 (17%)]\tLoss: 0.226701\n",
      "Train Epoch: 5 [3000/11811 (25%)]\tLoss: 0.245303\n",
      "Train Epoch: 5 [4000/11811 (34%)]\tLoss: 0.288063\n",
      "Train Epoch: 5 [5000/11811 (42%)]\tLoss: 0.206664\n",
      "Train Epoch: 5 [6000/11811 (50%)]\tLoss: 0.246410\n",
      "Train Epoch: 5 [7000/11811 (59%)]\tLoss: 0.275302\n",
      "Train Epoch: 5 [8000/11811 (67%)]\tLoss: 0.314383\n",
      "Train Epoch: 5 [9000/11811 (76%)]\tLoss: 0.206031\n",
      "Train Epoch: 5 [10000/11811 (84%)]\tLoss: 0.262754\n",
      "Train Epoch: 5 [11000/11811 (92%)]\tLoss: 0.172556\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/9726 (0%)]\tLoss: 0.595743\n",
      "Train Epoch: 1 [1000/9726 (10%)]\tLoss: 0.349357\n",
      "Train Epoch: 1 [2000/9726 (20%)]\tLoss: 0.246380\n",
      "Train Epoch: 1 [3000/9726 (31%)]\tLoss: 0.365325\n",
      "Train Epoch: 1 [4000/9726 (41%)]\tLoss: 0.383187\n",
      "Train Epoch: 1 [5000/9726 (51%)]\tLoss: 0.400679\n",
      "Train Epoch: 1 [6000/9726 (61%)]\tLoss: 0.446053\n",
      "Train Epoch: 1 [7000/9726 (71%)]\tLoss: 0.381135\n",
      "Train Epoch: 1 [8000/9726 (82%)]\tLoss: 0.446880\n",
      "Train Epoch: 1 [9000/9726 (92%)]\tLoss: 0.314824\n",
      "Train Epoch: 2 [0/9726 (0%)]\tLoss: 0.348692\n",
      "Train Epoch: 2 [1000/9726 (10%)]\tLoss: 0.321960\n",
      "Train Epoch: 2 [2000/9726 (20%)]\tLoss: 0.402506\n",
      "Train Epoch: 2 [3000/9726 (31%)]\tLoss: 0.340263\n",
      "Train Epoch: 2 [4000/9726 (41%)]\tLoss: 0.346989\n",
      "Train Epoch: 2 [5000/9726 (51%)]\tLoss: 0.324408\n",
      "Train Epoch: 2 [6000/9726 (61%)]\tLoss: 0.363822\n",
      "Train Epoch: 2 [7000/9726 (71%)]\tLoss: 0.369928\n",
      "Train Epoch: 2 [8000/9726 (82%)]\tLoss: 0.392152\n",
      "Train Epoch: 2 [9000/9726 (92%)]\tLoss: 0.416233\n",
      "Train Epoch: 3 [0/9726 (0%)]\tLoss: 0.356343\n",
      "Train Epoch: 3 [1000/9726 (10%)]\tLoss: 0.320821\n",
      "Train Epoch: 3 [2000/9726 (20%)]\tLoss: 0.320880\n",
      "Train Epoch: 3 [3000/9726 (31%)]\tLoss: 0.374620\n",
      "Train Epoch: 3 [4000/9726 (41%)]\tLoss: 0.291276\n",
      "Train Epoch: 3 [5000/9726 (51%)]\tLoss: 0.424756\n",
      "Train Epoch: 3 [6000/9726 (61%)]\tLoss: 0.315169\n",
      "Train Epoch: 3 [7000/9726 (71%)]\tLoss: 0.413498\n",
      "Train Epoch: 3 [8000/9726 (82%)]\tLoss: 0.354235\n",
      "Train Epoch: 3 [9000/9726 (92%)]\tLoss: 0.349162\n",
      "Train Epoch: 4 [0/9726 (0%)]\tLoss: 0.354671\n",
      "Train Epoch: 4 [1000/9726 (10%)]\tLoss: 0.377469\n",
      "Train Epoch: 4 [2000/9726 (20%)]\tLoss: 0.257643\n",
      "Train Epoch: 4 [3000/9726 (31%)]\tLoss: 0.258407\n",
      "Train Epoch: 4 [4000/9726 (41%)]\tLoss: 0.479775\n",
      "Train Epoch: 4 [5000/9726 (51%)]\tLoss: 0.438291\n",
      "Train Epoch: 4 [6000/9726 (61%)]\tLoss: 0.335800\n",
      "Train Epoch: 4 [7000/9726 (71%)]\tLoss: 0.478438\n",
      "Train Epoch: 4 [8000/9726 (82%)]\tLoss: 0.379434\n",
      "Train Epoch: 4 [9000/9726 (92%)]\tLoss: 0.339735\n",
      "Train Epoch: 5 [0/9726 (0%)]\tLoss: 0.306639\n",
      "Train Epoch: 5 [1000/9726 (10%)]\tLoss: 0.347272\n",
      "Train Epoch: 5 [2000/9726 (20%)]\tLoss: 0.290212\n",
      "Train Epoch: 5 [3000/9726 (31%)]\tLoss: 0.345827\n",
      "Train Epoch: 5 [4000/9726 (41%)]\tLoss: 0.477281\n",
      "Train Epoch: 5 [5000/9726 (51%)]\tLoss: 0.428080\n",
      "Train Epoch: 5 [6000/9726 (61%)]\tLoss: 0.347806\n",
      "Train Epoch: 5 [7000/9726 (71%)]\tLoss: 0.236866\n",
      "Train Epoch: 5 [8000/9726 (82%)]\tLoss: 0.464757\n",
      "Train Epoch: 5 [9000/9726 (92%)]\tLoss: 0.518527\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/6491 (0%)]\tLoss: 1.056244\n",
      "Train Epoch: 1 [1000/6491 (15%)]\tLoss: 0.526579\n",
      "Train Epoch: 1 [2000/6491 (31%)]\tLoss: 0.650387\n",
      "Train Epoch: 1 [3000/6491 (46%)]\tLoss: 0.503438\n",
      "Train Epoch: 1 [4000/6491 (62%)]\tLoss: 0.484799\n",
      "Train Epoch: 1 [5000/6491 (77%)]\tLoss: 0.495723\n",
      "Train Epoch: 1 [6000/6491 (92%)]\tLoss: 0.413044\n",
      "Train Epoch: 2 [0/6491 (0%)]\tLoss: 0.433214\n",
      "Train Epoch: 2 [1000/6491 (15%)]\tLoss: 0.543922\n",
      "Train Epoch: 2 [2000/6491 (31%)]\tLoss: 0.482211\n",
      "Train Epoch: 2 [3000/6491 (46%)]\tLoss: 0.455703\n",
      "Train Epoch: 2 [4000/6491 (62%)]\tLoss: 0.386081\n",
      "Train Epoch: 2 [5000/6491 (77%)]\tLoss: 0.417284\n",
      "Train Epoch: 2 [6000/6491 (92%)]\tLoss: 0.592083\n",
      "Train Epoch: 3 [0/6491 (0%)]\tLoss: 0.548754\n",
      "Train Epoch: 3 [1000/6491 (15%)]\tLoss: 0.527432\n",
      "Train Epoch: 3 [2000/6491 (31%)]\tLoss: 0.569392\n",
      "Train Epoch: 3 [3000/6491 (46%)]\tLoss: 0.658919\n",
      "Train Epoch: 3 [4000/6491 (62%)]\tLoss: 0.464541\n",
      "Train Epoch: 3 [5000/6491 (77%)]\tLoss: 0.382232\n",
      "Train Epoch: 3 [6000/6491 (92%)]\tLoss: 0.479400\n",
      "Train Epoch: 4 [0/6491 (0%)]\tLoss: 0.444989\n",
      "Train Epoch: 4 [1000/6491 (15%)]\tLoss: 0.522692\n",
      "Train Epoch: 4 [2000/6491 (31%)]\tLoss: 0.459413\n",
      "Train Epoch: 4 [3000/6491 (46%)]\tLoss: 0.427760\n",
      "Train Epoch: 4 [4000/6491 (62%)]\tLoss: 0.409583\n",
      "Train Epoch: 4 [5000/6491 (77%)]\tLoss: 0.586264\n",
      "Train Epoch: 4 [6000/6491 (92%)]\tLoss: 0.389702\n",
      "Train Epoch: 5 [0/6491 (0%)]\tLoss: 0.580486\n",
      "Train Epoch: 5 [1000/6491 (15%)]\tLoss: 0.377803\n",
      "Train Epoch: 5 [2000/6491 (31%)]\tLoss: 0.418554\n",
      "Train Epoch: 5 [3000/6491 (46%)]\tLoss: 0.550694\n",
      "Train Epoch: 5 [4000/6491 (62%)]\tLoss: 0.494659\n",
      "Train Epoch: 5 [5000/6491 (77%)]\tLoss: 0.576587\n",
      "Train Epoch: 5 [6000/6491 (92%)]\tLoss: 0.432877\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/14118 (0%)]\tLoss: 0.711544\n",
      "Train Epoch: 1 [1000/14118 (7%)]\tLoss: 0.356131\n",
      "Train Epoch: 1 [2000/14118 (14%)]\tLoss: 0.511566\n",
      "Train Epoch: 1 [3000/14118 (21%)]\tLoss: 0.236365\n",
      "Train Epoch: 1 [4000/14118 (28%)]\tLoss: 0.265602\n",
      "Train Epoch: 1 [5000/14118 (35%)]\tLoss: 0.365831\n",
      "Train Epoch: 1 [6000/14118 (42%)]\tLoss: 0.371324\n",
      "Train Epoch: 1 [7000/14118 (49%)]\tLoss: 0.227417\n",
      "Train Epoch: 1 [8000/14118 (56%)]\tLoss: 0.479869\n",
      "Train Epoch: 1 [9000/14118 (63%)]\tLoss: 0.485308\n",
      "Train Epoch: 1 [10000/14118 (70%)]\tLoss: 0.237630\n",
      "Train Epoch: 1 [11000/14118 (77%)]\tLoss: 0.265091\n",
      "Train Epoch: 1 [12000/14118 (85%)]\tLoss: 0.337262\n",
      "Train Epoch: 1 [13000/14118 (92%)]\tLoss: 0.396459\n",
      "Train Epoch: 1 [14000/14118 (99%)]\tLoss: 0.175287\n",
      "Train Epoch: 2 [0/14118 (0%)]\tLoss: 0.287856\n",
      "Train Epoch: 2 [1000/14118 (7%)]\tLoss: 0.363391\n",
      "Train Epoch: 2 [2000/14118 (14%)]\tLoss: 0.470132\n",
      "Train Epoch: 2 [3000/14118 (21%)]\tLoss: 0.351366\n",
      "Train Epoch: 2 [4000/14118 (28%)]\tLoss: 0.413194\n",
      "Train Epoch: 2 [5000/14118 (35%)]\tLoss: 0.374783\n",
      "Train Epoch: 2 [6000/14118 (42%)]\tLoss: 0.300891\n",
      "Train Epoch: 2 [7000/14118 (49%)]\tLoss: 0.366374\n",
      "Train Epoch: 2 [8000/14118 (56%)]\tLoss: 0.311723\n",
      "Train Epoch: 2 [9000/14118 (63%)]\tLoss: 0.300830\n",
      "Train Epoch: 2 [10000/14118 (70%)]\tLoss: 0.386496\n",
      "Train Epoch: 2 [11000/14118 (77%)]\tLoss: 0.241460\n",
      "Train Epoch: 2 [12000/14118 (85%)]\tLoss: 0.381071\n",
      "Train Epoch: 2 [13000/14118 (92%)]\tLoss: 0.264101\n",
      "Train Epoch: 2 [14000/14118 (99%)]\tLoss: 0.253980\n",
      "Train Epoch: 3 [0/14118 (0%)]\tLoss: 0.329207\n",
      "Train Epoch: 3 [1000/14118 (7%)]\tLoss: 0.312049\n",
      "Train Epoch: 3 [2000/14118 (14%)]\tLoss: 0.292762\n",
      "Train Epoch: 3 [3000/14118 (21%)]\tLoss: 0.353068\n",
      "Train Epoch: 3 [4000/14118 (28%)]\tLoss: 0.322561\n",
      "Train Epoch: 3 [5000/14118 (35%)]\tLoss: 0.357216\n",
      "Train Epoch: 3 [6000/14118 (42%)]\tLoss: 0.183890\n",
      "Train Epoch: 3 [7000/14118 (49%)]\tLoss: 0.375531\n",
      "Train Epoch: 3 [8000/14118 (56%)]\tLoss: 0.274989\n",
      "Train Epoch: 3 [9000/14118 (63%)]\tLoss: 0.382413\n",
      "Train Epoch: 3 [10000/14118 (70%)]\tLoss: 0.286356\n",
      "Train Epoch: 3 [11000/14118 (77%)]\tLoss: 0.309468\n",
      "Train Epoch: 3 [12000/14118 (85%)]\tLoss: 0.292010\n",
      "Train Epoch: 3 [13000/14118 (92%)]\tLoss: 0.326021\n",
      "Train Epoch: 3 [14000/14118 (99%)]\tLoss: 0.393256\n",
      "Train Epoch: 4 [0/14118 (0%)]\tLoss: 0.305894\n",
      "Train Epoch: 4 [1000/14118 (7%)]\tLoss: 0.389960\n",
      "Train Epoch: 4 [2000/14118 (14%)]\tLoss: 0.361327\n",
      "Train Epoch: 4 [3000/14118 (21%)]\tLoss: 0.353169\n",
      "Train Epoch: 4 [4000/14118 (28%)]\tLoss: 0.187821\n",
      "Train Epoch: 4 [5000/14118 (35%)]\tLoss: 0.191033\n",
      "Train Epoch: 4 [6000/14118 (42%)]\tLoss: 0.337182\n",
      "Train Epoch: 4 [7000/14118 (49%)]\tLoss: 0.343752\n",
      "Train Epoch: 4 [8000/14118 (56%)]\tLoss: 0.357813\n",
      "Train Epoch: 4 [9000/14118 (63%)]\tLoss: 0.262872\n",
      "Train Epoch: 4 [10000/14118 (70%)]\tLoss: 0.417081\n",
      "Train Epoch: 4 [11000/14118 (77%)]\tLoss: 0.371681\n",
      "Train Epoch: 4 [12000/14118 (85%)]\tLoss: 0.184198\n",
      "Train Epoch: 4 [13000/14118 (92%)]\tLoss: 0.306183\n",
      "Train Epoch: 4 [14000/14118 (99%)]\tLoss: 0.262762\n",
      "Train Epoch: 5 [0/14118 (0%)]\tLoss: 0.405609\n",
      "Train Epoch: 5 [1000/14118 (7%)]\tLoss: 0.389233\n",
      "Train Epoch: 5 [2000/14118 (14%)]\tLoss: 0.287072\n",
      "Train Epoch: 5 [3000/14118 (21%)]\tLoss: 0.273381\n",
      "Train Epoch: 5 [4000/14118 (28%)]\tLoss: 0.198042\n",
      "Train Epoch: 5 [5000/14118 (35%)]\tLoss: 0.324397\n",
      "Train Epoch: 5 [6000/14118 (42%)]\tLoss: 0.352862\n",
      "Train Epoch: 5 [7000/14118 (49%)]\tLoss: 0.267644\n",
      "Train Epoch: 5 [8000/14118 (56%)]\tLoss: 0.385114\n",
      "Train Epoch: 5 [9000/14118 (63%)]\tLoss: 0.360106\n",
      "Train Epoch: 5 [10000/14118 (70%)]\tLoss: 0.256800\n",
      "Train Epoch: 5 [11000/14118 (77%)]\tLoss: 0.296104\n",
      "Train Epoch: 5 [12000/14118 (85%)]\tLoss: 0.257780\n",
      "Train Epoch: 5 [13000/14118 (92%)]\tLoss: 0.243488\n",
      "Train Epoch: 5 [14000/14118 (99%)]\tLoss: 0.359150\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/9414 (0%)]\tLoss: 0.732202\n",
      "Train Epoch: 1 [1000/9414 (11%)]\tLoss: 0.446269\n",
      "Train Epoch: 1 [2000/9414 (21%)]\tLoss: 0.377413\n",
      "Train Epoch: 1 [3000/9414 (32%)]\tLoss: 0.420269\n",
      "Train Epoch: 1 [4000/9414 (42%)]\tLoss: 0.327320\n",
      "Train Epoch: 1 [5000/9414 (53%)]\tLoss: 0.493161\n",
      "Train Epoch: 1 [6000/9414 (63%)]\tLoss: 0.287461\n",
      "Train Epoch: 1 [7000/9414 (74%)]\tLoss: 0.371164\n",
      "Train Epoch: 1 [8000/9414 (84%)]\tLoss: 0.519109\n",
      "Train Epoch: 1 [9000/9414 (95%)]\tLoss: 0.480573\n",
      "Train Epoch: 2 [0/9414 (0%)]\tLoss: 0.439580\n",
      "Train Epoch: 2 [1000/9414 (11%)]\tLoss: 0.273822\n",
      "Train Epoch: 2 [2000/9414 (21%)]\tLoss: 0.351713\n",
      "Train Epoch: 2 [3000/9414 (32%)]\tLoss: 0.372037\n",
      "Train Epoch: 2 [4000/9414 (42%)]\tLoss: 0.385753\n",
      "Train Epoch: 2 [5000/9414 (53%)]\tLoss: 0.427119\n",
      "Train Epoch: 2 [6000/9414 (63%)]\tLoss: 0.302091\n",
      "Train Epoch: 2 [7000/9414 (74%)]\tLoss: 0.472395\n",
      "Train Epoch: 2 [8000/9414 (84%)]\tLoss: 0.330685\n",
      "Train Epoch: 2 [9000/9414 (95%)]\tLoss: 0.438036\n",
      "Train Epoch: 3 [0/9414 (0%)]\tLoss: 0.394835\n",
      "Train Epoch: 3 [1000/9414 (11%)]\tLoss: 0.342131\n",
      "Train Epoch: 3 [2000/9414 (21%)]\tLoss: 0.452752\n",
      "Train Epoch: 3 [3000/9414 (32%)]\tLoss: 0.437345\n",
      "Train Epoch: 3 [4000/9414 (42%)]\tLoss: 0.290048\n",
      "Train Epoch: 3 [5000/9414 (53%)]\tLoss: 0.392496\n",
      "Train Epoch: 3 [6000/9414 (63%)]\tLoss: 0.427762\n",
      "Train Epoch: 3 [7000/9414 (74%)]\tLoss: 0.334927\n",
      "Train Epoch: 3 [8000/9414 (84%)]\tLoss: 0.320155\n",
      "Train Epoch: 3 [9000/9414 (95%)]\tLoss: 0.394041\n",
      "Train Epoch: 4 [0/9414 (0%)]\tLoss: 0.398875\n",
      "Train Epoch: 4 [1000/9414 (11%)]\tLoss: 0.380049\n",
      "Train Epoch: 4 [2000/9414 (21%)]\tLoss: 0.387185\n",
      "Train Epoch: 4 [3000/9414 (32%)]\tLoss: 0.406468\n",
      "Train Epoch: 4 [4000/9414 (42%)]\tLoss: 0.502397\n",
      "Train Epoch: 4 [5000/9414 (53%)]\tLoss: 0.234320\n",
      "Train Epoch: 4 [6000/9414 (63%)]\tLoss: 0.318589\n",
      "Train Epoch: 4 [7000/9414 (74%)]\tLoss: 0.435230\n",
      "Train Epoch: 4 [8000/9414 (84%)]\tLoss: 0.317585\n",
      "Train Epoch: 4 [9000/9414 (95%)]\tLoss: 0.297327\n",
      "Train Epoch: 5 [0/9414 (0%)]\tLoss: 0.361822\n",
      "Train Epoch: 5 [1000/9414 (11%)]\tLoss: 0.363962\n",
      "Train Epoch: 5 [2000/9414 (21%)]\tLoss: 0.364157\n",
      "Train Epoch: 5 [3000/9414 (32%)]\tLoss: 0.306750\n",
      "Train Epoch: 5 [4000/9414 (42%)]\tLoss: 0.320594\n",
      "Train Epoch: 5 [5000/9414 (53%)]\tLoss: 0.392541\n",
      "Train Epoch: 5 [6000/9414 (63%)]\tLoss: 0.345746\n",
      "Train Epoch: 5 [7000/9414 (74%)]\tLoss: 0.397424\n",
      "Train Epoch: 5 [8000/9414 (84%)]\tLoss: 0.435447\n",
      "Train Epoch: 5 [9000/9414 (95%)]\tLoss: 0.351741\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "6\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.7711, Accuracy: 7781/10000 (78%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/8440 (0%)]\tLoss: 0.631138\n",
      "Train Epoch: 1 [1000/8440 (12%)]\tLoss: 0.399321\n",
      "Train Epoch: 1 [2000/8440 (24%)]\tLoss: 0.528497\n",
      "Train Epoch: 1 [3000/8440 (35%)]\tLoss: 0.549436\n",
      "Train Epoch: 1 [4000/8440 (47%)]\tLoss: 0.443798\n",
      "Train Epoch: 1 [5000/8440 (59%)]\tLoss: 0.455138\n",
      "Train Epoch: 1 [6000/8440 (71%)]\tLoss: 0.398278\n",
      "Train Epoch: 1 [7000/8440 (82%)]\tLoss: 0.428230\n",
      "Train Epoch: 1 [8000/8440 (94%)]\tLoss: 0.468044\n",
      "Train Epoch: 2 [0/8440 (0%)]\tLoss: 0.467015\n",
      "Train Epoch: 2 [1000/8440 (12%)]\tLoss: 0.496258\n",
      "Train Epoch: 2 [2000/8440 (24%)]\tLoss: 0.583699\n",
      "Train Epoch: 2 [3000/8440 (35%)]\tLoss: 0.432201\n",
      "Train Epoch: 2 [4000/8440 (47%)]\tLoss: 0.331451\n",
      "Train Epoch: 2 [5000/8440 (59%)]\tLoss: 0.330573\n",
      "Train Epoch: 2 [6000/8440 (71%)]\tLoss: 0.380970\n",
      "Train Epoch: 2 [7000/8440 (82%)]\tLoss: 0.445137\n",
      "Train Epoch: 2 [8000/8440 (94%)]\tLoss: 0.378054\n",
      "Train Epoch: 3 [0/8440 (0%)]\tLoss: 0.429443\n",
      "Train Epoch: 3 [1000/8440 (12%)]\tLoss: 0.333857\n",
      "Train Epoch: 3 [2000/8440 (24%)]\tLoss: 0.421963\n",
      "Train Epoch: 3 [3000/8440 (35%)]\tLoss: 0.450732\n",
      "Train Epoch: 3 [4000/8440 (47%)]\tLoss: 0.421364\n",
      "Train Epoch: 3 [5000/8440 (59%)]\tLoss: 0.445771\n",
      "Train Epoch: 3 [6000/8440 (71%)]\tLoss: 0.400725\n",
      "Train Epoch: 3 [7000/8440 (82%)]\tLoss: 0.519491\n",
      "Train Epoch: 3 [8000/8440 (94%)]\tLoss: 0.400405\n",
      "Train Epoch: 4 [0/8440 (0%)]\tLoss: 0.474389\n",
      "Train Epoch: 4 [1000/8440 (12%)]\tLoss: 0.384823\n",
      "Train Epoch: 4 [2000/8440 (24%)]\tLoss: 0.304816\n",
      "Train Epoch: 4 [3000/8440 (35%)]\tLoss: 0.395248\n",
      "Train Epoch: 4 [4000/8440 (47%)]\tLoss: 0.455626\n",
      "Train Epoch: 4 [5000/8440 (59%)]\tLoss: 0.491481\n",
      "Train Epoch: 4 [6000/8440 (71%)]\tLoss: 0.266271\n",
      "Train Epoch: 4 [7000/8440 (82%)]\tLoss: 0.470110\n",
      "Train Epoch: 4 [8000/8440 (94%)]\tLoss: 0.332601\n",
      "Train Epoch: 5 [0/8440 (0%)]\tLoss: 0.359662\n",
      "Train Epoch: 5 [1000/8440 (12%)]\tLoss: 0.450079\n",
      "Train Epoch: 5 [2000/8440 (24%)]\tLoss: 0.281213\n",
      "Train Epoch: 5 [3000/8440 (35%)]\tLoss: 0.535449\n",
      "Train Epoch: 5 [4000/8440 (47%)]\tLoss: 0.364895\n",
      "Train Epoch: 5 [5000/8440 (59%)]\tLoss: 0.372181\n",
      "Train Epoch: 5 [6000/8440 (71%)]\tLoss: 0.361428\n",
      "Train Epoch: 5 [7000/8440 (82%)]\tLoss: 0.398655\n",
      "Train Epoch: 5 [8000/8440 (94%)]\tLoss: 0.460848\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11811 (0%)]\tLoss: 0.500331\n",
      "Train Epoch: 1 [1000/11811 (8%)]\tLoss: 0.236119\n",
      "Train Epoch: 1 [2000/11811 (17%)]\tLoss: 0.126661\n",
      "Train Epoch: 1 [3000/11811 (25%)]\tLoss: 0.206136\n",
      "Train Epoch: 1 [4000/11811 (34%)]\tLoss: 0.210370\n",
      "Train Epoch: 1 [5000/11811 (42%)]\tLoss: 0.314016\n",
      "Train Epoch: 1 [6000/11811 (50%)]\tLoss: 0.218917\n",
      "Train Epoch: 1 [7000/11811 (59%)]\tLoss: 0.339887\n",
      "Train Epoch: 1 [8000/11811 (67%)]\tLoss: 0.161412\n",
      "Train Epoch: 1 [9000/11811 (76%)]\tLoss: 0.163648\n",
      "Train Epoch: 1 [10000/11811 (84%)]\tLoss: 0.269673\n",
      "Train Epoch: 1 [11000/11811 (92%)]\tLoss: 0.360748\n",
      "Train Epoch: 2 [0/11811 (0%)]\tLoss: 0.361550\n",
      "Train Epoch: 2 [1000/11811 (8%)]\tLoss: 0.169673\n",
      "Train Epoch: 2 [2000/11811 (17%)]\tLoss: 0.216872\n",
      "Train Epoch: 2 [3000/11811 (25%)]\tLoss: 0.263860\n",
      "Train Epoch: 2 [4000/11811 (34%)]\tLoss: 0.146527\n",
      "Train Epoch: 2 [5000/11811 (42%)]\tLoss: 0.193886\n",
      "Train Epoch: 2 [6000/11811 (50%)]\tLoss: 0.194469\n",
      "Train Epoch: 2 [7000/11811 (59%)]\tLoss: 0.177563\n",
      "Train Epoch: 2 [8000/11811 (67%)]\tLoss: 0.176611\n",
      "Train Epoch: 2 [9000/11811 (76%)]\tLoss: 0.372707\n",
      "Train Epoch: 2 [10000/11811 (84%)]\tLoss: 0.141344\n",
      "Train Epoch: 2 [11000/11811 (92%)]\tLoss: 0.155298\n",
      "Train Epoch: 3 [0/11811 (0%)]\tLoss: 0.238854\n",
      "Train Epoch: 3 [1000/11811 (8%)]\tLoss: 0.222686\n",
      "Train Epoch: 3 [2000/11811 (17%)]\tLoss: 0.154182\n",
      "Train Epoch: 3 [3000/11811 (25%)]\tLoss: 0.263635\n",
      "Train Epoch: 3 [4000/11811 (34%)]\tLoss: 0.227976\n",
      "Train Epoch: 3 [5000/11811 (42%)]\tLoss: 0.211079\n",
      "Train Epoch: 3 [6000/11811 (50%)]\tLoss: 0.141603\n",
      "Train Epoch: 3 [7000/11811 (59%)]\tLoss: 0.254302\n",
      "Train Epoch: 3 [8000/11811 (67%)]\tLoss: 0.271585\n",
      "Train Epoch: 3 [9000/11811 (76%)]\tLoss: 0.136556\n",
      "Train Epoch: 3 [10000/11811 (84%)]\tLoss: 0.255935\n",
      "Train Epoch: 3 [11000/11811 (92%)]\tLoss: 0.306217\n",
      "Train Epoch: 4 [0/11811 (0%)]\tLoss: 0.382143\n",
      "Train Epoch: 4 [1000/11811 (8%)]\tLoss: 0.301291\n",
      "Train Epoch: 4 [2000/11811 (17%)]\tLoss: 0.231261\n",
      "Train Epoch: 4 [3000/11811 (25%)]\tLoss: 0.232139\n",
      "Train Epoch: 4 [4000/11811 (34%)]\tLoss: 0.308570\n",
      "Train Epoch: 4 [5000/11811 (42%)]\tLoss: 0.279700\n",
      "Train Epoch: 4 [6000/11811 (50%)]\tLoss: 0.199625\n",
      "Train Epoch: 4 [7000/11811 (59%)]\tLoss: 0.149156\n",
      "Train Epoch: 4 [8000/11811 (67%)]\tLoss: 0.284729\n",
      "Train Epoch: 4 [9000/11811 (76%)]\tLoss: 0.193642\n",
      "Train Epoch: 4 [10000/11811 (84%)]\tLoss: 0.227032\n",
      "Train Epoch: 4 [11000/11811 (92%)]\tLoss: 0.186603\n",
      "Train Epoch: 5 [0/11811 (0%)]\tLoss: 0.299006\n",
      "Train Epoch: 5 [1000/11811 (8%)]\tLoss: 0.132644\n",
      "Train Epoch: 5 [2000/11811 (17%)]\tLoss: 0.242172\n",
      "Train Epoch: 5 [3000/11811 (25%)]\tLoss: 0.319355\n",
      "Train Epoch: 5 [4000/11811 (34%)]\tLoss: 0.197815\n",
      "Train Epoch: 5 [5000/11811 (42%)]\tLoss: 0.156310\n",
      "Train Epoch: 5 [6000/11811 (50%)]\tLoss: 0.288600\n",
      "Train Epoch: 5 [7000/11811 (59%)]\tLoss: 0.148247\n",
      "Train Epoch: 5 [8000/11811 (67%)]\tLoss: 0.163142\n",
      "Train Epoch: 5 [9000/11811 (76%)]\tLoss: 0.119426\n",
      "Train Epoch: 5 [10000/11811 (84%)]\tLoss: 0.225950\n",
      "Train Epoch: 5 [11000/11811 (92%)]\tLoss: 0.242073\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/9726 (0%)]\tLoss: 0.379687\n",
      "Train Epoch: 1 [1000/9726 (10%)]\tLoss: 0.383061\n",
      "Train Epoch: 1 [2000/9726 (20%)]\tLoss: 0.293706\n",
      "Train Epoch: 1 [3000/9726 (31%)]\tLoss: 0.248644\n",
      "Train Epoch: 1 [4000/9726 (41%)]\tLoss: 0.359566\n",
      "Train Epoch: 1 [5000/9726 (51%)]\tLoss: 0.383597\n",
      "Train Epoch: 1 [6000/9726 (61%)]\tLoss: 0.360387\n",
      "Train Epoch: 1 [7000/9726 (71%)]\tLoss: 0.410723\n",
      "Train Epoch: 1 [8000/9726 (82%)]\tLoss: 0.316119\n",
      "Train Epoch: 1 [9000/9726 (92%)]\tLoss: 0.385110\n",
      "Train Epoch: 2 [0/9726 (0%)]\tLoss: 0.343000\n",
      "Train Epoch: 2 [1000/9726 (10%)]\tLoss: 0.346378\n",
      "Train Epoch: 2 [2000/9726 (20%)]\tLoss: 0.302731\n",
      "Train Epoch: 2 [3000/9726 (31%)]\tLoss: 0.379807\n",
      "Train Epoch: 2 [4000/9726 (41%)]\tLoss: 0.345995\n",
      "Train Epoch: 2 [5000/9726 (51%)]\tLoss: 0.357447\n",
      "Train Epoch: 2 [6000/9726 (61%)]\tLoss: 0.289005\n",
      "Train Epoch: 2 [7000/9726 (71%)]\tLoss: 0.406222\n",
      "Train Epoch: 2 [8000/9726 (82%)]\tLoss: 0.349850\n",
      "Train Epoch: 2 [9000/9726 (92%)]\tLoss: 0.312344\n",
      "Train Epoch: 3 [0/9726 (0%)]\tLoss: 0.368734\n",
      "Train Epoch: 3 [1000/9726 (10%)]\tLoss: 0.446379\n",
      "Train Epoch: 3 [2000/9726 (20%)]\tLoss: 0.311380\n",
      "Train Epoch: 3 [3000/9726 (31%)]\tLoss: 0.370281\n",
      "Train Epoch: 3 [4000/9726 (41%)]\tLoss: 0.420754\n",
      "Train Epoch: 3 [5000/9726 (51%)]\tLoss: 0.381534\n",
      "Train Epoch: 3 [6000/9726 (61%)]\tLoss: 0.322853\n",
      "Train Epoch: 3 [7000/9726 (71%)]\tLoss: 0.269137\n",
      "Train Epoch: 3 [8000/9726 (82%)]\tLoss: 0.301731\n",
      "Train Epoch: 3 [9000/9726 (92%)]\tLoss: 0.414180\n",
      "Train Epoch: 4 [0/9726 (0%)]\tLoss: 0.397132\n",
      "Train Epoch: 4 [1000/9726 (10%)]\tLoss: 0.364690\n",
      "Train Epoch: 4 [2000/9726 (20%)]\tLoss: 0.385719\n",
      "Train Epoch: 4 [3000/9726 (31%)]\tLoss: 0.327275\n",
      "Train Epoch: 4 [4000/9726 (41%)]\tLoss: 0.443029\n",
      "Train Epoch: 4 [5000/9726 (51%)]\tLoss: 0.369872\n",
      "Train Epoch: 4 [6000/9726 (61%)]\tLoss: 0.312656\n",
      "Train Epoch: 4 [7000/9726 (71%)]\tLoss: 0.370676\n",
      "Train Epoch: 4 [8000/9726 (82%)]\tLoss: 0.276809\n",
      "Train Epoch: 4 [9000/9726 (92%)]\tLoss: 0.462887\n",
      "Train Epoch: 5 [0/9726 (0%)]\tLoss: 0.443141\n",
      "Train Epoch: 5 [1000/9726 (10%)]\tLoss: 0.381000\n",
      "Train Epoch: 5 [2000/9726 (20%)]\tLoss: 0.274643\n",
      "Train Epoch: 5 [3000/9726 (31%)]\tLoss: 0.423356\n",
      "Train Epoch: 5 [4000/9726 (41%)]\tLoss: 0.245784\n",
      "Train Epoch: 5 [5000/9726 (51%)]\tLoss: 0.306899\n",
      "Train Epoch: 5 [6000/9726 (61%)]\tLoss: 0.351393\n",
      "Train Epoch: 5 [7000/9726 (71%)]\tLoss: 0.438403\n",
      "Train Epoch: 5 [8000/9726 (82%)]\tLoss: 0.302391\n",
      "Train Epoch: 5 [9000/9726 (92%)]\tLoss: 0.438088\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/6491 (0%)]\tLoss: 0.573260\n",
      "Train Epoch: 1 [1000/6491 (15%)]\tLoss: 0.587659\n",
      "Train Epoch: 1 [2000/6491 (31%)]\tLoss: 0.476846\n",
      "Train Epoch: 1 [3000/6491 (46%)]\tLoss: 0.340725\n",
      "Train Epoch: 1 [4000/6491 (62%)]\tLoss: 0.474856\n",
      "Train Epoch: 1 [5000/6491 (77%)]\tLoss: 0.526370\n",
      "Train Epoch: 1 [6000/6491 (92%)]\tLoss: 0.543416\n",
      "Train Epoch: 2 [0/6491 (0%)]\tLoss: 0.440920\n",
      "Train Epoch: 2 [1000/6491 (15%)]\tLoss: 0.375138\n",
      "Train Epoch: 2 [2000/6491 (31%)]\tLoss: 0.388744\n",
      "Train Epoch: 2 [3000/6491 (46%)]\tLoss: 0.492387\n",
      "Train Epoch: 2 [4000/6491 (62%)]\tLoss: 0.389550\n",
      "Train Epoch: 2 [5000/6491 (77%)]\tLoss: 0.581882\n",
      "Train Epoch: 2 [6000/6491 (92%)]\tLoss: 0.460473\n",
      "Train Epoch: 3 [0/6491 (0%)]\tLoss: 0.387664\n",
      "Train Epoch: 3 [1000/6491 (15%)]\tLoss: 0.539951\n",
      "Train Epoch: 3 [2000/6491 (31%)]\tLoss: 0.360730\n",
      "Train Epoch: 3 [3000/6491 (46%)]\tLoss: 0.388998\n",
      "Train Epoch: 3 [4000/6491 (62%)]\tLoss: 0.455660\n",
      "Train Epoch: 3 [5000/6491 (77%)]\tLoss: 0.515794\n",
      "Train Epoch: 3 [6000/6491 (92%)]\tLoss: 0.329935\n",
      "Train Epoch: 4 [0/6491 (0%)]\tLoss: 0.430756\n",
      "Train Epoch: 4 [1000/6491 (15%)]\tLoss: 0.414433\n",
      "Train Epoch: 4 [2000/6491 (31%)]\tLoss: 0.602274\n",
      "Train Epoch: 4 [3000/6491 (46%)]\tLoss: 0.421371\n",
      "Train Epoch: 4 [4000/6491 (62%)]\tLoss: 0.524047\n",
      "Train Epoch: 4 [5000/6491 (77%)]\tLoss: 0.467557\n",
      "Train Epoch: 4 [6000/6491 (92%)]\tLoss: 0.485578\n",
      "Train Epoch: 5 [0/6491 (0%)]\tLoss: 0.488622\n",
      "Train Epoch: 5 [1000/6491 (15%)]\tLoss: 0.424890\n",
      "Train Epoch: 5 [2000/6491 (31%)]\tLoss: 0.437195\n",
      "Train Epoch: 5 [3000/6491 (46%)]\tLoss: 0.393218\n",
      "Train Epoch: 5 [4000/6491 (62%)]\tLoss: 0.515468\n",
      "Train Epoch: 5 [5000/6491 (77%)]\tLoss: 0.447351\n",
      "Train Epoch: 5 [6000/6491 (92%)]\tLoss: 0.258276\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/14118 (0%)]\tLoss: 0.556466\n",
      "Train Epoch: 1 [1000/14118 (7%)]\tLoss: 0.531311\n",
      "Train Epoch: 1 [2000/14118 (14%)]\tLoss: 0.351839\n",
      "Train Epoch: 1 [3000/14118 (21%)]\tLoss: 0.331518\n",
      "Train Epoch: 1 [4000/14118 (28%)]\tLoss: 0.262943\n",
      "Train Epoch: 1 [5000/14118 (35%)]\tLoss: 0.380607\n",
      "Train Epoch: 1 [6000/14118 (42%)]\tLoss: 0.477467\n",
      "Train Epoch: 1 [7000/14118 (49%)]\tLoss: 0.210990\n",
      "Train Epoch: 1 [8000/14118 (56%)]\tLoss: 0.306089\n",
      "Train Epoch: 1 [9000/14118 (63%)]\tLoss: 0.369845\n",
      "Train Epoch: 1 [10000/14118 (70%)]\tLoss: 0.308160\n",
      "Train Epoch: 1 [11000/14118 (77%)]\tLoss: 0.379478\n",
      "Train Epoch: 1 [12000/14118 (85%)]\tLoss: 0.308608\n",
      "Train Epoch: 1 [13000/14118 (92%)]\tLoss: 0.371118\n",
      "Train Epoch: 1 [14000/14118 (99%)]\tLoss: 0.283806\n",
      "Train Epoch: 2 [0/14118 (0%)]\tLoss: 0.388056\n",
      "Train Epoch: 2 [1000/14118 (7%)]\tLoss: 0.262923\n",
      "Train Epoch: 2 [2000/14118 (14%)]\tLoss: 0.306959\n",
      "Train Epoch: 2 [3000/14118 (21%)]\tLoss: 0.435275\n",
      "Train Epoch: 2 [4000/14118 (28%)]\tLoss: 0.304553\n",
      "Train Epoch: 2 [5000/14118 (35%)]\tLoss: 0.397204\n",
      "Train Epoch: 2 [6000/14118 (42%)]\tLoss: 0.304928\n",
      "Train Epoch: 2 [7000/14118 (49%)]\tLoss: 0.295421\n",
      "Train Epoch: 2 [8000/14118 (56%)]\tLoss: 0.287922\n",
      "Train Epoch: 2 [9000/14118 (63%)]\tLoss: 0.391599\n",
      "Train Epoch: 2 [10000/14118 (70%)]\tLoss: 0.290666\n",
      "Train Epoch: 2 [11000/14118 (77%)]\tLoss: 0.384523\n",
      "Train Epoch: 2 [12000/14118 (85%)]\tLoss: 0.217212\n",
      "Train Epoch: 2 [13000/14118 (92%)]\tLoss: 0.318697\n",
      "Train Epoch: 2 [14000/14118 (99%)]\tLoss: 0.404107\n",
      "Train Epoch: 3 [0/14118 (0%)]\tLoss: 0.250999\n",
      "Train Epoch: 3 [1000/14118 (7%)]\tLoss: 0.277313\n",
      "Train Epoch: 3 [2000/14118 (14%)]\tLoss: 0.477846\n",
      "Train Epoch: 3 [3000/14118 (21%)]\tLoss: 0.279452\n",
      "Train Epoch: 3 [4000/14118 (28%)]\tLoss: 0.437525\n",
      "Train Epoch: 3 [5000/14118 (35%)]\tLoss: 0.360320\n",
      "Train Epoch: 3 [6000/14118 (42%)]\tLoss: 0.499198\n",
      "Train Epoch: 3 [7000/14118 (49%)]\tLoss: 0.356466\n",
      "Train Epoch: 3 [8000/14118 (56%)]\tLoss: 0.265503\n",
      "Train Epoch: 3 [9000/14118 (63%)]\tLoss: 0.332202\n",
      "Train Epoch: 3 [10000/14118 (70%)]\tLoss: 0.425585\n",
      "Train Epoch: 3 [11000/14118 (77%)]\tLoss: 0.359335\n",
      "Train Epoch: 3 [12000/14118 (85%)]\tLoss: 0.257477\n",
      "Train Epoch: 3 [13000/14118 (92%)]\tLoss: 0.267731\n",
      "Train Epoch: 3 [14000/14118 (99%)]\tLoss: 0.358061\n",
      "Train Epoch: 4 [0/14118 (0%)]\tLoss: 0.261653\n",
      "Train Epoch: 4 [1000/14118 (7%)]\tLoss: 0.495270\n",
      "Train Epoch: 4 [2000/14118 (14%)]\tLoss: 0.314884\n",
      "Train Epoch: 4 [3000/14118 (21%)]\tLoss: 0.327827\n",
      "Train Epoch: 4 [4000/14118 (28%)]\tLoss: 0.274237\n",
      "Train Epoch: 4 [5000/14118 (35%)]\tLoss: 0.439406\n",
      "Train Epoch: 4 [6000/14118 (42%)]\tLoss: 0.448495\n",
      "Train Epoch: 4 [7000/14118 (49%)]\tLoss: 0.269688\n",
      "Train Epoch: 4 [8000/14118 (56%)]\tLoss: 0.318787\n",
      "Train Epoch: 4 [9000/14118 (63%)]\tLoss: 0.271014\n",
      "Train Epoch: 4 [10000/14118 (70%)]\tLoss: 0.398884\n",
      "Train Epoch: 4 [11000/14118 (77%)]\tLoss: 0.479881\n",
      "Train Epoch: 4 [12000/14118 (85%)]\tLoss: 0.324689\n",
      "Train Epoch: 4 [13000/14118 (92%)]\tLoss: 0.297162\n",
      "Train Epoch: 4 [14000/14118 (99%)]\tLoss: 0.234594\n",
      "Train Epoch: 5 [0/14118 (0%)]\tLoss: 0.283281\n",
      "Train Epoch: 5 [1000/14118 (7%)]\tLoss: 0.257479\n",
      "Train Epoch: 5 [2000/14118 (14%)]\tLoss: 0.299214\n",
      "Train Epoch: 5 [3000/14118 (21%)]\tLoss: 0.364017\n",
      "Train Epoch: 5 [4000/14118 (28%)]\tLoss: 0.282581\n",
      "Train Epoch: 5 [5000/14118 (35%)]\tLoss: 0.428561\n",
      "Train Epoch: 5 [6000/14118 (42%)]\tLoss: 0.332157\n",
      "Train Epoch: 5 [7000/14118 (49%)]\tLoss: 0.325654\n",
      "Train Epoch: 5 [8000/14118 (56%)]\tLoss: 0.332237\n",
      "Train Epoch: 5 [9000/14118 (63%)]\tLoss: 0.260309\n",
      "Train Epoch: 5 [10000/14118 (70%)]\tLoss: 0.360341\n",
      "Train Epoch: 5 [11000/14118 (77%)]\tLoss: 0.249087\n",
      "Train Epoch: 5 [12000/14118 (85%)]\tLoss: 0.180130\n",
      "Train Epoch: 5 [13000/14118 (92%)]\tLoss: 0.224736\n",
      "Train Epoch: 5 [14000/14118 (99%)]\tLoss: 0.253617\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/9414 (0%)]\tLoss: 0.433421\n",
      "Train Epoch: 1 [1000/9414 (11%)]\tLoss: 0.413480\n",
      "Train Epoch: 1 [2000/9414 (21%)]\tLoss: 0.305105\n",
      "Train Epoch: 1 [3000/9414 (32%)]\tLoss: 0.412806\n",
      "Train Epoch: 1 [4000/9414 (42%)]\tLoss: 0.520344\n",
      "Train Epoch: 1 [5000/9414 (53%)]\tLoss: 0.388816\n",
      "Train Epoch: 1 [6000/9414 (63%)]\tLoss: 0.296521\n",
      "Train Epoch: 1 [7000/9414 (74%)]\tLoss: 0.474285\n",
      "Train Epoch: 1 [8000/9414 (84%)]\tLoss: 0.333455\n",
      "Train Epoch: 1 [9000/9414 (95%)]\tLoss: 0.316701\n",
      "Train Epoch: 2 [0/9414 (0%)]\tLoss: 0.453011\n",
      "Train Epoch: 2 [1000/9414 (11%)]\tLoss: 0.279332\n",
      "Train Epoch: 2 [2000/9414 (21%)]\tLoss: 0.312117\n",
      "Train Epoch: 2 [3000/9414 (32%)]\tLoss: 0.492850\n",
      "Train Epoch: 2 [4000/9414 (42%)]\tLoss: 0.326805\n",
      "Train Epoch: 2 [5000/9414 (53%)]\tLoss: 0.397153\n",
      "Train Epoch: 2 [6000/9414 (63%)]\tLoss: 0.394335\n",
      "Train Epoch: 2 [7000/9414 (74%)]\tLoss: 0.270618\n",
      "Train Epoch: 2 [8000/9414 (84%)]\tLoss: 0.437044\n",
      "Train Epoch: 2 [9000/9414 (95%)]\tLoss: 0.401945\n",
      "Train Epoch: 3 [0/9414 (0%)]\tLoss: 0.391295\n",
      "Train Epoch: 3 [1000/9414 (11%)]\tLoss: 0.307151\n",
      "Train Epoch: 3 [2000/9414 (21%)]\tLoss: 0.321984\n",
      "Train Epoch: 3 [3000/9414 (32%)]\tLoss: 0.472492\n",
      "Train Epoch: 3 [4000/9414 (42%)]\tLoss: 0.518430\n",
      "Train Epoch: 3 [5000/9414 (53%)]\tLoss: 0.458159\n",
      "Train Epoch: 3 [6000/9414 (63%)]\tLoss: 0.298514\n",
      "Train Epoch: 3 [7000/9414 (74%)]\tLoss: 0.526239\n",
      "Train Epoch: 3 [8000/9414 (84%)]\tLoss: 0.389615\n",
      "Train Epoch: 3 [9000/9414 (95%)]\tLoss: 0.303956\n",
      "Train Epoch: 4 [0/9414 (0%)]\tLoss: 0.380236\n",
      "Train Epoch: 4 [1000/9414 (11%)]\tLoss: 0.556240\n",
      "Train Epoch: 4 [2000/9414 (21%)]\tLoss: 0.345354\n",
      "Train Epoch: 4 [3000/9414 (32%)]\tLoss: 0.266454\n",
      "Train Epoch: 4 [4000/9414 (42%)]\tLoss: 0.333624\n",
      "Train Epoch: 4 [5000/9414 (53%)]\tLoss: 0.360620\n",
      "Train Epoch: 4 [6000/9414 (63%)]\tLoss: 0.319416\n",
      "Train Epoch: 4 [7000/9414 (74%)]\tLoss: 0.341769\n",
      "Train Epoch: 4 [8000/9414 (84%)]\tLoss: 0.383100\n",
      "Train Epoch: 4 [9000/9414 (95%)]\tLoss: 0.439944\n",
      "Train Epoch: 5 [0/9414 (0%)]\tLoss: 0.250671\n",
      "Train Epoch: 5 [1000/9414 (11%)]\tLoss: 0.233554\n",
      "Train Epoch: 5 [2000/9414 (21%)]\tLoss: 0.350156\n",
      "Train Epoch: 5 [3000/9414 (32%)]\tLoss: 0.242760\n",
      "Train Epoch: 5 [4000/9414 (42%)]\tLoss: 0.420422\n",
      "Train Epoch: 5 [5000/9414 (53%)]\tLoss: 0.414096\n",
      "Train Epoch: 5 [6000/9414 (63%)]\tLoss: 0.417958\n",
      "Train Epoch: 5 [7000/9414 (74%)]\tLoss: 0.337479\n",
      "Train Epoch: 5 [8000/9414 (84%)]\tLoss: 0.290015\n",
      "Train Epoch: 5 [9000/9414 (95%)]\tLoss: 0.335820\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "6\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.7741, Accuracy: 7767/10000 (78%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/8440 (0%)]\tLoss: 0.596170\n",
      "Train Epoch: 1 [1000/8440 (12%)]\tLoss: 0.373944\n",
      "Train Epoch: 1 [2000/8440 (24%)]\tLoss: 0.405344\n",
      "Train Epoch: 1 [3000/8440 (35%)]\tLoss: 0.318985\n",
      "Train Epoch: 1 [4000/8440 (47%)]\tLoss: 0.413863\n",
      "Train Epoch: 1 [5000/8440 (59%)]\tLoss: 0.551788\n",
      "Train Epoch: 1 [6000/8440 (71%)]\tLoss: 0.638987\n",
      "Train Epoch: 1 [7000/8440 (82%)]\tLoss: 0.403530\n",
      "Train Epoch: 1 [8000/8440 (94%)]\tLoss: 0.695011\n",
      "Train Epoch: 2 [0/8440 (0%)]\tLoss: 0.617149\n",
      "Train Epoch: 2 [1000/8440 (12%)]\tLoss: 0.363626\n",
      "Train Epoch: 2 [2000/8440 (24%)]\tLoss: 0.450835\n",
      "Train Epoch: 2 [3000/8440 (35%)]\tLoss: 0.309541\n",
      "Train Epoch: 2 [4000/8440 (47%)]\tLoss: 0.430287\n",
      "Train Epoch: 2 [5000/8440 (59%)]\tLoss: 0.502902\n",
      "Train Epoch: 2 [6000/8440 (71%)]\tLoss: 0.361117\n",
      "Train Epoch: 2 [7000/8440 (82%)]\tLoss: 0.336265\n",
      "Train Epoch: 2 [8000/8440 (94%)]\tLoss: 0.359854\n",
      "Train Epoch: 3 [0/8440 (0%)]\tLoss: 0.439177\n",
      "Train Epoch: 3 [1000/8440 (12%)]\tLoss: 0.432466\n",
      "Train Epoch: 3 [2000/8440 (24%)]\tLoss: 0.276659\n",
      "Train Epoch: 3 [3000/8440 (35%)]\tLoss: 0.394947\n",
      "Train Epoch: 3 [4000/8440 (47%)]\tLoss: 0.326790\n",
      "Train Epoch: 3 [5000/8440 (59%)]\tLoss: 0.495279\n",
      "Train Epoch: 3 [6000/8440 (71%)]\tLoss: 0.419324\n",
      "Train Epoch: 3 [7000/8440 (82%)]\tLoss: 0.379997\n",
      "Train Epoch: 3 [8000/8440 (94%)]\tLoss: 0.335936\n",
      "Train Epoch: 4 [0/8440 (0%)]\tLoss: 0.502666\n",
      "Train Epoch: 4 [1000/8440 (12%)]\tLoss: 0.396213\n",
      "Train Epoch: 4 [2000/8440 (24%)]\tLoss: 0.445688\n",
      "Train Epoch: 4 [3000/8440 (35%)]\tLoss: 0.406821\n",
      "Train Epoch: 4 [4000/8440 (47%)]\tLoss: 0.401297\n",
      "Train Epoch: 4 [5000/8440 (59%)]\tLoss: 0.386396\n",
      "Train Epoch: 4 [6000/8440 (71%)]\tLoss: 0.427139\n",
      "Train Epoch: 4 [7000/8440 (82%)]\tLoss: 0.461079\n",
      "Train Epoch: 4 [8000/8440 (94%)]\tLoss: 0.445831\n",
      "Train Epoch: 5 [0/8440 (0%)]\tLoss: 0.389003\n",
      "Train Epoch: 5 [1000/8440 (12%)]\tLoss: 0.288579\n",
      "Train Epoch: 5 [2000/8440 (24%)]\tLoss: 0.423769\n",
      "Train Epoch: 5 [3000/8440 (35%)]\tLoss: 0.383598\n",
      "Train Epoch: 5 [4000/8440 (47%)]\tLoss: 0.387441\n",
      "Train Epoch: 5 [5000/8440 (59%)]\tLoss: 0.385443\n",
      "Train Epoch: 5 [6000/8440 (71%)]\tLoss: 0.447187\n",
      "Train Epoch: 5 [7000/8440 (82%)]\tLoss: 0.317198\n",
      "Train Epoch: 5 [8000/8440 (94%)]\tLoss: 0.288896\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11811 (0%)]\tLoss: 0.371684\n",
      "Train Epoch: 1 [1000/11811 (8%)]\tLoss: 0.313552\n",
      "Train Epoch: 1 [2000/11811 (17%)]\tLoss: 0.162205\n",
      "Train Epoch: 1 [3000/11811 (25%)]\tLoss: 0.141277\n",
      "Train Epoch: 1 [4000/11811 (34%)]\tLoss: 0.221155\n",
      "Train Epoch: 1 [5000/11811 (42%)]\tLoss: 0.245687\n",
      "Train Epoch: 1 [6000/11811 (50%)]\tLoss: 0.281298\n",
      "Train Epoch: 1 [7000/11811 (59%)]\tLoss: 0.157722\n",
      "Train Epoch: 1 [8000/11811 (67%)]\tLoss: 0.360209\n",
      "Train Epoch: 1 [9000/11811 (76%)]\tLoss: 0.257049\n",
      "Train Epoch: 1 [10000/11811 (84%)]\tLoss: 0.189708\n",
      "Train Epoch: 1 [11000/11811 (92%)]\tLoss: 0.096964\n",
      "Train Epoch: 2 [0/11811 (0%)]\tLoss: 0.309926\n",
      "Train Epoch: 2 [1000/11811 (8%)]\tLoss: 0.198410\n",
      "Train Epoch: 2 [2000/11811 (17%)]\tLoss: 0.226310\n",
      "Train Epoch: 2 [3000/11811 (25%)]\tLoss: 0.128927\n",
      "Train Epoch: 2 [4000/11811 (34%)]\tLoss: 0.172605\n",
      "Train Epoch: 2 [5000/11811 (42%)]\tLoss: 0.149476\n",
      "Train Epoch: 2 [6000/11811 (50%)]\tLoss: 0.273743\n",
      "Train Epoch: 2 [7000/11811 (59%)]\tLoss: 0.289412\n",
      "Train Epoch: 2 [8000/11811 (67%)]\tLoss: 0.333799\n",
      "Train Epoch: 2 [9000/11811 (76%)]\tLoss: 0.131219\n",
      "Train Epoch: 2 [10000/11811 (84%)]\tLoss: 0.155814\n",
      "Train Epoch: 2 [11000/11811 (92%)]\tLoss: 0.343631\n",
      "Train Epoch: 3 [0/11811 (0%)]\tLoss: 0.103356\n",
      "Train Epoch: 3 [1000/11811 (8%)]\tLoss: 0.288056\n",
      "Train Epoch: 3 [2000/11811 (17%)]\tLoss: 0.266029\n",
      "Train Epoch: 3 [3000/11811 (25%)]\tLoss: 0.119527\n",
      "Train Epoch: 3 [4000/11811 (34%)]\tLoss: 0.321867\n",
      "Train Epoch: 3 [5000/11811 (42%)]\tLoss: 0.167182\n",
      "Train Epoch: 3 [6000/11811 (50%)]\tLoss: 0.226138\n",
      "Train Epoch: 3 [7000/11811 (59%)]\tLoss: 0.212126\n",
      "Train Epoch: 3 [8000/11811 (67%)]\tLoss: 0.251984\n",
      "Train Epoch: 3 [9000/11811 (76%)]\tLoss: 0.217372\n",
      "Train Epoch: 3 [10000/11811 (84%)]\tLoss: 0.153614\n",
      "Train Epoch: 3 [11000/11811 (92%)]\tLoss: 0.253500\n",
      "Train Epoch: 4 [0/11811 (0%)]\tLoss: 0.162326\n",
      "Train Epoch: 4 [1000/11811 (8%)]\tLoss: 0.267360\n",
      "Train Epoch: 4 [2000/11811 (17%)]\tLoss: 0.231329\n",
      "Train Epoch: 4 [3000/11811 (25%)]\tLoss: 0.182105\n",
      "Train Epoch: 4 [4000/11811 (34%)]\tLoss: 0.258325\n",
      "Train Epoch: 4 [5000/11811 (42%)]\tLoss: 0.188079\n",
      "Train Epoch: 4 [6000/11811 (50%)]\tLoss: 0.160039\n",
      "Train Epoch: 4 [7000/11811 (59%)]\tLoss: 0.188719\n",
      "Train Epoch: 4 [8000/11811 (67%)]\tLoss: 0.241213\n",
      "Train Epoch: 4 [9000/11811 (76%)]\tLoss: 0.276175\n",
      "Train Epoch: 4 [10000/11811 (84%)]\tLoss: 0.225833\n",
      "Train Epoch: 4 [11000/11811 (92%)]\tLoss: 0.153198\n",
      "Train Epoch: 5 [0/11811 (0%)]\tLoss: 0.223804\n",
      "Train Epoch: 5 [1000/11811 (8%)]\tLoss: 0.280432\n",
      "Train Epoch: 5 [2000/11811 (17%)]\tLoss: 0.217247\n",
      "Train Epoch: 5 [3000/11811 (25%)]\tLoss: 0.197216\n",
      "Train Epoch: 5 [4000/11811 (34%)]\tLoss: 0.154395\n",
      "Train Epoch: 5 [5000/11811 (42%)]\tLoss: 0.236953\n",
      "Train Epoch: 5 [6000/11811 (50%)]\tLoss: 0.188230\n",
      "Train Epoch: 5 [7000/11811 (59%)]\tLoss: 0.211295\n",
      "Train Epoch: 5 [8000/11811 (67%)]\tLoss: 0.231397\n",
      "Train Epoch: 5 [9000/11811 (76%)]\tLoss: 0.180348\n",
      "Train Epoch: 5 [10000/11811 (84%)]\tLoss: 0.145771\n",
      "Train Epoch: 5 [11000/11811 (92%)]\tLoss: 0.167985\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/9726 (0%)]\tLoss: 0.385312\n",
      "Train Epoch: 1 [1000/9726 (10%)]\tLoss: 0.341127\n",
      "Train Epoch: 1 [2000/9726 (20%)]\tLoss: 0.367333\n",
      "Train Epoch: 1 [3000/9726 (31%)]\tLoss: 0.324067\n",
      "Train Epoch: 1 [4000/9726 (41%)]\tLoss: 0.248140\n",
      "Train Epoch: 1 [5000/9726 (51%)]\tLoss: 0.295302\n",
      "Train Epoch: 1 [6000/9726 (61%)]\tLoss: 0.279787\n",
      "Train Epoch: 1 [7000/9726 (71%)]\tLoss: 0.332059\n",
      "Train Epoch: 1 [8000/9726 (82%)]\tLoss: 0.353330\n",
      "Train Epoch: 1 [9000/9726 (92%)]\tLoss: 0.363753\n",
      "Train Epoch: 2 [0/9726 (0%)]\tLoss: 0.478168\n",
      "Train Epoch: 2 [1000/9726 (10%)]\tLoss: 0.449586\n",
      "Train Epoch: 2 [2000/9726 (20%)]\tLoss: 0.319817\n",
      "Train Epoch: 2 [3000/9726 (31%)]\tLoss: 0.373930\n",
      "Train Epoch: 2 [4000/9726 (41%)]\tLoss: 0.218886\n",
      "Train Epoch: 2 [5000/9726 (51%)]\tLoss: 0.354064\n",
      "Train Epoch: 2 [6000/9726 (61%)]\tLoss: 0.366585\n",
      "Train Epoch: 2 [7000/9726 (71%)]\tLoss: 0.312865\n",
      "Train Epoch: 2 [8000/9726 (82%)]\tLoss: 0.389690\n",
      "Train Epoch: 2 [9000/9726 (92%)]\tLoss: 0.277750\n",
      "Train Epoch: 3 [0/9726 (0%)]\tLoss: 0.348492\n",
      "Train Epoch: 3 [1000/9726 (10%)]\tLoss: 0.331753\n",
      "Train Epoch: 3 [2000/9726 (20%)]\tLoss: 0.282904\n",
      "Train Epoch: 3 [3000/9726 (31%)]\tLoss: 0.381835\n",
      "Train Epoch: 3 [4000/9726 (41%)]\tLoss: 0.479172\n",
      "Train Epoch: 3 [5000/9726 (51%)]\tLoss: 0.304616\n",
      "Train Epoch: 3 [6000/9726 (61%)]\tLoss: 0.266020\n",
      "Train Epoch: 3 [7000/9726 (71%)]\tLoss: 0.234137\n",
      "Train Epoch: 3 [8000/9726 (82%)]\tLoss: 0.286538\n",
      "Train Epoch: 3 [9000/9726 (92%)]\tLoss: 0.379446\n",
      "Train Epoch: 4 [0/9726 (0%)]\tLoss: 0.286898\n",
      "Train Epoch: 4 [1000/9726 (10%)]\tLoss: 0.277945\n",
      "Train Epoch: 4 [2000/9726 (20%)]\tLoss: 0.413395\n",
      "Train Epoch: 4 [3000/9726 (31%)]\tLoss: 0.395712\n",
      "Train Epoch: 4 [4000/9726 (41%)]\tLoss: 0.298602\n",
      "Train Epoch: 4 [5000/9726 (51%)]\tLoss: 0.222303\n",
      "Train Epoch: 4 [6000/9726 (61%)]\tLoss: 0.260001\n",
      "Train Epoch: 4 [7000/9726 (71%)]\tLoss: 0.210103\n",
      "Train Epoch: 4 [8000/9726 (82%)]\tLoss: 0.320925\n",
      "Train Epoch: 4 [9000/9726 (92%)]\tLoss: 0.357588\n",
      "Train Epoch: 5 [0/9726 (0%)]\tLoss: 0.334123\n",
      "Train Epoch: 5 [1000/9726 (10%)]\tLoss: 0.254653\n",
      "Train Epoch: 5 [2000/9726 (20%)]\tLoss: 0.338347\n",
      "Train Epoch: 5 [3000/9726 (31%)]\tLoss: 0.442997\n",
      "Train Epoch: 5 [4000/9726 (41%)]\tLoss: 0.268761\n",
      "Train Epoch: 5 [5000/9726 (51%)]\tLoss: 0.258121\n",
      "Train Epoch: 5 [6000/9726 (61%)]\tLoss: 0.273254\n",
      "Train Epoch: 5 [7000/9726 (71%)]\tLoss: 0.332203\n",
      "Train Epoch: 5 [8000/9726 (82%)]\tLoss: 0.315238\n",
      "Train Epoch: 5 [9000/9726 (92%)]\tLoss: 0.214671\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/6491 (0%)]\tLoss: 0.698782\n",
      "Train Epoch: 1 [1000/6491 (15%)]\tLoss: 0.356782\n",
      "Train Epoch: 1 [2000/6491 (31%)]\tLoss: 0.465895\n",
      "Train Epoch: 1 [3000/6491 (46%)]\tLoss: 0.500944\n",
      "Train Epoch: 1 [4000/6491 (62%)]\tLoss: 0.551298\n",
      "Train Epoch: 1 [5000/6491 (77%)]\tLoss: 0.649873\n",
      "Train Epoch: 1 [6000/6491 (92%)]\tLoss: 0.488529\n",
      "Train Epoch: 2 [0/6491 (0%)]\tLoss: 0.481148\n",
      "Train Epoch: 2 [1000/6491 (15%)]\tLoss: 0.382073\n",
      "Train Epoch: 2 [2000/6491 (31%)]\tLoss: 0.430083\n",
      "Train Epoch: 2 [3000/6491 (46%)]\tLoss: 0.447615\n",
      "Train Epoch: 2 [4000/6491 (62%)]\tLoss: 0.607868\n",
      "Train Epoch: 2 [5000/6491 (77%)]\tLoss: 0.539332\n",
      "Train Epoch: 2 [6000/6491 (92%)]\tLoss: 0.287865\n",
      "Train Epoch: 3 [0/6491 (0%)]\tLoss: 0.490656\n",
      "Train Epoch: 3 [1000/6491 (15%)]\tLoss: 0.438937\n",
      "Train Epoch: 3 [2000/6491 (31%)]\tLoss: 0.344380\n",
      "Train Epoch: 3 [3000/6491 (46%)]\tLoss: 0.434281\n",
      "Train Epoch: 3 [4000/6491 (62%)]\tLoss: 0.576210\n",
      "Train Epoch: 3 [5000/6491 (77%)]\tLoss: 0.470366\n",
      "Train Epoch: 3 [6000/6491 (92%)]\tLoss: 0.506425\n",
      "Train Epoch: 4 [0/6491 (0%)]\tLoss: 0.459261\n",
      "Train Epoch: 4 [1000/6491 (15%)]\tLoss: 0.384698\n",
      "Train Epoch: 4 [2000/6491 (31%)]\tLoss: 0.482639\n",
      "Train Epoch: 4 [3000/6491 (46%)]\tLoss: 0.721824\n",
      "Train Epoch: 4 [4000/6491 (62%)]\tLoss: 0.460041\n",
      "Train Epoch: 4 [5000/6491 (77%)]\tLoss: 0.401628\n",
      "Train Epoch: 4 [6000/6491 (92%)]\tLoss: 0.421176\n",
      "Train Epoch: 5 [0/6491 (0%)]\tLoss: 0.454834\n",
      "Train Epoch: 5 [1000/6491 (15%)]\tLoss: 0.382373\n",
      "Train Epoch: 5 [2000/6491 (31%)]\tLoss: 0.491920\n",
      "Train Epoch: 5 [3000/6491 (46%)]\tLoss: 0.356336\n",
      "Train Epoch: 5 [4000/6491 (62%)]\tLoss: 0.428357\n",
      "Train Epoch: 5 [5000/6491 (77%)]\tLoss: 0.414505\n",
      "Train Epoch: 5 [6000/6491 (92%)]\tLoss: 0.320420\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/14118 (0%)]\tLoss: 0.360382\n",
      "Train Epoch: 1 [1000/14118 (7%)]\tLoss: 0.319749\n",
      "Train Epoch: 1 [2000/14118 (14%)]\tLoss: 0.401881\n",
      "Train Epoch: 1 [3000/14118 (21%)]\tLoss: 0.461491\n",
      "Train Epoch: 1 [4000/14118 (28%)]\tLoss: 0.263932\n",
      "Train Epoch: 1 [5000/14118 (35%)]\tLoss: 0.277775\n",
      "Train Epoch: 1 [6000/14118 (42%)]\tLoss: 0.325563\n",
      "Train Epoch: 1 [7000/14118 (49%)]\tLoss: 0.310730\n",
      "Train Epoch: 1 [8000/14118 (56%)]\tLoss: 0.364652\n",
      "Train Epoch: 1 [9000/14118 (63%)]\tLoss: 0.308741\n",
      "Train Epoch: 1 [10000/14118 (70%)]\tLoss: 0.417907\n",
      "Train Epoch: 1 [11000/14118 (77%)]\tLoss: 0.375992\n",
      "Train Epoch: 1 [12000/14118 (85%)]\tLoss: 0.376185\n",
      "Train Epoch: 1 [13000/14118 (92%)]\tLoss: 0.282103\n",
      "Train Epoch: 1 [14000/14118 (99%)]\tLoss: 0.352987\n",
      "Train Epoch: 2 [0/14118 (0%)]\tLoss: 0.363328\n",
      "Train Epoch: 2 [1000/14118 (7%)]\tLoss: 0.271270\n",
      "Train Epoch: 2 [2000/14118 (14%)]\tLoss: 0.301558\n",
      "Train Epoch: 2 [3000/14118 (21%)]\tLoss: 0.310073\n",
      "Train Epoch: 2 [4000/14118 (28%)]\tLoss: 0.238083\n",
      "Train Epoch: 2 [5000/14118 (35%)]\tLoss: 0.324510\n",
      "Train Epoch: 2 [6000/14118 (42%)]\tLoss: 0.293959\n",
      "Train Epoch: 2 [7000/14118 (49%)]\tLoss: 0.364026\n",
      "Train Epoch: 2 [8000/14118 (56%)]\tLoss: 0.375509\n",
      "Train Epoch: 2 [9000/14118 (63%)]\tLoss: 0.277140\n",
      "Train Epoch: 2 [10000/14118 (70%)]\tLoss: 0.343094\n",
      "Train Epoch: 2 [11000/14118 (77%)]\tLoss: 0.391977\n",
      "Train Epoch: 2 [12000/14118 (85%)]\tLoss: 0.202185\n",
      "Train Epoch: 2 [13000/14118 (92%)]\tLoss: 0.248886\n",
      "Train Epoch: 2 [14000/14118 (99%)]\tLoss: 0.343430\n",
      "Train Epoch: 3 [0/14118 (0%)]\tLoss: 0.242550\n",
      "Train Epoch: 3 [1000/14118 (7%)]\tLoss: 0.325456\n",
      "Train Epoch: 3 [2000/14118 (14%)]\tLoss: 0.226909\n",
      "Train Epoch: 3 [3000/14118 (21%)]\tLoss: 0.240535\n",
      "Train Epoch: 3 [4000/14118 (28%)]\tLoss: 0.345232\n",
      "Train Epoch: 3 [5000/14118 (35%)]\tLoss: 0.335336\n",
      "Train Epoch: 3 [6000/14118 (42%)]\tLoss: 0.351646\n",
      "Train Epoch: 3 [7000/14118 (49%)]\tLoss: 0.274990\n",
      "Train Epoch: 3 [8000/14118 (56%)]\tLoss: 0.392502\n",
      "Train Epoch: 3 [9000/14118 (63%)]\tLoss: 0.489688\n",
      "Train Epoch: 3 [10000/14118 (70%)]\tLoss: 0.321926\n",
      "Train Epoch: 3 [11000/14118 (77%)]\tLoss: 0.300987\n",
      "Train Epoch: 3 [12000/14118 (85%)]\tLoss: 0.361660\n",
      "Train Epoch: 3 [13000/14118 (92%)]\tLoss: 0.243546\n",
      "Train Epoch: 3 [14000/14118 (99%)]\tLoss: 0.414883\n",
      "Train Epoch: 4 [0/14118 (0%)]\tLoss: 0.315821\n",
      "Train Epoch: 4 [1000/14118 (7%)]\tLoss: 0.339954\n",
      "Train Epoch: 4 [2000/14118 (14%)]\tLoss: 0.348602\n",
      "Train Epoch: 4 [3000/14118 (21%)]\tLoss: 0.298933\n",
      "Train Epoch: 4 [4000/14118 (28%)]\tLoss: 0.386947\n",
      "Train Epoch: 4 [5000/14118 (35%)]\tLoss: 0.247319\n",
      "Train Epoch: 4 [6000/14118 (42%)]\tLoss: 0.351995\n",
      "Train Epoch: 4 [7000/14118 (49%)]\tLoss: 0.336596\n",
      "Train Epoch: 4 [8000/14118 (56%)]\tLoss: 0.275150\n",
      "Train Epoch: 4 [9000/14118 (63%)]\tLoss: 0.282974\n",
      "Train Epoch: 4 [10000/14118 (70%)]\tLoss: 0.387500\n",
      "Train Epoch: 4 [11000/14118 (77%)]\tLoss: 0.326520\n",
      "Train Epoch: 4 [12000/14118 (85%)]\tLoss: 0.340615\n",
      "Train Epoch: 4 [13000/14118 (92%)]\tLoss: 0.270768\n",
      "Train Epoch: 4 [14000/14118 (99%)]\tLoss: 0.330437\n",
      "Train Epoch: 5 [0/14118 (0%)]\tLoss: 0.269268\n",
      "Train Epoch: 5 [1000/14118 (7%)]\tLoss: 0.153149\n",
      "Train Epoch: 5 [2000/14118 (14%)]\tLoss: 0.308410\n",
      "Train Epoch: 5 [3000/14118 (21%)]\tLoss: 0.399614\n",
      "Train Epoch: 5 [4000/14118 (28%)]\tLoss: 0.344827\n",
      "Train Epoch: 5 [5000/14118 (35%)]\tLoss: 0.316848\n",
      "Train Epoch: 5 [6000/14118 (42%)]\tLoss: 0.415823\n",
      "Train Epoch: 5 [7000/14118 (49%)]\tLoss: 0.242956\n",
      "Train Epoch: 5 [8000/14118 (56%)]\tLoss: 0.359288\n",
      "Train Epoch: 5 [9000/14118 (63%)]\tLoss: 0.193965\n",
      "Train Epoch: 5 [10000/14118 (70%)]\tLoss: 0.403622\n",
      "Train Epoch: 5 [11000/14118 (77%)]\tLoss: 0.372383\n",
      "Train Epoch: 5 [12000/14118 (85%)]\tLoss: 0.356218\n",
      "Train Epoch: 5 [13000/14118 (92%)]\tLoss: 0.259577\n",
      "Train Epoch: 5 [14000/14118 (99%)]\tLoss: 0.245353\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/9414 (0%)]\tLoss: 0.513557\n",
      "Train Epoch: 1 [1000/9414 (11%)]\tLoss: 0.282971\n",
      "Train Epoch: 1 [2000/9414 (21%)]\tLoss: 0.287402\n",
      "Train Epoch: 1 [3000/9414 (32%)]\tLoss: 0.463507\n",
      "Train Epoch: 1 [4000/9414 (42%)]\tLoss: 0.492959\n",
      "Train Epoch: 1 [5000/9414 (53%)]\tLoss: 0.337927\n",
      "Train Epoch: 1 [6000/9414 (63%)]\tLoss: 0.402536\n",
      "Train Epoch: 1 [7000/9414 (74%)]\tLoss: 0.386053\n",
      "Train Epoch: 1 [8000/9414 (84%)]\tLoss: 0.478711\n",
      "Train Epoch: 1 [9000/9414 (95%)]\tLoss: 0.338660\n",
      "Train Epoch: 2 [0/9414 (0%)]\tLoss: 0.340106\n",
      "Train Epoch: 2 [1000/9414 (11%)]\tLoss: 0.455160\n",
      "Train Epoch: 2 [2000/9414 (21%)]\tLoss: 0.344419\n",
      "Train Epoch: 2 [3000/9414 (32%)]\tLoss: 0.337807\n",
      "Train Epoch: 2 [4000/9414 (42%)]\tLoss: 0.253809\n",
      "Train Epoch: 2 [5000/9414 (53%)]\tLoss: 0.347183\n",
      "Train Epoch: 2 [6000/9414 (63%)]\tLoss: 0.375160\n",
      "Train Epoch: 2 [7000/9414 (74%)]\tLoss: 0.353462\n",
      "Train Epoch: 2 [8000/9414 (84%)]\tLoss: 0.302582\n",
      "Train Epoch: 2 [9000/9414 (95%)]\tLoss: 0.278521\n",
      "Train Epoch: 3 [0/9414 (0%)]\tLoss: 0.418603\n",
      "Train Epoch: 3 [1000/9414 (11%)]\tLoss: 0.497162\n",
      "Train Epoch: 3 [2000/9414 (21%)]\tLoss: 0.373558\n",
      "Train Epoch: 3 [3000/9414 (32%)]\tLoss: 0.367612\n",
      "Train Epoch: 3 [4000/9414 (42%)]\tLoss: 0.444839\n",
      "Train Epoch: 3 [5000/9414 (53%)]\tLoss: 0.401090\n",
      "Train Epoch: 3 [6000/9414 (63%)]\tLoss: 0.399547\n",
      "Train Epoch: 3 [7000/9414 (74%)]\tLoss: 0.387876\n",
      "Train Epoch: 3 [8000/9414 (84%)]\tLoss: 0.459058\n",
      "Train Epoch: 3 [9000/9414 (95%)]\tLoss: 0.294447\n",
      "Train Epoch: 4 [0/9414 (0%)]\tLoss: 0.321456\n",
      "Train Epoch: 4 [1000/9414 (11%)]\tLoss: 0.270882\n",
      "Train Epoch: 4 [2000/9414 (21%)]\tLoss: 0.423948\n",
      "Train Epoch: 4 [3000/9414 (32%)]\tLoss: 0.285992\n",
      "Train Epoch: 4 [4000/9414 (42%)]\tLoss: 0.342919\n",
      "Train Epoch: 4 [5000/9414 (53%)]\tLoss: 0.508475\n",
      "Train Epoch: 4 [6000/9414 (63%)]\tLoss: 0.362571\n",
      "Train Epoch: 4 [7000/9414 (74%)]\tLoss: 0.359066\n",
      "Train Epoch: 4 [8000/9414 (84%)]\tLoss: 0.260748\n",
      "Train Epoch: 4 [9000/9414 (95%)]\tLoss: 0.364643\n",
      "Train Epoch: 5 [0/9414 (0%)]\tLoss: 0.303687\n",
      "Train Epoch: 5 [1000/9414 (11%)]\tLoss: 0.411830\n",
      "Train Epoch: 5 [2000/9414 (21%)]\tLoss: 0.332340\n",
      "Train Epoch: 5 [3000/9414 (32%)]\tLoss: 0.411219\n",
      "Train Epoch: 5 [4000/9414 (42%)]\tLoss: 0.382912\n",
      "Train Epoch: 5 [5000/9414 (53%)]\tLoss: 0.215259\n",
      "Train Epoch: 5 [6000/9414 (63%)]\tLoss: 0.365508\n",
      "Train Epoch: 5 [7000/9414 (74%)]\tLoss: 0.429170\n",
      "Train Epoch: 5 [8000/9414 (84%)]\tLoss: 0.436072\n",
      "Train Epoch: 5 [9000/9414 (95%)]\tLoss: 0.362723\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "6\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.7824, Accuracy: 7780/10000 (78%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/8440 (0%)]\tLoss: 0.449249\n",
      "Train Epoch: 1 [1000/8440 (12%)]\tLoss: 0.451193\n",
      "Train Epoch: 1 [2000/8440 (24%)]\tLoss: 0.309681\n",
      "Train Epoch: 1 [3000/8440 (35%)]\tLoss: 0.310859\n",
      "Train Epoch: 1 [4000/8440 (47%)]\tLoss: 0.482147\n",
      "Train Epoch: 1 [5000/8440 (59%)]\tLoss: 0.388924\n",
      "Train Epoch: 1 [6000/8440 (71%)]\tLoss: 0.426859\n",
      "Train Epoch: 1 [7000/8440 (82%)]\tLoss: 0.507092\n",
      "Train Epoch: 1 [8000/8440 (94%)]\tLoss: 0.460334\n",
      "Train Epoch: 2 [0/8440 (0%)]\tLoss: 0.454483\n",
      "Train Epoch: 2 [1000/8440 (12%)]\tLoss: 0.424966\n",
      "Train Epoch: 2 [2000/8440 (24%)]\tLoss: 0.335696\n",
      "Train Epoch: 2 [3000/8440 (35%)]\tLoss: 0.388226\n",
      "Train Epoch: 2 [4000/8440 (47%)]\tLoss: 0.394235\n",
      "Train Epoch: 2 [5000/8440 (59%)]\tLoss: 0.390387\n",
      "Train Epoch: 2 [6000/8440 (71%)]\tLoss: 0.377502\n",
      "Train Epoch: 2 [7000/8440 (82%)]\tLoss: 0.314611\n",
      "Train Epoch: 2 [8000/8440 (94%)]\tLoss: 0.510318\n",
      "Train Epoch: 3 [0/8440 (0%)]\tLoss: 0.403061\n",
      "Train Epoch: 3 [1000/8440 (12%)]\tLoss: 0.281948\n",
      "Train Epoch: 3 [2000/8440 (24%)]\tLoss: 0.518924\n",
      "Train Epoch: 3 [3000/8440 (35%)]\tLoss: 0.446120\n",
      "Train Epoch: 3 [4000/8440 (47%)]\tLoss: 0.567916\n",
      "Train Epoch: 3 [5000/8440 (59%)]\tLoss: 0.305477\n",
      "Train Epoch: 3 [6000/8440 (71%)]\tLoss: 0.382628\n",
      "Train Epoch: 3 [7000/8440 (82%)]\tLoss: 0.497192\n",
      "Train Epoch: 3 [8000/8440 (94%)]\tLoss: 0.241787\n",
      "Train Epoch: 4 [0/8440 (0%)]\tLoss: 0.327036\n",
      "Train Epoch: 4 [1000/8440 (12%)]\tLoss: 0.377125\n",
      "Train Epoch: 4 [2000/8440 (24%)]\tLoss: 0.257762\n",
      "Train Epoch: 4 [3000/8440 (35%)]\tLoss: 0.399048\n",
      "Train Epoch: 4 [4000/8440 (47%)]\tLoss: 0.456905\n",
      "Train Epoch: 4 [5000/8440 (59%)]\tLoss: 0.424265\n",
      "Train Epoch: 4 [6000/8440 (71%)]\tLoss: 0.383817\n",
      "Train Epoch: 4 [7000/8440 (82%)]\tLoss: 0.374553\n",
      "Train Epoch: 4 [8000/8440 (94%)]\tLoss: 0.414496\n",
      "Train Epoch: 5 [0/8440 (0%)]\tLoss: 0.270667\n",
      "Train Epoch: 5 [1000/8440 (12%)]\tLoss: 0.319923\n",
      "Train Epoch: 5 [2000/8440 (24%)]\tLoss: 0.366455\n",
      "Train Epoch: 5 [3000/8440 (35%)]\tLoss: 0.407062\n",
      "Train Epoch: 5 [4000/8440 (47%)]\tLoss: 0.335235\n",
      "Train Epoch: 5 [5000/8440 (59%)]\tLoss: 0.362600\n",
      "Train Epoch: 5 [6000/8440 (71%)]\tLoss: 0.380870\n",
      "Train Epoch: 5 [7000/8440 (82%)]\tLoss: 0.232922\n",
      "Train Epoch: 5 [8000/8440 (94%)]\tLoss: 0.600851\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11811 (0%)]\tLoss: 0.441694\n",
      "Train Epoch: 1 [1000/11811 (8%)]\tLoss: 0.227096\n",
      "Train Epoch: 1 [2000/11811 (17%)]\tLoss: 0.290496\n",
      "Train Epoch: 1 [3000/11811 (25%)]\tLoss: 0.331084\n",
      "Train Epoch: 1 [4000/11811 (34%)]\tLoss: 0.246882\n",
      "Train Epoch: 1 [5000/11811 (42%)]\tLoss: 0.152615\n",
      "Train Epoch: 1 [6000/11811 (50%)]\tLoss: 0.351637\n",
      "Train Epoch: 1 [7000/11811 (59%)]\tLoss: 0.203246\n",
      "Train Epoch: 1 [8000/11811 (67%)]\tLoss: 0.213969\n",
      "Train Epoch: 1 [9000/11811 (76%)]\tLoss: 0.168662\n",
      "Train Epoch: 1 [10000/11811 (84%)]\tLoss: 0.211978\n",
      "Train Epoch: 1 [11000/11811 (92%)]\tLoss: 0.163317\n",
      "Train Epoch: 2 [0/11811 (0%)]\tLoss: 0.285847\n",
      "Train Epoch: 2 [1000/11811 (8%)]\tLoss: 0.145304\n",
      "Train Epoch: 2 [2000/11811 (17%)]\tLoss: 0.260866\n",
      "Train Epoch: 2 [3000/11811 (25%)]\tLoss: 0.162182\n",
      "Train Epoch: 2 [4000/11811 (34%)]\tLoss: 0.215521\n",
      "Train Epoch: 2 [5000/11811 (42%)]\tLoss: 0.174413\n",
      "Train Epoch: 2 [6000/11811 (50%)]\tLoss: 0.206078\n",
      "Train Epoch: 2 [7000/11811 (59%)]\tLoss: 0.160672\n",
      "Train Epoch: 2 [8000/11811 (67%)]\tLoss: 0.200873\n",
      "Train Epoch: 2 [9000/11811 (76%)]\tLoss: 0.205109\n",
      "Train Epoch: 2 [10000/11811 (84%)]\tLoss: 0.245099\n",
      "Train Epoch: 2 [11000/11811 (92%)]\tLoss: 0.145580\n",
      "Train Epoch: 3 [0/11811 (0%)]\tLoss: 0.209356\n",
      "Train Epoch: 3 [1000/11811 (8%)]\tLoss: 0.141096\n",
      "Train Epoch: 3 [2000/11811 (17%)]\tLoss: 0.207783\n",
      "Train Epoch: 3 [3000/11811 (25%)]\tLoss: 0.323429\n",
      "Train Epoch: 3 [4000/11811 (34%)]\tLoss: 0.486619\n",
      "Train Epoch: 3 [5000/11811 (42%)]\tLoss: 0.276504\n",
      "Train Epoch: 3 [6000/11811 (50%)]\tLoss: 0.258352\n",
      "Train Epoch: 3 [7000/11811 (59%)]\tLoss: 0.159135\n",
      "Train Epoch: 3 [8000/11811 (67%)]\tLoss: 0.239519\n",
      "Train Epoch: 3 [9000/11811 (76%)]\tLoss: 0.131088\n",
      "Train Epoch: 3 [10000/11811 (84%)]\tLoss: 0.274239\n",
      "Train Epoch: 3 [11000/11811 (92%)]\tLoss: 0.189266\n",
      "Train Epoch: 4 [0/11811 (0%)]\tLoss: 0.147554\n",
      "Train Epoch: 4 [1000/11811 (8%)]\tLoss: 0.131297\n",
      "Train Epoch: 4 [2000/11811 (17%)]\tLoss: 0.172165\n",
      "Train Epoch: 4 [3000/11811 (25%)]\tLoss: 0.227174\n",
      "Train Epoch: 4 [4000/11811 (34%)]\tLoss: 0.217993\n",
      "Train Epoch: 4 [5000/11811 (42%)]\tLoss: 0.307283\n",
      "Train Epoch: 4 [6000/11811 (50%)]\tLoss: 0.236064\n",
      "Train Epoch: 4 [7000/11811 (59%)]\tLoss: 0.199557\n",
      "Train Epoch: 4 [8000/11811 (67%)]\tLoss: 0.173264\n",
      "Train Epoch: 4 [9000/11811 (76%)]\tLoss: 0.351929\n",
      "Train Epoch: 4 [10000/11811 (84%)]\tLoss: 0.209276\n",
      "Train Epoch: 4 [11000/11811 (92%)]\tLoss: 0.227995\n",
      "Train Epoch: 5 [0/11811 (0%)]\tLoss: 0.234348\n",
      "Train Epoch: 5 [1000/11811 (8%)]\tLoss: 0.237046\n",
      "Train Epoch: 5 [2000/11811 (17%)]\tLoss: 0.119200\n",
      "Train Epoch: 5 [3000/11811 (25%)]\tLoss: 0.218840\n",
      "Train Epoch: 5 [4000/11811 (34%)]\tLoss: 0.203353\n",
      "Train Epoch: 5 [5000/11811 (42%)]\tLoss: 0.195145\n",
      "Train Epoch: 5 [6000/11811 (50%)]\tLoss: 0.195336\n",
      "Train Epoch: 5 [7000/11811 (59%)]\tLoss: 0.279497\n",
      "Train Epoch: 5 [8000/11811 (67%)]\tLoss: 0.302312\n",
      "Train Epoch: 5 [9000/11811 (76%)]\tLoss: 0.278083\n",
      "Train Epoch: 5 [10000/11811 (84%)]\tLoss: 0.115186\n",
      "Train Epoch: 5 [11000/11811 (92%)]\tLoss: 0.163157\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/9726 (0%)]\tLoss: 0.277881\n",
      "Train Epoch: 1 [1000/9726 (10%)]\tLoss: 0.458074\n",
      "Train Epoch: 1 [2000/9726 (20%)]\tLoss: 0.382330\n",
      "Train Epoch: 1 [3000/9726 (31%)]\tLoss: 0.302035\n",
      "Train Epoch: 1 [4000/9726 (41%)]\tLoss: 0.339175\n",
      "Train Epoch: 1 [5000/9726 (51%)]\tLoss: 0.407641\n",
      "Train Epoch: 1 [6000/9726 (61%)]\tLoss: 0.272682\n",
      "Train Epoch: 1 [7000/9726 (71%)]\tLoss: 0.368678\n",
      "Train Epoch: 1 [8000/9726 (82%)]\tLoss: 0.348375\n",
      "Train Epoch: 1 [9000/9726 (92%)]\tLoss: 0.320347\n",
      "Train Epoch: 2 [0/9726 (0%)]\tLoss: 0.329727\n",
      "Train Epoch: 2 [1000/9726 (10%)]\tLoss: 0.501603\n",
      "Train Epoch: 2 [2000/9726 (20%)]\tLoss: 0.404355\n",
      "Train Epoch: 2 [3000/9726 (31%)]\tLoss: 0.338222\n",
      "Train Epoch: 2 [4000/9726 (41%)]\tLoss: 0.230965\n",
      "Train Epoch: 2 [5000/9726 (51%)]\tLoss: 0.263540\n",
      "Train Epoch: 2 [6000/9726 (61%)]\tLoss: 0.299375\n",
      "Train Epoch: 2 [7000/9726 (71%)]\tLoss: 0.455120\n",
      "Train Epoch: 2 [8000/9726 (82%)]\tLoss: 0.245623\n",
      "Train Epoch: 2 [9000/9726 (92%)]\tLoss: 0.366254\n",
      "Train Epoch: 3 [0/9726 (0%)]\tLoss: 0.254829\n",
      "Train Epoch: 3 [1000/9726 (10%)]\tLoss: 0.281866\n",
      "Train Epoch: 3 [2000/9726 (20%)]\tLoss: 0.434074\n",
      "Train Epoch: 3 [3000/9726 (31%)]\tLoss: 0.422236\n",
      "Train Epoch: 3 [4000/9726 (41%)]\tLoss: 0.263503\n",
      "Train Epoch: 3 [5000/9726 (51%)]\tLoss: 0.195646\n",
      "Train Epoch: 3 [6000/9726 (61%)]\tLoss: 0.283899\n",
      "Train Epoch: 3 [7000/9726 (71%)]\tLoss: 0.284658\n",
      "Train Epoch: 3 [8000/9726 (82%)]\tLoss: 0.322204\n",
      "Train Epoch: 3 [9000/9726 (92%)]\tLoss: 0.279434\n",
      "Train Epoch: 4 [0/9726 (0%)]\tLoss: 0.297330\n",
      "Train Epoch: 4 [1000/9726 (10%)]\tLoss: 0.254296\n",
      "Train Epoch: 4 [2000/9726 (20%)]\tLoss: 0.421141\n",
      "Train Epoch: 4 [3000/9726 (31%)]\tLoss: 0.389709\n",
      "Train Epoch: 4 [4000/9726 (41%)]\tLoss: 0.378637\n",
      "Train Epoch: 4 [5000/9726 (51%)]\tLoss: 0.352977\n",
      "Train Epoch: 4 [6000/9726 (61%)]\tLoss: 0.234569\n",
      "Train Epoch: 4 [7000/9726 (71%)]\tLoss: 0.303180\n",
      "Train Epoch: 4 [8000/9726 (82%)]\tLoss: 0.425639\n",
      "Train Epoch: 4 [9000/9726 (92%)]\tLoss: 0.333511\n",
      "Train Epoch: 5 [0/9726 (0%)]\tLoss: 0.462602\n",
      "Train Epoch: 5 [1000/9726 (10%)]\tLoss: 0.363683\n",
      "Train Epoch: 5 [2000/9726 (20%)]\tLoss: 0.292133\n",
      "Train Epoch: 5 [3000/9726 (31%)]\tLoss: 0.448838\n",
      "Train Epoch: 5 [4000/9726 (41%)]\tLoss: 0.259012\n",
      "Train Epoch: 5 [5000/9726 (51%)]\tLoss: 0.203674\n",
      "Train Epoch: 5 [6000/9726 (61%)]\tLoss: 0.247165\n",
      "Train Epoch: 5 [7000/9726 (71%)]\tLoss: 0.232737\n",
      "Train Epoch: 5 [8000/9726 (82%)]\tLoss: 0.314509\n",
      "Train Epoch: 5 [9000/9726 (92%)]\tLoss: 0.335628\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/6491 (0%)]\tLoss: 0.624510\n",
      "Train Epoch: 1 [1000/6491 (15%)]\tLoss: 0.447993\n",
      "Train Epoch: 1 [2000/6491 (31%)]\tLoss: 0.464719\n",
      "Train Epoch: 1 [3000/6491 (46%)]\tLoss: 0.437753\n",
      "Train Epoch: 1 [4000/6491 (62%)]\tLoss: 0.544515\n",
      "Train Epoch: 1 [5000/6491 (77%)]\tLoss: 0.321484\n",
      "Train Epoch: 1 [6000/6491 (92%)]\tLoss: 0.501270\n",
      "Train Epoch: 2 [0/6491 (0%)]\tLoss: 0.359038\n",
      "Train Epoch: 2 [1000/6491 (15%)]\tLoss: 0.457187\n",
      "Train Epoch: 2 [2000/6491 (31%)]\tLoss: 0.372740\n",
      "Train Epoch: 2 [3000/6491 (46%)]\tLoss: 0.492496\n",
      "Train Epoch: 2 [4000/6491 (62%)]\tLoss: 0.552787\n",
      "Train Epoch: 2 [5000/6491 (77%)]\tLoss: 0.392734\n",
      "Train Epoch: 2 [6000/6491 (92%)]\tLoss: 0.395303\n",
      "Train Epoch: 3 [0/6491 (0%)]\tLoss: 0.505776\n",
      "Train Epoch: 3 [1000/6491 (15%)]\tLoss: 0.382541\n",
      "Train Epoch: 3 [2000/6491 (31%)]\tLoss: 0.349522\n",
      "Train Epoch: 3 [3000/6491 (46%)]\tLoss: 0.334656\n",
      "Train Epoch: 3 [4000/6491 (62%)]\tLoss: 0.370936\n",
      "Train Epoch: 3 [5000/6491 (77%)]\tLoss: 0.357090\n",
      "Train Epoch: 3 [6000/6491 (92%)]\tLoss: 0.568958\n",
      "Train Epoch: 4 [0/6491 (0%)]\tLoss: 0.413168\n",
      "Train Epoch: 4 [1000/6491 (15%)]\tLoss: 0.389838\n",
      "Train Epoch: 4 [2000/6491 (31%)]\tLoss: 0.498149\n",
      "Train Epoch: 4 [3000/6491 (46%)]\tLoss: 0.544587\n",
      "Train Epoch: 4 [4000/6491 (62%)]\tLoss: 0.458447\n",
      "Train Epoch: 4 [5000/6491 (77%)]\tLoss: 0.571087\n",
      "Train Epoch: 4 [6000/6491 (92%)]\tLoss: 0.411198\n",
      "Train Epoch: 5 [0/6491 (0%)]\tLoss: 0.498794\n",
      "Train Epoch: 5 [1000/6491 (15%)]\tLoss: 0.330035\n",
      "Train Epoch: 5 [2000/6491 (31%)]\tLoss: 0.512062\n",
      "Train Epoch: 5 [3000/6491 (46%)]\tLoss: 0.420246\n",
      "Train Epoch: 5 [4000/6491 (62%)]\tLoss: 0.470138\n",
      "Train Epoch: 5 [5000/6491 (77%)]\tLoss: 0.376481\n",
      "Train Epoch: 5 [6000/6491 (92%)]\tLoss: 0.627246\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/14118 (0%)]\tLoss: 0.467059\n",
      "Train Epoch: 1 [1000/14118 (7%)]\tLoss: 0.455186\n",
      "Train Epoch: 1 [2000/14118 (14%)]\tLoss: 0.372229\n",
      "Train Epoch: 1 [3000/14118 (21%)]\tLoss: 0.309653\n",
      "Train Epoch: 1 [4000/14118 (28%)]\tLoss: 0.220245\n",
      "Train Epoch: 1 [5000/14118 (35%)]\tLoss: 0.351005\n",
      "Train Epoch: 1 [6000/14118 (42%)]\tLoss: 0.313894\n",
      "Train Epoch: 1 [7000/14118 (49%)]\tLoss: 0.428433\n",
      "Train Epoch: 1 [8000/14118 (56%)]\tLoss: 0.364364\n",
      "Train Epoch: 1 [9000/14118 (63%)]\tLoss: 0.202444\n",
      "Train Epoch: 1 [10000/14118 (70%)]\tLoss: 0.282489\n",
      "Train Epoch: 1 [11000/14118 (77%)]\tLoss: 0.438764\n",
      "Train Epoch: 1 [12000/14118 (85%)]\tLoss: 0.238996\n",
      "Train Epoch: 1 [13000/14118 (92%)]\tLoss: 0.429581\n",
      "Train Epoch: 1 [14000/14118 (99%)]\tLoss: 0.211551\n",
      "Train Epoch: 2 [0/14118 (0%)]\tLoss: 0.374114\n",
      "Train Epoch: 2 [1000/14118 (7%)]\tLoss: 0.307030\n",
      "Train Epoch: 2 [2000/14118 (14%)]\tLoss: 0.481654\n",
      "Train Epoch: 2 [3000/14118 (21%)]\tLoss: 0.296155\n",
      "Train Epoch: 2 [4000/14118 (28%)]\tLoss: 0.435451\n",
      "Train Epoch: 2 [5000/14118 (35%)]\tLoss: 0.421870\n",
      "Train Epoch: 2 [6000/14118 (42%)]\tLoss: 0.298400\n",
      "Train Epoch: 2 [7000/14118 (49%)]\tLoss: 0.341866\n",
      "Train Epoch: 2 [8000/14118 (56%)]\tLoss: 0.350931\n",
      "Train Epoch: 2 [9000/14118 (63%)]\tLoss: 0.311643\n",
      "Train Epoch: 2 [10000/14118 (70%)]\tLoss: 0.251429\n",
      "Train Epoch: 2 [11000/14118 (77%)]\tLoss: 0.237168\n",
      "Train Epoch: 2 [12000/14118 (85%)]\tLoss: 0.249048\n",
      "Train Epoch: 2 [13000/14118 (92%)]\tLoss: 0.392026\n",
      "Train Epoch: 2 [14000/14118 (99%)]\tLoss: 0.322220\n",
      "Train Epoch: 3 [0/14118 (0%)]\tLoss: 0.337432\n",
      "Train Epoch: 3 [1000/14118 (7%)]\tLoss: 0.327204\n",
      "Train Epoch: 3 [2000/14118 (14%)]\tLoss: 0.323602\n",
      "Train Epoch: 3 [3000/14118 (21%)]\tLoss: 0.334499\n",
      "Train Epoch: 3 [4000/14118 (28%)]\tLoss: 0.364727\n",
      "Train Epoch: 3 [5000/14118 (35%)]\tLoss: 0.405944\n",
      "Train Epoch: 3 [6000/14118 (42%)]\tLoss: 0.216595\n",
      "Train Epoch: 3 [7000/14118 (49%)]\tLoss: 0.260100\n",
      "Train Epoch: 3 [8000/14118 (56%)]\tLoss: 0.379963\n",
      "Train Epoch: 3 [9000/14118 (63%)]\tLoss: 0.307942\n",
      "Train Epoch: 3 [10000/14118 (70%)]\tLoss: 0.301399\n",
      "Train Epoch: 3 [11000/14118 (77%)]\tLoss: 0.311362\n",
      "Train Epoch: 3 [12000/14118 (85%)]\tLoss: 0.228195\n",
      "Train Epoch: 3 [13000/14118 (92%)]\tLoss: 0.266096\n",
      "Train Epoch: 3 [14000/14118 (99%)]\tLoss: 0.299678\n",
      "Train Epoch: 4 [0/14118 (0%)]\tLoss: 0.252897\n",
      "Train Epoch: 4 [1000/14118 (7%)]\tLoss: 0.318805\n",
      "Train Epoch: 4 [2000/14118 (14%)]\tLoss: 0.415475\n",
      "Train Epoch: 4 [3000/14118 (21%)]\tLoss: 0.275191\n",
      "Train Epoch: 4 [4000/14118 (28%)]\tLoss: 0.205502\n",
      "Train Epoch: 4 [5000/14118 (35%)]\tLoss: 0.379539\n",
      "Train Epoch: 4 [6000/14118 (42%)]\tLoss: 0.278865\n",
      "Train Epoch: 4 [7000/14118 (49%)]\tLoss: 0.326071\n",
      "Train Epoch: 4 [8000/14118 (56%)]\tLoss: 0.277106\n",
      "Train Epoch: 4 [9000/14118 (63%)]\tLoss: 0.258626\n",
      "Train Epoch: 4 [10000/14118 (70%)]\tLoss: 0.296946\n",
      "Train Epoch: 4 [11000/14118 (77%)]\tLoss: 0.372945\n",
      "Train Epoch: 4 [12000/14118 (85%)]\tLoss: 0.283968\n",
      "Train Epoch: 4 [13000/14118 (92%)]\tLoss: 0.223644\n",
      "Train Epoch: 4 [14000/14118 (99%)]\tLoss: 0.216090\n",
      "Train Epoch: 5 [0/14118 (0%)]\tLoss: 0.419024\n",
      "Train Epoch: 5 [1000/14118 (7%)]\tLoss: 0.350256\n",
      "Train Epoch: 5 [2000/14118 (14%)]\tLoss: 0.239759\n",
      "Train Epoch: 5 [3000/14118 (21%)]\tLoss: 0.318893\n",
      "Train Epoch: 5 [4000/14118 (28%)]\tLoss: 0.180551\n",
      "Train Epoch: 5 [5000/14118 (35%)]\tLoss: 0.360614\n",
      "Train Epoch: 5 [6000/14118 (42%)]\tLoss: 0.300739\n",
      "Train Epoch: 5 [7000/14118 (49%)]\tLoss: 0.292056\n",
      "Train Epoch: 5 [8000/14118 (56%)]\tLoss: 0.204008\n",
      "Train Epoch: 5 [9000/14118 (63%)]\tLoss: 0.235038\n",
      "Train Epoch: 5 [10000/14118 (70%)]\tLoss: 0.282556\n",
      "Train Epoch: 5 [11000/14118 (77%)]\tLoss: 0.291684\n",
      "Train Epoch: 5 [12000/14118 (85%)]\tLoss: 0.426740\n",
      "Train Epoch: 5 [13000/14118 (92%)]\tLoss: 0.295304\n",
      "Train Epoch: 5 [14000/14118 (99%)]\tLoss: 0.163317\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/9414 (0%)]\tLoss: 0.670757\n",
      "Train Epoch: 1 [1000/9414 (11%)]\tLoss: 0.304960\n",
      "Train Epoch: 1 [2000/9414 (21%)]\tLoss: 0.342835\n",
      "Train Epoch: 1 [3000/9414 (32%)]\tLoss: 0.394024\n",
      "Train Epoch: 1 [4000/9414 (42%)]\tLoss: 0.425549\n",
      "Train Epoch: 1 [5000/9414 (53%)]\tLoss: 0.325688\n",
      "Train Epoch: 1 [6000/9414 (63%)]\tLoss: 0.413232\n",
      "Train Epoch: 1 [7000/9414 (74%)]\tLoss: 0.321837\n",
      "Train Epoch: 1 [8000/9414 (84%)]\tLoss: 0.374286\n",
      "Train Epoch: 1 [9000/9414 (95%)]\tLoss: 0.437460\n",
      "Train Epoch: 2 [0/9414 (0%)]\tLoss: 0.251387\n",
      "Train Epoch: 2 [1000/9414 (11%)]\tLoss: 0.403319\n",
      "Train Epoch: 2 [2000/9414 (21%)]\tLoss: 0.279261\n",
      "Train Epoch: 2 [3000/9414 (32%)]\tLoss: 0.282204\n",
      "Train Epoch: 2 [4000/9414 (42%)]\tLoss: 0.409581\n",
      "Train Epoch: 2 [5000/9414 (53%)]\tLoss: 0.328860\n",
      "Train Epoch: 2 [6000/9414 (63%)]\tLoss: 0.412407\n",
      "Train Epoch: 2 [7000/9414 (74%)]\tLoss: 0.231053\n",
      "Train Epoch: 2 [8000/9414 (84%)]\tLoss: 0.284491\n",
      "Train Epoch: 2 [9000/9414 (95%)]\tLoss: 0.377828\n",
      "Train Epoch: 3 [0/9414 (0%)]\tLoss: 0.623185\n",
      "Train Epoch: 3 [1000/9414 (11%)]\tLoss: 0.336291\n",
      "Train Epoch: 3 [2000/9414 (21%)]\tLoss: 0.318320\n",
      "Train Epoch: 3 [3000/9414 (32%)]\tLoss: 0.397458\n",
      "Train Epoch: 3 [4000/9414 (42%)]\tLoss: 0.291012\n",
      "Train Epoch: 3 [5000/9414 (53%)]\tLoss: 0.420751\n",
      "Train Epoch: 3 [6000/9414 (63%)]\tLoss: 0.328103\n",
      "Train Epoch: 3 [7000/9414 (74%)]\tLoss: 0.329037\n",
      "Train Epoch: 3 [8000/9414 (84%)]\tLoss: 0.415250\n",
      "Train Epoch: 3 [9000/9414 (95%)]\tLoss: 0.339253\n",
      "Train Epoch: 4 [0/9414 (0%)]\tLoss: 0.398515\n",
      "Train Epoch: 4 [1000/9414 (11%)]\tLoss: 0.478154\n",
      "Train Epoch: 4 [2000/9414 (21%)]\tLoss: 0.364718\n",
      "Train Epoch: 4 [3000/9414 (32%)]\tLoss: 0.288175\n",
      "Train Epoch: 4 [4000/9414 (42%)]\tLoss: 0.349620\n",
      "Train Epoch: 4 [5000/9414 (53%)]\tLoss: 0.316320\n",
      "Train Epoch: 4 [6000/9414 (63%)]\tLoss: 0.331322\n",
      "Train Epoch: 4 [7000/9414 (74%)]\tLoss: 0.424572\n",
      "Train Epoch: 4 [8000/9414 (84%)]\tLoss: 0.442511\n",
      "Train Epoch: 4 [9000/9414 (95%)]\tLoss: 0.188425\n",
      "Train Epoch: 5 [0/9414 (0%)]\tLoss: 0.414610\n",
      "Train Epoch: 5 [1000/9414 (11%)]\tLoss: 0.450284\n",
      "Train Epoch: 5 [2000/9414 (21%)]\tLoss: 0.298152\n",
      "Train Epoch: 5 [3000/9414 (32%)]\tLoss: 0.410326\n",
      "Train Epoch: 5 [4000/9414 (42%)]\tLoss: 0.344833\n",
      "Train Epoch: 5 [5000/9414 (53%)]\tLoss: 0.381091\n",
      "Train Epoch: 5 [6000/9414 (63%)]\tLoss: 0.373988\n",
      "Train Epoch: 5 [7000/9414 (74%)]\tLoss: 0.383300\n",
      "Train Epoch: 5 [8000/9414 (84%)]\tLoss: 0.226611\n",
      "Train Epoch: 5 [9000/9414 (95%)]\tLoss: 0.361028\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "6\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.7986, Accuracy: 7726/10000 (77%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/17854 (0%)]\tLoss: 0.617901\n",
      "Train Epoch: 1 [1000/17854 (6%)]\tLoss: 0.391742\n",
      "Train Epoch: 1 [2000/17854 (11%)]\tLoss: 0.462764\n",
      "Train Epoch: 1 [3000/17854 (17%)]\tLoss: 0.299471\n",
      "Train Epoch: 1 [4000/17854 (22%)]\tLoss: 0.385972\n",
      "Train Epoch: 1 [5000/17854 (28%)]\tLoss: 0.341711\n",
      "Train Epoch: 1 [6000/17854 (34%)]\tLoss: 0.488460\n",
      "Train Epoch: 1 [7000/17854 (39%)]\tLoss: 0.372413\n",
      "Train Epoch: 1 [8000/17854 (45%)]\tLoss: 0.463722\n",
      "Train Epoch: 1 [9000/17854 (50%)]\tLoss: 0.513074\n",
      "Train Epoch: 1 [10000/17854 (56%)]\tLoss: 0.579581\n",
      "Train Epoch: 1 [11000/17854 (61%)]\tLoss: 0.326767\n",
      "Train Epoch: 1 [12000/17854 (67%)]\tLoss: 0.415791\n",
      "Train Epoch: 1 [13000/17854 (73%)]\tLoss: 0.233881\n",
      "Train Epoch: 1 [14000/17854 (78%)]\tLoss: 0.365633\n",
      "Train Epoch: 1 [15000/17854 (84%)]\tLoss: 0.528156\n",
      "Train Epoch: 1 [16000/17854 (89%)]\tLoss: 0.460644\n",
      "Train Epoch: 1 [17000/17854 (95%)]\tLoss: 0.417488\n",
      "Train Epoch: 2 [0/17854 (0%)]\tLoss: 0.544945\n",
      "Train Epoch: 2 [1000/17854 (6%)]\tLoss: 0.452718\n",
      "Train Epoch: 2 [2000/17854 (11%)]\tLoss: 0.559001\n",
      "Train Epoch: 2 [3000/17854 (17%)]\tLoss: 0.315639\n",
      "Train Epoch: 2 [4000/17854 (22%)]\tLoss: 0.460109\n",
      "Train Epoch: 2 [5000/17854 (28%)]\tLoss: 0.300278\n",
      "Train Epoch: 2 [6000/17854 (34%)]\tLoss: 0.462742\n",
      "Train Epoch: 2 [7000/17854 (39%)]\tLoss: 0.429442\n",
      "Train Epoch: 2 [8000/17854 (45%)]\tLoss: 0.306072\n",
      "Train Epoch: 2 [9000/17854 (50%)]\tLoss: 0.464631\n",
      "Train Epoch: 2 [10000/17854 (56%)]\tLoss: 0.478821\n",
      "Train Epoch: 2 [11000/17854 (61%)]\tLoss: 0.426635\n",
      "Train Epoch: 2 [12000/17854 (67%)]\tLoss: 0.517953\n",
      "Train Epoch: 2 [13000/17854 (73%)]\tLoss: 0.459195\n",
      "Train Epoch: 2 [14000/17854 (78%)]\tLoss: 0.340231\n",
      "Train Epoch: 2 [15000/17854 (84%)]\tLoss: 0.274986\n",
      "Train Epoch: 2 [16000/17854 (89%)]\tLoss: 0.414663\n",
      "Train Epoch: 2 [17000/17854 (95%)]\tLoss: 0.604160\n",
      "Train Epoch: 3 [0/17854 (0%)]\tLoss: 0.393152\n",
      "Train Epoch: 3 [1000/17854 (6%)]\tLoss: 0.328636\n",
      "Train Epoch: 3 [2000/17854 (11%)]\tLoss: 0.600294\n",
      "Train Epoch: 3 [3000/17854 (17%)]\tLoss: 0.480693\n",
      "Train Epoch: 3 [4000/17854 (22%)]\tLoss: 0.631066\n",
      "Train Epoch: 3 [5000/17854 (28%)]\tLoss: 0.325230\n",
      "Train Epoch: 3 [6000/17854 (34%)]\tLoss: 0.396306\n",
      "Train Epoch: 3 [7000/17854 (39%)]\tLoss: 0.512155\n",
      "Train Epoch: 3 [8000/17854 (45%)]\tLoss: 0.472934\n",
      "Train Epoch: 3 [9000/17854 (50%)]\tLoss: 0.452417\n",
      "Train Epoch: 3 [10000/17854 (56%)]\tLoss: 0.428276\n",
      "Train Epoch: 3 [11000/17854 (61%)]\tLoss: 0.443320\n",
      "Train Epoch: 3 [12000/17854 (67%)]\tLoss: 0.253445\n",
      "Train Epoch: 3 [13000/17854 (73%)]\tLoss: 0.416609\n",
      "Train Epoch: 3 [14000/17854 (78%)]\tLoss: 0.497767\n",
      "Train Epoch: 3 [15000/17854 (84%)]\tLoss: 0.308918\n",
      "Train Epoch: 3 [16000/17854 (89%)]\tLoss: 0.356970\n",
      "Train Epoch: 3 [17000/17854 (95%)]\tLoss: 0.484021\n",
      "Train Epoch: 4 [0/17854 (0%)]\tLoss: 0.393881\n",
      "Train Epoch: 4 [1000/17854 (6%)]\tLoss: 0.391975\n",
      "Train Epoch: 4 [2000/17854 (11%)]\tLoss: 0.441162\n",
      "Train Epoch: 4 [3000/17854 (17%)]\tLoss: 0.396091\n",
      "Train Epoch: 4 [4000/17854 (22%)]\tLoss: 0.512405\n",
      "Train Epoch: 4 [5000/17854 (28%)]\tLoss: 0.483225\n",
      "Train Epoch: 4 [6000/17854 (34%)]\tLoss: 0.395988\n",
      "Train Epoch: 4 [7000/17854 (39%)]\tLoss: 0.350901\n",
      "Train Epoch: 4 [8000/17854 (45%)]\tLoss: 0.369616\n",
      "Train Epoch: 4 [9000/17854 (50%)]\tLoss: 0.394560\n",
      "Train Epoch: 4 [10000/17854 (56%)]\tLoss: 0.304225\n",
      "Train Epoch: 4 [11000/17854 (61%)]\tLoss: 0.325803\n",
      "Train Epoch: 4 [12000/17854 (67%)]\tLoss: 0.379427\n",
      "Train Epoch: 4 [13000/17854 (73%)]\tLoss: 0.531603\n",
      "Train Epoch: 4 [14000/17854 (78%)]\tLoss: 0.374914\n",
      "Train Epoch: 4 [15000/17854 (84%)]\tLoss: 0.358678\n",
      "Train Epoch: 4 [16000/17854 (89%)]\tLoss: 0.365355\n",
      "Train Epoch: 4 [17000/17854 (95%)]\tLoss: 0.384287\n",
      "Train Epoch: 5 [0/17854 (0%)]\tLoss: 0.409990\n",
      "Train Epoch: 5 [1000/17854 (6%)]\tLoss: 0.294338\n",
      "Train Epoch: 5 [2000/17854 (11%)]\tLoss: 0.379305\n",
      "Train Epoch: 5 [3000/17854 (17%)]\tLoss: 0.441489\n",
      "Train Epoch: 5 [4000/17854 (22%)]\tLoss: 0.295349\n",
      "Train Epoch: 5 [5000/17854 (28%)]\tLoss: 0.360704\n",
      "Train Epoch: 5 [6000/17854 (34%)]\tLoss: 0.365390\n",
      "Train Epoch: 5 [7000/17854 (39%)]\tLoss: 0.335037\n",
      "Train Epoch: 5 [8000/17854 (45%)]\tLoss: 0.494860\n",
      "Train Epoch: 5 [9000/17854 (50%)]\tLoss: 0.390881\n",
      "Train Epoch: 5 [10000/17854 (56%)]\tLoss: 0.374175\n",
      "Train Epoch: 5 [11000/17854 (61%)]\tLoss: 0.449283\n",
      "Train Epoch: 5 [12000/17854 (67%)]\tLoss: 0.548537\n",
      "Train Epoch: 5 [13000/17854 (73%)]\tLoss: 0.322285\n",
      "Train Epoch: 5 [14000/17854 (78%)]\tLoss: 0.336912\n",
      "Train Epoch: 5 [15000/17854 (84%)]\tLoss: 0.398732\n",
      "Train Epoch: 5 [16000/17854 (89%)]\tLoss: 0.435054\n",
      "Train Epoch: 5 [17000/17854 (95%)]\tLoss: 0.382004\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11811 (0%)]\tLoss: 0.366974\n",
      "Train Epoch: 1 [1000/11811 (8%)]\tLoss: 0.280028\n",
      "Train Epoch: 1 [2000/11811 (17%)]\tLoss: 0.240261\n",
      "Train Epoch: 1 [3000/11811 (25%)]\tLoss: 0.349967\n",
      "Train Epoch: 1 [4000/11811 (34%)]\tLoss: 0.282051\n",
      "Train Epoch: 1 [5000/11811 (42%)]\tLoss: 0.206547\n",
      "Train Epoch: 1 [6000/11811 (50%)]\tLoss: 0.217378\n",
      "Train Epoch: 1 [7000/11811 (59%)]\tLoss: 0.345064\n",
      "Train Epoch: 1 [8000/11811 (67%)]\tLoss: 0.217170\n",
      "Train Epoch: 1 [9000/11811 (76%)]\tLoss: 0.186367\n",
      "Train Epoch: 1 [10000/11811 (84%)]\tLoss: 0.171439\n",
      "Train Epoch: 1 [11000/11811 (92%)]\tLoss: 0.263698\n",
      "Train Epoch: 2 [0/11811 (0%)]\tLoss: 0.180938\n",
      "Train Epoch: 2 [1000/11811 (8%)]\tLoss: 0.174517\n",
      "Train Epoch: 2 [2000/11811 (17%)]\tLoss: 0.117427\n",
      "Train Epoch: 2 [3000/11811 (25%)]\tLoss: 0.366938\n",
      "Train Epoch: 2 [4000/11811 (34%)]\tLoss: 0.143041\n",
      "Train Epoch: 2 [5000/11811 (42%)]\tLoss: 0.182375\n",
      "Train Epoch: 2 [6000/11811 (50%)]\tLoss: 0.239722\n",
      "Train Epoch: 2 [7000/11811 (59%)]\tLoss: 0.233798\n",
      "Train Epoch: 2 [8000/11811 (67%)]\tLoss: 0.202367\n",
      "Train Epoch: 2 [9000/11811 (76%)]\tLoss: 0.240095\n",
      "Train Epoch: 2 [10000/11811 (84%)]\tLoss: 0.202723\n",
      "Train Epoch: 2 [11000/11811 (92%)]\tLoss: 0.304517\n",
      "Train Epoch: 3 [0/11811 (0%)]\tLoss: 0.219763\n",
      "Train Epoch: 3 [1000/11811 (8%)]\tLoss: 0.248313\n",
      "Train Epoch: 3 [2000/11811 (17%)]\tLoss: 0.239770\n",
      "Train Epoch: 3 [3000/11811 (25%)]\tLoss: 0.134234\n",
      "Train Epoch: 3 [4000/11811 (34%)]\tLoss: 0.182290\n",
      "Train Epoch: 3 [5000/11811 (42%)]\tLoss: 0.196669\n",
      "Train Epoch: 3 [6000/11811 (50%)]\tLoss: 0.262216\n",
      "Train Epoch: 3 [7000/11811 (59%)]\tLoss: 0.192299\n",
      "Train Epoch: 3 [8000/11811 (67%)]\tLoss: 0.187454\n",
      "Train Epoch: 3 [9000/11811 (76%)]\tLoss: 0.201768\n",
      "Train Epoch: 3 [10000/11811 (84%)]\tLoss: 0.191784\n",
      "Train Epoch: 3 [11000/11811 (92%)]\tLoss: 0.372037\n",
      "Train Epoch: 4 [0/11811 (0%)]\tLoss: 0.203688\n",
      "Train Epoch: 4 [1000/11811 (8%)]\tLoss: 0.137121\n",
      "Train Epoch: 4 [2000/11811 (17%)]\tLoss: 0.207962\n",
      "Train Epoch: 4 [3000/11811 (25%)]\tLoss: 0.249235\n",
      "Train Epoch: 4 [4000/11811 (34%)]\tLoss: 0.312248\n",
      "Train Epoch: 4 [5000/11811 (42%)]\tLoss: 0.145258\n",
      "Train Epoch: 4 [6000/11811 (50%)]\tLoss: 0.111269\n",
      "Train Epoch: 4 [7000/11811 (59%)]\tLoss: 0.162030\n",
      "Train Epoch: 4 [8000/11811 (67%)]\tLoss: 0.238000\n",
      "Train Epoch: 4 [9000/11811 (76%)]\tLoss: 0.214079\n",
      "Train Epoch: 4 [10000/11811 (84%)]\tLoss: 0.248696\n",
      "Train Epoch: 4 [11000/11811 (92%)]\tLoss: 0.211630\n",
      "Train Epoch: 5 [0/11811 (0%)]\tLoss: 0.217428\n",
      "Train Epoch: 5 [1000/11811 (8%)]\tLoss: 0.184756\n",
      "Train Epoch: 5 [2000/11811 (17%)]\tLoss: 0.185782\n",
      "Train Epoch: 5 [3000/11811 (25%)]\tLoss: 0.220744\n",
      "Train Epoch: 5 [4000/11811 (34%)]\tLoss: 0.257771\n",
      "Train Epoch: 5 [5000/11811 (42%)]\tLoss: 0.278337\n",
      "Train Epoch: 5 [6000/11811 (50%)]\tLoss: 0.293654\n",
      "Train Epoch: 5 [7000/11811 (59%)]\tLoss: 0.305029\n",
      "Train Epoch: 5 [8000/11811 (67%)]\tLoss: 0.166060\n",
      "Train Epoch: 5 [9000/11811 (76%)]\tLoss: 0.145885\n",
      "Train Epoch: 5 [10000/11811 (84%)]\tLoss: 0.124548\n",
      "Train Epoch: 5 [11000/11811 (92%)]\tLoss: 0.262858\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "6\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.0334, Accuracy: 7420/10000 (74%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/17854 (0%)]\tLoss: 0.562791\n",
      "Train Epoch: 1 [1000/17854 (6%)]\tLoss: 0.449238\n",
      "Train Epoch: 1 [2000/17854 (11%)]\tLoss: 0.445993\n",
      "Train Epoch: 1 [3000/17854 (17%)]\tLoss: 0.517293\n",
      "Train Epoch: 1 [4000/17854 (22%)]\tLoss: 0.506458\n",
      "Train Epoch: 1 [5000/17854 (28%)]\tLoss: 0.435893\n",
      "Train Epoch: 1 [6000/17854 (34%)]\tLoss: 0.330125\n",
      "Train Epoch: 1 [7000/17854 (39%)]\tLoss: 0.451907\n",
      "Train Epoch: 1 [8000/17854 (45%)]\tLoss: 0.400268\n",
      "Train Epoch: 1 [9000/17854 (50%)]\tLoss: 0.525510\n",
      "Train Epoch: 1 [10000/17854 (56%)]\tLoss: 0.392694\n",
      "Train Epoch: 1 [11000/17854 (61%)]\tLoss: 0.319888\n",
      "Train Epoch: 1 [12000/17854 (67%)]\tLoss: 0.394661\n",
      "Train Epoch: 1 [13000/17854 (73%)]\tLoss: 0.571726\n",
      "Train Epoch: 1 [14000/17854 (78%)]\tLoss: 0.310750\n",
      "Train Epoch: 1 [15000/17854 (84%)]\tLoss: 0.257787\n",
      "Train Epoch: 1 [16000/17854 (89%)]\tLoss: 0.383134\n",
      "Train Epoch: 1 [17000/17854 (95%)]\tLoss: 0.394633\n",
      "Train Epoch: 2 [0/17854 (0%)]\tLoss: 0.399480\n",
      "Train Epoch: 2 [1000/17854 (6%)]\tLoss: 0.336870\n",
      "Train Epoch: 2 [2000/17854 (11%)]\tLoss: 0.335912\n",
      "Train Epoch: 2 [3000/17854 (17%)]\tLoss: 0.388547\n",
      "Train Epoch: 2 [4000/17854 (22%)]\tLoss: 0.357303\n",
      "Train Epoch: 2 [5000/17854 (28%)]\tLoss: 0.324301\n",
      "Train Epoch: 2 [6000/17854 (34%)]\tLoss: 0.392418\n",
      "Train Epoch: 2 [7000/17854 (39%)]\tLoss: 0.305423\n",
      "Train Epoch: 2 [8000/17854 (45%)]\tLoss: 0.320570\n",
      "Train Epoch: 2 [9000/17854 (50%)]\tLoss: 0.436932\n",
      "Train Epoch: 2 [10000/17854 (56%)]\tLoss: 0.538336\n",
      "Train Epoch: 2 [11000/17854 (61%)]\tLoss: 0.282921\n",
      "Train Epoch: 2 [12000/17854 (67%)]\tLoss: 0.395359\n",
      "Train Epoch: 2 [13000/17854 (73%)]\tLoss: 0.357407\n",
      "Train Epoch: 2 [14000/17854 (78%)]\tLoss: 0.488911\n",
      "Train Epoch: 2 [15000/17854 (84%)]\tLoss: 0.513055\n",
      "Train Epoch: 2 [16000/17854 (89%)]\tLoss: 0.355338\n",
      "Train Epoch: 2 [17000/17854 (95%)]\tLoss: 0.296409\n",
      "Train Epoch: 3 [0/17854 (0%)]\tLoss: 0.446854\n",
      "Train Epoch: 3 [1000/17854 (6%)]\tLoss: 0.429367\n",
      "Train Epoch: 3 [2000/17854 (11%)]\tLoss: 0.482897\n",
      "Train Epoch: 3 [3000/17854 (17%)]\tLoss: 0.358103\n",
      "Train Epoch: 3 [4000/17854 (22%)]\tLoss: 0.393016\n",
      "Train Epoch: 3 [5000/17854 (28%)]\tLoss: 0.325720\n",
      "Train Epoch: 3 [6000/17854 (34%)]\tLoss: 0.400750\n",
      "Train Epoch: 3 [7000/17854 (39%)]\tLoss: 0.465887\n",
      "Train Epoch: 3 [8000/17854 (45%)]\tLoss: 0.462063\n",
      "Train Epoch: 3 [9000/17854 (50%)]\tLoss: 0.464185\n",
      "Train Epoch: 3 [10000/17854 (56%)]\tLoss: 0.364401\n",
      "Train Epoch: 3 [11000/17854 (61%)]\tLoss: 0.294683\n",
      "Train Epoch: 3 [12000/17854 (67%)]\tLoss: 0.395019\n",
      "Train Epoch: 3 [13000/17854 (73%)]\tLoss: 0.567395\n",
      "Train Epoch: 3 [14000/17854 (78%)]\tLoss: 0.405596\n",
      "Train Epoch: 3 [15000/17854 (84%)]\tLoss: 0.359513\n",
      "Train Epoch: 3 [16000/17854 (89%)]\tLoss: 0.403078\n",
      "Train Epoch: 3 [17000/17854 (95%)]\tLoss: 0.384026\n",
      "Train Epoch: 4 [0/17854 (0%)]\tLoss: 0.430842\n",
      "Train Epoch: 4 [1000/17854 (6%)]\tLoss: 0.456750\n",
      "Train Epoch: 4 [2000/17854 (11%)]\tLoss: 0.322448\n",
      "Train Epoch: 4 [3000/17854 (17%)]\tLoss: 0.563337\n",
      "Train Epoch: 4 [4000/17854 (22%)]\tLoss: 0.479574\n",
      "Train Epoch: 4 [5000/17854 (28%)]\tLoss: 0.400603\n",
      "Train Epoch: 4 [6000/17854 (34%)]\tLoss: 0.297336\n",
      "Train Epoch: 4 [7000/17854 (39%)]\tLoss: 0.426402\n",
      "Train Epoch: 4 [8000/17854 (45%)]\tLoss: 0.430525\n",
      "Train Epoch: 4 [9000/17854 (50%)]\tLoss: 0.319446\n",
      "Train Epoch: 4 [10000/17854 (56%)]\tLoss: 0.465404\n",
      "Train Epoch: 4 [11000/17854 (61%)]\tLoss: 0.327959\n",
      "Train Epoch: 4 [12000/17854 (67%)]\tLoss: 0.546285\n",
      "Train Epoch: 4 [13000/17854 (73%)]\tLoss: 0.380496\n",
      "Train Epoch: 4 [14000/17854 (78%)]\tLoss: 0.372098\n",
      "Train Epoch: 4 [15000/17854 (84%)]\tLoss: 0.333100\n",
      "Train Epoch: 4 [16000/17854 (89%)]\tLoss: 0.515890\n",
      "Train Epoch: 4 [17000/17854 (95%)]\tLoss: 0.236772\n",
      "Train Epoch: 5 [0/17854 (0%)]\tLoss: 0.283677\n",
      "Train Epoch: 5 [1000/17854 (6%)]\tLoss: 0.277920\n",
      "Train Epoch: 5 [2000/17854 (11%)]\tLoss: 0.296851\n",
      "Train Epoch: 5 [3000/17854 (17%)]\tLoss: 0.600488\n",
      "Train Epoch: 5 [4000/17854 (22%)]\tLoss: 0.370509\n",
      "Train Epoch: 5 [5000/17854 (28%)]\tLoss: 0.312476\n",
      "Train Epoch: 5 [6000/17854 (34%)]\tLoss: 0.235832\n",
      "Train Epoch: 5 [7000/17854 (39%)]\tLoss: 0.275770\n",
      "Train Epoch: 5 [8000/17854 (45%)]\tLoss: 0.429193\n",
      "Train Epoch: 5 [9000/17854 (50%)]\tLoss: 0.317768\n",
      "Train Epoch: 5 [10000/17854 (56%)]\tLoss: 0.301597\n",
      "Train Epoch: 5 [11000/17854 (61%)]\tLoss: 0.594233\n",
      "Train Epoch: 5 [12000/17854 (67%)]\tLoss: 0.360547\n",
      "Train Epoch: 5 [13000/17854 (73%)]\tLoss: 0.446964\n",
      "Train Epoch: 5 [14000/17854 (78%)]\tLoss: 0.355648\n",
      "Train Epoch: 5 [15000/17854 (84%)]\tLoss: 0.516246\n",
      "Train Epoch: 5 [16000/17854 (89%)]\tLoss: 0.289454\n",
      "Train Epoch: 5 [17000/17854 (95%)]\tLoss: 0.357928\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11811 (0%)]\tLoss: 0.230668\n",
      "Train Epoch: 1 [1000/11811 (8%)]\tLoss: 0.292847\n",
      "Train Epoch: 1 [2000/11811 (17%)]\tLoss: 0.291210\n",
      "Train Epoch: 1 [3000/11811 (25%)]\tLoss: 0.128386\n",
      "Train Epoch: 1 [4000/11811 (34%)]\tLoss: 0.269458\n",
      "Train Epoch: 1 [5000/11811 (42%)]\tLoss: 0.181242\n",
      "Train Epoch: 1 [6000/11811 (50%)]\tLoss: 0.202456\n",
      "Train Epoch: 1 [7000/11811 (59%)]\tLoss: 0.241863\n",
      "Train Epoch: 1 [8000/11811 (67%)]\tLoss: 0.265109\n",
      "Train Epoch: 1 [9000/11811 (76%)]\tLoss: 0.173129\n",
      "Train Epoch: 1 [10000/11811 (84%)]\tLoss: 0.182294\n",
      "Train Epoch: 1 [11000/11811 (92%)]\tLoss: 0.165304\n",
      "Train Epoch: 2 [0/11811 (0%)]\tLoss: 0.162824\n",
      "Train Epoch: 2 [1000/11811 (8%)]\tLoss: 0.197795\n",
      "Train Epoch: 2 [2000/11811 (17%)]\tLoss: 0.312032\n",
      "Train Epoch: 2 [3000/11811 (25%)]\tLoss: 0.163204\n",
      "Train Epoch: 2 [4000/11811 (34%)]\tLoss: 0.214099\n",
      "Train Epoch: 2 [5000/11811 (42%)]\tLoss: 0.230097\n",
      "Train Epoch: 2 [6000/11811 (50%)]\tLoss: 0.162356\n",
      "Train Epoch: 2 [7000/11811 (59%)]\tLoss: 0.169257\n",
      "Train Epoch: 2 [8000/11811 (67%)]\tLoss: 0.301143\n",
      "Train Epoch: 2 [9000/11811 (76%)]\tLoss: 0.188693\n",
      "Train Epoch: 2 [10000/11811 (84%)]\tLoss: 0.290197\n",
      "Train Epoch: 2 [11000/11811 (92%)]\tLoss: 0.288395\n",
      "Train Epoch: 3 [0/11811 (0%)]\tLoss: 0.246870\n",
      "Train Epoch: 3 [1000/11811 (8%)]\tLoss: 0.238564\n",
      "Train Epoch: 3 [2000/11811 (17%)]\tLoss: 0.284259\n",
      "Train Epoch: 3 [3000/11811 (25%)]\tLoss: 0.221430\n",
      "Train Epoch: 3 [4000/11811 (34%)]\tLoss: 0.202673\n",
      "Train Epoch: 3 [5000/11811 (42%)]\tLoss: 0.186643\n",
      "Train Epoch: 3 [6000/11811 (50%)]\tLoss: 0.209150\n",
      "Train Epoch: 3 [7000/11811 (59%)]\tLoss: 0.209032\n",
      "Train Epoch: 3 [8000/11811 (67%)]\tLoss: 0.268586\n",
      "Train Epoch: 3 [9000/11811 (76%)]\tLoss: 0.180642\n",
      "Train Epoch: 3 [10000/11811 (84%)]\tLoss: 0.266380\n",
      "Train Epoch: 3 [11000/11811 (92%)]\tLoss: 0.121766\n",
      "Train Epoch: 4 [0/11811 (0%)]\tLoss: 0.184561\n",
      "Train Epoch: 4 [1000/11811 (8%)]\tLoss: 0.152808\n",
      "Train Epoch: 4 [2000/11811 (17%)]\tLoss: 0.238190\n",
      "Train Epoch: 4 [3000/11811 (25%)]\tLoss: 0.216915\n",
      "Train Epoch: 4 [4000/11811 (34%)]\tLoss: 0.135709\n",
      "Train Epoch: 4 [5000/11811 (42%)]\tLoss: 0.130350\n",
      "Train Epoch: 4 [6000/11811 (50%)]\tLoss: 0.168002\n",
      "Train Epoch: 4 [7000/11811 (59%)]\tLoss: 0.209375\n",
      "Train Epoch: 4 [8000/11811 (67%)]\tLoss: 0.145827\n",
      "Train Epoch: 4 [9000/11811 (76%)]\tLoss: 0.146640\n",
      "Train Epoch: 4 [10000/11811 (84%)]\tLoss: 0.192936\n",
      "Train Epoch: 4 [11000/11811 (92%)]\tLoss: 0.194766\n",
      "Train Epoch: 5 [0/11811 (0%)]\tLoss: 0.120455\n",
      "Train Epoch: 5 [1000/11811 (8%)]\tLoss: 0.200899\n",
      "Train Epoch: 5 [2000/11811 (17%)]\tLoss: 0.242604\n",
      "Train Epoch: 5 [3000/11811 (25%)]\tLoss: 0.093384\n",
      "Train Epoch: 5 [4000/11811 (34%)]\tLoss: 0.274185\n",
      "Train Epoch: 5 [5000/11811 (42%)]\tLoss: 0.219881\n",
      "Train Epoch: 5 [6000/11811 (50%)]\tLoss: 0.291403\n",
      "Train Epoch: 5 [7000/11811 (59%)]\tLoss: 0.178684\n",
      "Train Epoch: 5 [8000/11811 (67%)]\tLoss: 0.260659\n",
      "Train Epoch: 5 [9000/11811 (76%)]\tLoss: 0.317762\n",
      "Train Epoch: 5 [10000/11811 (84%)]\tLoss: 0.158635\n",
      "Train Epoch: 5 [11000/11811 (92%)]\tLoss: 0.237848\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "6\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.1369, Accuracy: 7324/10000 (73%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/17854 (0%)]\tLoss: 0.570634\n",
      "Train Epoch: 1 [1000/17854 (6%)]\tLoss: 0.317686\n",
      "Train Epoch: 1 [2000/17854 (11%)]\tLoss: 0.451236\n",
      "Train Epoch: 1 [3000/17854 (17%)]\tLoss: 0.308295\n",
      "Train Epoch: 1 [4000/17854 (22%)]\tLoss: 0.378421\n",
      "Train Epoch: 1 [5000/17854 (28%)]\tLoss: 0.423794\n",
      "Train Epoch: 1 [6000/17854 (34%)]\tLoss: 0.417931\n",
      "Train Epoch: 1 [7000/17854 (39%)]\tLoss: 0.312556\n",
      "Train Epoch: 1 [8000/17854 (45%)]\tLoss: 0.355936\n",
      "Train Epoch: 1 [9000/17854 (50%)]\tLoss: 0.428219\n",
      "Train Epoch: 1 [10000/17854 (56%)]\tLoss: 0.432366\n",
      "Train Epoch: 1 [11000/17854 (61%)]\tLoss: 0.415528\n",
      "Train Epoch: 1 [12000/17854 (67%)]\tLoss: 0.340886\n",
      "Train Epoch: 1 [13000/17854 (73%)]\tLoss: 0.399685\n",
      "Train Epoch: 1 [14000/17854 (78%)]\tLoss: 0.581275\n",
      "Train Epoch: 1 [15000/17854 (84%)]\tLoss: 0.498106\n",
      "Train Epoch: 1 [16000/17854 (89%)]\tLoss: 0.484490\n",
      "Train Epoch: 1 [17000/17854 (95%)]\tLoss: 0.385579\n",
      "Train Epoch: 2 [0/17854 (0%)]\tLoss: 0.440648\n",
      "Train Epoch: 2 [1000/17854 (6%)]\tLoss: 0.289884\n",
      "Train Epoch: 2 [2000/17854 (11%)]\tLoss: 0.511544\n",
      "Train Epoch: 2 [3000/17854 (17%)]\tLoss: 0.442404\n",
      "Train Epoch: 2 [4000/17854 (22%)]\tLoss: 0.382822\n",
      "Train Epoch: 2 [5000/17854 (28%)]\tLoss: 0.455627\n",
      "Train Epoch: 2 [6000/17854 (34%)]\tLoss: 0.258048\n",
      "Train Epoch: 2 [7000/17854 (39%)]\tLoss: 0.399890\n",
      "Train Epoch: 2 [8000/17854 (45%)]\tLoss: 0.434629\n",
      "Train Epoch: 2 [9000/17854 (50%)]\tLoss: 0.380613\n",
      "Train Epoch: 2 [10000/17854 (56%)]\tLoss: 0.448512\n",
      "Train Epoch: 2 [11000/17854 (61%)]\tLoss: 0.409822\n",
      "Train Epoch: 2 [12000/17854 (67%)]\tLoss: 0.344674\n",
      "Train Epoch: 2 [13000/17854 (73%)]\tLoss: 0.328377\n",
      "Train Epoch: 2 [14000/17854 (78%)]\tLoss: 0.314968\n",
      "Train Epoch: 2 [15000/17854 (84%)]\tLoss: 0.383493\n",
      "Train Epoch: 2 [16000/17854 (89%)]\tLoss: 0.350785\n",
      "Train Epoch: 2 [17000/17854 (95%)]\tLoss: 0.460091\n",
      "Train Epoch: 3 [0/17854 (0%)]\tLoss: 0.440664\n",
      "Train Epoch: 3 [1000/17854 (6%)]\tLoss: 0.455582\n",
      "Train Epoch: 3 [2000/17854 (11%)]\tLoss: 0.360027\n",
      "Train Epoch: 3 [3000/17854 (17%)]\tLoss: 0.417912\n",
      "Train Epoch: 3 [4000/17854 (22%)]\tLoss: 0.391562\n",
      "Train Epoch: 3 [5000/17854 (28%)]\tLoss: 0.315619\n",
      "Train Epoch: 3 [6000/17854 (34%)]\tLoss: 0.410185\n",
      "Train Epoch: 3 [7000/17854 (39%)]\tLoss: 0.366671\n",
      "Train Epoch: 3 [8000/17854 (45%)]\tLoss: 0.390979\n",
      "Train Epoch: 3 [9000/17854 (50%)]\tLoss: 0.435969\n",
      "Train Epoch: 3 [10000/17854 (56%)]\tLoss: 0.415473\n",
      "Train Epoch: 3 [11000/17854 (61%)]\tLoss: 0.456866\n",
      "Train Epoch: 3 [12000/17854 (67%)]\tLoss: 0.438454\n",
      "Train Epoch: 3 [13000/17854 (73%)]\tLoss: 0.411942\n",
      "Train Epoch: 3 [14000/17854 (78%)]\tLoss: 0.458518\n",
      "Train Epoch: 3 [15000/17854 (84%)]\tLoss: 0.523127\n",
      "Train Epoch: 3 [16000/17854 (89%)]\tLoss: 0.250060\n",
      "Train Epoch: 3 [17000/17854 (95%)]\tLoss: 0.341070\n",
      "Train Epoch: 4 [0/17854 (0%)]\tLoss: 0.209174\n",
      "Train Epoch: 4 [1000/17854 (6%)]\tLoss: 0.389762\n",
      "Train Epoch: 4 [2000/17854 (11%)]\tLoss: 0.406256\n",
      "Train Epoch: 4 [3000/17854 (17%)]\tLoss: 0.415788\n",
      "Train Epoch: 4 [4000/17854 (22%)]\tLoss: 0.428544\n",
      "Train Epoch: 4 [5000/17854 (28%)]\tLoss: 0.332086\n",
      "Train Epoch: 4 [6000/17854 (34%)]\tLoss: 0.384424\n",
      "Train Epoch: 4 [7000/17854 (39%)]\tLoss: 0.407292\n",
      "Train Epoch: 4 [8000/17854 (45%)]\tLoss: 0.380183\n",
      "Train Epoch: 4 [9000/17854 (50%)]\tLoss: 0.456258\n",
      "Train Epoch: 4 [10000/17854 (56%)]\tLoss: 0.487879\n",
      "Train Epoch: 4 [11000/17854 (61%)]\tLoss: 0.447414\n",
      "Train Epoch: 4 [12000/17854 (67%)]\tLoss: 0.321874\n",
      "Train Epoch: 4 [13000/17854 (73%)]\tLoss: 0.372956\n",
      "Train Epoch: 4 [14000/17854 (78%)]\tLoss: 0.411483\n",
      "Train Epoch: 4 [15000/17854 (84%)]\tLoss: 0.410134\n",
      "Train Epoch: 4 [16000/17854 (89%)]\tLoss: 0.314598\n",
      "Train Epoch: 4 [17000/17854 (95%)]\tLoss: 0.257384\n",
      "Train Epoch: 5 [0/17854 (0%)]\tLoss: 0.387730\n",
      "Train Epoch: 5 [1000/17854 (6%)]\tLoss: 0.307028\n",
      "Train Epoch: 5 [2000/17854 (11%)]\tLoss: 0.361861\n",
      "Train Epoch: 5 [3000/17854 (17%)]\tLoss: 0.382505\n",
      "Train Epoch: 5 [4000/17854 (22%)]\tLoss: 0.566970\n",
      "Train Epoch: 5 [5000/17854 (28%)]\tLoss: 0.377927\n",
      "Train Epoch: 5 [6000/17854 (34%)]\tLoss: 0.315693\n",
      "Train Epoch: 5 [7000/17854 (39%)]\tLoss: 0.328817\n",
      "Train Epoch: 5 [8000/17854 (45%)]\tLoss: 0.461748\n",
      "Train Epoch: 5 [9000/17854 (50%)]\tLoss: 0.365923\n",
      "Train Epoch: 5 [10000/17854 (56%)]\tLoss: 0.410161\n",
      "Train Epoch: 5 [11000/17854 (61%)]\tLoss: 0.396317\n",
      "Train Epoch: 5 [12000/17854 (67%)]\tLoss: 0.374262\n",
      "Train Epoch: 5 [13000/17854 (73%)]\tLoss: 0.435853\n",
      "Train Epoch: 5 [14000/17854 (78%)]\tLoss: 0.463417\n",
      "Train Epoch: 5 [15000/17854 (84%)]\tLoss: 0.470011\n",
      "Train Epoch: 5 [16000/17854 (89%)]\tLoss: 0.360331\n",
      "Train Epoch: 5 [17000/17854 (95%)]\tLoss: 0.441936\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11811 (0%)]\tLoss: 0.372766\n",
      "Train Epoch: 1 [1000/11811 (8%)]\tLoss: 0.268180\n",
      "Train Epoch: 1 [2000/11811 (17%)]\tLoss: 0.204117\n",
      "Train Epoch: 1 [3000/11811 (25%)]\tLoss: 0.144438\n",
      "Train Epoch: 1 [4000/11811 (34%)]\tLoss: 0.201764\n",
      "Train Epoch: 1 [5000/11811 (42%)]\tLoss: 0.294749\n",
      "Train Epoch: 1 [6000/11811 (50%)]\tLoss: 0.131414\n",
      "Train Epoch: 1 [7000/11811 (59%)]\tLoss: 0.283039\n",
      "Train Epoch: 1 [8000/11811 (67%)]\tLoss: 0.292046\n",
      "Train Epoch: 1 [9000/11811 (76%)]\tLoss: 0.139577\n",
      "Train Epoch: 1 [10000/11811 (84%)]\tLoss: 0.163875\n",
      "Train Epoch: 1 [11000/11811 (92%)]\tLoss: 0.176046\n",
      "Train Epoch: 2 [0/11811 (0%)]\tLoss: 0.188543\n",
      "Train Epoch: 2 [1000/11811 (8%)]\tLoss: 0.159730\n",
      "Train Epoch: 2 [2000/11811 (17%)]\tLoss: 0.136214\n",
      "Train Epoch: 2 [3000/11811 (25%)]\tLoss: 0.192851\n",
      "Train Epoch: 2 [4000/11811 (34%)]\tLoss: 0.224800\n",
      "Train Epoch: 2 [5000/11811 (42%)]\tLoss: 0.143648\n",
      "Train Epoch: 2 [6000/11811 (50%)]\tLoss: 0.135299\n",
      "Train Epoch: 2 [7000/11811 (59%)]\tLoss: 0.292971\n",
      "Train Epoch: 2 [8000/11811 (67%)]\tLoss: 0.199269\n",
      "Train Epoch: 2 [9000/11811 (76%)]\tLoss: 0.285278\n",
      "Train Epoch: 2 [10000/11811 (84%)]\tLoss: 0.301084\n",
      "Train Epoch: 2 [11000/11811 (92%)]\tLoss: 0.206875\n",
      "Train Epoch: 3 [0/11811 (0%)]\tLoss: 0.252195\n",
      "Train Epoch: 3 [1000/11811 (8%)]\tLoss: 0.263460\n",
      "Train Epoch: 3 [2000/11811 (17%)]\tLoss: 0.186686\n",
      "Train Epoch: 3 [3000/11811 (25%)]\tLoss: 0.198874\n",
      "Train Epoch: 3 [4000/11811 (34%)]\tLoss: 0.273008\n",
      "Train Epoch: 3 [5000/11811 (42%)]\tLoss: 0.258707\n",
      "Train Epoch: 3 [6000/11811 (50%)]\tLoss: 0.140618\n",
      "Train Epoch: 3 [7000/11811 (59%)]\tLoss: 0.164743\n",
      "Train Epoch: 3 [8000/11811 (67%)]\tLoss: 0.126588\n",
      "Train Epoch: 3 [9000/11811 (76%)]\tLoss: 0.240136\n",
      "Train Epoch: 3 [10000/11811 (84%)]\tLoss: 0.230680\n",
      "Train Epoch: 3 [11000/11811 (92%)]\tLoss: 0.258891\n",
      "Train Epoch: 4 [0/11811 (0%)]\tLoss: 0.272228\n",
      "Train Epoch: 4 [1000/11811 (8%)]\tLoss: 0.323703\n",
      "Train Epoch: 4 [2000/11811 (17%)]\tLoss: 0.126644\n",
      "Train Epoch: 4 [3000/11811 (25%)]\tLoss: 0.274646\n",
      "Train Epoch: 4 [4000/11811 (34%)]\tLoss: 0.135451\n",
      "Train Epoch: 4 [5000/11811 (42%)]\tLoss: 0.175004\n",
      "Train Epoch: 4 [6000/11811 (50%)]\tLoss: 0.150816\n",
      "Train Epoch: 4 [7000/11811 (59%)]\tLoss: 0.164849\n",
      "Train Epoch: 4 [8000/11811 (67%)]\tLoss: 0.174679\n",
      "Train Epoch: 4 [9000/11811 (76%)]\tLoss: 0.112329\n",
      "Train Epoch: 4 [10000/11811 (84%)]\tLoss: 0.246459\n",
      "Train Epoch: 4 [11000/11811 (92%)]\tLoss: 0.203367\n",
      "Train Epoch: 5 [0/11811 (0%)]\tLoss: 0.167177\n",
      "Train Epoch: 5 [1000/11811 (8%)]\tLoss: 0.164070\n",
      "Train Epoch: 5 [2000/11811 (17%)]\tLoss: 0.172438\n",
      "Train Epoch: 5 [3000/11811 (25%)]\tLoss: 0.191796\n",
      "Train Epoch: 5 [4000/11811 (34%)]\tLoss: 0.172519\n",
      "Train Epoch: 5 [5000/11811 (42%)]\tLoss: 0.140590\n",
      "Train Epoch: 5 [6000/11811 (50%)]\tLoss: 0.131281\n",
      "Train Epoch: 5 [7000/11811 (59%)]\tLoss: 0.146404\n",
      "Train Epoch: 5 [8000/11811 (67%)]\tLoss: 0.224488\n",
      "Train Epoch: 5 [9000/11811 (76%)]\tLoss: 0.249074\n",
      "Train Epoch: 5 [10000/11811 (84%)]\tLoss: 0.210321\n",
      "Train Epoch: 5 [11000/11811 (92%)]\tLoss: 0.245478\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "6\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.1161, Accuracy: 7351/10000 (74%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/17854 (0%)]\tLoss: 0.467919\n",
      "Train Epoch: 1 [1000/17854 (6%)]\tLoss: 0.390256\n",
      "Train Epoch: 1 [2000/17854 (11%)]\tLoss: 0.427015\n",
      "Train Epoch: 1 [3000/17854 (17%)]\tLoss: 0.417083\n",
      "Train Epoch: 1 [4000/17854 (22%)]\tLoss: 0.375294\n",
      "Train Epoch: 1 [5000/17854 (28%)]\tLoss: 0.500045\n",
      "Train Epoch: 1 [6000/17854 (34%)]\tLoss: 0.431878\n",
      "Train Epoch: 1 [7000/17854 (39%)]\tLoss: 0.434121\n",
      "Train Epoch: 1 [8000/17854 (45%)]\tLoss: 0.329545\n",
      "Train Epoch: 1 [9000/17854 (50%)]\tLoss: 0.424268\n",
      "Train Epoch: 1 [10000/17854 (56%)]\tLoss: 0.334546\n",
      "Train Epoch: 1 [11000/17854 (61%)]\tLoss: 0.418246\n",
      "Train Epoch: 1 [12000/17854 (67%)]\tLoss: 0.380717\n",
      "Train Epoch: 1 [13000/17854 (73%)]\tLoss: 0.433744\n",
      "Train Epoch: 1 [14000/17854 (78%)]\tLoss: 0.384321\n",
      "Train Epoch: 1 [15000/17854 (84%)]\tLoss: 0.250926\n",
      "Train Epoch: 1 [16000/17854 (89%)]\tLoss: 0.292814\n",
      "Train Epoch: 1 [17000/17854 (95%)]\tLoss: 0.513428\n",
      "Train Epoch: 2 [0/17854 (0%)]\tLoss: 0.427094\n",
      "Train Epoch: 2 [1000/17854 (6%)]\tLoss: 0.361139\n",
      "Train Epoch: 2 [2000/17854 (11%)]\tLoss: 0.468812\n",
      "Train Epoch: 2 [3000/17854 (17%)]\tLoss: 0.441745\n",
      "Train Epoch: 2 [4000/17854 (22%)]\tLoss: 0.302587\n",
      "Train Epoch: 2 [5000/17854 (28%)]\tLoss: 0.280285\n",
      "Train Epoch: 2 [6000/17854 (34%)]\tLoss: 0.327772\n",
      "Train Epoch: 2 [7000/17854 (39%)]\tLoss: 0.329958\n",
      "Train Epoch: 2 [8000/17854 (45%)]\tLoss: 0.482353\n",
      "Train Epoch: 2 [9000/17854 (50%)]\tLoss: 0.505515\n",
      "Train Epoch: 2 [10000/17854 (56%)]\tLoss: 0.319183\n",
      "Train Epoch: 2 [11000/17854 (61%)]\tLoss: 0.464845\n",
      "Train Epoch: 2 [12000/17854 (67%)]\tLoss: 0.462916\n",
      "Train Epoch: 2 [13000/17854 (73%)]\tLoss: 0.420029\n",
      "Train Epoch: 2 [14000/17854 (78%)]\tLoss: 0.683906\n",
      "Train Epoch: 2 [15000/17854 (84%)]\tLoss: 0.460625\n",
      "Train Epoch: 2 [16000/17854 (89%)]\tLoss: 0.274646\n",
      "Train Epoch: 2 [17000/17854 (95%)]\tLoss: 0.383659\n",
      "Train Epoch: 3 [0/17854 (0%)]\tLoss: 0.418583\n",
      "Train Epoch: 3 [1000/17854 (6%)]\tLoss: 0.396722\n",
      "Train Epoch: 3 [2000/17854 (11%)]\tLoss: 0.461692\n",
      "Train Epoch: 3 [3000/17854 (17%)]\tLoss: 0.374402\n",
      "Train Epoch: 3 [4000/17854 (22%)]\tLoss: 0.351536\n",
      "Train Epoch: 3 [5000/17854 (28%)]\tLoss: 0.285731\n",
      "Train Epoch: 3 [6000/17854 (34%)]\tLoss: 0.409233\n",
      "Train Epoch: 3 [7000/17854 (39%)]\tLoss: 0.220894\n",
      "Train Epoch: 3 [8000/17854 (45%)]\tLoss: 0.360742\n",
      "Train Epoch: 3 [9000/17854 (50%)]\tLoss: 0.334888\n",
      "Train Epoch: 3 [10000/17854 (56%)]\tLoss: 0.428074\n",
      "Train Epoch: 3 [11000/17854 (61%)]\tLoss: 0.493461\n",
      "Train Epoch: 3 [12000/17854 (67%)]\tLoss: 0.478944\n",
      "Train Epoch: 3 [13000/17854 (73%)]\tLoss: 0.495189\n",
      "Train Epoch: 3 [14000/17854 (78%)]\tLoss: 0.331356\n",
      "Train Epoch: 3 [15000/17854 (84%)]\tLoss: 0.375433\n",
      "Train Epoch: 3 [16000/17854 (89%)]\tLoss: 0.544850\n",
      "Train Epoch: 3 [17000/17854 (95%)]\tLoss: 0.469260\n",
      "Train Epoch: 4 [0/17854 (0%)]\tLoss: 0.358674\n",
      "Train Epoch: 4 [1000/17854 (6%)]\tLoss: 0.336131\n",
      "Train Epoch: 4 [2000/17854 (11%)]\tLoss: 0.355298\n",
      "Train Epoch: 4 [3000/17854 (17%)]\tLoss: 0.381657\n",
      "Train Epoch: 4 [4000/17854 (22%)]\tLoss: 0.324316\n",
      "Train Epoch: 4 [5000/17854 (28%)]\tLoss: 0.392347\n",
      "Train Epoch: 4 [6000/17854 (34%)]\tLoss: 0.441876\n",
      "Train Epoch: 4 [7000/17854 (39%)]\tLoss: 0.344421\n",
      "Train Epoch: 4 [8000/17854 (45%)]\tLoss: 0.321879\n",
      "Train Epoch: 4 [9000/17854 (50%)]\tLoss: 0.501815\n",
      "Train Epoch: 4 [10000/17854 (56%)]\tLoss: 0.412445\n",
      "Train Epoch: 4 [11000/17854 (61%)]\tLoss: 0.425314\n",
      "Train Epoch: 4 [12000/17854 (67%)]\tLoss: 0.395230\n",
      "Train Epoch: 4 [13000/17854 (73%)]\tLoss: 0.355452\n",
      "Train Epoch: 4 [14000/17854 (78%)]\tLoss: 0.435750\n",
      "Train Epoch: 4 [15000/17854 (84%)]\tLoss: 0.303875\n",
      "Train Epoch: 4 [16000/17854 (89%)]\tLoss: 0.571815\n",
      "Train Epoch: 4 [17000/17854 (95%)]\tLoss: 0.426783\n",
      "Train Epoch: 5 [0/17854 (0%)]\tLoss: 0.385311\n",
      "Train Epoch: 5 [1000/17854 (6%)]\tLoss: 0.311997\n",
      "Train Epoch: 5 [2000/17854 (11%)]\tLoss: 0.351633\n",
      "Train Epoch: 5 [3000/17854 (17%)]\tLoss: 0.359100\n",
      "Train Epoch: 5 [4000/17854 (22%)]\tLoss: 0.378787\n",
      "Train Epoch: 5 [5000/17854 (28%)]\tLoss: 0.420823\n",
      "Train Epoch: 5 [6000/17854 (34%)]\tLoss: 0.398347\n",
      "Train Epoch: 5 [7000/17854 (39%)]\tLoss: 0.315649\n",
      "Train Epoch: 5 [8000/17854 (45%)]\tLoss: 0.337212\n",
      "Train Epoch: 5 [9000/17854 (50%)]\tLoss: 0.326315\n",
      "Train Epoch: 5 [10000/17854 (56%)]\tLoss: 0.323170\n",
      "Train Epoch: 5 [11000/17854 (61%)]\tLoss: 0.521820\n",
      "Train Epoch: 5 [12000/17854 (67%)]\tLoss: 0.457307\n",
      "Train Epoch: 5 [13000/17854 (73%)]\tLoss: 0.309199\n",
      "Train Epoch: 5 [14000/17854 (78%)]\tLoss: 0.365709\n",
      "Train Epoch: 5 [15000/17854 (84%)]\tLoss: 0.436689\n",
      "Train Epoch: 5 [16000/17854 (89%)]\tLoss: 0.366259\n",
      "Train Epoch: 5 [17000/17854 (95%)]\tLoss: 0.486535\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11811 (0%)]\tLoss: 0.229603\n",
      "Train Epoch: 1 [1000/11811 (8%)]\tLoss: 0.359395\n",
      "Train Epoch: 1 [2000/11811 (17%)]\tLoss: 0.148635\n",
      "Train Epoch: 1 [3000/11811 (25%)]\tLoss: 0.168215\n",
      "Train Epoch: 1 [4000/11811 (34%)]\tLoss: 0.156919\n",
      "Train Epoch: 1 [5000/11811 (42%)]\tLoss: 0.194903\n",
      "Train Epoch: 1 [6000/11811 (50%)]\tLoss: 0.148931\n",
      "Train Epoch: 1 [7000/11811 (59%)]\tLoss: 0.130946\n",
      "Train Epoch: 1 [8000/11811 (67%)]\tLoss: 0.208591\n",
      "Train Epoch: 1 [9000/11811 (76%)]\tLoss: 0.339239\n",
      "Train Epoch: 1 [10000/11811 (84%)]\tLoss: 0.181078\n",
      "Train Epoch: 1 [11000/11811 (92%)]\tLoss: 0.146636\n",
      "Train Epoch: 2 [0/11811 (0%)]\tLoss: 0.209560\n",
      "Train Epoch: 2 [1000/11811 (8%)]\tLoss: 0.153042\n",
      "Train Epoch: 2 [2000/11811 (17%)]\tLoss: 0.212090\n",
      "Train Epoch: 2 [3000/11811 (25%)]\tLoss: 0.127591\n",
      "Train Epoch: 2 [4000/11811 (34%)]\tLoss: 0.216492\n",
      "Train Epoch: 2 [5000/11811 (42%)]\tLoss: 0.100784\n",
      "Train Epoch: 2 [6000/11811 (50%)]\tLoss: 0.163959\n",
      "Train Epoch: 2 [7000/11811 (59%)]\tLoss: 0.185772\n",
      "Train Epoch: 2 [8000/11811 (67%)]\tLoss: 0.196748\n",
      "Train Epoch: 2 [9000/11811 (76%)]\tLoss: 0.113565\n",
      "Train Epoch: 2 [10000/11811 (84%)]\tLoss: 0.160559\n",
      "Train Epoch: 2 [11000/11811 (92%)]\tLoss: 0.138780\n",
      "Train Epoch: 3 [0/11811 (0%)]\tLoss: 0.130433\n",
      "Train Epoch: 3 [1000/11811 (8%)]\tLoss: 0.229907\n",
      "Train Epoch: 3 [2000/11811 (17%)]\tLoss: 0.102708\n",
      "Train Epoch: 3 [3000/11811 (25%)]\tLoss: 0.199943\n",
      "Train Epoch: 3 [4000/11811 (34%)]\tLoss: 0.195103\n",
      "Train Epoch: 3 [5000/11811 (42%)]\tLoss: 0.117289\n",
      "Train Epoch: 3 [6000/11811 (50%)]\tLoss: 0.196578\n",
      "Train Epoch: 3 [7000/11811 (59%)]\tLoss: 0.167614\n",
      "Train Epoch: 3 [8000/11811 (67%)]\tLoss: 0.199001\n",
      "Train Epoch: 3 [9000/11811 (76%)]\tLoss: 0.167984\n",
      "Train Epoch: 3 [10000/11811 (84%)]\tLoss: 0.274238\n",
      "Train Epoch: 3 [11000/11811 (92%)]\tLoss: 0.125294\n",
      "Train Epoch: 4 [0/11811 (0%)]\tLoss: 0.155895\n",
      "Train Epoch: 4 [1000/11811 (8%)]\tLoss: 0.112747\n",
      "Train Epoch: 4 [2000/11811 (17%)]\tLoss: 0.082950\n",
      "Train Epoch: 4 [3000/11811 (25%)]\tLoss: 0.227532\n",
      "Train Epoch: 4 [4000/11811 (34%)]\tLoss: 0.142849\n",
      "Train Epoch: 4 [5000/11811 (42%)]\tLoss: 0.383191\n",
      "Train Epoch: 4 [6000/11811 (50%)]\tLoss: 0.146969\n",
      "Train Epoch: 4 [7000/11811 (59%)]\tLoss: 0.237339\n",
      "Train Epoch: 4 [8000/11811 (67%)]\tLoss: 0.155358\n",
      "Train Epoch: 4 [9000/11811 (76%)]\tLoss: 0.192090\n",
      "Train Epoch: 4 [10000/11811 (84%)]\tLoss: 0.340122\n",
      "Train Epoch: 4 [11000/11811 (92%)]\tLoss: 0.206370\n",
      "Train Epoch: 5 [0/11811 (0%)]\tLoss: 0.233767\n",
      "Train Epoch: 5 [1000/11811 (8%)]\tLoss: 0.207628\n",
      "Train Epoch: 5 [2000/11811 (17%)]\tLoss: 0.165940\n",
      "Train Epoch: 5 [3000/11811 (25%)]\tLoss: 0.143711\n",
      "Train Epoch: 5 [4000/11811 (34%)]\tLoss: 0.196869\n",
      "Train Epoch: 5 [5000/11811 (42%)]\tLoss: 0.205511\n",
      "Train Epoch: 5 [6000/11811 (50%)]\tLoss: 0.210003\n",
      "Train Epoch: 5 [7000/11811 (59%)]\tLoss: 0.120958\n",
      "Train Epoch: 5 [8000/11811 (67%)]\tLoss: 0.182039\n",
      "Train Epoch: 5 [9000/11811 (76%)]\tLoss: 0.255035\n",
      "Train Epoch: 5 [10000/11811 (84%)]\tLoss: 0.254677\n",
      "Train Epoch: 5 [11000/11811 (92%)]\tLoss: 0.087519\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "6\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.2074, Accuracy: 7262/10000 (73%)\n",
      "\n",
      "Running experiment with 8 partitions...\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.463319\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 0.448740\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 0.799863\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 0.421515\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 0.580048\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 0.529757\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 0.623984\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 0.484032\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.482033\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 0.503485\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.378182\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 0.610751\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.422292\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 0.760568\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 0.393475\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.573708\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.495528\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 0.446145\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 0.331558\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 0.421663\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.588756\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 0.444059\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.444313\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 0.369636\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.598467\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.357379\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.498456\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 0.694134\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.535929\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 0.309429\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.461582\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 0.492671\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.627399\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 0.421922\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.382165\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.542381\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.459957\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 0.294587\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.568768\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 0.401824\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.476188\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 0.496599\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.490687\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 0.543168\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.618266\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.532483\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.464642\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 0.456311\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.402888\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 0.373541\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.518782\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 0.488092\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.475617\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 0.548602\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.552124\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.417980\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.611172\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 0.468834\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.468065\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 0.533529\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.489366\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 0.508506\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.465940\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 0.364273\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.469016\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.385658\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.505262\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 0.379104\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.402133\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 0.587690\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.712270\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 0.535054\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.554227\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 0.588699\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.444458\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.557643\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.588015\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 0.443991\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.509314\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 0.657828\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.414502\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 0.449206\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.429619\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 0.422355\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.398345\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.397386\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.509061\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 0.445392\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.538725\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 0.578807\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.585303\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 0.503551\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.493939\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 0.384347\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.429363\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.515881\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.433881\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 0.507004\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.452860\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 0.523221\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.379442\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 0.507170\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.603990\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 0.601707\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.457669\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.454375\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.457533\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 0.447167\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.467507\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 0.480422\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.315195\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 0.372701\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.352393\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 0.601685\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.423497\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.501773\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.616742\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 0.534293\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.440794\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 0.436711\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.396821\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 0.347690\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.458836\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 0.404128\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.454948\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.487435\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.522825\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 0.446768\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.451130\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 0.496917\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.508237\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 0.378522\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.516973\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 0.432297\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.622419\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.586486\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.404564\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 0.511347\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.299728\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 0.350775\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.382934\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 0.604079\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.343878\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 0.473354\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.372092\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.541246\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.453353\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 0.459504\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.460012\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 0.629028\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.581193\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 0.514129\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.422415\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 0.377813\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.729072\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.447473\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.442993\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 0.663414\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.531156\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 0.499875\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.505316\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 0.492432\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.460695\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 0.463580\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.466567\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.501492\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.396347\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 0.428470\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.386868\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 0.543846\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.624966\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 0.601837\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.410716\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 0.380651\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.495827\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.418808\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.459977\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 0.537272\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.455505\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 0.434230\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.474360\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 0.354521\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.511765\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 0.282042\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.360516\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.504699\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.475633\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 0.409609\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.589575\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 0.517663\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.542242\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 0.448403\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.452877\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 0.484526\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.351143\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.432336\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.567349\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 0.527482\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.448483\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 0.437341\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.494906\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 0.563970\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.340283\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 0.371039\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.338838\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.399426\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.498282\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 0.445605\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.418112\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 0.661631\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.610376\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 0.508865\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.375173\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 0.449486\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.485913\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.385081\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.416044\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 0.387555\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.692825\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 0.678739\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.464682\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 0.453378\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.295728\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 0.447304\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.362855\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.550161\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.369370\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 0.511881\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.427929\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 0.399807\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.372795\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 0.499768\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.404340\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 0.607822\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.451972\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.347732\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.463077\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 0.382009\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.513457\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 0.318182\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.463813\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 0.431573\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.467802\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 0.300929\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.327816\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.662133\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.494830\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 0.750647\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.350364\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 0.442747\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.404975\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 0.498646\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.534179\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 0.365160\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.388920\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.396279\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.400068\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 0.357123\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.497541\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 0.356972\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.372108\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 0.379673\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.353210\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 0.540141\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.349030\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.525648\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.441153\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 0.397893\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.483193\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 0.620262\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.675421\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 0.530125\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.460883\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 0.509459\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.492803\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.501788\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.391099\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 0.438922\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.394956\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 0.405018\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.406811\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 0.400588\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.537312\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 0.571580\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.485655\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.437029\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.387945\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 0.496373\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.409240\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 0.576632\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.562659\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 0.353917\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.425265\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 0.552018\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.433884\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.400187\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.343816\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 0.641867\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.461768\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 0.515984\n",
      "\n",
      "Test set: Avg. loss: 0.4481, Accuracy: 50333/60000 (84%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/7731 (0%)]\tLoss: 0.653611\n",
      "Train Epoch: 1 [1000/7731 (13%)]\tLoss: 0.345706\n",
      "Train Epoch: 1 [2000/7731 (26%)]\tLoss: 0.268131\n",
      "Train Epoch: 1 [3000/7731 (38%)]\tLoss: 0.250986\n",
      "Train Epoch: 1 [4000/7731 (51%)]\tLoss: 0.373565\n",
      "Train Epoch: 1 [5000/7731 (64%)]\tLoss: 0.402889\n",
      "Train Epoch: 1 [6000/7731 (77%)]\tLoss: 0.372712\n",
      "Train Epoch: 1 [7000/7731 (90%)]\tLoss: 0.296451\n",
      "Train Epoch: 2 [0/7731 (0%)]\tLoss: 0.471632\n",
      "Train Epoch: 2 [1000/7731 (13%)]\tLoss: 0.352355\n",
      "Train Epoch: 2 [2000/7731 (26%)]\tLoss: 0.272283\n",
      "Train Epoch: 2 [3000/7731 (38%)]\tLoss: 0.383294\n",
      "Train Epoch: 2 [4000/7731 (51%)]\tLoss: 0.194089\n",
      "Train Epoch: 2 [5000/7731 (64%)]\tLoss: 0.272295\n",
      "Train Epoch: 2 [6000/7731 (77%)]\tLoss: 0.255457\n",
      "Train Epoch: 2 [7000/7731 (90%)]\tLoss: 0.343604\n",
      "Train Epoch: 3 [0/7731 (0%)]\tLoss: 0.297940\n",
      "Train Epoch: 3 [1000/7731 (13%)]\tLoss: 0.308604\n",
      "Train Epoch: 3 [2000/7731 (26%)]\tLoss: 0.340999\n",
      "Train Epoch: 3 [3000/7731 (38%)]\tLoss: 0.461660\n",
      "Train Epoch: 3 [4000/7731 (51%)]\tLoss: 0.252889\n",
      "Train Epoch: 3 [5000/7731 (64%)]\tLoss: 0.337160\n",
      "Train Epoch: 3 [6000/7731 (77%)]\tLoss: 0.224862\n",
      "Train Epoch: 3 [7000/7731 (90%)]\tLoss: 0.279137\n",
      "Train Epoch: 4 [0/7731 (0%)]\tLoss: 0.239461\n",
      "Train Epoch: 4 [1000/7731 (13%)]\tLoss: 0.206227\n",
      "Train Epoch: 4 [2000/7731 (26%)]\tLoss: 0.331233\n",
      "Train Epoch: 4 [3000/7731 (38%)]\tLoss: 0.299198\n",
      "Train Epoch: 4 [4000/7731 (51%)]\tLoss: 0.151294\n",
      "Train Epoch: 4 [5000/7731 (64%)]\tLoss: 0.311278\n",
      "Train Epoch: 4 [6000/7731 (77%)]\tLoss: 0.316429\n",
      "Train Epoch: 4 [7000/7731 (90%)]\tLoss: 0.310924\n",
      "Train Epoch: 5 [0/7731 (0%)]\tLoss: 0.270502\n",
      "Train Epoch: 5 [1000/7731 (13%)]\tLoss: 0.375160\n",
      "Train Epoch: 5 [2000/7731 (26%)]\tLoss: 0.286390\n",
      "Train Epoch: 5 [3000/7731 (38%)]\tLoss: 0.289492\n",
      "Train Epoch: 5 [4000/7731 (51%)]\tLoss: 0.475214\n",
      "Train Epoch: 5 [5000/7731 (64%)]\tLoss: 0.209334\n",
      "Train Epoch: 5 [6000/7731 (77%)]\tLoss: 0.287357\n",
      "Train Epoch: 5 [7000/7731 (90%)]\tLoss: 0.257548\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11194 (0%)]\tLoss: 0.529349\n",
      "Train Epoch: 1 [1000/11194 (9%)]\tLoss: 0.380751\n",
      "Train Epoch: 1 [2000/11194 (18%)]\tLoss: 0.454846\n",
      "Train Epoch: 1 [3000/11194 (27%)]\tLoss: 0.374068\n",
      "Train Epoch: 1 [4000/11194 (36%)]\tLoss: 0.260117\n",
      "Train Epoch: 1 [5000/11194 (45%)]\tLoss: 0.324838\n",
      "Train Epoch: 1 [6000/11194 (54%)]\tLoss: 0.221326\n",
      "Train Epoch: 1 [7000/11194 (62%)]\tLoss: 0.385431\n",
      "Train Epoch: 1 [8000/11194 (71%)]\tLoss: 0.356597\n",
      "Train Epoch: 1 [9000/11194 (80%)]\tLoss: 0.306386\n",
      "Train Epoch: 1 [10000/11194 (89%)]\tLoss: 0.438180\n",
      "Train Epoch: 1 [11000/11194 (98%)]\tLoss: 0.462586\n",
      "Train Epoch: 2 [0/11194 (0%)]\tLoss: 0.249932\n",
      "Train Epoch: 2 [1000/11194 (9%)]\tLoss: 0.307323\n",
      "Train Epoch: 2 [2000/11194 (18%)]\tLoss: 0.250991\n",
      "Train Epoch: 2 [3000/11194 (27%)]\tLoss: 0.332100\n",
      "Train Epoch: 2 [4000/11194 (36%)]\tLoss: 0.321277\n",
      "Train Epoch: 2 [5000/11194 (45%)]\tLoss: 0.690943\n",
      "Train Epoch: 2 [6000/11194 (54%)]\tLoss: 0.315518\n",
      "Train Epoch: 2 [7000/11194 (62%)]\tLoss: 0.293646\n",
      "Train Epoch: 2 [8000/11194 (71%)]\tLoss: 0.308351\n",
      "Train Epoch: 2 [9000/11194 (80%)]\tLoss: 0.319249\n",
      "Train Epoch: 2 [10000/11194 (89%)]\tLoss: 0.275422\n",
      "Train Epoch: 2 [11000/11194 (98%)]\tLoss: 0.336881\n",
      "Train Epoch: 3 [0/11194 (0%)]\tLoss: 0.327282\n",
      "Train Epoch: 3 [1000/11194 (9%)]\tLoss: 0.289313\n",
      "Train Epoch: 3 [2000/11194 (18%)]\tLoss: 0.237206\n",
      "Train Epoch: 3 [3000/11194 (27%)]\tLoss: 0.262087\n",
      "Train Epoch: 3 [4000/11194 (36%)]\tLoss: 0.390022\n",
      "Train Epoch: 3 [5000/11194 (45%)]\tLoss: 0.308260\n",
      "Train Epoch: 3 [6000/11194 (54%)]\tLoss: 0.387663\n",
      "Train Epoch: 3 [7000/11194 (62%)]\tLoss: 0.260052\n",
      "Train Epoch: 3 [8000/11194 (71%)]\tLoss: 0.301186\n",
      "Train Epoch: 3 [9000/11194 (80%)]\tLoss: 0.236293\n",
      "Train Epoch: 3 [10000/11194 (89%)]\tLoss: 0.473135\n",
      "Train Epoch: 3 [11000/11194 (98%)]\tLoss: 0.259264\n",
      "Train Epoch: 4 [0/11194 (0%)]\tLoss: 0.330648\n",
      "Train Epoch: 4 [1000/11194 (9%)]\tLoss: 0.275349\n",
      "Train Epoch: 4 [2000/11194 (18%)]\tLoss: 0.359674\n",
      "Train Epoch: 4 [3000/11194 (27%)]\tLoss: 0.183066\n",
      "Train Epoch: 4 [4000/11194 (36%)]\tLoss: 0.257660\n",
      "Train Epoch: 4 [5000/11194 (45%)]\tLoss: 0.401985\n",
      "Train Epoch: 4 [6000/11194 (54%)]\tLoss: 0.284701\n",
      "Train Epoch: 4 [7000/11194 (62%)]\tLoss: 0.281253\n",
      "Train Epoch: 4 [8000/11194 (71%)]\tLoss: 0.282353\n",
      "Train Epoch: 4 [9000/11194 (80%)]\tLoss: 0.329593\n",
      "Train Epoch: 4 [10000/11194 (89%)]\tLoss: 0.345922\n",
      "Train Epoch: 4 [11000/11194 (98%)]\tLoss: 0.311609\n",
      "Train Epoch: 5 [0/11194 (0%)]\tLoss: 0.476692\n",
      "Train Epoch: 5 [1000/11194 (9%)]\tLoss: 0.217816\n",
      "Train Epoch: 5 [2000/11194 (18%)]\tLoss: 0.329732\n",
      "Train Epoch: 5 [3000/11194 (27%)]\tLoss: 0.248859\n",
      "Train Epoch: 5 [4000/11194 (36%)]\tLoss: 0.269498\n",
      "Train Epoch: 5 [5000/11194 (45%)]\tLoss: 0.250236\n",
      "Train Epoch: 5 [6000/11194 (54%)]\tLoss: 0.252947\n",
      "Train Epoch: 5 [7000/11194 (62%)]\tLoss: 0.308406\n",
      "Train Epoch: 5 [8000/11194 (71%)]\tLoss: 0.398857\n",
      "Train Epoch: 5 [9000/11194 (80%)]\tLoss: 0.284001\n",
      "Train Epoch: 5 [10000/11194 (89%)]\tLoss: 0.206465\n",
      "Train Epoch: 5 [11000/11194 (98%)]\tLoss: 0.366009\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/7891 (0%)]\tLoss: 0.436836\n",
      "Train Epoch: 1 [1000/7891 (13%)]\tLoss: 0.380330\n",
      "Train Epoch: 1 [2000/7891 (25%)]\tLoss: 0.310224\n",
      "Train Epoch: 1 [3000/7891 (38%)]\tLoss: 0.276008\n",
      "Train Epoch: 1 [4000/7891 (51%)]\tLoss: 0.295902\n",
      "Train Epoch: 1 [5000/7891 (63%)]\tLoss: 0.317788\n",
      "Train Epoch: 1 [6000/7891 (76%)]\tLoss: 0.246992\n",
      "Train Epoch: 1 [7000/7891 (89%)]\tLoss: 0.271219\n",
      "Train Epoch: 2 [0/7891 (0%)]\tLoss: 0.344667\n",
      "Train Epoch: 2 [1000/7891 (13%)]\tLoss: 0.169620\n",
      "Train Epoch: 2 [2000/7891 (25%)]\tLoss: 0.239943\n",
      "Train Epoch: 2 [3000/7891 (38%)]\tLoss: 0.190049\n",
      "Train Epoch: 2 [4000/7891 (51%)]\tLoss: 0.263842\n",
      "Train Epoch: 2 [5000/7891 (63%)]\tLoss: 0.246556\n",
      "Train Epoch: 2 [6000/7891 (76%)]\tLoss: 0.145855\n",
      "Train Epoch: 2 [7000/7891 (89%)]\tLoss: 0.325892\n",
      "Train Epoch: 3 [0/7891 (0%)]\tLoss: 0.248287\n",
      "Train Epoch: 3 [1000/7891 (13%)]\tLoss: 0.330368\n",
      "Train Epoch: 3 [2000/7891 (25%)]\tLoss: 0.268786\n",
      "Train Epoch: 3 [3000/7891 (38%)]\tLoss: 0.318590\n",
      "Train Epoch: 3 [4000/7891 (51%)]\tLoss: 0.259305\n",
      "Train Epoch: 3 [5000/7891 (63%)]\tLoss: 0.179985\n",
      "Train Epoch: 3 [6000/7891 (76%)]\tLoss: 0.287863\n",
      "Train Epoch: 3 [7000/7891 (89%)]\tLoss: 0.333694\n",
      "Train Epoch: 4 [0/7891 (0%)]\tLoss: 0.250461\n",
      "Train Epoch: 4 [1000/7891 (13%)]\tLoss: 0.277949\n",
      "Train Epoch: 4 [2000/7891 (25%)]\tLoss: 0.243717\n",
      "Train Epoch: 4 [3000/7891 (38%)]\tLoss: 0.152541\n",
      "Train Epoch: 4 [4000/7891 (51%)]\tLoss: 0.211145\n",
      "Train Epoch: 4 [5000/7891 (63%)]\tLoss: 0.148126\n",
      "Train Epoch: 4 [6000/7891 (76%)]\tLoss: 0.191191\n",
      "Train Epoch: 4 [7000/7891 (89%)]\tLoss: 0.289799\n",
      "Train Epoch: 5 [0/7891 (0%)]\tLoss: 0.257196\n",
      "Train Epoch: 5 [1000/7891 (13%)]\tLoss: 0.232849\n",
      "Train Epoch: 5 [2000/7891 (25%)]\tLoss: 0.241171\n",
      "Train Epoch: 5 [3000/7891 (38%)]\tLoss: 0.187854\n",
      "Train Epoch: 5 [4000/7891 (51%)]\tLoss: 0.165630\n",
      "Train Epoch: 5 [5000/7891 (63%)]\tLoss: 0.272570\n",
      "Train Epoch: 5 [6000/7891 (76%)]\tLoss: 0.221032\n",
      "Train Epoch: 5 [7000/7891 (89%)]\tLoss: 0.177114\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/3053 (0%)]\tLoss: 0.412148\n",
      "Train Epoch: 1 [1000/3053 (32%)]\tLoss: 0.250643\n",
      "Train Epoch: 1 [2000/3053 (65%)]\tLoss: 0.276140\n",
      "Train Epoch: 1 [1590/3053 (97%)]\tLoss: 0.279775\n",
      "Train Epoch: 2 [0/3053 (0%)]\tLoss: 0.227381\n",
      "Train Epoch: 2 [1000/3053 (32%)]\tLoss: 0.322834\n",
      "Train Epoch: 2 [2000/3053 (65%)]\tLoss: 0.316955\n",
      "Train Epoch: 2 [1590/3053 (97%)]\tLoss: 0.273131\n",
      "Train Epoch: 3 [0/3053 (0%)]\tLoss: 0.240107\n",
      "Train Epoch: 3 [1000/3053 (32%)]\tLoss: 0.124806\n",
      "Train Epoch: 3 [2000/3053 (65%)]\tLoss: 0.288575\n",
      "Train Epoch: 3 [1590/3053 (97%)]\tLoss: 0.360503\n",
      "Train Epoch: 4 [0/3053 (0%)]\tLoss: 0.338210\n",
      "Train Epoch: 4 [1000/3053 (32%)]\tLoss: 0.161206\n",
      "Train Epoch: 4 [2000/3053 (65%)]\tLoss: 0.178774\n",
      "Train Epoch: 4 [1590/3053 (97%)]\tLoss: 0.355397\n",
      "Train Epoch: 5 [0/3053 (0%)]\tLoss: 0.200942\n",
      "Train Epoch: 5 [1000/3053 (32%)]\tLoss: 0.266240\n",
      "Train Epoch: 5 [2000/3053 (65%)]\tLoss: 0.140333\n",
      "Train Epoch: 5 [1590/3053 (97%)]\tLoss: 0.183052\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/9145 (0%)]\tLoss: 0.501520\n",
      "Train Epoch: 1 [1000/9145 (11%)]\tLoss: 0.483120\n",
      "Train Epoch: 1 [2000/9145 (22%)]\tLoss: 0.334271\n",
      "Train Epoch: 1 [3000/9145 (33%)]\tLoss: 0.448643\n",
      "Train Epoch: 1 [4000/9145 (43%)]\tLoss: 0.330071\n",
      "Train Epoch: 1 [5000/9145 (54%)]\tLoss: 0.245173\n",
      "Train Epoch: 1 [6000/9145 (65%)]\tLoss: 0.414200\n",
      "Train Epoch: 1 [7000/9145 (76%)]\tLoss: 0.445087\n",
      "Train Epoch: 1 [8000/9145 (87%)]\tLoss: 0.365220\n",
      "Train Epoch: 1 [9000/9145 (98%)]\tLoss: 0.365204\n",
      "Train Epoch: 2 [0/9145 (0%)]\tLoss: 0.305087\n",
      "Train Epoch: 2 [1000/9145 (11%)]\tLoss: 0.262709\n",
      "Train Epoch: 2 [2000/9145 (22%)]\tLoss: 0.396277\n",
      "Train Epoch: 2 [3000/9145 (33%)]\tLoss: 0.346449\n",
      "Train Epoch: 2 [4000/9145 (43%)]\tLoss: 0.318189\n",
      "Train Epoch: 2 [5000/9145 (54%)]\tLoss: 0.365038\n",
      "Train Epoch: 2 [6000/9145 (65%)]\tLoss: 0.395221\n",
      "Train Epoch: 2 [7000/9145 (76%)]\tLoss: 0.415516\n",
      "Train Epoch: 2 [8000/9145 (87%)]\tLoss: 0.460509\n",
      "Train Epoch: 2 [9000/9145 (98%)]\tLoss: 0.290144\n",
      "Train Epoch: 3 [0/9145 (0%)]\tLoss: 0.374600\n",
      "Train Epoch: 3 [1000/9145 (11%)]\tLoss: 0.353969\n",
      "Train Epoch: 3 [2000/9145 (22%)]\tLoss: 0.336141\n",
      "Train Epoch: 3 [3000/9145 (33%)]\tLoss: 0.420083\n",
      "Train Epoch: 3 [4000/9145 (43%)]\tLoss: 0.257795\n",
      "Train Epoch: 3 [5000/9145 (54%)]\tLoss: 0.196673\n",
      "Train Epoch: 3 [6000/9145 (65%)]\tLoss: 0.290830\n",
      "Train Epoch: 3 [7000/9145 (76%)]\tLoss: 0.194049\n",
      "Train Epoch: 3 [8000/9145 (87%)]\tLoss: 0.410605\n",
      "Train Epoch: 3 [9000/9145 (98%)]\tLoss: 0.378193\n",
      "Train Epoch: 4 [0/9145 (0%)]\tLoss: 0.300096\n",
      "Train Epoch: 4 [1000/9145 (11%)]\tLoss: 0.329420\n",
      "Train Epoch: 4 [2000/9145 (22%)]\tLoss: 0.351443\n",
      "Train Epoch: 4 [3000/9145 (33%)]\tLoss: 0.471269\n",
      "Train Epoch: 4 [4000/9145 (43%)]\tLoss: 0.356725\n",
      "Train Epoch: 4 [5000/9145 (54%)]\tLoss: 0.399431\n",
      "Train Epoch: 4 [6000/9145 (65%)]\tLoss: 0.281761\n",
      "Train Epoch: 4 [7000/9145 (76%)]\tLoss: 0.358185\n",
      "Train Epoch: 4 [8000/9145 (87%)]\tLoss: 0.327494\n",
      "Train Epoch: 4 [9000/9145 (98%)]\tLoss: 0.297222\n",
      "Train Epoch: 5 [0/9145 (0%)]\tLoss: 0.258902\n",
      "Train Epoch: 5 [1000/9145 (11%)]\tLoss: 0.364502\n",
      "Train Epoch: 5 [2000/9145 (22%)]\tLoss: 0.363844\n",
      "Train Epoch: 5 [3000/9145 (33%)]\tLoss: 0.259489\n",
      "Train Epoch: 5 [4000/9145 (43%)]\tLoss: 0.315887\n",
      "Train Epoch: 5 [5000/9145 (54%)]\tLoss: 0.371425\n",
      "Train Epoch: 5 [6000/9145 (65%)]\tLoss: 0.317493\n",
      "Train Epoch: 5 [7000/9145 (76%)]\tLoss: 0.256272\n",
      "Train Epoch: 5 [8000/9145 (87%)]\tLoss: 0.258217\n",
      "Train Epoch: 5 [9000/9145 (98%)]\tLoss: 0.380759\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3021 (0%)]\tLoss: 0.391002\n",
      "Train Epoch: 1 [1000/3021 (32%)]\tLoss: 0.289711\n",
      "Train Epoch: 1 [2000/3021 (65%)]\tLoss: 0.477497\n",
      "Train Epoch: 1 [630/3021 (97%)]\tLoss: 0.393033\n",
      "Train Epoch: 2 [0/3021 (0%)]\tLoss: 0.418932\n",
      "Train Epoch: 2 [1000/3021 (32%)]\tLoss: 0.254864\n",
      "Train Epoch: 2 [2000/3021 (65%)]\tLoss: 0.252318\n",
      "Train Epoch: 2 [630/3021 (97%)]\tLoss: 0.210584\n",
      "Train Epoch: 3 [0/3021 (0%)]\tLoss: 0.201509\n",
      "Train Epoch: 3 [1000/3021 (32%)]\tLoss: 0.322974\n",
      "Train Epoch: 3 [2000/3021 (65%)]\tLoss: 0.269777\n",
      "Train Epoch: 3 [630/3021 (97%)]\tLoss: 0.354694\n",
      "Train Epoch: 4 [0/3021 (0%)]\tLoss: 0.228939\n",
      "Train Epoch: 4 [1000/3021 (32%)]\tLoss: 0.345463\n",
      "Train Epoch: 4 [2000/3021 (65%)]\tLoss: 0.255824\n",
      "Train Epoch: 4 [630/3021 (97%)]\tLoss: 0.119034\n",
      "Train Epoch: 5 [0/3021 (0%)]\tLoss: 0.281217\n",
      "Train Epoch: 5 [1000/3021 (32%)]\tLoss: 0.237412\n",
      "Train Epoch: 5 [2000/3021 (65%)]\tLoss: 0.281724\n",
      "Train Epoch: 5 [630/3021 (97%)]\tLoss: 0.101427\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/7953 (0%)]\tLoss: 0.524757\n",
      "Train Epoch: 1 [1000/7953 (12%)]\tLoss: 0.531218\n",
      "Train Epoch: 1 [2000/7953 (25%)]\tLoss: 0.512038\n",
      "Train Epoch: 1 [3000/7953 (38%)]\tLoss: 0.562205\n",
      "Train Epoch: 1 [4000/7953 (50%)]\tLoss: 0.597728\n",
      "Train Epoch: 1 [5000/7953 (62%)]\tLoss: 0.577762\n",
      "Train Epoch: 1 [6000/7953 (75%)]\tLoss: 0.543333\n",
      "Train Epoch: 1 [7000/7953 (88%)]\tLoss: 0.454291\n",
      "Train Epoch: 2 [0/7953 (0%)]\tLoss: 0.448043\n",
      "Train Epoch: 2 [1000/7953 (12%)]\tLoss: 0.604331\n",
      "Train Epoch: 2 [2000/7953 (25%)]\tLoss: 0.633245\n",
      "Train Epoch: 2 [3000/7953 (38%)]\tLoss: 0.512648\n",
      "Train Epoch: 2 [4000/7953 (50%)]\tLoss: 0.479690\n",
      "Train Epoch: 2 [5000/7953 (62%)]\tLoss: 0.460235\n",
      "Train Epoch: 2 [6000/7953 (75%)]\tLoss: 0.582473\n",
      "Train Epoch: 2 [7000/7953 (88%)]\tLoss: 0.496022\n",
      "Train Epoch: 3 [0/7953 (0%)]\tLoss: 0.397665\n",
      "Train Epoch: 3 [1000/7953 (12%)]\tLoss: 0.536879\n",
      "Train Epoch: 3 [2000/7953 (25%)]\tLoss: 0.490314\n",
      "Train Epoch: 3 [3000/7953 (38%)]\tLoss: 0.466358\n",
      "Train Epoch: 3 [4000/7953 (50%)]\tLoss: 0.462830\n",
      "Train Epoch: 3 [5000/7953 (62%)]\tLoss: 0.606857\n",
      "Train Epoch: 3 [6000/7953 (75%)]\tLoss: 0.405896\n",
      "Train Epoch: 3 [7000/7953 (88%)]\tLoss: 0.506300\n",
      "Train Epoch: 4 [0/7953 (0%)]\tLoss: 0.403559\n",
      "Train Epoch: 4 [1000/7953 (12%)]\tLoss: 0.440905\n",
      "Train Epoch: 4 [2000/7953 (25%)]\tLoss: 0.426741\n",
      "Train Epoch: 4 [3000/7953 (38%)]\tLoss: 0.491955\n",
      "Train Epoch: 4 [4000/7953 (50%)]\tLoss: 0.462228\n",
      "Train Epoch: 4 [5000/7953 (62%)]\tLoss: 0.441875\n",
      "Train Epoch: 4 [6000/7953 (75%)]\tLoss: 0.660137\n",
      "Train Epoch: 4 [7000/7953 (88%)]\tLoss: 0.479349\n",
      "Train Epoch: 5 [0/7953 (0%)]\tLoss: 0.602722\n",
      "Train Epoch: 5 [1000/7953 (12%)]\tLoss: 0.619783\n",
      "Train Epoch: 5 [2000/7953 (25%)]\tLoss: 0.545713\n",
      "Train Epoch: 5 [3000/7953 (38%)]\tLoss: 0.711476\n",
      "Train Epoch: 5 [4000/7953 (50%)]\tLoss: 0.509982\n",
      "Train Epoch: 5 [5000/7953 (62%)]\tLoss: 0.475047\n",
      "Train Epoch: 5 [6000/7953 (75%)]\tLoss: 0.486041\n",
      "Train Epoch: 5 [7000/7953 (88%)]\tLoss: 0.458179\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/10012 (0%)]\tLoss: 0.471332\n",
      "Train Epoch: 1 [1000/10012 (10%)]\tLoss: 0.293474\n",
      "Train Epoch: 1 [2000/10012 (20%)]\tLoss: 0.374514\n",
      "Train Epoch: 1 [3000/10012 (30%)]\tLoss: 0.389569\n",
      "Train Epoch: 1 [4000/10012 (40%)]\tLoss: 0.247891\n",
      "Train Epoch: 1 [5000/10012 (50%)]\tLoss: 0.191936\n",
      "Train Epoch: 1 [6000/10012 (59%)]\tLoss: 0.396983\n",
      "Train Epoch: 1 [7000/10012 (69%)]\tLoss: 0.173544\n",
      "Train Epoch: 1 [8000/10012 (79%)]\tLoss: 0.238915\n",
      "Train Epoch: 1 [9000/10012 (89%)]\tLoss: 0.244652\n",
      "Train Epoch: 1 [1200/10012 (99%)]\tLoss: 0.431548\n",
      "Train Epoch: 2 [0/10012 (0%)]\tLoss: 0.185095\n",
      "Train Epoch: 2 [1000/10012 (10%)]\tLoss: 0.183846\n",
      "Train Epoch: 2 [2000/10012 (20%)]\tLoss: 0.145439\n",
      "Train Epoch: 2 [3000/10012 (30%)]\tLoss: 0.345861\n",
      "Train Epoch: 2 [4000/10012 (40%)]\tLoss: 0.252378\n",
      "Train Epoch: 2 [5000/10012 (50%)]\tLoss: 0.315901\n",
      "Train Epoch: 2 [6000/10012 (59%)]\tLoss: 0.261807\n",
      "Train Epoch: 2 [7000/10012 (69%)]\tLoss: 0.299827\n",
      "Train Epoch: 2 [8000/10012 (79%)]\tLoss: 0.149044\n",
      "Train Epoch: 2 [9000/10012 (89%)]\tLoss: 0.186508\n",
      "Train Epoch: 2 [1200/10012 (99%)]\tLoss: 0.200011\n",
      "Train Epoch: 3 [0/10012 (0%)]\tLoss: 0.366071\n",
      "Train Epoch: 3 [1000/10012 (10%)]\tLoss: 0.257000\n",
      "Train Epoch: 3 [2000/10012 (20%)]\tLoss: 0.309707\n",
      "Train Epoch: 3 [3000/10012 (30%)]\tLoss: 0.215052\n",
      "Train Epoch: 3 [4000/10012 (40%)]\tLoss: 0.274810\n",
      "Train Epoch: 3 [5000/10012 (50%)]\tLoss: 0.133951\n",
      "Train Epoch: 3 [6000/10012 (59%)]\tLoss: 0.195419\n",
      "Train Epoch: 3 [7000/10012 (69%)]\tLoss: 0.171037\n",
      "Train Epoch: 3 [8000/10012 (79%)]\tLoss: 0.171809\n",
      "Train Epoch: 3 [9000/10012 (89%)]\tLoss: 0.134968\n",
      "Train Epoch: 3 [1200/10012 (99%)]\tLoss: 0.213836\n",
      "Train Epoch: 4 [0/10012 (0%)]\tLoss: 0.184646\n",
      "Train Epoch: 4 [1000/10012 (10%)]\tLoss: 0.265750\n",
      "Train Epoch: 4 [2000/10012 (20%)]\tLoss: 0.238479\n",
      "Train Epoch: 4 [3000/10012 (30%)]\tLoss: 0.349797\n",
      "Train Epoch: 4 [4000/10012 (40%)]\tLoss: 0.163440\n",
      "Train Epoch: 4 [5000/10012 (50%)]\tLoss: 0.230110\n",
      "Train Epoch: 4 [6000/10012 (59%)]\tLoss: 0.208631\n",
      "Train Epoch: 4 [7000/10012 (69%)]\tLoss: 0.262638\n",
      "Train Epoch: 4 [8000/10012 (79%)]\tLoss: 0.150299\n",
      "Train Epoch: 4 [9000/10012 (89%)]\tLoss: 0.394779\n",
      "Train Epoch: 4 [1200/10012 (99%)]\tLoss: 0.220647\n",
      "Train Epoch: 5 [0/10012 (0%)]\tLoss: 0.337169\n",
      "Train Epoch: 5 [1000/10012 (10%)]\tLoss: 0.304313\n",
      "Train Epoch: 5 [2000/10012 (20%)]\tLoss: 0.167939\n",
      "Train Epoch: 5 [3000/10012 (30%)]\tLoss: 0.219387\n",
      "Train Epoch: 5 [4000/10012 (40%)]\tLoss: 0.166556\n",
      "Train Epoch: 5 [5000/10012 (50%)]\tLoss: 0.157427\n",
      "Train Epoch: 5 [6000/10012 (59%)]\tLoss: 0.171505\n",
      "Train Epoch: 5 [7000/10012 (69%)]\tLoss: 0.192585\n",
      "Train Epoch: 5 [8000/10012 (79%)]\tLoss: 0.205328\n",
      "Train Epoch: 5 [9000/10012 (89%)]\tLoss: 0.213148\n",
      "Train Epoch: 5 [1200/10012 (99%)]\tLoss: 0.090839\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "8\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9875, Accuracy: 7580/10000 (76%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/7731 (0%)]\tLoss: 0.305378\n",
      "Train Epoch: 1 [1000/7731 (13%)]\tLoss: 0.232958\n",
      "Train Epoch: 1 [2000/7731 (26%)]\tLoss: 0.433391\n",
      "Train Epoch: 1 [3000/7731 (38%)]\tLoss: 0.262296\n",
      "Train Epoch: 1 [4000/7731 (51%)]\tLoss: 0.327784\n",
      "Train Epoch: 1 [5000/7731 (64%)]\tLoss: 0.178750\n",
      "Train Epoch: 1 [6000/7731 (77%)]\tLoss: 0.287960\n",
      "Train Epoch: 1 [7000/7731 (90%)]\tLoss: 0.254944\n",
      "Train Epoch: 2 [0/7731 (0%)]\tLoss: 0.304088\n",
      "Train Epoch: 2 [1000/7731 (13%)]\tLoss: 0.289014\n",
      "Train Epoch: 2 [2000/7731 (26%)]\tLoss: 0.242768\n",
      "Train Epoch: 2 [3000/7731 (38%)]\tLoss: 0.369557\n",
      "Train Epoch: 2 [4000/7731 (51%)]\tLoss: 0.379942\n",
      "Train Epoch: 2 [5000/7731 (64%)]\tLoss: 0.401457\n",
      "Train Epoch: 2 [6000/7731 (77%)]\tLoss: 0.280892\n",
      "Train Epoch: 2 [7000/7731 (90%)]\tLoss: 0.273203\n",
      "Train Epoch: 3 [0/7731 (0%)]\tLoss: 0.266955\n",
      "Train Epoch: 3 [1000/7731 (13%)]\tLoss: 0.381633\n",
      "Train Epoch: 3 [2000/7731 (26%)]\tLoss: 0.330860\n",
      "Train Epoch: 3 [3000/7731 (38%)]\tLoss: 0.277925\n",
      "Train Epoch: 3 [4000/7731 (51%)]\tLoss: 0.185707\n",
      "Train Epoch: 3 [5000/7731 (64%)]\tLoss: 0.348197\n",
      "Train Epoch: 3 [6000/7731 (77%)]\tLoss: 0.305572\n",
      "Train Epoch: 3 [7000/7731 (90%)]\tLoss: 0.241477\n",
      "Train Epoch: 4 [0/7731 (0%)]\tLoss: 0.161339\n",
      "Train Epoch: 4 [1000/7731 (13%)]\tLoss: 0.370326\n",
      "Train Epoch: 4 [2000/7731 (26%)]\tLoss: 0.193117\n",
      "Train Epoch: 4 [3000/7731 (38%)]\tLoss: 0.255957\n",
      "Train Epoch: 4 [4000/7731 (51%)]\tLoss: 0.223607\n",
      "Train Epoch: 4 [5000/7731 (64%)]\tLoss: 0.278495\n",
      "Train Epoch: 4 [6000/7731 (77%)]\tLoss: 0.366701\n",
      "Train Epoch: 4 [7000/7731 (90%)]\tLoss: 0.399613\n",
      "Train Epoch: 5 [0/7731 (0%)]\tLoss: 0.370857\n",
      "Train Epoch: 5 [1000/7731 (13%)]\tLoss: 0.303544\n",
      "Train Epoch: 5 [2000/7731 (26%)]\tLoss: 0.255370\n",
      "Train Epoch: 5 [3000/7731 (38%)]\tLoss: 0.364716\n",
      "Train Epoch: 5 [4000/7731 (51%)]\tLoss: 0.179197\n",
      "Train Epoch: 5 [5000/7731 (64%)]\tLoss: 0.218715\n",
      "Train Epoch: 5 [6000/7731 (77%)]\tLoss: 0.270396\n",
      "Train Epoch: 5 [7000/7731 (90%)]\tLoss: 0.258710\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11194 (0%)]\tLoss: 0.487059\n",
      "Train Epoch: 1 [1000/11194 (9%)]\tLoss: 0.228935\n",
      "Train Epoch: 1 [2000/11194 (18%)]\tLoss: 0.456915\n",
      "Train Epoch: 1 [3000/11194 (27%)]\tLoss: 0.411852\n",
      "Train Epoch: 1 [4000/11194 (36%)]\tLoss: 0.313517\n",
      "Train Epoch: 1 [5000/11194 (45%)]\tLoss: 0.401336\n",
      "Train Epoch: 1 [6000/11194 (54%)]\tLoss: 0.400242\n",
      "Train Epoch: 1 [7000/11194 (62%)]\tLoss: 0.312779\n",
      "Train Epoch: 1 [8000/11194 (71%)]\tLoss: 0.292503\n",
      "Train Epoch: 1 [9000/11194 (80%)]\tLoss: 0.422343\n",
      "Train Epoch: 1 [10000/11194 (89%)]\tLoss: 0.278780\n",
      "Train Epoch: 1 [11000/11194 (98%)]\tLoss: 0.420487\n",
      "Train Epoch: 2 [0/11194 (0%)]\tLoss: 0.401420\n",
      "Train Epoch: 2 [1000/11194 (9%)]\tLoss: 0.259396\n",
      "Train Epoch: 2 [2000/11194 (18%)]\tLoss: 0.286951\n",
      "Train Epoch: 2 [3000/11194 (27%)]\tLoss: 0.291711\n",
      "Train Epoch: 2 [4000/11194 (36%)]\tLoss: 0.174715\n",
      "Train Epoch: 2 [5000/11194 (45%)]\tLoss: 0.322312\n",
      "Train Epoch: 2 [6000/11194 (54%)]\tLoss: 0.255240\n",
      "Train Epoch: 2 [7000/11194 (62%)]\tLoss: 0.252376\n",
      "Train Epoch: 2 [8000/11194 (71%)]\tLoss: 0.315082\n",
      "Train Epoch: 2 [9000/11194 (80%)]\tLoss: 0.214500\n",
      "Train Epoch: 2 [10000/11194 (89%)]\tLoss: 0.312512\n",
      "Train Epoch: 2 [11000/11194 (98%)]\tLoss: 0.236657\n",
      "Train Epoch: 3 [0/11194 (0%)]\tLoss: 0.316403\n",
      "Train Epoch: 3 [1000/11194 (9%)]\tLoss: 0.255491\n",
      "Train Epoch: 3 [2000/11194 (18%)]\tLoss: 0.336207\n",
      "Train Epoch: 3 [3000/11194 (27%)]\tLoss: 0.365705\n",
      "Train Epoch: 3 [4000/11194 (36%)]\tLoss: 0.324903\n",
      "Train Epoch: 3 [5000/11194 (45%)]\tLoss: 0.395518\n",
      "Train Epoch: 3 [6000/11194 (54%)]\tLoss: 0.310865\n",
      "Train Epoch: 3 [7000/11194 (62%)]\tLoss: 0.308306\n",
      "Train Epoch: 3 [8000/11194 (71%)]\tLoss: 0.431295\n",
      "Train Epoch: 3 [9000/11194 (80%)]\tLoss: 0.269001\n",
      "Train Epoch: 3 [10000/11194 (89%)]\tLoss: 0.277830\n",
      "Train Epoch: 3 [11000/11194 (98%)]\tLoss: 0.461291\n",
      "Train Epoch: 4 [0/11194 (0%)]\tLoss: 0.273214\n",
      "Train Epoch: 4 [1000/11194 (9%)]\tLoss: 0.286525\n",
      "Train Epoch: 4 [2000/11194 (18%)]\tLoss: 0.307253\n",
      "Train Epoch: 4 [3000/11194 (27%)]\tLoss: 0.275111\n",
      "Train Epoch: 4 [4000/11194 (36%)]\tLoss: 0.214398\n",
      "Train Epoch: 4 [5000/11194 (45%)]\tLoss: 0.335103\n",
      "Train Epoch: 4 [6000/11194 (54%)]\tLoss: 0.292320\n",
      "Train Epoch: 4 [7000/11194 (62%)]\tLoss: 0.198782\n",
      "Train Epoch: 4 [8000/11194 (71%)]\tLoss: 0.411463\n",
      "Train Epoch: 4 [9000/11194 (80%)]\tLoss: 0.241421\n",
      "Train Epoch: 4 [10000/11194 (89%)]\tLoss: 0.386129\n",
      "Train Epoch: 4 [11000/11194 (98%)]\tLoss: 0.347875\n",
      "Train Epoch: 5 [0/11194 (0%)]\tLoss: 0.368059\n",
      "Train Epoch: 5 [1000/11194 (9%)]\tLoss: 0.367690\n",
      "Train Epoch: 5 [2000/11194 (18%)]\tLoss: 0.378052\n",
      "Train Epoch: 5 [3000/11194 (27%)]\tLoss: 0.286974\n",
      "Train Epoch: 5 [4000/11194 (36%)]\tLoss: 0.300218\n",
      "Train Epoch: 5 [5000/11194 (45%)]\tLoss: 0.339034\n",
      "Train Epoch: 5 [6000/11194 (54%)]\tLoss: 0.287177\n",
      "Train Epoch: 5 [7000/11194 (62%)]\tLoss: 0.170781\n",
      "Train Epoch: 5 [8000/11194 (71%)]\tLoss: 0.222122\n",
      "Train Epoch: 5 [9000/11194 (80%)]\tLoss: 0.280017\n",
      "Train Epoch: 5 [10000/11194 (89%)]\tLoss: 0.207148\n",
      "Train Epoch: 5 [11000/11194 (98%)]\tLoss: 0.320074\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/7891 (0%)]\tLoss: 0.477168\n",
      "Train Epoch: 1 [1000/7891 (13%)]\tLoss: 0.209883\n",
      "Train Epoch: 1 [2000/7891 (25%)]\tLoss: 0.283756\n",
      "Train Epoch: 1 [3000/7891 (38%)]\tLoss: 0.238562\n",
      "Train Epoch: 1 [4000/7891 (51%)]\tLoss: 0.313107\n",
      "Train Epoch: 1 [5000/7891 (63%)]\tLoss: 0.278020\n",
      "Train Epoch: 1 [6000/7891 (76%)]\tLoss: 0.187200\n",
      "Train Epoch: 1 [7000/7891 (89%)]\tLoss: 0.221210\n",
      "Train Epoch: 2 [0/7891 (0%)]\tLoss: 0.229267\n",
      "Train Epoch: 2 [1000/7891 (13%)]\tLoss: 0.274633\n",
      "Train Epoch: 2 [2000/7891 (25%)]\tLoss: 0.274205\n",
      "Train Epoch: 2 [3000/7891 (38%)]\tLoss: 0.137312\n",
      "Train Epoch: 2 [4000/7891 (51%)]\tLoss: 0.230275\n",
      "Train Epoch: 2 [5000/7891 (63%)]\tLoss: 0.220792\n",
      "Train Epoch: 2 [6000/7891 (76%)]\tLoss: 0.212874\n",
      "Train Epoch: 2 [7000/7891 (89%)]\tLoss: 0.284409\n",
      "Train Epoch: 3 [0/7891 (0%)]\tLoss: 0.188558\n",
      "Train Epoch: 3 [1000/7891 (13%)]\tLoss: 0.256542\n",
      "Train Epoch: 3 [2000/7891 (25%)]\tLoss: 0.132315\n",
      "Train Epoch: 3 [3000/7891 (38%)]\tLoss: 0.201524\n",
      "Train Epoch: 3 [4000/7891 (51%)]\tLoss: 0.249760\n",
      "Train Epoch: 3 [5000/7891 (63%)]\tLoss: 0.270405\n",
      "Train Epoch: 3 [6000/7891 (76%)]\tLoss: 0.209143\n",
      "Train Epoch: 3 [7000/7891 (89%)]\tLoss: 0.263734\n",
      "Train Epoch: 4 [0/7891 (0%)]\tLoss: 0.233877\n",
      "Train Epoch: 4 [1000/7891 (13%)]\tLoss: 0.209296\n",
      "Train Epoch: 4 [2000/7891 (25%)]\tLoss: 0.122864\n",
      "Train Epoch: 4 [3000/7891 (38%)]\tLoss: 0.215889\n",
      "Train Epoch: 4 [4000/7891 (51%)]\tLoss: 0.357985\n",
      "Train Epoch: 4 [5000/7891 (63%)]\tLoss: 0.308516\n",
      "Train Epoch: 4 [6000/7891 (76%)]\tLoss: 0.148466\n",
      "Train Epoch: 4 [7000/7891 (89%)]\tLoss: 0.144300\n",
      "Train Epoch: 5 [0/7891 (0%)]\tLoss: 0.198590\n",
      "Train Epoch: 5 [1000/7891 (13%)]\tLoss: 0.246106\n",
      "Train Epoch: 5 [2000/7891 (25%)]\tLoss: 0.304847\n",
      "Train Epoch: 5 [3000/7891 (38%)]\tLoss: 0.164727\n",
      "Train Epoch: 5 [4000/7891 (51%)]\tLoss: 0.181849\n",
      "Train Epoch: 5 [5000/7891 (63%)]\tLoss: 0.227137\n",
      "Train Epoch: 5 [6000/7891 (76%)]\tLoss: 0.271640\n",
      "Train Epoch: 5 [7000/7891 (89%)]\tLoss: 0.156381\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/3053 (0%)]\tLoss: 0.185411\n",
      "Train Epoch: 1 [1000/3053 (32%)]\tLoss: 0.255867\n",
      "Train Epoch: 1 [2000/3053 (65%)]\tLoss: 0.222054\n",
      "Train Epoch: 1 [1590/3053 (97%)]\tLoss: 0.281575\n",
      "Train Epoch: 2 [0/3053 (0%)]\tLoss: 0.187665\n",
      "Train Epoch: 2 [1000/3053 (32%)]\tLoss: 0.220983\n",
      "Train Epoch: 2 [2000/3053 (65%)]\tLoss: 0.367668\n",
      "Train Epoch: 2 [1590/3053 (97%)]\tLoss: 0.310916\n",
      "Train Epoch: 3 [0/3053 (0%)]\tLoss: 0.210062\n",
      "Train Epoch: 3 [1000/3053 (32%)]\tLoss: 0.201880\n",
      "Train Epoch: 3 [2000/3053 (65%)]\tLoss: 0.202228\n",
      "Train Epoch: 3 [1590/3053 (97%)]\tLoss: 0.114567\n",
      "Train Epoch: 4 [0/3053 (0%)]\tLoss: 0.272279\n",
      "Train Epoch: 4 [1000/3053 (32%)]\tLoss: 0.170897\n",
      "Train Epoch: 4 [2000/3053 (65%)]\tLoss: 0.225782\n",
      "Train Epoch: 4 [1590/3053 (97%)]\tLoss: 0.272668\n",
      "Train Epoch: 5 [0/3053 (0%)]\tLoss: 0.137241\n",
      "Train Epoch: 5 [1000/3053 (32%)]\tLoss: 0.240402\n",
      "Train Epoch: 5 [2000/3053 (65%)]\tLoss: 0.248638\n",
      "Train Epoch: 5 [1590/3053 (97%)]\tLoss: 0.140284\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/9145 (0%)]\tLoss: 0.402886\n",
      "Train Epoch: 1 [1000/9145 (11%)]\tLoss: 0.270754\n",
      "Train Epoch: 1 [2000/9145 (22%)]\tLoss: 0.350744\n",
      "Train Epoch: 1 [3000/9145 (33%)]\tLoss: 0.353904\n",
      "Train Epoch: 1 [4000/9145 (43%)]\tLoss: 0.289808\n",
      "Train Epoch: 1 [5000/9145 (54%)]\tLoss: 0.401022\n",
      "Train Epoch: 1 [6000/9145 (65%)]\tLoss: 0.218265\n",
      "Train Epoch: 1 [7000/9145 (76%)]\tLoss: 0.304385\n",
      "Train Epoch: 1 [8000/9145 (87%)]\tLoss: 0.283350\n",
      "Train Epoch: 1 [9000/9145 (98%)]\tLoss: 0.314694\n",
      "Train Epoch: 2 [0/9145 (0%)]\tLoss: 0.298932\n",
      "Train Epoch: 2 [1000/9145 (11%)]\tLoss: 0.284678\n",
      "Train Epoch: 2 [2000/9145 (22%)]\tLoss: 0.296810\n",
      "Train Epoch: 2 [3000/9145 (33%)]\tLoss: 0.419232\n",
      "Train Epoch: 2 [4000/9145 (43%)]\tLoss: 0.322342\n",
      "Train Epoch: 2 [5000/9145 (54%)]\tLoss: 0.446703\n",
      "Train Epoch: 2 [6000/9145 (65%)]\tLoss: 0.402552\n",
      "Train Epoch: 2 [7000/9145 (76%)]\tLoss: 0.353395\n",
      "Train Epoch: 2 [8000/9145 (87%)]\tLoss: 0.361865\n",
      "Train Epoch: 2 [9000/9145 (98%)]\tLoss: 0.272438\n",
      "Train Epoch: 3 [0/9145 (0%)]\tLoss: 0.379140\n",
      "Train Epoch: 3 [1000/9145 (11%)]\tLoss: 0.350732\n",
      "Train Epoch: 3 [2000/9145 (22%)]\tLoss: 0.355186\n",
      "Train Epoch: 3 [3000/9145 (33%)]\tLoss: 0.314700\n",
      "Train Epoch: 3 [4000/9145 (43%)]\tLoss: 0.190382\n",
      "Train Epoch: 3 [5000/9145 (54%)]\tLoss: 0.339595\n",
      "Train Epoch: 3 [6000/9145 (65%)]\tLoss: 0.316201\n",
      "Train Epoch: 3 [7000/9145 (76%)]\tLoss: 0.380076\n",
      "Train Epoch: 3 [8000/9145 (87%)]\tLoss: 0.537605\n",
      "Train Epoch: 3 [9000/9145 (98%)]\tLoss: 0.387454\n",
      "Train Epoch: 4 [0/9145 (0%)]\tLoss: 0.455591\n",
      "Train Epoch: 4 [1000/9145 (11%)]\tLoss: 0.321332\n",
      "Train Epoch: 4 [2000/9145 (22%)]\tLoss: 0.324964\n",
      "Train Epoch: 4 [3000/9145 (33%)]\tLoss: 0.333018\n",
      "Train Epoch: 4 [4000/9145 (43%)]\tLoss: 0.294222\n",
      "Train Epoch: 4 [5000/9145 (54%)]\tLoss: 0.258742\n",
      "Train Epoch: 4 [6000/9145 (65%)]\tLoss: 0.317060\n",
      "Train Epoch: 4 [7000/9145 (76%)]\tLoss: 0.248388\n",
      "Train Epoch: 4 [8000/9145 (87%)]\tLoss: 0.261237\n",
      "Train Epoch: 4 [9000/9145 (98%)]\tLoss: 0.320804\n",
      "Train Epoch: 5 [0/9145 (0%)]\tLoss: 0.440311\n",
      "Train Epoch: 5 [1000/9145 (11%)]\tLoss: 0.490834\n",
      "Train Epoch: 5 [2000/9145 (22%)]\tLoss: 0.429730\n",
      "Train Epoch: 5 [3000/9145 (33%)]\tLoss: 0.355578\n",
      "Train Epoch: 5 [4000/9145 (43%)]\tLoss: 0.339346\n",
      "Train Epoch: 5 [5000/9145 (54%)]\tLoss: 0.362561\n",
      "Train Epoch: 5 [6000/9145 (65%)]\tLoss: 0.331683\n",
      "Train Epoch: 5 [7000/9145 (76%)]\tLoss: 0.275452\n",
      "Train Epoch: 5 [8000/9145 (87%)]\tLoss: 0.295236\n",
      "Train Epoch: 5 [9000/9145 (98%)]\tLoss: 0.286543\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3021 (0%)]\tLoss: 0.328406\n",
      "Train Epoch: 1 [1000/3021 (32%)]\tLoss: 0.283588\n",
      "Train Epoch: 1 [2000/3021 (65%)]\tLoss: 0.367387\n",
      "Train Epoch: 1 [630/3021 (97%)]\tLoss: 0.331288\n",
      "Train Epoch: 2 [0/3021 (0%)]\tLoss: 0.325604\n",
      "Train Epoch: 2 [1000/3021 (32%)]\tLoss: 0.285586\n",
      "Train Epoch: 2 [2000/3021 (65%)]\tLoss: 0.293963\n",
      "Train Epoch: 2 [630/3021 (97%)]\tLoss: 0.118938\n",
      "Train Epoch: 3 [0/3021 (0%)]\tLoss: 0.376963\n",
      "Train Epoch: 3 [1000/3021 (32%)]\tLoss: 0.329942\n",
      "Train Epoch: 3 [2000/3021 (65%)]\tLoss: 0.410288\n",
      "Train Epoch: 3 [630/3021 (97%)]\tLoss: 0.156407\n",
      "Train Epoch: 4 [0/3021 (0%)]\tLoss: 0.309838\n",
      "Train Epoch: 4 [1000/3021 (32%)]\tLoss: 0.398632\n",
      "Train Epoch: 4 [2000/3021 (65%)]\tLoss: 0.253947\n",
      "Train Epoch: 4 [630/3021 (97%)]\tLoss: 0.282641\n",
      "Train Epoch: 5 [0/3021 (0%)]\tLoss: 0.209644\n",
      "Train Epoch: 5 [1000/3021 (32%)]\tLoss: 0.258321\n",
      "Train Epoch: 5 [2000/3021 (65%)]\tLoss: 0.317658\n",
      "Train Epoch: 5 [630/3021 (97%)]\tLoss: 0.382279\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/7953 (0%)]\tLoss: 0.754937\n",
      "Train Epoch: 1 [1000/7953 (12%)]\tLoss: 0.614446\n",
      "Train Epoch: 1 [2000/7953 (25%)]\tLoss: 0.631015\n",
      "Train Epoch: 1 [3000/7953 (38%)]\tLoss: 0.512153\n",
      "Train Epoch: 1 [4000/7953 (50%)]\tLoss: 0.512256\n",
      "Train Epoch: 1 [5000/7953 (62%)]\tLoss: 0.488305\n",
      "Train Epoch: 1 [6000/7953 (75%)]\tLoss: 0.610230\n",
      "Train Epoch: 1 [7000/7953 (88%)]\tLoss: 0.562755\n",
      "Train Epoch: 2 [0/7953 (0%)]\tLoss: 0.635136\n",
      "Train Epoch: 2 [1000/7953 (12%)]\tLoss: 0.584351\n",
      "Train Epoch: 2 [2000/7953 (25%)]\tLoss: 0.679318\n",
      "Train Epoch: 2 [3000/7953 (38%)]\tLoss: 0.535656\n",
      "Train Epoch: 2 [4000/7953 (50%)]\tLoss: 0.426236\n",
      "Train Epoch: 2 [5000/7953 (62%)]\tLoss: 0.481521\n",
      "Train Epoch: 2 [6000/7953 (75%)]\tLoss: 0.687675\n",
      "Train Epoch: 2 [7000/7953 (88%)]\tLoss: 0.596078\n",
      "Train Epoch: 3 [0/7953 (0%)]\tLoss: 0.532405\n",
      "Train Epoch: 3 [1000/7953 (12%)]\tLoss: 0.446427\n",
      "Train Epoch: 3 [2000/7953 (25%)]\tLoss: 0.565444\n",
      "Train Epoch: 3 [3000/7953 (38%)]\tLoss: 0.609372\n",
      "Train Epoch: 3 [4000/7953 (50%)]\tLoss: 0.572333\n",
      "Train Epoch: 3 [5000/7953 (62%)]\tLoss: 0.459347\n",
      "Train Epoch: 3 [6000/7953 (75%)]\tLoss: 0.440819\n",
      "Train Epoch: 3 [7000/7953 (88%)]\tLoss: 0.580425\n",
      "Train Epoch: 4 [0/7953 (0%)]\tLoss: 0.546483\n",
      "Train Epoch: 4 [1000/7953 (12%)]\tLoss: 0.473070\n",
      "Train Epoch: 4 [2000/7953 (25%)]\tLoss: 0.543052\n",
      "Train Epoch: 4 [3000/7953 (38%)]\tLoss: 0.476329\n",
      "Train Epoch: 4 [4000/7953 (50%)]\tLoss: 0.509534\n",
      "Train Epoch: 4 [5000/7953 (62%)]\tLoss: 0.466253\n",
      "Train Epoch: 4 [6000/7953 (75%)]\tLoss: 0.555946\n",
      "Train Epoch: 4 [7000/7953 (88%)]\tLoss: 0.547294\n",
      "Train Epoch: 5 [0/7953 (0%)]\tLoss: 0.456858\n",
      "Train Epoch: 5 [1000/7953 (12%)]\tLoss: 0.479874\n",
      "Train Epoch: 5 [2000/7953 (25%)]\tLoss: 0.491935\n",
      "Train Epoch: 5 [3000/7953 (38%)]\tLoss: 0.517066\n",
      "Train Epoch: 5 [4000/7953 (50%)]\tLoss: 0.605053\n",
      "Train Epoch: 5 [5000/7953 (62%)]\tLoss: 0.528341\n",
      "Train Epoch: 5 [6000/7953 (75%)]\tLoss: 0.515649\n",
      "Train Epoch: 5 [7000/7953 (88%)]\tLoss: 0.507559\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/10012 (0%)]\tLoss: 0.281385\n",
      "Train Epoch: 1 [1000/10012 (10%)]\tLoss: 0.349465\n",
      "Train Epoch: 1 [2000/10012 (20%)]\tLoss: 0.194980\n",
      "Train Epoch: 1 [3000/10012 (30%)]\tLoss: 0.171812\n",
      "Train Epoch: 1 [4000/10012 (40%)]\tLoss: 0.295648\n",
      "Train Epoch: 1 [5000/10012 (50%)]\tLoss: 0.273916\n",
      "Train Epoch: 1 [6000/10012 (59%)]\tLoss: 0.199564\n",
      "Train Epoch: 1 [7000/10012 (69%)]\tLoss: 0.150838\n",
      "Train Epoch: 1 [8000/10012 (79%)]\tLoss: 0.176792\n",
      "Train Epoch: 1 [9000/10012 (89%)]\tLoss: 0.308364\n",
      "Train Epoch: 1 [1200/10012 (99%)]\tLoss: 0.136717\n",
      "Train Epoch: 2 [0/10012 (0%)]\tLoss: 0.304182\n",
      "Train Epoch: 2 [1000/10012 (10%)]\tLoss: 0.229970\n",
      "Train Epoch: 2 [2000/10012 (20%)]\tLoss: 0.219634\n",
      "Train Epoch: 2 [3000/10012 (30%)]\tLoss: 0.159022\n",
      "Train Epoch: 2 [4000/10012 (40%)]\tLoss: 0.163408\n",
      "Train Epoch: 2 [5000/10012 (50%)]\tLoss: 0.194394\n",
      "Train Epoch: 2 [6000/10012 (59%)]\tLoss: 0.206875\n",
      "Train Epoch: 2 [7000/10012 (69%)]\tLoss: 0.196323\n",
      "Train Epoch: 2 [8000/10012 (79%)]\tLoss: 0.184450\n",
      "Train Epoch: 2 [9000/10012 (89%)]\tLoss: 0.206858\n",
      "Train Epoch: 2 [1200/10012 (99%)]\tLoss: 0.301935\n",
      "Train Epoch: 3 [0/10012 (0%)]\tLoss: 0.133070\n",
      "Train Epoch: 3 [1000/10012 (10%)]\tLoss: 0.281165\n",
      "Train Epoch: 3 [2000/10012 (20%)]\tLoss: 0.260178\n",
      "Train Epoch: 3 [3000/10012 (30%)]\tLoss: 0.251055\n",
      "Train Epoch: 3 [4000/10012 (40%)]\tLoss: 0.211174\n",
      "Train Epoch: 3 [5000/10012 (50%)]\tLoss: 0.199451\n",
      "Train Epoch: 3 [6000/10012 (59%)]\tLoss: 0.320104\n",
      "Train Epoch: 3 [7000/10012 (69%)]\tLoss: 0.302287\n",
      "Train Epoch: 3 [8000/10012 (79%)]\tLoss: 0.180210\n",
      "Train Epoch: 3 [9000/10012 (89%)]\tLoss: 0.244772\n",
      "Train Epoch: 3 [1200/10012 (99%)]\tLoss: 0.425333\n",
      "Train Epoch: 4 [0/10012 (0%)]\tLoss: 0.228213\n",
      "Train Epoch: 4 [1000/10012 (10%)]\tLoss: 0.176730\n",
      "Train Epoch: 4 [2000/10012 (20%)]\tLoss: 0.371421\n",
      "Train Epoch: 4 [3000/10012 (30%)]\tLoss: 0.198158\n",
      "Train Epoch: 4 [4000/10012 (40%)]\tLoss: 0.152893\n",
      "Train Epoch: 4 [5000/10012 (50%)]\tLoss: 0.211369\n",
      "Train Epoch: 4 [6000/10012 (59%)]\tLoss: 0.208207\n",
      "Train Epoch: 4 [7000/10012 (69%)]\tLoss: 0.327185\n",
      "Train Epoch: 4 [8000/10012 (79%)]\tLoss: 0.121658\n",
      "Train Epoch: 4 [9000/10012 (89%)]\tLoss: 0.291488\n",
      "Train Epoch: 4 [1200/10012 (99%)]\tLoss: 0.247083\n",
      "Train Epoch: 5 [0/10012 (0%)]\tLoss: 0.153830\n",
      "Train Epoch: 5 [1000/10012 (10%)]\tLoss: 0.152150\n",
      "Train Epoch: 5 [2000/10012 (20%)]\tLoss: 0.237395\n",
      "Train Epoch: 5 [3000/10012 (30%)]\tLoss: 0.267002\n",
      "Train Epoch: 5 [4000/10012 (40%)]\tLoss: 0.147656\n",
      "Train Epoch: 5 [5000/10012 (50%)]\tLoss: 0.278331\n",
      "Train Epoch: 5 [6000/10012 (59%)]\tLoss: 0.336856\n",
      "Train Epoch: 5 [7000/10012 (69%)]\tLoss: 0.154910\n",
      "Train Epoch: 5 [8000/10012 (79%)]\tLoss: 0.208159\n",
      "Train Epoch: 5 [9000/10012 (89%)]\tLoss: 0.126162\n",
      "Train Epoch: 5 [1200/10012 (99%)]\tLoss: 0.069402\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "8\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9896, Accuracy: 7587/10000 (76%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/7731 (0%)]\tLoss: 0.416270\n",
      "Train Epoch: 1 [1000/7731 (13%)]\tLoss: 0.418394\n",
      "Train Epoch: 1 [2000/7731 (26%)]\tLoss: 0.172615\n",
      "Train Epoch: 1 [3000/7731 (38%)]\tLoss: 0.248820\n",
      "Train Epoch: 1 [4000/7731 (51%)]\tLoss: 0.380283\n",
      "Train Epoch: 1 [5000/7731 (64%)]\tLoss: 0.267830\n",
      "Train Epoch: 1 [6000/7731 (77%)]\tLoss: 0.326741\n",
      "Train Epoch: 1 [7000/7731 (90%)]\tLoss: 0.326650\n",
      "Train Epoch: 2 [0/7731 (0%)]\tLoss: 0.348374\n",
      "Train Epoch: 2 [1000/7731 (13%)]\tLoss: 0.353366\n",
      "Train Epoch: 2 [2000/7731 (26%)]\tLoss: 0.305161\n",
      "Train Epoch: 2 [3000/7731 (38%)]\tLoss: 0.243863\n",
      "Train Epoch: 2 [4000/7731 (51%)]\tLoss: 0.419357\n",
      "Train Epoch: 2 [5000/7731 (64%)]\tLoss: 0.249252\n",
      "Train Epoch: 2 [6000/7731 (77%)]\tLoss: 0.240052\n",
      "Train Epoch: 2 [7000/7731 (90%)]\tLoss: 0.224930\n",
      "Train Epoch: 3 [0/7731 (0%)]\tLoss: 0.268313\n",
      "Train Epoch: 3 [1000/7731 (13%)]\tLoss: 0.327447\n",
      "Train Epoch: 3 [2000/7731 (26%)]\tLoss: 0.266655\n",
      "Train Epoch: 3 [3000/7731 (38%)]\tLoss: 0.317825\n",
      "Train Epoch: 3 [4000/7731 (51%)]\tLoss: 0.299031\n",
      "Train Epoch: 3 [5000/7731 (64%)]\tLoss: 0.216771\n",
      "Train Epoch: 3 [6000/7731 (77%)]\tLoss: 0.250293\n",
      "Train Epoch: 3 [7000/7731 (90%)]\tLoss: 0.228787\n",
      "Train Epoch: 4 [0/7731 (0%)]\tLoss: 0.226097\n",
      "Train Epoch: 4 [1000/7731 (13%)]\tLoss: 0.294629\n",
      "Train Epoch: 4 [2000/7731 (26%)]\tLoss: 0.264047\n",
      "Train Epoch: 4 [3000/7731 (38%)]\tLoss: 0.287382\n",
      "Train Epoch: 4 [4000/7731 (51%)]\tLoss: 0.170320\n",
      "Train Epoch: 4 [5000/7731 (64%)]\tLoss: 0.240524\n",
      "Train Epoch: 4 [6000/7731 (77%)]\tLoss: 0.259122\n",
      "Train Epoch: 4 [7000/7731 (90%)]\tLoss: 0.399738\n",
      "Train Epoch: 5 [0/7731 (0%)]\tLoss: 0.255268\n",
      "Train Epoch: 5 [1000/7731 (13%)]\tLoss: 0.182937\n",
      "Train Epoch: 5 [2000/7731 (26%)]\tLoss: 0.281898\n",
      "Train Epoch: 5 [3000/7731 (38%)]\tLoss: 0.263501\n",
      "Train Epoch: 5 [4000/7731 (51%)]\tLoss: 0.209370\n",
      "Train Epoch: 5 [5000/7731 (64%)]\tLoss: 0.324242\n",
      "Train Epoch: 5 [6000/7731 (77%)]\tLoss: 0.136821\n",
      "Train Epoch: 5 [7000/7731 (90%)]\tLoss: 0.277289\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11194 (0%)]\tLoss: 0.528144\n",
      "Train Epoch: 1 [1000/11194 (9%)]\tLoss: 0.332306\n",
      "Train Epoch: 1 [2000/11194 (18%)]\tLoss: 0.245843\n",
      "Train Epoch: 1 [3000/11194 (27%)]\tLoss: 0.376401\n",
      "Train Epoch: 1 [4000/11194 (36%)]\tLoss: 0.342863\n",
      "Train Epoch: 1 [5000/11194 (45%)]\tLoss: 0.414614\n",
      "Train Epoch: 1 [6000/11194 (54%)]\tLoss: 0.314114\n",
      "Train Epoch: 1 [7000/11194 (62%)]\tLoss: 0.286428\n",
      "Train Epoch: 1 [8000/11194 (71%)]\tLoss: 0.235942\n",
      "Train Epoch: 1 [9000/11194 (80%)]\tLoss: 0.356874\n",
      "Train Epoch: 1 [10000/11194 (89%)]\tLoss: 0.364251\n",
      "Train Epoch: 1 [11000/11194 (98%)]\tLoss: 0.318403\n",
      "Train Epoch: 2 [0/11194 (0%)]\tLoss: 0.254584\n",
      "Train Epoch: 2 [1000/11194 (9%)]\tLoss: 0.341437\n",
      "Train Epoch: 2 [2000/11194 (18%)]\tLoss: 0.278732\n",
      "Train Epoch: 2 [3000/11194 (27%)]\tLoss: 0.302079\n",
      "Train Epoch: 2 [4000/11194 (36%)]\tLoss: 0.404115\n",
      "Train Epoch: 2 [5000/11194 (45%)]\tLoss: 0.224635\n",
      "Train Epoch: 2 [6000/11194 (54%)]\tLoss: 0.331238\n",
      "Train Epoch: 2 [7000/11194 (62%)]\tLoss: 0.375301\n",
      "Train Epoch: 2 [8000/11194 (71%)]\tLoss: 0.301797\n",
      "Train Epoch: 2 [9000/11194 (80%)]\tLoss: 0.327399\n",
      "Train Epoch: 2 [10000/11194 (89%)]\tLoss: 0.293271\n",
      "Train Epoch: 2 [11000/11194 (98%)]\tLoss: 0.325663\n",
      "Train Epoch: 3 [0/11194 (0%)]\tLoss: 0.235232\n",
      "Train Epoch: 3 [1000/11194 (9%)]\tLoss: 0.266063\n",
      "Train Epoch: 3 [2000/11194 (18%)]\tLoss: 0.337746\n",
      "Train Epoch: 3 [3000/11194 (27%)]\tLoss: 0.364131\n",
      "Train Epoch: 3 [4000/11194 (36%)]\tLoss: 0.241813\n",
      "Train Epoch: 3 [5000/11194 (45%)]\tLoss: 0.359562\n",
      "Train Epoch: 3 [6000/11194 (54%)]\tLoss: 0.341799\n",
      "Train Epoch: 3 [7000/11194 (62%)]\tLoss: 0.268371\n",
      "Train Epoch: 3 [8000/11194 (71%)]\tLoss: 0.298138\n",
      "Train Epoch: 3 [9000/11194 (80%)]\tLoss: 0.348344\n",
      "Train Epoch: 3 [10000/11194 (89%)]\tLoss: 0.151852\n",
      "Train Epoch: 3 [11000/11194 (98%)]\tLoss: 0.238444\n",
      "Train Epoch: 4 [0/11194 (0%)]\tLoss: 0.353893\n",
      "Train Epoch: 4 [1000/11194 (9%)]\tLoss: 0.409986\n",
      "Train Epoch: 4 [2000/11194 (18%)]\tLoss: 0.382673\n",
      "Train Epoch: 4 [3000/11194 (27%)]\tLoss: 0.301396\n",
      "Train Epoch: 4 [4000/11194 (36%)]\tLoss: 0.335304\n",
      "Train Epoch: 4 [5000/11194 (45%)]\tLoss: 0.261262\n",
      "Train Epoch: 4 [6000/11194 (54%)]\tLoss: 0.319764\n",
      "Train Epoch: 4 [7000/11194 (62%)]\tLoss: 0.317813\n",
      "Train Epoch: 4 [8000/11194 (71%)]\tLoss: 0.281654\n",
      "Train Epoch: 4 [9000/11194 (80%)]\tLoss: 0.334990\n",
      "Train Epoch: 4 [10000/11194 (89%)]\tLoss: 0.226551\n",
      "Train Epoch: 4 [11000/11194 (98%)]\tLoss: 0.294222\n",
      "Train Epoch: 5 [0/11194 (0%)]\tLoss: 0.279297\n",
      "Train Epoch: 5 [1000/11194 (9%)]\tLoss: 0.232842\n",
      "Train Epoch: 5 [2000/11194 (18%)]\tLoss: 0.355328\n",
      "Train Epoch: 5 [3000/11194 (27%)]\tLoss: 0.387366\n",
      "Train Epoch: 5 [4000/11194 (36%)]\tLoss: 0.245344\n",
      "Train Epoch: 5 [5000/11194 (45%)]\tLoss: 0.410868\n",
      "Train Epoch: 5 [6000/11194 (54%)]\tLoss: 0.333528\n",
      "Train Epoch: 5 [7000/11194 (62%)]\tLoss: 0.361308\n",
      "Train Epoch: 5 [8000/11194 (71%)]\tLoss: 0.356523\n",
      "Train Epoch: 5 [9000/11194 (80%)]\tLoss: 0.285127\n",
      "Train Epoch: 5 [10000/11194 (89%)]\tLoss: 0.280645\n",
      "Train Epoch: 5 [11000/11194 (98%)]\tLoss: 0.214639\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/7891 (0%)]\tLoss: 0.401946\n",
      "Train Epoch: 1 [1000/7891 (13%)]\tLoss: 0.241693\n",
      "Train Epoch: 1 [2000/7891 (25%)]\tLoss: 0.154530\n",
      "Train Epoch: 1 [3000/7891 (38%)]\tLoss: 0.249450\n",
      "Train Epoch: 1 [4000/7891 (51%)]\tLoss: 0.193877\n",
      "Train Epoch: 1 [5000/7891 (63%)]\tLoss: 0.234501\n",
      "Train Epoch: 1 [6000/7891 (76%)]\tLoss: 0.250558\n",
      "Train Epoch: 1 [7000/7891 (89%)]\tLoss: 0.318506\n",
      "Train Epoch: 2 [0/7891 (0%)]\tLoss: 0.325567\n",
      "Train Epoch: 2 [1000/7891 (13%)]\tLoss: 0.206204\n",
      "Train Epoch: 2 [2000/7891 (25%)]\tLoss: 0.281045\n",
      "Train Epoch: 2 [3000/7891 (38%)]\tLoss: 0.226818\n",
      "Train Epoch: 2 [4000/7891 (51%)]\tLoss: 0.209866\n",
      "Train Epoch: 2 [5000/7891 (63%)]\tLoss: 0.293957\n",
      "Train Epoch: 2 [6000/7891 (76%)]\tLoss: 0.331764\n",
      "Train Epoch: 2 [7000/7891 (89%)]\tLoss: 0.196986\n",
      "Train Epoch: 3 [0/7891 (0%)]\tLoss: 0.209790\n",
      "Train Epoch: 3 [1000/7891 (13%)]\tLoss: 0.226852\n",
      "Train Epoch: 3 [2000/7891 (25%)]\tLoss: 0.148331\n",
      "Train Epoch: 3 [3000/7891 (38%)]\tLoss: 0.182851\n",
      "Train Epoch: 3 [4000/7891 (51%)]\tLoss: 0.318824\n",
      "Train Epoch: 3 [5000/7891 (63%)]\tLoss: 0.205252\n",
      "Train Epoch: 3 [6000/7891 (76%)]\tLoss: 0.195098\n",
      "Train Epoch: 3 [7000/7891 (89%)]\tLoss: 0.162833\n",
      "Train Epoch: 4 [0/7891 (0%)]\tLoss: 0.136427\n",
      "Train Epoch: 4 [1000/7891 (13%)]\tLoss: 0.176239\n",
      "Train Epoch: 4 [2000/7891 (25%)]\tLoss: 0.140090\n",
      "Train Epoch: 4 [3000/7891 (38%)]\tLoss: 0.250444\n",
      "Train Epoch: 4 [4000/7891 (51%)]\tLoss: 0.264115\n",
      "Train Epoch: 4 [5000/7891 (63%)]\tLoss: 0.273613\n",
      "Train Epoch: 4 [6000/7891 (76%)]\tLoss: 0.277642\n",
      "Train Epoch: 4 [7000/7891 (89%)]\tLoss: 0.323744\n",
      "Train Epoch: 5 [0/7891 (0%)]\tLoss: 0.227424\n",
      "Train Epoch: 5 [1000/7891 (13%)]\tLoss: 0.198623\n",
      "Train Epoch: 5 [2000/7891 (25%)]\tLoss: 0.278890\n",
      "Train Epoch: 5 [3000/7891 (38%)]\tLoss: 0.230253\n",
      "Train Epoch: 5 [4000/7891 (51%)]\tLoss: 0.267742\n",
      "Train Epoch: 5 [5000/7891 (63%)]\tLoss: 0.261057\n",
      "Train Epoch: 5 [6000/7891 (76%)]\tLoss: 0.276875\n",
      "Train Epoch: 5 [7000/7891 (89%)]\tLoss: 0.289875\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/3053 (0%)]\tLoss: 0.269718\n",
      "Train Epoch: 1 [1000/3053 (32%)]\tLoss: 0.280068\n",
      "Train Epoch: 1 [2000/3053 (65%)]\tLoss: 0.292433\n",
      "Train Epoch: 1 [1590/3053 (97%)]\tLoss: 0.242656\n",
      "Train Epoch: 2 [0/3053 (0%)]\tLoss: 0.174711\n",
      "Train Epoch: 2 [1000/3053 (32%)]\tLoss: 0.256466\n",
      "Train Epoch: 2 [2000/3053 (65%)]\tLoss: 0.247486\n",
      "Train Epoch: 2 [1590/3053 (97%)]\tLoss: 0.322159\n",
      "Train Epoch: 3 [0/3053 (0%)]\tLoss: 0.297551\n",
      "Train Epoch: 3 [1000/3053 (32%)]\tLoss: 0.163884\n",
      "Train Epoch: 3 [2000/3053 (65%)]\tLoss: 0.199674\n",
      "Train Epoch: 3 [1590/3053 (97%)]\tLoss: 0.332795\n",
      "Train Epoch: 4 [0/3053 (0%)]\tLoss: 0.184739\n",
      "Train Epoch: 4 [1000/3053 (32%)]\tLoss: 0.208562\n",
      "Train Epoch: 4 [2000/3053 (65%)]\tLoss: 0.363850\n",
      "Train Epoch: 4 [1590/3053 (97%)]\tLoss: 0.297142\n",
      "Train Epoch: 5 [0/3053 (0%)]\tLoss: 0.144506\n",
      "Train Epoch: 5 [1000/3053 (32%)]\tLoss: 0.206114\n",
      "Train Epoch: 5 [2000/3053 (65%)]\tLoss: 0.223306\n",
      "Train Epoch: 5 [1590/3053 (97%)]\tLoss: 0.214658\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/9145 (0%)]\tLoss: 0.376265\n",
      "Train Epoch: 1 [1000/9145 (11%)]\tLoss: 0.305792\n",
      "Train Epoch: 1 [2000/9145 (22%)]\tLoss: 0.310934\n",
      "Train Epoch: 1 [3000/9145 (33%)]\tLoss: 0.227895\n",
      "Train Epoch: 1 [4000/9145 (43%)]\tLoss: 0.329593\n",
      "Train Epoch: 1 [5000/9145 (54%)]\tLoss: 0.176268\n",
      "Train Epoch: 1 [6000/9145 (65%)]\tLoss: 0.422923\n",
      "Train Epoch: 1 [7000/9145 (76%)]\tLoss: 0.509583\n",
      "Train Epoch: 1 [8000/9145 (87%)]\tLoss: 0.222068\n",
      "Train Epoch: 1 [9000/9145 (98%)]\tLoss: 0.383577\n",
      "Train Epoch: 2 [0/9145 (0%)]\tLoss: 0.287877\n",
      "Train Epoch: 2 [1000/9145 (11%)]\tLoss: 0.480190\n",
      "Train Epoch: 2 [2000/9145 (22%)]\tLoss: 0.273191\n",
      "Train Epoch: 2 [3000/9145 (33%)]\tLoss: 0.332171\n",
      "Train Epoch: 2 [4000/9145 (43%)]\tLoss: 0.271071\n",
      "Train Epoch: 2 [5000/9145 (54%)]\tLoss: 0.288320\n",
      "Train Epoch: 2 [6000/9145 (65%)]\tLoss: 0.268775\n",
      "Train Epoch: 2 [7000/9145 (76%)]\tLoss: 0.253102\n",
      "Train Epoch: 2 [8000/9145 (87%)]\tLoss: 0.478619\n",
      "Train Epoch: 2 [9000/9145 (98%)]\tLoss: 0.361319\n",
      "Train Epoch: 3 [0/9145 (0%)]\tLoss: 0.369196\n",
      "Train Epoch: 3 [1000/9145 (11%)]\tLoss: 0.249339\n",
      "Train Epoch: 3 [2000/9145 (22%)]\tLoss: 0.329560\n",
      "Train Epoch: 3 [3000/9145 (33%)]\tLoss: 0.230916\n",
      "Train Epoch: 3 [4000/9145 (43%)]\tLoss: 0.387447\n",
      "Train Epoch: 3 [5000/9145 (54%)]\tLoss: 0.475715\n",
      "Train Epoch: 3 [6000/9145 (65%)]\tLoss: 0.388379\n",
      "Train Epoch: 3 [7000/9145 (76%)]\tLoss: 0.337690\n",
      "Train Epoch: 3 [8000/9145 (87%)]\tLoss: 0.258894\n",
      "Train Epoch: 3 [9000/9145 (98%)]\tLoss: 0.298834\n",
      "Train Epoch: 4 [0/9145 (0%)]\tLoss: 0.388264\n",
      "Train Epoch: 4 [1000/9145 (11%)]\tLoss: 0.326069\n",
      "Train Epoch: 4 [2000/9145 (22%)]\tLoss: 0.291215\n",
      "Train Epoch: 4 [3000/9145 (33%)]\tLoss: 0.307187\n",
      "Train Epoch: 4 [4000/9145 (43%)]\tLoss: 0.340275\n",
      "Train Epoch: 4 [5000/9145 (54%)]\tLoss: 0.412764\n",
      "Train Epoch: 4 [6000/9145 (65%)]\tLoss: 0.359127\n",
      "Train Epoch: 4 [7000/9145 (76%)]\tLoss: 0.301421\n",
      "Train Epoch: 4 [8000/9145 (87%)]\tLoss: 0.483254\n",
      "Train Epoch: 4 [9000/9145 (98%)]\tLoss: 0.245136\n",
      "Train Epoch: 5 [0/9145 (0%)]\tLoss: 0.235218\n",
      "Train Epoch: 5 [1000/9145 (11%)]\tLoss: 0.354045\n",
      "Train Epoch: 5 [2000/9145 (22%)]\tLoss: 0.328488\n",
      "Train Epoch: 5 [3000/9145 (33%)]\tLoss: 0.269781\n",
      "Train Epoch: 5 [4000/9145 (43%)]\tLoss: 0.419684\n",
      "Train Epoch: 5 [5000/9145 (54%)]\tLoss: 0.401355\n",
      "Train Epoch: 5 [6000/9145 (65%)]\tLoss: 0.298668\n",
      "Train Epoch: 5 [7000/9145 (76%)]\tLoss: 0.330320\n",
      "Train Epoch: 5 [8000/9145 (87%)]\tLoss: 0.399340\n",
      "Train Epoch: 5 [9000/9145 (98%)]\tLoss: 0.457168\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3021 (0%)]\tLoss: 0.461445\n",
      "Train Epoch: 1 [1000/3021 (32%)]\tLoss: 0.356543\n",
      "Train Epoch: 1 [2000/3021 (65%)]\tLoss: 0.359884\n",
      "Train Epoch: 1 [630/3021 (97%)]\tLoss: 0.313187\n",
      "Train Epoch: 2 [0/3021 (0%)]\tLoss: 0.330686\n",
      "Train Epoch: 2 [1000/3021 (32%)]\tLoss: 0.180445\n",
      "Train Epoch: 2 [2000/3021 (65%)]\tLoss: 0.232151\n",
      "Train Epoch: 2 [630/3021 (97%)]\tLoss: 0.501318\n",
      "Train Epoch: 3 [0/3021 (0%)]\tLoss: 0.302469\n",
      "Train Epoch: 3 [1000/3021 (32%)]\tLoss: 0.182170\n",
      "Train Epoch: 3 [2000/3021 (65%)]\tLoss: 0.385715\n",
      "Train Epoch: 3 [630/3021 (97%)]\tLoss: 0.282038\n",
      "Train Epoch: 4 [0/3021 (0%)]\tLoss: 0.351277\n",
      "Train Epoch: 4 [1000/3021 (32%)]\tLoss: 0.342719\n",
      "Train Epoch: 4 [2000/3021 (65%)]\tLoss: 0.256016\n",
      "Train Epoch: 4 [630/3021 (97%)]\tLoss: 0.180761\n",
      "Train Epoch: 5 [0/3021 (0%)]\tLoss: 0.216817\n",
      "Train Epoch: 5 [1000/3021 (32%)]\tLoss: 0.288655\n",
      "Train Epoch: 5 [2000/3021 (65%)]\tLoss: 0.196113\n",
      "Train Epoch: 5 [630/3021 (97%)]\tLoss: 0.328847\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/7953 (0%)]\tLoss: 0.581634\n",
      "Train Epoch: 1 [1000/7953 (12%)]\tLoss: 0.481250\n",
      "Train Epoch: 1 [2000/7953 (25%)]\tLoss: 0.576297\n",
      "Train Epoch: 1 [3000/7953 (38%)]\tLoss: 0.677273\n",
      "Train Epoch: 1 [4000/7953 (50%)]\tLoss: 0.454595\n",
      "Train Epoch: 1 [5000/7953 (62%)]\tLoss: 0.364993\n",
      "Train Epoch: 1 [6000/7953 (75%)]\tLoss: 0.443659\n",
      "Train Epoch: 1 [7000/7953 (88%)]\tLoss: 0.379637\n",
      "Train Epoch: 2 [0/7953 (0%)]\tLoss: 0.460132\n",
      "Train Epoch: 2 [1000/7953 (12%)]\tLoss: 0.632297\n",
      "Train Epoch: 2 [2000/7953 (25%)]\tLoss: 0.459169\n",
      "Train Epoch: 2 [3000/7953 (38%)]\tLoss: 0.557870\n",
      "Train Epoch: 2 [4000/7953 (50%)]\tLoss: 0.493799\n",
      "Train Epoch: 2 [5000/7953 (62%)]\tLoss: 0.450116\n",
      "Train Epoch: 2 [6000/7953 (75%)]\tLoss: 0.465433\n",
      "Train Epoch: 2 [7000/7953 (88%)]\tLoss: 0.562626\n",
      "Train Epoch: 3 [0/7953 (0%)]\tLoss: 0.593449\n",
      "Train Epoch: 3 [1000/7953 (12%)]\tLoss: 0.757545\n",
      "Train Epoch: 3 [2000/7953 (25%)]\tLoss: 0.453534\n",
      "Train Epoch: 3 [3000/7953 (38%)]\tLoss: 0.706263\n",
      "Train Epoch: 3 [4000/7953 (50%)]\tLoss: 0.506849\n",
      "Train Epoch: 3 [5000/7953 (62%)]\tLoss: 0.610413\n",
      "Train Epoch: 3 [6000/7953 (75%)]\tLoss: 0.494150\n",
      "Train Epoch: 3 [7000/7953 (88%)]\tLoss: 0.391885\n",
      "Train Epoch: 4 [0/7953 (0%)]\tLoss: 0.586315\n",
      "Train Epoch: 4 [1000/7953 (12%)]\tLoss: 0.481212\n",
      "Train Epoch: 4 [2000/7953 (25%)]\tLoss: 0.498902\n",
      "Train Epoch: 4 [3000/7953 (38%)]\tLoss: 0.543324\n",
      "Train Epoch: 4 [4000/7953 (50%)]\tLoss: 0.512725\n",
      "Train Epoch: 4 [5000/7953 (62%)]\tLoss: 0.411183\n",
      "Train Epoch: 4 [6000/7953 (75%)]\tLoss: 0.554125\n",
      "Train Epoch: 4 [7000/7953 (88%)]\tLoss: 0.431725\n",
      "Train Epoch: 5 [0/7953 (0%)]\tLoss: 0.542586\n",
      "Train Epoch: 5 [1000/7953 (12%)]\tLoss: 0.514078\n",
      "Train Epoch: 5 [2000/7953 (25%)]\tLoss: 0.514215\n",
      "Train Epoch: 5 [3000/7953 (38%)]\tLoss: 0.580547\n",
      "Train Epoch: 5 [4000/7953 (50%)]\tLoss: 0.509857\n",
      "Train Epoch: 5 [5000/7953 (62%)]\tLoss: 0.482970\n",
      "Train Epoch: 5 [6000/7953 (75%)]\tLoss: 0.570096\n",
      "Train Epoch: 5 [7000/7953 (88%)]\tLoss: 0.476705\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/10012 (0%)]\tLoss: 0.273987\n",
      "Train Epoch: 1 [1000/10012 (10%)]\tLoss: 0.171056\n",
      "Train Epoch: 1 [2000/10012 (20%)]\tLoss: 0.386165\n",
      "Train Epoch: 1 [3000/10012 (30%)]\tLoss: 0.357082\n",
      "Train Epoch: 1 [4000/10012 (40%)]\tLoss: 0.171148\n",
      "Train Epoch: 1 [5000/10012 (50%)]\tLoss: 0.294845\n",
      "Train Epoch: 1 [6000/10012 (59%)]\tLoss: 0.324851\n",
      "Train Epoch: 1 [7000/10012 (69%)]\tLoss: 0.326514\n",
      "Train Epoch: 1 [8000/10012 (79%)]\tLoss: 0.261778\n",
      "Train Epoch: 1 [9000/10012 (89%)]\tLoss: 0.293459\n",
      "Train Epoch: 1 [1200/10012 (99%)]\tLoss: 0.031170\n",
      "Train Epoch: 2 [0/10012 (0%)]\tLoss: 0.225648\n",
      "Train Epoch: 2 [1000/10012 (10%)]\tLoss: 0.217656\n",
      "Train Epoch: 2 [2000/10012 (20%)]\tLoss: 0.244123\n",
      "Train Epoch: 2 [3000/10012 (30%)]\tLoss: 0.310434\n",
      "Train Epoch: 2 [4000/10012 (40%)]\tLoss: 0.320645\n",
      "Train Epoch: 2 [5000/10012 (50%)]\tLoss: 0.422855\n",
      "Train Epoch: 2 [6000/10012 (59%)]\tLoss: 0.166681\n",
      "Train Epoch: 2 [7000/10012 (69%)]\tLoss: 0.353160\n",
      "Train Epoch: 2 [8000/10012 (79%)]\tLoss: 0.245450\n",
      "Train Epoch: 2 [9000/10012 (89%)]\tLoss: 0.126120\n",
      "Train Epoch: 2 [1200/10012 (99%)]\tLoss: 0.367723\n",
      "Train Epoch: 3 [0/10012 (0%)]\tLoss: 0.208487\n",
      "Train Epoch: 3 [1000/10012 (10%)]\tLoss: 0.198965\n",
      "Train Epoch: 3 [2000/10012 (20%)]\tLoss: 0.199868\n",
      "Train Epoch: 3 [3000/10012 (30%)]\tLoss: 0.303205\n",
      "Train Epoch: 3 [4000/10012 (40%)]\tLoss: 0.207538\n",
      "Train Epoch: 3 [5000/10012 (50%)]\tLoss: 0.283860\n",
      "Train Epoch: 3 [6000/10012 (59%)]\tLoss: 0.177715\n",
      "Train Epoch: 3 [7000/10012 (69%)]\tLoss: 0.263550\n",
      "Train Epoch: 3 [8000/10012 (79%)]\tLoss: 0.211535\n",
      "Train Epoch: 3 [9000/10012 (89%)]\tLoss: 0.343909\n",
      "Train Epoch: 3 [1200/10012 (99%)]\tLoss: 0.411744\n",
      "Train Epoch: 4 [0/10012 (0%)]\tLoss: 0.201711\n",
      "Train Epoch: 4 [1000/10012 (10%)]\tLoss: 0.112432\n",
      "Train Epoch: 4 [2000/10012 (20%)]\tLoss: 0.114631\n",
      "Train Epoch: 4 [3000/10012 (30%)]\tLoss: 0.297350\n",
      "Train Epoch: 4 [4000/10012 (40%)]\tLoss: 0.143154\n",
      "Train Epoch: 4 [5000/10012 (50%)]\tLoss: 0.225980\n",
      "Train Epoch: 4 [6000/10012 (59%)]\tLoss: 0.214459\n",
      "Train Epoch: 4 [7000/10012 (69%)]\tLoss: 0.123552\n",
      "Train Epoch: 4 [8000/10012 (79%)]\tLoss: 0.333713\n",
      "Train Epoch: 4 [9000/10012 (89%)]\tLoss: 0.418861\n",
      "Train Epoch: 4 [1200/10012 (99%)]\tLoss: 0.161714\n",
      "Train Epoch: 5 [0/10012 (0%)]\tLoss: 0.118893\n",
      "Train Epoch: 5 [1000/10012 (10%)]\tLoss: 0.201395\n",
      "Train Epoch: 5 [2000/10012 (20%)]\tLoss: 0.137448\n",
      "Train Epoch: 5 [3000/10012 (30%)]\tLoss: 0.270943\n",
      "Train Epoch: 5 [4000/10012 (40%)]\tLoss: 0.237703\n",
      "Train Epoch: 5 [5000/10012 (50%)]\tLoss: 0.274665\n",
      "Train Epoch: 5 [6000/10012 (59%)]\tLoss: 0.264134\n",
      "Train Epoch: 5 [7000/10012 (69%)]\tLoss: 0.379726\n",
      "Train Epoch: 5 [8000/10012 (79%)]\tLoss: 0.216400\n",
      "Train Epoch: 5 [9000/10012 (89%)]\tLoss: 0.141198\n",
      "Train Epoch: 5 [1200/10012 (99%)]\tLoss: 0.269156\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "8\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9712, Accuracy: 7623/10000 (76%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/7731 (0%)]\tLoss: 0.463814\n",
      "Train Epoch: 1 [1000/7731 (13%)]\tLoss: 0.242479\n",
      "Train Epoch: 1 [2000/7731 (26%)]\tLoss: 0.413762\n",
      "Train Epoch: 1 [3000/7731 (38%)]\tLoss: 0.230415\n",
      "Train Epoch: 1 [4000/7731 (51%)]\tLoss: 0.167244\n",
      "Train Epoch: 1 [5000/7731 (64%)]\tLoss: 0.302218\n",
      "Train Epoch: 1 [6000/7731 (77%)]\tLoss: 0.177869\n",
      "Train Epoch: 1 [7000/7731 (90%)]\tLoss: 0.305793\n",
      "Train Epoch: 2 [0/7731 (0%)]\tLoss: 0.230498\n",
      "Train Epoch: 2 [1000/7731 (13%)]\tLoss: 0.192511\n",
      "Train Epoch: 2 [2000/7731 (26%)]\tLoss: 0.275915\n",
      "Train Epoch: 2 [3000/7731 (38%)]\tLoss: 0.245657\n",
      "Train Epoch: 2 [4000/7731 (51%)]\tLoss: 0.303914\n",
      "Train Epoch: 2 [5000/7731 (64%)]\tLoss: 0.256302\n",
      "Train Epoch: 2 [6000/7731 (77%)]\tLoss: 0.268041\n",
      "Train Epoch: 2 [7000/7731 (90%)]\tLoss: 0.315906\n",
      "Train Epoch: 3 [0/7731 (0%)]\tLoss: 0.294315\n",
      "Train Epoch: 3 [1000/7731 (13%)]\tLoss: 0.288418\n",
      "Train Epoch: 3 [2000/7731 (26%)]\tLoss: 0.237180\n",
      "Train Epoch: 3 [3000/7731 (38%)]\tLoss: 0.215954\n",
      "Train Epoch: 3 [4000/7731 (51%)]\tLoss: 0.259977\n",
      "Train Epoch: 3 [5000/7731 (64%)]\tLoss: 0.297943\n",
      "Train Epoch: 3 [6000/7731 (77%)]\tLoss: 0.289752\n",
      "Train Epoch: 3 [7000/7731 (90%)]\tLoss: 0.264474\n",
      "Train Epoch: 4 [0/7731 (0%)]\tLoss: 0.248927\n",
      "Train Epoch: 4 [1000/7731 (13%)]\tLoss: 0.326403\n",
      "Train Epoch: 4 [2000/7731 (26%)]\tLoss: 0.461205\n",
      "Train Epoch: 4 [3000/7731 (38%)]\tLoss: 0.169079\n",
      "Train Epoch: 4 [4000/7731 (51%)]\tLoss: 0.298250\n",
      "Train Epoch: 4 [5000/7731 (64%)]\tLoss: 0.302004\n",
      "Train Epoch: 4 [6000/7731 (77%)]\tLoss: 0.218217\n",
      "Train Epoch: 4 [7000/7731 (90%)]\tLoss: 0.234217\n",
      "Train Epoch: 5 [0/7731 (0%)]\tLoss: 0.293034\n",
      "Train Epoch: 5 [1000/7731 (13%)]\tLoss: 0.314862\n",
      "Train Epoch: 5 [2000/7731 (26%)]\tLoss: 0.217179\n",
      "Train Epoch: 5 [3000/7731 (38%)]\tLoss: 0.315353\n",
      "Train Epoch: 5 [4000/7731 (51%)]\tLoss: 0.265219\n",
      "Train Epoch: 5 [5000/7731 (64%)]\tLoss: 0.270072\n",
      "Train Epoch: 5 [6000/7731 (77%)]\tLoss: 0.276143\n",
      "Train Epoch: 5 [7000/7731 (90%)]\tLoss: 0.311408\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11194 (0%)]\tLoss: 0.375776\n",
      "Train Epoch: 1 [1000/11194 (9%)]\tLoss: 0.443876\n",
      "Train Epoch: 1 [2000/11194 (18%)]\tLoss: 0.314078\n",
      "Train Epoch: 1 [3000/11194 (27%)]\tLoss: 0.366103\n",
      "Train Epoch: 1 [4000/11194 (36%)]\tLoss: 0.353720\n",
      "Train Epoch: 1 [5000/11194 (45%)]\tLoss: 0.287132\n",
      "Train Epoch: 1 [6000/11194 (54%)]\tLoss: 0.417330\n",
      "Train Epoch: 1 [7000/11194 (62%)]\tLoss: 0.420979\n",
      "Train Epoch: 1 [8000/11194 (71%)]\tLoss: 0.259005\n",
      "Train Epoch: 1 [9000/11194 (80%)]\tLoss: 0.283016\n",
      "Train Epoch: 1 [10000/11194 (89%)]\tLoss: 0.235219\n",
      "Train Epoch: 1 [11000/11194 (98%)]\tLoss: 0.337242\n",
      "Train Epoch: 2 [0/11194 (0%)]\tLoss: 0.200599\n",
      "Train Epoch: 2 [1000/11194 (9%)]\tLoss: 0.215025\n",
      "Train Epoch: 2 [2000/11194 (18%)]\tLoss: 0.380694\n",
      "Train Epoch: 2 [3000/11194 (27%)]\tLoss: 0.244362\n",
      "Train Epoch: 2 [4000/11194 (36%)]\tLoss: 0.364806\n",
      "Train Epoch: 2 [5000/11194 (45%)]\tLoss: 0.304522\n",
      "Train Epoch: 2 [6000/11194 (54%)]\tLoss: 0.331226\n",
      "Train Epoch: 2 [7000/11194 (62%)]\tLoss: 0.349834\n",
      "Train Epoch: 2 [8000/11194 (71%)]\tLoss: 0.542292\n",
      "Train Epoch: 2 [9000/11194 (80%)]\tLoss: 0.222270\n",
      "Train Epoch: 2 [10000/11194 (89%)]\tLoss: 0.281986\n",
      "Train Epoch: 2 [11000/11194 (98%)]\tLoss: 0.343470\n",
      "Train Epoch: 3 [0/11194 (0%)]\tLoss: 0.273704\n",
      "Train Epoch: 3 [1000/11194 (9%)]\tLoss: 0.351176\n",
      "Train Epoch: 3 [2000/11194 (18%)]\tLoss: 0.455649\n",
      "Train Epoch: 3 [3000/11194 (27%)]\tLoss: 0.161750\n",
      "Train Epoch: 3 [4000/11194 (36%)]\tLoss: 0.261656\n",
      "Train Epoch: 3 [5000/11194 (45%)]\tLoss: 0.307566\n",
      "Train Epoch: 3 [6000/11194 (54%)]\tLoss: 0.322100\n",
      "Train Epoch: 3 [7000/11194 (62%)]\tLoss: 0.328891\n",
      "Train Epoch: 3 [8000/11194 (71%)]\tLoss: 0.379890\n",
      "Train Epoch: 3 [9000/11194 (80%)]\tLoss: 0.400339\n",
      "Train Epoch: 3 [10000/11194 (89%)]\tLoss: 0.340911\n",
      "Train Epoch: 3 [11000/11194 (98%)]\tLoss: 0.260755\n",
      "Train Epoch: 4 [0/11194 (0%)]\tLoss: 0.256418\n",
      "Train Epoch: 4 [1000/11194 (9%)]\tLoss: 0.280460\n",
      "Train Epoch: 4 [2000/11194 (18%)]\tLoss: 0.223462\n",
      "Train Epoch: 4 [3000/11194 (27%)]\tLoss: 0.297222\n",
      "Train Epoch: 4 [4000/11194 (36%)]\tLoss: 0.215336\n",
      "Train Epoch: 4 [5000/11194 (45%)]\tLoss: 0.251286\n",
      "Train Epoch: 4 [6000/11194 (54%)]\tLoss: 0.335069\n",
      "Train Epoch: 4 [7000/11194 (62%)]\tLoss: 0.162223\n",
      "Train Epoch: 4 [8000/11194 (71%)]\tLoss: 0.259686\n",
      "Train Epoch: 4 [9000/11194 (80%)]\tLoss: 0.246069\n",
      "Train Epoch: 4 [10000/11194 (89%)]\tLoss: 0.357960\n",
      "Train Epoch: 4 [11000/11194 (98%)]\tLoss: 0.216864\n",
      "Train Epoch: 5 [0/11194 (0%)]\tLoss: 0.217684\n",
      "Train Epoch: 5 [1000/11194 (9%)]\tLoss: 0.260781\n",
      "Train Epoch: 5 [2000/11194 (18%)]\tLoss: 0.299981\n",
      "Train Epoch: 5 [3000/11194 (27%)]\tLoss: 0.350236\n",
      "Train Epoch: 5 [4000/11194 (36%)]\tLoss: 0.263470\n",
      "Train Epoch: 5 [5000/11194 (45%)]\tLoss: 0.229324\n",
      "Train Epoch: 5 [6000/11194 (54%)]\tLoss: 0.257150\n",
      "Train Epoch: 5 [7000/11194 (62%)]\tLoss: 0.236935\n",
      "Train Epoch: 5 [8000/11194 (71%)]\tLoss: 0.336168\n",
      "Train Epoch: 5 [9000/11194 (80%)]\tLoss: 0.365817\n",
      "Train Epoch: 5 [10000/11194 (89%)]\tLoss: 0.254795\n",
      "Train Epoch: 5 [11000/11194 (98%)]\tLoss: 0.323374\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/7891 (0%)]\tLoss: 0.312540\n",
      "Train Epoch: 1 [1000/7891 (13%)]\tLoss: 0.373335\n",
      "Train Epoch: 1 [2000/7891 (25%)]\tLoss: 0.201593\n",
      "Train Epoch: 1 [3000/7891 (38%)]\tLoss: 0.237975\n",
      "Train Epoch: 1 [4000/7891 (51%)]\tLoss: 0.278631\n",
      "Train Epoch: 1 [5000/7891 (63%)]\tLoss: 0.240209\n",
      "Train Epoch: 1 [6000/7891 (76%)]\tLoss: 0.289326\n",
      "Train Epoch: 1 [7000/7891 (89%)]\tLoss: 0.187644\n",
      "Train Epoch: 2 [0/7891 (0%)]\tLoss: 0.267489\n",
      "Train Epoch: 2 [1000/7891 (13%)]\tLoss: 0.243430\n",
      "Train Epoch: 2 [2000/7891 (25%)]\tLoss: 0.322331\n",
      "Train Epoch: 2 [3000/7891 (38%)]\tLoss: 0.292166\n",
      "Train Epoch: 2 [4000/7891 (51%)]\tLoss: 0.242051\n",
      "Train Epoch: 2 [5000/7891 (63%)]\tLoss: 0.242620\n",
      "Train Epoch: 2 [6000/7891 (76%)]\tLoss: 0.364773\n",
      "Train Epoch: 2 [7000/7891 (89%)]\tLoss: 0.185723\n",
      "Train Epoch: 3 [0/7891 (0%)]\tLoss: 0.241635\n",
      "Train Epoch: 3 [1000/7891 (13%)]\tLoss: 0.240395\n",
      "Train Epoch: 3 [2000/7891 (25%)]\tLoss: 0.209171\n",
      "Train Epoch: 3 [3000/7891 (38%)]\tLoss: 0.200823\n",
      "Train Epoch: 3 [4000/7891 (51%)]\tLoss: 0.281995\n",
      "Train Epoch: 3 [5000/7891 (63%)]\tLoss: 0.236331\n",
      "Train Epoch: 3 [6000/7891 (76%)]\tLoss: 0.180796\n",
      "Train Epoch: 3 [7000/7891 (89%)]\tLoss: 0.391802\n",
      "Train Epoch: 4 [0/7891 (0%)]\tLoss: 0.239064\n",
      "Train Epoch: 4 [1000/7891 (13%)]\tLoss: 0.331305\n",
      "Train Epoch: 4 [2000/7891 (25%)]\tLoss: 0.172903\n",
      "Train Epoch: 4 [3000/7891 (38%)]\tLoss: 0.200742\n",
      "Train Epoch: 4 [4000/7891 (51%)]\tLoss: 0.233409\n",
      "Train Epoch: 4 [5000/7891 (63%)]\tLoss: 0.214441\n",
      "Train Epoch: 4 [6000/7891 (76%)]\tLoss: 0.335911\n",
      "Train Epoch: 4 [7000/7891 (89%)]\tLoss: 0.139131\n",
      "Train Epoch: 5 [0/7891 (0%)]\tLoss: 0.236604\n",
      "Train Epoch: 5 [1000/7891 (13%)]\tLoss: 0.215691\n",
      "Train Epoch: 5 [2000/7891 (25%)]\tLoss: 0.125875\n",
      "Train Epoch: 5 [3000/7891 (38%)]\tLoss: 0.287369\n",
      "Train Epoch: 5 [4000/7891 (51%)]\tLoss: 0.232129\n",
      "Train Epoch: 5 [5000/7891 (63%)]\tLoss: 0.202533\n",
      "Train Epoch: 5 [6000/7891 (76%)]\tLoss: 0.198534\n",
      "Train Epoch: 5 [7000/7891 (89%)]\tLoss: 0.187649\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/3053 (0%)]\tLoss: 0.272428\n",
      "Train Epoch: 1 [1000/3053 (32%)]\tLoss: 0.271584\n",
      "Train Epoch: 1 [2000/3053 (65%)]\tLoss: 0.261375\n",
      "Train Epoch: 1 [1590/3053 (97%)]\tLoss: 0.197513\n",
      "Train Epoch: 2 [0/3053 (0%)]\tLoss: 0.332984\n",
      "Train Epoch: 2 [1000/3053 (32%)]\tLoss: 0.166055\n",
      "Train Epoch: 2 [2000/3053 (65%)]\tLoss: 0.275216\n",
      "Train Epoch: 2 [1590/3053 (97%)]\tLoss: 0.307573\n",
      "Train Epoch: 3 [0/3053 (0%)]\tLoss: 0.229047\n",
      "Train Epoch: 3 [1000/3053 (32%)]\tLoss: 0.328561\n",
      "Train Epoch: 3 [2000/3053 (65%)]\tLoss: 0.133745\n",
      "Train Epoch: 3 [1590/3053 (97%)]\tLoss: 0.185945\n",
      "Train Epoch: 4 [0/3053 (0%)]\tLoss: 0.131571\n",
      "Train Epoch: 4 [1000/3053 (32%)]\tLoss: 0.223236\n",
      "Train Epoch: 4 [2000/3053 (65%)]\tLoss: 0.271377\n",
      "Train Epoch: 4 [1590/3053 (97%)]\tLoss: 0.196413\n",
      "Train Epoch: 5 [0/3053 (0%)]\tLoss: 0.140449\n",
      "Train Epoch: 5 [1000/3053 (32%)]\tLoss: 0.250590\n",
      "Train Epoch: 5 [2000/3053 (65%)]\tLoss: 0.282762\n",
      "Train Epoch: 5 [1590/3053 (97%)]\tLoss: 0.189034\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/9145 (0%)]\tLoss: 0.545132\n",
      "Train Epoch: 1 [1000/9145 (11%)]\tLoss: 0.367353\n",
      "Train Epoch: 1 [2000/9145 (22%)]\tLoss: 0.227673\n",
      "Train Epoch: 1 [3000/9145 (33%)]\tLoss: 0.312872\n",
      "Train Epoch: 1 [4000/9145 (43%)]\tLoss: 0.403083\n",
      "Train Epoch: 1 [5000/9145 (54%)]\tLoss: 0.474877\n",
      "Train Epoch: 1 [6000/9145 (65%)]\tLoss: 0.304628\n",
      "Train Epoch: 1 [7000/9145 (76%)]\tLoss: 0.260877\n",
      "Train Epoch: 1 [8000/9145 (87%)]\tLoss: 0.294430\n",
      "Train Epoch: 1 [9000/9145 (98%)]\tLoss: 0.307107\n",
      "Train Epoch: 2 [0/9145 (0%)]\tLoss: 0.358088\n",
      "Train Epoch: 2 [1000/9145 (11%)]\tLoss: 0.434117\n",
      "Train Epoch: 2 [2000/9145 (22%)]\tLoss: 0.434526\n",
      "Train Epoch: 2 [3000/9145 (33%)]\tLoss: 0.265037\n",
      "Train Epoch: 2 [4000/9145 (43%)]\tLoss: 0.301261\n",
      "Train Epoch: 2 [5000/9145 (54%)]\tLoss: 0.313507\n",
      "Train Epoch: 2 [6000/9145 (65%)]\tLoss: 0.347825\n",
      "Train Epoch: 2 [7000/9145 (76%)]\tLoss: 0.385534\n",
      "Train Epoch: 2 [8000/9145 (87%)]\tLoss: 0.268592\n",
      "Train Epoch: 2 [9000/9145 (98%)]\tLoss: 0.378709\n",
      "Train Epoch: 3 [0/9145 (0%)]\tLoss: 0.285094\n",
      "Train Epoch: 3 [1000/9145 (11%)]\tLoss: 0.409793\n",
      "Train Epoch: 3 [2000/9145 (22%)]\tLoss: 0.289470\n",
      "Train Epoch: 3 [3000/9145 (33%)]\tLoss: 0.289405\n",
      "Train Epoch: 3 [4000/9145 (43%)]\tLoss: 0.335377\n",
      "Train Epoch: 3 [5000/9145 (54%)]\tLoss: 0.475078\n",
      "Train Epoch: 3 [6000/9145 (65%)]\tLoss: 0.396592\n",
      "Train Epoch: 3 [7000/9145 (76%)]\tLoss: 0.273485\n",
      "Train Epoch: 3 [8000/9145 (87%)]\tLoss: 0.390235\n",
      "Train Epoch: 3 [9000/9145 (98%)]\tLoss: 0.275336\n",
      "Train Epoch: 4 [0/9145 (0%)]\tLoss: 0.337466\n",
      "Train Epoch: 4 [1000/9145 (11%)]\tLoss: 0.235442\n",
      "Train Epoch: 4 [2000/9145 (22%)]\tLoss: 0.229023\n",
      "Train Epoch: 4 [3000/9145 (33%)]\tLoss: 0.283874\n",
      "Train Epoch: 4 [4000/9145 (43%)]\tLoss: 0.306369\n",
      "Train Epoch: 4 [5000/9145 (54%)]\tLoss: 0.202076\n",
      "Train Epoch: 4 [6000/9145 (65%)]\tLoss: 0.349077\n",
      "Train Epoch: 4 [7000/9145 (76%)]\tLoss: 0.370772\n",
      "Train Epoch: 4 [8000/9145 (87%)]\tLoss: 0.425367\n",
      "Train Epoch: 4 [9000/9145 (98%)]\tLoss: 0.329704\n",
      "Train Epoch: 5 [0/9145 (0%)]\tLoss: 0.277774\n",
      "Train Epoch: 5 [1000/9145 (11%)]\tLoss: 0.447808\n",
      "Train Epoch: 5 [2000/9145 (22%)]\tLoss: 0.304739\n",
      "Train Epoch: 5 [3000/9145 (33%)]\tLoss: 0.363572\n",
      "Train Epoch: 5 [4000/9145 (43%)]\tLoss: 0.365129\n",
      "Train Epoch: 5 [5000/9145 (54%)]\tLoss: 0.321959\n",
      "Train Epoch: 5 [6000/9145 (65%)]\tLoss: 0.258764\n",
      "Train Epoch: 5 [7000/9145 (76%)]\tLoss: 0.234884\n",
      "Train Epoch: 5 [8000/9145 (87%)]\tLoss: 0.362813\n",
      "Train Epoch: 5 [9000/9145 (98%)]\tLoss: 0.399319\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3021 (0%)]\tLoss: 0.426074\n",
      "Train Epoch: 1 [1000/3021 (32%)]\tLoss: 0.348475\n",
      "Train Epoch: 1 [2000/3021 (65%)]\tLoss: 0.421937\n",
      "Train Epoch: 1 [630/3021 (97%)]\tLoss: 0.237103\n",
      "Train Epoch: 2 [0/3021 (0%)]\tLoss: 0.394768\n",
      "Train Epoch: 2 [1000/3021 (32%)]\tLoss: 0.188661\n",
      "Train Epoch: 2 [2000/3021 (65%)]\tLoss: 0.424096\n",
      "Train Epoch: 2 [630/3021 (97%)]\tLoss: 0.362425\n",
      "Train Epoch: 3 [0/3021 (0%)]\tLoss: 0.215545\n",
      "Train Epoch: 3 [1000/3021 (32%)]\tLoss: 0.320529\n",
      "Train Epoch: 3 [2000/3021 (65%)]\tLoss: 0.333629\n",
      "Train Epoch: 3 [630/3021 (97%)]\tLoss: 0.227769\n",
      "Train Epoch: 4 [0/3021 (0%)]\tLoss: 0.215819\n",
      "Train Epoch: 4 [1000/3021 (32%)]\tLoss: 0.222288\n",
      "Train Epoch: 4 [2000/3021 (65%)]\tLoss: 0.281000\n",
      "Train Epoch: 4 [630/3021 (97%)]\tLoss: 0.228861\n",
      "Train Epoch: 5 [0/3021 (0%)]\tLoss: 0.322823\n",
      "Train Epoch: 5 [1000/3021 (32%)]\tLoss: 0.431353\n",
      "Train Epoch: 5 [2000/3021 (65%)]\tLoss: 0.312964\n",
      "Train Epoch: 5 [630/3021 (97%)]\tLoss: 0.296670\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/7953 (0%)]\tLoss: 0.492299\n",
      "Train Epoch: 1 [1000/7953 (12%)]\tLoss: 0.584153\n",
      "Train Epoch: 1 [2000/7953 (25%)]\tLoss: 0.600446\n",
      "Train Epoch: 1 [3000/7953 (38%)]\tLoss: 0.633063\n",
      "Train Epoch: 1 [4000/7953 (50%)]\tLoss: 0.560015\n",
      "Train Epoch: 1 [5000/7953 (62%)]\tLoss: 0.490683\n",
      "Train Epoch: 1 [6000/7953 (75%)]\tLoss: 0.455785\n",
      "Train Epoch: 1 [7000/7953 (88%)]\tLoss: 0.529441\n",
      "Train Epoch: 2 [0/7953 (0%)]\tLoss: 0.567579\n",
      "Train Epoch: 2 [1000/7953 (12%)]\tLoss: 0.411568\n",
      "Train Epoch: 2 [2000/7953 (25%)]\tLoss: 0.565364\n",
      "Train Epoch: 2 [3000/7953 (38%)]\tLoss: 0.459734\n",
      "Train Epoch: 2 [4000/7953 (50%)]\tLoss: 0.535648\n",
      "Train Epoch: 2 [5000/7953 (62%)]\tLoss: 0.450277\n",
      "Train Epoch: 2 [6000/7953 (75%)]\tLoss: 0.683078\n",
      "Train Epoch: 2 [7000/7953 (88%)]\tLoss: 0.598810\n",
      "Train Epoch: 3 [0/7953 (0%)]\tLoss: 0.419010\n",
      "Train Epoch: 3 [1000/7953 (12%)]\tLoss: 0.519876\n",
      "Train Epoch: 3 [2000/7953 (25%)]\tLoss: 0.628119\n",
      "Train Epoch: 3 [3000/7953 (38%)]\tLoss: 0.502808\n",
      "Train Epoch: 3 [4000/7953 (50%)]\tLoss: 0.541755\n",
      "Train Epoch: 3 [5000/7953 (62%)]\tLoss: 0.542008\n",
      "Train Epoch: 3 [6000/7953 (75%)]\tLoss: 0.573804\n",
      "Train Epoch: 3 [7000/7953 (88%)]\tLoss: 0.530658\n",
      "Train Epoch: 4 [0/7953 (0%)]\tLoss: 0.697689\n",
      "Train Epoch: 4 [1000/7953 (12%)]\tLoss: 0.659698\n",
      "Train Epoch: 4 [2000/7953 (25%)]\tLoss: 0.502739\n",
      "Train Epoch: 4 [3000/7953 (38%)]\tLoss: 0.463472\n",
      "Train Epoch: 4 [4000/7953 (50%)]\tLoss: 0.518053\n",
      "Train Epoch: 4 [5000/7953 (62%)]\tLoss: 0.482409\n",
      "Train Epoch: 4 [6000/7953 (75%)]\tLoss: 0.403769\n",
      "Train Epoch: 4 [7000/7953 (88%)]\tLoss: 0.593164\n",
      "Train Epoch: 5 [0/7953 (0%)]\tLoss: 0.505704\n",
      "Train Epoch: 5 [1000/7953 (12%)]\tLoss: 0.628289\n",
      "Train Epoch: 5 [2000/7953 (25%)]\tLoss: 0.452257\n",
      "Train Epoch: 5 [3000/7953 (38%)]\tLoss: 0.573703\n",
      "Train Epoch: 5 [4000/7953 (50%)]\tLoss: 0.503807\n",
      "Train Epoch: 5 [5000/7953 (62%)]\tLoss: 0.632682\n",
      "Train Epoch: 5 [6000/7953 (75%)]\tLoss: 0.510179\n",
      "Train Epoch: 5 [7000/7953 (88%)]\tLoss: 0.475870\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/10012 (0%)]\tLoss: 0.378897\n",
      "Train Epoch: 1 [1000/10012 (10%)]\tLoss: 0.335089\n",
      "Train Epoch: 1 [2000/10012 (20%)]\tLoss: 0.279157\n",
      "Train Epoch: 1 [3000/10012 (30%)]\tLoss: 0.158371\n",
      "Train Epoch: 1 [4000/10012 (40%)]\tLoss: 0.153322\n",
      "Train Epoch: 1 [5000/10012 (50%)]\tLoss: 0.177065\n",
      "Train Epoch: 1 [6000/10012 (59%)]\tLoss: 0.127014\n",
      "Train Epoch: 1 [7000/10012 (69%)]\tLoss: 0.346610\n",
      "Train Epoch: 1 [8000/10012 (79%)]\tLoss: 0.281800\n",
      "Train Epoch: 1 [9000/10012 (89%)]\tLoss: 0.156002\n",
      "Train Epoch: 1 [1200/10012 (99%)]\tLoss: 0.084231\n",
      "Train Epoch: 2 [0/10012 (0%)]\tLoss: 0.270092\n",
      "Train Epoch: 2 [1000/10012 (10%)]\tLoss: 0.242119\n",
      "Train Epoch: 2 [2000/10012 (20%)]\tLoss: 0.193220\n",
      "Train Epoch: 2 [3000/10012 (30%)]\tLoss: 0.207416\n",
      "Train Epoch: 2 [4000/10012 (40%)]\tLoss: 0.147662\n",
      "Train Epoch: 2 [5000/10012 (50%)]\tLoss: 0.178371\n",
      "Train Epoch: 2 [6000/10012 (59%)]\tLoss: 0.290011\n",
      "Train Epoch: 2 [7000/10012 (69%)]\tLoss: 0.352124\n",
      "Train Epoch: 2 [8000/10012 (79%)]\tLoss: 0.217512\n",
      "Train Epoch: 2 [9000/10012 (89%)]\tLoss: 0.234553\n",
      "Train Epoch: 2 [1200/10012 (99%)]\tLoss: 0.231023\n",
      "Train Epoch: 3 [0/10012 (0%)]\tLoss: 0.204324\n",
      "Train Epoch: 3 [1000/10012 (10%)]\tLoss: 0.259585\n",
      "Train Epoch: 3 [2000/10012 (20%)]\tLoss: 0.183790\n",
      "Train Epoch: 3 [3000/10012 (30%)]\tLoss: 0.294385\n",
      "Train Epoch: 3 [4000/10012 (40%)]\tLoss: 0.357411\n",
      "Train Epoch: 3 [5000/10012 (50%)]\tLoss: 0.268157\n",
      "Train Epoch: 3 [6000/10012 (59%)]\tLoss: 0.208086\n",
      "Train Epoch: 3 [7000/10012 (69%)]\tLoss: 0.238097\n",
      "Train Epoch: 3 [8000/10012 (79%)]\tLoss: 0.181923\n",
      "Train Epoch: 3 [9000/10012 (89%)]\tLoss: 0.210052\n",
      "Train Epoch: 3 [1200/10012 (99%)]\tLoss: 0.364936\n",
      "Train Epoch: 4 [0/10012 (0%)]\tLoss: 0.146778\n",
      "Train Epoch: 4 [1000/10012 (10%)]\tLoss: 0.196172\n",
      "Train Epoch: 4 [2000/10012 (20%)]\tLoss: 0.133262\n",
      "Train Epoch: 4 [3000/10012 (30%)]\tLoss: 0.249937\n",
      "Train Epoch: 4 [4000/10012 (40%)]\tLoss: 0.128814\n",
      "Train Epoch: 4 [5000/10012 (50%)]\tLoss: 0.240551\n",
      "Train Epoch: 4 [6000/10012 (59%)]\tLoss: 0.136848\n",
      "Train Epoch: 4 [7000/10012 (69%)]\tLoss: 0.171996\n",
      "Train Epoch: 4 [8000/10012 (79%)]\tLoss: 0.144800\n",
      "Train Epoch: 4 [9000/10012 (89%)]\tLoss: 0.232417\n",
      "Train Epoch: 4 [1200/10012 (99%)]\tLoss: 0.396428\n",
      "Train Epoch: 5 [0/10012 (0%)]\tLoss: 0.197060\n",
      "Train Epoch: 5 [1000/10012 (10%)]\tLoss: 0.372902\n",
      "Train Epoch: 5 [2000/10012 (20%)]\tLoss: 0.147795\n",
      "Train Epoch: 5 [3000/10012 (30%)]\tLoss: 0.128729\n",
      "Train Epoch: 5 [4000/10012 (40%)]\tLoss: 0.370585\n",
      "Train Epoch: 5 [5000/10012 (50%)]\tLoss: 0.316568\n",
      "Train Epoch: 5 [6000/10012 (59%)]\tLoss: 0.231329\n",
      "Train Epoch: 5 [7000/10012 (69%)]\tLoss: 0.246220\n",
      "Train Epoch: 5 [8000/10012 (79%)]\tLoss: 0.269798\n",
      "Train Epoch: 5 [9000/10012 (89%)]\tLoss: 0.129859\n",
      "Train Epoch: 5 [1200/10012 (99%)]\tLoss: 0.020228\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "8\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9907, Accuracy: 7618/10000 (76%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/20764 (0%)]\tLoss: 0.409042\n",
      "Train Epoch: 1 [1000/20764 (5%)]\tLoss: 0.368976\n",
      "Train Epoch: 1 [2000/20764 (10%)]\tLoss: 0.207533\n",
      "Train Epoch: 1 [3000/20764 (14%)]\tLoss: 0.386075\n",
      "Train Epoch: 1 [4000/20764 (19%)]\tLoss: 0.387717\n",
      "Train Epoch: 1 [5000/20764 (24%)]\tLoss: 0.363241\n",
      "Train Epoch: 1 [6000/20764 (29%)]\tLoss: 0.312162\n",
      "Train Epoch: 1 [7000/20764 (34%)]\tLoss: 0.381207\n",
      "Train Epoch: 1 [8000/20764 (38%)]\tLoss: 0.303505\n",
      "Train Epoch: 1 [9000/20764 (43%)]\tLoss: 0.280845\n",
      "Train Epoch: 1 [10000/20764 (48%)]\tLoss: 0.416486\n",
      "Train Epoch: 1 [11000/20764 (53%)]\tLoss: 0.242761\n",
      "Train Epoch: 1 [12000/20764 (58%)]\tLoss: 0.400281\n",
      "Train Epoch: 1 [13000/20764 (62%)]\tLoss: 0.405627\n",
      "Train Epoch: 1 [14000/20764 (67%)]\tLoss: 0.260176\n",
      "Train Epoch: 1 [15000/20764 (72%)]\tLoss: 0.439939\n",
      "Train Epoch: 1 [16000/20764 (77%)]\tLoss: 0.355275\n",
      "Train Epoch: 1 [17000/20764 (82%)]\tLoss: 0.280903\n",
      "Train Epoch: 1 [18000/20764 (87%)]\tLoss: 0.278199\n",
      "Train Epoch: 1 [19000/20764 (91%)]\tLoss: 0.316204\n",
      "Train Epoch: 1 [20000/20764 (96%)]\tLoss: 0.299543\n",
      "Train Epoch: 2 [0/20764 (0%)]\tLoss: 0.214585\n",
      "Train Epoch: 2 [1000/20764 (5%)]\tLoss: 0.398767\n",
      "Train Epoch: 2 [2000/20764 (10%)]\tLoss: 0.338735\n",
      "Train Epoch: 2 [3000/20764 (14%)]\tLoss: 0.318889\n",
      "Train Epoch: 2 [4000/20764 (19%)]\tLoss: 0.334879\n",
      "Train Epoch: 2 [5000/20764 (24%)]\tLoss: 0.370813\n",
      "Train Epoch: 2 [6000/20764 (29%)]\tLoss: 0.305475\n",
      "Train Epoch: 2 [7000/20764 (34%)]\tLoss: 0.266881\n",
      "Train Epoch: 2 [8000/20764 (38%)]\tLoss: 0.350914\n",
      "Train Epoch: 2 [9000/20764 (43%)]\tLoss: 0.278589\n",
      "Train Epoch: 2 [10000/20764 (48%)]\tLoss: 0.477796\n",
      "Train Epoch: 2 [11000/20764 (53%)]\tLoss: 0.508347\n",
      "Train Epoch: 2 [12000/20764 (58%)]\tLoss: 0.243219\n",
      "Train Epoch: 2 [13000/20764 (62%)]\tLoss: 0.276243\n",
      "Train Epoch: 2 [14000/20764 (67%)]\tLoss: 0.347369\n",
      "Train Epoch: 2 [15000/20764 (72%)]\tLoss: 0.397154\n",
      "Train Epoch: 2 [16000/20764 (77%)]\tLoss: 0.441959\n",
      "Train Epoch: 2 [17000/20764 (82%)]\tLoss: 0.361560\n",
      "Train Epoch: 2 [18000/20764 (87%)]\tLoss: 0.254611\n",
      "Train Epoch: 2 [19000/20764 (91%)]\tLoss: 0.260934\n",
      "Train Epoch: 2 [20000/20764 (96%)]\tLoss: 0.392154\n",
      "Train Epoch: 3 [0/20764 (0%)]\tLoss: 0.421260\n",
      "Train Epoch: 3 [1000/20764 (5%)]\tLoss: 0.482929\n",
      "Train Epoch: 3 [2000/20764 (10%)]\tLoss: 0.525021\n",
      "Train Epoch: 3 [3000/20764 (14%)]\tLoss: 0.321103\n",
      "Train Epoch: 3 [4000/20764 (19%)]\tLoss: 0.353234\n",
      "Train Epoch: 3 [5000/20764 (24%)]\tLoss: 0.289480\n",
      "Train Epoch: 3 [6000/20764 (29%)]\tLoss: 0.240033\n",
      "Train Epoch: 3 [7000/20764 (34%)]\tLoss: 0.342052\n",
      "Train Epoch: 3 [8000/20764 (38%)]\tLoss: 0.428496\n",
      "Train Epoch: 3 [9000/20764 (43%)]\tLoss: 0.420829\n",
      "Train Epoch: 3 [10000/20764 (48%)]\tLoss: 0.395986\n",
      "Train Epoch: 3 [11000/20764 (53%)]\tLoss: 0.440584\n",
      "Train Epoch: 3 [12000/20764 (58%)]\tLoss: 0.311521\n",
      "Train Epoch: 3 [13000/20764 (62%)]\tLoss: 0.245962\n",
      "Train Epoch: 3 [14000/20764 (67%)]\tLoss: 0.335323\n",
      "Train Epoch: 3 [15000/20764 (72%)]\tLoss: 0.284767\n",
      "Train Epoch: 3 [16000/20764 (77%)]\tLoss: 0.358650\n",
      "Train Epoch: 3 [17000/20764 (82%)]\tLoss: 0.325286\n",
      "Train Epoch: 3 [18000/20764 (87%)]\tLoss: 0.466967\n",
      "Train Epoch: 3 [19000/20764 (91%)]\tLoss: 0.295545\n",
      "Train Epoch: 3 [20000/20764 (96%)]\tLoss: 0.561141\n",
      "Train Epoch: 4 [0/20764 (0%)]\tLoss: 0.462479\n",
      "Train Epoch: 4 [1000/20764 (5%)]\tLoss: 0.262875\n",
      "Train Epoch: 4 [2000/20764 (10%)]\tLoss: 0.309136\n",
      "Train Epoch: 4 [3000/20764 (14%)]\tLoss: 0.191668\n",
      "Train Epoch: 4 [4000/20764 (19%)]\tLoss: 0.328996\n",
      "Train Epoch: 4 [5000/20764 (24%)]\tLoss: 0.447580\n",
      "Train Epoch: 4 [6000/20764 (29%)]\tLoss: 0.306570\n",
      "Train Epoch: 4 [7000/20764 (34%)]\tLoss: 0.214868\n",
      "Train Epoch: 4 [8000/20764 (38%)]\tLoss: 0.474171\n",
      "Train Epoch: 4 [9000/20764 (43%)]\tLoss: 0.206441\n",
      "Train Epoch: 4 [10000/20764 (48%)]\tLoss: 0.327528\n",
      "Train Epoch: 4 [11000/20764 (53%)]\tLoss: 0.329379\n",
      "Train Epoch: 4 [12000/20764 (58%)]\tLoss: 0.372780\n",
      "Train Epoch: 4 [13000/20764 (62%)]\tLoss: 0.294666\n",
      "Train Epoch: 4 [14000/20764 (67%)]\tLoss: 0.330546\n",
      "Train Epoch: 4 [15000/20764 (72%)]\tLoss: 0.326409\n",
      "Train Epoch: 4 [16000/20764 (77%)]\tLoss: 0.371519\n",
      "Train Epoch: 4 [17000/20764 (82%)]\tLoss: 0.208392\n",
      "Train Epoch: 4 [18000/20764 (87%)]\tLoss: 0.337183\n",
      "Train Epoch: 4 [19000/20764 (91%)]\tLoss: 0.271648\n",
      "Train Epoch: 4 [20000/20764 (96%)]\tLoss: 0.369480\n",
      "Train Epoch: 5 [0/20764 (0%)]\tLoss: 0.299464\n",
      "Train Epoch: 5 [1000/20764 (5%)]\tLoss: 0.288667\n",
      "Train Epoch: 5 [2000/20764 (10%)]\tLoss: 0.256970\n",
      "Train Epoch: 5 [3000/20764 (14%)]\tLoss: 0.404124\n",
      "Train Epoch: 5 [4000/20764 (19%)]\tLoss: 0.249268\n",
      "Train Epoch: 5 [5000/20764 (24%)]\tLoss: 0.438202\n",
      "Train Epoch: 5 [6000/20764 (29%)]\tLoss: 0.284628\n",
      "Train Epoch: 5 [7000/20764 (34%)]\tLoss: 0.213760\n",
      "Train Epoch: 5 [8000/20764 (38%)]\tLoss: 0.232415\n",
      "Train Epoch: 5 [9000/20764 (43%)]\tLoss: 0.276798\n",
      "Train Epoch: 5 [10000/20764 (48%)]\tLoss: 0.354806\n",
      "Train Epoch: 5 [11000/20764 (53%)]\tLoss: 0.472957\n",
      "Train Epoch: 5 [12000/20764 (58%)]\tLoss: 0.453842\n",
      "Train Epoch: 5 [13000/20764 (62%)]\tLoss: 0.290080\n",
      "Train Epoch: 5 [14000/20764 (67%)]\tLoss: 0.239000\n",
      "Train Epoch: 5 [15000/20764 (72%)]\tLoss: 0.183518\n",
      "Train Epoch: 5 [16000/20764 (77%)]\tLoss: 0.341804\n",
      "Train Epoch: 5 [17000/20764 (82%)]\tLoss: 0.370117\n",
      "Train Epoch: 5 [18000/20764 (87%)]\tLoss: 0.347358\n",
      "Train Epoch: 5 [19000/20764 (91%)]\tLoss: 0.307871\n",
      "Train Epoch: 5 [20000/20764 (96%)]\tLoss: 0.301885\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11194 (0%)]\tLoss: 0.391568\n",
      "Train Epoch: 1 [1000/11194 (9%)]\tLoss: 0.433739\n",
      "Train Epoch: 1 [2000/11194 (18%)]\tLoss: 0.357356\n",
      "Train Epoch: 1 [3000/11194 (27%)]\tLoss: 0.255823\n",
      "Train Epoch: 1 [4000/11194 (36%)]\tLoss: 0.363883\n",
      "Train Epoch: 1 [5000/11194 (45%)]\tLoss: 0.278634\n",
      "Train Epoch: 1 [6000/11194 (54%)]\tLoss: 0.450460\n",
      "Train Epoch: 1 [7000/11194 (62%)]\tLoss: 0.279184\n",
      "Train Epoch: 1 [8000/11194 (71%)]\tLoss: 0.252491\n",
      "Train Epoch: 1 [9000/11194 (80%)]\tLoss: 0.391892\n",
      "Train Epoch: 1 [10000/11194 (89%)]\tLoss: 0.229960\n",
      "Train Epoch: 1 [11000/11194 (98%)]\tLoss: 0.353839\n",
      "Train Epoch: 2 [0/11194 (0%)]\tLoss: 0.392067\n",
      "Train Epoch: 2 [1000/11194 (9%)]\tLoss: 0.299444\n",
      "Train Epoch: 2 [2000/11194 (18%)]\tLoss: 0.365979\n",
      "Train Epoch: 2 [3000/11194 (27%)]\tLoss: 0.414154\n",
      "Train Epoch: 2 [4000/11194 (36%)]\tLoss: 0.209952\n",
      "Train Epoch: 2 [5000/11194 (45%)]\tLoss: 0.365747\n",
      "Train Epoch: 2 [6000/11194 (54%)]\tLoss: 0.399674\n",
      "Train Epoch: 2 [7000/11194 (62%)]\tLoss: 0.321322\n",
      "Train Epoch: 2 [8000/11194 (71%)]\tLoss: 0.507700\n",
      "Train Epoch: 2 [9000/11194 (80%)]\tLoss: 0.258535\n",
      "Train Epoch: 2 [10000/11194 (89%)]\tLoss: 0.285226\n",
      "Train Epoch: 2 [11000/11194 (98%)]\tLoss: 0.224951\n",
      "Train Epoch: 3 [0/11194 (0%)]\tLoss: 0.327386\n",
      "Train Epoch: 3 [1000/11194 (9%)]\tLoss: 0.345277\n",
      "Train Epoch: 3 [2000/11194 (18%)]\tLoss: 0.302575\n",
      "Train Epoch: 3 [3000/11194 (27%)]\tLoss: 0.283286\n",
      "Train Epoch: 3 [4000/11194 (36%)]\tLoss: 0.161565\n",
      "Train Epoch: 3 [5000/11194 (45%)]\tLoss: 0.231649\n",
      "Train Epoch: 3 [6000/11194 (54%)]\tLoss: 0.312302\n",
      "Train Epoch: 3 [7000/11194 (62%)]\tLoss: 0.295821\n",
      "Train Epoch: 3 [8000/11194 (71%)]\tLoss: 0.236854\n",
      "Train Epoch: 3 [9000/11194 (80%)]\tLoss: 0.292257\n",
      "Train Epoch: 3 [10000/11194 (89%)]\tLoss: 0.278185\n",
      "Train Epoch: 3 [11000/11194 (98%)]\tLoss: 0.187777\n",
      "Train Epoch: 4 [0/11194 (0%)]\tLoss: 0.261225\n",
      "Train Epoch: 4 [1000/11194 (9%)]\tLoss: 0.410819\n",
      "Train Epoch: 4 [2000/11194 (18%)]\tLoss: 0.411551\n",
      "Train Epoch: 4 [3000/11194 (27%)]\tLoss: 0.299711\n",
      "Train Epoch: 4 [4000/11194 (36%)]\tLoss: 0.209477\n",
      "Train Epoch: 4 [5000/11194 (45%)]\tLoss: 0.190491\n",
      "Train Epoch: 4 [6000/11194 (54%)]\tLoss: 0.232190\n",
      "Train Epoch: 4 [7000/11194 (62%)]\tLoss: 0.365963\n",
      "Train Epoch: 4 [8000/11194 (71%)]\tLoss: 0.224328\n",
      "Train Epoch: 4 [9000/11194 (80%)]\tLoss: 0.208464\n",
      "Train Epoch: 4 [10000/11194 (89%)]\tLoss: 0.309777\n",
      "Train Epoch: 4 [11000/11194 (98%)]\tLoss: 0.299736\n",
      "Train Epoch: 5 [0/11194 (0%)]\tLoss: 0.241413\n",
      "Train Epoch: 5 [1000/11194 (9%)]\tLoss: 0.287196\n",
      "Train Epoch: 5 [2000/11194 (18%)]\tLoss: 0.329956\n",
      "Train Epoch: 5 [3000/11194 (27%)]\tLoss: 0.277179\n",
      "Train Epoch: 5 [4000/11194 (36%)]\tLoss: 0.179185\n",
      "Train Epoch: 5 [5000/11194 (45%)]\tLoss: 0.319353\n",
      "Train Epoch: 5 [6000/11194 (54%)]\tLoss: 0.279492\n",
      "Train Epoch: 5 [7000/11194 (62%)]\tLoss: 0.316390\n",
      "Train Epoch: 5 [8000/11194 (71%)]\tLoss: 0.287980\n",
      "Train Epoch: 5 [9000/11194 (80%)]\tLoss: 0.219329\n",
      "Train Epoch: 5 [10000/11194 (89%)]\tLoss: 0.379157\n",
      "Train Epoch: 5 [11000/11194 (98%)]\tLoss: 0.327343\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "8\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.0701, Accuracy: 7356/10000 (74%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/20764 (0%)]\tLoss: 0.602203\n",
      "Train Epoch: 1 [1000/20764 (5%)]\tLoss: 0.259270\n",
      "Train Epoch: 1 [2000/20764 (10%)]\tLoss: 0.438734\n",
      "Train Epoch: 1 [3000/20764 (14%)]\tLoss: 0.304979\n",
      "Train Epoch: 1 [4000/20764 (19%)]\tLoss: 0.272191\n",
      "Train Epoch: 1 [5000/20764 (24%)]\tLoss: 0.394275\n",
      "Train Epoch: 1 [6000/20764 (29%)]\tLoss: 0.454872\n",
      "Train Epoch: 1 [7000/20764 (34%)]\tLoss: 0.377875\n",
      "Train Epoch: 1 [8000/20764 (38%)]\tLoss: 0.383909\n",
      "Train Epoch: 1 [9000/20764 (43%)]\tLoss: 0.367180\n",
      "Train Epoch: 1 [10000/20764 (48%)]\tLoss: 0.361776\n",
      "Train Epoch: 1 [11000/20764 (53%)]\tLoss: 0.302288\n",
      "Train Epoch: 1 [12000/20764 (58%)]\tLoss: 0.350776\n",
      "Train Epoch: 1 [13000/20764 (62%)]\tLoss: 0.389513\n",
      "Train Epoch: 1 [14000/20764 (67%)]\tLoss: 0.310096\n",
      "Train Epoch: 1 [15000/20764 (72%)]\tLoss: 0.268726\n",
      "Train Epoch: 1 [16000/20764 (77%)]\tLoss: 0.318830\n",
      "Train Epoch: 1 [17000/20764 (82%)]\tLoss: 0.427923\n",
      "Train Epoch: 1 [18000/20764 (87%)]\tLoss: 0.463488\n",
      "Train Epoch: 1 [19000/20764 (91%)]\tLoss: 0.391709\n",
      "Train Epoch: 1 [20000/20764 (96%)]\tLoss: 0.274755\n",
      "Train Epoch: 2 [0/20764 (0%)]\tLoss: 0.359026\n",
      "Train Epoch: 2 [1000/20764 (5%)]\tLoss: 0.306736\n",
      "Train Epoch: 2 [2000/20764 (10%)]\tLoss: 0.392061\n",
      "Train Epoch: 2 [3000/20764 (14%)]\tLoss: 0.222019\n",
      "Train Epoch: 2 [4000/20764 (19%)]\tLoss: 0.336502\n",
      "Train Epoch: 2 [5000/20764 (24%)]\tLoss: 0.471883\n",
      "Train Epoch: 2 [6000/20764 (29%)]\tLoss: 0.319053\n",
      "Train Epoch: 2 [7000/20764 (34%)]\tLoss: 0.327684\n",
      "Train Epoch: 2 [8000/20764 (38%)]\tLoss: 0.311289\n",
      "Train Epoch: 2 [9000/20764 (43%)]\tLoss: 0.310786\n",
      "Train Epoch: 2 [10000/20764 (48%)]\tLoss: 0.269283\n",
      "Train Epoch: 2 [11000/20764 (53%)]\tLoss: 0.262223\n",
      "Train Epoch: 2 [12000/20764 (58%)]\tLoss: 0.309247\n",
      "Train Epoch: 2 [13000/20764 (62%)]\tLoss: 0.235287\n",
      "Train Epoch: 2 [14000/20764 (67%)]\tLoss: 0.377114\n",
      "Train Epoch: 2 [15000/20764 (72%)]\tLoss: 0.411166\n",
      "Train Epoch: 2 [16000/20764 (77%)]\tLoss: 0.430743\n",
      "Train Epoch: 2 [17000/20764 (82%)]\tLoss: 0.373202\n",
      "Train Epoch: 2 [18000/20764 (87%)]\tLoss: 0.351399\n",
      "Train Epoch: 2 [19000/20764 (91%)]\tLoss: 0.510261\n",
      "Train Epoch: 2 [20000/20764 (96%)]\tLoss: 0.191667\n",
      "Train Epoch: 3 [0/20764 (0%)]\tLoss: 0.277544\n",
      "Train Epoch: 3 [1000/20764 (5%)]\tLoss: 0.462381\n",
      "Train Epoch: 3 [2000/20764 (10%)]\tLoss: 0.345688\n",
      "Train Epoch: 3 [3000/20764 (14%)]\tLoss: 0.385423\n",
      "Train Epoch: 3 [4000/20764 (19%)]\tLoss: 0.350918\n",
      "Train Epoch: 3 [5000/20764 (24%)]\tLoss: 0.411926\n",
      "Train Epoch: 3 [6000/20764 (29%)]\tLoss: 0.381965\n",
      "Train Epoch: 3 [7000/20764 (34%)]\tLoss: 0.444095\n",
      "Train Epoch: 3 [8000/20764 (38%)]\tLoss: 0.265329\n",
      "Train Epoch: 3 [9000/20764 (43%)]\tLoss: 0.309885\n",
      "Train Epoch: 3 [10000/20764 (48%)]\tLoss: 0.294112\n",
      "Train Epoch: 3 [11000/20764 (53%)]\tLoss: 0.239591\n",
      "Train Epoch: 3 [12000/20764 (58%)]\tLoss: 0.461471\n",
      "Train Epoch: 3 [13000/20764 (62%)]\tLoss: 0.332801\n",
      "Train Epoch: 3 [14000/20764 (67%)]\tLoss: 0.203696\n",
      "Train Epoch: 3 [15000/20764 (72%)]\tLoss: 0.289892\n",
      "Train Epoch: 3 [16000/20764 (77%)]\tLoss: 0.193285\n",
      "Train Epoch: 3 [17000/20764 (82%)]\tLoss: 0.515249\n",
      "Train Epoch: 3 [18000/20764 (87%)]\tLoss: 0.351032\n",
      "Train Epoch: 3 [19000/20764 (91%)]\tLoss: 0.430493\n",
      "Train Epoch: 3 [20000/20764 (96%)]\tLoss: 0.341734\n",
      "Train Epoch: 4 [0/20764 (0%)]\tLoss: 0.214501\n",
      "Train Epoch: 4 [1000/20764 (5%)]\tLoss: 0.259590\n",
      "Train Epoch: 4 [2000/20764 (10%)]\tLoss: 0.346211\n",
      "Train Epoch: 4 [3000/20764 (14%)]\tLoss: 0.233223\n",
      "Train Epoch: 4 [4000/20764 (19%)]\tLoss: 0.177282\n",
      "Train Epoch: 4 [5000/20764 (24%)]\tLoss: 0.222996\n",
      "Train Epoch: 4 [6000/20764 (29%)]\tLoss: 0.327327\n",
      "Train Epoch: 4 [7000/20764 (34%)]\tLoss: 0.402828\n",
      "Train Epoch: 4 [8000/20764 (38%)]\tLoss: 0.220357\n",
      "Train Epoch: 4 [9000/20764 (43%)]\tLoss: 0.311258\n",
      "Train Epoch: 4 [10000/20764 (48%)]\tLoss: 0.396179\n",
      "Train Epoch: 4 [11000/20764 (53%)]\tLoss: 0.378452\n",
      "Train Epoch: 4 [12000/20764 (58%)]\tLoss: 0.461621\n",
      "Train Epoch: 4 [13000/20764 (62%)]\tLoss: 0.214361\n",
      "Train Epoch: 4 [14000/20764 (67%)]\tLoss: 0.244856\n",
      "Train Epoch: 4 [15000/20764 (72%)]\tLoss: 0.394251\n",
      "Train Epoch: 4 [16000/20764 (77%)]\tLoss: 0.425297\n",
      "Train Epoch: 4 [17000/20764 (82%)]\tLoss: 0.235188\n",
      "Train Epoch: 4 [18000/20764 (87%)]\tLoss: 0.396367\n",
      "Train Epoch: 4 [19000/20764 (91%)]\tLoss: 0.313302\n",
      "Train Epoch: 4 [20000/20764 (96%)]\tLoss: 0.230141\n",
      "Train Epoch: 5 [0/20764 (0%)]\tLoss: 0.428074\n",
      "Train Epoch: 5 [1000/20764 (5%)]\tLoss: 0.294721\n",
      "Train Epoch: 5 [2000/20764 (10%)]\tLoss: 0.368490\n",
      "Train Epoch: 5 [3000/20764 (14%)]\tLoss: 0.374927\n",
      "Train Epoch: 5 [4000/20764 (19%)]\tLoss: 0.329367\n",
      "Train Epoch: 5 [5000/20764 (24%)]\tLoss: 0.374690\n",
      "Train Epoch: 5 [6000/20764 (29%)]\tLoss: 0.341271\n",
      "Train Epoch: 5 [7000/20764 (34%)]\tLoss: 0.329454\n",
      "Train Epoch: 5 [8000/20764 (38%)]\tLoss: 0.453167\n",
      "Train Epoch: 5 [9000/20764 (43%)]\tLoss: 0.277905\n",
      "Train Epoch: 5 [10000/20764 (48%)]\tLoss: 0.181135\n",
      "Train Epoch: 5 [11000/20764 (53%)]\tLoss: 0.221948\n",
      "Train Epoch: 5 [12000/20764 (58%)]\tLoss: 0.365483\n",
      "Train Epoch: 5 [13000/20764 (62%)]\tLoss: 0.217808\n",
      "Train Epoch: 5 [14000/20764 (67%)]\tLoss: 0.283956\n",
      "Train Epoch: 5 [15000/20764 (72%)]\tLoss: 0.289433\n",
      "Train Epoch: 5 [16000/20764 (77%)]\tLoss: 0.315311\n",
      "Train Epoch: 5 [17000/20764 (82%)]\tLoss: 0.345452\n",
      "Train Epoch: 5 [18000/20764 (87%)]\tLoss: 0.351647\n",
      "Train Epoch: 5 [19000/20764 (91%)]\tLoss: 0.337799\n",
      "Train Epoch: 5 [20000/20764 (96%)]\tLoss: 0.365875\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11194 (0%)]\tLoss: 0.283054\n",
      "Train Epoch: 1 [1000/11194 (9%)]\tLoss: 0.330671\n",
      "Train Epoch: 1 [2000/11194 (18%)]\tLoss: 0.322266\n",
      "Train Epoch: 1 [3000/11194 (27%)]\tLoss: 0.311065\n",
      "Train Epoch: 1 [4000/11194 (36%)]\tLoss: 0.240344\n",
      "Train Epoch: 1 [5000/11194 (45%)]\tLoss: 0.230049\n",
      "Train Epoch: 1 [6000/11194 (54%)]\tLoss: 0.266684\n",
      "Train Epoch: 1 [7000/11194 (62%)]\tLoss: 0.243226\n",
      "Train Epoch: 1 [8000/11194 (71%)]\tLoss: 0.290267\n",
      "Train Epoch: 1 [9000/11194 (80%)]\tLoss: 0.227970\n",
      "Train Epoch: 1 [10000/11194 (89%)]\tLoss: 0.328110\n",
      "Train Epoch: 1 [11000/11194 (98%)]\tLoss: 0.390571\n",
      "Train Epoch: 2 [0/11194 (0%)]\tLoss: 0.279791\n",
      "Train Epoch: 2 [1000/11194 (9%)]\tLoss: 0.335131\n",
      "Train Epoch: 2 [2000/11194 (18%)]\tLoss: 0.256402\n",
      "Train Epoch: 2 [3000/11194 (27%)]\tLoss: 0.242068\n",
      "Train Epoch: 2 [4000/11194 (36%)]\tLoss: 0.361436\n",
      "Train Epoch: 2 [5000/11194 (45%)]\tLoss: 0.175202\n",
      "Train Epoch: 2 [6000/11194 (54%)]\tLoss: 0.599511\n",
      "Train Epoch: 2 [7000/11194 (62%)]\tLoss: 0.219866\n",
      "Train Epoch: 2 [8000/11194 (71%)]\tLoss: 0.279147\n",
      "Train Epoch: 2 [9000/11194 (80%)]\tLoss: 0.284107\n",
      "Train Epoch: 2 [10000/11194 (89%)]\tLoss: 0.328657\n",
      "Train Epoch: 2 [11000/11194 (98%)]\tLoss: 0.224004\n",
      "Train Epoch: 3 [0/11194 (0%)]\tLoss: 0.204448\n",
      "Train Epoch: 3 [1000/11194 (9%)]\tLoss: 0.329477\n",
      "Train Epoch: 3 [2000/11194 (18%)]\tLoss: 0.244363\n",
      "Train Epoch: 3 [3000/11194 (27%)]\tLoss: 0.252376\n",
      "Train Epoch: 3 [4000/11194 (36%)]\tLoss: 0.298205\n",
      "Train Epoch: 3 [5000/11194 (45%)]\tLoss: 0.341770\n",
      "Train Epoch: 3 [6000/11194 (54%)]\tLoss: 0.205625\n",
      "Train Epoch: 3 [7000/11194 (62%)]\tLoss: 0.206252\n",
      "Train Epoch: 3 [8000/11194 (71%)]\tLoss: 0.239884\n",
      "Train Epoch: 3 [9000/11194 (80%)]\tLoss: 0.297376\n",
      "Train Epoch: 3 [10000/11194 (89%)]\tLoss: 0.342820\n",
      "Train Epoch: 3 [11000/11194 (98%)]\tLoss: 0.329741\n",
      "Train Epoch: 4 [0/11194 (0%)]\tLoss: 0.280684\n",
      "Train Epoch: 4 [1000/11194 (9%)]\tLoss: 0.261849\n",
      "Train Epoch: 4 [2000/11194 (18%)]\tLoss: 0.307080\n",
      "Train Epoch: 4 [3000/11194 (27%)]\tLoss: 0.195167\n",
      "Train Epoch: 4 [4000/11194 (36%)]\tLoss: 0.229305\n",
      "Train Epoch: 4 [5000/11194 (45%)]\tLoss: 0.353387\n",
      "Train Epoch: 4 [6000/11194 (54%)]\tLoss: 0.181590\n",
      "Train Epoch: 4 [7000/11194 (62%)]\tLoss: 0.278370\n",
      "Train Epoch: 4 [8000/11194 (71%)]\tLoss: 0.367501\n",
      "Train Epoch: 4 [9000/11194 (80%)]\tLoss: 0.320592\n",
      "Train Epoch: 4 [10000/11194 (89%)]\tLoss: 0.313873\n",
      "Train Epoch: 4 [11000/11194 (98%)]\tLoss: 0.234924\n",
      "Train Epoch: 5 [0/11194 (0%)]\tLoss: 0.309761\n",
      "Train Epoch: 5 [1000/11194 (9%)]\tLoss: 0.208588\n",
      "Train Epoch: 5 [2000/11194 (18%)]\tLoss: 0.322317\n",
      "Train Epoch: 5 [3000/11194 (27%)]\tLoss: 0.182753\n",
      "Train Epoch: 5 [4000/11194 (36%)]\tLoss: 0.266212\n",
      "Train Epoch: 5 [5000/11194 (45%)]\tLoss: 0.398257\n",
      "Train Epoch: 5 [6000/11194 (54%)]\tLoss: 0.333472\n",
      "Train Epoch: 5 [7000/11194 (62%)]\tLoss: 0.289048\n",
      "Train Epoch: 5 [8000/11194 (71%)]\tLoss: 0.277285\n",
      "Train Epoch: 5 [9000/11194 (80%)]\tLoss: 0.367322\n",
      "Train Epoch: 5 [10000/11194 (89%)]\tLoss: 0.205100\n",
      "Train Epoch: 5 [11000/11194 (98%)]\tLoss: 0.383157\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "8\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.0920, Accuracy: 7364/10000 (74%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/20764 (0%)]\tLoss: 0.481968\n",
      "Train Epoch: 1 [1000/20764 (5%)]\tLoss: 0.384098\n",
      "Train Epoch: 1 [2000/20764 (10%)]\tLoss: 0.326122\n",
      "Train Epoch: 1 [3000/20764 (14%)]\tLoss: 0.475384\n",
      "Train Epoch: 1 [4000/20764 (19%)]\tLoss: 0.427658\n",
      "Train Epoch: 1 [5000/20764 (24%)]\tLoss: 0.309731\n",
      "Train Epoch: 1 [6000/20764 (29%)]\tLoss: 0.275022\n",
      "Train Epoch: 1 [7000/20764 (34%)]\tLoss: 0.247880\n",
      "Train Epoch: 1 [8000/20764 (38%)]\tLoss: 0.383240\n",
      "Train Epoch: 1 [9000/20764 (43%)]\tLoss: 0.263617\n",
      "Train Epoch: 1 [10000/20764 (48%)]\tLoss: 0.270708\n",
      "Train Epoch: 1 [11000/20764 (53%)]\tLoss: 0.390807\n",
      "Train Epoch: 1 [12000/20764 (58%)]\tLoss: 0.269997\n",
      "Train Epoch: 1 [13000/20764 (62%)]\tLoss: 0.535267\n",
      "Train Epoch: 1 [14000/20764 (67%)]\tLoss: 0.362850\n",
      "Train Epoch: 1 [15000/20764 (72%)]\tLoss: 0.697225\n",
      "Train Epoch: 1 [16000/20764 (77%)]\tLoss: 0.256899\n",
      "Train Epoch: 1 [17000/20764 (82%)]\tLoss: 0.462221\n",
      "Train Epoch: 1 [18000/20764 (87%)]\tLoss: 0.295788\n",
      "Train Epoch: 1 [19000/20764 (91%)]\tLoss: 0.154914\n",
      "Train Epoch: 1 [20000/20764 (96%)]\tLoss: 0.342372\n",
      "Train Epoch: 2 [0/20764 (0%)]\tLoss: 0.447244\n",
      "Train Epoch: 2 [1000/20764 (5%)]\tLoss: 0.291602\n",
      "Train Epoch: 2 [2000/20764 (10%)]\tLoss: 0.311164\n",
      "Train Epoch: 2 [3000/20764 (14%)]\tLoss: 0.347120\n",
      "Train Epoch: 2 [4000/20764 (19%)]\tLoss: 0.432744\n",
      "Train Epoch: 2 [5000/20764 (24%)]\tLoss: 0.250569\n",
      "Train Epoch: 2 [6000/20764 (29%)]\tLoss: 0.208741\n",
      "Train Epoch: 2 [7000/20764 (34%)]\tLoss: 0.269601\n",
      "Train Epoch: 2 [8000/20764 (38%)]\tLoss: 0.333673\n",
      "Train Epoch: 2 [9000/20764 (43%)]\tLoss: 0.210431\n",
      "Train Epoch: 2 [10000/20764 (48%)]\tLoss: 0.356615\n",
      "Train Epoch: 2 [11000/20764 (53%)]\tLoss: 0.287246\n",
      "Train Epoch: 2 [12000/20764 (58%)]\tLoss: 0.289878\n",
      "Train Epoch: 2 [13000/20764 (62%)]\tLoss: 0.384113\n",
      "Train Epoch: 2 [14000/20764 (67%)]\tLoss: 0.269626\n",
      "Train Epoch: 2 [15000/20764 (72%)]\tLoss: 0.270560\n",
      "Train Epoch: 2 [16000/20764 (77%)]\tLoss: 0.390783\n",
      "Train Epoch: 2 [17000/20764 (82%)]\tLoss: 0.495947\n",
      "Train Epoch: 2 [18000/20764 (87%)]\tLoss: 0.262184\n",
      "Train Epoch: 2 [19000/20764 (91%)]\tLoss: 0.326951\n",
      "Train Epoch: 2 [20000/20764 (96%)]\tLoss: 0.361456\n",
      "Train Epoch: 3 [0/20764 (0%)]\tLoss: 0.417988\n",
      "Train Epoch: 3 [1000/20764 (5%)]\tLoss: 0.351551\n",
      "Train Epoch: 3 [2000/20764 (10%)]\tLoss: 0.241115\n",
      "Train Epoch: 3 [3000/20764 (14%)]\tLoss: 0.333897\n",
      "Train Epoch: 3 [4000/20764 (19%)]\tLoss: 0.283881\n",
      "Train Epoch: 3 [5000/20764 (24%)]\tLoss: 0.252453\n",
      "Train Epoch: 3 [6000/20764 (29%)]\tLoss: 0.259485\n",
      "Train Epoch: 3 [7000/20764 (34%)]\tLoss: 0.405467\n",
      "Train Epoch: 3 [8000/20764 (38%)]\tLoss: 0.250267\n",
      "Train Epoch: 3 [9000/20764 (43%)]\tLoss: 0.338034\n",
      "Train Epoch: 3 [10000/20764 (48%)]\tLoss: 0.388089\n",
      "Train Epoch: 3 [11000/20764 (53%)]\tLoss: 0.304364\n",
      "Train Epoch: 3 [12000/20764 (58%)]\tLoss: 0.363643\n",
      "Train Epoch: 3 [13000/20764 (62%)]\tLoss: 0.326175\n",
      "Train Epoch: 3 [14000/20764 (67%)]\tLoss: 0.238194\n",
      "Train Epoch: 3 [15000/20764 (72%)]\tLoss: 0.283371\n",
      "Train Epoch: 3 [16000/20764 (77%)]\tLoss: 0.395370\n",
      "Train Epoch: 3 [17000/20764 (82%)]\tLoss: 0.258234\n",
      "Train Epoch: 3 [18000/20764 (87%)]\tLoss: 0.266366\n",
      "Train Epoch: 3 [19000/20764 (91%)]\tLoss: 0.226088\n",
      "Train Epoch: 3 [20000/20764 (96%)]\tLoss: 0.299014\n",
      "Train Epoch: 4 [0/20764 (0%)]\tLoss: 0.318799\n",
      "Train Epoch: 4 [1000/20764 (5%)]\tLoss: 0.237250\n",
      "Train Epoch: 4 [2000/20764 (10%)]\tLoss: 0.288129\n",
      "Train Epoch: 4 [3000/20764 (14%)]\tLoss: 0.338475\n",
      "Train Epoch: 4 [4000/20764 (19%)]\tLoss: 0.377571\n",
      "Train Epoch: 4 [5000/20764 (24%)]\tLoss: 0.319041\n",
      "Train Epoch: 4 [6000/20764 (29%)]\tLoss: 0.464757\n",
      "Train Epoch: 4 [7000/20764 (34%)]\tLoss: 0.306078\n",
      "Train Epoch: 4 [8000/20764 (38%)]\tLoss: 0.401401\n",
      "Train Epoch: 4 [9000/20764 (43%)]\tLoss: 0.402863\n",
      "Train Epoch: 4 [10000/20764 (48%)]\tLoss: 0.384512\n",
      "Train Epoch: 4 [11000/20764 (53%)]\tLoss: 0.419856\n",
      "Train Epoch: 4 [12000/20764 (58%)]\tLoss: 0.294417\n",
      "Train Epoch: 4 [13000/20764 (62%)]\tLoss: 0.382806\n",
      "Train Epoch: 4 [14000/20764 (67%)]\tLoss: 0.309203\n",
      "Train Epoch: 4 [15000/20764 (72%)]\tLoss: 0.260958\n",
      "Train Epoch: 4 [16000/20764 (77%)]\tLoss: 0.176939\n",
      "Train Epoch: 4 [17000/20764 (82%)]\tLoss: 0.243152\n",
      "Train Epoch: 4 [18000/20764 (87%)]\tLoss: 0.401014\n",
      "Train Epoch: 4 [19000/20764 (91%)]\tLoss: 0.260535\n",
      "Train Epoch: 4 [20000/20764 (96%)]\tLoss: 0.281286\n",
      "Train Epoch: 5 [0/20764 (0%)]\tLoss: 0.333011\n",
      "Train Epoch: 5 [1000/20764 (5%)]\tLoss: 0.198409\n",
      "Train Epoch: 5 [2000/20764 (10%)]\tLoss: 0.219267\n",
      "Train Epoch: 5 [3000/20764 (14%)]\tLoss: 0.258080\n",
      "Train Epoch: 5 [4000/20764 (19%)]\tLoss: 0.229102\n",
      "Train Epoch: 5 [5000/20764 (24%)]\tLoss: 0.469050\n",
      "Train Epoch: 5 [6000/20764 (29%)]\tLoss: 0.285591\n",
      "Train Epoch: 5 [7000/20764 (34%)]\tLoss: 0.458597\n",
      "Train Epoch: 5 [8000/20764 (38%)]\tLoss: 0.318009\n",
      "Train Epoch: 5 [9000/20764 (43%)]\tLoss: 0.358780\n",
      "Train Epoch: 5 [10000/20764 (48%)]\tLoss: 0.259534\n",
      "Train Epoch: 5 [11000/20764 (53%)]\tLoss: 0.286763\n",
      "Train Epoch: 5 [12000/20764 (58%)]\tLoss: 0.262909\n",
      "Train Epoch: 5 [13000/20764 (62%)]\tLoss: 0.269263\n",
      "Train Epoch: 5 [14000/20764 (67%)]\tLoss: 0.288764\n",
      "Train Epoch: 5 [15000/20764 (72%)]\tLoss: 0.351661\n",
      "Train Epoch: 5 [16000/20764 (77%)]\tLoss: 0.375415\n",
      "Train Epoch: 5 [17000/20764 (82%)]\tLoss: 0.381475\n",
      "Train Epoch: 5 [18000/20764 (87%)]\tLoss: 0.311341\n",
      "Train Epoch: 5 [19000/20764 (91%)]\tLoss: 0.330793\n",
      "Train Epoch: 5 [20000/20764 (96%)]\tLoss: 0.259688\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11194 (0%)]\tLoss: 0.269815\n",
      "Train Epoch: 1 [1000/11194 (9%)]\tLoss: 0.299343\n",
      "Train Epoch: 1 [2000/11194 (18%)]\tLoss: 0.424985\n",
      "Train Epoch: 1 [3000/11194 (27%)]\tLoss: 0.303838\n",
      "Train Epoch: 1 [4000/11194 (36%)]\tLoss: 0.381819\n",
      "Train Epoch: 1 [5000/11194 (45%)]\tLoss: 0.249082\n",
      "Train Epoch: 1 [6000/11194 (54%)]\tLoss: 0.227639\n",
      "Train Epoch: 1 [7000/11194 (62%)]\tLoss: 0.352209\n",
      "Train Epoch: 1 [8000/11194 (71%)]\tLoss: 0.316090\n",
      "Train Epoch: 1 [9000/11194 (80%)]\tLoss: 0.298957\n",
      "Train Epoch: 1 [10000/11194 (89%)]\tLoss: 0.354762\n",
      "Train Epoch: 1 [11000/11194 (98%)]\tLoss: 0.446262\n",
      "Train Epoch: 2 [0/11194 (0%)]\tLoss: 0.177040\n",
      "Train Epoch: 2 [1000/11194 (9%)]\tLoss: 0.349265\n",
      "Train Epoch: 2 [2000/11194 (18%)]\tLoss: 0.188194\n",
      "Train Epoch: 2 [3000/11194 (27%)]\tLoss: 0.232909\n",
      "Train Epoch: 2 [4000/11194 (36%)]\tLoss: 0.288081\n",
      "Train Epoch: 2 [5000/11194 (45%)]\tLoss: 0.144622\n",
      "Train Epoch: 2 [6000/11194 (54%)]\tLoss: 0.261997\n",
      "Train Epoch: 2 [7000/11194 (62%)]\tLoss: 0.407700\n",
      "Train Epoch: 2 [8000/11194 (71%)]\tLoss: 0.436812\n",
      "Train Epoch: 2 [9000/11194 (80%)]\tLoss: 0.434220\n",
      "Train Epoch: 2 [10000/11194 (89%)]\tLoss: 0.314443\n",
      "Train Epoch: 2 [11000/11194 (98%)]\tLoss: 0.251393\n",
      "Train Epoch: 3 [0/11194 (0%)]\tLoss: 0.461588\n",
      "Train Epoch: 3 [1000/11194 (9%)]\tLoss: 0.181482\n",
      "Train Epoch: 3 [2000/11194 (18%)]\tLoss: 0.265511\n",
      "Train Epoch: 3 [3000/11194 (27%)]\tLoss: 0.427834\n",
      "Train Epoch: 3 [4000/11194 (36%)]\tLoss: 0.228571\n",
      "Train Epoch: 3 [5000/11194 (45%)]\tLoss: 0.321366\n",
      "Train Epoch: 3 [6000/11194 (54%)]\tLoss: 0.234394\n",
      "Train Epoch: 3 [7000/11194 (62%)]\tLoss: 0.289957\n",
      "Train Epoch: 3 [8000/11194 (71%)]\tLoss: 0.329633\n",
      "Train Epoch: 3 [9000/11194 (80%)]\tLoss: 0.353331\n",
      "Train Epoch: 3 [10000/11194 (89%)]\tLoss: 0.333510\n",
      "Train Epoch: 3 [11000/11194 (98%)]\tLoss: 0.198822\n",
      "Train Epoch: 4 [0/11194 (0%)]\tLoss: 0.348444\n",
      "Train Epoch: 4 [1000/11194 (9%)]\tLoss: 0.279401\n",
      "Train Epoch: 4 [2000/11194 (18%)]\tLoss: 0.240256\n",
      "Train Epoch: 4 [3000/11194 (27%)]\tLoss: 0.217720\n",
      "Train Epoch: 4 [4000/11194 (36%)]\tLoss: 0.327922\n",
      "Train Epoch: 4 [5000/11194 (45%)]\tLoss: 0.183485\n",
      "Train Epoch: 4 [6000/11194 (54%)]\tLoss: 0.196234\n",
      "Train Epoch: 4 [7000/11194 (62%)]\tLoss: 0.337895\n",
      "Train Epoch: 4 [8000/11194 (71%)]\tLoss: 0.288263\n",
      "Train Epoch: 4 [9000/11194 (80%)]\tLoss: 0.425734\n",
      "Train Epoch: 4 [10000/11194 (89%)]\tLoss: 0.203681\n",
      "Train Epoch: 4 [11000/11194 (98%)]\tLoss: 0.188144\n",
      "Train Epoch: 5 [0/11194 (0%)]\tLoss: 0.300878\n",
      "Train Epoch: 5 [1000/11194 (9%)]\tLoss: 0.282490\n",
      "Train Epoch: 5 [2000/11194 (18%)]\tLoss: 0.199004\n",
      "Train Epoch: 5 [3000/11194 (27%)]\tLoss: 0.352078\n",
      "Train Epoch: 5 [4000/11194 (36%)]\tLoss: 0.245245\n",
      "Train Epoch: 5 [5000/11194 (45%)]\tLoss: 0.185582\n",
      "Train Epoch: 5 [6000/11194 (54%)]\tLoss: 0.347023\n",
      "Train Epoch: 5 [7000/11194 (62%)]\tLoss: 0.212815\n",
      "Train Epoch: 5 [8000/11194 (71%)]\tLoss: 0.358944\n",
      "Train Epoch: 5 [9000/11194 (80%)]\tLoss: 0.258426\n",
      "Train Epoch: 5 [10000/11194 (89%)]\tLoss: 0.200190\n",
      "Train Epoch: 5 [11000/11194 (98%)]\tLoss: 0.171686\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "8\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.0904, Accuracy: 7397/10000 (74%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/20764 (0%)]\tLoss: 0.343397\n",
      "Train Epoch: 1 [1000/20764 (5%)]\tLoss: 0.303710\n",
      "Train Epoch: 1 [2000/20764 (10%)]\tLoss: 0.213554\n",
      "Train Epoch: 1 [3000/20764 (14%)]\tLoss: 0.299732\n",
      "Train Epoch: 1 [4000/20764 (19%)]\tLoss: 0.253157\n",
      "Train Epoch: 1 [5000/20764 (24%)]\tLoss: 0.291419\n",
      "Train Epoch: 1 [6000/20764 (29%)]\tLoss: 0.425646\n",
      "Train Epoch: 1 [7000/20764 (34%)]\tLoss: 0.252789\n",
      "Train Epoch: 1 [8000/20764 (38%)]\tLoss: 0.273529\n",
      "Train Epoch: 1 [9000/20764 (43%)]\tLoss: 0.439074\n",
      "Train Epoch: 1 [10000/20764 (48%)]\tLoss: 0.228960\n",
      "Train Epoch: 1 [11000/20764 (53%)]\tLoss: 0.177725\n",
      "Train Epoch: 1 [12000/20764 (58%)]\tLoss: 0.368195\n",
      "Train Epoch: 1 [13000/20764 (62%)]\tLoss: 0.343170\n",
      "Train Epoch: 1 [14000/20764 (67%)]\tLoss: 0.258636\n",
      "Train Epoch: 1 [15000/20764 (72%)]\tLoss: 0.233877\n",
      "Train Epoch: 1 [16000/20764 (77%)]\tLoss: 0.301566\n",
      "Train Epoch: 1 [17000/20764 (82%)]\tLoss: 0.313599\n",
      "Train Epoch: 1 [18000/20764 (87%)]\tLoss: 0.315248\n",
      "Train Epoch: 1 [19000/20764 (91%)]\tLoss: 0.313604\n",
      "Train Epoch: 1 [20000/20764 (96%)]\tLoss: 0.438583\n",
      "Train Epoch: 2 [0/20764 (0%)]\tLoss: 0.360660\n",
      "Train Epoch: 2 [1000/20764 (5%)]\tLoss: 0.227403\n",
      "Train Epoch: 2 [2000/20764 (10%)]\tLoss: 0.261506\n",
      "Train Epoch: 2 [3000/20764 (14%)]\tLoss: 0.344389\n",
      "Train Epoch: 2 [4000/20764 (19%)]\tLoss: 0.374675\n",
      "Train Epoch: 2 [5000/20764 (24%)]\tLoss: 0.247999\n",
      "Train Epoch: 2 [6000/20764 (29%)]\tLoss: 0.227005\n",
      "Train Epoch: 2 [7000/20764 (34%)]\tLoss: 0.448144\n",
      "Train Epoch: 2 [8000/20764 (38%)]\tLoss: 0.191819\n",
      "Train Epoch: 2 [9000/20764 (43%)]\tLoss: 0.315101\n",
      "Train Epoch: 2 [10000/20764 (48%)]\tLoss: 0.215195\n",
      "Train Epoch: 2 [11000/20764 (53%)]\tLoss: 0.302567\n",
      "Train Epoch: 2 [12000/20764 (58%)]\tLoss: 0.168005\n",
      "Train Epoch: 2 [13000/20764 (62%)]\tLoss: 0.403007\n",
      "Train Epoch: 2 [14000/20764 (67%)]\tLoss: 0.265322\n",
      "Train Epoch: 2 [15000/20764 (72%)]\tLoss: 0.345718\n",
      "Train Epoch: 2 [16000/20764 (77%)]\tLoss: 0.409229\n",
      "Train Epoch: 2 [17000/20764 (82%)]\tLoss: 0.278901\n",
      "Train Epoch: 2 [18000/20764 (87%)]\tLoss: 0.250396\n",
      "Train Epoch: 2 [19000/20764 (91%)]\tLoss: 0.248773\n",
      "Train Epoch: 2 [20000/20764 (96%)]\tLoss: 0.433630\n",
      "Train Epoch: 3 [0/20764 (0%)]\tLoss: 0.341962\n",
      "Train Epoch: 3 [1000/20764 (5%)]\tLoss: 0.347631\n",
      "Train Epoch: 3 [2000/20764 (10%)]\tLoss: 0.276622\n",
      "Train Epoch: 3 [3000/20764 (14%)]\tLoss: 0.409392\n",
      "Train Epoch: 3 [4000/20764 (19%)]\tLoss: 0.205701\n",
      "Train Epoch: 3 [5000/20764 (24%)]\tLoss: 0.308161\n",
      "Train Epoch: 3 [6000/20764 (29%)]\tLoss: 0.283452\n",
      "Train Epoch: 3 [7000/20764 (34%)]\tLoss: 0.180504\n",
      "Train Epoch: 3 [8000/20764 (38%)]\tLoss: 0.261196\n",
      "Train Epoch: 3 [9000/20764 (43%)]\tLoss: 0.284862\n",
      "Train Epoch: 3 [10000/20764 (48%)]\tLoss: 0.232335\n",
      "Train Epoch: 3 [11000/20764 (53%)]\tLoss: 0.260183\n",
      "Train Epoch: 3 [12000/20764 (58%)]\tLoss: 0.367453\n",
      "Train Epoch: 3 [13000/20764 (62%)]\tLoss: 0.283354\n",
      "Train Epoch: 3 [14000/20764 (67%)]\tLoss: 0.241616\n",
      "Train Epoch: 3 [15000/20764 (72%)]\tLoss: 0.277614\n",
      "Train Epoch: 3 [16000/20764 (77%)]\tLoss: 0.363193\n",
      "Train Epoch: 3 [17000/20764 (82%)]\tLoss: 0.318324\n",
      "Train Epoch: 3 [18000/20764 (87%)]\tLoss: 0.433189\n",
      "Train Epoch: 3 [19000/20764 (91%)]\tLoss: 0.283916\n",
      "Train Epoch: 3 [20000/20764 (96%)]\tLoss: 0.209419\n",
      "Train Epoch: 4 [0/20764 (0%)]\tLoss: 0.518447\n",
      "Train Epoch: 4 [1000/20764 (5%)]\tLoss: 0.252350\n",
      "Train Epoch: 4 [2000/20764 (10%)]\tLoss: 0.335196\n",
      "Train Epoch: 4 [3000/20764 (14%)]\tLoss: 0.376427\n",
      "Train Epoch: 4 [4000/20764 (19%)]\tLoss: 0.266327\n",
      "Train Epoch: 4 [5000/20764 (24%)]\tLoss: 0.319675\n",
      "Train Epoch: 4 [6000/20764 (29%)]\tLoss: 0.212249\n",
      "Train Epoch: 4 [7000/20764 (34%)]\tLoss: 0.428427\n",
      "Train Epoch: 4 [8000/20764 (38%)]\tLoss: 0.314215\n",
      "Train Epoch: 4 [9000/20764 (43%)]\tLoss: 0.279570\n",
      "Train Epoch: 4 [10000/20764 (48%)]\tLoss: 0.332881\n",
      "Train Epoch: 4 [11000/20764 (53%)]\tLoss: 0.248047\n",
      "Train Epoch: 4 [12000/20764 (58%)]\tLoss: 0.289596\n",
      "Train Epoch: 4 [13000/20764 (62%)]\tLoss: 0.341442\n",
      "Train Epoch: 4 [14000/20764 (67%)]\tLoss: 0.339879\n",
      "Train Epoch: 4 [15000/20764 (72%)]\tLoss: 0.210482\n",
      "Train Epoch: 4 [16000/20764 (77%)]\tLoss: 0.346213\n",
      "Train Epoch: 4 [17000/20764 (82%)]\tLoss: 0.377711\n",
      "Train Epoch: 4 [18000/20764 (87%)]\tLoss: 0.253838\n",
      "Train Epoch: 4 [19000/20764 (91%)]\tLoss: 0.200628\n",
      "Train Epoch: 4 [20000/20764 (96%)]\tLoss: 0.218347\n",
      "Train Epoch: 5 [0/20764 (0%)]\tLoss: 0.369259\n",
      "Train Epoch: 5 [1000/20764 (5%)]\tLoss: 0.327346\n",
      "Train Epoch: 5 [2000/20764 (10%)]\tLoss: 0.344343\n",
      "Train Epoch: 5 [3000/20764 (14%)]\tLoss: 0.364100\n",
      "Train Epoch: 5 [4000/20764 (19%)]\tLoss: 0.260989\n",
      "Train Epoch: 5 [5000/20764 (24%)]\tLoss: 0.206950\n",
      "Train Epoch: 5 [6000/20764 (29%)]\tLoss: 0.352848\n",
      "Train Epoch: 5 [7000/20764 (34%)]\tLoss: 0.307752\n",
      "Train Epoch: 5 [8000/20764 (38%)]\tLoss: 0.225854\n",
      "Train Epoch: 5 [9000/20764 (43%)]\tLoss: 0.233463\n",
      "Train Epoch: 5 [10000/20764 (48%)]\tLoss: 0.360068\n",
      "Train Epoch: 5 [11000/20764 (53%)]\tLoss: 0.307092\n",
      "Train Epoch: 5 [12000/20764 (58%)]\tLoss: 0.375751\n",
      "Train Epoch: 5 [13000/20764 (62%)]\tLoss: 0.490864\n",
      "Train Epoch: 5 [14000/20764 (67%)]\tLoss: 0.369443\n",
      "Train Epoch: 5 [15000/20764 (72%)]\tLoss: 0.314995\n",
      "Train Epoch: 5 [16000/20764 (77%)]\tLoss: 0.300566\n",
      "Train Epoch: 5 [17000/20764 (82%)]\tLoss: 0.274075\n",
      "Train Epoch: 5 [18000/20764 (87%)]\tLoss: 0.452680\n",
      "Train Epoch: 5 [19000/20764 (91%)]\tLoss: 0.328253\n",
      "Train Epoch: 5 [20000/20764 (96%)]\tLoss: 0.357013\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/11194 (0%)]\tLoss: 0.313601\n",
      "Train Epoch: 1 [1000/11194 (9%)]\tLoss: 0.280142\n",
      "Train Epoch: 1 [2000/11194 (18%)]\tLoss: 0.254577\n",
      "Train Epoch: 1 [3000/11194 (27%)]\tLoss: 0.449911\n",
      "Train Epoch: 1 [4000/11194 (36%)]\tLoss: 0.270447\n",
      "Train Epoch: 1 [5000/11194 (45%)]\tLoss: 0.236828\n",
      "Train Epoch: 1 [6000/11194 (54%)]\tLoss: 0.360218\n",
      "Train Epoch: 1 [7000/11194 (62%)]\tLoss: 0.345797\n",
      "Train Epoch: 1 [8000/11194 (71%)]\tLoss: 0.375131\n",
      "Train Epoch: 1 [9000/11194 (80%)]\tLoss: 0.325414\n",
      "Train Epoch: 1 [10000/11194 (89%)]\tLoss: 0.332918\n",
      "Train Epoch: 1 [11000/11194 (98%)]\tLoss: 0.321026\n",
      "Train Epoch: 2 [0/11194 (0%)]\tLoss: 0.258936\n",
      "Train Epoch: 2 [1000/11194 (9%)]\tLoss: 0.191228\n",
      "Train Epoch: 2 [2000/11194 (18%)]\tLoss: 0.318428\n",
      "Train Epoch: 2 [3000/11194 (27%)]\tLoss: 0.223458\n",
      "Train Epoch: 2 [4000/11194 (36%)]\tLoss: 0.258148\n",
      "Train Epoch: 2 [5000/11194 (45%)]\tLoss: 0.339433\n",
      "Train Epoch: 2 [6000/11194 (54%)]\tLoss: 0.348652\n",
      "Train Epoch: 2 [7000/11194 (62%)]\tLoss: 0.331177\n",
      "Train Epoch: 2 [8000/11194 (71%)]\tLoss: 0.249506\n",
      "Train Epoch: 2 [9000/11194 (80%)]\tLoss: 0.227569\n",
      "Train Epoch: 2 [10000/11194 (89%)]\tLoss: 0.246996\n",
      "Train Epoch: 2 [11000/11194 (98%)]\tLoss: 0.301401\n",
      "Train Epoch: 3 [0/11194 (0%)]\tLoss: 0.354642\n",
      "Train Epoch: 3 [1000/11194 (9%)]\tLoss: 0.235909\n",
      "Train Epoch: 3 [2000/11194 (18%)]\tLoss: 0.294555\n",
      "Train Epoch: 3 [3000/11194 (27%)]\tLoss: 0.188831\n",
      "Train Epoch: 3 [4000/11194 (36%)]\tLoss: 0.244169\n",
      "Train Epoch: 3 [5000/11194 (45%)]\tLoss: 0.314525\n",
      "Train Epoch: 3 [6000/11194 (54%)]\tLoss: 0.293946\n",
      "Train Epoch: 3 [7000/11194 (62%)]\tLoss: 0.214066\n",
      "Train Epoch: 3 [8000/11194 (71%)]\tLoss: 0.326131\n",
      "Train Epoch: 3 [9000/11194 (80%)]\tLoss: 0.209799\n",
      "Train Epoch: 3 [10000/11194 (89%)]\tLoss: 0.207402\n",
      "Train Epoch: 3 [11000/11194 (98%)]\tLoss: 0.285132\n",
      "Train Epoch: 4 [0/11194 (0%)]\tLoss: 0.233419\n",
      "Train Epoch: 4 [1000/11194 (9%)]\tLoss: 0.191130\n",
      "Train Epoch: 4 [2000/11194 (18%)]\tLoss: 0.223302\n",
      "Train Epoch: 4 [3000/11194 (27%)]\tLoss: 0.175692\n",
      "Train Epoch: 4 [4000/11194 (36%)]\tLoss: 0.213036\n",
      "Train Epoch: 4 [5000/11194 (45%)]\tLoss: 0.237926\n",
      "Train Epoch: 4 [6000/11194 (54%)]\tLoss: 0.322588\n",
      "Train Epoch: 4 [7000/11194 (62%)]\tLoss: 0.267760\n",
      "Train Epoch: 4 [8000/11194 (71%)]\tLoss: 0.246713\n",
      "Train Epoch: 4 [9000/11194 (80%)]\tLoss: 0.255140\n",
      "Train Epoch: 4 [10000/11194 (89%)]\tLoss: 0.200510\n",
      "Train Epoch: 4 [11000/11194 (98%)]\tLoss: 0.228684\n",
      "Train Epoch: 5 [0/11194 (0%)]\tLoss: 0.242281\n",
      "Train Epoch: 5 [1000/11194 (9%)]\tLoss: 0.201124\n",
      "Train Epoch: 5 [2000/11194 (18%)]\tLoss: 0.289613\n",
      "Train Epoch: 5 [3000/11194 (27%)]\tLoss: 0.254475\n",
      "Train Epoch: 5 [4000/11194 (36%)]\tLoss: 0.237364\n",
      "Train Epoch: 5 [5000/11194 (45%)]\tLoss: 0.365129\n",
      "Train Epoch: 5 [6000/11194 (54%)]\tLoss: 0.383240\n",
      "Train Epoch: 5 [7000/11194 (62%)]\tLoss: 0.319545\n",
      "Train Epoch: 5 [8000/11194 (71%)]\tLoss: 0.389065\n",
      "Train Epoch: 5 [9000/11194 (80%)]\tLoss: 0.351184\n",
      "Train Epoch: 5 [10000/11194 (89%)]\tLoss: 0.263081\n",
      "Train Epoch: 5 [11000/11194 (98%)]\tLoss: 0.219273\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "8\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.1137, Accuracy: 7387/10000 (74%)\n",
      "\n",
      "Running experiment with 10 partitions...\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.533168\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 0.349248\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 0.408505\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 0.488132\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 0.395695\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 0.507576\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 0.506902\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 0.479743\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.446951\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 0.376026\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.308579\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 0.443110\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.411078\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 0.505340\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 0.454281\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.592159\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.395503\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 0.374549\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 0.537630\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 0.636275\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.446040\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 0.562219\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.405674\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 0.520646\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.487026\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.469172\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.463984\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 0.334459\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.376183\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 0.381434\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.716356\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 0.378892\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.465691\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 0.420953\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.401664\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.336037\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.270006\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 0.428950\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.427274\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 0.600972\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.422393\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 0.459009\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.419021\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 0.437396\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.638150\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.383286\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.384407\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 0.384695\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.445549\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 0.578110\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.482519\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 0.425426\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.473522\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 0.569048\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.350130\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.433794\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.582766\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 0.397494\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.441232\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 0.395172\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.470809\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 0.392757\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.435602\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 0.462261\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.384619\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.369310\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.395759\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 0.389122\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.449026\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 0.381654\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.526391\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 0.493495\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.562608\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 0.514739\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.487590\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.584557\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.447893\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 0.529374\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.418952\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 0.466421\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.473230\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 0.454653\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.443945\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 0.510727\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.339895\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.405217\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.368151\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 0.369614\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.354661\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 0.630930\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.499853\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 0.562851\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.439952\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 0.385644\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.579022\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.300348\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.382472\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 0.390679\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.547679\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 0.398867\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.452185\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 0.410817\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.341492\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 0.423023\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.393600\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.443568\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.401241\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 0.420001\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.419079\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 0.572514\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.583130\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 0.473770\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.285231\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 0.432411\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.527790\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.392910\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.500593\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 0.308348\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.349291\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 0.356917\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.371576\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 0.507842\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.484635\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 0.425966\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.562134\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.378490\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.386249\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 0.392821\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.511386\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 0.525822\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.410889\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 0.431376\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.551854\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 0.501692\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.422286\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.524802\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.533497\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 0.489461\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.490964\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 0.300595\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.388814\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 0.385520\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.378688\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 0.307455\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.512846\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.415210\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.395799\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 0.409286\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.452284\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 0.488153\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.434670\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 0.390553\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.390689\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 0.280546\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.465674\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.542658\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.548160\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 0.565300\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.427396\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 0.514122\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.345705\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 0.454123\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.439052\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 0.378372\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.522249\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.455735\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.555135\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 0.432311\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.558282\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 0.433541\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.338408\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 0.448320\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.393048\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 0.365004\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.484055\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.475416\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.491259\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 0.528576\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.440672\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 0.514313\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.341357\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 0.288840\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.542892\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 0.487335\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.293598\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.386845\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.332285\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 0.533955\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.360116\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 0.383357\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.385724\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 0.342063\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.383676\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 0.472792\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.321933\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.400658\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.342457\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 0.370914\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.311052\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 0.463252\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.381501\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 0.453290\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.597144\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 0.526638\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.680918\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.390892\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.421371\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 0.354216\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.513376\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 0.419847\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.519206\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 0.516230\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.285108\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 0.446546\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.437287\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.493676\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.351592\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 0.372552\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.447666\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 0.345733\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.509383\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 0.323328\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.444389\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 0.610717\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.402342\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.496332\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.346085\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 0.579126\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.444069\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 0.567856\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.312159\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 0.486673\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.422484\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 0.492859\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.380259\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.532864\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.472899\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 0.418070\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.326373\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 0.503520\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.458855\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 0.363721\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.502121\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 0.442085\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.436620\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.462498\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.323626\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 0.458680\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.400540\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 0.498518\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.478337\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 0.399594\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.402163\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 0.424760\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.417494\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.376947\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.405123\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 0.382336\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.495029\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 0.490811\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.440110\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 0.398061\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.524297\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 0.511927\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.334448\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.440496\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.433680\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 0.373182\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.438035\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 0.415884\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.318892\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 0.469499\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.409731\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 0.423446\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.351799\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.504767\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.588495\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 0.462093\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.520209\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 0.349823\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.367392\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 0.490388\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.372536\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 0.410538\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.510527\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.525669\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.425938\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 0.419842\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.486093\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 0.283674\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.428432\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 0.459030\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.259671\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 0.405139\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.481403\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.442216\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.409564\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 0.390350\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.286641\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 0.567970\n",
      "\n",
      "Test set: Avg. loss: 0.4233, Accuracy: 50788/60000 (85%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.670346\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.413887\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.355794\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.399605\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.422543\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.321252\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.408030\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.375026\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.283957\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.374759\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.335336\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.456510\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.403097\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.324595\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.416554\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.354874\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.083120\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.196901\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.226013\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.183691\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.069876\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.028915\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.122409\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.153301\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.047202\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.102800\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.134644\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.143102\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.110803\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.256100\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.129594\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.162355\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.063711\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.114022\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.235991\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.077975\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.158837\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.092868\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.065508\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.135904\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.130370\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.108491\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.091763\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.221388\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.107245\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.080540\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.166659\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.071364\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.098536\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.168109\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.144754\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.128896\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.113767\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.120679\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.107399\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.219253\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.214824\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.150416\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.164990\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.157977\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.136770\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.205475\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.307233\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.150484\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.174203\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.194903\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.138907\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.207399\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.217213\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.186296\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.126517\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.281837\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.210833\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.168363\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.180096\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.189806\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.283421\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.224080\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.270820\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.171950\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.158965\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.130769\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.229460\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.220662\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.371746\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.219761\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.181734\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.144769\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.199811\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.222348\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.345538\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.294419\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.189938\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.220616\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.167339\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.305713\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.174342\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.182284\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.284122\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.245904\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.340779\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.275780\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.161115\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.316921\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.129701\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.315623\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.221540\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.181323\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.225046\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.158523\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.217751\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.235305\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.198556\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.308532\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.251960\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.275792\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.344520\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.166012\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.398434\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.287506\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.626294\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.312727\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.298456\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.318252\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.399084\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.270667\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.188761\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.476665\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.326109\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.328632\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.274223\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.289606\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.267369\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.313591\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.201107\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.355472\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.321678\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.207780\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.224117\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.236352\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.275625\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.335341\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.275406\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.218697\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.243761\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.248137\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.205952\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.189685\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.375079\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.340665\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.353479\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.349233\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.392768\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.483290\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.348416\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.308418\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.322157\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.136292\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.323384\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.312774\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.291734\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.215867\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.394004\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.323436\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.236970\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.261714\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.313379\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.284491\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.172392\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.362681\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.427818\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.545843\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.500687\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.344274\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.304281\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.287380\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.401576\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.357485\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.368251\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.530078\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.358284\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.435165\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.421731\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.360196\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.433371\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.323045\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.502366\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.322510\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.212934\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.382265\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.366576\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.317655\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.369478\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.366322\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.409531\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.287985\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.268779\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.410220\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.389982\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.347922\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.284152\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.338066\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.325012\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.439001\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.304069\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.252073\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.246165\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.393470\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.364448\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.319499\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.382122\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.416681\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.427786\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.328861\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.294233\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.284983\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.274429\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.259756\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.333571\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.299676\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.459659\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.244605\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.291596\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.146225\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.288334\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.280254\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.274145\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.171088\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.235136\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.283317\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.308635\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.198074\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.270267\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.150287\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.200934\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.182026\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.127215\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.231999\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.255354\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.239852\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.356224\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.140859\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.240699\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.169998\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.194469\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.177485\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.236270\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.253544\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.159097\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.120849\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.141465\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.214739\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.216845\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.099010\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.291095\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.393042\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.387598\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.313045\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.393210\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.255433\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.459946\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.337423\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.320933\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.338490\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.249018\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.331350\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.441567\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.256515\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.236642\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.314586\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.300378\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.335456\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.243515\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.308912\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.257225\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.335516\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.292317\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.341601\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.317899\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.284670\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.307939\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.170144\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.367973\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.324961\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.426179\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.433407\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.302244\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.285542\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.246692\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.309225\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.300258\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.251310\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.269610\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.244931\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.307001\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.318157\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.268577\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.266711\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.272862\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.236138\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.205570\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.142994\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.202461\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.323544\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.183863\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.218814\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.319629\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.400758\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.301353\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.294710\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.167399\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.325281\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.187007\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.280273\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.359271\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.336365\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.278872\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.113528\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.284988\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.142033\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.266030\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.251306\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.310984\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.249133\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.134974\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.0438, Accuracy: 7548/10000 (75%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.461634\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.341932\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.420934\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.431533\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.314054\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.365385\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.342792\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.412242\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.267224\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.286827\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.308414\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.415359\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.366704\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.300074\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.235354\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.269132\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.152013\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.232210\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.290280\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.169574\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.103282\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.196297\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.153717\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.121764\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.098521\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.156968\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.105256\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.099260\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.082545\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.139940\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.155612\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.267779\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.123663\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.196861\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.170871\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.168327\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.261797\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.110175\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.113170\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.109070\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.123725\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.122778\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.118610\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.120362\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.062392\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.095550\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.138564\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.116237\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.116680\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.164418\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.135134\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.090467\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.098872\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.147449\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.126306\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.301458\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.221475\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.166966\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.130784\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.342852\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.313985\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.253927\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.136669\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.350191\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.275534\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.311709\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.201357\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.161959\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.131036\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.197053\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.234079\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.188496\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.175970\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.206366\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.159438\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.180701\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.181773\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.214639\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.124790\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.284289\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.137765\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.191544\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.214796\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.131351\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.260240\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.165624\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.158931\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.157992\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.256058\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.244603\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.374823\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.258202\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.322028\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.300404\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.284773\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.216109\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.272974\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.182693\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.330048\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.244158\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.231383\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.163058\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.139111\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.178813\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.378211\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.269123\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.363292\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.213962\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.248159\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.237885\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.334073\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.266328\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.184590\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.164027\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.152042\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.214629\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.159162\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.161398\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.298214\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.237971\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.360830\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.157141\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.312701\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.298690\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.230144\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.265903\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.261464\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.198158\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.293135\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.336756\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.280976\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.208705\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.316527\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.305979\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.233140\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.310494\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.163944\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.286547\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.235557\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.322170\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.239306\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.323937\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.322942\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.311103\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.415589\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.271765\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.243865\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.251879\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.206400\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.269978\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.282734\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.383541\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.387700\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.305631\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.303315\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.218633\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.300538\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.296701\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.255448\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.321830\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.402420\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.354309\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.288905\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.223810\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.407257\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.263977\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.415783\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.259711\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.314241\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.275321\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.461970\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.443766\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.321573\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.399247\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.334639\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.293531\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.261780\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.331837\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.274902\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.438688\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.413194\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.383278\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.336265\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.331541\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.269214\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.273701\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.407260\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.223977\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.300758\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.264517\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.331041\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.226630\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.375383\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.457862\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.323623\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.379452\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.388275\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.360733\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.455102\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.436416\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.444486\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.391382\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.468820\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.312447\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.317641\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.293550\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.314770\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.411022\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.231572\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.308295\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.246012\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.416546\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.475223\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.353205\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.348424\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.452587\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.328465\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.361374\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.273528\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.455260\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.351043\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.126527\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.133208\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.245907\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.332961\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.211164\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.323739\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.346308\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.293874\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.180722\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.227165\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.260441\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.202393\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.233049\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.225227\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.238282\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.207960\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.207153\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.305084\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.195436\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.172412\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.143245\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.212945\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.278304\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.187355\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.318920\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.235313\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.154773\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.241983\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.149080\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.182265\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.274931\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.136216\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.173450\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.197951\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.394387\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.288949\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.344526\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.216082\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.305995\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.328285\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.250684\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.352673\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.275932\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.283145\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.399493\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.256864\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.212302\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.301492\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.299491\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.242913\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.360520\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.223441\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.326391\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.245808\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.268489\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.363119\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.281852\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.302692\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.288440\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.414455\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.309027\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.329703\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.376295\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.294644\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.282530\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.265345\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.385478\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.335016\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.190367\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.311132\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.268108\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.315166\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.319276\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.396185\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.259795\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.296260\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.217148\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.239828\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.245482\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.334066\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.295591\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.275739\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.156175\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.277819\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.209600\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.202903\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.204991\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.286936\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.193483\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.261191\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.284339\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.182431\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.108366\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.257325\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.248239\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.277431\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.193506\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.202018\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.224433\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.259123\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.277629\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.202767\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.274328\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.199873\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.0896, Accuracy: 7480/10000 (75%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.498224\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.390390\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.467429\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.380124\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.286934\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.263153\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.448713\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.357748\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.389055\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.381478\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.345280\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.349106\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.271596\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.341455\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.243570\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.506208\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.288083\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.219639\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.136547\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.170617\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.181324\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.221920\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.142511\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.081217\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.154866\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.225035\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.137581\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.022017\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.181077\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.211659\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.161947\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.139830\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.090148\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.081616\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.104258\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.095034\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.112051\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.149225\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.125989\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.116436\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.137385\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.123680\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.240714\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.127583\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.181259\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.117214\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.154241\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.058996\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.169241\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.119451\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.063790\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.268855\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.113627\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.216300\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.173092\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.370838\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.109492\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.312165\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.197403\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.158816\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.239902\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.332457\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.238544\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.188449\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.165932\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.221624\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.158092\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.244491\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.160185\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.203086\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.162673\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.162720\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.236506\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.104574\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.198019\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.261414\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.160703\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.158329\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.174270\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.191761\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.186640\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.194408\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.229874\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.124245\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.095156\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.166926\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.216415\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.142127\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.181148\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.122746\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.390029\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.181659\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.345949\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.159265\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.189412\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.419447\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.255450\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.305325\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.327570\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.273569\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.128714\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.358231\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.367998\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.267779\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.170514\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.278671\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.226157\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.189776\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.242020\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.177594\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.253329\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.210408\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.212511\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.340620\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.218356\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.211654\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.241282\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.284649\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.199625\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.305323\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.333857\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.219733\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.303396\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.213068\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.383365\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.349199\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.310564\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.307332\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.255384\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.307834\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.330909\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.218646\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.286187\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.234096\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.358603\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.285103\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.269945\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.233599\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.343981\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.322405\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.339598\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.397242\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.207270\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.291278\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.264796\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.236337\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.246219\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.297704\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.243238\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.360683\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.409315\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.372487\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.293267\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.264362\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.274303\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.212276\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.368570\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.217800\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.244597\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.379936\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.297473\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.197117\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.259175\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.307680\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.384597\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.304141\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.307247\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.253141\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.185467\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.211180\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.447788\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.332143\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.484201\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.375708\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.410278\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.320893\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.324207\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.311375\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.375792\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.336452\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.528637\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.306549\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.397178\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.278096\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.263002\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.211609\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.318166\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.364099\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.491443\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.388209\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.370422\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.445439\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.354814\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.470296\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.420931\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.501951\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.476451\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.405819\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.271601\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.324868\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.405975\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.309053\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.393344\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.299173\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.321268\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.351134\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.403809\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.397183\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.308959\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.411778\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.230961\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.296452\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.270490\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.363190\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.307189\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.333449\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.318722\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.421574\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.332409\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.379070\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.281376\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.192783\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.179095\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.289726\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.165782\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.150117\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.126647\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.137750\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.151489\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.175938\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.221782\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.269590\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.141161\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.103153\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.267981\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.185717\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.183333\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.231388\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.221382\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.209417\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.172308\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.125604\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.285514\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.232810\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.195666\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.378210\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.120535\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.158235\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.220393\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.201133\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.104016\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.246042\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.164565\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.164683\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.236915\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.381544\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.254471\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.334407\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.345608\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.385495\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.302979\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.437492\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.323521\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.476941\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.256539\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.330163\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.303775\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.223602\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.444732\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.340897\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.336074\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.296953\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.281667\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.481849\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.305533\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.316340\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.391244\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.351342\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.390633\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.326801\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.232328\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.291780\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.346875\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.289746\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.327671\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.204802\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.389526\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.228415\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.338709\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.294182\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.522281\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.151865\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.213152\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.303432\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.363395\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.178254\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.205252\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.264589\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.215411\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.281975\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.319370\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.149534\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.222815\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.135909\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.305336\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.159582\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.335430\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.199448\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.490120\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.185400\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.329264\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.211228\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.204074\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.128595\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.174320\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.274804\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.214961\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.157108\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.235081\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.221117\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.190332\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.119828\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.253827\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.334204\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.239714\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.0964, Accuracy: 7454/10000 (75%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.464493\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.402073\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.504669\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.360780\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.251944\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.575315\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.450620\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.337504\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.430578\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.325480\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.425970\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.418546\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.499899\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.355543\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.347911\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.437806\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.146587\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.190573\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.088743\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.074172\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.258125\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.115383\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.133620\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.141869\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.222357\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.097809\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.087178\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.131870\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.167005\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.108483\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.076776\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.084691\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.141322\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.075609\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.110896\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.097912\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.162999\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.316101\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.124776\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.128458\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.110484\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.220900\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.107797\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.088417\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.100335\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.252096\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.212217\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.093431\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.118153\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.164195\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.106295\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.138346\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.123871\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.085074\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.220968\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.186939\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.222148\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.298246\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.255858\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.186229\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.191166\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.134234\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.166903\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.193279\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.137508\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.224501\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.148664\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.212157\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.358575\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.208302\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.201475\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.134373\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.164275\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.225225\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.241519\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.116753\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.214485\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.221076\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.178034\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.181632\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.197551\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.146364\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.156076\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.168699\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.194664\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.262842\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.187607\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.124909\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.270896\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.171200\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.365003\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.373420\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.250540\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.201894\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.254014\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.235407\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.244080\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.115553\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.254902\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.157122\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.265527\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.279090\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.237529\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.247793\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.284846\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.289870\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.221913\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.279570\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.168009\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.352433\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.254548\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.386389\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.134869\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.171484\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.325749\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.327525\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.223899\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.214110\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.210736\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.259753\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.420361\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.235863\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.176790\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.282168\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.361966\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.274635\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.273303\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.343068\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.317630\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.224093\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.351564\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.307084\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.230199\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.219655\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.250521\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.300389\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.269128\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.307968\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.367045\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.255507\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.279445\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.268728\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.301212\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.234761\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.159612\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.260665\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.213411\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.273443\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.292657\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.266230\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.352866\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.316426\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.313820\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.273598\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.243603\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.334450\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.433624\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.186267\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.172033\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.467501\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.269544\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.211222\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.286890\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.292998\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.450695\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.207178\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.326860\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.271720\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.394461\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.261369\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.473711\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.363243\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.347713\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.462901\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.450305\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.348491\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.366413\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.393906\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.416774\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.210821\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.355878\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.397362\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.420844\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.415317\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.209124\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.361497\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.251872\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.412077\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.487448\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.473857\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.357318\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.332125\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.302168\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.283810\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.331039\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.328565\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.436003\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.435907\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.449293\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.362507\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.329325\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.401966\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.333338\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.413624\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.317984\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.378199\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.314431\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.334187\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.364716\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.299512\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.424083\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.389672\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.224421\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.287814\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.408158\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.424854\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.261910\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.308288\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.343506\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.451323\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.450572\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.118897\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.261573\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.207748\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.186037\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.319319\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.205842\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.107248\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.111428\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.178725\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.157734\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.268614\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.187100\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.203467\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.238386\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.251947\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.331998\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.227390\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.218021\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.178749\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.178321\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.215545\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.233696\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.179548\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.152641\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.243797\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.212282\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.187003\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.133382\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.179834\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.226383\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.261157\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.235630\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.204703\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.335306\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.497655\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.398292\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.338953\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.331962\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.318292\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.376294\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.359065\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.189906\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.270043\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.321905\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.233669\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.324155\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.366402\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.290413\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.305383\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.309461\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.329046\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.178921\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.435726\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.407647\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.323353\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.235798\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.389372\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.337920\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.350396\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.321203\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.199888\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.322184\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.319864\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.322485\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.278577\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.288025\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.287250\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.274363\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.179000\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.556026\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.273051\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.200453\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.250205\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.205232\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.368118\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.185704\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.219027\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.383252\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.249189\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.243138\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.217443\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.183944\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.311742\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.423570\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.319270\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.210908\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.182470\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.344276\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.182473\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.350459\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.235855\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.221795\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.232741\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.222277\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.307518\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.281220\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.126457\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.209439\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.457900\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.210395\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.275548\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.202192\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.319952\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.157313\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.1366, Accuracy: 7415/10000 (74%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/14254 (0%)]\tLoss: 0.465499\n",
      "Train Epoch: 1 [1000/14254 (7%)]\tLoss: 0.432899\n",
      "Train Epoch: 1 [2000/14254 (14%)]\tLoss: 0.278280\n",
      "Train Epoch: 1 [3000/14254 (21%)]\tLoss: 0.286379\n",
      "Train Epoch: 1 [4000/14254 (28%)]\tLoss: 0.373964\n",
      "Train Epoch: 1 [5000/14254 (35%)]\tLoss: 0.374551\n",
      "Train Epoch: 1 [6000/14254 (42%)]\tLoss: 0.542201\n",
      "Train Epoch: 1 [7000/14254 (49%)]\tLoss: 0.424529\n",
      "Train Epoch: 1 [8000/14254 (56%)]\tLoss: 0.281623\n",
      "Train Epoch: 1 [9000/14254 (63%)]\tLoss: 0.377838\n",
      "Train Epoch: 1 [10000/14254 (70%)]\tLoss: 0.396905\n",
      "Train Epoch: 1 [11000/14254 (77%)]\tLoss: 0.414249\n",
      "Train Epoch: 1 [12000/14254 (84%)]\tLoss: 0.292772\n",
      "Train Epoch: 1 [13000/14254 (91%)]\tLoss: 0.416363\n",
      "Train Epoch: 1 [14000/14254 (98%)]\tLoss: 0.459315\n",
      "Train Epoch: 2 [0/14254 (0%)]\tLoss: 0.314822\n",
      "Train Epoch: 2 [1000/14254 (7%)]\tLoss: 0.391507\n",
      "Train Epoch: 2 [2000/14254 (14%)]\tLoss: 0.332125\n",
      "Train Epoch: 2 [3000/14254 (21%)]\tLoss: 0.463376\n",
      "Train Epoch: 2 [4000/14254 (28%)]\tLoss: 0.325933\n",
      "Train Epoch: 2 [5000/14254 (35%)]\tLoss: 0.263446\n",
      "Train Epoch: 2 [6000/14254 (42%)]\tLoss: 0.419967\n",
      "Train Epoch: 2 [7000/14254 (49%)]\tLoss: 0.328783\n",
      "Train Epoch: 2 [8000/14254 (56%)]\tLoss: 0.204747\n",
      "Train Epoch: 2 [9000/14254 (63%)]\tLoss: 0.323289\n",
      "Train Epoch: 2 [10000/14254 (70%)]\tLoss: 0.276178\n",
      "Train Epoch: 2 [11000/14254 (77%)]\tLoss: 0.383234\n",
      "Train Epoch: 2 [12000/14254 (84%)]\tLoss: 0.337178\n",
      "Train Epoch: 2 [13000/14254 (91%)]\tLoss: 0.350998\n",
      "Train Epoch: 2 [14000/14254 (98%)]\tLoss: 0.298945\n",
      "Train Epoch: 3 [0/14254 (0%)]\tLoss: 0.313112\n",
      "Train Epoch: 3 [1000/14254 (7%)]\tLoss: 0.290524\n",
      "Train Epoch: 3 [2000/14254 (14%)]\tLoss: 0.381584\n",
      "Train Epoch: 3 [3000/14254 (21%)]\tLoss: 0.259496\n",
      "Train Epoch: 3 [4000/14254 (28%)]\tLoss: 0.410403\n",
      "Train Epoch: 3 [5000/14254 (35%)]\tLoss: 0.398400\n",
      "Train Epoch: 3 [6000/14254 (42%)]\tLoss: 0.493416\n",
      "Train Epoch: 3 [7000/14254 (49%)]\tLoss: 0.284685\n",
      "Train Epoch: 3 [8000/14254 (56%)]\tLoss: 0.262349\n",
      "Train Epoch: 3 [9000/14254 (63%)]\tLoss: 0.469222\n",
      "Train Epoch: 3 [10000/14254 (70%)]\tLoss: 0.408545\n",
      "Train Epoch: 3 [11000/14254 (77%)]\tLoss: 0.426897\n",
      "Train Epoch: 3 [12000/14254 (84%)]\tLoss: 0.310608\n",
      "Train Epoch: 3 [13000/14254 (91%)]\tLoss: 0.286416\n",
      "Train Epoch: 3 [14000/14254 (98%)]\tLoss: 0.461953\n",
      "Train Epoch: 4 [0/14254 (0%)]\tLoss: 0.437466\n",
      "Train Epoch: 4 [1000/14254 (7%)]\tLoss: 0.472635\n",
      "Train Epoch: 4 [2000/14254 (14%)]\tLoss: 0.257443\n",
      "Train Epoch: 4 [3000/14254 (21%)]\tLoss: 0.304072\n",
      "Train Epoch: 4 [4000/14254 (28%)]\tLoss: 0.366156\n",
      "Train Epoch: 4 [5000/14254 (35%)]\tLoss: 0.294902\n",
      "Train Epoch: 4 [6000/14254 (42%)]\tLoss: 0.394961\n",
      "Train Epoch: 4 [7000/14254 (49%)]\tLoss: 0.358205\n",
      "Train Epoch: 4 [8000/14254 (56%)]\tLoss: 0.343193\n",
      "Train Epoch: 4 [9000/14254 (63%)]\tLoss: 0.441492\n",
      "Train Epoch: 4 [10000/14254 (70%)]\tLoss: 0.237960\n",
      "Train Epoch: 4 [11000/14254 (77%)]\tLoss: 0.305969\n",
      "Train Epoch: 4 [12000/14254 (84%)]\tLoss: 0.283547\n",
      "Train Epoch: 4 [13000/14254 (91%)]\tLoss: 0.363485\n",
      "Train Epoch: 4 [14000/14254 (98%)]\tLoss: 0.357637\n",
      "Train Epoch: 5 [0/14254 (0%)]\tLoss: 0.323594\n",
      "Train Epoch: 5 [1000/14254 (7%)]\tLoss: 0.391785\n",
      "Train Epoch: 5 [2000/14254 (14%)]\tLoss: 0.319752\n",
      "Train Epoch: 5 [3000/14254 (21%)]\tLoss: 0.269477\n",
      "Train Epoch: 5 [4000/14254 (28%)]\tLoss: 0.213864\n",
      "Train Epoch: 5 [5000/14254 (35%)]\tLoss: 0.262091\n",
      "Train Epoch: 5 [6000/14254 (42%)]\tLoss: 0.321081\n",
      "Train Epoch: 5 [7000/14254 (49%)]\tLoss: 0.262557\n",
      "Train Epoch: 5 [8000/14254 (56%)]\tLoss: 0.324789\n",
      "Train Epoch: 5 [9000/14254 (63%)]\tLoss: 0.328510\n",
      "Train Epoch: 5 [10000/14254 (70%)]\tLoss: 0.295505\n",
      "Train Epoch: 5 [11000/14254 (77%)]\tLoss: 0.391064\n",
      "Train Epoch: 5 [12000/14254 (84%)]\tLoss: 0.386225\n",
      "Train Epoch: 5 [13000/14254 (91%)]\tLoss: 0.594608\n",
      "Train Epoch: 5 [14000/14254 (98%)]\tLoss: 0.374297\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/13824 (0%)]\tLoss: 0.543738\n",
      "Train Epoch: 1 [1000/13824 (7%)]\tLoss: 0.213354\n",
      "Train Epoch: 1 [2000/13824 (14%)]\tLoss: 0.348394\n",
      "Train Epoch: 1 [3000/13824 (22%)]\tLoss: 0.295138\n",
      "Train Epoch: 1 [4000/13824 (29%)]\tLoss: 0.370570\n",
      "Train Epoch: 1 [5000/13824 (36%)]\tLoss: 0.324836\n",
      "Train Epoch: 1 [6000/13824 (43%)]\tLoss: 0.228465\n",
      "Train Epoch: 1 [7000/13824 (50%)]\tLoss: 0.189100\n",
      "Train Epoch: 1 [8000/13824 (58%)]\tLoss: 0.267370\n",
      "Train Epoch: 1 [9000/13824 (65%)]\tLoss: 0.317509\n",
      "Train Epoch: 1 [10000/13824 (72%)]\tLoss: 0.210257\n",
      "Train Epoch: 1 [11000/13824 (79%)]\tLoss: 0.174764\n",
      "Train Epoch: 1 [12000/13824 (86%)]\tLoss: 0.297391\n",
      "Train Epoch: 1 [13000/13824 (94%)]\tLoss: 0.110230\n",
      "Train Epoch: 2 [0/13824 (0%)]\tLoss: 0.130526\n",
      "Train Epoch: 2 [1000/13824 (7%)]\tLoss: 0.125090\n",
      "Train Epoch: 2 [2000/13824 (14%)]\tLoss: 0.216573\n",
      "Train Epoch: 2 [3000/13824 (22%)]\tLoss: 0.272694\n",
      "Train Epoch: 2 [4000/13824 (29%)]\tLoss: 0.182009\n",
      "Train Epoch: 2 [5000/13824 (36%)]\tLoss: 0.179758\n",
      "Train Epoch: 2 [6000/13824 (43%)]\tLoss: 0.316512\n",
      "Train Epoch: 2 [7000/13824 (50%)]\tLoss: 0.211892\n",
      "Train Epoch: 2 [8000/13824 (58%)]\tLoss: 0.248283\n",
      "Train Epoch: 2 [9000/13824 (65%)]\tLoss: 0.239443\n",
      "Train Epoch: 2 [10000/13824 (72%)]\tLoss: 0.219080\n",
      "Train Epoch: 2 [11000/13824 (79%)]\tLoss: 0.208764\n",
      "Train Epoch: 2 [12000/13824 (86%)]\tLoss: 0.304466\n",
      "Train Epoch: 2 [13000/13824 (94%)]\tLoss: 0.155419\n",
      "Train Epoch: 3 [0/13824 (0%)]\tLoss: 0.187829\n",
      "Train Epoch: 3 [1000/13824 (7%)]\tLoss: 0.231632\n",
      "Train Epoch: 3 [2000/13824 (14%)]\tLoss: 0.153762\n",
      "Train Epoch: 3 [3000/13824 (22%)]\tLoss: 0.283426\n",
      "Train Epoch: 3 [4000/13824 (29%)]\tLoss: 0.131840\n",
      "Train Epoch: 3 [5000/13824 (36%)]\tLoss: 0.177227\n",
      "Train Epoch: 3 [6000/13824 (43%)]\tLoss: 0.200770\n",
      "Train Epoch: 3 [7000/13824 (50%)]\tLoss: 0.223448\n",
      "Train Epoch: 3 [8000/13824 (58%)]\tLoss: 0.166871\n",
      "Train Epoch: 3 [9000/13824 (65%)]\tLoss: 0.203295\n",
      "Train Epoch: 3 [10000/13824 (72%)]\tLoss: 0.147652\n",
      "Train Epoch: 3 [11000/13824 (79%)]\tLoss: 0.220792\n",
      "Train Epoch: 3 [12000/13824 (86%)]\tLoss: 0.120765\n",
      "Train Epoch: 3 [13000/13824 (94%)]\tLoss: 0.329980\n",
      "Train Epoch: 4 [0/13824 (0%)]\tLoss: 0.113278\n",
      "Train Epoch: 4 [1000/13824 (7%)]\tLoss: 0.279830\n",
      "Train Epoch: 4 [2000/13824 (14%)]\tLoss: 0.317411\n",
      "Train Epoch: 4 [3000/13824 (22%)]\tLoss: 0.217904\n",
      "Train Epoch: 4 [4000/13824 (29%)]\tLoss: 0.183011\n",
      "Train Epoch: 4 [5000/13824 (36%)]\tLoss: 0.185902\n",
      "Train Epoch: 4 [6000/13824 (43%)]\tLoss: 0.271312\n",
      "Train Epoch: 4 [7000/13824 (50%)]\tLoss: 0.253941\n",
      "Train Epoch: 4 [8000/13824 (58%)]\tLoss: 0.266856\n",
      "Train Epoch: 4 [9000/13824 (65%)]\tLoss: 0.140292\n",
      "Train Epoch: 4 [10000/13824 (72%)]\tLoss: 0.191503\n",
      "Train Epoch: 4 [11000/13824 (79%)]\tLoss: 0.224127\n",
      "Train Epoch: 4 [12000/13824 (86%)]\tLoss: 0.154268\n",
      "Train Epoch: 4 [13000/13824 (94%)]\tLoss: 0.240553\n",
      "Train Epoch: 5 [0/13824 (0%)]\tLoss: 0.444720\n",
      "Train Epoch: 5 [1000/13824 (7%)]\tLoss: 0.173237\n",
      "Train Epoch: 5 [2000/13824 (14%)]\tLoss: 0.190924\n",
      "Train Epoch: 5 [3000/13824 (22%)]\tLoss: 0.198728\n",
      "Train Epoch: 5 [4000/13824 (29%)]\tLoss: 0.244617\n",
      "Train Epoch: 5 [5000/13824 (36%)]\tLoss: 0.280845\n",
      "Train Epoch: 5 [6000/13824 (43%)]\tLoss: 0.242451\n",
      "Train Epoch: 5 [7000/13824 (50%)]\tLoss: 0.235137\n",
      "Train Epoch: 5 [8000/13824 (58%)]\tLoss: 0.229008\n",
      "Train Epoch: 5 [9000/13824 (65%)]\tLoss: 0.155938\n",
      "Train Epoch: 5 [10000/13824 (72%)]\tLoss: 0.235701\n",
      "Train Epoch: 5 [11000/13824 (79%)]\tLoss: 0.239220\n",
      "Train Epoch: 5 [12000/13824 (86%)]\tLoss: 0.286564\n",
      "Train Epoch: 5 [13000/13824 (94%)]\tLoss: 0.125120\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.3227, Accuracy: 7247/10000 (72%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/14254 (0%)]\tLoss: 0.324457\n",
      "Train Epoch: 1 [1000/14254 (7%)]\tLoss: 0.319282\n",
      "Train Epoch: 1 [2000/14254 (14%)]\tLoss: 0.365513\n",
      "Train Epoch: 1 [3000/14254 (21%)]\tLoss: 0.433634\n",
      "Train Epoch: 1 [4000/14254 (28%)]\tLoss: 0.321597\n",
      "Train Epoch: 1 [5000/14254 (35%)]\tLoss: 0.288135\n",
      "Train Epoch: 1 [6000/14254 (42%)]\tLoss: 0.312527\n",
      "Train Epoch: 1 [7000/14254 (49%)]\tLoss: 0.381837\n",
      "Train Epoch: 1 [8000/14254 (56%)]\tLoss: 0.369102\n",
      "Train Epoch: 1 [9000/14254 (63%)]\tLoss: 0.367791\n",
      "Train Epoch: 1 [10000/14254 (70%)]\tLoss: 0.366425\n",
      "Train Epoch: 1 [11000/14254 (77%)]\tLoss: 0.425570\n",
      "Train Epoch: 1 [12000/14254 (84%)]\tLoss: 0.449462\n",
      "Train Epoch: 1 [13000/14254 (91%)]\tLoss: 0.548835\n",
      "Train Epoch: 1 [14000/14254 (98%)]\tLoss: 0.449337\n",
      "Train Epoch: 2 [0/14254 (0%)]\tLoss: 0.430923\n",
      "Train Epoch: 2 [1000/14254 (7%)]\tLoss: 0.415416\n",
      "Train Epoch: 2 [2000/14254 (14%)]\tLoss: 0.322653\n",
      "Train Epoch: 2 [3000/14254 (21%)]\tLoss: 0.323363\n",
      "Train Epoch: 2 [4000/14254 (28%)]\tLoss: 0.333628\n",
      "Train Epoch: 2 [5000/14254 (35%)]\tLoss: 0.399344\n",
      "Train Epoch: 2 [6000/14254 (42%)]\tLoss: 0.315139\n",
      "Train Epoch: 2 [7000/14254 (49%)]\tLoss: 0.331599\n",
      "Train Epoch: 2 [8000/14254 (56%)]\tLoss: 0.252352\n",
      "Train Epoch: 2 [9000/14254 (63%)]\tLoss: 0.310823\n",
      "Train Epoch: 2 [10000/14254 (70%)]\tLoss: 0.338199\n",
      "Train Epoch: 2 [11000/14254 (77%)]\tLoss: 0.284782\n",
      "Train Epoch: 2 [12000/14254 (84%)]\tLoss: 0.239210\n",
      "Train Epoch: 2 [13000/14254 (91%)]\tLoss: 0.276224\n",
      "Train Epoch: 2 [14000/14254 (98%)]\tLoss: 0.356342\n",
      "Train Epoch: 3 [0/14254 (0%)]\tLoss: 0.306037\n",
      "Train Epoch: 3 [1000/14254 (7%)]\tLoss: 0.268591\n",
      "Train Epoch: 3 [2000/14254 (14%)]\tLoss: 0.304320\n",
      "Train Epoch: 3 [3000/14254 (21%)]\tLoss: 0.333822\n",
      "Train Epoch: 3 [4000/14254 (28%)]\tLoss: 0.278804\n",
      "Train Epoch: 3 [5000/14254 (35%)]\tLoss: 0.254263\n",
      "Train Epoch: 3 [6000/14254 (42%)]\tLoss: 0.331073\n",
      "Train Epoch: 3 [7000/14254 (49%)]\tLoss: 0.331343\n",
      "Train Epoch: 3 [8000/14254 (56%)]\tLoss: 0.342368\n",
      "Train Epoch: 3 [9000/14254 (63%)]\tLoss: 0.316002\n",
      "Train Epoch: 3 [10000/14254 (70%)]\tLoss: 0.446210\n",
      "Train Epoch: 3 [11000/14254 (77%)]\tLoss: 0.373528\n",
      "Train Epoch: 3 [12000/14254 (84%)]\tLoss: 0.272531\n",
      "Train Epoch: 3 [13000/14254 (91%)]\tLoss: 0.318629\n",
      "Train Epoch: 3 [14000/14254 (98%)]\tLoss: 0.299380\n",
      "Train Epoch: 4 [0/14254 (0%)]\tLoss: 0.393782\n",
      "Train Epoch: 4 [1000/14254 (7%)]\tLoss: 0.260053\n",
      "Train Epoch: 4 [2000/14254 (14%)]\tLoss: 0.228324\n",
      "Train Epoch: 4 [3000/14254 (21%)]\tLoss: 0.303599\n",
      "Train Epoch: 4 [4000/14254 (28%)]\tLoss: 0.208626\n",
      "Train Epoch: 4 [5000/14254 (35%)]\tLoss: 0.301673\n",
      "Train Epoch: 4 [6000/14254 (42%)]\tLoss: 0.380791\n",
      "Train Epoch: 4 [7000/14254 (49%)]\tLoss: 0.306255\n",
      "Train Epoch: 4 [8000/14254 (56%)]\tLoss: 0.340108\n",
      "Train Epoch: 4 [9000/14254 (63%)]\tLoss: 0.451182\n",
      "Train Epoch: 4 [10000/14254 (70%)]\tLoss: 0.357846\n",
      "Train Epoch: 4 [11000/14254 (77%)]\tLoss: 0.514530\n",
      "Train Epoch: 4 [12000/14254 (84%)]\tLoss: 0.373670\n",
      "Train Epoch: 4 [13000/14254 (91%)]\tLoss: 0.214176\n",
      "Train Epoch: 4 [14000/14254 (98%)]\tLoss: 0.312530\n",
      "Train Epoch: 5 [0/14254 (0%)]\tLoss: 0.371061\n",
      "Train Epoch: 5 [1000/14254 (7%)]\tLoss: 0.247765\n",
      "Train Epoch: 5 [2000/14254 (14%)]\tLoss: 0.225822\n",
      "Train Epoch: 5 [3000/14254 (21%)]\tLoss: 0.290217\n",
      "Train Epoch: 5 [4000/14254 (28%)]\tLoss: 0.501163\n",
      "Train Epoch: 5 [5000/14254 (35%)]\tLoss: 0.301786\n",
      "Train Epoch: 5 [6000/14254 (42%)]\tLoss: 0.245432\n",
      "Train Epoch: 5 [7000/14254 (49%)]\tLoss: 0.339947\n",
      "Train Epoch: 5 [8000/14254 (56%)]\tLoss: 0.323382\n",
      "Train Epoch: 5 [9000/14254 (63%)]\tLoss: 0.326769\n",
      "Train Epoch: 5 [10000/14254 (70%)]\tLoss: 0.303601\n",
      "Train Epoch: 5 [11000/14254 (77%)]\tLoss: 0.318733\n",
      "Train Epoch: 5 [12000/14254 (84%)]\tLoss: 0.342797\n",
      "Train Epoch: 5 [13000/14254 (91%)]\tLoss: 0.413825\n",
      "Train Epoch: 5 [14000/14254 (98%)]\tLoss: 0.272199\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/13824 (0%)]\tLoss: 0.460219\n",
      "Train Epoch: 1 [1000/13824 (7%)]\tLoss: 0.260536\n",
      "Train Epoch: 1 [2000/13824 (14%)]\tLoss: 0.243009\n",
      "Train Epoch: 1 [3000/13824 (22%)]\tLoss: 0.169922\n",
      "Train Epoch: 1 [4000/13824 (29%)]\tLoss: 0.139498\n",
      "Train Epoch: 1 [5000/13824 (36%)]\tLoss: 0.274976\n",
      "Train Epoch: 1 [6000/13824 (43%)]\tLoss: 0.281579\n",
      "Train Epoch: 1 [7000/13824 (50%)]\tLoss: 0.291117\n",
      "Train Epoch: 1 [8000/13824 (58%)]\tLoss: 0.190164\n",
      "Train Epoch: 1 [9000/13824 (65%)]\tLoss: 0.142921\n",
      "Train Epoch: 1 [10000/13824 (72%)]\tLoss: 0.207077\n",
      "Train Epoch: 1 [11000/13824 (79%)]\tLoss: 0.240618\n",
      "Train Epoch: 1 [12000/13824 (86%)]\tLoss: 0.235716\n",
      "Train Epoch: 1 [13000/13824 (94%)]\tLoss: 0.210382\n",
      "Train Epoch: 2 [0/13824 (0%)]\tLoss: 0.135270\n",
      "Train Epoch: 2 [1000/13824 (7%)]\tLoss: 0.222311\n",
      "Train Epoch: 2 [2000/13824 (14%)]\tLoss: 0.269779\n",
      "Train Epoch: 2 [3000/13824 (22%)]\tLoss: 0.281122\n",
      "Train Epoch: 2 [4000/13824 (29%)]\tLoss: 0.100029\n",
      "Train Epoch: 2 [5000/13824 (36%)]\tLoss: 0.201701\n",
      "Train Epoch: 2 [6000/13824 (43%)]\tLoss: 0.212218\n",
      "Train Epoch: 2 [7000/13824 (50%)]\tLoss: 0.266170\n",
      "Train Epoch: 2 [8000/13824 (58%)]\tLoss: 0.213110\n",
      "Train Epoch: 2 [9000/13824 (65%)]\tLoss: 0.215455\n",
      "Train Epoch: 2 [10000/13824 (72%)]\tLoss: 0.193157\n",
      "Train Epoch: 2 [11000/13824 (79%)]\tLoss: 0.232802\n",
      "Train Epoch: 2 [12000/13824 (86%)]\tLoss: 0.172179\n",
      "Train Epoch: 2 [13000/13824 (94%)]\tLoss: 0.355752\n",
      "Train Epoch: 3 [0/13824 (0%)]\tLoss: 0.205582\n",
      "Train Epoch: 3 [1000/13824 (7%)]\tLoss: 0.207003\n",
      "Train Epoch: 3 [2000/13824 (14%)]\tLoss: 0.172790\n",
      "Train Epoch: 3 [3000/13824 (22%)]\tLoss: 0.291415\n",
      "Train Epoch: 3 [4000/13824 (29%)]\tLoss: 0.301987\n",
      "Train Epoch: 3 [5000/13824 (36%)]\tLoss: 0.196937\n",
      "Train Epoch: 3 [6000/13824 (43%)]\tLoss: 0.233763\n",
      "Train Epoch: 3 [7000/13824 (50%)]\tLoss: 0.084351\n",
      "Train Epoch: 3 [8000/13824 (58%)]\tLoss: 0.369116\n",
      "Train Epoch: 3 [9000/13824 (65%)]\tLoss: 0.166628\n",
      "Train Epoch: 3 [10000/13824 (72%)]\tLoss: 0.185575\n",
      "Train Epoch: 3 [11000/13824 (79%)]\tLoss: 0.276981\n",
      "Train Epoch: 3 [12000/13824 (86%)]\tLoss: 0.243454\n",
      "Train Epoch: 3 [13000/13824 (94%)]\tLoss: 0.180634\n",
      "Train Epoch: 4 [0/13824 (0%)]\tLoss: 0.302144\n",
      "Train Epoch: 4 [1000/13824 (7%)]\tLoss: 0.145818\n",
      "Train Epoch: 4 [2000/13824 (14%)]\tLoss: 0.191137\n",
      "Train Epoch: 4 [3000/13824 (22%)]\tLoss: 0.191906\n",
      "Train Epoch: 4 [4000/13824 (29%)]\tLoss: 0.169442\n",
      "Train Epoch: 4 [5000/13824 (36%)]\tLoss: 0.213487\n",
      "Train Epoch: 4 [6000/13824 (43%)]\tLoss: 0.154561\n",
      "Train Epoch: 4 [7000/13824 (50%)]\tLoss: 0.250049\n",
      "Train Epoch: 4 [8000/13824 (58%)]\tLoss: 0.182629\n",
      "Train Epoch: 4 [9000/13824 (65%)]\tLoss: 0.106696\n",
      "Train Epoch: 4 [10000/13824 (72%)]\tLoss: 0.184499\n",
      "Train Epoch: 4 [11000/13824 (79%)]\tLoss: 0.209064\n",
      "Train Epoch: 4 [12000/13824 (86%)]\tLoss: 0.208680\n",
      "Train Epoch: 4 [13000/13824 (94%)]\tLoss: 0.106055\n",
      "Train Epoch: 5 [0/13824 (0%)]\tLoss: 0.336905\n",
      "Train Epoch: 5 [1000/13824 (7%)]\tLoss: 0.201247\n",
      "Train Epoch: 5 [2000/13824 (14%)]\tLoss: 0.147267\n",
      "Train Epoch: 5 [3000/13824 (22%)]\tLoss: 0.165292\n",
      "Train Epoch: 5 [4000/13824 (29%)]\tLoss: 0.263484\n",
      "Train Epoch: 5 [5000/13824 (36%)]\tLoss: 0.238013\n",
      "Train Epoch: 5 [6000/13824 (43%)]\tLoss: 0.197310\n",
      "Train Epoch: 5 [7000/13824 (50%)]\tLoss: 0.177372\n",
      "Train Epoch: 5 [8000/13824 (58%)]\tLoss: 0.122371\n",
      "Train Epoch: 5 [9000/13824 (65%)]\tLoss: 0.151278\n",
      "Train Epoch: 5 [10000/13824 (72%)]\tLoss: 0.272914\n",
      "Train Epoch: 5 [11000/13824 (79%)]\tLoss: 0.215268\n",
      "Train Epoch: 5 [12000/13824 (86%)]\tLoss: 0.211697\n",
      "Train Epoch: 5 [13000/13824 (94%)]\tLoss: 0.149559\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.4245, Accuracy: 7130/10000 (71%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/14254 (0%)]\tLoss: 0.243696\n",
      "Train Epoch: 1 [1000/14254 (7%)]\tLoss: 0.324608\n",
      "Train Epoch: 1 [2000/14254 (14%)]\tLoss: 0.287890\n",
      "Train Epoch: 1 [3000/14254 (21%)]\tLoss: 0.308268\n",
      "Train Epoch: 1 [4000/14254 (28%)]\tLoss: 0.440528\n",
      "Train Epoch: 1 [5000/14254 (35%)]\tLoss: 0.540294\n",
      "Train Epoch: 1 [6000/14254 (42%)]\tLoss: 0.309313\n",
      "Train Epoch: 1 [7000/14254 (49%)]\tLoss: 0.346774\n",
      "Train Epoch: 1 [8000/14254 (56%)]\tLoss: 0.271945\n",
      "Train Epoch: 1 [9000/14254 (63%)]\tLoss: 0.391325\n",
      "Train Epoch: 1 [10000/14254 (70%)]\tLoss: 0.385287\n",
      "Train Epoch: 1 [11000/14254 (77%)]\tLoss: 0.310913\n",
      "Train Epoch: 1 [12000/14254 (84%)]\tLoss: 0.303552\n",
      "Train Epoch: 1 [13000/14254 (91%)]\tLoss: 0.432187\n",
      "Train Epoch: 1 [14000/14254 (98%)]\tLoss: 0.322691\n",
      "Train Epoch: 2 [0/14254 (0%)]\tLoss: 0.354626\n",
      "Train Epoch: 2 [1000/14254 (7%)]\tLoss: 0.360638\n",
      "Train Epoch: 2 [2000/14254 (14%)]\tLoss: 0.263503\n",
      "Train Epoch: 2 [3000/14254 (21%)]\tLoss: 0.365195\n",
      "Train Epoch: 2 [4000/14254 (28%)]\tLoss: 0.365130\n",
      "Train Epoch: 2 [5000/14254 (35%)]\tLoss: 0.414266\n",
      "Train Epoch: 2 [6000/14254 (42%)]\tLoss: 0.239010\n",
      "Train Epoch: 2 [7000/14254 (49%)]\tLoss: 0.362950\n",
      "Train Epoch: 2 [8000/14254 (56%)]\tLoss: 0.335465\n",
      "Train Epoch: 2 [9000/14254 (63%)]\tLoss: 0.231139\n",
      "Train Epoch: 2 [10000/14254 (70%)]\tLoss: 0.302383\n",
      "Train Epoch: 2 [11000/14254 (77%)]\tLoss: 0.259407\n",
      "Train Epoch: 2 [12000/14254 (84%)]\tLoss: 0.222622\n",
      "Train Epoch: 2 [13000/14254 (91%)]\tLoss: 0.357129\n",
      "Train Epoch: 2 [14000/14254 (98%)]\tLoss: 0.346163\n",
      "Train Epoch: 3 [0/14254 (0%)]\tLoss: 0.285083\n",
      "Train Epoch: 3 [1000/14254 (7%)]\tLoss: 0.387960\n",
      "Train Epoch: 3 [2000/14254 (14%)]\tLoss: 0.327727\n",
      "Train Epoch: 3 [3000/14254 (21%)]\tLoss: 0.376364\n",
      "Train Epoch: 3 [4000/14254 (28%)]\tLoss: 0.293619\n",
      "Train Epoch: 3 [5000/14254 (35%)]\tLoss: 0.281463\n",
      "Train Epoch: 3 [6000/14254 (42%)]\tLoss: 0.324160\n",
      "Train Epoch: 3 [7000/14254 (49%)]\tLoss: 0.322487\n",
      "Train Epoch: 3 [8000/14254 (56%)]\tLoss: 0.287431\n",
      "Train Epoch: 3 [9000/14254 (63%)]\tLoss: 0.222377\n",
      "Train Epoch: 3 [10000/14254 (70%)]\tLoss: 0.273400\n",
      "Train Epoch: 3 [11000/14254 (77%)]\tLoss: 0.306685\n",
      "Train Epoch: 3 [12000/14254 (84%)]\tLoss: 0.399481\n",
      "Train Epoch: 3 [13000/14254 (91%)]\tLoss: 0.287328\n",
      "Train Epoch: 3 [14000/14254 (98%)]\tLoss: 0.254373\n",
      "Train Epoch: 4 [0/14254 (0%)]\tLoss: 0.174863\n",
      "Train Epoch: 4 [1000/14254 (7%)]\tLoss: 0.339899\n",
      "Train Epoch: 4 [2000/14254 (14%)]\tLoss: 0.344827\n",
      "Train Epoch: 4 [3000/14254 (21%)]\tLoss: 0.312438\n",
      "Train Epoch: 4 [4000/14254 (28%)]\tLoss: 0.221390\n",
      "Train Epoch: 4 [5000/14254 (35%)]\tLoss: 0.331501\n",
      "Train Epoch: 4 [6000/14254 (42%)]\tLoss: 0.404899\n",
      "Train Epoch: 4 [7000/14254 (49%)]\tLoss: 0.287644\n",
      "Train Epoch: 4 [8000/14254 (56%)]\tLoss: 0.364192\n",
      "Train Epoch: 4 [9000/14254 (63%)]\tLoss: 0.299836\n",
      "Train Epoch: 4 [10000/14254 (70%)]\tLoss: 0.241280\n",
      "Train Epoch: 4 [11000/14254 (77%)]\tLoss: 0.352322\n",
      "Train Epoch: 4 [12000/14254 (84%)]\tLoss: 0.335167\n",
      "Train Epoch: 4 [13000/14254 (91%)]\tLoss: 0.315711\n",
      "Train Epoch: 4 [14000/14254 (98%)]\tLoss: 0.376531\n",
      "Train Epoch: 5 [0/14254 (0%)]\tLoss: 0.322891\n",
      "Train Epoch: 5 [1000/14254 (7%)]\tLoss: 0.437436\n",
      "Train Epoch: 5 [2000/14254 (14%)]\tLoss: 0.324786\n",
      "Train Epoch: 5 [3000/14254 (21%)]\tLoss: 0.249389\n",
      "Train Epoch: 5 [4000/14254 (28%)]\tLoss: 0.347619\n",
      "Train Epoch: 5 [5000/14254 (35%)]\tLoss: 0.287399\n",
      "Train Epoch: 5 [6000/14254 (42%)]\tLoss: 0.210430\n",
      "Train Epoch: 5 [7000/14254 (49%)]\tLoss: 0.312267\n",
      "Train Epoch: 5 [8000/14254 (56%)]\tLoss: 0.230558\n",
      "Train Epoch: 5 [9000/14254 (63%)]\tLoss: 0.282832\n",
      "Train Epoch: 5 [10000/14254 (70%)]\tLoss: 0.240156\n",
      "Train Epoch: 5 [11000/14254 (77%)]\tLoss: 0.513677\n",
      "Train Epoch: 5 [12000/14254 (84%)]\tLoss: 0.363340\n",
      "Train Epoch: 5 [13000/14254 (91%)]\tLoss: 0.135235\n",
      "Train Epoch: 5 [14000/14254 (98%)]\tLoss: 0.466581\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/13824 (0%)]\tLoss: 0.311398\n",
      "Train Epoch: 1 [1000/13824 (7%)]\tLoss: 0.144633\n",
      "Train Epoch: 1 [2000/13824 (14%)]\tLoss: 0.154421\n",
      "Train Epoch: 1 [3000/13824 (22%)]\tLoss: 0.296145\n",
      "Train Epoch: 1 [4000/13824 (29%)]\tLoss: 0.174869\n",
      "Train Epoch: 1 [5000/13824 (36%)]\tLoss: 0.137217\n",
      "Train Epoch: 1 [6000/13824 (43%)]\tLoss: 0.330877\n",
      "Train Epoch: 1 [7000/13824 (50%)]\tLoss: 0.130041\n",
      "Train Epoch: 1 [8000/13824 (58%)]\tLoss: 0.235660\n",
      "Train Epoch: 1 [9000/13824 (65%)]\tLoss: 0.218384\n",
      "Train Epoch: 1 [10000/13824 (72%)]\tLoss: 0.170914\n",
      "Train Epoch: 1 [11000/13824 (79%)]\tLoss: 0.172441\n",
      "Train Epoch: 1 [12000/13824 (86%)]\tLoss: 0.358734\n",
      "Train Epoch: 1 [13000/13824 (94%)]\tLoss: 0.180523\n",
      "Train Epoch: 2 [0/13824 (0%)]\tLoss: 0.220627\n",
      "Train Epoch: 2 [1000/13824 (7%)]\tLoss: 0.214406\n",
      "Train Epoch: 2 [2000/13824 (14%)]\tLoss: 0.180106\n",
      "Train Epoch: 2 [3000/13824 (22%)]\tLoss: 0.258787\n",
      "Train Epoch: 2 [4000/13824 (29%)]\tLoss: 0.252327\n",
      "Train Epoch: 2 [5000/13824 (36%)]\tLoss: 0.146264\n",
      "Train Epoch: 2 [6000/13824 (43%)]\tLoss: 0.307754\n",
      "Train Epoch: 2 [7000/13824 (50%)]\tLoss: 0.308932\n",
      "Train Epoch: 2 [8000/13824 (58%)]\tLoss: 0.294778\n",
      "Train Epoch: 2 [9000/13824 (65%)]\tLoss: 0.166699\n",
      "Train Epoch: 2 [10000/13824 (72%)]\tLoss: 0.102310\n",
      "Train Epoch: 2 [11000/13824 (79%)]\tLoss: 0.184011\n",
      "Train Epoch: 2 [12000/13824 (86%)]\tLoss: 0.194053\n",
      "Train Epoch: 2 [13000/13824 (94%)]\tLoss: 0.214952\n",
      "Train Epoch: 3 [0/13824 (0%)]\tLoss: 0.180764\n",
      "Train Epoch: 3 [1000/13824 (7%)]\tLoss: 0.153694\n",
      "Train Epoch: 3 [2000/13824 (14%)]\tLoss: 0.225830\n",
      "Train Epoch: 3 [3000/13824 (22%)]\tLoss: 0.161124\n",
      "Train Epoch: 3 [4000/13824 (29%)]\tLoss: 0.252342\n",
      "Train Epoch: 3 [5000/13824 (36%)]\tLoss: 0.173994\n",
      "Train Epoch: 3 [6000/13824 (43%)]\tLoss: 0.154447\n",
      "Train Epoch: 3 [7000/13824 (50%)]\tLoss: 0.247142\n",
      "Train Epoch: 3 [8000/13824 (58%)]\tLoss: 0.126212\n",
      "Train Epoch: 3 [9000/13824 (65%)]\tLoss: 0.266595\n",
      "Train Epoch: 3 [10000/13824 (72%)]\tLoss: 0.232053\n",
      "Train Epoch: 3 [11000/13824 (79%)]\tLoss: 0.274795\n",
      "Train Epoch: 3 [12000/13824 (86%)]\tLoss: 0.212075\n",
      "Train Epoch: 3 [13000/13824 (94%)]\tLoss: 0.166385\n",
      "Train Epoch: 4 [0/13824 (0%)]\tLoss: 0.268299\n",
      "Train Epoch: 4 [1000/13824 (7%)]\tLoss: 0.291500\n",
      "Train Epoch: 4 [2000/13824 (14%)]\tLoss: 0.238587\n",
      "Train Epoch: 4 [3000/13824 (22%)]\tLoss: 0.239744\n",
      "Train Epoch: 4 [4000/13824 (29%)]\tLoss: 0.122767\n",
      "Train Epoch: 4 [5000/13824 (36%)]\tLoss: 0.119188\n",
      "Train Epoch: 4 [6000/13824 (43%)]\tLoss: 0.169632\n",
      "Train Epoch: 4 [7000/13824 (50%)]\tLoss: 0.180096\n",
      "Train Epoch: 4 [8000/13824 (58%)]\tLoss: 0.212840\n",
      "Train Epoch: 4 [9000/13824 (65%)]\tLoss: 0.126389\n",
      "Train Epoch: 4 [10000/13824 (72%)]\tLoss: 0.250188\n",
      "Train Epoch: 4 [11000/13824 (79%)]\tLoss: 0.207341\n",
      "Train Epoch: 4 [12000/13824 (86%)]\tLoss: 0.254361\n",
      "Train Epoch: 4 [13000/13824 (94%)]\tLoss: 0.292599\n",
      "Train Epoch: 5 [0/13824 (0%)]\tLoss: 0.148741\n",
      "Train Epoch: 5 [1000/13824 (7%)]\tLoss: 0.265663\n",
      "Train Epoch: 5 [2000/13824 (14%)]\tLoss: 0.160686\n",
      "Train Epoch: 5 [3000/13824 (22%)]\tLoss: 0.240826\n",
      "Train Epoch: 5 [4000/13824 (29%)]\tLoss: 0.204852\n",
      "Train Epoch: 5 [5000/13824 (36%)]\tLoss: 0.102111\n",
      "Train Epoch: 5 [6000/13824 (43%)]\tLoss: 0.144370\n",
      "Train Epoch: 5 [7000/13824 (50%)]\tLoss: 0.293976\n",
      "Train Epoch: 5 [8000/13824 (58%)]\tLoss: 0.239514\n",
      "Train Epoch: 5 [9000/13824 (65%)]\tLoss: 0.150716\n",
      "Train Epoch: 5 [10000/13824 (72%)]\tLoss: 0.136695\n",
      "Train Epoch: 5 [11000/13824 (79%)]\tLoss: 0.235392\n",
      "Train Epoch: 5 [12000/13824 (86%)]\tLoss: 0.187266\n",
      "Train Epoch: 5 [13000/13824 (94%)]\tLoss: 0.268152\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.4629, Accuracy: 7134/10000 (71%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/14254 (0%)]\tLoss: 0.498209\n",
      "Train Epoch: 1 [1000/14254 (7%)]\tLoss: 0.379020\n",
      "Train Epoch: 1 [2000/14254 (14%)]\tLoss: 0.422868\n",
      "Train Epoch: 1 [3000/14254 (21%)]\tLoss: 0.235540\n",
      "Train Epoch: 1 [4000/14254 (28%)]\tLoss: 0.300380\n",
      "Train Epoch: 1 [5000/14254 (35%)]\tLoss: 0.373835\n",
      "Train Epoch: 1 [6000/14254 (42%)]\tLoss: 0.399170\n",
      "Train Epoch: 1 [7000/14254 (49%)]\tLoss: 0.248633\n",
      "Train Epoch: 1 [8000/14254 (56%)]\tLoss: 0.320504\n",
      "Train Epoch: 1 [9000/14254 (63%)]\tLoss: 0.297373\n",
      "Train Epoch: 1 [10000/14254 (70%)]\tLoss: 0.301116\n",
      "Train Epoch: 1 [11000/14254 (77%)]\tLoss: 0.342620\n",
      "Train Epoch: 1 [12000/14254 (84%)]\tLoss: 0.359794\n",
      "Train Epoch: 1 [13000/14254 (91%)]\tLoss: 0.365203\n",
      "Train Epoch: 1 [14000/14254 (98%)]\tLoss: 0.236232\n",
      "Train Epoch: 2 [0/14254 (0%)]\tLoss: 0.266424\n",
      "Train Epoch: 2 [1000/14254 (7%)]\tLoss: 0.426095\n",
      "Train Epoch: 2 [2000/14254 (14%)]\tLoss: 0.360780\n",
      "Train Epoch: 2 [3000/14254 (21%)]\tLoss: 0.416945\n",
      "Train Epoch: 2 [4000/14254 (28%)]\tLoss: 0.364423\n",
      "Train Epoch: 2 [5000/14254 (35%)]\tLoss: 0.288379\n",
      "Train Epoch: 2 [6000/14254 (42%)]\tLoss: 0.291311\n",
      "Train Epoch: 2 [7000/14254 (49%)]\tLoss: 0.376441\n",
      "Train Epoch: 2 [8000/14254 (56%)]\tLoss: 0.343284\n",
      "Train Epoch: 2 [9000/14254 (63%)]\tLoss: 0.290380\n",
      "Train Epoch: 2 [10000/14254 (70%)]\tLoss: 0.235635\n",
      "Train Epoch: 2 [11000/14254 (77%)]\tLoss: 0.450148\n",
      "Train Epoch: 2 [12000/14254 (84%)]\tLoss: 0.316899\n",
      "Train Epoch: 2 [13000/14254 (91%)]\tLoss: 0.512551\n",
      "Train Epoch: 2 [14000/14254 (98%)]\tLoss: 0.394000\n",
      "Train Epoch: 3 [0/14254 (0%)]\tLoss: 0.283995\n",
      "Train Epoch: 3 [1000/14254 (7%)]\tLoss: 0.381837\n",
      "Train Epoch: 3 [2000/14254 (14%)]\tLoss: 0.283651\n",
      "Train Epoch: 3 [3000/14254 (21%)]\tLoss: 0.275593\n",
      "Train Epoch: 3 [4000/14254 (28%)]\tLoss: 0.327623\n",
      "Train Epoch: 3 [5000/14254 (35%)]\tLoss: 0.251942\n",
      "Train Epoch: 3 [6000/14254 (42%)]\tLoss: 0.329572\n",
      "Train Epoch: 3 [7000/14254 (49%)]\tLoss: 0.324468\n",
      "Train Epoch: 3 [8000/14254 (56%)]\tLoss: 0.334011\n",
      "Train Epoch: 3 [9000/14254 (63%)]\tLoss: 0.340832\n",
      "Train Epoch: 3 [10000/14254 (70%)]\tLoss: 0.281321\n",
      "Train Epoch: 3 [11000/14254 (77%)]\tLoss: 0.248219\n",
      "Train Epoch: 3 [12000/14254 (84%)]\tLoss: 0.461920\n",
      "Train Epoch: 3 [13000/14254 (91%)]\tLoss: 0.309175\n",
      "Train Epoch: 3 [14000/14254 (98%)]\tLoss: 0.302297\n",
      "Train Epoch: 4 [0/14254 (0%)]\tLoss: 0.321511\n",
      "Train Epoch: 4 [1000/14254 (7%)]\tLoss: 0.397688\n",
      "Train Epoch: 4 [2000/14254 (14%)]\tLoss: 0.221242\n",
      "Train Epoch: 4 [3000/14254 (21%)]\tLoss: 0.274419\n",
      "Train Epoch: 4 [4000/14254 (28%)]\tLoss: 0.319446\n",
      "Train Epoch: 4 [5000/14254 (35%)]\tLoss: 0.325868\n",
      "Train Epoch: 4 [6000/14254 (42%)]\tLoss: 0.312207\n",
      "Train Epoch: 4 [7000/14254 (49%)]\tLoss: 0.373834\n",
      "Train Epoch: 4 [8000/14254 (56%)]\tLoss: 0.274932\n",
      "Train Epoch: 4 [9000/14254 (63%)]\tLoss: 0.282124\n",
      "Train Epoch: 4 [10000/14254 (70%)]\tLoss: 0.318169\n",
      "Train Epoch: 4 [11000/14254 (77%)]\tLoss: 0.263212\n",
      "Train Epoch: 4 [12000/14254 (84%)]\tLoss: 0.244058\n",
      "Train Epoch: 4 [13000/14254 (91%)]\tLoss: 0.295038\n",
      "Train Epoch: 4 [14000/14254 (98%)]\tLoss: 0.262141\n",
      "Train Epoch: 5 [0/14254 (0%)]\tLoss: 0.353851\n",
      "Train Epoch: 5 [1000/14254 (7%)]\tLoss: 0.371915\n",
      "Train Epoch: 5 [2000/14254 (14%)]\tLoss: 0.251599\n",
      "Train Epoch: 5 [3000/14254 (21%)]\tLoss: 0.354427\n",
      "Train Epoch: 5 [4000/14254 (28%)]\tLoss: 0.443234\n",
      "Train Epoch: 5 [5000/14254 (35%)]\tLoss: 0.338959\n",
      "Train Epoch: 5 [6000/14254 (42%)]\tLoss: 0.402191\n",
      "Train Epoch: 5 [7000/14254 (49%)]\tLoss: 0.278609\n",
      "Train Epoch: 5 [8000/14254 (56%)]\tLoss: 0.297103\n",
      "Train Epoch: 5 [9000/14254 (63%)]\tLoss: 0.225660\n",
      "Train Epoch: 5 [10000/14254 (70%)]\tLoss: 0.237226\n",
      "Train Epoch: 5 [11000/14254 (77%)]\tLoss: 0.368595\n",
      "Train Epoch: 5 [12000/14254 (84%)]\tLoss: 0.258497\n",
      "Train Epoch: 5 [13000/14254 (91%)]\tLoss: 0.270485\n",
      "Train Epoch: 5 [14000/14254 (98%)]\tLoss: 0.216072\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/13824 (0%)]\tLoss: 0.460019\n",
      "Train Epoch: 1 [1000/13824 (7%)]\tLoss: 0.158938\n",
      "Train Epoch: 1 [2000/13824 (14%)]\tLoss: 0.123045\n",
      "Train Epoch: 1 [3000/13824 (22%)]\tLoss: 0.180123\n",
      "Train Epoch: 1 [4000/13824 (29%)]\tLoss: 0.233501\n",
      "Train Epoch: 1 [5000/13824 (36%)]\tLoss: 0.179342\n",
      "Train Epoch: 1 [6000/13824 (43%)]\tLoss: 0.373466\n",
      "Train Epoch: 1 [7000/13824 (50%)]\tLoss: 0.176182\n",
      "Train Epoch: 1 [8000/13824 (58%)]\tLoss: 0.149525\n",
      "Train Epoch: 1 [9000/13824 (65%)]\tLoss: 0.154630\n",
      "Train Epoch: 1 [10000/13824 (72%)]\tLoss: 0.158089\n",
      "Train Epoch: 1 [11000/13824 (79%)]\tLoss: 0.253786\n",
      "Train Epoch: 1 [12000/13824 (86%)]\tLoss: 0.180446\n",
      "Train Epoch: 1 [13000/13824 (94%)]\tLoss: 0.270176\n",
      "Train Epoch: 2 [0/13824 (0%)]\tLoss: 0.218938\n",
      "Train Epoch: 2 [1000/13824 (7%)]\tLoss: 0.172155\n",
      "Train Epoch: 2 [2000/13824 (14%)]\tLoss: 0.207584\n",
      "Train Epoch: 2 [3000/13824 (22%)]\tLoss: 0.156780\n",
      "Train Epoch: 2 [4000/13824 (29%)]\tLoss: 0.252018\n",
      "Train Epoch: 2 [5000/13824 (36%)]\tLoss: 0.171683\n",
      "Train Epoch: 2 [6000/13824 (43%)]\tLoss: 0.171903\n",
      "Train Epoch: 2 [7000/13824 (50%)]\tLoss: 0.219755\n",
      "Train Epoch: 2 [8000/13824 (58%)]\tLoss: 0.271476\n",
      "Train Epoch: 2 [9000/13824 (65%)]\tLoss: 0.155077\n",
      "Train Epoch: 2 [10000/13824 (72%)]\tLoss: 0.229288\n",
      "Train Epoch: 2 [11000/13824 (79%)]\tLoss: 0.184400\n",
      "Train Epoch: 2 [12000/13824 (86%)]\tLoss: 0.345054\n",
      "Train Epoch: 2 [13000/13824 (94%)]\tLoss: 0.203938\n",
      "Train Epoch: 3 [0/13824 (0%)]\tLoss: 0.265218\n",
      "Train Epoch: 3 [1000/13824 (7%)]\tLoss: 0.176530\n",
      "Train Epoch: 3 [2000/13824 (14%)]\tLoss: 0.219823\n",
      "Train Epoch: 3 [3000/13824 (22%)]\tLoss: 0.172532\n",
      "Train Epoch: 3 [4000/13824 (29%)]\tLoss: 0.258525\n",
      "Train Epoch: 3 [5000/13824 (36%)]\tLoss: 0.084736\n",
      "Train Epoch: 3 [6000/13824 (43%)]\tLoss: 0.175874\n",
      "Train Epoch: 3 [7000/13824 (50%)]\tLoss: 0.181580\n",
      "Train Epoch: 3 [8000/13824 (58%)]\tLoss: 0.150833\n",
      "Train Epoch: 3 [9000/13824 (65%)]\tLoss: 0.138174\n",
      "Train Epoch: 3 [10000/13824 (72%)]\tLoss: 0.224295\n",
      "Train Epoch: 3 [11000/13824 (79%)]\tLoss: 0.163033\n",
      "Train Epoch: 3 [12000/13824 (86%)]\tLoss: 0.223600\n",
      "Train Epoch: 3 [13000/13824 (94%)]\tLoss: 0.270941\n",
      "Train Epoch: 4 [0/13824 (0%)]\tLoss: 0.183074\n",
      "Train Epoch: 4 [1000/13824 (7%)]\tLoss: 0.165404\n",
      "Train Epoch: 4 [2000/13824 (14%)]\tLoss: 0.240694\n",
      "Train Epoch: 4 [3000/13824 (22%)]\tLoss: 0.193149\n",
      "Train Epoch: 4 [4000/13824 (29%)]\tLoss: 0.090095\n",
      "Train Epoch: 4 [5000/13824 (36%)]\tLoss: 0.233832\n",
      "Train Epoch: 4 [6000/13824 (43%)]\tLoss: 0.163438\n",
      "Train Epoch: 4 [7000/13824 (50%)]\tLoss: 0.120549\n",
      "Train Epoch: 4 [8000/13824 (58%)]\tLoss: 0.111628\n",
      "Train Epoch: 4 [9000/13824 (65%)]\tLoss: 0.288771\n",
      "Train Epoch: 4 [10000/13824 (72%)]\tLoss: 0.155194\n",
      "Train Epoch: 4 [11000/13824 (79%)]\tLoss: 0.175010\n",
      "Train Epoch: 4 [12000/13824 (86%)]\tLoss: 0.273050\n",
      "Train Epoch: 4 [13000/13824 (94%)]\tLoss: 0.249468\n",
      "Train Epoch: 5 [0/13824 (0%)]\tLoss: 0.153178\n",
      "Train Epoch: 5 [1000/13824 (7%)]\tLoss: 0.145689\n",
      "Train Epoch: 5 [2000/13824 (14%)]\tLoss: 0.158695\n",
      "Train Epoch: 5 [3000/13824 (22%)]\tLoss: 0.225357\n",
      "Train Epoch: 5 [4000/13824 (29%)]\tLoss: 0.147969\n",
      "Train Epoch: 5 [5000/13824 (36%)]\tLoss: 0.146508\n",
      "Train Epoch: 5 [6000/13824 (43%)]\tLoss: 0.239357\n",
      "Train Epoch: 5 [7000/13824 (50%)]\tLoss: 0.133552\n",
      "Train Epoch: 5 [8000/13824 (58%)]\tLoss: 0.136409\n",
      "Train Epoch: 5 [9000/13824 (65%)]\tLoss: 0.229222\n",
      "Train Epoch: 5 [10000/13824 (72%)]\tLoss: 0.181704\n",
      "Train Epoch: 5 [11000/13824 (79%)]\tLoss: 0.169323\n",
      "Train Epoch: 5 [12000/13824 (86%)]\tLoss: 0.227547\n",
      "Train Epoch: 5 [13000/13824 (94%)]\tLoss: 0.412197\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.4414, Accuracy: 7166/10000 (72%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for partitions_number in numberOfPartitions:\n",
    "    print(f\"Running experiment with {partitions_number} partitions...\")\n",
    "    \n",
    "    partitioned_data_auto = partition.balanced_dirichlet_partition(trainingset_auto, partitions_number=partitions_number, alpha=0.5)\n",
    "    auto_client_loaders = [\n",
    "        DataLoader(Subset(trainingset_auto, indices), batch_size=batch_size_train, shuffle=True)\n",
    "        for indices in partitioned_data_auto.values()\n",
    "    ]\n",
    "    \n",
    "    num_clients = partitions_number\n",
    "    local_model_autoencoder_strong = [copy.deepcopy(global_model_auto_strong) for _ in range(num_clients)]\n",
    "    \n",
    "    optimizer = optim.SGD(trial_model_auto_strong.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    \n",
    "    train_losses = []\n",
    "    train_counter = []\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):  \n",
    "        train_fashion(epoch, trial_model_auto_strong, reduced_train_loader_auto, optimizer, log_interval, train_losses, train_counter)\n",
    "    \n",
    "    test_losses_auto_strong = []\n",
    "    test_fashion(trial_model_auto_strong, reduced_train_loader_auto, test_losses_auto_strong)\n",
    "\n",
    "    rounds_auto = 4\n",
    "    for round_idx in range(rounds_auto):\n",
    "        print(f\"Round {round_idx + 1}/{rounds_auto}\")\n",
    "        \n",
    "        local_weights_auto = []\n",
    "        for client_idx, client_model in enumerate(local_model_autoencoder_strong):\n",
    "            print(f\"Training client {client_idx + 1}\")\n",
    "            \n",
    "            optimizer = optim.SGD(client_model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "            \n",
    "            train_losses = []\n",
    "            train_counter = []\n",
    "        \n",
    "            for epoch in range(1, n_epochs + 1):  \n",
    "                train_fashion(epoch, client_model, auto_client_loaders[client_idx], optimizer, log_interval, train_losses, train_counter)\n",
    "            \n",
    "            client_weights = [param.data.numpy() for param in client_model.parameters()]\n",
    "            local_weights_auto.append(client_weights)\n",
    "        \n",
    "        global_weights_auto = federated_averaging(local_weights_auto)\n",
    "        \n",
    "        distribute_global_model(global_weights_auto, local_model_autoencoder_strong, single=False)\n",
    "        distribute_global_model(global_weights_auto, global_model_auto_strong, single=True)\n",
    "        \n",
    "        test_losses = []\n",
    "        test_fashion(global_model_auto_strong, test_loader_auto, test_losses)\n",
    "        \n",
    "        test_accuracies_classic = []\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader_auto:\n",
    "                output = global_model_classic(data)\n",
    "                pred = output.data.max(1, keepdim=True)[1]\n",
    "                correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "        accuracy = 100. * correct / len(test_loader_auto.dataset)\n",
    "        test_accuracies_classic.append(accuracy)\n",
    "        \n",
    "        # Save results for non-clustered classic\n",
    "        if partitions_number not in results[\"autoencoder\"]:\n",
    "            results[\"autoencoder\"][partitions_number] = {\"losses\": [], \"accuracy\": []}\n",
    "        \n",
    "        results[\"autoencoder\"][partitions_number][\"losses\"].extend(test_losses)\n",
    "        results[\"autoencoder\"][partitions_number][\"accuracy\"].extend(test_accuracies_classic)\n",
    "\n",
    "    ######################\n",
    "    # Clustering process\n",
    "    import cluster\n",
    "    cluster = cluster.Cluster(num_clusters=4)\n",
    "    \n",
    "    targets = trainingset_auto.targets\n",
    "    num_classes = len(set(targets)) \n",
    "    clustered_data = cluster.apply_clustering(partitioned_data_auto, targets, num_classes)\n",
    "    \n",
    "    partitioned_data_auto_clustered = clustered_data\n",
    "    \n",
    "    auto_client_loaders_clustered = [\n",
    "        DataLoader(Subset(trainingset_auto, indices), batch_size=batch_size_train, shuffle=True)\n",
    "        for indices in partitioned_data_auto_clustered.values()\n",
    "    ]\n",
    "    \n",
    "    for round_idx in range(rounds_auto):\n",
    "        print(f\"Round {round_idx + 1}/{rounds_auto}\")\n",
    "        \n",
    "        local_weights_auto = []\n",
    "        for client_idx, client_model in enumerate(local_model_autoencoder_strong[0:num_clusters]):\n",
    "            print(f\"Training client {client_idx + 1}\")\n",
    "            \n",
    "            optimizer = optim.SGD(client_model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "            \n",
    "            train_losses = []\n",
    "            train_counter = []\n",
    "        \n",
    "            for epoch in range(1, n_epochs + 1):  \n",
    "                train_fashion(epoch, client_model, auto_client_loaders_clustered[client_idx], optimizer, log_interval, train_losses, train_counter)\n",
    "            \n",
    "            client_weights = [param.data.numpy() for param in client_model.parameters()]\n",
    "            local_weights_auto.append(client_weights)\n",
    "        \n",
    "        global_weights_auto = federated_averaging(local_weights_auto)\n",
    "        \n",
    "        distribute_global_model(global_weights_auto, local_model_autoencoder_strong, single=False)\n",
    "        distribute_global_model(global_weights_auto, global_model_auto_strong, single=True)\n",
    "        \n",
    "        test_losses = []\n",
    "        test_fashion(global_model_auto_strong, test_loader_auto, test_losses)\n",
    "        \n",
    "        test_accuracies_classic = []\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader_auto:\n",
    "                output = global_model_classic(data)\n",
    "                pred = output.data.max(1, keepdim=True)[1]\n",
    "                correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "        accuracy = 100. * correct / len(test_loader_auto.dataset)\n",
    "        test_accuracies_classic.append(accuracy)\n",
    "        \n",
    "        # Save results for clustered classic\n",
    "        if partitions_number not in clusteredResults[\"autoencoder\"]:\n",
    "            clusteredResults[\"autoencoder\"][partitions_number] = {\"losses\": [], \"accuracy\": []}\n",
    "        \n",
    "        clusteredResults[\"autoencoder\"][partitions_number][\"losses\"].extend(test_losses)\n",
    "        clusteredResults[\"autoencoder\"][partitions_number][\"accuracy\"].extend(test_accuracies_classic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results (Non-Clustered): {'classic': {4: {'losses': [0.6815479064941407, 0.49938775939941404, 0.46115848693847655, 0.4383513153076172], 'accuracy': [10.29, 10.05, 10.41, 10.14]}, 6: {'losses': [0.382756201171875, 0.38323160400390627, 0.3741429901123047, 0.36963440551757815], 'accuracy': [10.28, 10.22, 10.08, 10.48]}, 8: {'losses': [0.36661693725585937, 0.3617134796142578, 0.3648541442871094, 0.3626453094482422], 'accuracy': [10.42, 10.1, 10.52, 10.87]}, 10: {'losses': [0.3590808044433594, 0.3577126373291016, 0.35142200622558595, 0.3532148468017578], 'accuracy': [10.6, 9.53, 10.48, 9.72]}}, 'pca': {4: {'losses': [1.1178964111328125, 0.9523929016113282, 0.8969520141601562, 0.851038330078125], 'accuracy': [9.98, 10.22, 9.72, 10.25]}, 6: {'losses': [0.7265787658691406, 0.7113021057128907, 0.7031130065917969, 0.6795821533203125], 'accuracy': [10.22, 10.22, 9.68, 9.8]}, 8: {'losses': [0.6413265014648437, 0.6276532104492187, 0.6225778503417969, 0.6192710388183593], 'accuracy': [10.47, 10.23, 10.37, 10.12]}, 10: {'losses': [0.5939065734863281, 0.5915477111816406, 0.5883621154785156, 0.5806868286132812], 'accuracy': [10.25, 9.73, 10.24, 10.1]}}, 'autoencoder': {4: {'losses': [1.2434223876953125, 1.1041057373046874, 0.9885256408691406, 0.9419609741210937], 'accuracy': [9.69, 10.31, 10.19, 9.99]}, 6: {'losses': [0.7711310729980468, 0.7741464599609374, 0.7823713134765625, 0.7985965759277344], 'accuracy': [10.06, 10.13, 10.21, 10.36]}, 8: {'losses': [0.9874863159179688, 0.9896409729003907, 0.9711555053710937, 0.9907492614746094], 'accuracy': [10.4, 10.2, 10.83, 10.57]}, 10: {'losses': [1.0437593383789063, 1.0895837524414063, 1.096368536376953, 1.13660517578125], 'accuracy': [9.27, 10.29, 10.21, 10.38]}}}\n",
      "Final Results (Clustered): {'classic': {4: {'losses': [0.43703709716796874, 0.4280464233398438, 0.41145969848632813, 0.42101661376953126], 'accuracy': [10.17, 9.97, 10.26, 9.91]}, 6: {'losses': [0.3982194122314453, 0.395793017578125, 0.38184085693359376, 0.4105090576171875], 'accuracy': [9.9, 10.49, 10.04, 10.6]}, 8: {'losses': [0.40630611267089844, 0.43011572265625, 0.41488186645507813, 0.41762550048828123], 'accuracy': [10.14, 9.79, 9.97, 9.88]}, 10: {'losses': [0.42335987243652345, 0.43057445068359373, 0.4588637054443359, 0.4647010650634766], 'accuracy': [10.01, 10.33, 9.53, 9.97]}}, 'pca': {4: {'losses': [0.8079928405761718, 0.7724112243652344, 0.7576869506835937, 0.7453690246582031], 'accuracy': [10.01, 10.26, 10.32, 9.98]}, 6: {'losses': [0.6738732360839844, 0.6647598022460938, 0.6618483276367187, 0.6516339904785157], 'accuracy': [9.71, 9.8, 9.88, 10.21]}, 8: {'losses': [0.6119742736816406, 0.5993320007324219, 0.5925026550292969, 0.5916678833007812], 'accuracy': [10.34, 9.91, 9.61, 9.75]}, 10: {'losses': [0.5778182800292969, 0.5766717102050781, 0.5687302124023438, 0.564671142578125], 'accuracy': [10.43, 10.19, 10.06, 10.33]}}, 'autoencoder': {4: {'losses': [0.9562535949707032, 0.8634262939453125, 0.8196472229003906, 0.9050225891113282], 'accuracy': [10.22, 9.95, 10.12, 10.17]}, 6: {'losses': [1.0333704833984374, 1.13689970703125, 1.1160997375488282, 1.2073543579101562], 'accuracy': [10.05, 10.02, 10.08, 10.29]}, 8: {'losses': [1.0700794677734375, 1.09198310546875, 1.090372381591797, 1.113705584716797], 'accuracy': [10.45, 10.34, 9.87, 10.03]}, 10: {'losses': [1.3227311401367188, 1.424512451171875, 1.4629238891601561, 1.4413832763671874], 'accuracy': [10.33, 10.0, 10.34, 9.86]}}}\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Results (Non-Clustered):\", results)\n",
    "print(\"Final Results (Clustered):\", clusteredResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_client_averages(data):\n",
    "    client_averages = {}\n",
    "    for client, client_data in data.items():  \n",
    "        client_averages[client] = {}\n",
    "        for partition_number, metrics in client_data.items():  # Iterate over partitions\n",
    "            avg_loss = sum(metrics['losses']) / len(metrics['losses']) if metrics['losses'] else 0\n",
    "            avg_accuracy = sum(metrics['accuracy']) / len(metrics['accuracy']) if metrics['accuracy'] else 0\n",
    "            client_averages[client][partition_number] = {\"average_loss\": avg_loss, \"average_accuracy\": avg_accuracy}\n",
    "    return client_averages\n",
    "\n",
    "\n",
    "non_clustered_averages = calculate_client_averages(results)\n",
    "clustered_averages = calculate_client_averages(clusteredResults)\n",
    "\n",
    "\n",
    "def plot_averages(non_clustered, clustered):\n",
    "    for client_type in non_clustered.keys(): \n",
    "        partitions_non_clustered = list(non_clustered[client_type].keys())\n",
    "        losses_non_clustered = [\n",
    "            non_clustered[client_type][partition][\"average_loss\"] for partition in partitions_non_clustered\n",
    "        ]\n",
    "        accuracies_non_clustered = [\n",
    "            non_clustered[client_type][partition][\"average_accuracy\"] for partition in partitions_non_clustered\n",
    "        ]\n",
    "\n",
    "        partitions_clustered = list(clustered[client_type].keys())\n",
    "        losses_clustered = [\n",
    "            clustered[client_type][partition][\"average_loss\"] for partition in partitions_clustered\n",
    "        ]\n",
    "        accuracies_clustered = [\n",
    "            clustered[client_type][partition][\"average_accuracy\"] for partition in partitions_clustered\n",
    "        ]\n",
    "\n",
    "        plt.figure(figsize=(14, 6))\n",
    "\n",
    " \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(partitions_non_clustered, losses_non_clustered, label=\"Non-Clustered\", marker=\"o\")\n",
    "        plt.plot(partitions_clustered, losses_clustered, label=\"Clustered\", marker=\"o\")\n",
    "        plt.xlabel(\"Number of Partitions\")\n",
    "        plt.ylabel(\"Average Loss\")\n",
    "        plt.title(f\"Average Loss per Partition ({client_type.capitalize()})\")\n",
    "        plt.legend()\n",
    "\n",
    " \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(partitions_non_clustered, accuracies_non_clustered, label=\"Non-Clustered\", marker=\"o\")\n",
    "        plt.plot(partitions_clustered, accuracies_clustered, label=\"Clustered\", marker=\"o\")\n",
    "        plt.xlabel(\"Number of Partitions\")\n",
    "        plt.ylabel(\"Average Accuracy (%)\")\n",
    "        plt.title(f\"Average Accuracy per Partition ({client_type.capitalize()})\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Plot averages for all client types\n",
    "plot_averages(non_clustered_averages, clustered_averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
