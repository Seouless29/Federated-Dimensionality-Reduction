{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "from abc import ABC, abstractmethod\n",
    "import time\n",
    "from sklearn.manifold import TSNE\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: torch.Size([60000, 28, 28]), Targets: torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "# Data Stuff\n",
    "# Set download to False if already downloaded\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# Load the MNIST dataset \n",
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=False, transform=transform)\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=False, transform=transform)\n",
    "\n",
    "print(f\"Data: {mnist_trainset.data.shape}, Targets: {mnist_trainset.targets.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Help Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def dirichlet_partition(dataset, num_partitions, num_classes, alpha=0.5, seed=42):\n",
    "    \"\"\"\n",
    "    Partition the dataset into multiple subsets using a Dirichlet distribution.\n",
    "\n",
    "    Args:\n",
    "        dataset (torch.utils.data.Dataset): The dataset to partition. It should have\n",
    "                                            'data' and 'targets' attributes.\n",
    "        num_partitions (int): Number of partitions (clients) to divide the dataset into.\n",
    "        num_classes (int): Number of unique classes in the dataset.\n",
    "        alpha (float): Dirichlet concentration parameter (controls imbalance).\n",
    "        seed (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are partition indices (0 to num_partitions-1)\n",
    "              and values are lists of indices corresponding to the samples in each partition.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Extract labels\n",
    "    if isinstance(dataset.targets, np.ndarray):\n",
    "        y_train = dataset.targets\n",
    "    elif hasattr(dataset.targets, \"numpy\"):  # For torch.Tensor\n",
    "        y_train = dataset.targets.numpy()\n",
    "    else:\n",
    "        y_train = np.asarray(dataset.targets)\n",
    "\n",
    "    min_size = 0\n",
    "    K = np.unique(y_train)\n",
    "    N = y_train.shape[0]  # Total number of samples\n",
    "    net_dataidx_map = {}\n",
    "\n",
    "    # Ensure minimum size of partition\n",
    "    while min_size < 10:\n",
    "        idx_batch = [[] for _ in range(num_partitions)]\n",
    "        for k in K:\n",
    "            idx_k = np.where(y_train == k)[0]\n",
    "            np.random.shuffle(idx_k)\n",
    "\n",
    "            if len(idx_k) > 0:\n",
    "                proportions = np.random.dirichlet(np.repeat(alpha, num_partitions))\n",
    "                proportions = np.array([p * (len(idx_j) < N / num_partitions) for p, idx_j in zip(proportions, idx_batch)])\n",
    "                proportions = proportions / proportions.sum()\n",
    "                proportions = (np.cumsum(proportions) * len(idx_k)).astype(int)[:-1]\n",
    "                idx_batch = [idx_j + idx.tolist() for idx_j, idx in zip(idx_batch, np.split(idx_k, proportions))]\n",
    "\n",
    "        min_size = min([len(idx_j) for idx_j in idx_batch])\n",
    "\n",
    "    for j in range(num_partitions):\n",
    "        np.random.shuffle(idx_batch[j])\n",
    "        net_dataidx_map[j] = idx_batch[j]\n",
    "\n",
    "    return net_dataidx_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mnist_trainset\n",
    "\n",
    "# Number of clients (participants in federated learning)\n",
    "num_clients = 10\n",
    "# Number of unique classes in MNIST\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 0: 5744 samples\n",
      "Client 1: 7794 samples\n",
      "Client 2: 4667 samples\n",
      "Client 3: 2937 samples\n",
      "Client 4: 7538 samples\n",
      "Client 5: 6137 samples\n",
      "Client 6: 6201 samples\n",
      "Client 7: 7199 samples\n",
      "Client 8: 5441 samples\n",
      "Client 9: 6342 samples\n"
     ]
    }
   ],
   "source": [
    "partitions = dirichlet_partition(dataset, num_partitions=num_clients, num_classes=num_classes, alpha=0.5, seed=42)\n",
    "\n",
    "# Check partitions\n",
    "x = 0\n",
    "for i, partition in partitions.items():\n",
    "    x = x + len(partition)\n",
    "    print(f\"Client {i}: {len(partition)} samples\")\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
