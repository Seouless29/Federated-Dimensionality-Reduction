{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset,TensorDataset\n",
    "from autoencoder import Autoencoder\n",
    "import torchvision\n",
    "from model2 import classification_model\n",
    "import copy\n",
    "import partition\n",
    "from pca import PCADigitReducer\n",
    "from autoencoder import reduce_dimensions\n",
    "from training import train,test, train_fashion,test_fashion\n",
    "from federated_learning import distribute_global_model, federated_averaging\n",
    "from model4 import MultilayerPerceptron\n",
    "import cluster2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x15f75d23e10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predefined stuff\n",
    "\n",
    "n_epochs = 5\n",
    "batch_size_train = 100\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.2860,), (0.3204,))  \n",
    "])\n",
    "\n",
    "fashion_mnist_train_loader = DataLoader(\n",
    "    datasets.FashionMNIST('/files/', train=True, download=True, transform=fashion_mnist_transform),\n",
    "    batch_size=batch_size_train, shuffle=True\n",
    ")\n",
    "\n",
    "fashion_mnist_test_loader = DataLoader(\n",
    "    datasets.FashionMNIST('/files/', train=False, download=True, transform=fashion_mnist_transform),\n",
    "    batch_size=batch_size_test, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_pca = copy.copy(fashion_mnist_train_loader)\n",
    "test_loader_pca = copy.copy(fashion_mnist_test_loader)\n",
    "\n",
    "train_loader_auto = copy.copy(fashion_mnist_train_loader)\n",
    "test_loader_auto = copy.copy(fashion_mnist_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTensorDataset(TensorDataset):\n",
    "    def __init__(self, *tensors):\n",
    "        super().__init__(*tensors)\n",
    "        self.data = tensors[0]\n",
    "        self.targets = tensors[1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "train_labels = []\n",
    "for data, labels in train_loader_pca:\n",
    "    train_data.append(data.view(data.size(0), -1))  \n",
    "    train_labels.append(labels)\n",
    "train_data = torch.cat(train_data, dim=0)  \n",
    "train_labels = torch.cat(train_labels, dim=0)\n",
    "\n",
    "train_data_np = train_data.numpy()\n",
    "\n",
    "pca = PCADigitReducer(100)\n",
    "train_data_reduced = pca.fit_transform(train_data_np)  \n",
    "\n",
    "train_data_reconstructed_np = pca.inverse_transform(train_data_reduced) \n",
    "train_data_reconstructed = torch.tensor(train_data_reconstructed_np, dtype=torch.float32)\n",
    "\n",
    "train_data_reconstructed = train_data_reconstructed.view(-1, 1, 28, 28)\n",
    "\n",
    "train_data_reconstructed = (train_data_reconstructed - 0.2860) / 0.3204\n",
    "\n",
    "batch_size_train = train_loader_pca.batch_size\n",
    "train_dataset_pca = CustomTensorDataset(train_data_reconstructed, train_labels)\n",
    "train_loader_reduced_pca = DataLoader(train_dataset_pca, batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.6598843336105347\n",
      "Epoch [2/5], Loss: 0.6293150186538696\n",
      "Epoch [3/5], Loss: 0.6253346800804138\n",
      "Epoch [4/5], Loss: 0.5940108895301819\n",
      "Epoch [5/5], Loss: 0.6230719089508057\n"
     ]
    }
   ],
   "source": [
    "# Autoencoder\n",
    "latent_dim = 100  \n",
    "autoencoder = Autoencoder(latent_dim=latent_dim)\n",
    "auto_criterion = nn.MSELoss()\n",
    "auto_optimizer = optim.Adam(autoencoder.parameters(), lr=1e-3)\n",
    "auto_num_epochs = 5\n",
    "for epoch in range(auto_num_epochs): \n",
    "    for images, _ in train_loader_auto:\n",
    "        auto_optimizer.zero_grad()\n",
    "        reconstructed = autoencoder(images)\n",
    "        loss = auto_criterion(reconstructed, images)  \n",
    "        loss.backward()\n",
    "        auto_optimizer.step()\n",
    "        \n",
    "    print(f\"Epoch [{epoch+1}/5], Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.eval()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "latent_features, labels = reduce_dimensions(train_loader_auto, autoencoder.encoder, device)\n",
    "latent_features = latent_features.detach()\n",
    "\n",
    "reconstructed_images = autoencoder.decoder(latent_features.to(device))  \n",
    "reconstructed_images = reconstructed_images.view(-1, 1, 28, 28)  # Reshape to [batch_size, channels, height, width]\n",
    "\n",
    "reconstructed_dataset = CustomTensorDataset(reconstructed_images.cpu(), labels)  \n",
    "reduced_train_loader_auto = DataLoader(reconstructed_dataset, batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.5\n",
    "num_clients = 10\n",
    "num_clusters = [2, 4, 6, 8, 10]\n",
    "results = {\"classic\": {}, \"pca\": {}, \"autoencoder\": {}}\n",
    "clusteredResults = {\"classic\": {}, \"pca\": {}, \"autoencoder\": {}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingset = fashion_mnist_train_loader.dataset\n",
    "trial_model_strong = MultilayerPerceptron()\n",
    "global_model_classic_strong = MultilayerPerceptron()\n",
    "rounds_classic = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.324810\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 2.199836\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.106051\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 1.900947\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 1.799925\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 1.511707\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 1.348910\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 1.207755\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 1.161974\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 1.016412\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.945645\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 0.906458\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.855002\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 0.901501\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 0.704619\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.864728\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.889839\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 0.847664\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 0.694646\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 0.868231\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.671750\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 0.718153\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.801688\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 0.750281\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.826234\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.652694\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.732019\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 0.561594\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.644146\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 0.717330\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.601688\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 0.570822\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.747713\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 0.715763\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.502512\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.482374\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.625540\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 0.787463\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.607936\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 0.512569\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.577560\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 0.650192\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.670712\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 0.612866\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.619173\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.451524\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.383784\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 0.637926\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.609271\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 0.377471\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.391996\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 0.463133\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.561105\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 0.615370\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.533281\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.442207\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.600018\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 0.539301\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.638416\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 0.475389\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.580414\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 0.604152\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.453871\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 0.430688\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.619274\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.322217\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.380576\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 0.553794\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.507959\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 0.359990\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.365472\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 0.397876\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.524049\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 0.434529\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.468780\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.409490\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.454093\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 0.364686\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.542348\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 0.418050\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.367089\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 0.350438\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.553736\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 0.471592\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.290673\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.434766\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.466006\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 0.535097\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.460422\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 0.535004\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.543002\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 0.580002\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.463393\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 0.433591\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.364949\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.406440\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.541399\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 0.446972\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.520156\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 0.477473\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.581453\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 0.351168\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.313059\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 0.495975\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.419968\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.475725\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.413279\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 0.341098\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.416840\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 0.412314\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.435924\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 0.377714\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.455753\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 0.423401\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.501808\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.440359\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.476109\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 0.396799\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.611509\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 0.403931\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.497481\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 0.467227\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.347432\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 0.389729\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.507918\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.332721\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.642288\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 0.430780\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.392851\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 0.595691\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.466406\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 0.565025\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.376547\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 0.458290\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.417238\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.553131\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.407008\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 0.447778\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.320819\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 0.528244\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.311235\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 0.490607\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.327020\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 0.571725\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.486682\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.555624\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.469706\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 0.389288\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.311727\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 0.519457\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.543178\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 0.453094\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.583476\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 0.340993\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.374385\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.556313\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.222718\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 0.550254\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.301898\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 0.408734\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.507644\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 0.317091\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.371015\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 0.406141\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.472255\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.521793\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.457967\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 0.391156\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.458224\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 0.307618\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.433541\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 0.376290\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.491311\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 0.445242\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.516759\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.425632\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.390125\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 0.366381\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.506984\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 0.358978\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.414562\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 0.402983\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.422749\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 0.415457\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.258842\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.434286\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.423274\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 0.263214\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.301198\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 0.292538\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.335005\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 0.394807\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.477822\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 0.466052\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.435278\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.446100\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.363528\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 0.472154\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.477539\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 0.600672\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.279875\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 0.360634\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.496553\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 0.367147\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.366720\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.421086\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.491356\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 0.381853\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.352628\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 0.331867\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.373716\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 0.387276\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.347098\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 0.489538\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.439314\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.532139\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.481524\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 0.442446\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.444384\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 0.269552\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.354932\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 0.298892\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.260256\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 0.276362\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.398393\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.352039\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.259183\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 0.525426\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.401250\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 0.477645\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.468421\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 0.284135\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.310752\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 0.307670\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.270601\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.250103\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.347866\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 0.330395\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.302646\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 0.402659\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.370342\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 0.377114\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.303851\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 0.409528\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.247290\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.205749\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.300834\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 0.312544\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.544163\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 0.526945\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.240526\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 0.334159\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.485901\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 0.369074\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.402577\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.456165\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.425216\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 0.200654\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.412832\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 0.354654\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.402368\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 0.316527\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.416587\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 0.327612\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.394811\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.390623\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.396238\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 0.310059\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.415494\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 0.451906\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.404993\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 0.402288\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.390684\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 0.239089\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.532247\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.175896\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.394671\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 0.409376\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.504530\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 0.563459\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.316211\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 0.305766\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.406966\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 0.467438\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.475642\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.439397\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.439275\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 0.402634\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.316285\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 0.364219\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.320714\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 0.395756\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.278752\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 0.255576\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.413563\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.375243\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.400292\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 0.302280\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.458834\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 0.349156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nazek\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.3693, Accuracy: 52129/60000 (87%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 2.299964\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 1.965513\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 1.761632\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 1.626960\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 1.439416\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 1.407890\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 1.182385\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 1.140931\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 1.201632\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 1.152443\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.998125\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.936935\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.898230\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.826114\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.799782\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 2.275290\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 1.398348\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.761844\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.674585\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.676503\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.461950\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.459736\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.462349\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.696034\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.596003\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.614313\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.409051\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.249700\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.292174\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.499196\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.360735\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.240726\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.521503\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.366211\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.383516\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.257836\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.285219\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.548449\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.282312\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.301259\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.339903\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.414902\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.289536\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.246642\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.265612\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.212258\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.225920\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.244165\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.306135\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.394684\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.368617\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.240623\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.217321\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.232956\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.316486\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 2.369808\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 2.030345\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 1.466695\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 1.398935\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 1.226941\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 1.107553\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.843775\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.765072\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.766130\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.558541\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.641982\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.597409\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.552327\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.574308\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.430154\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.580851\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.525088\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.442786\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.481498\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.403975\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.433460\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.403058\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.419480\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.335523\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.527671\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.351655\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.474864\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.440226\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.323967\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.480425\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.315250\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.535501\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.395841\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.389531\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.329687\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 2.276024\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 2.007636\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 1.557413\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.971036\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 1.014056\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.675844\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.818170\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.880008\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.843863\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.680270\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.784956\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.657017\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.689601\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.640535\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.716415\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.628267\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.736552\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.437988\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.449102\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.409525\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.740670\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.499797\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.466396\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.449932\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.351576\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.573050\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.482728\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.341812\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.386266\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.384329\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 2.303612\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 2.138145\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 1.892252\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 1.339401\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 1.121604\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.904829\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 1.027071\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.992140\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.822136\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.703001\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.656795\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.814918\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.735432\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.642084\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.523944\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.735959\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.541610\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.513826\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.511451\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.653534\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.573252\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.524286\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.548409\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.532048\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.464250\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.447805\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.507006\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.572138\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.393110\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.566283\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 2.395713\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 1.959599\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 1.344444\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 1.118764\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 1.195379\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.915081\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.900490\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 1.029496\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.983801\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.957140\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.796926\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.750971\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 1.014294\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.901529\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.740989\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.756563\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.726452\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.720567\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.648924\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.763315\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 2.329176\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 2.150025\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 1.872548\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 1.640645\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 1.413126\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 1.229187\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 1.155691\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 1.107895\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 1.128352\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.948795\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 1.032607\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.888716\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.761925\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.777249\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.870742\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.748382\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.699959\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.658110\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.755686\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.683609\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.681466\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.568520\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.682082\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.630153\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.685772\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.673126\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.519873\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.568349\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.544758\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.620142\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.561380\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.664152\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.468220\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.591212\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.536272\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.451003\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.545882\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.533235\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.563594\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.458270\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.566010\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.383022\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.455359\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.475255\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.549738\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.524580\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.424856\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.434934\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.401202\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.533903\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 2.289876\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 2.023820\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 1.735570\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 1.420755\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 1.128127\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.879375\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.967232\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.999307\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.937547\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.807997\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.587178\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.710263\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.671189\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.546164\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.447672\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.472617\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.473536\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.523949\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.476013\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.465181\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.362573\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.427180\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.386232\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.464888\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.362921\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.435745\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.475567\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.263629\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.387682\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.401845\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.365621\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.484039\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.319030\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.255537\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.331602\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 2.337782\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 2.194682\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 1.945706\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 1.667629\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 1.355484\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 1.213002\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 1.116568\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 1.062785\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 1.075311\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.838476\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.792915\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.816033\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.718152\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.547072\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.580434\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.736556\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.631549\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.438205\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.473807\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.441364\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.476207\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.604761\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.503927\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.620964\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.460635\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.575163\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.447550\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.661955\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.479392\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.415346\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.408098\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.368562\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.541437\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.514763\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.295013\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 2.296719\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 2.023898\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 1.715352\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 1.334254\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 1.255499\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.988259\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.764013\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.778780\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.699509\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.797383\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.525739\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.525706\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.787791\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.631168\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.580409\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.465787\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.699338\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.702837\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.797704\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.496464\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.511234\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.431470\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.382776\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.488818\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.366275\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.366921\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.364733\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.432115\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.327656\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.360283\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.331429\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.481587\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.326956\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.376317\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.380027\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.0434, Accuracy: 6569/10000 (66%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.933691\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.882700\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.727691\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.797599\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.573314\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.690912\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.625529\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.592948\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.503134\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.618765\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.568126\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.591227\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.540161\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.722387\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.520534\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 1.629729\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.312847\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.290433\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.361181\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.362999\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.212138\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.279373\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.226294\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.270614\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.385515\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.253243\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.388092\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.205497\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.237150\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.278736\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.153195\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.137488\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.119904\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.296528\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.141101\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.128603\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.250511\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.241917\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.222947\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.248614\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.183388\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.235937\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.148488\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.307711\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.168718\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.389597\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.166559\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.188859\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.112048\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.132214\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.185702\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.247981\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.180142\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.129314\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.138988\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.867586\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.578440\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.539387\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.462104\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.535083\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.409261\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.307140\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.404637\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.352840\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.398509\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.394129\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.345650\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.253151\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.297410\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.439207\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.286605\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.421838\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.289256\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.437054\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.323087\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.330422\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.331758\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.361614\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.297885\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.244713\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.272149\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.289401\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.317514\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.274732\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.132657\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.271602\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.304524\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.462328\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.321765\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.397731\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 1.290683\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.546146\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.462158\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.456790\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.468479\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.433367\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.380172\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.407288\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.362972\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.336521\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.414320\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.370599\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.439219\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.370320\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.320023\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.297327\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.418896\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.362418\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.268780\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.355576\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.295777\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.240465\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.481155\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.413262\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.437294\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.373761\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.325608\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.370073\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.227929\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.439585\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.931264\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.639178\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.598188\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.548920\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.489949\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.513635\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.475651\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.469027\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.494772\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.515957\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.505950\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.359381\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.461543\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.419049\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.406417\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.325892\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.309091\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.428327\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.456401\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.338761\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.359839\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.403079\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.365312\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.386652\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.324158\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.472696\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.347097\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.420061\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.310302\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.378255\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.970611\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.722912\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.770930\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.509817\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.617617\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.565340\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.582182\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.427240\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.736547\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.461842\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.568882\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.565133\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.447178\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.480061\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.558910\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.465902\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.403057\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.406608\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.585218\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.575502\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.970752\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.781135\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.686905\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.692044\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.704263\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.686366\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.739292\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.537683\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.636385\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.562211\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.500151\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.590835\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.711502\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.563235\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.436810\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.501096\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.488912\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.473636\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.429352\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.631536\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.464396\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.604074\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.520747\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.553747\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.676256\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.573757\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.421921\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.340503\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.302483\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.472299\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.450242\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.474845\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.522376\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.485518\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.420014\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.450138\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.428597\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.491458\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.414262\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.581457\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.374581\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.423449\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.320733\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.499977\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.445920\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.384569\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.425926\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.452445\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.514862\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.389117\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 1.284225\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.621039\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.472252\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.391955\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.572954\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.448233\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.393600\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.354595\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.344776\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.436388\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.227323\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.462247\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.356861\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.343234\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.297000\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.409081\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.331099\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.290443\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.224799\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.466674\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.324929\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.357577\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.268407\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.322034\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.258374\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.268653\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.246582\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.382808\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.370506\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.288243\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.283892\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.296155\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.375037\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.232423\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.241667\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.852979\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.696243\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.477646\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.585738\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.439472\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.416632\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.502103\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.528748\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.489076\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.460678\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.521672\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.403885\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.601633\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.456959\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.456938\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.586407\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.443190\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.373870\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.528682\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.533695\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.555703\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.399998\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.471643\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.387259\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.416983\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.402074\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.427250\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.425999\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.415459\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.376827\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.367656\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.378512\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.434998\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.379325\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.451733\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.974196\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.582569\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.508431\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.416958\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.524133\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.396934\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.309579\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.356004\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.338615\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.512009\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.520118\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.416396\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.339519\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.340996\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.474624\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.570453\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.408768\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.274947\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.443187\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.341795\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.411635\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.380885\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.411623\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.293017\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.297296\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.321750\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.538117\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.281545\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.309227\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.345422\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.285868\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.332382\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.326340\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.357803\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.267237\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.6397, Accuracy: 7511/10000 (75%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.829609\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.613968\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.552580\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.727515\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.580750\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.526795\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.544750\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.603869\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.508280\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.560355\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.601511\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.532390\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.495481\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.400640\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.565257\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.877077\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.214776\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.249320\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.161670\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.244082\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.230686\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.220375\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.134014\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.244042\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.116422\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.257095\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.146904\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.170696\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.133452\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.110984\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.095922\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.215595\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.102864\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.225057\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.108306\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.204862\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.262563\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.249866\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.218187\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.185446\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.177591\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.159130\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.193844\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.165635\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.150159\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.163519\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.090482\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.171505\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.202813\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.216027\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.150345\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.156838\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.161630\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.262352\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.090844\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.626443\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.255386\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.269003\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.356497\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.301284\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.308728\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.394301\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.262547\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.265262\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.275660\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.208009\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.411005\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.227523\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.388420\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.172507\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.155739\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.162037\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.357526\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.267642\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.332120\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.322717\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.270218\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.365772\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.352899\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.240396\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.378808\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.326855\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.251823\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.241942\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.296450\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.265549\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.244671\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.255670\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.350513\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.399943\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.584328\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.391799\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.396074\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.409784\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.481382\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.330437\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.337638\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.276040\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.306771\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.373559\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.336022\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.292294\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.311470\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.325396\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.398893\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.314290\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.439601\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.298553\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.271169\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.283484\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.251196\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.319900\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.219316\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.281160\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.229746\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.315973\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.315849\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.223914\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.344538\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.241986\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.567133\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.476156\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.444681\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.439883\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.488063\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.434945\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.349063\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.409952\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.389885\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.395348\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.413987\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.339655\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.483641\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.478729\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.305763\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.375208\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.392951\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.464677\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.374088\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.435225\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.369034\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.246011\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.458630\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.414356\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.251180\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.352627\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.296314\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.348449\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.423229\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.430778\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.556711\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.583184\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.531835\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.324664\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.404784\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.512870\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.377747\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.425766\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.366912\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.600615\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.383577\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.499361\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.502318\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.356248\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.464781\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.317933\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.461433\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.461345\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.370664\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.412125\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.589870\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.409752\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.513029\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.450753\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.737173\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.450712\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.474798\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.484651\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.452937\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.400475\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.463361\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.480642\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.574179\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.408058\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.628485\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.449434\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.574659\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.516099\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.395904\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.495863\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.445714\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.417390\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.510054\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.250879\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.502413\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.384211\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.459616\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.477342\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.335775\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.550165\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.403831\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.241462\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.478760\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.392985\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.468234\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.401147\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.516769\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.354321\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.458165\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.418455\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.271296\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.400413\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.392500\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.567196\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.453660\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.515247\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.358074\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.541700\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.399910\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.355103\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.688103\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.541286\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.378522\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.406319\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.372611\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.283088\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.223785\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.347898\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.317773\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.262134\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.244952\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.348479\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.293540\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.264579\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.254110\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.173942\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.308347\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.264199\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.234720\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.360954\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.284504\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.358127\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.399566\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.238028\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.234169\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.298193\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.270271\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.260144\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.283453\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.214141\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.304434\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.215075\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.267050\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.338083\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.140055\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.495937\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.396911\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.329679\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.484183\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.362943\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.493518\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.427476\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.297694\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.424501\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.381919\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.485670\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.349320\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.347413\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.434590\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.423533\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.453735\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.405623\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.328078\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.397647\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.283650\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.523325\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.470136\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.347221\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.214483\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.415149\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.311147\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.320804\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.288699\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.313590\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.466224\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.386571\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.380029\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.293695\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.256314\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.432154\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.425339\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.393647\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.342104\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.378024\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.365540\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.385626\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.308501\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.371239\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.386812\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.376313\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.354846\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.258778\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.232607\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.317677\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.199072\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.343455\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.294344\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.308824\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.295458\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.354592\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.280035\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.226592\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.376642\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.249716\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.241751\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.271853\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.350754\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.239858\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.236486\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.292401\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.438087\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.367186\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.194386\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.271506\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.264078\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.5520, Accuracy: 7906/10000 (79%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.770396\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.538846\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.532021\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.564960\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.369125\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.436189\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.525912\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.537494\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.550465\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.440023\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.358794\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.435929\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.421863\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.364420\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.500354\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.621259\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.144696\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.069856\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.205355\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.211341\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.258478\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.200665\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.142611\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.141098\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.128966\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.203571\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.225051\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.161235\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.194214\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.244108\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.127259\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.099746\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.155396\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.203954\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.092372\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.236365\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.098566\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.196130\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.140338\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.166317\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.070818\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.125585\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.143239\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.223478\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.228922\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.153674\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.118823\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.140231\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.116465\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.180524\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.184995\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.142440\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.119867\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.227206\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.153220\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.504440\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.374707\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.289421\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.256542\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.276816\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.187253\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.476535\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.338069\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.357218\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.342588\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.208650\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.375680\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.228174\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.184689\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.241685\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.236347\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.217747\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.351187\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.353029\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.201951\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.305562\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.243436\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.273937\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.214740\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.288398\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.231105\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.216146\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.246378\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.147455\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.322789\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.220623\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.246231\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.281875\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.246899\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.215019\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.532003\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.272638\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.281965\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.202732\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.270750\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.335333\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.290629\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.343783\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.279393\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.294497\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.271061\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.294323\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.306857\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.397630\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.166855\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.246670\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.273896\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.310968\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.115747\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.260237\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.324042\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.384523\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.332646\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.259792\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.342618\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.223703\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.228986\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.204262\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.213770\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.300903\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.387598\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.335311\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.283430\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.413013\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.225909\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.325118\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.355219\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.228493\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.362469\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.319706\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.426061\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.368942\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.275341\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.289349\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.291651\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.446658\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.339595\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.261437\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.293057\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.300376\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.217471\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.477142\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.334940\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.398857\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.338800\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.376489\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.247291\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.251571\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.357781\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.255618\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.650136\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.408746\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.445549\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.337283\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.285529\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.343473\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.340878\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.473487\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.335400\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.327347\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.426137\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.373546\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.498118\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.471817\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.328892\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.386195\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.430176\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.413839\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.322015\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.288639\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.445430\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.374386\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.552860\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.474996\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.369760\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.405080\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.437726\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.644584\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.513751\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.454675\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.433989\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.385801\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.512210\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.439168\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.387061\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.376216\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.364621\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.361015\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.365671\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.367789\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.426541\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.383608\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.549109\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.453614\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.394381\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.402552\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.448657\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.315020\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.368498\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.390910\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.442266\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.407031\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.484824\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.389598\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.314091\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.293538\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.434711\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.340253\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.338943\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.368165\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.461801\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.322172\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.487899\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.316265\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.451127\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.306112\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.435636\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.351558\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.302441\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.537402\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.595359\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.280691\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.301385\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.277002\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.138473\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.198677\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.381113\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.295602\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.406393\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.284450\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.249798\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.191890\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.227011\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.470164\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.258778\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.282071\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.197645\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.236169\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.202636\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.230025\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.264579\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.175022\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.231923\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.332256\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.126839\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.206787\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.175289\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.230224\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.296441\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.317260\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.172756\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.236035\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.251289\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.278564\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.273690\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.577941\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.351202\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.348640\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.305277\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.504677\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.556831\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.398457\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.270774\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.452123\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.266492\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.522382\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.515631\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.450276\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.369677\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.400339\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.298650\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.335170\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.321542\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.499647\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.298342\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.276892\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.338761\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.396665\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.291346\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.287766\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.322718\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.332420\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.310766\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.300321\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.230521\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.284047\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.381648\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.349682\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.298877\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.351613\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.508368\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.468720\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.257835\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.305144\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.326432\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.385192\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.231744\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.410202\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.163896\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.250876\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.264737\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.292994\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.228957\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.243778\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.286072\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.423565\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.291741\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.281753\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.277681\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.364022\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.267102\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.294857\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.276090\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.243466\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.250193\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.362154\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.233024\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.291380\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.259015\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.170938\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.179386\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.276682\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.204383\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.266314\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.289464\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.5189, Accuracy: 8019/10000 (80%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.500887\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.382019\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.506963\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.472528\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.444264\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.445974\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.281680\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.421118\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.731651\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.354857\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.526634\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.512289\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.446087\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.390719\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.397027\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.782461\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.124934\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.167510\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.086480\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.192565\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.204770\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.111615\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.291464\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.164645\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.165804\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.059237\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.166400\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.163343\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.168143\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.160641\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.169788\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.189885\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.126466\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.139904\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.145195\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.147171\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.063278\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.178506\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.216484\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.101447\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.295990\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.259834\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.188694\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.168266\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.075622\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.134908\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.283231\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.205466\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.218352\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.147736\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.149029\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.229377\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.153815\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.139313\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.158364\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.6112, Accuracy: 7731/10000 (77%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.614357\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.496701\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.425491\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.535602\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.421861\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.389646\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.408838\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.436568\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.522003\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.421794\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.404721\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.554487\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.483631\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.352350\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.528012\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.386595\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.131797\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.111246\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.214410\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.113373\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.200262\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.231649\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.080478\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.098424\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.175707\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.195056\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.119185\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.124090\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.120294\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.144899\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.136534\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.202028\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.173049\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.159886\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.100758\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.113611\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.131041\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.102879\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.078196\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.147023\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.181194\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.167130\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.224527\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.161991\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.203059\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.116782\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.151991\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.105620\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.149290\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.134030\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.272426\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.214077\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.162074\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.077788\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.096773\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.5730, Accuracy: 7864/10000 (79%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.624253\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.499638\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.550590\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.334442\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.545166\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.372112\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.451788\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.369594\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.477423\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.428514\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.357936\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.491442\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.346525\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.362484\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.437946\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.244472\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.078187\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.088968\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.233771\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.101091\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.145367\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.218302\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.072442\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.179085\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.141771\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.080048\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.196750\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.121847\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.222549\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.133291\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.308731\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.138916\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.194760\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.223569\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.094829\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.225608\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.237032\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.174875\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.228048\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.057670\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.091323\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.171288\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.144200\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.119116\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.163606\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.173614\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.110061\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.178387\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.103757\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.100403\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.085828\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.119362\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.104060\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.079446\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.111291\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.5779, Accuracy: 7881/10000 (79%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.683212\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.671036\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.410831\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.348703\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.447387\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.661891\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.434685\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.466190\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.429904\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.406374\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.379756\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.414889\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.364976\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.320585\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.434677\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.181635\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.136121\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.149845\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.159853\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.069619\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.141105\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.154282\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.128462\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.076737\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.139925\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.141992\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.117225\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.132530\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.098115\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.107580\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.242976\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.263903\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.139039\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.152340\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.171634\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.119664\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.081855\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.064000\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.176326\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.162891\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.185323\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.137117\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.216079\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.102458\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.168467\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.102472\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.134020\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.141526\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.162492\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.168190\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.158016\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.152064\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.130374\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.107543\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.213654\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.5886, Accuracy: 7837/10000 (78%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.635427\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.297943\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.363168\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.424107\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.508273\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.412679\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.303762\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.372378\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.315812\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.307681\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.261730\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.344901\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.505364\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.285066\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.319029\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.185448\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.112201\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.139400\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.110546\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.149438\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.118067\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.193295\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.203956\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.083576\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.114850\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.139585\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.077901\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.162906\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.117265\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.118425\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.128436\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.132563\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.114408\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.134647\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.138620\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.100742\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.261215\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.114436\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.135033\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.098407\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.066182\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.206225\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.087803\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.150016\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.097564\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.156903\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.172362\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.063822\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.199944\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.101916\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.072405\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.134267\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.090493\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.150498\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.109640\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.601104\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.347108\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.242246\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.198308\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.293034\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.311556\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.224989\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.181611\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.173691\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.148853\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.190890\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.100036\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.280913\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.169637\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.202268\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.215391\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.234928\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.132492\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.297615\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.289332\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.112116\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.223493\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.309186\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.145888\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.183321\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.196719\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.261234\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.285536\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.142629\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.145738\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.103762\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.224763\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.252186\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.301533\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.202909\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.503623\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.300807\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.281297\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.214223\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.192967\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.407741\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.230467\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.367456\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.239478\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.307805\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.205958\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.165321\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.311219\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.325032\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.172502\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.235648\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.176205\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.182343\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.279089\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.197372\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.192454\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.265871\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.263939\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.262198\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.209570\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.307050\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.253070\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.158076\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.165762\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.269207\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.5569, Accuracy: 7938/10000 (79%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.535249\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.363459\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.280533\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.412716\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.385137\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.454393\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.469453\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.464122\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.320780\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.350330\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.376677\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.466685\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.247958\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.465331\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.244056\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.438387\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.076885\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.113917\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.067979\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.177258\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.092665\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.059617\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.065587\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.090944\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.181671\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.158177\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.133373\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.122648\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.255046\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.060923\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.062866\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.156158\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.084214\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.114308\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.079204\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.107296\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.111024\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.128690\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.090721\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.079450\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.103122\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.115767\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.191515\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.071742\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.191846\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.149667\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.121023\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.081109\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.098521\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.121166\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.116658\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.040319\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.080182\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.141609\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.100303\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.503312\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.182795\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.188394\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.238868\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.148185\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.183523\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.174069\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.186698\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.254026\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.203837\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.192910\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.159450\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.236698\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.243066\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.192494\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.255779\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.205642\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.112615\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.294606\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.171679\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.072909\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.299889\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.208791\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.264165\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.293437\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.319115\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.335967\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.194799\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.120401\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.107691\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.175999\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.184016\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.114783\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.177519\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.140684\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.460975\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.347011\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.289450\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.267044\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.225596\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.176782\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.293542\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.178565\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.272758\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.274970\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.298777\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.196192\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.275188\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.280949\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.304023\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.219854\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.374187\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.230531\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.196500\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.155056\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.248525\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.303627\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.240118\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.242875\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.220731\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.162999\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.286947\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.281156\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.243171\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.145168\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.5165, Accuracy: 8076/10000 (81%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.500653\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.417742\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.332087\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.374935\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.473843\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.362813\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.434873\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.321883\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.328021\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.218007\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.281050\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.340429\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.413754\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.357719\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.267018\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.318202\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.134593\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.141500\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.142878\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.189235\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.194052\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.097093\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.108893\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.086972\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.091154\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.177358\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.217228\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.127598\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.069668\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.105421\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.131714\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.109699\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.096035\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.112159\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.070953\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.273622\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.115681\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.212647\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.125566\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.107189\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.141750\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.137069\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.169362\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.060627\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.074571\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.106716\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.111731\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.188653\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.047254\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.107568\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.102347\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.099026\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.096406\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.124560\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.049381\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.389136\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.187134\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.154161\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.267033\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.220269\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.317749\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.223560\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.264924\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.285972\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.166042\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.229503\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.155776\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.118279\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.178390\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.217917\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.204170\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.223960\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.247390\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.205531\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.177305\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.131635\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.198247\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.181512\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.115364\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.257028\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.237110\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.272352\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.093589\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.157085\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.112376\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.229001\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.148486\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.124481\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.171456\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.159221\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.330629\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.221338\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.230849\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.237320\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.213541\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.210318\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.309655\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.218798\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.147425\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.183883\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.269716\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.341232\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.239656\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.280907\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.136354\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.257181\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.110523\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.188775\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.149611\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.188641\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.242823\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.231033\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.202188\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.134539\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.221307\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.291647\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.250815\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.180084\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.168635\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.155179\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.5320, Accuracy: 8022/10000 (80%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.316697\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.310045\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.419449\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.451377\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.300747\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.350556\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.470199\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.491921\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.363394\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.179636\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.322899\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.289020\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.515457\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.348669\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.323217\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.364842\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.118267\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.093210\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.087781\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.094262\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.178166\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.198301\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.198629\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.092509\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.170471\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.104077\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.102522\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.078423\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.219212\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.193351\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.120347\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.147621\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.146258\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.139654\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.107337\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.074259\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.248437\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.118902\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.170692\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.202215\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.098695\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.173548\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.184857\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.069430\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.135562\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.141307\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.112681\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.068501\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.132119\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.077374\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.115595\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.078189\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.140495\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.084583\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.205088\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.355026\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.191428\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.143065\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.227046\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.184002\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.134973\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.074343\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.237506\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.130421\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.207484\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.336352\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.244260\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.202283\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.176850\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.160535\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.131894\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.085575\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.280859\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.130303\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.183016\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.199729\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.174654\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.118757\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.298307\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.248032\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.127934\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.137724\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.112693\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.189222\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.125995\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.224242\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.142676\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.114054\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.174132\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.152726\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.478359\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.252192\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.236251\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.242801\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.267997\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.210377\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.241073\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.331425\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.124023\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.183002\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.245603\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.135982\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.199300\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.249021\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.181597\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.164644\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.181092\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.271757\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.128855\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.169968\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.240545\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.147068\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.249958\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.216718\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.215323\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.120912\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.186755\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.252357\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.162803\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.210484\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.5280, Accuracy: 8034/10000 (80%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.480296\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.370291\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.341335\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.202191\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.388373\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.448406\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.233708\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.302684\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.474986\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.247980\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.259690\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.411826\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.416101\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.212972\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.384769\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.341472\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.139380\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.170782\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.168333\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.145355\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.149341\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.089870\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.103078\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.091406\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.127923\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.085936\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.141809\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.118475\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.099757\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.231298\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.125682\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.102293\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.132697\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.092372\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.097975\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.159654\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.062537\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.057210\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.154912\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.115247\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.190843\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.096387\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.100933\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.069469\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.047023\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.046399\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.168081\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.046805\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.121991\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.096560\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.144742\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.129576\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.128837\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.065453\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.279841\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.380377\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.149143\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.220355\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.176919\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.188311\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.321970\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.253738\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.215750\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.403892\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.117919\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.179154\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.197505\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.070891\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.168596\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.185582\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.197964\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.133721\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.183956\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.317524\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.162326\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.207018\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.166006\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.161973\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.079752\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.126727\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.221085\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.136873\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.187966\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.112948\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.229183\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.307179\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.264429\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.171017\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.164476\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.099604\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.397008\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.206716\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.242763\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.190290\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.297277\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.226381\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.266816\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.222213\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.245478\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.210272\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.179516\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.109804\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.282205\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.261310\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.168201\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.295089\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.256532\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.210933\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.176585\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.160852\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.183685\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.315859\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.188690\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.190408\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.225827\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.220166\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.279833\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.182970\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.272901\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.251163\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.676845\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.274072\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.396108\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.285357\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.390682\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.182967\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.345863\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.305360\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.358987\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.366989\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.251339\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.176183\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.269082\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.293832\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.492651\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.305795\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.324966\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.289890\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.334142\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.200644\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.294549\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.234962\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.249181\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.301361\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.277292\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.353486\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.241124\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.308706\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.248544\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.235997\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.668325\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.381778\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.422946\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.330520\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.317740\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.362590\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.293546\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.384323\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.325765\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.304014\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.256209\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.336075\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.309697\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.340362\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.411967\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.211396\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.352014\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.237506\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.296017\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.278630\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4633, Accuracy: 8279/10000 (83%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.313426\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.377956\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.433854\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.439377\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.288384\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.260827\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.326926\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.367038\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.436077\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.355846\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.288097\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.400062\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.297141\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.444593\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.417293\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.462580\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.252053\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.084165\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.181746\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.166242\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.124471\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.193024\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.076051\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.172570\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.165023\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.058501\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.122276\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.116911\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.115223\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.066678\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.151694\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.130563\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.138109\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.144277\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.150945\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.052383\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.212493\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.105638\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.210374\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.034665\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.162486\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.177305\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.096032\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.067311\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.122407\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.134052\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.145249\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.137833\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.053686\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.102218\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.068178\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.055474\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.164800\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.036612\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.086414\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.248445\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.183571\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.236735\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.176470\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.156673\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.170420\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.217810\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.208690\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.171675\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.256969\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.173581\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.159612\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.182227\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.203606\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.247513\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.192815\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.182920\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.207010\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.147963\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.167696\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.344988\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.147964\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.161751\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.258140\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.182209\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.158808\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.156319\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.174077\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.164362\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.129444\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.102248\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.114742\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.206824\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.210942\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.275856\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.402337\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.372490\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.229639\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.150695\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.177259\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.226852\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.183766\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.269160\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.223977\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.142295\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.286215\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.125249\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.197790\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.267808\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.184793\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.205147\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.308998\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.208099\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.168256\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.337830\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.401770\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.166256\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.319550\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.149931\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.193189\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.193545\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.078623\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.171661\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.117353\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.190290\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.356937\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.353040\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.213214\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.434648\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.419162\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.221595\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.206352\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.251128\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.393094\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.313731\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.285284\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.305148\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.287636\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.224038\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.225711\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.334950\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.274415\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.311905\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.330519\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.363862\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.192529\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.308922\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.217059\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.390683\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.368219\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.218192\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.317768\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.265980\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.231223\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.300557\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.453811\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.320144\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.336049\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.429674\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.186715\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.279220\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.320423\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.330088\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.323980\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.208957\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.299283\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.336754\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.259389\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.240175\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.339536\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.313369\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.193696\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.149861\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.391522\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.223915\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4645, Accuracy: 8260/10000 (83%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.465519\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.284680\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.387725\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.377923\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.339463\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.328807\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.232083\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.252383\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.297347\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.257904\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.442151\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.266212\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.464739\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.340273\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.292117\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.610128\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.092431\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.087446\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.160718\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.161555\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.135659\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.070340\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.183124\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.201034\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.118628\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.090943\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.109537\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.069644\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.135046\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.252120\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.093088\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.130366\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.182314\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.244705\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.108918\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.067560\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.087555\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.132075\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.079243\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.126544\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.115586\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.125635\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.051412\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.164609\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.085356\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.106465\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.063624\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.026062\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.175544\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.096097\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.092657\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.107864\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.031515\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.068693\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.191126\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.390227\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.098234\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.206133\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.240454\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.236581\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.071747\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.217939\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.170164\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.167633\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.239075\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.129090\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.174715\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.091528\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.138441\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.240676\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.237286\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.265940\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.182578\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.144414\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.139528\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.110570\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.147876\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.129965\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.136248\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.154091\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.147267\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.097203\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.173845\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.073858\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.164832\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.179480\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.193333\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.199472\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.115780\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.189245\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.245195\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.292318\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.195475\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.187069\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.168525\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.163106\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.193552\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.166830\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.300238\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.154611\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.131156\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.203013\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.171245\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.178078\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.181838\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.215385\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.076900\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.266324\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.218077\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.222200\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.256103\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.111430\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.342359\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.241406\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.183560\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.244693\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.161837\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.161398\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.206354\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.181883\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.329196\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.289000\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.269634\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.282959\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.203360\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.343534\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.141024\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.478367\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.227100\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.216175\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.230901\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.265021\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.255071\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.188158\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.296216\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.341270\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.326699\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.196826\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.289286\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.257543\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.236822\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.168207\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.325645\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.265769\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.302720\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.306634\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.247049\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.218291\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.245684\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.161884\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.341858\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.320187\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.370208\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.313560\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.274234\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.253134\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.228716\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.366644\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.327696\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.322291\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.295561\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.342444\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.252451\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.212343\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.395217\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.395105\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.394796\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.297576\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.152874\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.283852\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4653, Accuracy: 8267/10000 (83%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.301158\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.346530\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.359624\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.334856\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.361796\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.353143\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.330088\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.419450\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.240356\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.463127\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.275776\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.392002\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.330308\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.323163\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.280493\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.435316\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.136965\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.173631\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.057712\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.090933\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.160195\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.167796\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.112604\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.142054\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.267021\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.087914\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.062786\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.092354\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.047291\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.119297\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.216399\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.066853\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.111694\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.254017\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.048328\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.130438\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.076901\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.056887\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.100846\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.086789\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.033695\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.063067\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.069524\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.116832\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.154853\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.146866\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.111468\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.075651\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.094869\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.158888\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.037162\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.136099\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.139861\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.121079\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.053735\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.305856\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.194776\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.179371\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.113019\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.180371\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.162150\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.167281\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.171290\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.235158\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.143703\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.252334\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.151072\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.163403\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.268016\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.204613\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.138932\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.170845\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.194104\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.119494\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.165003\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.138114\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.178856\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.127451\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.095485\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.150605\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.113556\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.205251\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.219078\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.127373\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.124030\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.170989\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.095615\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.194816\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.104300\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.124260\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.529208\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.161000\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.218588\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.128547\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.159386\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.212184\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.216593\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.190245\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.247505\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.121890\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.163965\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.137269\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.104155\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.114812\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.234975\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.251284\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.152165\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.216952\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.169476\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.230376\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.196052\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.164652\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.251467\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.151082\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.196571\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.154006\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.147927\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.249077\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.158714\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.252031\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.447678\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.389153\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.478643\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.318129\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.306162\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.360198\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.334020\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.197084\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.384445\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.287907\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.227417\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.215822\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.376383\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.290380\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.198151\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.260488\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.173615\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.162003\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.264838\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.283554\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.284736\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.211419\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.262749\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.286691\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.355068\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.321031\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.252845\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.190155\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.337745\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.213747\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.443454\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.330688\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.237016\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.290297\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.367371\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.222188\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.354357\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.491090\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.305587\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.396866\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.206703\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.397701\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.311782\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.265509\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.230379\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.335479\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.278613\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.269577\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.274405\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.227032\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4457, Accuracy: 8338/10000 (83%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.439488\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.394133\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.323807\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.274360\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.298755\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.338351\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.445281\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.238894\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.369115\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.247024\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.381667\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.262393\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.327939\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.332423\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.275603\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.380541\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.074177\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.113199\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.200506\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.086675\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.098490\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.122597\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.115974\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.111583\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.071316\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.179275\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.052632\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.055235\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.135853\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.113396\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.112774\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.067710\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.147082\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.050861\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.082823\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.161960\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.164155\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.089519\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.072622\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.152212\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.090953\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.085445\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.101530\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.058766\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.088110\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.102670\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.154813\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.085795\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.117424\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.097731\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.107778\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.074069\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.048166\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.133591\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.087837\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.402609\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.238885\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.168251\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.125900\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.131197\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.113855\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.257813\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.171846\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.093651\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.158814\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.200104\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.143793\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.184360\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.164171\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.245224\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.138776\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.061300\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.129076\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.148634\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.252025\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.167038\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.189095\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.176721\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.126105\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.065685\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.200650\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.153481\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.103291\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.072402\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.141795\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.169986\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.124068\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.109491\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.218039\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.101144\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.282995\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.100764\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.214394\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.175689\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.245028\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.169841\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.145503\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.172581\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.258976\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.196607\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.206970\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.133947\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.177770\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.177523\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.189255\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.268234\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.238402\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.122428\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.220003\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.164792\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.146701\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.227280\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.216047\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.105462\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.210506\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.185086\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.166979\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.215341\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.141179\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.145747\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.448295\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.249598\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.476208\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.248312\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.228297\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.255802\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.272716\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.237595\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.284694\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.189721\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.353618\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.320830\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.194358\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.209226\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.370060\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.338807\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.217559\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.189926\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.209729\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.245129\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.171261\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.275899\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.244991\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.197318\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.251304\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.329848\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.120887\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.258641\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.180878\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.313248\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.428076\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.235301\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.270045\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.314400\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.238950\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.366104\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.268074\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.263234\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.212474\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.292374\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.331140\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.275094\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.222919\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.160134\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.398868\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.257040\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.263258\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.233526\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.337690\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.210231\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.546273\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.270326\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.316426\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.283797\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.361059\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.407858\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.284666\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.216411\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.276529\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.550731\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.294631\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.485200\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.344340\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.233092\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.257008\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.403940\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.301431\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.348728\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.399516\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.337731\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.251262\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.385928\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.319407\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.423660\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.357746\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.322975\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.269967\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.298674\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.271091\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.292546\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.333531\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.260746\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.363934\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.159949\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.423121\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.230378\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.305471\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.339463\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.312779\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.229776\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.435758\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.295043\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.212635\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.254968\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.378882\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.246290\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.352076\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.443674\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.262046\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.285436\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.516221\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.277762\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.433942\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.257728\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.242455\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.112095\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.265293\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.233416\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.197868\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.227322\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.209450\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.201811\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.112594\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.168474\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.284295\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.207601\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.281308\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.181599\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.209165\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.248345\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.182300\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.124836\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.182023\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.184563\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.393641\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.217027\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.166699\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.152040\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.228816\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.270225\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.149510\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.145622\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.171464\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.276845\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.352466\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4280, Accuracy: 8437/10000 (84%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.449816\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.535491\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.364424\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.446337\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.363936\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.293811\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.355939\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.235938\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.402319\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.379435\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.474570\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.267377\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.454380\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.229320\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.302477\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.225566\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.300426\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.152115\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.088727\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.085718\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.047184\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.174625\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.202991\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.088217\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.047169\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.031645\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.134508\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.109646\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.073338\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.120395\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.052781\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.133223\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.138022\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.131175\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.070953\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.101667\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.115194\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.105701\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.207721\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.066434\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.055128\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.088664\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.129434\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.094469\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.127973\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.055044\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.061049\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.116923\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.131657\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.084350\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.095432\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.165688\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.137591\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.040036\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.156660\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.222894\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.062312\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.121521\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.211360\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.161291\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.233297\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.067284\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.229023\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.204286\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.167643\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.184016\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.150835\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.165815\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.197172\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.177177\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.124537\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.267792\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.175591\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.160627\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.136878\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.216341\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.106674\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.154854\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.130612\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.206086\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.136780\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.084988\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.254116\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.122084\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.093688\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.159194\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.118489\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.154745\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.150955\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.179223\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.353624\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.309577\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.158668\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.170484\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.141171\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.223124\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.152062\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.206137\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.181623\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.167988\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.150454\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.109205\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.253933\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.184717\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.219792\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.224449\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.276889\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.107432\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.127753\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.192482\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.111100\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.242365\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.193971\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.158249\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.246650\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.141939\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.188796\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.223793\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.132329\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.197588\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.341802\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.259813\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.354301\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.215790\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.313867\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.204550\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.122877\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.239477\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.219275\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.200539\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.210392\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.286286\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.160120\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.333899\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.267033\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.217868\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.230626\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.255229\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.118423\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.250435\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.290985\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.235493\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.167033\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.400648\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.196857\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.253929\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.381078\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.158984\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.332348\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.212057\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.335237\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.439253\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.221639\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.302298\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.217410\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.324866\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.291378\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.349574\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.253632\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.239253\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.331290\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.264455\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.209553\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.261513\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.371308\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.164985\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.388101\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.258368\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.288216\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.162839\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.325081\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.205396\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.348545\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.341452\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.388571\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.388096\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.402811\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.425253\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.395993\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.332349\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.361285\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.239412\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.339696\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.312579\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.175593\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.194173\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.320047\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.371881\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.473968\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.499561\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.357144\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.368912\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.290088\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.208057\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.428087\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.475484\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.338398\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.362988\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.336388\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.324702\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.270949\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.411575\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.273769\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.378643\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.312456\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.242507\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.444081\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.286691\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.264265\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.219111\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.284898\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.270561\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.424625\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.296074\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.267684\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.251573\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.334347\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.237630\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.239400\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.225432\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.501166\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.211736\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.239532\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.304718\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.333653\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.254898\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.082909\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.222165\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.128273\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.179133\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.167742\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.185251\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.147888\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.238577\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.148814\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.103868\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.206114\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.135680\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.176457\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.234174\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.160890\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.141412\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.267346\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.221011\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.328245\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.105949\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.256102\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.105942\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.198236\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.229997\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.124852\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.138927\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.101058\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.200607\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.183959\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4304, Accuracy: 8418/10000 (84%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.509774\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.408769\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.326538\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.384699\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.289908\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.307496\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.343029\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.317717\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.271968\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.396832\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.283031\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.270048\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.320551\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.355712\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.209182\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.421618\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.132065\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.174381\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.101809\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.209508\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.108124\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.095608\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.163012\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.105774\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.220821\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.120439\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.155948\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.221808\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.146292\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.088858\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.094981\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.083229\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.089294\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.119524\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.144571\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.170598\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.084721\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.039555\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.060015\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.093680\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.149583\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.132029\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.190369\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.070972\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.159601\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.133805\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.082344\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.074670\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.083580\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.143734\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.073498\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.169554\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.126269\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.214271\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.083494\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.226422\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.301716\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.165398\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.142951\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.136736\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.119124\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.162435\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.164628\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.169553\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.152155\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.204782\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.145661\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.144790\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.116377\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.186240\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.150487\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.191218\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.248126\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.227726\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.127422\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.126142\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.169937\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.183578\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.116841\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.149583\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.182512\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.111065\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.075451\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.134593\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.107665\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.108904\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.099824\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.064942\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.112873\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.148458\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.437701\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.210965\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.106981\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.228263\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.143041\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.154804\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.258173\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.137008\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.244326\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.171075\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.287871\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.144231\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.190742\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.149424\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.167557\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.153575\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.116506\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.268956\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.133483\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.195066\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.237998\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.243144\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.132926\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.187208\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.240441\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.085774\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.158928\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.194073\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.260497\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.185079\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.274237\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.176862\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.280558\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.212067\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.169040\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.291654\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.280885\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.322976\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.383591\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.287307\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.142998\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.276045\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.248933\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.308125\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.185763\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.162072\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.302305\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.238472\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.188637\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.202250\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.247202\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.368198\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.271018\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.286635\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.269515\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.110271\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.321524\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.162679\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.326067\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.172672\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.383849\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.252042\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.287120\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.353105\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.301740\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.187237\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.322618\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.136667\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.290091\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.303671\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.311815\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.272723\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.226853\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.370702\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.215177\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.198354\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.232574\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.230685\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.257182\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.218447\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.493722\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.379336\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.373594\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.347313\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.397937\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.466038\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.348244\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.299375\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.413687\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.345539\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.238872\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.244306\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.315119\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.320967\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.232003\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.353386\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.338239\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.265790\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.369880\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.493199\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.344028\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.293072\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.379888\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.300580\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.334170\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.472048\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.317791\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.276863\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.190891\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.300636\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.306495\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.331406\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.343955\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.332971\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.241247\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.421024\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.377012\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.454268\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.402852\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.389093\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.190745\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.221748\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.448711\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.256056\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.215448\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.344926\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.240904\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.265505\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.323541\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.326500\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.466124\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.244786\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.247594\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.231194\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.105352\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.242283\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.363579\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.241128\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.350783\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.178828\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.215182\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.140921\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.194150\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.193848\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.096748\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.193075\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.214946\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.173796\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.169206\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.157530\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.184911\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.265809\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.245684\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.292753\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.122950\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.282575\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.311996\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.257342\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.243895\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.141361\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.225947\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.218705\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.135591\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.241753\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.205544\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4187, Accuracy: 8451/10000 (85%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.394975\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.351484\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.350288\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.314036\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.356287\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.355446\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.245600\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.278646\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.263010\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.289008\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.303709\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.334778\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.311602\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.241008\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.366137\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.384072\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.120468\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.096351\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.102422\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.152843\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.122949\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.063217\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.098376\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.166263\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.125466\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.098151\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.210909\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.113942\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.098304\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.072665\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.105500\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.101612\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.110016\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.133412\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.047716\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.061761\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.331761\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.141252\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.078711\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.200506\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.109661\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.065364\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.040520\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.175826\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.084921\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.064465\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.071186\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.081237\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.062698\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.087457\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.071689\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.120506\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.131936\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.059456\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.078833\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.255350\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.153657\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.161781\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.162278\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.103265\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.130723\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.198827\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.144993\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.195002\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.069039\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.102819\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.103998\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.159999\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.116462\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.104198\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.241030\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.281363\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.143213\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.179670\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.141633\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.261535\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.163676\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.124491\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.157793\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.107250\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.147466\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.177518\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.167975\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.179179\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.188274\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.081704\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.123455\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.051407\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.188354\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.220947\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.373945\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.197416\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.117467\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.204086\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.134934\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.128630\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.180709\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.178828\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.204866\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.204865\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.192458\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.336077\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.170568\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.161393\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.158624\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.157860\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.194436\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.082019\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.224602\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.153757\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.102462\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.197819\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.106625\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.144720\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.137402\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.270498\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.201050\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.087591\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.171424\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.175467\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.380377\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.193854\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.329817\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.318155\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.131330\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.376493\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.256065\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.209562\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.239619\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.303535\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.248002\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.200953\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.283431\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.274092\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.192800\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.248339\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.160173\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.272151\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.437426\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.272129\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.212732\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.181824\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.200003\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.256799\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.185793\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.229562\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.273273\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.174681\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.209659\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.230660\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.323343\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.303708\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.170368\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.233367\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.267712\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.288378\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.196266\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.355669\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.222490\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.389749\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.249880\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.311246\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.235971\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.310277\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.360868\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.275044\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.177525\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.292679\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.215483\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.310086\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.280205\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.269674\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.399991\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.332907\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.471556\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.327160\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.280262\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.257396\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.217466\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.293266\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.308103\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.222476\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.307647\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.367186\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.407704\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.273917\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.365750\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.225719\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.265280\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.414609\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.283398\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.276026\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.344714\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.317861\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.345878\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.224384\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.362606\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.412104\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.369222\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.390708\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.275350\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.305981\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.233026\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.268541\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.302939\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.227515\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.308596\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.198859\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.335352\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.221295\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.417778\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.292751\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.267842\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.420103\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.272425\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.297842\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.260935\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.268357\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.385502\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.228800\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.416335\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.161483\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.215190\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.157403\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.296668\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.243784\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.138880\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.121290\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.158049\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.138184\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.141919\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.170149\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.147185\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.119407\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.300448\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.078963\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.285208\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.093543\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.196145\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.191382\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.123965\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.309944\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.098082\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.217126\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.192745\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.142953\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.254623\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.291857\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.276522\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.169363\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.385575\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.126809\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.131555\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.160967\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.266976\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4129, Accuracy: 8512/10000 (85%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.375273\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.216217\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.300408\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.401906\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.344527\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.355000\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.252813\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.270180\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.283094\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.281114\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.366120\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.406946\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.289071\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.237947\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.394845\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.403660\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.039613\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.057862\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.140688\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.227221\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.061751\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.108519\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.076531\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.064883\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.142907\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.115207\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.070758\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.081155\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.097807\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.142061\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.134734\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.077593\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.107302\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.061172\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.105573\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.072295\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.123584\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.100626\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.123746\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.122585\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.127838\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.095940\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.103130\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.145732\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.073234\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.088869\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.063908\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.061237\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.095478\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.059261\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.081771\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.028503\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.079255\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.149288\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.033608\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.260394\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.176086\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.121409\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.096314\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.148213\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.166171\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.163831\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.108048\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.197647\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.125061\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.128394\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.205528\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.195371\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.180286\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.167488\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.207576\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.101126\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.173475\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.163799\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.131793\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.294282\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.144550\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.115480\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.094361\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.158791\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.208049\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.234121\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.133201\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.143032\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.120491\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.096883\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.150784\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.243862\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.156822\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.149671\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.274209\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.145350\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.279261\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.127693\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.267881\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.233331\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.189304\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.198858\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.222644\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.207339\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.115172\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.175022\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.157949\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.197068\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.166565\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.250327\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.177169\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.275834\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.280904\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.139330\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.168491\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.166243\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.142595\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.138923\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.110964\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.262107\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.222513\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.076484\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.165108\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.119224\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.339904\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.253423\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.343849\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.087500\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.241586\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.266636\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.344393\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.283680\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.172822\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.243913\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.225844\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.316237\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.220761\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.344830\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.261464\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.204745\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.243806\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.307930\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.198056\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.228065\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.232130\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.188932\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.220412\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.261135\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.156838\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.324377\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.245389\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.234372\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.181873\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.267095\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.325007\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.348668\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.227319\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.285515\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.234964\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.328486\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.228910\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.496319\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.225344\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.182211\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.235950\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.336697\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.265277\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.320366\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.349402\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.243839\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.253861\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.183536\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.252712\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.189497\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.417535\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.222301\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.248412\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.306822\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.237921\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.257765\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.548745\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.379957\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.318726\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.264625\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.468987\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.309684\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.269191\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.309622\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.326329\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.336465\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.225924\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.390424\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.353079\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.275835\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.272440\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.303875\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.301186\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.362685\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.274206\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.292015\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.280785\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.312649\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.329613\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.352130\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.312929\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.234960\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.380977\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.240192\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.247428\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.394477\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.256888\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.460528\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.272937\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.230389\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.310049\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.207001\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.283837\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.315699\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.271453\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.268417\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.277556\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.266034\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.167090\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.286502\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.475802\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.055464\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.228400\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.246145\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.093613\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.208596\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.215891\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.307884\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.211871\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.160201\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.197733\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.222398\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.173476\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.340038\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.188358\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.127712\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.258006\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.147573\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.175625\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.120521\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.172740\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.272080\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.103985\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.261088\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.166147\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.169471\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.125096\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.198269\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.232527\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.081231\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.160310\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.268830\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.187467\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.103714\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.167061\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.395338\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.418160\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.257732\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.182552\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.552691\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.263562\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.243744\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.232041\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.245275\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.209341\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.259619\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.398465\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.229167\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.167612\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.263795\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.192087\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.292960\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.314796\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.212532\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.259431\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.328355\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.209991\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.209216\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.262997\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.301999\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.316995\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.214546\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.251117\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.242222\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.308223\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.209031\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.419693\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.315505\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.324907\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.271946\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.360968\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.303659\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.191570\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.220086\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.180798\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.264925\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.343936\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.186845\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.171431\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.420788\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.134599\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.221988\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.104247\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.182949\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.201176\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.133795\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.205780\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.217759\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.159883\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.280947\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.208376\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.183285\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.151700\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.185774\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.195532\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.247300\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.158134\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.244990\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.128497\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.126114\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.338492\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.184999\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.310859\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.251372\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.210229\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4158, Accuracy: 8490/10000 (85%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.418002\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.337875\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.337506\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.239235\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.362800\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.400231\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.208260\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.296860\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.349176\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.372782\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.283956\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.223619\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.521721\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.210856\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.246639\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.411436\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.129119\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.070177\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.146128\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.133508\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.218738\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.072416\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.097503\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.109287\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.110487\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.065214\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.144508\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.105685\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.078742\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.088861\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.080560\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.098110\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.133664\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.119969\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.070524\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.138133\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.129531\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.095134\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.177369\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.096989\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.167357\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.053063\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.147432\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.036745\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.098194\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.096253\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.090853\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.014745\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.033778\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.083421\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.113663\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.129417\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.080997\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.172212\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.078923\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.312296\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.173799\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.235757\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.152544\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.187366\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.204778\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.217539\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.261244\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.108392\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.246933\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.177643\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.104938\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.077216\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.071061\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.095222\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.111602\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.145799\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.062793\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.154044\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.102565\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.219996\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.102029\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.109916\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.129836\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.180686\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.161512\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.062027\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.123578\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.160000\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.073232\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.131268\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.097637\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.157858\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.116402\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.181711\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.323583\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.176661\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.210773\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.240804\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.202911\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.177528\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.222382\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.173965\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.197694\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.149157\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.209521\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.163975\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.297490\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.223810\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.173459\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.117052\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.128514\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.270574\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.175038\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.291236\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.157509\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.157733\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.117414\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.175725\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.101515\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.142132\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.149651\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.171895\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.063464\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.136210\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.149881\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.190351\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.209792\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.226776\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.252802\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.194885\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.266812\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.311218\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.167397\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.318180\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.198925\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.247152\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.239685\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.177707\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.250063\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.146388\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.326795\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.201897\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.227288\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.206479\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.232272\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.207160\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.171246\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.218210\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.229294\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.194843\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.290320\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.189856\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.191589\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.161382\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.248508\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.365011\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.320883\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.351769\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.198170\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.231161\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.268949\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.232685\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.225015\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.272278\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.289015\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.162868\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.304669\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.258030\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.283584\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.307563\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.254028\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.146807\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.219379\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.278374\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.361245\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.234166\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.152131\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.323506\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.386943\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.330875\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.240369\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.290184\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.214840\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.329439\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.264360\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.241169\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.205177\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.354986\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.275992\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.266571\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.369615\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.343918\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.405149\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.455640\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.327112\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.291802\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.209076\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.209473\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.196146\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.233799\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.298534\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.242408\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.412265\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.206427\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.297772\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.375039\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.390482\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.198260\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.337919\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.235769\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.127476\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.268183\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.338129\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.390484\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.210065\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.320735\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.231841\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.280095\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.270634\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.290917\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.205912\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.253096\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.233343\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.149124\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.534285\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.130803\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.119820\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.159551\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.224213\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.284135\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.229739\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.252105\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.123784\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.270317\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.104891\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.216691\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.192474\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.101213\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.226488\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.311200\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.145224\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.103642\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.198924\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.161069\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.157881\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.190127\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.185907\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.155443\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.258323\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.252685\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.248074\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.136072\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.123629\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.305530\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.148071\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.160896\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.148990\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.140709\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.151347\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.320188\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.115115\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.352276\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.219593\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.287524\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.370244\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.297750\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.266093\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.207849\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.295321\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.239751\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.240337\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.321508\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.318711\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.354608\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.308077\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.310473\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.221806\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.138192\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.219055\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.206299\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.296909\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.159779\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.152798\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.213801\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.220990\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.105032\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.180043\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.154037\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.248653\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.220003\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.267072\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.235068\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.279580\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.278989\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.319333\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.214042\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.213881\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.215115\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.158751\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.287678\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.174772\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.327299\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.237436\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.246984\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.237732\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.193119\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.186815\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.127730\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.194230\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.215414\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.166274\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.124898\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.139076\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.220398\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.254056\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.162657\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.269530\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.220683\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.216727\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.116166\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.215095\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.108948\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.161547\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.131353\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.158294\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.213149\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.193738\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.137835\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.208965\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4128, Accuracy: 8482/10000 (85%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.282811\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.403103\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.321206\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.394571\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.266444\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.403252\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.235670\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.285423\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.290858\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.217089\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.369661\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.279292\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.355397\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.222198\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.270075\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.343793\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.189663\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.150233\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.130408\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.102034\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.098362\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.105492\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.059753\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.098385\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.124275\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.079080\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.118519\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.084672\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.100550\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.188014\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.215057\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.132314\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.066236\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.130201\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.091815\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.075090\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.124918\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.197370\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.091346\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.063078\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.134817\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.059947\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.095836\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.060998\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.168050\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.018331\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.103536\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.105222\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.084290\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.065353\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.070366\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.074767\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.158515\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.129063\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.040355\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.408164\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.111114\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.160132\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.146833\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.162477\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.139978\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.169158\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.254060\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.144205\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.097441\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.113652\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.143300\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.154909\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.132743\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.172524\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.119789\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.097079\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.145302\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.199568\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.159065\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.150109\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.102920\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.184894\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.173159\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.149474\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.156736\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.179896\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.120552\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.209463\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.263287\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.095746\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.214545\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.151540\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.173182\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.105402\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.340379\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.261780\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.221503\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.254238\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.161396\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.281675\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.221176\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.203036\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.158690\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.196810\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.212784\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.239588\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.234510\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.178770\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.167985\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.111035\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.145902\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.241591\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.194636\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.220765\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.149725\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.117585\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.160280\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.177904\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.089720\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.187041\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.089357\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.118688\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.146928\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.137936\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.321280\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.257029\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.217186\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.231428\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.324425\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.302832\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.119946\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.162308\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.359800\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.283238\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.196535\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.285613\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.211817\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.348135\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.238524\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.190998\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.208012\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.092215\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.154601\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.161179\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.144153\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.156948\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.222354\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.257301\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.224360\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.240218\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.179187\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.246772\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.125622\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.253934\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.474112\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.282808\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.212018\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.314097\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.282395\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.301535\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.254042\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.149195\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.261354\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.225913\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.259374\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.308680\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.355739\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.251538\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.144032\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.241929\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.273079\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.237004\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.188824\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.284157\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.393611\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.305861\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.336727\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.313143\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.229171\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.296688\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.307239\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.244859\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.279457\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.413043\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.321200\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.317750\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.294158\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.397996\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.197782\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.311617\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.356344\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.373738\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.212755\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.287881\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.406326\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.288302\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.221213\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.375213\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.246585\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.352074\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.245548\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.303227\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.231676\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.430391\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.357200\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.271210\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.230310\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.246633\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.287619\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.182854\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.264068\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.265818\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.375870\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.268077\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.332413\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.311569\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.324521\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.353240\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.243556\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.314399\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.290154\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.480684\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.240034\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.323106\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.409355\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.185642\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.183204\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.134696\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.217422\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.195086\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.274616\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.154136\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.182387\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.220367\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.233260\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.239293\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.226338\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.129257\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.232421\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.410176\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.137326\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.248803\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.128504\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.174845\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.171680\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.074600\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.125367\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.272051\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.392870\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.132291\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.237245\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.248235\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.173013\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.198421\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.243954\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.278441\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.159620\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.144301\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.151102\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.226005\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.250920\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.146074\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.175664\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.327060\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.307115\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.291411\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.196595\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.239786\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.225464\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.384599\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.171341\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.252063\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.221110\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.322292\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.322798\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.254337\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.236928\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.359477\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.303144\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.149103\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.223861\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.258712\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.277171\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.148339\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.209406\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.212005\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.282701\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.233596\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.230604\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.217180\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.264945\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.324098\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.203426\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.229524\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.298492\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.188276\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.276826\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.239937\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.122218\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.166809\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.131913\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.184219\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.363128\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.123665\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.223998\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.175648\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.131184\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.190200\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.153483\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.084558\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.281174\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.131732\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.148409\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.243755\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.255855\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.159981\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.214582\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.175344\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.104407\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.193671\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.194009\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.204424\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.237793\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.204555\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.271747\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.117185\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.146137\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.194532\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.193036\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.4013, Accuracy: 8530/10000 (85%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.454498\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.225588\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.288940\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.351143\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.233926\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.326130\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.262692\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.246087\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.334186\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.301434\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.243666\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.291594\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.250101\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.254062\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.173934\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.398482\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.160887\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.066681\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.100729\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.156359\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.065247\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.134495\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.184004\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.214539\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.310248\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.151742\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.085135\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.116380\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.178120\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.145262\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.055929\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.116756\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.106736\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.093246\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.082226\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.220865\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.173126\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.119129\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.196633\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.051195\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.149981\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.145741\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.145429\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.086266\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.046011\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.101237\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.046917\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.035813\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.116167\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.086283\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.084416\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.042602\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.089752\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.086439\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.054556\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.286463\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.194787\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.179265\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.197877\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.135720\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.110180\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.170845\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.117930\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.083670\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.108338\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.174083\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.149387\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.083733\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.113254\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.145980\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.082516\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.194709\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.113879\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.111601\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.093719\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.143230\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.148569\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.098987\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.148346\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.079712\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.224457\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.100672\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.099235\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.091064\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.149489\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.172815\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.130115\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.182762\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.088317\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.120621\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.319827\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.131107\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.168384\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.272215\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.136222\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.103476\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.163906\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.198586\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.153156\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.205048\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.169147\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.234110\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.186898\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.205730\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.173147\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.175437\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.118919\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.173740\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.173672\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.142781\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.129913\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.186554\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.198078\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.141085\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.224053\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.106698\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.106010\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.183145\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.125232\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.123095\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.295832\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.179381\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.215182\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.312478\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.273885\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.288971\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.255186\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.311077\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.231891\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.271934\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.188375\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.333172\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.110453\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.223401\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.225668\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.148040\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.217116\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.224252\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.277635\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.223718\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.089813\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.265226\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.353937\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.286428\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.421492\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.243914\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.256848\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.177149\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.264070\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.135405\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.343938\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.203852\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.179720\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.297122\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.224606\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.279544\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.187774\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.293329\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.333276\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.261968\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.236883\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.298431\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.271177\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.264177\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.282235\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.193592\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.126720\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.207445\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.173612\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.201943\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.327820\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.239147\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.337392\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.336939\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.239271\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.458260\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.307811\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.391511\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.326036\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.390427\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.248065\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.259030\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.313429\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.298497\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.306256\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.242081\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.287215\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.331549\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.291349\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.317035\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.221704\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.310295\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.336571\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.286466\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.389270\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.375718\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.371574\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.316590\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.201757\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.337174\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.243496\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.314627\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.217839\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.445937\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.223831\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.285977\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.181215\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.181755\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.256792\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.264333\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.316089\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.276293\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.301665\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.308858\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.280283\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.354151\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.179262\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.301789\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.252298\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.261441\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.520222\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.176359\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.183384\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.269423\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.203893\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.196737\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.209202\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.212241\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.196384\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.135710\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.173673\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.196931\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.235570\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.115173\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.137668\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.246868\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.176971\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.200443\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.111956\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.243132\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.209527\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.150690\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.147734\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.198746\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.210552\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.176502\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.129591\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.264045\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.128860\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.139455\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.169296\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.099895\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.225237\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.144744\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.233582\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.282186\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.266545\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.250626\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.228749\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.208460\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.390347\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.280593\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.354472\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.189308\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.302019\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.252376\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.251082\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.223583\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.250469\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.211544\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.295627\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.133130\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.370543\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.235715\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.174099\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.238309\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.242755\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.237544\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.216655\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.305382\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.300908\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.184011\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.187377\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.185803\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.160516\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.164260\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.175691\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.224971\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.136697\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.125729\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.286979\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.202497\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.145297\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.128994\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.222944\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.222859\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.227031\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.224310\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.126954\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.121137\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.147998\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.147456\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.134943\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.133094\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.234742\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.175593\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.175318\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.088905\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.092582\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.233617\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.136943\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.216787\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.266014\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.128957\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.109843\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.196959\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.210590\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.149957\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.204734\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.159361\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.156573\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.186506\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.153009\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.089702\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.163358\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.3945, Accuracy: 8584/10000 (86%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "partitioned_data_classic = partition.balanced_dirichlet_partition(\n",
    "    trainingset, partitions_number=num_clients, alpha=alpha)\n",
    "\n",
    "classic_client_loaders = [\n",
    "    DataLoader(Subset(trainingset, indices), batch_size=batch_size_train, shuffle=True)\n",
    "    for indices in partitioned_data_classic.values()\n",
    "]\n",
    "\n",
    "local_models_classic_strong = [copy.deepcopy(global_model_classic_strong) for _ in range(num_clients)]\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(trial_model_strong.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):  \n",
    "    train_fashion(epoch, trial_model_strong, fashion_mnist_train_loader, optimizer, log_interval, train_losses, train_counter)\n",
    "\n",
    "\n",
    "\n",
    "test_losses_classic_strong = []\n",
    "test_fashion(trial_model_strong,fashion_mnist_train_loader,test_losses_classic_strong)\n",
    "\n",
    "\n",
    "for round_idx in range(rounds_classic):\n",
    "    \n",
    "    print(f\"Round {round_idx + 1}/{rounds_classic}\")\n",
    "\n",
    "    local_weights_classic = []\n",
    "    for client_idx, client_model in enumerate(local_models_classic_strong):\n",
    "        print(f\"Training client {client_idx + 1}\")\n",
    "        \n",
    "        optimizer = optim.SGD(client_model.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "\n",
    "        train_losses = []\n",
    "        train_counter = []\n",
    "\n",
    "        for epoch in range(1, n_epochs + 1):  \n",
    "            train_fashion(epoch, client_model, classic_client_loaders[client_idx], optimizer, log_interval, train_losses, train_counter)\n",
    "        \n",
    "        client_weights = [param.data.numpy() for param in client_model.parameters()]\n",
    "        local_weights_classic.append(client_weights)\n",
    "        \n",
    "\n",
    "    global_weights_classic = federated_averaging(local_weights_classic)\n",
    "\n",
    "\n",
    "    distribute_global_model(global_weights_classic,local_models_classic_strong,single=False)\n",
    "\n",
    "    distribute_global_model(global_weights_classic,global_model_classic_strong,single=True)\n",
    "    test_losses = []\n",
    "    test_fashion(global_model_classic_strong,fashion_mnist_test_loader,test_losses)\n",
    "\n",
    "    test_accuracies_classic = []\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in fashion_mnist_test_loader:\n",
    "            data = data.view(data.shape[0], -1)\n",
    "            output = global_model_classic_strong(data)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "    accuracy = 100. * correct / len(fashion_mnist_test_loader.dataset)\n",
    "    test_accuracies_classic.append(accuracy)\n",
    "\n",
    "    results[\"classic\"][\"NoCluster\"] = {\"losses\": [], \"accuracy\": []}\n",
    "\n",
    "    results[\"classic\"][\"NoCluster\"][\"losses\"].extend(test_losses)\n",
    "    results[\"classic\"][\"NoCluster\"][\"accuracy\"].extend(test_accuracies_classic)\n",
    "\n",
    "    ######################\n",
    "for num_cluster in num_clusters:\n",
    "    import cluster2\n",
    "\n",
    "    targets = trainingset.targets\n",
    "    num_classes = len(set(targets)) \n",
    "    # Erstelle Clients\n",
    "    clients = [cluster2.FederatedClient(cid, indices, targets, num_classes) for cid, indices in partitioned_data_classic.items()]\n",
    "    \n",
    "    # Jeder Client berechnet seine Labelverteilung\n",
    "    client_distributions = [client.compute_label_distribution() for client in clients]\n",
    "    \n",
    "    # Server fhrt Clustering durch\n",
    "    server = cluster2.FederatedClusterServer(num_cluster)\n",
    "    aggregated_data = server.aggregate_client_data(client_distributions)\n",
    "    clustered_data = server.perform_greedy_clustering(aggregated_data, partitioned_data_classic)\n",
    "    \n",
    "    partitioned_data_classic_clustered = clustered_data\n",
    "\n",
    "    \"\"\"\n",
    "    import cluster\n",
    "    cluster = cluster.Cluster(num_clusters=num_cluster)\n",
    "    \n",
    "    targets = trainingset.targets\n",
    "    num_classes = len(set(targets)) \n",
    "    clustered_data = cluster.apply_clustering(partitioned_data_classic, targets, num_classes)\n",
    "    \n",
    "    partitioned_data_classic_clustered = clustered_data\n",
    "    \"\"\"\n",
    "\n",
    "    classic_client_loaders_clustered = [\n",
    "        DataLoader(Subset(trainingset, indices), batch_size=batch_size_train, shuffle=True)\n",
    "        for indices in partitioned_data_classic_clustered.values()\n",
    "    ]\n",
    "\n",
    "    for round_idx in range(rounds_classic):\n",
    "        print(f\"Round {round_idx + 1}/{rounds_classic}\")\n",
    "\n",
    "        local_weights_classic = []\n",
    "        for client_idx, client_model in enumerate(local_models_classic_strong[0:num_cluster]):\n",
    "            print(f\"Training client {client_idx + 1}\")\n",
    "            \n",
    "            optimizer = optim.SGD(client_model.parameters(), lr=learning_rate,\n",
    "                          momentum=momentum)\n",
    "    \n",
    "            train_losses = []\n",
    "            train_counter = []\n",
    "    \n",
    "            for epoch in range(1, n_epochs + 1):  \n",
    "                train_fashion(epoch, client_model, classic_client_loaders[client_idx], optimizer, log_interval, train_losses, train_counter)\n",
    "            \n",
    "            client_weights = [param.data.numpy() for param in client_model.parameters()]\n",
    "            local_weights_classic.append(client_weights)\n",
    "            \n",
    "    \n",
    "        global_weights_classic = federated_averaging(local_weights_classic)\n",
    "    \n",
    "    \n",
    "        distribute_global_model(global_weights_classic,local_models_classic_strong,single=False)\n",
    "    \n",
    "        distribute_global_model(global_weights_classic,global_model_classic_strong,single=True)\n",
    "        test_losses = []\n",
    "        test_fashion(global_model_classic_strong,fashion_mnist_test_loader,test_losses)\n",
    "\n",
    "        test_accuracies_classic = []\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in fashion_mnist_test_loader:\n",
    "                data = data.view(data.shape[0], -1)\n",
    "                output = global_model_classic_strong(data)\n",
    "                pred = output.data.max(1, keepdim=True)[1]\n",
    "                correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "        accuracy = 100. * correct / len(fashion_mnist_test_loader.dataset)\n",
    "        test_accuracies_classic.append(accuracy)\n",
    "\n",
    "        if num_cluster not in clusteredResults[\"classic\"]:\n",
    "            clusteredResults[\"classic\"][num_cluster] = {\"losses\": [], \"accuracy\": []}\n",
    "\n",
    "        clusteredResults[\"classic\"][num_cluster][\"losses\"].extend(test_losses)\n",
    "        clusteredResults[\"classic\"][num_cluster][\"accuracy\"].extend(test_accuracies_classic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results (Non-Clustered): {'classic': {'NoCluster': {'losses': [0.5188619812011719], 'accuracy': [80.19]}}, 'pca': {}, 'autoencoder': {}}\n",
      "Final Results (Clustered): {'classic': {2: {'losses': [0.6111913330078125, 0.5729868041992188, 0.5778576416015625, 0.5886122863769532], 'accuracy': [77.31, 78.64, 78.81, 78.37]}, 4: {'losses': [0.5569269927978515, 0.5164715148925781, 0.5319765411376953, 0.5280328765869141], 'accuracy': [79.38, 80.76, 80.22, 80.34]}, 6: {'losses': [0.4632906616210937, 0.4644641296386719, 0.4652772644042969, 0.44572009887695313], 'accuracy': [82.79, 82.6, 82.67, 83.38]}, 8: {'losses': [0.4280053955078125, 0.4304277587890625, 0.41870563354492185, 0.41287210998535157], 'accuracy': [84.37, 84.18, 84.51, 85.12]}, 10: {'losses': [0.4158003601074219, 0.4127583312988281, 0.4012933013916016, 0.39449208984375], 'accuracy': [84.9, 84.82, 85.3, 85.84]}}, 'pca': {}, 'autoencoder': {}}\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Results (Non-Clustered):\", results)\n",
    "print(\"Final Results (Clustered):\", clusteredResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingset_pca = train_loader_reduced_pca.dataset\n",
    "trial_model_pca_strong = MultilayerPerceptron()\n",
    "global_model_pca_strong = MultilayerPerceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.347369\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 1.495971\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 1.185859\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 0.798364\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 0.868576\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 0.632974\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 0.759118\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 0.740417\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.730175\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 0.577776\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.735130\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 0.685180\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.540653\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 0.565609\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 0.515572\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.474472\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.649605\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 0.730648\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 0.700656\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 0.560809\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.425099\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 0.680923\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.566303\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 0.446334\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.416799\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.565155\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.440945\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 0.328573\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.471937\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 0.592069\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.352098\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 0.466636\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.570936\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 0.643500\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.456451\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.439278\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.356675\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 0.357730\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.444555\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 0.536701\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.499887\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 0.471420\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.473473\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 0.462589\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.631542\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.555536\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.623300\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 0.396236\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.511858\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 0.474225\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.549596\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 0.413720\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.443460\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 0.469282\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.446156\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.396244\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.393387\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 0.446338\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.528635\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 0.546735\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.404908\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 0.460654\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.403651\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 0.473501\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.484168\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.451608\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.487608\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 0.604758\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.456264\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 0.334451\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.527584\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 0.378228\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.361981\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 0.426305\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.330668\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.363656\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.447537\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 0.326822\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.395568\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 0.483992\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.400351\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 0.475721\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.529785\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 0.329447\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.566234\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.454617\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.391051\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 0.523471\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.380759\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 0.342632\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.383335\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 0.366239\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.393101\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 0.311873\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.469916\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.374085\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.437741\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 0.490133\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.335967\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 0.440282\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.321946\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 0.424373\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.388832\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 0.400748\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.391986\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.467645\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.440387\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 0.363349\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.248269\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 0.465158\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.308534\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 0.283463\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.359885\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 0.468645\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.348133\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.410273\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.366799\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 0.505339\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.439369\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 0.511762\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.359077\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 0.278238\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.380187\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 0.396015\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.288920\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.416071\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.326221\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 0.511240\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.304542\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 0.379305\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.339356\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 0.437996\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.361107\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 0.313723\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.363636\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.457461\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.403854\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 0.308219\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.355416\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 0.441068\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.238368\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 0.405003\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.445152\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 0.368415\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.330892\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.306420\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.368857\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 0.426343\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.482071\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 0.291532\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.355292\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 0.284572\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.303771\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 0.410745\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.275150\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.338861\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.317784\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 0.430884\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.387943\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 0.384321\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.426181\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 0.340385\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.327669\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 0.406054\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.344857\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.266280\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.276197\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 0.439447\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.391587\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 0.363428\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.215288\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 0.391577\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.434053\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 0.421964\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.412471\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.275321\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.263516\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 0.435746\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.327517\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 0.346439\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.361027\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 0.299624\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.454261\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 0.336729\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.399050\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.411334\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.351593\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 0.309445\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.360073\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 0.331426\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.397475\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 0.339517\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.325723\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 0.351546\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.302817\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.295347\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.436388\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 0.366408\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.414261\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 0.279491\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.357996\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 0.340872\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.292786\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 0.350949\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.266138\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.307935\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.429692\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 0.285224\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.328537\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 0.457832\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.411896\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 0.207711\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.381187\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 0.316364\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.192715\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.437226\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.389444\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 0.312128\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.366759\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 0.449461\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.280962\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 0.356514\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.253429\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 0.385714\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.281311\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.266645\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.286916\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 0.299671\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.196487\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 0.208532\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.220864\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 0.206477\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.343685\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 0.299353\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.293422\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.363425\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.273475\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 0.431231\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.397074\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 0.381463\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.341472\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 0.294907\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.282435\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 0.300781\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.453663\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.359099\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.434683\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 0.297846\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.381601\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 0.557186\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.462376\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 0.349463\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.509111\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 0.320412\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.445212\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.286784\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.369835\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 0.423875\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.326117\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 0.467319\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.376744\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 0.335825\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.244117\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 0.383765\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.310421\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.386899\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.313384\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 0.476572\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.382485\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 0.290806\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.391166\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 0.244277\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.377992\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 0.387529\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.310487\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.276281\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.502211\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 0.434194\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.584966\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 0.441960\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.330952\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 0.341755\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.327697\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 0.353616\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.328105\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.359296\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.303355\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 0.401181\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.207206\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 0.274584\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.265106\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 0.457427\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.232887\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 0.284241\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.239178\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.368805\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.281262\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 0.361075\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.337874\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 0.329147\n",
      "\n",
      "Test set: Avg. loss: 0.3295, Accuracy: 52782/60000 (88%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 2.381326\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 1.077912\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.877727\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.932932\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.782629\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.909592\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.692556\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.638080\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.517382\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.593708\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.547530\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.642761\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.476542\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.613112\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.549820\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 2.487200\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.558960\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.536518\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.352780\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.280192\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.309962\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.348050\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.349540\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.251992\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.189899\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.322004\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.228113\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.179320\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.140390\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.293985\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.300395\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.147700\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.263562\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.229675\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.246677\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.285504\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.290046\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.179087\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.221978\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.213085\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.157650\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.209140\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.235950\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.214280\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.218278\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.262177\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.162917\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.136128\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.255897\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.163062\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.304807\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.239806\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.160950\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.181547\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.151004\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 2.230870\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 1.150246\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.649627\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.540074\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.506900\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.476994\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.316339\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.397043\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.335187\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.331124\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.377095\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.399325\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.339086\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.296829\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.153203\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.399452\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.405606\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.264805\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.281364\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.301914\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.291436\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.326687\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.484161\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.283210\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.300450\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.346369\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.304932\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.256215\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.186513\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.290501\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.203502\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.247770\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.205833\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.185135\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.234921\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 2.308238\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.907714\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.637238\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.666603\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.644354\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.572519\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.546059\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.560119\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.461324\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.500103\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.492550\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.307025\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.326596\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.480566\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.432611\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.283040\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.369268\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.486615\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.427142\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.325455\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.271923\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.358547\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.221753\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.455414\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.248070\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.321959\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.473162\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.358223\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.299310\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.335270\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 2.265306\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 1.041763\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.864416\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.683903\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.725226\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.716935\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.634867\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.425364\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.490810\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.493861\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.423397\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.464752\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.436670\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.526963\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.383403\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.477097\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.537397\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.482189\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.535703\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.351016\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.571750\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.365595\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.330966\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.451043\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.540340\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.323831\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.394242\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.307672\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.281276\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.391953\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 2.316231\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 1.254110\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.651869\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.733089\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.788779\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.633550\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.587147\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.568121\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.493339\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.618538\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.527836\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.494694\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.600336\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.472941\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.351758\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.562543\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.515706\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.465745\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.487641\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.365073\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 2.347615\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 1.448807\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 1.135712\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.822369\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.830149\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.482611\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.636525\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.567390\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.609029\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.636830\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.678876\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.551155\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.605015\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.500768\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.633915\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.442062\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.450226\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.520659\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.503224\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.508078\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.703260\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.582975\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.428968\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.655918\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.485768\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.311766\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.545125\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.500484\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.594185\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.394712\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.569045\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.393892\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.255128\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.470973\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.318284\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.527597\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.299239\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.347915\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.541091\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.349121\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.604208\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.462221\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.368661\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.418252\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.501740\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.409883\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.521936\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.369264\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.420262\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.313599\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 2.446167\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.962108\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.858712\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.621528\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.503254\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.491932\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.492377\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.395131\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.281623\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.331906\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.368682\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.320422\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.476091\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.375334\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.327027\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.285735\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.345624\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.294123\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.310093\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.344266\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.345753\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.349910\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.454717\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.318916\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.227942\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.295761\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.233611\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.415445\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.213031\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.177359\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.196440\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.260141\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.403294\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.299628\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.221758\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 2.214909\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 1.346492\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.957995\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.682353\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.776192\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.652460\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.588520\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.524580\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.458353\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.718275\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.448688\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.431257\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.455913\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.414467\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.391370\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.392968\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.541885\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.431092\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.383777\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.381293\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.340450\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.285031\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.512228\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.249884\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.258884\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.558486\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.452002\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.278751\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.301088\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.434359\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.282787\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.460778\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.321264\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.325454\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.499047\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 2.487745\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 1.180995\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.832844\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.772320\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.637999\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.668513\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.364746\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.371286\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.605190\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.522415\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.295039\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.349930\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.394995\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.366579\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.458697\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.324033\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.382491\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.297909\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.358599\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.392686\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.477635\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.182985\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.297811\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.237805\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.297982\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.306653\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.253241\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.271481\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.228373\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.301019\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.353890\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.439657\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.265371\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.432970\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.264906\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.3699, Accuracy: 7560/10000 (76%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.830126\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.498169\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.665464\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.463463\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.574781\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.531242\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.500242\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.621230\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.424230\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.451761\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.459245\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.468099\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.425394\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.599538\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.402099\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.658132\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.157784\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.171918\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.140421\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.283670\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.193743\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.209113\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.201122\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.167145\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.213622\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.129154\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.131629\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.117226\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.205115\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.125694\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.221473\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.218852\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.077178\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.195900\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.246829\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.119206\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.142507\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.167384\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.156841\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.119614\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.108002\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.070802\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.186795\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.154180\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.175524\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.176690\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.192444\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.134683\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.173610\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.134197\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.187108\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.095875\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.131117\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.235619\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.108510\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.492182\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.295098\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.307176\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.574549\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.229212\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.328881\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.347392\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.254773\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.263534\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.183178\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.242660\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.145841\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.301931\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.192161\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.308487\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.264344\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.322610\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.152997\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.386466\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.178487\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.194713\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.270561\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.232685\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.200645\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.332416\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.270870\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.147383\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.285311\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.176960\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.219211\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.220799\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.121667\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.281313\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.318075\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.224887\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.681369\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.415630\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.523251\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.411493\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.458265\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.408304\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.440212\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.346979\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.334675\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.407825\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.176051\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.330764\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.401940\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.237428\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.401339\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.284051\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.246034\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.270688\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.280016\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.334166\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.441997\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.377479\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.220403\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.361031\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.212324\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.197200\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.400706\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.379312\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.304007\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.236631\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.563828\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.427689\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.330986\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.297203\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.473128\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.353685\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.666838\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.317083\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.351386\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.350507\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.239983\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.389660\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.354346\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.308937\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.220781\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.411984\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.223382\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.291589\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.671708\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.295892\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.404570\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.240214\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.294472\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.267266\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.290923\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.384672\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.338374\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.190596\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.284904\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.357782\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.588331\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.332924\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.482657\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.424668\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.563714\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.403869\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.407879\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.415929\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.322809\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.282851\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.375592\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.383968\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.360651\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.284463\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.369337\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.361206\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.308062\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.311711\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.296408\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.368764\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.623183\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.519911\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.477358\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.436862\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.510378\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.500598\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.448692\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.420343\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.392807\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.566523\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.478823\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.374388\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.357060\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.376465\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.294837\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.366027\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.406944\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.386793\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.357785\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.385135\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.514172\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.407576\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.484907\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.391626\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.426040\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.400004\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.430537\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.349618\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.417648\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.277246\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.440191\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.406884\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.462215\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.362933\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.410487\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.411714\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.460591\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.335112\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.443734\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.484670\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.469545\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.340665\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.276138\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.404229\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.305736\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.305220\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.397567\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.449598\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.334920\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.454130\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.570531\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.313292\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.231799\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.307495\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.390745\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.421181\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.209219\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.318073\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.316746\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.275919\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.226922\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.356731\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.311160\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.296344\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.215016\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.193745\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.138272\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.354256\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.175705\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.337045\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.324144\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.227933\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.354633\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.176839\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.274395\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.148594\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.208807\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.303146\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.258801\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.305684\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.207681\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.200094\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.300258\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.168833\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.347477\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.574860\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.605829\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.494200\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.333837\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.289555\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.527076\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.396566\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.339712\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.351960\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.377337\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.486115\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.313690\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.301544\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.234385\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.361776\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.575095\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.510828\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.522932\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.387687\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.356287\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.353521\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.239493\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.341151\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.312856\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.314353\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.323590\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.404831\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.250106\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.359282\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.321677\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.501941\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.302147\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.348899\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.278884\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.289985\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.471516\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.426128\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.337066\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.360479\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.286243\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.304817\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.356386\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.360150\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.186535\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.326311\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.531320\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.247414\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.242645\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.241771\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.285814\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.305579\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.152115\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.287479\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.239674\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.229026\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.338860\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.333910\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.252877\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.308311\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.245100\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.345810\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.248085\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.252892\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.320655\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.254897\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.324805\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.272377\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.191270\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.225655\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.182189\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.0796, Accuracy: 8015/10000 (80%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.573655\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.540669\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.448039\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.517100\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.442498\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.433436\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.302517\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.313753\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.497506\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.407195\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.511198\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.316936\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.437282\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.424525\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.473970\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.744580\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.078514\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.187782\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.154193\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.064921\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.117791\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.119611\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.325445\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.071723\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.145207\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.173112\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.138581\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.103332\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.140518\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.274340\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.119625\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.078597\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.166036\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.161212\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.225740\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.128130\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.135629\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.209510\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.051749\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.140795\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.092593\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.159202\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.089910\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.126066\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.127659\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.284363\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.125961\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.103547\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.120437\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.059935\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.135050\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.079033\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.163720\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.164092\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.198256\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.381260\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.224497\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.252620\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.377620\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.185664\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.232137\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.260674\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.280107\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.189358\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.229301\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.205931\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.270952\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.144539\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.196301\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.217874\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.185736\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.182418\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.168216\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.158439\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.215067\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.182172\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.339348\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.207961\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.123262\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.300038\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.187215\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.154953\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.310710\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.266371\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.151320\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.362397\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.208503\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.180596\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.263162\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.186859\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.570468\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.330262\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.313614\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.453230\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.287436\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.309496\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.446942\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.339928\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.411671\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.255739\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.426651\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.226101\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.345870\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.195248\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.302289\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.283035\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.234516\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.251595\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.364182\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.221081\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.166482\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.331291\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.377654\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.147703\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.239611\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.269530\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.250879\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.287157\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.385519\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.255496\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.396535\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.258700\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.433406\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.308912\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.325273\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.405152\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.301046\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.309567\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.353696\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.249163\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.339918\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.338926\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.366913\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.325954\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.316729\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.215175\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.444884\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.228022\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.284032\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.345396\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.269871\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.254425\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.316119\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.394055\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.327888\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.412391\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.289696\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.257678\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.291824\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.367480\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.463054\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.466422\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.310833\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.336329\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.472296\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.343146\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.427962\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.372303\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.237490\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.356225\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.356687\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.375549\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.347064\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.260505\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.276175\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.336112\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.291326\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.422956\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.458397\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.341391\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.426826\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.416825\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.365253\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.442440\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.469832\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.403210\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.501211\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.489231\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.445815\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.449232\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.343512\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.477328\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.409246\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.385745\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.559596\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.426977\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.381684\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.510720\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.319259\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.351503\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.468935\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.388642\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.447827\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.428425\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.344418\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.320075\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.335311\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.451416\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.290585\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.311887\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.465466\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.489443\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.374590\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.307656\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.275661\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.244887\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.352820\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.340483\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.336925\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.429459\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.375235\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.274294\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.375840\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.300312\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.326441\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.419278\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.382232\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.385434\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.404405\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.405911\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.603251\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.145120\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.329952\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.193529\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.252020\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.208438\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.235951\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.345812\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.219706\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.244556\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.281693\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.211004\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.189035\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.190212\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.167552\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.269271\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.237114\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.196449\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.137507\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.270018\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.189555\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.173222\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.191015\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.336737\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.282940\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.154370\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.263040\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.173617\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.221345\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.223576\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.326245\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.099646\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.214399\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.116695\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.122715\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.476271\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.231043\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.351019\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.426267\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.301572\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.314843\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.350994\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.341993\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.323648\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.359317\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.175755\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.320208\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.266053\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.348905\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.391989\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.428233\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.317553\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.310191\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.207949\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.334596\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.310386\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.312221\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.297754\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.354461\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.346251\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.323849\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.430159\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.244957\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.364990\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.385991\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.199482\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.319550\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.276041\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.319735\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.281274\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.377635\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.196384\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.287077\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.316079\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.257553\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.252015\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.249511\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.243381\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.413469\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.347080\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.179732\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.201287\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.458981\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.220901\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.159447\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.245883\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.199995\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.191028\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.207797\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.258076\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.270157\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.199428\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.293147\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.430331\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.191704\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.218135\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.172530\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.191646\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.154279\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.221780\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.185102\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.217123\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.256838\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.237295\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.084718\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.0041, Accuracy: 8161/10000 (82%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.558069\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.405163\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.454749\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.514067\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.426883\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.403640\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.454363\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.440242\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.432843\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.351916\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.391432\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.342002\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.494766\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.335841\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.382975\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.564244\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.176471\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.111209\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.167631\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.203984\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.097113\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.119741\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.093264\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.177560\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.119113\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.166444\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.048126\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.063740\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.143803\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.183580\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.196085\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.165930\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.176731\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.230077\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.149348\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.134066\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.230806\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.083698\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.141371\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.171403\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.118001\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.062802\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.061331\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.103397\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.054609\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.086123\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.192782\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.071640\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.092421\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.122207\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.074467\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.124480\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.103409\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.195477\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.031142\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.286541\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.232568\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.183449\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.281220\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.280279\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.159839\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.221237\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.220306\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.272783\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.356370\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.312898\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.220454\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.318454\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.278780\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.246474\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.226455\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.151934\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.229672\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.217111\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.241975\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.238642\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.117922\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.106443\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.348416\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.175054\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.237312\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.120576\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.263656\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.249745\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.217961\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.177664\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.361810\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.179466\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.170085\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.252578\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.527900\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.503088\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.239732\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.297526\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.247016\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.368847\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.209262\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.222836\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.204981\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.472348\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.362949\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.231977\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.160875\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.224484\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.205523\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.287802\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.213887\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.312175\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.248521\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.181773\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.191624\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.294429\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.305654\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.253636\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.195052\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.302941\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.286427\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.195315\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.219569\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.307844\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.428611\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.261062\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.275360\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.281195\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.193505\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.474637\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.244610\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.293309\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.342331\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.281119\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.255402\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.170719\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.506860\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.276242\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.228617\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.354881\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.179966\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.258888\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.478427\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.226499\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.282733\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.313082\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.277627\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.274223\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.350858\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.207940\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.291972\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.312558\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.303173\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.209542\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.536342\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.511326\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.429250\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.308144\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.320222\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.232347\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.382902\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.282682\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.214838\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.242831\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.270651\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.406975\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.265454\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.316203\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.329495\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.318103\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.248213\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.241174\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.347681\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.237604\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.414530\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.230700\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.377001\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.278317\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.332467\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.448902\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.360911\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.388577\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.469756\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.330924\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.356453\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.284148\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.425994\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.320985\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.373085\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.523404\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.292323\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.395679\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.468123\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.277415\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.251433\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.309359\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.392692\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.428325\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.285253\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.388966\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.329702\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.333561\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.322273\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.322564\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.299108\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.339326\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.431457\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.394204\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.392373\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.429454\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.556358\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.315321\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.373556\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.449104\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.337281\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.319391\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.405939\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.357303\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.254230\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.530286\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.426458\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.386834\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.481526\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.326096\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.611684\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.211321\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.326472\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.210662\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.449777\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.145124\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.130126\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.245889\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.171314\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.190587\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.284730\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.266279\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.238079\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.134854\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.190251\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.246689\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.247413\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.118951\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.217157\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.261511\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.363342\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.193460\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.225100\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.288417\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.292096\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.191952\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.308609\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.242114\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.256022\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.170413\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.232897\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.269370\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.250423\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.297340\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.202666\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.420356\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.266612\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.326146\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.480506\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.285773\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.381683\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.256361\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.333386\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.238915\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.236835\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.294311\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.279484\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.316870\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.387167\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.328441\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.257065\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.413380\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.314847\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.286834\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.266618\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.319999\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.276827\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.281477\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.409431\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.311220\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.383622\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.304328\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.312153\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.243407\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.278777\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.284236\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.274334\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.258386\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.301610\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.350760\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.413405\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.165137\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.238561\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.323222\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.218256\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.321528\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.224489\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.485483\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.212021\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.185828\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.144859\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.160438\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.238400\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.265163\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.278012\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.175112\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.200144\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.222516\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.229308\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.265357\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.230490\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.229071\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.145029\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.287350\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.137017\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.222815\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.272409\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.290485\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.294612\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.262122\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.320191\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.227774\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.210011\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.291260\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.189492\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9589, Accuracy: 8298/10000 (83%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.498624\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.408396\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.592363\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.230566\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.467770\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.414459\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.367557\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.371337\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.445808\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.390211\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.374036\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.501005\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.452394\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.442219\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.281455\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.568756\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.139829\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.085014\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.055737\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.222249\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.145454\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.113377\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.289205\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.152276\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.106298\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.126816\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.120349\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.129602\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.138031\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.090416\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.137372\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.080096\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.184397\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.163028\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.159305\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.163427\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.064794\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.243542\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.081113\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.104359\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.145011\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.076994\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.126819\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.181080\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.094670\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.130396\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.187274\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.145698\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.107190\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.065567\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.059542\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.115282\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.105752\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.039381\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.077089\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9835, Accuracy: 7818/10000 (78%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.388259\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.467162\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.367852\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.396245\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.513677\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.404617\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.516526\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.584543\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.337845\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.359104\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.412938\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.367377\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.350618\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.312717\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.479383\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.193232\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.092909\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.149428\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.194630\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.107980\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.203677\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.063845\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.048325\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.138064\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.088102\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.087770\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.179206\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.075892\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.171682\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.144132\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.191687\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.124096\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.091436\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.055315\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.119167\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.098449\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.112449\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.242688\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.094760\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.151780\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.107608\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.106190\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.141342\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.057918\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.148687\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.120256\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.120608\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.143214\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.124871\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.070722\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.128558\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.181468\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.164389\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.090250\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.112767\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9531, Accuracy: 7927/10000 (79%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.489711\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.363188\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.338563\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.330708\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.373446\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.393562\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.308611\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.330601\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.281672\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.334128\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.458339\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.310091\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.372086\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.317361\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.373125\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.367656\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.109338\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.094675\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.087657\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.050517\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.052933\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.209532\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.073749\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.113143\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.132265\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.269834\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.054009\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.105578\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.170739\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.183586\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.198128\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.071661\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.032974\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.098973\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.099252\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.109146\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.105661\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.126704\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.085986\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.060906\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.069754\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.133951\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.069033\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.142605\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.146786\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.177910\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.130511\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.192883\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.146543\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.088473\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.139916\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.083139\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.158940\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.147243\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.112776\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9494, Accuracy: 7892/10000 (79%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.589143\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.285187\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.338713\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.339429\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.384431\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.319510\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.247791\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.235420\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.347267\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.318771\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.343072\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.345025\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.436546\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.425469\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.366102\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.338541\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.177382\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.031727\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.118468\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.081781\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.035306\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.148748\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.093260\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.134996\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.059569\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.117122\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.089151\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.133096\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.112289\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.084547\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.065591\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.096221\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.170456\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.187000\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.141186\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.257599\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.071611\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.071016\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.057962\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.130978\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.074870\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.071221\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.119841\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.072199\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.106447\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.156868\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.078790\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.113726\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.109076\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.106125\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.108873\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.036122\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.050238\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.056411\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.181792\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9242, Accuracy: 7995/10000 (80%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.509689\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.258650\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.425926\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.300883\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.268364\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.342317\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.393263\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.293648\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.344560\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.206437\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.246360\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.280122\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.430961\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.310917\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.277841\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.270495\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.040710\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.101727\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.099995\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.087878\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.073903\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.099442\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.079164\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.090890\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.068198\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.044199\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.093540\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.137727\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.058606\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.053733\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.165284\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.032939\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.238606\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.067933\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.113986\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.090984\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.065572\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.148118\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.061418\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.096572\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.096256\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.118564\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.145533\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.098253\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.153595\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.160097\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.051001\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.158926\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.066121\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.066563\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.082109\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.185787\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.052467\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.116623\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.172142\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.398020\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.182294\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.151589\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.148992\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.235618\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.369239\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.193127\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.291070\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.290347\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.089903\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.138439\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.059152\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.352654\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.157066\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.173929\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.241192\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.165638\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.213379\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.244547\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.155797\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.192825\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.149529\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.166223\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.151900\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.134881\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.209844\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.138311\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.204157\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.242638\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.137611\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.095239\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.049360\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.096817\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.135831\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.268104\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.454486\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.272915\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.356008\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.239612\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.263997\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.159357\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.246942\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.169001\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.276570\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.240474\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.302946\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.231853\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.156136\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.193979\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.144063\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.401706\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.148383\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.242466\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.149173\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.188930\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.365815\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.250789\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.258559\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.288984\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.309419\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.126754\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.233432\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.183901\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.231504\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.321416\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9022, Accuracy: 8116/10000 (81%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.467297\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.419612\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.347772\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.313985\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.413341\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.327152\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.384124\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.305728\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.265047\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.425285\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.348515\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.338405\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.226049\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.374348\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.228242\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.226504\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.097002\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.087257\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.074027\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.127891\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.131523\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.092700\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.145607\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.140896\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.070757\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.146994\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.135435\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.123850\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.145576\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.098878\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.085284\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.153877\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.120369\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.163608\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.124968\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.097696\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.122239\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.127478\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.048293\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.096574\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.095275\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.099254\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.043211\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.068160\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.117868\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.091086\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.087639\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.135313\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.090160\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.030720\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.074625\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.164104\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.105851\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.162453\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.072848\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.381913\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.180543\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.232381\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.125276\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.241080\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.169332\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.185074\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.114404\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.124450\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.161788\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.140095\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.285170\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.248609\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.189647\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.187795\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.060998\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.119396\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.119963\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.175841\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.163731\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.233066\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.109065\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.251861\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.158348\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.110762\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.105856\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.210117\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.240364\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.227562\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.228341\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.177260\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.095952\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.091865\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.080378\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.243670\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.380985\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.135433\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.225851\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.305754\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.218287\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.232049\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.292207\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.238313\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.334689\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.173763\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.200794\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.235678\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.190500\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.283271\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.251833\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.210264\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.212142\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.317484\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.196192\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.176519\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.326286\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.133124\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.168050\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.145674\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.240373\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.247832\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.116963\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.216529\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.134522\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.227070\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8805, Accuracy: 8174/10000 (82%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.351932\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.353242\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.348919\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.331568\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.342253\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.267800\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.389301\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.292425\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.450163\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.255526\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.330891\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.402199\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.208410\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.301290\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.234116\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.317062\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.168440\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.137386\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.041589\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.143658\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.095026\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.118359\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.124009\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.265961\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.068211\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.081499\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.093088\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.077355\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.115140\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.132896\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.043374\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.060308\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.093991\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.095681\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.134762\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.062121\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.088083\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.170470\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.047903\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.072978\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.040431\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.111626\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.122484\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.142445\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.018685\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.122539\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.104229\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.152504\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.115270\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.075506\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.068466\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.159940\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.047504\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.064233\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.127148\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.244928\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.131706\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.238256\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.168693\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.190754\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.219277\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.118040\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.187266\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.124869\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.179562\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.178099\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.162260\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.230467\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.225863\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.205408\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.206316\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.120726\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.200038\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.202068\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.187448\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.075185\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.119681\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.112243\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.123608\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.072414\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.136293\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.117088\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.231215\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.147318\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.225548\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.128274\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.107930\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.182728\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.131775\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.120657\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.310782\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.195198\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.177199\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.208103\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.275172\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.304431\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.167015\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.218682\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.267667\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.250372\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.258852\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.246487\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.128268\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.207807\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.166958\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.097474\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.222539\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.251453\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.232144\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.162848\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.134807\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.234506\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.160154\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.188050\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.248822\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.196714\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.212104\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.152265\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.193226\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.191037\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8694, Accuracy: 8067/10000 (81%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.370264\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.319659\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.271263\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.280950\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.385992\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.177613\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.237481\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.310337\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.319684\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.271412\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.236946\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.229516\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.333772\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.257237\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.374485\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.362751\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.076585\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.056455\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.196293\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.114692\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.045790\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.098370\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.044391\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.080752\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.127301\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.065525\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.080614\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.045245\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.070221\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.120855\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.163687\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.099810\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.166432\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.064781\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.088250\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.021304\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.098534\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.087578\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.096365\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.131474\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.116647\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.053676\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.100696\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.131965\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.153971\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.143422\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.081456\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.084830\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.057236\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.104988\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.048979\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.134237\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.050184\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.058970\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.067015\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.452083\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.157394\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.132573\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.142001\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.233702\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.109433\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.308857\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.200312\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.215836\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.145784\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.124580\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.198752\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.182684\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.179933\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.076383\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.187272\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.157954\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.146630\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.204010\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.145210\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.307966\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.110831\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.077958\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.123496\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.184149\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.126533\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.211427\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.150353\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.096189\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.121463\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.256056\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.148134\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.200508\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.144699\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.244188\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.365328\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.119503\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.329635\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.317278\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.241151\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.342703\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.182297\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.257445\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.306554\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.191630\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.183794\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.267082\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.225484\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.237504\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.385991\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.250183\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.202069\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.176823\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.155983\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.143001\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.229152\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.118673\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.196351\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.223993\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.216536\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.213384\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.212309\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.157897\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.176870\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.139105\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8525, Accuracy: 8183/10000 (82%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.513072\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.372235\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.359088\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.360973\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.271748\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.353434\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.245249\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.289626\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.388945\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.220675\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.300336\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.386869\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.342448\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.296483\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.343150\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.203485\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.064494\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.052764\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.161704\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.183672\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.096242\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.099635\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.114693\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.050362\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.068302\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.129119\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.169228\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.134804\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.150695\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.099196\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.080005\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.050980\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.091610\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.079191\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.105712\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.069583\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.103422\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.035641\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.056803\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.022748\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.086791\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.179920\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.085968\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.051921\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.035478\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.064126\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.054902\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.089462\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.107946\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.211115\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.043503\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.054532\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.086219\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.102711\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.115347\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.253685\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.344447\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.177255\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.156169\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.158554\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.176894\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.117027\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.241377\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.143862\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.094664\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.175417\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.153385\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.138271\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.093369\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.180604\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.073554\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.113955\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.114360\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.109545\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.153389\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.204233\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.082062\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.226068\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.074179\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.112212\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.132871\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.174295\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.090986\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.158734\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.135061\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.105910\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.205576\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.076322\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.189673\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.190025\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.273922\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.221383\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.180112\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.163159\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.203759\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.163223\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.165523\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.353496\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.241241\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.153054\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.187439\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.214364\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.091414\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.232256\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.164741\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.196715\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.158558\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.161076\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.210276\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.133502\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.159571\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.164582\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.175699\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.144580\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.182968\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.136066\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.254306\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.102280\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.113982\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.140937\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.458442\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.203531\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.514103\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.248947\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.188780\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.340199\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.199134\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.304275\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.199825\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.242158\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.301508\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.291634\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.373125\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.246962\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.242171\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.205960\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.197686\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.408524\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.198344\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.244157\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.197277\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.190815\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.348294\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.205753\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.409391\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.241120\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.264829\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.282558\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.143527\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.229455\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.358066\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.334235\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.377427\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.339530\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.420473\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.313608\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.274293\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.289985\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.190324\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.341680\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.252729\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.310006\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.239534\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.424831\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.328911\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.307642\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.185136\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.182569\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.380388\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.343222\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8438, Accuracy: 8377/10000 (84%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.407954\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.233403\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.229956\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.315432\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.305680\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.232366\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.265222\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.243732\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.251567\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.235469\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.233591\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.253210\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.272785\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.274197\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.239331\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.266920\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.105267\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.046511\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.181293\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.118443\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.117264\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.036476\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.181016\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.086792\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.135958\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.065558\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.077713\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.175827\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.089583\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.053336\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.071596\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.143816\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.084518\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.220534\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.071199\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.142482\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.081128\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.121933\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.075056\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.150297\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.098849\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.053687\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.075969\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.095697\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.078978\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.071348\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.088925\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.070571\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.106830\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.160587\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.162347\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.067501\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.154336\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.079429\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.112963\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.342659\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.118711\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.175192\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.178774\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.072957\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.077292\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.126736\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.124063\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.083540\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.183612\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.049123\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.199650\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.191297\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.234241\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.172729\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.158430\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.087712\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.117992\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.164836\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.194698\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.209032\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.083178\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.135939\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.102097\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.096836\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.140928\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.100282\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.230612\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.140586\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.084940\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.147430\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.106674\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.142451\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.361775\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.076965\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.299012\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.153317\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.165652\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.207717\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.225317\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.259864\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.245267\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.184875\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.138740\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.193330\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.240857\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.244451\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.349092\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.150340\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.199561\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.096895\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.338550\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.167366\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.162066\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.181178\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.135883\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.164119\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.130252\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.152773\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.155000\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.255979\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.112912\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.175580\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.157819\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.241158\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.469823\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.412951\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.258214\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.324639\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.201214\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.195536\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.290160\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.327272\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.157537\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.224739\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.164481\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.203345\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.301780\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.224789\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.313049\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.227105\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.230067\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.326789\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.222185\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.197862\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.216829\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.185517\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.231501\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.107487\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.268222\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.242545\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.205564\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.197925\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.170833\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.171141\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.508182\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.303518\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.297826\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.275527\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.312524\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.329334\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.375309\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.305980\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.185618\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.171892\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.199298\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.328226\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.309323\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.263038\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.220172\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.351312\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.200750\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.317518\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.257718\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.259112\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8240, Accuracy: 8413/10000 (84%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.242104\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.317945\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.303361\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.223284\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.315691\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.256432\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.294267\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.266065\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.369358\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.270872\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.240047\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.246251\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.234074\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.183101\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.353834\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.450984\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.142309\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.112886\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.118768\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.103704\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.073582\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.103251\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.093156\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.100398\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.039011\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.063187\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.149961\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.096935\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.048109\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.191171\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.115284\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.056118\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.064125\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.068043\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.044826\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.119833\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.089308\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.198066\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.089474\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.074500\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.124203\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.097389\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.050710\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.095485\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.055585\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.055206\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.078867\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.083034\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.209208\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.125627\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.076827\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.033250\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.050984\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.108038\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.033782\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.282504\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.183095\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.169883\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.089217\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.101137\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.156981\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.080309\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.165421\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.193215\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.129248\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.141604\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.083267\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.096207\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.140026\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.166939\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.079982\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.118595\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.152518\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.245718\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.080857\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.187142\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.131730\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.127565\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.209170\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.160234\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.122046\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.145389\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.086597\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.103239\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.162573\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.115711\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.147618\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.151823\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.219944\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.118870\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.269588\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.165275\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.257109\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.127676\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.248939\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.132400\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.156401\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.183026\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.176368\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.163737\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.167123\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.215608\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.155907\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.215226\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.103605\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.197953\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.210443\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.193824\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.145918\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.123107\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.198566\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.199264\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.153291\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.136700\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.216011\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.218315\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.186080\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.147318\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.179933\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.152948\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.248191\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.197824\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.274648\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.298610\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.250536\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.172022\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.231590\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.228455\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.123287\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.310107\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.276001\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.277398\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.245072\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.319138\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.266853\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.140105\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.229365\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.154052\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.224913\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.186068\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.293870\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.155233\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.228874\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.144702\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.291796\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.266913\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.237209\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.192657\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.207382\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.284190\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.474418\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.196053\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.266011\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.345430\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.230184\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.205258\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.238891\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.421951\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.264090\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.272939\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.158950\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.234314\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.308323\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.217049\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.163730\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.253275\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.171446\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.341228\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.251746\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.308565\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8075, Accuracy: 8463/10000 (85%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.491223\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.243827\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.376803\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.147779\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.195345\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.205787\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.271327\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.167890\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.335918\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.227081\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.308217\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.212785\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.296135\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.249322\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.228418\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.367816\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.090535\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.175920\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.067131\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.085231\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.068783\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.103669\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.038476\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.038827\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.139243\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.141668\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.068684\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.082369\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.146572\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.070004\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.152881\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.082628\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.164453\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.067394\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.028459\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.056499\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.072500\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.050627\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.110708\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.156397\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.076582\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.091003\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.069041\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.061392\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.120995\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.160311\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.034596\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.087823\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.127786\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.120280\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.144202\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.024149\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.067817\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.111857\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.063515\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.271934\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.097317\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.163911\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.163904\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.118728\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.117023\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.126044\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.154484\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.185686\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.188572\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.100733\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.120047\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.147874\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.224694\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.070041\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.174472\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.127637\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.097387\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.175127\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.209030\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.080620\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.132184\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.137963\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.095612\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.166892\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.129051\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.137188\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.083100\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.384218\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.062436\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.120389\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.054943\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.200926\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.079302\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.047638\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.388917\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.158700\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.288313\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.154495\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.110854\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.348904\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.139634\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.156970\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.181725\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.159763\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.218676\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.250022\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.112479\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.152478\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.128546\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.197980\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.192463\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.260693\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.102307\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.143202\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.191931\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.167059\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.123266\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.097013\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.150773\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.173573\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.156788\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.167443\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.242423\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.114884\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.340643\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.118014\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.177433\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.268421\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.177637\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.267712\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.220173\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.247188\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.198491\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.192987\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.314140\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.267471\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.466331\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.250657\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.181681\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.239405\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.187226\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.286647\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.443546\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.269779\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.262959\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.189071\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.224308\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.241019\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.285126\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.164258\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.198259\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.303568\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.207380\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.152800\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.427259\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.348977\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.319311\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.416159\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.341359\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.180546\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.249362\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.205697\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.246257\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.227350\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.186450\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.367374\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.261151\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.159871\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.246339\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.227179\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.220999\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.346066\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.266808\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.180942\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.7894, Accuracy: 8485/10000 (85%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.420527\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.363548\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.277920\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.180973\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.360609\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.196668\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.514380\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.329934\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.253906\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.353020\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.370402\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.295860\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.214637\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.213586\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.246624\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.551770\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.076281\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.120761\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.169374\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.159014\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.097517\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.080628\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.082049\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.045448\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.073335\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.075441\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.101653\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.070792\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.055337\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.121559\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.204858\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.165191\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.126437\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.042825\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.053793\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.130646\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.093429\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.141298\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.049176\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.045526\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.061246\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.071184\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.055219\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.143114\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.129163\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.048897\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.069137\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.119588\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.092227\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.038638\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.039036\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.048877\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.074261\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.052249\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.073550\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.263852\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.150901\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.067937\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.097480\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.097417\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.206313\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.198624\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.148017\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.062960\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.142474\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.261338\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.150363\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.175272\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.186133\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.139756\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.197589\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.090755\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.088916\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.193344\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.141788\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.134359\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.121507\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.162406\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.112441\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.188514\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.204292\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.098858\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.241262\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.125343\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.226602\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.143375\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.166580\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.111532\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.141985\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.161526\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.211534\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.101944\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.206447\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.203097\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.249569\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.224905\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.104180\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.178793\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.126488\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.200622\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.176591\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.127566\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.117508\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.219089\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.128558\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.200657\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.159082\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.111122\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.246602\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.205185\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.105133\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.138363\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.124202\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.173957\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.225498\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.125683\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.157822\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.230530\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.169810\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.189678\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.331703\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.174302\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.177417\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.206910\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.442377\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.356720\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.249555\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.189630\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.161375\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.203014\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.259003\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.233568\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.347241\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.257611\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.228159\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.183332\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.196427\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.197463\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.210055\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.152907\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.089235\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.145711\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.130497\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.141377\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.215654\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.167561\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.185643\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.094386\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.233226\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.232217\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.398222\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.305860\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.353065\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.339376\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.341284\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.312019\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.243627\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.216871\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.313901\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.229940\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.251947\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.319246\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.237128\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.331951\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.197717\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.241983\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.212241\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.205506\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.212583\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.228642\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.323643\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.499074\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.392236\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.243291\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.368753\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.343011\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.324353\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.370584\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.321355\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.283216\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.430406\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.289594\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.243463\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.394913\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.321608\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.351689\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.283293\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.356077\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.364822\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.212840\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.423720\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.355729\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.329420\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.221305\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.222600\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.265134\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.287266\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.276457\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.240030\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.311119\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.233887\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.382304\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.334937\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.355333\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.279899\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.305995\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.368987\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.454513\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.220471\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.209830\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.296189\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.199279\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.210782\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.292458\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.241177\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.219985\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.279072\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.336795\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.332019\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.259985\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.482279\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.239463\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.329819\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.179435\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.219550\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.155710\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.459585\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.128950\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.253320\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.141038\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.240809\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.171987\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.064457\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.243123\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.106565\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.332241\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.160110\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.269880\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.257961\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.188910\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.098881\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.160739\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.112869\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.177868\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.211426\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.159039\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.140383\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.204025\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.158210\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.102194\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.118831\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.134211\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.171614\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.225029\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.171242\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.7941, Accuracy: 8556/10000 (86%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.553456\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.230978\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.371949\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.230168\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.334185\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.284466\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.214933\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.186807\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.287382\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.209113\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.358135\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.405744\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.272363\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.256343\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.261917\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.323233\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.111685\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.111887\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.187941\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.069508\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.027556\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.181926\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.151354\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.054804\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.054684\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.068770\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.250917\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.095887\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.069917\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.046807\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.072893\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.110210\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.061144\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.179188\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.083539\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.150193\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.095053\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.063868\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.059891\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.064059\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.130359\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.142038\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.096299\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.176663\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.055078\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.103093\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.031456\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.100890\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.063822\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.143056\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.086549\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.051381\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.063840\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.062364\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.070688\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.319503\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.151313\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.227553\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.103188\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.209822\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.080291\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.168206\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.106296\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.077830\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.146512\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.107285\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.105173\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.038465\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.142239\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.099494\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.155759\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.171563\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.081137\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.113017\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.109558\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.118768\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.128359\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.070114\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.043427\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.095380\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.086555\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.096095\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.095191\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.133488\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.062410\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.090248\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.072316\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.101950\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.081549\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.156940\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.265609\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.257882\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.157024\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.156821\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.207910\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.107294\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.117781\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.203536\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.184418\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.259339\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.338183\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.174638\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.078780\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.145137\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.112395\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.101335\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.145438\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.135809\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.086080\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.163062\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.300937\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.281462\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.180156\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.254786\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.155896\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.123285\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.175400\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.154024\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.204186\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.132275\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.238614\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.282435\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.325234\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.266338\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.208936\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.211714\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.300868\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.203621\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.251750\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.240636\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.200532\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.127620\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.299550\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.168691\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.132307\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.261949\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.201644\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.330428\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.240045\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.183757\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.162215\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.191756\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.229533\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.236666\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.201053\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.277183\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.155127\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.232131\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.289769\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.144010\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.310144\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.354013\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.198627\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.278791\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.271573\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.239869\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.205678\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.180039\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.180405\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.155456\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.351667\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.211537\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.234809\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.382160\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.414771\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.244646\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.283339\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.289578\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.328601\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.221423\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.302652\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.330814\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.185432\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.449375\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.341712\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.298409\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.253809\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.358795\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.266924\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.213904\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.244618\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.252094\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.288995\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.337483\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.367860\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.375958\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.432704\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.444321\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.406563\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.184486\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.337404\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.247716\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.355354\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.433048\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.311440\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.345039\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.286949\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.161860\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.328764\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.275910\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.417897\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.253071\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.430799\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.263523\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.377809\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.362254\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.307972\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.251676\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.335663\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.293376\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.217186\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.338832\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.252112\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.348872\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.338144\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.303436\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.400199\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.281289\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.232137\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.326645\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.416725\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.257877\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.242472\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.127501\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.219789\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.179812\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.207748\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.191292\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.207806\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.202858\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.197693\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.112522\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.148230\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.309009\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.243860\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.157339\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.144945\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.202158\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.154991\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.263545\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.170345\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.267943\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.163635\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.229619\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.202584\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.080573\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.238944\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.224041\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.076981\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.097473\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.112670\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.148183\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.320929\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.075711\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.126205\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.7833, Accuracy: 8505/10000 (85%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.377915\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.250795\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.292198\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.268041\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.349672\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.231436\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.262020\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.377889\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.303134\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.288830\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.299664\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.386367\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.256669\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.244081\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.154063\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.293733\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.078951\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.104972\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.101260\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.114990\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.067602\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.063114\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.086541\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.054080\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.077391\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.022832\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.127668\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.098766\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.137995\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.065657\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.168668\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.053194\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.058144\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.144626\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.078398\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.077487\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.072129\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.129496\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.076622\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.085970\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.096389\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.066640\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.067268\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.112918\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.167825\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.077795\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.134375\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.166810\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.080446\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.115040\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.168297\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.045327\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.026620\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.070821\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.126829\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.302652\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.207365\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.213047\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.182646\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.113983\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.204935\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.157375\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.057070\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.148855\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.125396\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.198705\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.136757\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.148295\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.126078\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.134256\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.085460\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.081452\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.149341\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.084871\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.156925\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.090072\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.123077\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.165762\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.115630\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.145379\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.130326\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.144593\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.173778\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.128282\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.070321\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.142688\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.238196\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.103058\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.140529\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.074621\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.318674\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.158549\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.176385\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.206608\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.119257\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.236898\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.117158\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.172783\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.116184\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.243032\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.164425\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.222945\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.134378\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.131784\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.180139\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.110151\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.180225\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.161312\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.086161\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.127239\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.209528\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.169509\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.210708\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.106795\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.180125\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.161716\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.151767\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.135158\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.110865\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.135510\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.280598\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.245985\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.249275\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.230893\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.093923\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.180520\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.138747\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.137031\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.252643\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.155815\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.195936\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.223295\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.605528\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.185027\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.141288\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.160884\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.193945\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.203983\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.118225\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.234759\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.204216\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.204808\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.282455\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.173126\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.171732\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.406350\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.153671\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.151880\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.199821\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.195120\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.315619\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.141959\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.209864\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.281750\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.262043\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.279858\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.311550\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.193223\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.234038\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.243161\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.273435\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.274709\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.209392\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.158196\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.268607\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.255058\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.220982\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.140109\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.252518\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.319751\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.330059\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.435535\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.306411\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.375799\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.308897\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.210324\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.209502\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.232109\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.414819\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.342399\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.256022\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.333963\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.379529\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.389049\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.287638\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.240748\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.295397\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.271307\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.365772\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.322907\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.241261\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.381211\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.331802\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.206903\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.249711\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.315377\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.276629\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.308445\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.223896\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.278864\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.531349\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.339788\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.387248\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.168749\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.300417\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.248045\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.227681\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.280084\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.273661\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.410158\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.213952\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.296197\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.307530\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.181653\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.246494\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.191024\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.254612\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.269209\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.398742\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.203203\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.639117\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.127968\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.160229\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.152833\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.188200\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.308894\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.115631\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.102807\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.184160\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.110652\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.139549\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.102349\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.146065\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.166525\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.231290\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.149620\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.199072\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.231132\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.150419\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.158090\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.172411\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.171614\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.071879\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.225718\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.204741\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.191125\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.083237\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.160702\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.137559\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.097789\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.234337\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.210549\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.197765\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.270388\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.063935\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.7690, Accuracy: 8599/10000 (86%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.391889\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.263037\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.341633\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.237847\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.230088\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.300181\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.333294\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.193346\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.208846\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.241905\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.190020\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.187130\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.330692\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.327307\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.262013\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.307211\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.127147\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.095687\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.132193\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.057194\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.122914\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.078194\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.185931\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.042169\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.097115\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.104483\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.029123\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.045362\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.075387\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.038960\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.140418\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.070885\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.063618\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.045383\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.048526\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.115441\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.056839\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.030532\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.220882\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.086691\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.049330\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.099460\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.101867\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.133451\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.036530\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.123951\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.042763\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.059004\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.097868\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.059292\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.070643\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.089135\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.078432\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.038258\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.046663\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.368805\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.182103\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.092554\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.214544\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.046501\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.143068\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.126866\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.170727\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.158020\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.147633\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.172334\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.183022\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.127545\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.137692\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.132129\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.116006\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.066774\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.107372\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.143465\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.091252\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.122322\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.051364\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.117154\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.107925\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.148683\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.080598\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.094565\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.128976\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.134140\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.052094\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.056504\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.057311\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.139971\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.111966\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.110106\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.327669\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.099565\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.137397\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.235156\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.161518\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.203920\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.204669\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.252309\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.164437\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.251284\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.197518\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.138211\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.085691\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.097865\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.094795\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.298456\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.176642\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.200920\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.171221\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.177307\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.141320\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.147969\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.124717\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.145797\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.187599\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.123432\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.154221\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.139354\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.160742\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.211953\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.323457\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.277414\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.168467\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.371699\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.176015\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.218332\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 1.093454\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.297332\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.213426\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.199127\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.163309\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.208927\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.187079\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.219986\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.241496\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.299824\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.251045\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.151491\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.164260\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.119665\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.246001\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.299497\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.206297\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.189935\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.347792\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.186009\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.127279\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.124320\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.265534\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.224183\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.325812\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.198037\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.193704\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.206116\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.225120\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.284477\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.191887\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.251210\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.344607\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.333508\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.188127\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.265835\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.151842\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.295204\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.213788\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.218229\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.210778\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.221501\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.225713\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.175827\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.466937\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.306801\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.255240\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.414506\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.328551\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.406589\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.318601\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.265023\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.209747\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.211045\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.297654\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.426892\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.189196\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.242942\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.220757\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.371801\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.267768\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.238892\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.297654\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.303216\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.281853\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.276207\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.289512\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.247412\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.227648\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.300764\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.201279\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.203657\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.255203\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.286215\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.266027\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.266996\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.270276\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.230812\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.275966\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.409049\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.264688\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.288815\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.284803\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.271323\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.199577\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.180611\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.161058\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.322548\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.176232\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.239818\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.267336\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.295938\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.337144\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.258791\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.419293\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.180864\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.219771\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.281358\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.234838\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.226740\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.225057\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.188888\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.099410\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.331662\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.198702\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.101075\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.241474\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.213171\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.285185\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.139809\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.089872\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.231140\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.212191\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.153929\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.253304\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.132138\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.102723\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.061603\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.254445\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.200216\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.182532\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.092084\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.125051\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.145866\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.195046\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.245377\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.157207\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.235674\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.127759\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.7600, Accuracy: 8562/10000 (86%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.309603\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.314842\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.350291\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.294797\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.278380\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.278085\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.314441\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.198455\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.252511\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.202119\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.271368\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.186430\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.157574\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.289000\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.196815\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.434718\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.049077\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.051588\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.078992\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.111837\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.113020\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.044429\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.111866\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.083555\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.070898\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.056333\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.049931\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.057667\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.139527\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.061252\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.103361\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.082377\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.065174\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.085136\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.081978\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.064067\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.050327\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.233380\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.086198\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.095842\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.026124\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.054333\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.029579\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.096580\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.027767\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.050149\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.098299\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.054349\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.058720\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.049690\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.118897\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.075003\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.077756\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.036907\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.062674\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.204348\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.079782\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.100684\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.164946\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.114454\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.119222\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.130938\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.124793\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.083049\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.152444\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.121385\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.160617\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.158642\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.089642\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.045497\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.106160\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.071752\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.183679\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.154294\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.120138\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.188311\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.096076\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.116859\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.091875\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.181229\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.071104\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.094494\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.141593\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.218928\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.095746\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.153525\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.081039\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.170077\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.154052\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.047540\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.247215\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.110311\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.199785\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.117261\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.140294\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.166768\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.162499\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.260659\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.211557\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.125265\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.121209\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.152337\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.125506\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.187026\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.127082\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.163658\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.140533\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.198230\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.221884\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.216342\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.179686\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.106978\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.103253\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.107190\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.183079\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.071117\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.169144\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.190945\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.193333\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.212220\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.267120\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.264019\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.195034\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.291703\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.212720\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.313608\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.219159\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.117991\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.184449\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.181652\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.172509\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.273308\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.194526\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.159454\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.214557\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.182776\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.159191\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.231195\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.238141\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.168715\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.180454\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.266746\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.138643\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.198530\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.114648\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.156398\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.314683\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.182852\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.130484\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.124229\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.201113\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.314718\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.339590\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.401143\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.214233\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.257086\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.229313\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.189137\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.186133\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.283374\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.240597\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.283746\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.280900\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.306782\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.174699\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.225422\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.144399\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.241640\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.145436\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.279518\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.304584\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.295162\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.375509\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.271443\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.408123\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.224320\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.315942\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.240154\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.391858\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.278388\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.303535\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.300202\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.237706\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.271578\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.277976\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.163412\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.369834\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.196749\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.237462\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.401020\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.273798\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.194293\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.272801\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.385622\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.311385\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.239606\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.286177\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.228116\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.297007\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.298634\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.269724\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.245170\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.265813\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.337945\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.374620\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.236167\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.255126\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.334677\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.276177\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.230468\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.242768\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.301943\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.271516\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.258909\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.226984\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.191268\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.129895\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.266071\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.260511\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.217520\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.517795\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.311551\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.231665\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.132842\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.121308\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.188684\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.320553\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.166401\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.173268\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.110135\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.116446\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.232106\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.138683\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.095421\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.119546\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.074379\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.218209\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.161615\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.186550\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.192775\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.178519\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.133219\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.215982\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.191160\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.093024\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.097957\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.151822\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.068460\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.179244\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.107999\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.190908\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.147272\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.080709\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.297731\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.264968\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.348992\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.236820\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.317324\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.353304\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.168545\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.385970\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.203963\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.294302\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.224324\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.254256\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.156712\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.217939\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.181062\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.229716\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.192221\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.213078\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.270507\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.159927\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.244672\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.229417\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.234838\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.187838\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.209539\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.205239\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.123649\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.314547\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.230808\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.157131\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.208192\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.199283\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.154176\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.189430\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.178237\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.156629\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.126433\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.280706\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.134498\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.230506\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.183398\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.157093\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.298188\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.323385\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.203448\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.213385\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.149095\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.307925\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.138772\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.290077\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.101218\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.258823\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.178514\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.230428\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.127138\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.285089\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.167972\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.228248\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.170974\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.153202\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.159021\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.197189\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.249284\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.161637\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.165929\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.219733\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.161526\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.089441\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.181491\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.148928\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.172978\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.114452\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.7524, Accuracy: 8601/10000 (86%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.346712\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.262217\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.313560\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.288203\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.242459\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.248106\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.209148\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.295069\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.277254\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.249340\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.243768\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.184397\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.174700\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.230657\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.299385\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.295720\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.061348\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.079050\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.137029\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.050799\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.296695\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.093610\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.106716\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.147974\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.098232\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.111856\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.116746\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.181003\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.085541\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.093636\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.137597\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.140069\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.036027\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.028420\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.092515\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.056535\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.021057\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.112070\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.062231\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.037623\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.039446\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.061677\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.055268\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.049961\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.101340\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.110377\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.068827\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.122547\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.116601\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.030853\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.073561\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.030609\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.066294\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.055749\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.032469\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.228661\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.139837\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.127066\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.143667\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.084880\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.175186\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.132666\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.123848\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.209064\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.171785\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.154024\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.089171\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.112479\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.084303\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.074928\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.155650\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.151099\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.058495\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.112917\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.096243\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.143739\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.080389\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.195531\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.123722\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.072493\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.140139\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.250155\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.087306\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.070175\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.168054\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.068763\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.053497\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.088120\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.115578\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.094934\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.186260\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.154570\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.149267\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.095939\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.226379\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.112597\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.130998\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.092264\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.202599\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.146159\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.130409\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.146837\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.146818\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.172726\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.100208\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.183800\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.120955\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.191764\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.124661\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.157065\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.102864\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.118561\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.182851\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.178214\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.210015\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.079710\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.165460\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.196623\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.120735\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.133289\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.255908\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.198195\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.125131\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.178409\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.169174\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.261461\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.210004\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.243814\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.191160\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.197903\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.219235\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.208825\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.241107\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.156353\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.213388\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.229693\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.241057\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.136252\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.197537\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.126358\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.128251\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.134900\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.197741\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.173245\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.335632\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.104199\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.186605\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.254095\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.207977\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.183967\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.338955\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.178776\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.123355\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.299669\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.185688\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.230460\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.147609\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.310869\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.182669\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.229146\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.134811\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.190716\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.236136\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.268008\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.251611\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.263044\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.152060\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.203951\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.204125\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.148004\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.304180\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.210198\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.329414\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.354455\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.365818\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.266573\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.418815\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.178059\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.245674\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.264875\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.393786\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.277497\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.322030\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.331673\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.271336\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.249169\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.387915\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.253936\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.199564\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.142987\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.303482\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.222683\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.241019\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.223060\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.234316\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.164884\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.236256\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.253796\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.255146\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.307762\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.393847\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.327949\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.150411\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.305734\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.343732\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.192287\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.307593\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.315786\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.287960\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.312245\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.148569\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.292814\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.100290\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.293920\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.223047\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.230778\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.258990\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.259927\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.307583\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.413167\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.412423\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.254520\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.123674\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.134983\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.100681\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.267124\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.234645\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.154860\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.131368\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.159538\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.105153\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.115425\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.150529\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.167639\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.123009\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.174591\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.240941\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.112302\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.144468\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.116298\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.110619\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.111308\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.278546\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.049384\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.194039\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.098658\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.132429\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.059047\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.118186\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.176256\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.172989\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.101918\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.141719\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.125900\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.147037\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.207002\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.188237\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.215175\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.179917\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.356633\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.271302\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.244769\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.216355\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.270475\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.158467\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.314173\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.241752\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.219122\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.270221\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.324917\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.211566\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.218792\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.194868\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.215043\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.362204\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.118275\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.189699\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.319210\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.188323\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.271258\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.235884\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.153407\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.241171\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.188849\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.198023\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.092424\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.242460\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.156185\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.236725\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.200952\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.169107\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.195683\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.257340\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.196269\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.151018\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.115410\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.118852\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.277543\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.131728\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.197959\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.158704\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.128667\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.232416\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.224290\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.174807\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.205928\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.196032\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.119527\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.113790\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.148963\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.197593\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.197058\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.115801\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.156828\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.161842\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.204280\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.200089\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.224593\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.224152\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.160652\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.147162\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.141419\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.130804\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.150539\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.252274\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.7420, Accuracy: 8605/10000 (86%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.466286\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.346287\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.288385\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.251547\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.320043\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.207470\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.222766\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.129082\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.308492\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.257229\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.128418\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.193016\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.247736\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.204095\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.216306\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.377959\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.083858\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.159900\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.090614\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.096468\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.086987\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.066296\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.033020\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.050536\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.042763\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.072001\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.080250\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.106369\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.074501\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.078421\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.047393\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.113894\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.076187\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.082491\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.073572\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.050838\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.075474\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.086824\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.087874\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.059570\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.034144\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.058040\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.031652\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.095901\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.039155\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.050433\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.056332\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.041734\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.020861\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.119452\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.090496\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.070508\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.048432\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.123170\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.145382\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.322657\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.123681\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.178013\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.178417\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.162697\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.315274\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.134176\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.223517\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.107765\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.103876\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.093628\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.115915\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.127349\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.231967\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.105125\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.090824\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.117432\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.074252\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.123144\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.078502\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.034135\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.181068\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.086894\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.106024\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.101098\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.086373\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.152579\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.114512\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.095340\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.049405\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.119343\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.046661\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.083003\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.163545\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.201871\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.366906\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.179926\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.186859\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.254575\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.150356\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.195649\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.149612\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.143615\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.129121\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.170036\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.211500\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.147118\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.151832\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.093071\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.185261\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.085709\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.161230\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.130268\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.130861\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.202184\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.131932\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.082380\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.161496\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.072079\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.183247\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.140316\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.098291\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.132048\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.121645\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.111314\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.369115\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.316759\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.269510\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.253992\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.163378\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.244798\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.219794\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.193030\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.229366\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.201458\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.258114\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.254586\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.174747\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.174792\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.160131\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.165413\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.146161\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.142593\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.630519\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.162564\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.217485\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.161349\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.111741\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.191830\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.322169\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.136631\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.149742\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.258143\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.144822\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.142469\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.397015\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.225619\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.261632\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.305460\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.187385\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.148700\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.202877\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.204079\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.128234\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.286276\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.235456\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.204894\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.161302\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.232953\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.190695\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.296106\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.212795\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.184838\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.237880\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.119557\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.255416\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.364474\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.161630\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.302345\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.259883\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.193967\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.353941\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.315970\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.336175\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.287406\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.248260\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.274726\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.239589\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.268868\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.455518\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.253072\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.334679\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.141924\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.304296\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.237421\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.284429\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.172722\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.210866\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.229654\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.289650\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.368898\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.326407\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.314613\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.224257\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.288774\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.317270\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.236375\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.191186\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.246219\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.318120\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.274947\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.298862\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.245000\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.341623\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.225988\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.245013\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.257224\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.187714\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.347890\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.372076\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.199805\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.303818\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.297805\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.226203\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.209538\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.395305\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.129507\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.273827\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.193479\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.108635\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.190532\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.215606\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.158179\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.059600\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.169639\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.133446\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.204891\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.228592\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.143001\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.207126\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.100148\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.141011\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.171232\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.157119\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.182355\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.115375\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.098846\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.094883\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.169086\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.099770\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.146482\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.135314\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.106639\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.127685\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.197845\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.077117\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.153678\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.123263\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.112430\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.144339\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.373093\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.177948\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.261235\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.253218\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.255281\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.176166\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.292306\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.205885\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.194716\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.263093\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.227951\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.197524\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.245984\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.252938\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.167650\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.267108\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.329345\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.170480\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.237417\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.257204\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.204137\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.220712\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.160242\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.129678\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.210709\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.257976\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.224204\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.227060\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.156804\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.185725\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.213152\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.168813\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.185487\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.229679\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.199895\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.164274\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.132220\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.344937\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.165890\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.246338\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.106093\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.107232\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.199870\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.140607\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.168146\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.258098\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.084170\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.207714\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.128273\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.201340\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.156468\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.127564\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.171337\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.126235\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.081750\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.139233\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.150737\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.217136\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.066663\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.081343\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.107323\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.252885\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.229018\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.155028\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.124727\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.192453\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.172583\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.078802\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.106870\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.165806\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.7239, Accuracy: 8649/10000 (86%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.375672\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.267781\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.298900\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.217857\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.326398\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.355556\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.299261\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.289267\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.268299\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.277440\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.411992\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.284165\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.214884\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.208956\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.206742\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.216889\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.171270\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.054496\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.046950\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.106810\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.115063\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.054419\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.080825\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.083193\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.159709\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.091350\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.126880\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.184357\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.152833\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.083774\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.088313\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.039120\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.142050\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.113456\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.049584\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.055026\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.088991\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.048415\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.039369\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.058066\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.049628\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.128612\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.061297\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.045927\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.112125\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.079108\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.145529\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.078784\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.065346\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.066366\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.020581\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.038707\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.064257\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.111736\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.035304\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.182600\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.089598\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.067400\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.110584\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.182373\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.061518\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.204373\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.089312\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.060441\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.060613\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.226786\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.137678\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.116486\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.083828\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.142302\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.050847\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.070588\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.081062\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.113088\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.126106\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.276033\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.138427\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.180491\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.074211\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.128461\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.101797\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.104857\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.063712\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.153060\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.044697\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.081274\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.173850\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.047826\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.158137\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.108124\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.252934\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.226107\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.109844\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.252576\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.179975\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.152335\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.186981\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.181538\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.160020\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.159391\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.134737\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.193538\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.104815\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.102159\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.229796\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.224293\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.141741\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.121908\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.063729\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.148280\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.307258\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.142287\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.193996\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.189888\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.164804\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.170216\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.189361\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.084726\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.228177\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.157900\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.319720\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.382969\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.170762\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.237355\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.228198\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.180755\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.181105\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.215809\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.218310\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.305558\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.282000\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.236677\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.150919\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.123832\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.179568\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.185966\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.224978\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.226653\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.110962\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.133449\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.311256\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.123630\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.194764\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.199394\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.286778\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.226673\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.191137\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.136862\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.119871\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.123637\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.212803\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.302864\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.332480\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.255782\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.159856\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.202171\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.202641\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.199809\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.167208\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.191386\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.209727\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.192807\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.167000\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.226339\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.280058\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.244271\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.189084\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.295070\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.285640\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.196194\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.225514\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.303345\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.213532\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.410443\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.329031\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.286782\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.338554\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.264495\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.182452\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.308294\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.452500\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.264202\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.277992\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.172373\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.173724\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.206220\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.268445\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.305434\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.256275\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.270695\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.272161\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.350325\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.234914\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.253853\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.334085\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.201663\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.284946\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.314906\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.224813\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.381843\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.223050\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.137766\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.195032\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.334906\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.313996\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.220191\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.331515\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.327150\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.249192\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.231101\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.304268\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.284238\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.422489\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.250036\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.207812\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.361461\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.333017\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.282660\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.152684\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.361698\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.357978\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.125183\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.295550\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.146725\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.187219\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.193530\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.144415\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.142829\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.098219\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.119388\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.124691\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.153478\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.177727\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.206414\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.126653\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.172799\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.225485\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.117467\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.257091\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.225685\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.103811\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.206199\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.156241\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.257642\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.140970\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.256175\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.209807\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.121757\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.126283\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.234798\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.098749\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.136820\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.123121\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.213805\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.308270\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.203797\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.149548\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.265060\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.132618\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.317968\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.226020\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.172314\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.152061\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.128927\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.211162\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.217362\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.262764\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.176625\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.167002\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.279954\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.218875\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.165691\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.217846\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.197900\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.165459\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.198198\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.202541\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.178094\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.316795\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.218584\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.258394\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.150258\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.207379\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.212456\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.138156\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.227393\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.183366\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.280466\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.267870\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.184916\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.128878\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.278431\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.226202\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.182164\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.134909\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.184293\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.198929\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.131799\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.167075\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.116586\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.091141\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.197274\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.261014\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.150727\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.100646\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.141486\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.193265\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.168268\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.165356\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.163450\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.132366\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.090523\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.196859\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.213064\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.139065\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.160044\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.024561\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.125265\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.268658\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.172235\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.146192\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.091328\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.110889\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.235692\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.068995\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.7175, Accuracy: 8649/10000 (86%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "partitioned_data_pca = partition.balanced_dirichlet_partition(trainingset_pca, partitions_number=num_clients, alpha=alpha)\n",
    "pca_client_loaders = [\n",
    "    DataLoader(Subset(trainingset_pca, indices), batch_size=batch_size_train, shuffle=True)\n",
    "    for indices in partitioned_data_pca.values()\n",
    "]\n",
    "\n",
    "local_models_pca_strong = [copy.deepcopy(global_model_pca_strong) for _ in range(num_clients)]\n",
    "\n",
    "# Pca strong\n",
    "optimizer = optim.SGD(trial_model_pca_strong.parameters(), lr=learning_rate,\n",
    "                  momentum=momentum)\n",
    "\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):  \n",
    "    train_fashion(epoch, trial_model_pca_strong, train_loader_reduced_pca, optimizer, log_interval, train_losses, train_counter)\n",
    "\n",
    "\n",
    "\n",
    "test_losses_pca_strong = []\n",
    "test_fashion(trial_model_pca_strong,train_loader_reduced_pca,test_losses_pca_strong)\n",
    "\n",
    "rounds_pca = 4\n",
    "for round_idx in range(rounds_pca):\n",
    "    \n",
    "    print(f\"Round {round_idx + 1}/{rounds_pca}\")\n",
    "\n",
    "    local_weights_pca = []\n",
    "    for client_idx, client_model in enumerate(local_models_pca_strong):\n",
    "        print(f\"Training client {client_idx + 1}\")\n",
    "        \n",
    "        optimizer = optim.SGD(client_model.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "\n",
    "        train_losses = []\n",
    "        train_counter = []\n",
    "\n",
    "\n",
    "        for epoch in range(1, n_epochs + 1):  \n",
    "            train_fashion(epoch, client_model, pca_client_loaders[client_idx], optimizer, log_interval, train_losses, train_counter)\n",
    "        \n",
    "        client_weights = [param.data.numpy() for param in client_model.parameters()]\n",
    "        local_weights_pca.append(client_weights)\n",
    "        \n",
    "\n",
    "    global_weights_pca = federated_averaging(local_weights_pca)\n",
    "\n",
    "    distribute_global_model(global_weights_pca,local_models_pca_strong,single=False)\n",
    "\n",
    "    distribute_global_model(global_weights_pca,global_model_pca_strong,single=True)\n",
    "    test_losses = []\n",
    "    test_fashion(global_model_pca_strong,test_loader_pca,test_losses)\n",
    "\n",
    "    test_accuracies_classic = []\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader_pca:\n",
    "            data = data.view(data.shape[0], -1)\n",
    "            output = global_model_pca_strong(data)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "    accuracy = 100. * correct / len(test_loader_pca.dataset)\n",
    "    test_accuracies_classic.append(accuracy)\n",
    "\n",
    "    # Save results for non-clustered classic\n",
    "    results[\"pca\"][\"NoCluster\"] = {\"losses\": [], \"accuracy\": []}\n",
    "\n",
    "    results[\"pca\"][\"NoCluster\"][\"losses\"].extend(test_losses)\n",
    "    results[\"pca\"][\"NoCluster\"][\"accuracy\"].extend(test_accuracies_classic)\n",
    "\n",
    "    ######################\n",
    "for num_cluster in num_clusters:\n",
    "    import cluster2\n",
    "\n",
    "    targets = trainingset.targets\n",
    "    num_classes = len(set(targets)) \n",
    "    # Erstelle Clients\n",
    "    clients = [cluster2.FederatedClient(cid, indices, targets, num_classes) for cid, indices in partitioned_data_pca.items()]\n",
    "    \n",
    "    # Jeder Client berechnet seine Labelverteilung\n",
    "    client_distributions = [client.compute_label_distribution() for client in clients]\n",
    "    \n",
    "    # Server fhrt Clustering durch\n",
    "    server = cluster2.FederatedClusterServer(num_cluster)\n",
    "    aggregated_data = server.aggregate_client_data(client_distributions)\n",
    "    clustered_data = server.perform_greedy_clustering(aggregated_data, partitioned_data_pca)\n",
    "    \n",
    "    partitioned_data_pca_clustered = clustered_data\n",
    "\n",
    "    \"\"\"\n",
    "    import cluster\n",
    "    cluster = cluster.Cluster(num_clusters=num_cluster)\n",
    "    \n",
    "    targets = trainingset_pca.targets\n",
    "    num_classes = len(set(targets)) \n",
    "    clustered_data = cluster.apply_clustering(partitioned_data_pca, targets, num_classes)\n",
    "    \n",
    "    partitioned_data_pca_clustered = clustered_data\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    pca_client_loaders_clustered = [\n",
    "        DataLoader(Subset(trainingset_pca, indices), batch_size=batch_size_train, shuffle=True)\n",
    "        for indices in partitioned_data_pca_clustered.values()\n",
    "    ]\n",
    "\n",
    "    for round_idx in range(rounds_classic):\n",
    "        print(f\"Round {round_idx + 1}/{rounds_classic}\")\n",
    "\n",
    "        local_weights_pca = []\n",
    "        for client_idx, client_model in enumerate(local_models_pca_strong[0:num_cluster]):\n",
    "            print(f\"Training client {client_idx + 1}\")\n",
    "            \n",
    "            optimizer = optim.SGD(client_model.parameters(), lr=learning_rate,\n",
    "                          momentum=momentum)\n",
    "    \n",
    "            train_losses = []\n",
    "            train_counter = []\n",
    "    \n",
    "    \n",
    "            for epoch in range(1, n_epochs + 1):  \n",
    "                train_fashion(epoch, client_model, pca_client_loaders[client_idx], optimizer, log_interval, train_losses, train_counter)\n",
    "            \n",
    "            client_weights = [param.data.numpy() for param in client_model.parameters()]\n",
    "            local_weights_pca.append(client_weights)\n",
    "            \n",
    "    \n",
    "        global_weights_pca = federated_averaging(local_weights_pca)\n",
    "    \n",
    "        distribute_global_model(global_weights_pca,local_models_pca_strong,single=False)\n",
    "    \n",
    "        distribute_global_model(global_weights_pca,global_model_pca_strong,single=True)\n",
    "        test_losses = []\n",
    "        test_fashion(global_model_pca_strong,test_loader_pca,test_losses)\n",
    "    \n",
    "        test_accuracies_pca = []\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader_pca:\n",
    "                data = data.view(data.shape[0], -1)\n",
    "                output = global_model_pca_strong(data)\n",
    "                pred = output.data.max(1, keepdim=True)[1]\n",
    "                correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "        accuracy = 100. * correct / len(test_loader_pca.dataset)\n",
    "        test_accuracies_classic.append(accuracy)\n",
    "\n",
    "        # Save results for clustered classic\n",
    "        if num_cluster not in clusteredResults[\"pca\"]:\n",
    "            clusteredResults[\"pca\"][num_cluster] = {\"losses\": [], \"accuracy\": []}\n",
    "\n",
    "        clusteredResults[\"pca\"][num_cluster][\"losses\"].extend(test_losses)\n",
    "        clusteredResults[\"pca\"][num_cluster][\"accuracy\"].extend(test_accuracies_classic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results (Non-Clustered): {'classic': {'NoCluster': {'losses': [0.5188619812011719], 'accuracy': [80.19]}}, 'pca': {'NoCluster': {'losses': [0.9589244445800781], 'accuracy': [82.98]}}, 'autoencoder': {}}\n",
      "Final Results (Clustered): {'classic': {2: {'losses': [0.6111913330078125, 0.5729868041992188, 0.5778576416015625, 0.5886122863769532], 'accuracy': [77.31, 78.64, 78.81, 78.37]}, 4: {'losses': [0.5569269927978515, 0.5164715148925781, 0.5319765411376953, 0.5280328765869141], 'accuracy': [79.38, 80.76, 80.22, 80.34]}, 6: {'losses': [0.4632906616210937, 0.4644641296386719, 0.4652772644042969, 0.44572009887695313], 'accuracy': [82.79, 82.6, 82.67, 83.38]}, 8: {'losses': [0.4280053955078125, 0.4304277587890625, 0.41870563354492185, 0.41287210998535157], 'accuracy': [84.37, 84.18, 84.51, 85.12]}, 10: {'losses': [0.4158003601074219, 0.4127583312988281, 0.4012933013916016, 0.39449208984375], 'accuracy': [84.9, 84.82, 85.3, 85.84]}}, 'pca': {2: {'losses': [0.9835310729980469, 0.9530772888183594, 0.9494121459960938, 0.9241965759277344], 'accuracy': [82.98, 78.18, 82.98, 78.18, 79.27, 82.98, 78.18, 79.27, 78.92, 82.98, 78.18, 79.27, 78.92, 79.95]}, 4: {'losses': [0.9022241882324219, 0.8804853637695312, 0.8694283996582032, 0.8524799865722656], 'accuracy': [82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 81.74, 82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 81.74, 80.67, 82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 81.74, 80.67, 81.83]}, 6: {'losses': [0.843761083984375, 0.8239902954101562, 0.8075113098144531, 0.7894371398925781], 'accuracy': [82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 81.74, 80.67, 81.83, 83.77, 82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 81.74, 80.67, 81.83, 83.77, 84.13, 82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 81.74, 80.67, 81.83, 83.77, 84.13, 84.63, 82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 81.74, 80.67, 81.83, 83.77, 84.13, 84.63, 84.85]}, 8: {'losses': [0.7941073120117188, 0.7832655151367187, 0.7690023315429687, 0.7600245178222657], 'accuracy': [82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 81.74, 80.67, 81.83, 83.77, 84.13, 84.63, 84.85, 85.56, 82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 81.74, 80.67, 81.83, 83.77, 84.13, 84.63, 84.85, 85.56, 85.05, 82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 81.74, 80.67, 81.83, 83.77, 84.13, 84.63, 84.85, 85.56, 85.05, 85.99, 82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 81.74, 80.67, 81.83, 83.77, 84.13, 84.63, 84.85, 85.56, 85.05, 85.99, 85.62]}, 10: {'losses': [0.7523985046386719, 0.7419623474121094, 0.7239168029785156, 0.7174635925292969], 'accuracy': [82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 81.74, 80.67, 81.83, 83.77, 84.13, 84.63, 84.85, 85.56, 85.05, 85.99, 85.62, 86.01, 82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 81.74, 80.67, 81.83, 83.77, 84.13, 84.63, 84.85, 85.56, 85.05, 85.99, 85.62, 86.01, 86.05, 82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 81.74, 80.67, 81.83, 83.77, 84.13, 84.63, 84.85, 85.56, 85.05, 85.99, 85.62, 86.01, 86.05, 86.49, 82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 81.74, 80.67, 81.83, 83.77, 84.13, 84.63, 84.85, 85.56, 85.05, 85.99, 85.62, 86.01, 86.05, 86.49, 86.49]}}, 'autoencoder': {}}\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Results (Non-Clustered):\", results)\n",
    "print(\"Final Results (Clustered):\", clusteredResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder\n",
    "trainingset_auto = reduced_train_loader_auto.dataset\n",
    "trial_model_auto_strong = MultilayerPerceptron()\n",
    "global_model_auto_strong = MultilayerPerceptron()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.311788\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 2.297354\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.281559\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 2.260314\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 2.218559\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 2.193289\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 2.171206\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 2.116008\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 2.084164\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 1.963554\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 1.980799\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 1.847897\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 1.837845\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 1.744823\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 1.735857\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 1.559035\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.543303\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 1.371148\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 1.232727\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 1.291346\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 1.324041\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 1.204301\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 1.190851\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 1.108628\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 1.187462\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.995786\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 1.120788\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 1.086503\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 1.023790\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 1.054452\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 1.059861\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 0.937672\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.002105\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 1.005561\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 1.014439\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 1.081030\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.860093\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 0.987080\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.787137\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 0.879051\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.965638\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 0.723544\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.864103\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 0.885257\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.885036\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 1.096074\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.869215\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 0.790466\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.586371\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 0.746935\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.728116\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 0.836634\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.780758\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 0.743279\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.728800\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.777796\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.759281\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 0.906071\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.900026\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 0.675147\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.803872\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 0.613192\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.674789\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 0.776516\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.914664\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.916591\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.862634\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 0.682478\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.715825\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 0.641428\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.840833\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 0.781655\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.732989\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 0.868692\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.650531\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.765894\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.679212\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 0.668856\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.798064\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 0.589771\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.733820\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 0.739429\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.607145\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 0.666686\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.602573\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.627300\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.641081\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 0.640306\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.813178\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 0.680481\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.526349\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 0.620189\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.731549\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 0.582765\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.650148\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.664173\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.634064\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 0.648967\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.739686\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 0.690954\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.553446\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 0.691501\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.760149\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 0.768468\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.797390\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.746775\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.599889\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 0.543633\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.617434\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 0.658816\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.621754\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 0.720619\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.823954\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 0.547180\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.540212\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.645893\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.641059\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 0.827641\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.803982\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 0.683072\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.707755\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 0.682606\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.515520\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 0.665280\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.699647\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.672949\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.731590\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 0.669489\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.672007\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 0.718324\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.805215\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 0.726031\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.692530\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 0.548358\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.497794\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.662400\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.612373\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 0.712769\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.662566\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 0.585116\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.662574\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 0.600140\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.507747\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 0.577812\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.464322\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.571176\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.600918\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 0.541950\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.719993\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 0.605883\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.555523\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 0.479437\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.639113\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 0.564705\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.616196\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.582068\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.729552\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 0.532840\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.479183\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 0.959672\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.658479\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 0.416722\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.703385\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 0.596104\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.598718\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.486415\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.475612\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 0.652871\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.564051\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 0.599822\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.710229\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 0.735889\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.703917\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 0.646219\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.698099\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.650963\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.721523\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 0.433142\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.560740\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 0.483366\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.580711\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 0.626084\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.580280\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 0.743878\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.487551\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.554071\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.566571\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 0.629746\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.759818\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 0.726774\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.501625\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 0.625221\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.486118\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 0.716244\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.633157\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.732035\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.474090\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 0.519338\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.367484\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 0.590158\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.599446\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 0.824153\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.689511\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 0.630669\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.523967\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.473595\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.667083\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 0.556161\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.517904\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 0.390027\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.597362\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 0.537766\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.645637\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 0.602707\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.469816\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.638454\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.516121\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 0.528292\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.505648\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 0.632319\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.748167\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 0.660272\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.541588\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 0.638003\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.720852\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.491934\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.497310\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 0.517936\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.649731\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 0.609063\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.714414\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 0.716055\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.591783\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 0.438930\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.548146\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.531497\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.713545\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 0.629277\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.594407\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 0.589588\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.668961\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 0.551221\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.710594\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 0.494810\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.498360\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.622920\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.598156\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 0.605419\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.497342\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 0.920292\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.607317\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 0.572758\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.421399\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 0.463318\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.399940\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.718756\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.697370\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 0.725984\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.760267\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 0.525110\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.492387\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 0.586879\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.614055\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 0.685226\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.568697\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.577842\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.455714\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 0.734283\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.488256\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 0.592110\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.559636\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 0.584479\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.670111\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 0.619237\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.602443\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.486175\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.494002\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 0.519554\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.511671\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 0.547022\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.537220\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 0.801897\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.472750\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 0.652698\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.610560\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.563980\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.507270\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 0.702315\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.610037\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 0.546160\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.589336\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 0.605334\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.539792\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 0.529339\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.629974\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.483913\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.537612\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 0.654153\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.663836\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 0.428750\n",
      "\n",
      "Test set: Avg. loss: 0.5554, Accuracy: 48246/60000 (80%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 2.279322\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 2.156003\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 2.109490\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 2.006161\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 1.800844\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 1.753901\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 1.738304\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 1.599473\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 1.630333\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 1.622503\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 1.497242\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 1.497798\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 1.446073\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 1.416022\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 1.259459\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 2.325688\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 2.067135\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 1.648685\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 1.060290\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.869213\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.959871\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.773338\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.526930\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.608200\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.615884\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.607344\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.638131\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.334685\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.690279\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.606546\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.535409\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.423350\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.527764\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.522197\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.507103\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.618083\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.299267\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.505903\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.531853\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.457812\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.461258\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.315224\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.515839\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.471306\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.448994\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.383376\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.360962\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.469297\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.312408\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.398457\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.430623\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.428941\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.275795\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.408264\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.230126\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 2.313073\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 2.183893\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 1.980855\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 1.774460\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 1.532289\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 1.580812\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 1.570667\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 1.361124\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 1.339759\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 1.069330\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 1.136018\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 1.126023\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 1.061750\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.949885\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.995380\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 1.033376\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.956463\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.918322\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 1.064127\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.769858\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.930693\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.814920\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.935244\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.750872\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.664503\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.839794\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.963913\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.827215\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.625509\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.518299\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.627035\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.722645\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.716640\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.651961\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.608997\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 2.281156\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 2.183605\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 2.077933\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 1.960615\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 1.580244\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 1.414396\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 1.317839\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 1.140226\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 1.153681\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.985725\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 1.143223\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.992867\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.875596\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.816583\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.909529\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.897070\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.909028\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.665092\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.969143\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.711580\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.713210\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.790784\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.710892\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.917381\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.643138\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.720277\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.696715\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.729161\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.666607\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.638324\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 2.282169\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 2.220270\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 2.169312\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 2.127840\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 2.005120\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 1.871469\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 1.829298\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 1.851876\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 1.658916\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 1.535202\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 1.444733\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 1.518804\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 1.269354\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 1.292430\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 1.240017\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.989532\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 1.080267\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 1.117519\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 1.176453\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 1.073224\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 1.071499\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.830094\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.803561\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 1.020225\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.856867\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 1.018956\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.870796\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.755448\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.716388\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.885011\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 2.371800\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 2.222866\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 2.075718\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 1.755535\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 1.636695\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 1.490567\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 1.305718\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 1.143956\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 1.318218\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 1.316740\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 1.198254\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 1.196298\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 1.029136\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 1.286969\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 1.126489\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 1.173519\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 1.125160\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 1.195727\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 1.098273\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.996716\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 2.318560\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 2.250316\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 2.172736\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 2.090582\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 2.008910\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 1.946322\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 1.772945\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 1.640180\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 1.568670\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 1.460589\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 1.579621\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 1.262388\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 1.453764\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 1.328887\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 1.310401\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 1.325356\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 1.161714\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 1.372773\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 1.216470\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 1.221642\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 1.123841\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 1.035095\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 1.228736\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 1.027061\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.941686\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 1.049824\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.913721\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 1.062023\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 1.006046\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.993889\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.889144\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 1.087904\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 1.081816\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.917989\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.922573\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.944362\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.942584\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.995822\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.994468\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.785674\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.800816\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.718861\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.851226\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.725759\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.651055\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.772391\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.856825\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.835055\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.888610\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.789917\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 2.286565\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 2.199796\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 2.053256\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 1.896929\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 1.840985\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 1.667555\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 1.784522\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 1.594676\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 1.487015\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 1.644578\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 1.472539\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 1.257939\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 1.221751\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 1.276953\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 1.167293\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 1.105687\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 1.227645\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.890465\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.912824\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.883410\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.848359\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.886916\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.918501\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.748919\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.805916\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.743374\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.673492\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.666378\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.645205\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.651505\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.742143\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.557244\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.666143\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.660669\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.750588\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 2.274944\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 2.211716\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 2.119386\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 2.000696\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 1.898564\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 1.906322\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 1.759642\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 1.897782\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 1.719160\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 1.667066\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 1.489890\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 1.557024\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 1.442198\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 1.301614\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 1.290220\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 1.206517\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 1.155326\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 1.164051\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 1.066433\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 1.044921\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 1.151536\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 1.152176\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 1.067886\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.926681\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.884402\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.867187\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.992204\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.942710\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.923127\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.939794\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.873544\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.925272\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.646409\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.764151\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.744657\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 2.276176\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 2.211550\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 2.059017\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 2.046206\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 1.750689\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 1.607407\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 1.525047\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 1.515868\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 1.298883\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 1.405027\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 1.416122\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 1.204566\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 1.354464\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 1.260897\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.863297\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 1.256100\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.941463\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 1.179681\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.956804\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.920670\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.866709\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.971004\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.770214\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.891195\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.948789\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 1.039981\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.695407\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.758105\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.709109\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.819491\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 1.040465\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.669726\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.827984\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.609512\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.912791\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.5333, Accuracy: 5193/10000 (52%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 1.503967\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 1.223030\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 1.306165\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 1.132094\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 1.202418\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 1.015559\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 1.049915\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 1.145972\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.923602\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 1.032592\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.966834\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.934823\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.984547\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.945118\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.914910\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 1.771944\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.571407\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.529150\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.436596\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.639910\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.348167\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.390650\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.383663\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.643122\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.476032\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.511056\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.397706\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.425162\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.306277\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.288430\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.410750\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.222562\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.392643\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.308850\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.382617\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.373791\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.284913\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.238736\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.335194\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.293834\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.344902\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.277421\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.249326\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.424571\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.257321\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.275180\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.418268\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.186955\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.327882\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.290799\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.312465\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.204556\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.394406\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.247733\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.361801\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 1.351692\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 1.104084\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 1.046698\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.762198\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.805609\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.736177\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.824725\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.748226\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.789285\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.741555\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.591688\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.725302\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.697836\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.637223\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.504312\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.536154\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.599243\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.639859\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.715703\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.534525\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.590625\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.657452\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.530338\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.420930\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.465707\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.546441\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.440075\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.558015\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.492877\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.695553\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.399799\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.595020\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.639733\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.489040\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.435656\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 1.738097\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.901675\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.737657\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.854827\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.827137\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.669370\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.638639\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.550076\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.734681\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.685888\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.519622\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.716179\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.799614\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.627915\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.613206\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.701039\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.787160\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.532646\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.671689\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.791327\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.390687\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.608136\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.440327\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.570787\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.605306\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.473807\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.596604\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.559138\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.464103\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.468528\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 1.583507\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 1.190757\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.919946\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.992981\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.756169\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.755618\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 1.071552\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.815373\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.687622\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.824869\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.923665\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.679895\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.902306\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.753639\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.669226\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.836252\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.771986\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.591566\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.663415\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.789199\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.646715\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.722167\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.577998\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.682673\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 1.007232\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.626331\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.547846\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.638762\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.721275\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.664178\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 1.398697\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.993635\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 1.001876\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.896887\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.908714\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.792512\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.694125\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.889993\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.900752\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.914665\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.758252\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.755582\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.961304\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.710112\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.603549\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.780636\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.814101\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.682609\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.640018\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.685399\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 1.381459\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 1.294465\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 1.036603\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 1.077782\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.886926\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.959233\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 1.011784\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 1.019612\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.806507\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.840078\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 1.094290\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.993301\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.821320\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.880983\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.718388\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.850249\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.827990\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.883643\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.706373\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.893677\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.796402\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 1.041608\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.812175\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.660381\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.787286\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.735653\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.759146\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.789489\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.790428\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.661897\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.715121\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.683342\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.762592\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.663671\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.694374\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.586617\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.705769\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.582911\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.731897\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.822239\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.941350\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.838741\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.831027\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.756259\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.640763\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.805411\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.624842\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.543063\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.539312\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.724603\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 1.960074\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 1.151514\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.909426\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.876596\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.672442\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.749628\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.737427\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.660100\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.865942\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.700400\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.644214\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.607642\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.655891\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.808472\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.578540\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.710247\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.744547\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.594667\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.670693\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.560983\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.595276\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.770029\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.537308\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.627194\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.690423\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.571473\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.528608\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.567988\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.555900\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.615300\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.464598\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.565798\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.544082\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.443930\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.450885\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 1.539462\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 1.144542\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 1.221900\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 1.114298\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.920234\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 1.044070\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.910018\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.965034\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.859525\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.819323\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.850225\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.781613\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.819199\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.857960\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.645689\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.841485\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.764444\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.910076\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.622705\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.710337\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.666325\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.605281\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.882790\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.629460\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.579115\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.699729\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.778200\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.710073\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.585919\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.684323\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.734435\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.562376\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.611165\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.634958\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.629383\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 1.576117\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 1.111001\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.999439\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.992044\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.839029\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.828309\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.883859\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.721102\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.804234\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.781631\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.774501\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.753817\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.647798\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.643334\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.854321\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.644791\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.739286\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.707659\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.756447\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.646994\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.661244\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.707893\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.496948\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.826717\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.609507\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.522529\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.620317\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.573201\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.625718\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.556535\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.630408\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.599523\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.696576\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.673494\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.632061\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.1577, Accuracy: 6091/10000 (61%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 1.089477\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.846156\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.973110\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.836366\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.993309\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.775396\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.861025\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.740627\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.718272\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.645753\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.983453\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.838668\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.762200\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.750174\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.796122\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 1.343166\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.414610\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.277892\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.359280\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.471280\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.267130\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.393640\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.276339\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.265272\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.272467\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.438421\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.353927\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.390377\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.149852\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.391800\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.267499\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.228757\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.285543\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.423826\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.301513\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.189317\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.305300\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.302942\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.318034\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.308155\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.239464\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.298046\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.181885\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.262957\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.326545\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.254720\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.295752\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.291146\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.245288\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.280940\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.208876\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.223049\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.252777\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.232981\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.219737\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.803232\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.493433\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.550396\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.496993\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.574563\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.474490\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.492190\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.540632\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.613396\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.550368\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.486138\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.491123\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.441389\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.545656\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.399360\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.424374\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.651097\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.467384\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.544186\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.441656\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.522920\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.438855\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.484004\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.688921\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.534206\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.354609\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.385300\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.386170\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.341536\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.574796\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.461386\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.225001\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.592493\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.463025\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.458977\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 1.061812\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.469960\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.403816\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.551334\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.517164\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.454368\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.464117\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.655694\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.562802\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.489462\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.620673\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.433580\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.451992\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.408531\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.464759\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.450152\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.437978\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.317911\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.362931\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.413439\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.543824\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.544062\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.527818\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.394093\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.375042\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.512741\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.382392\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.418862\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.632311\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.440299\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.872500\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.736356\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.670131\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.612371\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.559241\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.618343\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.632588\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.719693\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.666699\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.731265\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.567479\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.694355\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.657335\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.677262\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.488769\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.620361\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.549773\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.470804\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.486147\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.623776\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.509776\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.614326\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.502719\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.577128\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.580973\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.385544\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.586894\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.561450\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.653608\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.620716\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.806588\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.753509\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.646111\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.719581\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.618080\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.642923\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.671704\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.749253\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.590671\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.566353\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.697487\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.443334\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.547551\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.569147\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.626235\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.634053\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.526003\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.551853\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.444868\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.464851\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.962668\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.771569\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.949709\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.780543\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.743205\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.790685\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.541203\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.743557\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.805292\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.659475\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.641190\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.865735\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.782537\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.793222\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.820062\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.631031\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.695801\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.695246\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.664342\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.735437\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.769887\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.659050\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.811332\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.606233\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.505865\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.674279\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.671346\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.648103\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.610505\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.651005\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.657902\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.586966\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.694759\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.637480\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.621009\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.857831\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.498178\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.517744\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.783251\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.516476\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.703519\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.573674\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.715088\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.556744\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.548946\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.583872\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.602112\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.723611\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.554381\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.727754\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 1.278503\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.575296\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.618231\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.540081\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.545731\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.683811\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.457698\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.688553\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.616858\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.675557\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.557153\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.538208\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.651010\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.563778\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.509715\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.529764\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.674433\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.479221\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.601083\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.459480\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.477896\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.565804\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.592011\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.359149\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.442216\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.338629\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.572597\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.493909\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.415989\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.422266\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.393893\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.463422\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.529185\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.368426\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.456392\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.910788\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.711230\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.693061\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.686518\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.644764\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.693759\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.712950\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.534283\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.553701\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.646976\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.567643\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.633629\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.628115\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.703465\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.544160\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.634415\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.702365\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.689985\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.685250\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.583414\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.527061\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.537148\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.716823\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.676386\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.554284\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.404815\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.684817\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.565785\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.630213\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.575668\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.556502\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.491638\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.640711\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.584344\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.632572\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.903262\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.678893\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.737972\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.591772\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.531561\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.568556\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.628949\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.614249\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.512292\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.505543\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.615986\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.561252\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.487347\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.643674\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.595008\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.447427\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.630165\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.598680\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.611242\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.532424\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.467752\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.476697\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.525038\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.537436\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.480146\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.533615\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.604494\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.440475\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.450009\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.471400\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.523039\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.521742\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.452817\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.411615\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.622375\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.0149, Accuracy: 6603/10000 (66%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.961681\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.816284\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.681605\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.799108\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.627156\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.661960\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.689056\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.691077\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.689795\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.709927\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.809812\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.631189\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.719991\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.700453\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.732428\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.931554\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.195059\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.328104\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.244255\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.259391\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.310184\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.199761\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.237400\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.259373\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.240865\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.266089\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.369934\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.261969\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.161739\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.301675\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.334089\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.316118\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.338162\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.374351\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.244994\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.208865\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.217630\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.177813\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.324260\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.232097\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.145151\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.293891\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.214918\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.190675\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.241808\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.239202\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.250327\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.194158\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.226034\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.218715\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.335105\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.274186\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.186553\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.292224\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.196541\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.737527\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.610663\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.392531\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.497518\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.631166\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.455043\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.566270\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.497797\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.485398\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.358061\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.483732\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.362593\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.421823\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.607426\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.438703\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.307682\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.385881\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.541368\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.367651\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.475672\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.559174\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.352064\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.466851\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.507291\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.445067\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.382315\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.389089\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.348312\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.490041\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.527399\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.375951\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.364656\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.545549\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.328574\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.495776\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.814745\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.458151\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.462437\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.517651\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.409718\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.569514\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.501298\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.483425\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.438776\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.528786\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.405216\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.376506\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.462793\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.588008\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.486715\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.541906\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.424355\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.539186\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.338558\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.354785\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.427032\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.422853\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.344674\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.415220\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.489520\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.382188\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.793199\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.431302\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.347399\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.506222\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.648602\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.433711\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.626497\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.591966\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.584596\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.524720\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.665589\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.702582\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.395818\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.520900\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.474243\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.508688\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.573170\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.446967\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.433470\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.372537\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.546853\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.574598\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.421304\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.521526\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.542489\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.469749\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.460525\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.658534\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.571439\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.690416\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.580696\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.426327\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.540364\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.633866\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.647430\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.575196\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.648984\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.599585\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.775856\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.575311\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.593257\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.519874\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.572804\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.725066\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.496395\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.555317\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.591059\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.566376\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.509207\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.758574\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.512343\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.643179\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.535100\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.525761\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.733545\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.609723\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.818974\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.587390\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.762332\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.717900\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.718415\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.781152\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.618501\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.697199\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.609930\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.589566\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.735018\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.452501\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.821979\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.674073\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.548395\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.746681\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.639377\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.643904\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.585283\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.787297\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.623053\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.564939\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.435494\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.685943\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.586721\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.574663\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.538837\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.598519\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.654442\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.470297\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.678097\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.569384\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.550962\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.679138\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.505095\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.533526\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.629643\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.611832\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.758436\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.737317\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.668434\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.611370\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.498545\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.667923\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.669599\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.647775\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.559878\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.658154\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 1.060098\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.528292\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.627541\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.578691\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.493822\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.480862\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.511276\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.485649\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.479018\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.500602\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.605963\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.517165\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.459079\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.520970\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.335866\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.455670\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.358230\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.442155\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.516941\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.382190\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.470575\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.356454\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.519097\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.403082\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.485539\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.328524\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.444260\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.394761\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.486252\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.370140\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.333860\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.350846\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.459742\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.357567\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.478733\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.846814\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.614275\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.652614\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.830564\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.701990\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.722225\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.605303\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.616874\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.490359\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.496334\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.541525\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.512540\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.456639\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.511545\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.535070\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.706462\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.683361\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.612752\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.534137\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.580911\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.567994\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.550933\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.516998\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.589574\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.543734\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.538841\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.586209\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.500554\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.382101\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.635663\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.623706\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.526794\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.574907\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.587596\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.481622\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.708253\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.633081\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.583774\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.592649\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.623927\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.645518\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.531597\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.649689\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.333170\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.507306\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.487898\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.536014\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.470617\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.486276\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.578117\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.573137\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.459850\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.560495\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.437483\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.516404\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.515045\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.543722\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.541185\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.435647\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.561741\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.518564\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.463230\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.493660\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.414651\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.348060\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.672427\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.372146\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.417987\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.448534\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.510222\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9626, Accuracy: 6905/10000 (69%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/27366 (0%)]\tLoss: 0.681009\n",
      "Train Epoch: 1 [1000/27366 (4%)]\tLoss: 0.796007\n",
      "Train Epoch: 1 [2000/27366 (7%)]\tLoss: 0.859324\n",
      "Train Epoch: 1 [3000/27366 (11%)]\tLoss: 0.535463\n",
      "Train Epoch: 1 [4000/27366 (15%)]\tLoss: 0.748250\n",
      "Train Epoch: 1 [5000/27366 (18%)]\tLoss: 0.757138\n",
      "Train Epoch: 1 [6000/27366 (22%)]\tLoss: 0.699675\n",
      "Train Epoch: 1 [7000/27366 (26%)]\tLoss: 0.679844\n",
      "Train Epoch: 1 [8000/27366 (29%)]\tLoss: 0.601765\n",
      "Train Epoch: 1 [9000/27366 (33%)]\tLoss: 0.604607\n",
      "Train Epoch: 1 [10000/27366 (36%)]\tLoss: 0.437984\n",
      "Train Epoch: 1 [11000/27366 (40%)]\tLoss: 0.806632\n",
      "Train Epoch: 1 [12000/27366 (44%)]\tLoss: 0.682859\n",
      "Train Epoch: 1 [13000/27366 (47%)]\tLoss: 0.655173\n",
      "Train Epoch: 1 [14000/27366 (51%)]\tLoss: 0.619416\n",
      "Train Epoch: 1 [15000/27366 (55%)]\tLoss: 0.708872\n",
      "Train Epoch: 1 [16000/27366 (58%)]\tLoss: 0.691254\n",
      "Train Epoch: 1 [17000/27366 (62%)]\tLoss: 0.742971\n",
      "Train Epoch: 1 [18000/27366 (66%)]\tLoss: 0.574042\n",
      "Train Epoch: 1 [19000/27366 (69%)]\tLoss: 0.633715\n",
      "Train Epoch: 1 [20000/27366 (73%)]\tLoss: 0.706900\n",
      "Train Epoch: 1 [21000/27366 (77%)]\tLoss: 0.521596\n",
      "Train Epoch: 1 [22000/27366 (80%)]\tLoss: 0.690817\n",
      "Train Epoch: 1 [23000/27366 (84%)]\tLoss: 0.498596\n",
      "Train Epoch: 1 [24000/27366 (88%)]\tLoss: 0.657000\n",
      "Train Epoch: 1 [25000/27366 (91%)]\tLoss: 0.430023\n",
      "Train Epoch: 1 [26000/27366 (95%)]\tLoss: 0.604407\n",
      "Train Epoch: 1 [27000/27366 (99%)]\tLoss: 0.657818\n",
      "Train Epoch: 2 [0/27366 (0%)]\tLoss: 0.683274\n",
      "Train Epoch: 2 [1000/27366 (4%)]\tLoss: 0.800451\n",
      "Train Epoch: 2 [2000/27366 (7%)]\tLoss: 0.562442\n",
      "Train Epoch: 2 [3000/27366 (11%)]\tLoss: 0.599527\n",
      "Train Epoch: 2 [4000/27366 (15%)]\tLoss: 0.729158\n",
      "Train Epoch: 2 [5000/27366 (18%)]\tLoss: 0.660916\n",
      "Train Epoch: 2 [6000/27366 (22%)]\tLoss: 0.549012\n",
      "Train Epoch: 2 [7000/27366 (26%)]\tLoss: 0.428772\n",
      "Train Epoch: 2 [8000/27366 (29%)]\tLoss: 0.694925\n",
      "Train Epoch: 2 [9000/27366 (33%)]\tLoss: 0.675389\n",
      "Train Epoch: 2 [10000/27366 (36%)]\tLoss: 0.539392\n",
      "Train Epoch: 2 [11000/27366 (40%)]\tLoss: 0.680386\n",
      "Train Epoch: 2 [12000/27366 (44%)]\tLoss: 0.628614\n",
      "Train Epoch: 2 [13000/27366 (47%)]\tLoss: 0.736600\n",
      "Train Epoch: 2 [14000/27366 (51%)]\tLoss: 0.689713\n",
      "Train Epoch: 2 [15000/27366 (55%)]\tLoss: 0.501018\n",
      "Train Epoch: 2 [16000/27366 (58%)]\tLoss: 0.528676\n",
      "Train Epoch: 2 [17000/27366 (62%)]\tLoss: 0.627688\n",
      "Train Epoch: 2 [18000/27366 (66%)]\tLoss: 0.641440\n",
      "Train Epoch: 2 [19000/27366 (69%)]\tLoss: 0.566487\n",
      "Train Epoch: 2 [20000/27366 (73%)]\tLoss: 0.682512\n",
      "Train Epoch: 2 [21000/27366 (77%)]\tLoss: 0.471662\n",
      "Train Epoch: 2 [22000/27366 (80%)]\tLoss: 0.542139\n",
      "Train Epoch: 2 [23000/27366 (84%)]\tLoss: 0.480757\n",
      "Train Epoch: 2 [24000/27366 (88%)]\tLoss: 0.620244\n",
      "Train Epoch: 2 [25000/27366 (91%)]\tLoss: 0.443702\n",
      "Train Epoch: 2 [26000/27366 (95%)]\tLoss: 0.644716\n",
      "Train Epoch: 2 [27000/27366 (99%)]\tLoss: 0.665169\n",
      "Train Epoch: 3 [0/27366 (0%)]\tLoss: 0.630697\n",
      "Train Epoch: 3 [1000/27366 (4%)]\tLoss: 0.572588\n",
      "Train Epoch: 3 [2000/27366 (7%)]\tLoss: 0.427966\n",
      "Train Epoch: 3 [3000/27366 (11%)]\tLoss: 0.611196\n",
      "Train Epoch: 3 [4000/27366 (15%)]\tLoss: 0.867105\n",
      "Train Epoch: 3 [5000/27366 (18%)]\tLoss: 0.684112\n",
      "Train Epoch: 3 [6000/27366 (22%)]\tLoss: 0.494131\n",
      "Train Epoch: 3 [7000/27366 (26%)]\tLoss: 0.628841\n",
      "Train Epoch: 3 [8000/27366 (29%)]\tLoss: 0.576124\n",
      "Train Epoch: 3 [9000/27366 (33%)]\tLoss: 0.427214\n",
      "Train Epoch: 3 [10000/27366 (36%)]\tLoss: 0.635975\n",
      "Train Epoch: 3 [11000/27366 (40%)]\tLoss: 0.538629\n",
      "Train Epoch: 3 [12000/27366 (44%)]\tLoss: 0.540352\n",
      "Train Epoch: 3 [13000/27366 (47%)]\tLoss: 0.726610\n",
      "Train Epoch: 3 [14000/27366 (51%)]\tLoss: 0.592267\n",
      "Train Epoch: 3 [15000/27366 (55%)]\tLoss: 0.685986\n",
      "Train Epoch: 3 [16000/27366 (58%)]\tLoss: 0.531290\n",
      "Train Epoch: 3 [17000/27366 (62%)]\tLoss: 0.541344\n",
      "Train Epoch: 3 [18000/27366 (66%)]\tLoss: 0.561667\n",
      "Train Epoch: 3 [19000/27366 (69%)]\tLoss: 0.563235\n",
      "Train Epoch: 3 [20000/27366 (73%)]\tLoss: 0.525496\n",
      "Train Epoch: 3 [21000/27366 (77%)]\tLoss: 0.546998\n",
      "Train Epoch: 3 [22000/27366 (80%)]\tLoss: 0.516585\n",
      "Train Epoch: 3 [23000/27366 (84%)]\tLoss: 0.603790\n",
      "Train Epoch: 3 [24000/27366 (88%)]\tLoss: 0.460012\n",
      "Train Epoch: 3 [25000/27366 (91%)]\tLoss: 0.666699\n",
      "Train Epoch: 3 [26000/27366 (95%)]\tLoss: 0.566728\n",
      "Train Epoch: 3 [27000/27366 (99%)]\tLoss: 0.588691\n",
      "Train Epoch: 4 [0/27366 (0%)]\tLoss: 0.565921\n",
      "Train Epoch: 4 [1000/27366 (4%)]\tLoss: 0.564722\n",
      "Train Epoch: 4 [2000/27366 (7%)]\tLoss: 0.514166\n",
      "Train Epoch: 4 [3000/27366 (11%)]\tLoss: 0.637560\n",
      "Train Epoch: 4 [4000/27366 (15%)]\tLoss: 0.576964\n",
      "Train Epoch: 4 [5000/27366 (18%)]\tLoss: 0.512948\n",
      "Train Epoch: 4 [6000/27366 (22%)]\tLoss: 0.576482\n",
      "Train Epoch: 4 [7000/27366 (26%)]\tLoss: 0.636697\n",
      "Train Epoch: 4 [8000/27366 (29%)]\tLoss: 0.588475\n",
      "Train Epoch: 4 [9000/27366 (33%)]\tLoss: 0.599209\n",
      "Train Epoch: 4 [10000/27366 (36%)]\tLoss: 0.655334\n",
      "Train Epoch: 4 [11000/27366 (40%)]\tLoss: 0.594223\n",
      "Train Epoch: 4 [12000/27366 (44%)]\tLoss: 0.624502\n",
      "Train Epoch: 4 [13000/27366 (47%)]\tLoss: 0.691689\n",
      "Train Epoch: 4 [14000/27366 (51%)]\tLoss: 0.478058\n",
      "Train Epoch: 4 [15000/27366 (55%)]\tLoss: 0.523506\n",
      "Train Epoch: 4 [16000/27366 (58%)]\tLoss: 0.543795\n",
      "Train Epoch: 4 [17000/27366 (62%)]\tLoss: 0.645244\n",
      "Train Epoch: 4 [18000/27366 (66%)]\tLoss: 0.618650\n",
      "Train Epoch: 4 [19000/27366 (69%)]\tLoss: 0.603798\n",
      "Train Epoch: 4 [20000/27366 (73%)]\tLoss: 0.335116\n",
      "Train Epoch: 4 [21000/27366 (77%)]\tLoss: 0.477129\n",
      "Train Epoch: 4 [22000/27366 (80%)]\tLoss: 0.591901\n",
      "Train Epoch: 4 [23000/27366 (84%)]\tLoss: 0.630873\n",
      "Train Epoch: 4 [24000/27366 (88%)]\tLoss: 0.526410\n",
      "Train Epoch: 4 [25000/27366 (91%)]\tLoss: 0.403128\n",
      "Train Epoch: 4 [26000/27366 (95%)]\tLoss: 0.631815\n",
      "Train Epoch: 4 [27000/27366 (99%)]\tLoss: 0.522877\n",
      "Train Epoch: 5 [0/27366 (0%)]\tLoss: 0.478428\n",
      "Train Epoch: 5 [1000/27366 (4%)]\tLoss: 0.647124\n",
      "Train Epoch: 5 [2000/27366 (7%)]\tLoss: 0.442620\n",
      "Train Epoch: 5 [3000/27366 (11%)]\tLoss: 0.700737\n",
      "Train Epoch: 5 [4000/27366 (15%)]\tLoss: 0.549036\n",
      "Train Epoch: 5 [5000/27366 (18%)]\tLoss: 0.462475\n",
      "Train Epoch: 5 [6000/27366 (22%)]\tLoss: 0.600282\n",
      "Train Epoch: 5 [7000/27366 (26%)]\tLoss: 0.651903\n",
      "Train Epoch: 5 [8000/27366 (29%)]\tLoss: 0.720509\n",
      "Train Epoch: 5 [9000/27366 (33%)]\tLoss: 0.561107\n",
      "Train Epoch: 5 [10000/27366 (36%)]\tLoss: 0.378722\n",
      "Train Epoch: 5 [11000/27366 (40%)]\tLoss: 0.692230\n",
      "Train Epoch: 5 [12000/27366 (44%)]\tLoss: 0.704696\n",
      "Train Epoch: 5 [13000/27366 (47%)]\tLoss: 0.667945\n",
      "Train Epoch: 5 [14000/27366 (51%)]\tLoss: 0.528704\n",
      "Train Epoch: 5 [15000/27366 (55%)]\tLoss: 0.575286\n",
      "Train Epoch: 5 [16000/27366 (58%)]\tLoss: 0.504366\n",
      "Train Epoch: 5 [17000/27366 (62%)]\tLoss: 0.628737\n",
      "Train Epoch: 5 [18000/27366 (66%)]\tLoss: 0.351597\n",
      "Train Epoch: 5 [19000/27366 (69%)]\tLoss: 0.796261\n",
      "Train Epoch: 5 [20000/27366 (73%)]\tLoss: 0.568780\n",
      "Train Epoch: 5 [21000/27366 (77%)]\tLoss: 0.630893\n",
      "Train Epoch: 5 [22000/27366 (80%)]\tLoss: 0.571005\n",
      "Train Epoch: 5 [23000/27366 (84%)]\tLoss: 0.707369\n",
      "Train Epoch: 5 [24000/27366 (88%)]\tLoss: 0.517007\n",
      "Train Epoch: 5 [25000/27366 (91%)]\tLoss: 0.560885\n",
      "Train Epoch: 5 [26000/27366 (95%)]\tLoss: 0.558273\n",
      "Train Epoch: 5 [27000/27366 (99%)]\tLoss: 0.542773\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/32634 (0%)]\tLoss: 0.789302\n",
      "Train Epoch: 1 [1000/32634 (3%)]\tLoss: 0.693156\n",
      "Train Epoch: 1 [2000/32634 (6%)]\tLoss: 0.635522\n",
      "Train Epoch: 1 [3000/32634 (9%)]\tLoss: 0.859938\n",
      "Train Epoch: 1 [4000/32634 (12%)]\tLoss: 0.742335\n",
      "Train Epoch: 1 [5000/32634 (15%)]\tLoss: 0.745462\n",
      "Train Epoch: 1 [6000/32634 (18%)]\tLoss: 0.751620\n",
      "Train Epoch: 1 [7000/32634 (21%)]\tLoss: 0.455707\n",
      "Train Epoch: 1 [8000/32634 (24%)]\tLoss: 0.518489\n",
      "Train Epoch: 1 [9000/32634 (28%)]\tLoss: 0.667292\n",
      "Train Epoch: 1 [10000/32634 (31%)]\tLoss: 0.630872\n",
      "Train Epoch: 1 [11000/32634 (34%)]\tLoss: 0.671562\n",
      "Train Epoch: 1 [12000/32634 (37%)]\tLoss: 0.565542\n",
      "Train Epoch: 1 [13000/32634 (40%)]\tLoss: 0.761413\n",
      "Train Epoch: 1 [14000/32634 (43%)]\tLoss: 0.608647\n",
      "Train Epoch: 1 [15000/32634 (46%)]\tLoss: 0.694848\n",
      "Train Epoch: 1 [16000/32634 (49%)]\tLoss: 0.527190\n",
      "Train Epoch: 1 [17000/32634 (52%)]\tLoss: 0.526206\n",
      "Train Epoch: 1 [18000/32634 (55%)]\tLoss: 0.705762\n",
      "Train Epoch: 1 [19000/32634 (58%)]\tLoss: 0.683350\n",
      "Train Epoch: 1 [20000/32634 (61%)]\tLoss: 0.627131\n",
      "Train Epoch: 1 [21000/32634 (64%)]\tLoss: 0.780230\n",
      "Train Epoch: 1 [22000/32634 (67%)]\tLoss: 0.668264\n",
      "Train Epoch: 1 [23000/32634 (70%)]\tLoss: 0.695610\n",
      "Train Epoch: 1 [24000/32634 (73%)]\tLoss: 0.464752\n",
      "Train Epoch: 1 [25000/32634 (76%)]\tLoss: 0.714138\n",
      "Train Epoch: 1 [26000/32634 (80%)]\tLoss: 0.545668\n",
      "Train Epoch: 1 [27000/32634 (83%)]\tLoss: 0.686985\n",
      "Train Epoch: 1 [28000/32634 (86%)]\tLoss: 0.619539\n",
      "Train Epoch: 1 [29000/32634 (89%)]\tLoss: 0.546017\n",
      "Train Epoch: 1 [30000/32634 (92%)]\tLoss: 0.608551\n",
      "Train Epoch: 1 [31000/32634 (95%)]\tLoss: 0.646158\n",
      "Train Epoch: 1 [32000/32634 (98%)]\tLoss: 0.471531\n",
      "Train Epoch: 2 [0/32634 (0%)]\tLoss: 0.689251\n",
      "Train Epoch: 2 [1000/32634 (3%)]\tLoss: 0.588171\n",
      "Train Epoch: 2 [2000/32634 (6%)]\tLoss: 0.638962\n",
      "Train Epoch: 2 [3000/32634 (9%)]\tLoss: 0.655847\n",
      "Train Epoch: 2 [4000/32634 (12%)]\tLoss: 0.640962\n",
      "Train Epoch: 2 [5000/32634 (15%)]\tLoss: 0.750570\n",
      "Train Epoch: 2 [6000/32634 (18%)]\tLoss: 0.604025\n",
      "Train Epoch: 2 [7000/32634 (21%)]\tLoss: 0.582073\n",
      "Train Epoch: 2 [8000/32634 (24%)]\tLoss: 0.549313\n",
      "Train Epoch: 2 [9000/32634 (28%)]\tLoss: 0.669595\n",
      "Train Epoch: 2 [10000/32634 (31%)]\tLoss: 0.520415\n",
      "Train Epoch: 2 [11000/32634 (34%)]\tLoss: 0.590045\n",
      "Train Epoch: 2 [12000/32634 (37%)]\tLoss: 0.744316\n",
      "Train Epoch: 2 [13000/32634 (40%)]\tLoss: 0.679452\n",
      "Train Epoch: 2 [14000/32634 (43%)]\tLoss: 0.625607\n",
      "Train Epoch: 2 [15000/32634 (46%)]\tLoss: 0.502415\n",
      "Train Epoch: 2 [16000/32634 (49%)]\tLoss: 0.466474\n",
      "Train Epoch: 2 [17000/32634 (52%)]\tLoss: 0.647995\n",
      "Train Epoch: 2 [18000/32634 (55%)]\tLoss: 0.582700\n",
      "Train Epoch: 2 [19000/32634 (58%)]\tLoss: 0.767756\n",
      "Train Epoch: 2 [20000/32634 (61%)]\tLoss: 0.478711\n",
      "Train Epoch: 2 [21000/32634 (64%)]\tLoss: 0.546169\n",
      "Train Epoch: 2 [22000/32634 (67%)]\tLoss: 0.835374\n",
      "Train Epoch: 2 [23000/32634 (70%)]\tLoss: 0.688059\n",
      "Train Epoch: 2 [24000/32634 (73%)]\tLoss: 0.680260\n",
      "Train Epoch: 2 [25000/32634 (76%)]\tLoss: 0.631768\n",
      "Train Epoch: 2 [26000/32634 (80%)]\tLoss: 0.646055\n",
      "Train Epoch: 2 [27000/32634 (83%)]\tLoss: 0.441467\n",
      "Train Epoch: 2 [28000/32634 (86%)]\tLoss: 0.513965\n",
      "Train Epoch: 2 [29000/32634 (89%)]\tLoss: 0.576447\n",
      "Train Epoch: 2 [30000/32634 (92%)]\tLoss: 0.608282\n",
      "Train Epoch: 2 [31000/32634 (95%)]\tLoss: 0.520585\n",
      "Train Epoch: 2 [32000/32634 (98%)]\tLoss: 0.708275\n",
      "Train Epoch: 3 [0/32634 (0%)]\tLoss: 0.671955\n",
      "Train Epoch: 3 [1000/32634 (3%)]\tLoss: 0.615070\n",
      "Train Epoch: 3 [2000/32634 (6%)]\tLoss: 0.565998\n",
      "Train Epoch: 3 [3000/32634 (9%)]\tLoss: 0.776306\n",
      "Train Epoch: 3 [4000/32634 (12%)]\tLoss: 0.519970\n",
      "Train Epoch: 3 [5000/32634 (15%)]\tLoss: 0.594807\n",
      "Train Epoch: 3 [6000/32634 (18%)]\tLoss: 0.541303\n",
      "Train Epoch: 3 [7000/32634 (21%)]\tLoss: 0.535483\n",
      "Train Epoch: 3 [8000/32634 (24%)]\tLoss: 0.556062\n",
      "Train Epoch: 3 [9000/32634 (28%)]\tLoss: 0.726088\n",
      "Train Epoch: 3 [10000/32634 (31%)]\tLoss: 0.591567\n",
      "Train Epoch: 3 [11000/32634 (34%)]\tLoss: 0.447155\n",
      "Train Epoch: 3 [12000/32634 (37%)]\tLoss: 0.599365\n",
      "Train Epoch: 3 [13000/32634 (40%)]\tLoss: 0.670015\n",
      "Train Epoch: 3 [14000/32634 (43%)]\tLoss: 0.615362\n",
      "Train Epoch: 3 [15000/32634 (46%)]\tLoss: 0.569704\n",
      "Train Epoch: 3 [16000/32634 (49%)]\tLoss: 0.555712\n",
      "Train Epoch: 3 [17000/32634 (52%)]\tLoss: 0.468905\n",
      "Train Epoch: 3 [18000/32634 (55%)]\tLoss: 0.498168\n",
      "Train Epoch: 3 [19000/32634 (58%)]\tLoss: 0.434488\n",
      "Train Epoch: 3 [20000/32634 (61%)]\tLoss: 0.675228\n",
      "Train Epoch: 3 [21000/32634 (64%)]\tLoss: 0.512430\n",
      "Train Epoch: 3 [22000/32634 (67%)]\tLoss: 0.469639\n",
      "Train Epoch: 3 [23000/32634 (70%)]\tLoss: 0.598900\n",
      "Train Epoch: 3 [24000/32634 (73%)]\tLoss: 0.607624\n",
      "Train Epoch: 3 [25000/32634 (76%)]\tLoss: 0.447604\n",
      "Train Epoch: 3 [26000/32634 (80%)]\tLoss: 0.709177\n",
      "Train Epoch: 3 [27000/32634 (83%)]\tLoss: 0.622718\n",
      "Train Epoch: 3 [28000/32634 (86%)]\tLoss: 0.573863\n",
      "Train Epoch: 3 [29000/32634 (89%)]\tLoss: 0.656788\n",
      "Train Epoch: 3 [30000/32634 (92%)]\tLoss: 0.604363\n",
      "Train Epoch: 3 [31000/32634 (95%)]\tLoss: 0.486541\n",
      "Train Epoch: 3 [32000/32634 (98%)]\tLoss: 0.691988\n",
      "Train Epoch: 4 [0/32634 (0%)]\tLoss: 0.523181\n",
      "Train Epoch: 4 [1000/32634 (3%)]\tLoss: 0.492686\n",
      "Train Epoch: 4 [2000/32634 (6%)]\tLoss: 0.707797\n",
      "Train Epoch: 4 [3000/32634 (9%)]\tLoss: 0.613958\n",
      "Train Epoch: 4 [4000/32634 (12%)]\tLoss: 0.445034\n",
      "Train Epoch: 4 [5000/32634 (15%)]\tLoss: 0.613394\n",
      "Train Epoch: 4 [6000/32634 (18%)]\tLoss: 0.519621\n",
      "Train Epoch: 4 [7000/32634 (21%)]\tLoss: 0.722016\n",
      "Train Epoch: 4 [8000/32634 (24%)]\tLoss: 0.660986\n",
      "Train Epoch: 4 [9000/32634 (28%)]\tLoss: 0.565442\n",
      "Train Epoch: 4 [10000/32634 (31%)]\tLoss: 0.535584\n",
      "Train Epoch: 4 [11000/32634 (34%)]\tLoss: 0.647188\n",
      "Train Epoch: 4 [12000/32634 (37%)]\tLoss: 0.633314\n",
      "Train Epoch: 4 [13000/32634 (40%)]\tLoss: 0.690962\n",
      "Train Epoch: 4 [14000/32634 (43%)]\tLoss: 0.555892\n",
      "Train Epoch: 4 [15000/32634 (46%)]\tLoss: 0.501181\n",
      "Train Epoch: 4 [16000/32634 (49%)]\tLoss: 0.460526\n",
      "Train Epoch: 4 [17000/32634 (52%)]\tLoss: 0.623865\n",
      "Train Epoch: 4 [18000/32634 (55%)]\tLoss: 0.426532\n",
      "Train Epoch: 4 [19000/32634 (58%)]\tLoss: 0.536630\n",
      "Train Epoch: 4 [20000/32634 (61%)]\tLoss: 0.586164\n",
      "Train Epoch: 4 [21000/32634 (64%)]\tLoss: 0.550792\n",
      "Train Epoch: 4 [22000/32634 (67%)]\tLoss: 0.678741\n",
      "Train Epoch: 4 [23000/32634 (70%)]\tLoss: 0.540775\n",
      "Train Epoch: 4 [24000/32634 (73%)]\tLoss: 0.517474\n",
      "Train Epoch: 4 [25000/32634 (76%)]\tLoss: 0.639289\n",
      "Train Epoch: 4 [26000/32634 (80%)]\tLoss: 0.574522\n",
      "Train Epoch: 4 [27000/32634 (83%)]\tLoss: 0.437681\n",
      "Train Epoch: 4 [28000/32634 (86%)]\tLoss: 0.577448\n",
      "Train Epoch: 4 [29000/32634 (89%)]\tLoss: 0.514994\n",
      "Train Epoch: 4 [30000/32634 (92%)]\tLoss: 0.587262\n",
      "Train Epoch: 4 [31000/32634 (95%)]\tLoss: 0.539964\n",
      "Train Epoch: 4 [32000/32634 (98%)]\tLoss: 0.615962\n",
      "Train Epoch: 5 [0/32634 (0%)]\tLoss: 0.481671\n",
      "Train Epoch: 5 [1000/32634 (3%)]\tLoss: 0.551464\n",
      "Train Epoch: 5 [2000/32634 (6%)]\tLoss: 0.502707\n",
      "Train Epoch: 5 [3000/32634 (9%)]\tLoss: 0.495856\n",
      "Train Epoch: 5 [4000/32634 (12%)]\tLoss: 0.352808\n",
      "Train Epoch: 5 [5000/32634 (15%)]\tLoss: 0.477308\n",
      "Train Epoch: 5 [6000/32634 (18%)]\tLoss: 0.527771\n",
      "Train Epoch: 5 [7000/32634 (21%)]\tLoss: 0.612867\n",
      "Train Epoch: 5 [8000/32634 (24%)]\tLoss: 0.759108\n",
      "Train Epoch: 5 [9000/32634 (28%)]\tLoss: 0.505563\n",
      "Train Epoch: 5 [10000/32634 (31%)]\tLoss: 0.573352\n",
      "Train Epoch: 5 [11000/32634 (34%)]\tLoss: 0.450521\n",
      "Train Epoch: 5 [12000/32634 (37%)]\tLoss: 0.500426\n",
      "Train Epoch: 5 [13000/32634 (40%)]\tLoss: 0.536439\n",
      "Train Epoch: 5 [14000/32634 (43%)]\tLoss: 0.490661\n",
      "Train Epoch: 5 [15000/32634 (46%)]\tLoss: 0.498891\n",
      "Train Epoch: 5 [16000/32634 (49%)]\tLoss: 0.499190\n",
      "Train Epoch: 5 [17000/32634 (52%)]\tLoss: 0.613590\n",
      "Train Epoch: 5 [18000/32634 (55%)]\tLoss: 0.456181\n",
      "Train Epoch: 5 [19000/32634 (58%)]\tLoss: 0.469040\n",
      "Train Epoch: 5 [20000/32634 (61%)]\tLoss: 0.655881\n",
      "Train Epoch: 5 [21000/32634 (64%)]\tLoss: 0.429420\n",
      "Train Epoch: 5 [22000/32634 (67%)]\tLoss: 0.461488\n",
      "Train Epoch: 5 [23000/32634 (70%)]\tLoss: 0.428170\n",
      "Train Epoch: 5 [24000/32634 (73%)]\tLoss: 0.607789\n",
      "Train Epoch: 5 [25000/32634 (76%)]\tLoss: 0.623951\n",
      "Train Epoch: 5 [26000/32634 (80%)]\tLoss: 0.671715\n",
      "Train Epoch: 5 [27000/32634 (83%)]\tLoss: 0.440224\n",
      "Train Epoch: 5 [28000/32634 (86%)]\tLoss: 0.550964\n",
      "Train Epoch: 5 [29000/32634 (89%)]\tLoss: 0.505756\n",
      "Train Epoch: 5 [30000/32634 (92%)]\tLoss: 0.714099\n",
      "Train Epoch: 5 [31000/32634 (95%)]\tLoss: 0.685127\n",
      "Train Epoch: 5 [32000/32634 (98%)]\tLoss: 0.466396\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8754, Accuracy: 7436/10000 (74%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/27366 (0%)]\tLoss: 0.685932\n",
      "Train Epoch: 1 [1000/27366 (4%)]\tLoss: 0.477306\n",
      "Train Epoch: 1 [2000/27366 (7%)]\tLoss: 0.511454\n",
      "Train Epoch: 1 [3000/27366 (11%)]\tLoss: 0.620826\n",
      "Train Epoch: 1 [4000/27366 (15%)]\tLoss: 0.572920\n",
      "Train Epoch: 1 [5000/27366 (18%)]\tLoss: 0.650693\n",
      "Train Epoch: 1 [6000/27366 (22%)]\tLoss: 0.604695\n",
      "Train Epoch: 1 [7000/27366 (26%)]\tLoss: 0.738828\n",
      "Train Epoch: 1 [8000/27366 (29%)]\tLoss: 0.719724\n",
      "Train Epoch: 1 [9000/27366 (33%)]\tLoss: 0.533548\n",
      "Train Epoch: 1 [10000/27366 (36%)]\tLoss: 0.626342\n",
      "Train Epoch: 1 [11000/27366 (40%)]\tLoss: 0.469804\n",
      "Train Epoch: 1 [12000/27366 (44%)]\tLoss: 0.741101\n",
      "Train Epoch: 1 [13000/27366 (47%)]\tLoss: 0.463653\n",
      "Train Epoch: 1 [14000/27366 (51%)]\tLoss: 0.477918\n",
      "Train Epoch: 1 [15000/27366 (55%)]\tLoss: 0.665761\n",
      "Train Epoch: 1 [16000/27366 (58%)]\tLoss: 0.454194\n",
      "Train Epoch: 1 [17000/27366 (62%)]\tLoss: 0.508401\n",
      "Train Epoch: 1 [18000/27366 (66%)]\tLoss: 0.420366\n",
      "Train Epoch: 1 [19000/27366 (69%)]\tLoss: 0.516683\n",
      "Train Epoch: 1 [20000/27366 (73%)]\tLoss: 0.496865\n",
      "Train Epoch: 1 [21000/27366 (77%)]\tLoss: 0.477422\n",
      "Train Epoch: 1 [22000/27366 (80%)]\tLoss: 0.391643\n",
      "Train Epoch: 1 [23000/27366 (84%)]\tLoss: 0.641680\n",
      "Train Epoch: 1 [24000/27366 (88%)]\tLoss: 0.504763\n",
      "Train Epoch: 1 [25000/27366 (91%)]\tLoss: 0.490802\n",
      "Train Epoch: 1 [26000/27366 (95%)]\tLoss: 0.466679\n",
      "Train Epoch: 1 [27000/27366 (99%)]\tLoss: 0.382040\n",
      "Train Epoch: 2 [0/27366 (0%)]\tLoss: 0.525135\n",
      "Train Epoch: 2 [1000/27366 (4%)]\tLoss: 0.489215\n",
      "Train Epoch: 2 [2000/27366 (7%)]\tLoss: 0.316477\n",
      "Train Epoch: 2 [3000/27366 (11%)]\tLoss: 0.595063\n",
      "Train Epoch: 2 [4000/27366 (15%)]\tLoss: 0.450606\n",
      "Train Epoch: 2 [5000/27366 (18%)]\tLoss: 0.500843\n",
      "Train Epoch: 2 [6000/27366 (22%)]\tLoss: 0.490418\n",
      "Train Epoch: 2 [7000/27366 (26%)]\tLoss: 0.587479\n",
      "Train Epoch: 2 [8000/27366 (29%)]\tLoss: 0.611445\n",
      "Train Epoch: 2 [9000/27366 (33%)]\tLoss: 0.340992\n",
      "Train Epoch: 2 [10000/27366 (36%)]\tLoss: 0.631864\n",
      "Train Epoch: 2 [11000/27366 (40%)]\tLoss: 0.668195\n",
      "Train Epoch: 2 [12000/27366 (44%)]\tLoss: 0.463893\n",
      "Train Epoch: 2 [13000/27366 (47%)]\tLoss: 0.567882\n",
      "Train Epoch: 2 [14000/27366 (51%)]\tLoss: 0.565625\n",
      "Train Epoch: 2 [15000/27366 (55%)]\tLoss: 0.473929\n",
      "Train Epoch: 2 [16000/27366 (58%)]\tLoss: 0.448272\n",
      "Train Epoch: 2 [17000/27366 (62%)]\tLoss: 0.631926\n",
      "Train Epoch: 2 [18000/27366 (66%)]\tLoss: 0.470148\n",
      "Train Epoch: 2 [19000/27366 (69%)]\tLoss: 0.578546\n",
      "Train Epoch: 2 [20000/27366 (73%)]\tLoss: 0.557227\n",
      "Train Epoch: 2 [21000/27366 (77%)]\tLoss: 0.514833\n",
      "Train Epoch: 2 [22000/27366 (80%)]\tLoss: 0.502269\n",
      "Train Epoch: 2 [23000/27366 (84%)]\tLoss: 0.458938\n",
      "Train Epoch: 2 [24000/27366 (88%)]\tLoss: 0.476156\n",
      "Train Epoch: 2 [25000/27366 (91%)]\tLoss: 0.433532\n",
      "Train Epoch: 2 [26000/27366 (95%)]\tLoss: 0.435784\n",
      "Train Epoch: 2 [27000/27366 (99%)]\tLoss: 0.598810\n",
      "Train Epoch: 3 [0/27366 (0%)]\tLoss: 0.528064\n",
      "Train Epoch: 3 [1000/27366 (4%)]\tLoss: 0.565045\n",
      "Train Epoch: 3 [2000/27366 (7%)]\tLoss: 0.682287\n",
      "Train Epoch: 3 [3000/27366 (11%)]\tLoss: 0.584688\n",
      "Train Epoch: 3 [4000/27366 (15%)]\tLoss: 0.648418\n",
      "Train Epoch: 3 [5000/27366 (18%)]\tLoss: 0.631628\n",
      "Train Epoch: 3 [6000/27366 (22%)]\tLoss: 0.483109\n",
      "Train Epoch: 3 [7000/27366 (26%)]\tLoss: 0.565776\n",
      "Train Epoch: 3 [8000/27366 (29%)]\tLoss: 0.690698\n",
      "Train Epoch: 3 [9000/27366 (33%)]\tLoss: 0.531522\n",
      "Train Epoch: 3 [10000/27366 (36%)]\tLoss: 0.532654\n",
      "Train Epoch: 3 [11000/27366 (40%)]\tLoss: 0.520025\n",
      "Train Epoch: 3 [12000/27366 (44%)]\tLoss: 0.583403\n",
      "Train Epoch: 3 [13000/27366 (47%)]\tLoss: 0.575447\n",
      "Train Epoch: 3 [14000/27366 (51%)]\tLoss: 0.421488\n",
      "Train Epoch: 3 [15000/27366 (55%)]\tLoss: 0.613151\n",
      "Train Epoch: 3 [16000/27366 (58%)]\tLoss: 0.540757\n",
      "Train Epoch: 3 [17000/27366 (62%)]\tLoss: 0.474950\n",
      "Train Epoch: 3 [18000/27366 (66%)]\tLoss: 0.542188\n",
      "Train Epoch: 3 [19000/27366 (69%)]\tLoss: 0.532356\n",
      "Train Epoch: 3 [20000/27366 (73%)]\tLoss: 0.511557\n",
      "Train Epoch: 3 [21000/27366 (77%)]\tLoss: 0.682017\n",
      "Train Epoch: 3 [22000/27366 (80%)]\tLoss: 0.418759\n",
      "Train Epoch: 3 [23000/27366 (84%)]\tLoss: 0.412134\n",
      "Train Epoch: 3 [24000/27366 (88%)]\tLoss: 0.460238\n",
      "Train Epoch: 3 [25000/27366 (91%)]\tLoss: 0.578362\n",
      "Train Epoch: 3 [26000/27366 (95%)]\tLoss: 0.594565\n",
      "Train Epoch: 3 [27000/27366 (99%)]\tLoss: 0.481481\n",
      "Train Epoch: 4 [0/27366 (0%)]\tLoss: 0.479202\n",
      "Train Epoch: 4 [1000/27366 (4%)]\tLoss: 0.460635\n",
      "Train Epoch: 4 [2000/27366 (7%)]\tLoss: 0.509485\n",
      "Train Epoch: 4 [3000/27366 (11%)]\tLoss: 0.537251\n",
      "Train Epoch: 4 [4000/27366 (15%)]\tLoss: 0.518719\n",
      "Train Epoch: 4 [5000/27366 (18%)]\tLoss: 0.387437\n",
      "Train Epoch: 4 [6000/27366 (22%)]\tLoss: 0.680226\n",
      "Train Epoch: 4 [7000/27366 (26%)]\tLoss: 0.495312\n",
      "Train Epoch: 4 [8000/27366 (29%)]\tLoss: 0.551014\n",
      "Train Epoch: 4 [9000/27366 (33%)]\tLoss: 0.557243\n",
      "Train Epoch: 4 [10000/27366 (36%)]\tLoss: 0.519869\n",
      "Train Epoch: 4 [11000/27366 (40%)]\tLoss: 0.455452\n",
      "Train Epoch: 4 [12000/27366 (44%)]\tLoss: 0.571416\n",
      "Train Epoch: 4 [13000/27366 (47%)]\tLoss: 0.322218\n",
      "Train Epoch: 4 [14000/27366 (51%)]\tLoss: 0.343199\n",
      "Train Epoch: 4 [15000/27366 (55%)]\tLoss: 0.502467\n",
      "Train Epoch: 4 [16000/27366 (58%)]\tLoss: 0.438771\n",
      "Train Epoch: 4 [17000/27366 (62%)]\tLoss: 0.549526\n",
      "Train Epoch: 4 [18000/27366 (66%)]\tLoss: 0.457848\n",
      "Train Epoch: 4 [19000/27366 (69%)]\tLoss: 0.603696\n",
      "Train Epoch: 4 [20000/27366 (73%)]\tLoss: 0.405656\n",
      "Train Epoch: 4 [21000/27366 (77%)]\tLoss: 0.671377\n",
      "Train Epoch: 4 [22000/27366 (80%)]\tLoss: 0.535914\n",
      "Train Epoch: 4 [23000/27366 (84%)]\tLoss: 0.569091\n",
      "Train Epoch: 4 [24000/27366 (88%)]\tLoss: 0.386422\n",
      "Train Epoch: 4 [25000/27366 (91%)]\tLoss: 0.616874\n",
      "Train Epoch: 4 [26000/27366 (95%)]\tLoss: 0.479926\n",
      "Train Epoch: 4 [27000/27366 (99%)]\tLoss: 0.474626\n",
      "Train Epoch: 5 [0/27366 (0%)]\tLoss: 0.596686\n",
      "Train Epoch: 5 [1000/27366 (4%)]\tLoss: 0.421104\n",
      "Train Epoch: 5 [2000/27366 (7%)]\tLoss: 0.517335\n",
      "Train Epoch: 5 [3000/27366 (11%)]\tLoss: 0.465460\n",
      "Train Epoch: 5 [4000/27366 (15%)]\tLoss: 0.665252\n",
      "Train Epoch: 5 [5000/27366 (18%)]\tLoss: 0.418046\n",
      "Train Epoch: 5 [6000/27366 (22%)]\tLoss: 0.526640\n",
      "Train Epoch: 5 [7000/27366 (26%)]\tLoss: 0.478388\n",
      "Train Epoch: 5 [8000/27366 (29%)]\tLoss: 0.654871\n",
      "Train Epoch: 5 [9000/27366 (33%)]\tLoss: 0.482066\n",
      "Train Epoch: 5 [10000/27366 (36%)]\tLoss: 0.503916\n",
      "Train Epoch: 5 [11000/27366 (40%)]\tLoss: 0.362957\n",
      "Train Epoch: 5 [12000/27366 (44%)]\tLoss: 0.565041\n",
      "Train Epoch: 5 [13000/27366 (47%)]\tLoss: 0.411801\n",
      "Train Epoch: 5 [14000/27366 (51%)]\tLoss: 0.614906\n",
      "Train Epoch: 5 [15000/27366 (55%)]\tLoss: 0.634153\n",
      "Train Epoch: 5 [16000/27366 (58%)]\tLoss: 0.493608\n",
      "Train Epoch: 5 [17000/27366 (62%)]\tLoss: 0.519017\n",
      "Train Epoch: 5 [18000/27366 (66%)]\tLoss: 0.484069\n",
      "Train Epoch: 5 [19000/27366 (69%)]\tLoss: 0.436645\n",
      "Train Epoch: 5 [20000/27366 (73%)]\tLoss: 0.655358\n",
      "Train Epoch: 5 [21000/27366 (77%)]\tLoss: 0.400660\n",
      "Train Epoch: 5 [22000/27366 (80%)]\tLoss: 0.388140\n",
      "Train Epoch: 5 [23000/27366 (84%)]\tLoss: 0.425045\n",
      "Train Epoch: 5 [24000/27366 (88%)]\tLoss: 0.521407\n",
      "Train Epoch: 5 [25000/27366 (91%)]\tLoss: 0.500919\n",
      "Train Epoch: 5 [26000/27366 (95%)]\tLoss: 0.554109\n",
      "Train Epoch: 5 [27000/27366 (99%)]\tLoss: 0.494872\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/32634 (0%)]\tLoss: 0.545137\n",
      "Train Epoch: 1 [1000/32634 (3%)]\tLoss: 0.633663\n",
      "Train Epoch: 1 [2000/32634 (6%)]\tLoss: 0.479653\n",
      "Train Epoch: 1 [3000/32634 (9%)]\tLoss: 0.540016\n",
      "Train Epoch: 1 [4000/32634 (12%)]\tLoss: 0.326327\n",
      "Train Epoch: 1 [5000/32634 (15%)]\tLoss: 0.620846\n",
      "Train Epoch: 1 [6000/32634 (18%)]\tLoss: 0.588947\n",
      "Train Epoch: 1 [7000/32634 (21%)]\tLoss: 0.563692\n",
      "Train Epoch: 1 [8000/32634 (24%)]\tLoss: 0.332118\n",
      "Train Epoch: 1 [9000/32634 (28%)]\tLoss: 0.677869\n",
      "Train Epoch: 1 [10000/32634 (31%)]\tLoss: 0.699091\n",
      "Train Epoch: 1 [11000/32634 (34%)]\tLoss: 0.597844\n",
      "Train Epoch: 1 [12000/32634 (37%)]\tLoss: 0.688750\n",
      "Train Epoch: 1 [13000/32634 (40%)]\tLoss: 0.526792\n",
      "Train Epoch: 1 [14000/32634 (43%)]\tLoss: 0.488558\n",
      "Train Epoch: 1 [15000/32634 (46%)]\tLoss: 0.471151\n",
      "Train Epoch: 1 [16000/32634 (49%)]\tLoss: 0.473198\n",
      "Train Epoch: 1 [17000/32634 (52%)]\tLoss: 0.608845\n",
      "Train Epoch: 1 [18000/32634 (55%)]\tLoss: 0.353361\n",
      "Train Epoch: 1 [19000/32634 (58%)]\tLoss: 0.391886\n",
      "Train Epoch: 1 [20000/32634 (61%)]\tLoss: 0.371532\n",
      "Train Epoch: 1 [21000/32634 (64%)]\tLoss: 0.521958\n",
      "Train Epoch: 1 [22000/32634 (67%)]\tLoss: 0.717098\n",
      "Train Epoch: 1 [23000/32634 (70%)]\tLoss: 0.604476\n",
      "Train Epoch: 1 [24000/32634 (73%)]\tLoss: 0.515086\n",
      "Train Epoch: 1 [25000/32634 (76%)]\tLoss: 0.445969\n",
      "Train Epoch: 1 [26000/32634 (80%)]\tLoss: 0.562121\n",
      "Train Epoch: 1 [27000/32634 (83%)]\tLoss: 0.552207\n",
      "Train Epoch: 1 [28000/32634 (86%)]\tLoss: 0.406897\n",
      "Train Epoch: 1 [29000/32634 (89%)]\tLoss: 0.612514\n",
      "Train Epoch: 1 [30000/32634 (92%)]\tLoss: 0.613910\n",
      "Train Epoch: 1 [31000/32634 (95%)]\tLoss: 0.675938\n",
      "Train Epoch: 1 [32000/32634 (98%)]\tLoss: 0.546281\n",
      "Train Epoch: 2 [0/32634 (0%)]\tLoss: 0.639298\n",
      "Train Epoch: 2 [1000/32634 (3%)]\tLoss: 0.571385\n",
      "Train Epoch: 2 [2000/32634 (6%)]\tLoss: 0.497054\n",
      "Train Epoch: 2 [3000/32634 (9%)]\tLoss: 0.562783\n",
      "Train Epoch: 2 [4000/32634 (12%)]\tLoss: 0.524243\n",
      "Train Epoch: 2 [5000/32634 (15%)]\tLoss: 0.526070\n",
      "Train Epoch: 2 [6000/32634 (18%)]\tLoss: 0.644835\n",
      "Train Epoch: 2 [7000/32634 (21%)]\tLoss: 0.649575\n",
      "Train Epoch: 2 [8000/32634 (24%)]\tLoss: 0.430883\n",
      "Train Epoch: 2 [9000/32634 (28%)]\tLoss: 0.651821\n",
      "Train Epoch: 2 [10000/32634 (31%)]\tLoss: 0.419579\n",
      "Train Epoch: 2 [11000/32634 (34%)]\tLoss: 0.483695\n",
      "Train Epoch: 2 [12000/32634 (37%)]\tLoss: 0.431147\n",
      "Train Epoch: 2 [13000/32634 (40%)]\tLoss: 0.514098\n",
      "Train Epoch: 2 [14000/32634 (43%)]\tLoss: 0.427608\n",
      "Train Epoch: 2 [15000/32634 (46%)]\tLoss: 0.497731\n",
      "Train Epoch: 2 [16000/32634 (49%)]\tLoss: 0.538710\n",
      "Train Epoch: 2 [17000/32634 (52%)]\tLoss: 0.450744\n",
      "Train Epoch: 2 [18000/32634 (55%)]\tLoss: 0.758721\n",
      "Train Epoch: 2 [19000/32634 (58%)]\tLoss: 0.407010\n",
      "Train Epoch: 2 [20000/32634 (61%)]\tLoss: 0.655110\n",
      "Train Epoch: 2 [21000/32634 (64%)]\tLoss: 0.428105\n",
      "Train Epoch: 2 [22000/32634 (67%)]\tLoss: 0.540556\n",
      "Train Epoch: 2 [23000/32634 (70%)]\tLoss: 0.738865\n",
      "Train Epoch: 2 [24000/32634 (73%)]\tLoss: 0.455606\n",
      "Train Epoch: 2 [25000/32634 (76%)]\tLoss: 0.528969\n",
      "Train Epoch: 2 [26000/32634 (80%)]\tLoss: 0.399355\n",
      "Train Epoch: 2 [27000/32634 (83%)]\tLoss: 0.583780\n",
      "Train Epoch: 2 [28000/32634 (86%)]\tLoss: 0.630552\n",
      "Train Epoch: 2 [29000/32634 (89%)]\tLoss: 0.356019\n",
      "Train Epoch: 2 [30000/32634 (92%)]\tLoss: 0.370562\n",
      "Train Epoch: 2 [31000/32634 (95%)]\tLoss: 0.428027\n",
      "Train Epoch: 2 [32000/32634 (98%)]\tLoss: 0.590907\n",
      "Train Epoch: 3 [0/32634 (0%)]\tLoss: 0.377404\n",
      "Train Epoch: 3 [1000/32634 (3%)]\tLoss: 0.591546\n",
      "Train Epoch: 3 [2000/32634 (6%)]\tLoss: 0.473303\n",
      "Train Epoch: 3 [3000/32634 (9%)]\tLoss: 0.458288\n",
      "Train Epoch: 3 [4000/32634 (12%)]\tLoss: 0.494823\n",
      "Train Epoch: 3 [5000/32634 (15%)]\tLoss: 0.387797\n",
      "Train Epoch: 3 [6000/32634 (18%)]\tLoss: 0.511455\n",
      "Train Epoch: 3 [7000/32634 (21%)]\tLoss: 0.447613\n",
      "Train Epoch: 3 [8000/32634 (24%)]\tLoss: 0.496530\n",
      "Train Epoch: 3 [9000/32634 (28%)]\tLoss: 0.427154\n",
      "Train Epoch: 3 [10000/32634 (31%)]\tLoss: 0.294317\n",
      "Train Epoch: 3 [11000/32634 (34%)]\tLoss: 0.513468\n",
      "Train Epoch: 3 [12000/32634 (37%)]\tLoss: 0.525579\n",
      "Train Epoch: 3 [13000/32634 (40%)]\tLoss: 0.553386\n",
      "Train Epoch: 3 [14000/32634 (43%)]\tLoss: 0.437636\n",
      "Train Epoch: 3 [15000/32634 (46%)]\tLoss: 0.538527\n",
      "Train Epoch: 3 [16000/32634 (49%)]\tLoss: 0.416859\n",
      "Train Epoch: 3 [17000/32634 (52%)]\tLoss: 0.460135\n",
      "Train Epoch: 3 [18000/32634 (55%)]\tLoss: 0.501925\n",
      "Train Epoch: 3 [19000/32634 (58%)]\tLoss: 0.585333\n",
      "Train Epoch: 3 [20000/32634 (61%)]\tLoss: 0.454799\n",
      "Train Epoch: 3 [21000/32634 (64%)]\tLoss: 0.426610\n",
      "Train Epoch: 3 [22000/32634 (67%)]\tLoss: 0.456779\n",
      "Train Epoch: 3 [23000/32634 (70%)]\tLoss: 0.578029\n",
      "Train Epoch: 3 [24000/32634 (73%)]\tLoss: 0.612845\n",
      "Train Epoch: 3 [25000/32634 (76%)]\tLoss: 0.466172\n",
      "Train Epoch: 3 [26000/32634 (80%)]\tLoss: 0.557057\n",
      "Train Epoch: 3 [27000/32634 (83%)]\tLoss: 0.464138\n",
      "Train Epoch: 3 [28000/32634 (86%)]\tLoss: 0.586421\n",
      "Train Epoch: 3 [29000/32634 (89%)]\tLoss: 0.566271\n",
      "Train Epoch: 3 [30000/32634 (92%)]\tLoss: 0.574570\n",
      "Train Epoch: 3 [31000/32634 (95%)]\tLoss: 0.490963\n",
      "Train Epoch: 3 [32000/32634 (98%)]\tLoss: 0.418682\n",
      "Train Epoch: 4 [0/32634 (0%)]\tLoss: 0.469657\n",
      "Train Epoch: 4 [1000/32634 (3%)]\tLoss: 0.549505\n",
      "Train Epoch: 4 [2000/32634 (6%)]\tLoss: 0.484186\n",
      "Train Epoch: 4 [3000/32634 (9%)]\tLoss: 0.681793\n",
      "Train Epoch: 4 [4000/32634 (12%)]\tLoss: 0.447248\n",
      "Train Epoch: 4 [5000/32634 (15%)]\tLoss: 0.518559\n",
      "Train Epoch: 4 [6000/32634 (18%)]\tLoss: 0.596732\n",
      "Train Epoch: 4 [7000/32634 (21%)]\tLoss: 0.640218\n",
      "Train Epoch: 4 [8000/32634 (24%)]\tLoss: 0.537082\n",
      "Train Epoch: 4 [9000/32634 (28%)]\tLoss: 0.521000\n",
      "Train Epoch: 4 [10000/32634 (31%)]\tLoss: 0.552516\n",
      "Train Epoch: 4 [11000/32634 (34%)]\tLoss: 0.312309\n",
      "Train Epoch: 4 [12000/32634 (37%)]\tLoss: 0.547295\n",
      "Train Epoch: 4 [13000/32634 (40%)]\tLoss: 0.347621\n",
      "Train Epoch: 4 [14000/32634 (43%)]\tLoss: 0.554914\n",
      "Train Epoch: 4 [15000/32634 (46%)]\tLoss: 0.550654\n",
      "Train Epoch: 4 [16000/32634 (49%)]\tLoss: 0.496215\n",
      "Train Epoch: 4 [17000/32634 (52%)]\tLoss: 0.644381\n",
      "Train Epoch: 4 [18000/32634 (55%)]\tLoss: 0.416492\n",
      "Train Epoch: 4 [19000/32634 (58%)]\tLoss: 0.424574\n",
      "Train Epoch: 4 [20000/32634 (61%)]\tLoss: 0.481995\n",
      "Train Epoch: 4 [21000/32634 (64%)]\tLoss: 0.526657\n",
      "Train Epoch: 4 [22000/32634 (67%)]\tLoss: 0.601957\n",
      "Train Epoch: 4 [23000/32634 (70%)]\tLoss: 0.484198\n",
      "Train Epoch: 4 [24000/32634 (73%)]\tLoss: 0.422795\n",
      "Train Epoch: 4 [25000/32634 (76%)]\tLoss: 0.469265\n",
      "Train Epoch: 4 [26000/32634 (80%)]\tLoss: 0.515709\n",
      "Train Epoch: 4 [27000/32634 (83%)]\tLoss: 0.509775\n",
      "Train Epoch: 4 [28000/32634 (86%)]\tLoss: 0.308342\n",
      "Train Epoch: 4 [29000/32634 (89%)]\tLoss: 0.458199\n",
      "Train Epoch: 4 [30000/32634 (92%)]\tLoss: 0.517305\n",
      "Train Epoch: 4 [31000/32634 (95%)]\tLoss: 0.689458\n",
      "Train Epoch: 4 [32000/32634 (98%)]\tLoss: 0.460034\n",
      "Train Epoch: 5 [0/32634 (0%)]\tLoss: 0.466575\n",
      "Train Epoch: 5 [1000/32634 (3%)]\tLoss: 0.410105\n",
      "Train Epoch: 5 [2000/32634 (6%)]\tLoss: 0.484088\n",
      "Train Epoch: 5 [3000/32634 (9%)]\tLoss: 0.384237\n",
      "Train Epoch: 5 [4000/32634 (12%)]\tLoss: 0.511720\n",
      "Train Epoch: 5 [5000/32634 (15%)]\tLoss: 0.494848\n",
      "Train Epoch: 5 [6000/32634 (18%)]\tLoss: 0.593225\n",
      "Train Epoch: 5 [7000/32634 (21%)]\tLoss: 0.528810\n",
      "Train Epoch: 5 [8000/32634 (24%)]\tLoss: 0.536656\n",
      "Train Epoch: 5 [9000/32634 (28%)]\tLoss: 0.468235\n",
      "Train Epoch: 5 [10000/32634 (31%)]\tLoss: 0.505069\n",
      "Train Epoch: 5 [11000/32634 (34%)]\tLoss: 0.625018\n",
      "Train Epoch: 5 [12000/32634 (37%)]\tLoss: 0.525004\n",
      "Train Epoch: 5 [13000/32634 (40%)]\tLoss: 0.586279\n",
      "Train Epoch: 5 [14000/32634 (43%)]\tLoss: 0.619430\n",
      "Train Epoch: 5 [15000/32634 (46%)]\tLoss: 0.572340\n",
      "Train Epoch: 5 [16000/32634 (49%)]\tLoss: 0.406410\n",
      "Train Epoch: 5 [17000/32634 (52%)]\tLoss: 0.491150\n",
      "Train Epoch: 5 [18000/32634 (55%)]\tLoss: 0.448537\n",
      "Train Epoch: 5 [19000/32634 (58%)]\tLoss: 0.585248\n",
      "Train Epoch: 5 [20000/32634 (61%)]\tLoss: 0.552843\n",
      "Train Epoch: 5 [21000/32634 (64%)]\tLoss: 0.518162\n",
      "Train Epoch: 5 [22000/32634 (67%)]\tLoss: 0.621950\n",
      "Train Epoch: 5 [23000/32634 (70%)]\tLoss: 0.426890\n",
      "Train Epoch: 5 [24000/32634 (73%)]\tLoss: 0.432615\n",
      "Train Epoch: 5 [25000/32634 (76%)]\tLoss: 0.550898\n",
      "Train Epoch: 5 [26000/32634 (80%)]\tLoss: 0.405985\n",
      "Train Epoch: 5 [27000/32634 (83%)]\tLoss: 0.484331\n",
      "Train Epoch: 5 [28000/32634 (86%)]\tLoss: 0.596430\n",
      "Train Epoch: 5 [29000/32634 (89%)]\tLoss: 0.415550\n",
      "Train Epoch: 5 [30000/32634 (92%)]\tLoss: 0.506719\n",
      "Train Epoch: 5 [31000/32634 (95%)]\tLoss: 0.390245\n",
      "Train Epoch: 5 [32000/32634 (98%)]\tLoss: 0.427344\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8262, Accuracy: 7599/10000 (76%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/27366 (0%)]\tLoss: 0.499987\n",
      "Train Epoch: 1 [1000/27366 (4%)]\tLoss: 0.435196\n",
      "Train Epoch: 1 [2000/27366 (7%)]\tLoss: 0.680615\n",
      "Train Epoch: 1 [3000/27366 (11%)]\tLoss: 0.569337\n",
      "Train Epoch: 1 [4000/27366 (15%)]\tLoss: 0.691005\n",
      "Train Epoch: 1 [5000/27366 (18%)]\tLoss: 0.513644\n",
      "Train Epoch: 1 [6000/27366 (22%)]\tLoss: 0.712676\n",
      "Train Epoch: 1 [7000/27366 (26%)]\tLoss: 0.374780\n",
      "Train Epoch: 1 [8000/27366 (29%)]\tLoss: 0.433227\n",
      "Train Epoch: 1 [9000/27366 (33%)]\tLoss: 0.557063\n",
      "Train Epoch: 1 [10000/27366 (36%)]\tLoss: 0.654989\n",
      "Train Epoch: 1 [11000/27366 (40%)]\tLoss: 0.615671\n",
      "Train Epoch: 1 [12000/27366 (44%)]\tLoss: 0.566179\n",
      "Train Epoch: 1 [13000/27366 (47%)]\tLoss: 0.543148\n",
      "Train Epoch: 1 [14000/27366 (51%)]\tLoss: 0.554131\n",
      "Train Epoch: 1 [15000/27366 (55%)]\tLoss: 0.531225\n",
      "Train Epoch: 1 [16000/27366 (58%)]\tLoss: 0.467486\n",
      "Train Epoch: 1 [17000/27366 (62%)]\tLoss: 0.674387\n",
      "Train Epoch: 1 [18000/27366 (66%)]\tLoss: 0.389896\n",
      "Train Epoch: 1 [19000/27366 (69%)]\tLoss: 0.444477\n",
      "Train Epoch: 1 [20000/27366 (73%)]\tLoss: 0.672799\n",
      "Train Epoch: 1 [21000/27366 (77%)]\tLoss: 0.437159\n",
      "Train Epoch: 1 [22000/27366 (80%)]\tLoss: 0.307721\n",
      "Train Epoch: 1 [23000/27366 (84%)]\tLoss: 0.430851\n",
      "Train Epoch: 1 [24000/27366 (88%)]\tLoss: 0.404202\n",
      "Train Epoch: 1 [25000/27366 (91%)]\tLoss: 0.591530\n",
      "Train Epoch: 1 [26000/27366 (95%)]\tLoss: 0.443967\n",
      "Train Epoch: 1 [27000/27366 (99%)]\tLoss: 0.548469\n",
      "Train Epoch: 2 [0/27366 (0%)]\tLoss: 0.483597\n",
      "Train Epoch: 2 [1000/27366 (4%)]\tLoss: 0.499653\n",
      "Train Epoch: 2 [2000/27366 (7%)]\tLoss: 0.513536\n",
      "Train Epoch: 2 [3000/27366 (11%)]\tLoss: 0.464155\n",
      "Train Epoch: 2 [4000/27366 (15%)]\tLoss: 0.463097\n",
      "Train Epoch: 2 [5000/27366 (18%)]\tLoss: 0.586833\n",
      "Train Epoch: 2 [6000/27366 (22%)]\tLoss: 0.552819\n",
      "Train Epoch: 2 [7000/27366 (26%)]\tLoss: 0.501937\n",
      "Train Epoch: 2 [8000/27366 (29%)]\tLoss: 0.401148\n",
      "Train Epoch: 2 [9000/27366 (33%)]\tLoss: 0.346813\n",
      "Train Epoch: 2 [10000/27366 (36%)]\tLoss: 0.507483\n",
      "Train Epoch: 2 [11000/27366 (40%)]\tLoss: 0.615529\n",
      "Train Epoch: 2 [12000/27366 (44%)]\tLoss: 0.446389\n",
      "Train Epoch: 2 [13000/27366 (47%)]\tLoss: 0.446860\n",
      "Train Epoch: 2 [14000/27366 (51%)]\tLoss: 0.637236\n",
      "Train Epoch: 2 [15000/27366 (55%)]\tLoss: 0.561823\n",
      "Train Epoch: 2 [16000/27366 (58%)]\tLoss: 0.539071\n",
      "Train Epoch: 2 [17000/27366 (62%)]\tLoss: 0.502481\n",
      "Train Epoch: 2 [18000/27366 (66%)]\tLoss: 0.526522\n",
      "Train Epoch: 2 [19000/27366 (69%)]\tLoss: 0.456190\n",
      "Train Epoch: 2 [20000/27366 (73%)]\tLoss: 0.520849\n",
      "Train Epoch: 2 [21000/27366 (77%)]\tLoss: 0.569395\n",
      "Train Epoch: 2 [22000/27366 (80%)]\tLoss: 0.618569\n",
      "Train Epoch: 2 [23000/27366 (84%)]\tLoss: 0.507872\n",
      "Train Epoch: 2 [24000/27366 (88%)]\tLoss: 0.497751\n",
      "Train Epoch: 2 [25000/27366 (91%)]\tLoss: 0.469499\n",
      "Train Epoch: 2 [26000/27366 (95%)]\tLoss: 0.694123\n",
      "Train Epoch: 2 [27000/27366 (99%)]\tLoss: 0.453494\n",
      "Train Epoch: 3 [0/27366 (0%)]\tLoss: 0.501729\n",
      "Train Epoch: 3 [1000/27366 (4%)]\tLoss: 0.378834\n",
      "Train Epoch: 3 [2000/27366 (7%)]\tLoss: 0.428402\n",
      "Train Epoch: 3 [3000/27366 (11%)]\tLoss: 0.388515\n",
      "Train Epoch: 3 [4000/27366 (15%)]\tLoss: 0.422027\n",
      "Train Epoch: 3 [5000/27366 (18%)]\tLoss: 0.469851\n",
      "Train Epoch: 3 [6000/27366 (22%)]\tLoss: 0.460283\n",
      "Train Epoch: 3 [7000/27366 (26%)]\tLoss: 0.384195\n",
      "Train Epoch: 3 [8000/27366 (29%)]\tLoss: 0.345589\n",
      "Train Epoch: 3 [9000/27366 (33%)]\tLoss: 0.505315\n",
      "Train Epoch: 3 [10000/27366 (36%)]\tLoss: 0.478380\n",
      "Train Epoch: 3 [11000/27366 (40%)]\tLoss: 0.379148\n",
      "Train Epoch: 3 [12000/27366 (44%)]\tLoss: 0.544962\n",
      "Train Epoch: 3 [13000/27366 (47%)]\tLoss: 0.378786\n",
      "Train Epoch: 3 [14000/27366 (51%)]\tLoss: 0.449935\n",
      "Train Epoch: 3 [15000/27366 (55%)]\tLoss: 0.375293\n",
      "Train Epoch: 3 [16000/27366 (58%)]\tLoss: 0.434727\n",
      "Train Epoch: 3 [17000/27366 (62%)]\tLoss: 0.389274\n",
      "Train Epoch: 3 [18000/27366 (66%)]\tLoss: 0.442651\n",
      "Train Epoch: 3 [19000/27366 (69%)]\tLoss: 0.474898\n",
      "Train Epoch: 3 [20000/27366 (73%)]\tLoss: 0.437189\n",
      "Train Epoch: 3 [21000/27366 (77%)]\tLoss: 0.558977\n",
      "Train Epoch: 3 [22000/27366 (80%)]\tLoss: 0.523485\n",
      "Train Epoch: 3 [23000/27366 (84%)]\tLoss: 0.483057\n",
      "Train Epoch: 3 [24000/27366 (88%)]\tLoss: 0.342301\n",
      "Train Epoch: 3 [25000/27366 (91%)]\tLoss: 0.555623\n",
      "Train Epoch: 3 [26000/27366 (95%)]\tLoss: 0.401269\n",
      "Train Epoch: 3 [27000/27366 (99%)]\tLoss: 0.519290\n",
      "Train Epoch: 4 [0/27366 (0%)]\tLoss: 0.422328\n",
      "Train Epoch: 4 [1000/27366 (4%)]\tLoss: 0.479114\n",
      "Train Epoch: 4 [2000/27366 (7%)]\tLoss: 0.532821\n",
      "Train Epoch: 4 [3000/27366 (11%)]\tLoss: 0.411066\n",
      "Train Epoch: 4 [4000/27366 (15%)]\tLoss: 0.492373\n",
      "Train Epoch: 4 [5000/27366 (18%)]\tLoss: 0.392460\n",
      "Train Epoch: 4 [6000/27366 (22%)]\tLoss: 0.576453\n",
      "Train Epoch: 4 [7000/27366 (26%)]\tLoss: 0.449812\n",
      "Train Epoch: 4 [8000/27366 (29%)]\tLoss: 0.521310\n",
      "Train Epoch: 4 [9000/27366 (33%)]\tLoss: 0.519921\n",
      "Train Epoch: 4 [10000/27366 (36%)]\tLoss: 0.634936\n",
      "Train Epoch: 4 [11000/27366 (40%)]\tLoss: 0.445265\n",
      "Train Epoch: 4 [12000/27366 (44%)]\tLoss: 0.311886\n",
      "Train Epoch: 4 [13000/27366 (47%)]\tLoss: 0.270612\n",
      "Train Epoch: 4 [14000/27366 (51%)]\tLoss: 0.471074\n",
      "Train Epoch: 4 [15000/27366 (55%)]\tLoss: 0.486874\n",
      "Train Epoch: 4 [16000/27366 (58%)]\tLoss: 0.446436\n",
      "Train Epoch: 4 [17000/27366 (62%)]\tLoss: 0.444458\n",
      "Train Epoch: 4 [18000/27366 (66%)]\tLoss: 0.496470\n",
      "Train Epoch: 4 [19000/27366 (69%)]\tLoss: 0.454597\n",
      "Train Epoch: 4 [20000/27366 (73%)]\tLoss: 0.692059\n",
      "Train Epoch: 4 [21000/27366 (77%)]\tLoss: 0.637691\n",
      "Train Epoch: 4 [22000/27366 (80%)]\tLoss: 0.537919\n",
      "Train Epoch: 4 [23000/27366 (84%)]\tLoss: 0.449871\n",
      "Train Epoch: 4 [24000/27366 (88%)]\tLoss: 0.633001\n",
      "Train Epoch: 4 [25000/27366 (91%)]\tLoss: 0.495074\n",
      "Train Epoch: 4 [26000/27366 (95%)]\tLoss: 0.431847\n",
      "Train Epoch: 4 [27000/27366 (99%)]\tLoss: 0.336365\n",
      "Train Epoch: 5 [0/27366 (0%)]\tLoss: 0.436654\n",
      "Train Epoch: 5 [1000/27366 (4%)]\tLoss: 0.474410\n",
      "Train Epoch: 5 [2000/27366 (7%)]\tLoss: 0.695477\n",
      "Train Epoch: 5 [3000/27366 (11%)]\tLoss: 0.340349\n",
      "Train Epoch: 5 [4000/27366 (15%)]\tLoss: 0.471123\n",
      "Train Epoch: 5 [5000/27366 (18%)]\tLoss: 0.381891\n",
      "Train Epoch: 5 [6000/27366 (22%)]\tLoss: 0.482614\n",
      "Train Epoch: 5 [7000/27366 (26%)]\tLoss: 0.371339\n",
      "Train Epoch: 5 [8000/27366 (29%)]\tLoss: 0.574436\n",
      "Train Epoch: 5 [9000/27366 (33%)]\tLoss: 0.631863\n",
      "Train Epoch: 5 [10000/27366 (36%)]\tLoss: 0.442257\n",
      "Train Epoch: 5 [11000/27366 (40%)]\tLoss: 0.529823\n",
      "Train Epoch: 5 [12000/27366 (44%)]\tLoss: 0.511133\n",
      "Train Epoch: 5 [13000/27366 (47%)]\tLoss: 0.349872\n",
      "Train Epoch: 5 [14000/27366 (51%)]\tLoss: 0.458292\n",
      "Train Epoch: 5 [15000/27366 (55%)]\tLoss: 0.762312\n",
      "Train Epoch: 5 [16000/27366 (58%)]\tLoss: 0.537892\n",
      "Train Epoch: 5 [17000/27366 (62%)]\tLoss: 0.411552\n",
      "Train Epoch: 5 [18000/27366 (66%)]\tLoss: 0.553728\n",
      "Train Epoch: 5 [19000/27366 (69%)]\tLoss: 0.648293\n",
      "Train Epoch: 5 [20000/27366 (73%)]\tLoss: 0.496819\n",
      "Train Epoch: 5 [21000/27366 (77%)]\tLoss: 0.434058\n",
      "Train Epoch: 5 [22000/27366 (80%)]\tLoss: 0.473216\n",
      "Train Epoch: 5 [23000/27366 (84%)]\tLoss: 0.527382\n",
      "Train Epoch: 5 [24000/27366 (88%)]\tLoss: 0.514602\n",
      "Train Epoch: 5 [25000/27366 (91%)]\tLoss: 0.354461\n",
      "Train Epoch: 5 [26000/27366 (95%)]\tLoss: 0.521145\n",
      "Train Epoch: 5 [27000/27366 (99%)]\tLoss: 0.396970\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/32634 (0%)]\tLoss: 0.611032\n",
      "Train Epoch: 1 [1000/32634 (3%)]\tLoss: 0.643542\n",
      "Train Epoch: 1 [2000/32634 (6%)]\tLoss: 0.564676\n",
      "Train Epoch: 1 [3000/32634 (9%)]\tLoss: 0.389327\n",
      "Train Epoch: 1 [4000/32634 (12%)]\tLoss: 0.472639\n",
      "Train Epoch: 1 [5000/32634 (15%)]\tLoss: 0.411668\n",
      "Train Epoch: 1 [6000/32634 (18%)]\tLoss: 0.499787\n",
      "Train Epoch: 1 [7000/32634 (21%)]\tLoss: 0.557658\n",
      "Train Epoch: 1 [8000/32634 (24%)]\tLoss: 0.405333\n",
      "Train Epoch: 1 [9000/32634 (28%)]\tLoss: 0.465896\n",
      "Train Epoch: 1 [10000/32634 (31%)]\tLoss: 0.509345\n",
      "Train Epoch: 1 [11000/32634 (34%)]\tLoss: 0.521299\n",
      "Train Epoch: 1 [12000/32634 (37%)]\tLoss: 0.412222\n",
      "Train Epoch: 1 [13000/32634 (40%)]\tLoss: 0.606329\n",
      "Train Epoch: 1 [14000/32634 (43%)]\tLoss: 0.460835\n",
      "Train Epoch: 1 [15000/32634 (46%)]\tLoss: 0.387994\n",
      "Train Epoch: 1 [16000/32634 (49%)]\tLoss: 0.448213\n",
      "Train Epoch: 1 [17000/32634 (52%)]\tLoss: 0.511898\n",
      "Train Epoch: 1 [18000/32634 (55%)]\tLoss: 0.528014\n",
      "Train Epoch: 1 [19000/32634 (58%)]\tLoss: 0.616267\n",
      "Train Epoch: 1 [20000/32634 (61%)]\tLoss: 0.750504\n",
      "Train Epoch: 1 [21000/32634 (64%)]\tLoss: 0.598107\n",
      "Train Epoch: 1 [22000/32634 (67%)]\tLoss: 0.447062\n",
      "Train Epoch: 1 [23000/32634 (70%)]\tLoss: 0.651788\n",
      "Train Epoch: 1 [24000/32634 (73%)]\tLoss: 0.550104\n",
      "Train Epoch: 1 [25000/32634 (76%)]\tLoss: 0.502473\n",
      "Train Epoch: 1 [26000/32634 (80%)]\tLoss: 0.397468\n",
      "Train Epoch: 1 [27000/32634 (83%)]\tLoss: 0.674082\n",
      "Train Epoch: 1 [28000/32634 (86%)]\tLoss: 0.422772\n",
      "Train Epoch: 1 [29000/32634 (89%)]\tLoss: 0.525854\n",
      "Train Epoch: 1 [30000/32634 (92%)]\tLoss: 0.429521\n",
      "Train Epoch: 1 [31000/32634 (95%)]\tLoss: 0.466375\n",
      "Train Epoch: 1 [32000/32634 (98%)]\tLoss: 0.521551\n",
      "Train Epoch: 2 [0/32634 (0%)]\tLoss: 0.494314\n",
      "Train Epoch: 2 [1000/32634 (3%)]\tLoss: 0.530250\n",
      "Train Epoch: 2 [2000/32634 (6%)]\tLoss: 0.443005\n",
      "Train Epoch: 2 [3000/32634 (9%)]\tLoss: 0.595303\n",
      "Train Epoch: 2 [4000/32634 (12%)]\tLoss: 0.558058\n",
      "Train Epoch: 2 [5000/32634 (15%)]\tLoss: 0.482181\n",
      "Train Epoch: 2 [6000/32634 (18%)]\tLoss: 0.446538\n",
      "Train Epoch: 2 [7000/32634 (21%)]\tLoss: 0.570638\n",
      "Train Epoch: 2 [8000/32634 (24%)]\tLoss: 0.545812\n",
      "Train Epoch: 2 [9000/32634 (28%)]\tLoss: 0.308522\n",
      "Train Epoch: 2 [10000/32634 (31%)]\tLoss: 0.448492\n",
      "Train Epoch: 2 [11000/32634 (34%)]\tLoss: 0.541592\n",
      "Train Epoch: 2 [12000/32634 (37%)]\tLoss: 0.321220\n",
      "Train Epoch: 2 [13000/32634 (40%)]\tLoss: 0.515100\n",
      "Train Epoch: 2 [14000/32634 (43%)]\tLoss: 0.529494\n",
      "Train Epoch: 2 [15000/32634 (46%)]\tLoss: 0.587264\n",
      "Train Epoch: 2 [16000/32634 (49%)]\tLoss: 0.508040\n",
      "Train Epoch: 2 [17000/32634 (52%)]\tLoss: 0.474059\n",
      "Train Epoch: 2 [18000/32634 (55%)]\tLoss: 0.552798\n",
      "Train Epoch: 2 [19000/32634 (58%)]\tLoss: 0.544722\n",
      "Train Epoch: 2 [20000/32634 (61%)]\tLoss: 0.523884\n",
      "Train Epoch: 2 [21000/32634 (64%)]\tLoss: 0.610937\n",
      "Train Epoch: 2 [22000/32634 (67%)]\tLoss: 0.400945\n",
      "Train Epoch: 2 [23000/32634 (70%)]\tLoss: 0.496753\n",
      "Train Epoch: 2 [24000/32634 (73%)]\tLoss: 0.469011\n",
      "Train Epoch: 2 [25000/32634 (76%)]\tLoss: 0.562655\n",
      "Train Epoch: 2 [26000/32634 (80%)]\tLoss: 0.579991\n",
      "Train Epoch: 2 [27000/32634 (83%)]\tLoss: 0.499206\n",
      "Train Epoch: 2 [28000/32634 (86%)]\tLoss: 0.484680\n",
      "Train Epoch: 2 [29000/32634 (89%)]\tLoss: 0.518117\n",
      "Train Epoch: 2 [30000/32634 (92%)]\tLoss: 0.656761\n",
      "Train Epoch: 2 [31000/32634 (95%)]\tLoss: 0.457037\n",
      "Train Epoch: 2 [32000/32634 (98%)]\tLoss: 0.475760\n",
      "Train Epoch: 3 [0/32634 (0%)]\tLoss: 0.515960\n",
      "Train Epoch: 3 [1000/32634 (3%)]\tLoss: 0.525912\n",
      "Train Epoch: 3 [2000/32634 (6%)]\tLoss: 0.499845\n",
      "Train Epoch: 3 [3000/32634 (9%)]\tLoss: 0.703256\n",
      "Train Epoch: 3 [4000/32634 (12%)]\tLoss: 0.375512\n",
      "Train Epoch: 3 [5000/32634 (15%)]\tLoss: 0.463361\n",
      "Train Epoch: 3 [6000/32634 (18%)]\tLoss: 0.394690\n",
      "Train Epoch: 3 [7000/32634 (21%)]\tLoss: 0.474349\n",
      "Train Epoch: 3 [8000/32634 (24%)]\tLoss: 0.633306\n",
      "Train Epoch: 3 [9000/32634 (28%)]\tLoss: 0.541114\n",
      "Train Epoch: 3 [10000/32634 (31%)]\tLoss: 0.497691\n",
      "Train Epoch: 3 [11000/32634 (34%)]\tLoss: 0.585564\n",
      "Train Epoch: 3 [12000/32634 (37%)]\tLoss: 0.489043\n",
      "Train Epoch: 3 [13000/32634 (40%)]\tLoss: 0.428877\n",
      "Train Epoch: 3 [14000/32634 (43%)]\tLoss: 0.444686\n",
      "Train Epoch: 3 [15000/32634 (46%)]\tLoss: 0.590107\n",
      "Train Epoch: 3 [16000/32634 (49%)]\tLoss: 0.479078\n",
      "Train Epoch: 3 [17000/32634 (52%)]\tLoss: 0.501972\n",
      "Train Epoch: 3 [18000/32634 (55%)]\tLoss: 0.504917\n",
      "Train Epoch: 3 [19000/32634 (58%)]\tLoss: 0.347134\n",
      "Train Epoch: 3 [20000/32634 (61%)]\tLoss: 0.586932\n",
      "Train Epoch: 3 [21000/32634 (64%)]\tLoss: 0.618493\n",
      "Train Epoch: 3 [22000/32634 (67%)]\tLoss: 0.711474\n",
      "Train Epoch: 3 [23000/32634 (70%)]\tLoss: 0.393458\n",
      "Train Epoch: 3 [24000/32634 (73%)]\tLoss: 0.273230\n",
      "Train Epoch: 3 [25000/32634 (76%)]\tLoss: 0.344430\n",
      "Train Epoch: 3 [26000/32634 (80%)]\tLoss: 0.509996\n",
      "Train Epoch: 3 [27000/32634 (83%)]\tLoss: 0.349251\n",
      "Train Epoch: 3 [28000/32634 (86%)]\tLoss: 0.514877\n",
      "Train Epoch: 3 [29000/32634 (89%)]\tLoss: 0.403383\n",
      "Train Epoch: 3 [30000/32634 (92%)]\tLoss: 0.548218\n",
      "Train Epoch: 3 [31000/32634 (95%)]\tLoss: 0.439158\n",
      "Train Epoch: 3 [32000/32634 (98%)]\tLoss: 0.510164\n",
      "Train Epoch: 4 [0/32634 (0%)]\tLoss: 0.530737\n",
      "Train Epoch: 4 [1000/32634 (3%)]\tLoss: 0.609902\n",
      "Train Epoch: 4 [2000/32634 (6%)]\tLoss: 0.559774\n",
      "Train Epoch: 4 [3000/32634 (9%)]\tLoss: 0.510881\n",
      "Train Epoch: 4 [4000/32634 (12%)]\tLoss: 0.501447\n",
      "Train Epoch: 4 [5000/32634 (15%)]\tLoss: 0.500101\n",
      "Train Epoch: 4 [6000/32634 (18%)]\tLoss: 0.616556\n",
      "Train Epoch: 4 [7000/32634 (21%)]\tLoss: 0.534829\n",
      "Train Epoch: 4 [8000/32634 (24%)]\tLoss: 0.494334\n",
      "Train Epoch: 4 [9000/32634 (28%)]\tLoss: 0.470466\n",
      "Train Epoch: 4 [10000/32634 (31%)]\tLoss: 0.498118\n",
      "Train Epoch: 4 [11000/32634 (34%)]\tLoss: 0.538504\n",
      "Train Epoch: 4 [12000/32634 (37%)]\tLoss: 0.512158\n",
      "Train Epoch: 4 [13000/32634 (40%)]\tLoss: 0.294393\n",
      "Train Epoch: 4 [14000/32634 (43%)]\tLoss: 0.493843\n",
      "Train Epoch: 4 [15000/32634 (46%)]\tLoss: 0.533915\n",
      "Train Epoch: 4 [16000/32634 (49%)]\tLoss: 0.484176\n",
      "Train Epoch: 4 [17000/32634 (52%)]\tLoss: 0.444941\n",
      "Train Epoch: 4 [18000/32634 (55%)]\tLoss: 0.417540\n",
      "Train Epoch: 4 [19000/32634 (58%)]\tLoss: 0.423114\n",
      "Train Epoch: 4 [20000/32634 (61%)]\tLoss: 0.619430\n",
      "Train Epoch: 4 [21000/32634 (64%)]\tLoss: 0.443853\n",
      "Train Epoch: 4 [22000/32634 (67%)]\tLoss: 0.509197\n",
      "Train Epoch: 4 [23000/32634 (70%)]\tLoss: 0.491351\n",
      "Train Epoch: 4 [24000/32634 (73%)]\tLoss: 0.527753\n",
      "Train Epoch: 4 [25000/32634 (76%)]\tLoss: 0.417976\n",
      "Train Epoch: 4 [26000/32634 (80%)]\tLoss: 0.452456\n",
      "Train Epoch: 4 [27000/32634 (83%)]\tLoss: 0.473709\n",
      "Train Epoch: 4 [28000/32634 (86%)]\tLoss: 0.554398\n",
      "Train Epoch: 4 [29000/32634 (89%)]\tLoss: 0.518194\n",
      "Train Epoch: 4 [30000/32634 (92%)]\tLoss: 0.402269\n",
      "Train Epoch: 4 [31000/32634 (95%)]\tLoss: 0.575710\n",
      "Train Epoch: 4 [32000/32634 (98%)]\tLoss: 0.614950\n",
      "Train Epoch: 5 [0/32634 (0%)]\tLoss: 0.608892\n",
      "Train Epoch: 5 [1000/32634 (3%)]\tLoss: 0.370372\n",
      "Train Epoch: 5 [2000/32634 (6%)]\tLoss: 0.470945\n",
      "Train Epoch: 5 [3000/32634 (9%)]\tLoss: 0.412372\n",
      "Train Epoch: 5 [4000/32634 (12%)]\tLoss: 0.362141\n",
      "Train Epoch: 5 [5000/32634 (15%)]\tLoss: 0.519731\n",
      "Train Epoch: 5 [6000/32634 (18%)]\tLoss: 0.490485\n",
      "Train Epoch: 5 [7000/32634 (21%)]\tLoss: 0.742117\n",
      "Train Epoch: 5 [8000/32634 (24%)]\tLoss: 0.429892\n",
      "Train Epoch: 5 [9000/32634 (28%)]\tLoss: 0.612494\n",
      "Train Epoch: 5 [10000/32634 (31%)]\tLoss: 0.438112\n",
      "Train Epoch: 5 [11000/32634 (34%)]\tLoss: 0.522884\n",
      "Train Epoch: 5 [12000/32634 (37%)]\tLoss: 0.373104\n",
      "Train Epoch: 5 [13000/32634 (40%)]\tLoss: 0.385554\n",
      "Train Epoch: 5 [14000/32634 (43%)]\tLoss: 0.685270\n",
      "Train Epoch: 5 [15000/32634 (46%)]\tLoss: 0.490999\n",
      "Train Epoch: 5 [16000/32634 (49%)]\tLoss: 0.458184\n",
      "Train Epoch: 5 [17000/32634 (52%)]\tLoss: 0.569924\n",
      "Train Epoch: 5 [18000/32634 (55%)]\tLoss: 0.468427\n",
      "Train Epoch: 5 [19000/32634 (58%)]\tLoss: 0.498151\n",
      "Train Epoch: 5 [20000/32634 (61%)]\tLoss: 0.475050\n",
      "Train Epoch: 5 [21000/32634 (64%)]\tLoss: 0.669734\n",
      "Train Epoch: 5 [22000/32634 (67%)]\tLoss: 0.518006\n",
      "Train Epoch: 5 [23000/32634 (70%)]\tLoss: 0.448728\n",
      "Train Epoch: 5 [24000/32634 (73%)]\tLoss: 0.449168\n",
      "Train Epoch: 5 [25000/32634 (76%)]\tLoss: 0.482313\n",
      "Train Epoch: 5 [26000/32634 (80%)]\tLoss: 0.500058\n",
      "Train Epoch: 5 [27000/32634 (83%)]\tLoss: 0.518525\n",
      "Train Epoch: 5 [28000/32634 (86%)]\tLoss: 0.473795\n",
      "Train Epoch: 5 [29000/32634 (89%)]\tLoss: 0.579146\n",
      "Train Epoch: 5 [30000/32634 (92%)]\tLoss: 0.410252\n",
      "Train Epoch: 5 [31000/32634 (95%)]\tLoss: 0.521790\n",
      "Train Epoch: 5 [32000/32634 (98%)]\tLoss: 0.414921\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8268, Accuracy: 7668/10000 (77%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/27366 (0%)]\tLoss: 0.455466\n",
      "Train Epoch: 1 [1000/27366 (4%)]\tLoss: 0.529312\n",
      "Train Epoch: 1 [2000/27366 (7%)]\tLoss: 0.480455\n",
      "Train Epoch: 1 [3000/27366 (11%)]\tLoss: 0.617126\n",
      "Train Epoch: 1 [4000/27366 (15%)]\tLoss: 0.409862\n",
      "Train Epoch: 1 [5000/27366 (18%)]\tLoss: 0.499694\n",
      "Train Epoch: 1 [6000/27366 (22%)]\tLoss: 0.275048\n",
      "Train Epoch: 1 [7000/27366 (26%)]\tLoss: 0.400523\n",
      "Train Epoch: 1 [8000/27366 (29%)]\tLoss: 0.540182\n",
      "Train Epoch: 1 [9000/27366 (33%)]\tLoss: 0.420612\n",
      "Train Epoch: 1 [10000/27366 (36%)]\tLoss: 0.565227\n",
      "Train Epoch: 1 [11000/27366 (40%)]\tLoss: 0.383397\n",
      "Train Epoch: 1 [12000/27366 (44%)]\tLoss: 0.323524\n",
      "Train Epoch: 1 [13000/27366 (47%)]\tLoss: 0.570807\n",
      "Train Epoch: 1 [14000/27366 (51%)]\tLoss: 0.497824\n",
      "Train Epoch: 1 [15000/27366 (55%)]\tLoss: 0.555414\n",
      "Train Epoch: 1 [16000/27366 (58%)]\tLoss: 0.376700\n",
      "Train Epoch: 1 [17000/27366 (62%)]\tLoss: 0.325746\n",
      "Train Epoch: 1 [18000/27366 (66%)]\tLoss: 0.587603\n",
      "Train Epoch: 1 [19000/27366 (69%)]\tLoss: 0.379623\n",
      "Train Epoch: 1 [20000/27366 (73%)]\tLoss: 0.559502\n",
      "Train Epoch: 1 [21000/27366 (77%)]\tLoss: 0.436494\n",
      "Train Epoch: 1 [22000/27366 (80%)]\tLoss: 0.557543\n",
      "Train Epoch: 1 [23000/27366 (84%)]\tLoss: 0.302294\n",
      "Train Epoch: 1 [24000/27366 (88%)]\tLoss: 0.529140\n",
      "Train Epoch: 1 [25000/27366 (91%)]\tLoss: 0.595937\n",
      "Train Epoch: 1 [26000/27366 (95%)]\tLoss: 0.492275\n",
      "Train Epoch: 1 [27000/27366 (99%)]\tLoss: 0.466026\n",
      "Train Epoch: 2 [0/27366 (0%)]\tLoss: 0.331732\n",
      "Train Epoch: 2 [1000/27366 (4%)]\tLoss: 0.602799\n",
      "Train Epoch: 2 [2000/27366 (7%)]\tLoss: 0.489390\n",
      "Train Epoch: 2 [3000/27366 (11%)]\tLoss: 0.488166\n",
      "Train Epoch: 2 [4000/27366 (15%)]\tLoss: 0.503022\n",
      "Train Epoch: 2 [5000/27366 (18%)]\tLoss: 0.545779\n",
      "Train Epoch: 2 [6000/27366 (22%)]\tLoss: 0.386034\n",
      "Train Epoch: 2 [7000/27366 (26%)]\tLoss: 0.482505\n",
      "Train Epoch: 2 [8000/27366 (29%)]\tLoss: 0.633589\n",
      "Train Epoch: 2 [9000/27366 (33%)]\tLoss: 0.523110\n",
      "Train Epoch: 2 [10000/27366 (36%)]\tLoss: 0.534840\n",
      "Train Epoch: 2 [11000/27366 (40%)]\tLoss: 0.408802\n",
      "Train Epoch: 2 [12000/27366 (44%)]\tLoss: 0.850959\n",
      "Train Epoch: 2 [13000/27366 (47%)]\tLoss: 0.559216\n",
      "Train Epoch: 2 [14000/27366 (51%)]\tLoss: 0.506313\n",
      "Train Epoch: 2 [15000/27366 (55%)]\tLoss: 0.479617\n",
      "Train Epoch: 2 [16000/27366 (58%)]\tLoss: 0.424655\n",
      "Train Epoch: 2 [17000/27366 (62%)]\tLoss: 0.539597\n",
      "Train Epoch: 2 [18000/27366 (66%)]\tLoss: 0.434113\n",
      "Train Epoch: 2 [19000/27366 (69%)]\tLoss: 0.350329\n",
      "Train Epoch: 2 [20000/27366 (73%)]\tLoss: 0.398854\n",
      "Train Epoch: 2 [21000/27366 (77%)]\tLoss: 0.491237\n",
      "Train Epoch: 2 [22000/27366 (80%)]\tLoss: 0.442187\n",
      "Train Epoch: 2 [23000/27366 (84%)]\tLoss: 0.662186\n",
      "Train Epoch: 2 [24000/27366 (88%)]\tLoss: 0.455545\n",
      "Train Epoch: 2 [25000/27366 (91%)]\tLoss: 0.560177\n",
      "Train Epoch: 2 [26000/27366 (95%)]\tLoss: 0.499209\n",
      "Train Epoch: 2 [27000/27366 (99%)]\tLoss: 0.650103\n",
      "Train Epoch: 3 [0/27366 (0%)]\tLoss: 0.375779\n",
      "Train Epoch: 3 [1000/27366 (4%)]\tLoss: 0.390197\n",
      "Train Epoch: 3 [2000/27366 (7%)]\tLoss: 0.507763\n",
      "Train Epoch: 3 [3000/27366 (11%)]\tLoss: 0.406153\n",
      "Train Epoch: 3 [4000/27366 (15%)]\tLoss: 0.471931\n",
      "Train Epoch: 3 [5000/27366 (18%)]\tLoss: 0.494119\n",
      "Train Epoch: 3 [6000/27366 (22%)]\tLoss: 0.278398\n",
      "Train Epoch: 3 [7000/27366 (26%)]\tLoss: 0.521851\n",
      "Train Epoch: 3 [8000/27366 (29%)]\tLoss: 0.406887\n",
      "Train Epoch: 3 [9000/27366 (33%)]\tLoss: 0.509548\n",
      "Train Epoch: 3 [10000/27366 (36%)]\tLoss: 0.463462\n",
      "Train Epoch: 3 [11000/27366 (40%)]\tLoss: 0.548904\n",
      "Train Epoch: 3 [12000/27366 (44%)]\tLoss: 0.490223\n",
      "Train Epoch: 3 [13000/27366 (47%)]\tLoss: 0.488109\n",
      "Train Epoch: 3 [14000/27366 (51%)]\tLoss: 0.498321\n",
      "Train Epoch: 3 [15000/27366 (55%)]\tLoss: 0.374713\n",
      "Train Epoch: 3 [16000/27366 (58%)]\tLoss: 0.456443\n",
      "Train Epoch: 3 [17000/27366 (62%)]\tLoss: 0.482852\n",
      "Train Epoch: 3 [18000/27366 (66%)]\tLoss: 0.471692\n",
      "Train Epoch: 3 [19000/27366 (69%)]\tLoss: 0.457996\n",
      "Train Epoch: 3 [20000/27366 (73%)]\tLoss: 0.518916\n",
      "Train Epoch: 3 [21000/27366 (77%)]\tLoss: 0.438079\n",
      "Train Epoch: 3 [22000/27366 (80%)]\tLoss: 0.430688\n",
      "Train Epoch: 3 [23000/27366 (84%)]\tLoss: 0.567899\n",
      "Train Epoch: 3 [24000/27366 (88%)]\tLoss: 0.473744\n",
      "Train Epoch: 3 [25000/27366 (91%)]\tLoss: 0.364270\n",
      "Train Epoch: 3 [26000/27366 (95%)]\tLoss: 0.418118\n",
      "Train Epoch: 3 [27000/27366 (99%)]\tLoss: 0.455375\n",
      "Train Epoch: 4 [0/27366 (0%)]\tLoss: 0.419766\n",
      "Train Epoch: 4 [1000/27366 (4%)]\tLoss: 0.557778\n",
      "Train Epoch: 4 [2000/27366 (7%)]\tLoss: 0.453577\n",
      "Train Epoch: 4 [3000/27366 (11%)]\tLoss: 0.393032\n",
      "Train Epoch: 4 [4000/27366 (15%)]\tLoss: 0.443387\n",
      "Train Epoch: 4 [5000/27366 (18%)]\tLoss: 0.470561\n",
      "Train Epoch: 4 [6000/27366 (22%)]\tLoss: 0.460582\n",
      "Train Epoch: 4 [7000/27366 (26%)]\tLoss: 0.456883\n",
      "Train Epoch: 4 [8000/27366 (29%)]\tLoss: 0.501057\n",
      "Train Epoch: 4 [9000/27366 (33%)]\tLoss: 0.446770\n",
      "Train Epoch: 4 [10000/27366 (36%)]\tLoss: 0.608818\n",
      "Train Epoch: 4 [11000/27366 (40%)]\tLoss: 0.602192\n",
      "Train Epoch: 4 [12000/27366 (44%)]\tLoss: 0.489321\n",
      "Train Epoch: 4 [13000/27366 (47%)]\tLoss: 0.345510\n",
      "Train Epoch: 4 [14000/27366 (51%)]\tLoss: 0.361971\n",
      "Train Epoch: 4 [15000/27366 (55%)]\tLoss: 0.561801\n",
      "Train Epoch: 4 [16000/27366 (58%)]\tLoss: 0.361742\n",
      "Train Epoch: 4 [17000/27366 (62%)]\tLoss: 0.381040\n",
      "Train Epoch: 4 [18000/27366 (66%)]\tLoss: 0.439541\n",
      "Train Epoch: 4 [19000/27366 (69%)]\tLoss: 0.492348\n",
      "Train Epoch: 4 [20000/27366 (73%)]\tLoss: 0.543899\n",
      "Train Epoch: 4 [21000/27366 (77%)]\tLoss: 0.637189\n",
      "Train Epoch: 4 [22000/27366 (80%)]\tLoss: 0.400591\n",
      "Train Epoch: 4 [23000/27366 (84%)]\tLoss: 0.441250\n",
      "Train Epoch: 4 [24000/27366 (88%)]\tLoss: 0.408355\n",
      "Train Epoch: 4 [25000/27366 (91%)]\tLoss: 0.446713\n",
      "Train Epoch: 4 [26000/27366 (95%)]\tLoss: 0.400694\n",
      "Train Epoch: 4 [27000/27366 (99%)]\tLoss: 0.458744\n",
      "Train Epoch: 5 [0/27366 (0%)]\tLoss: 0.476069\n",
      "Train Epoch: 5 [1000/27366 (4%)]\tLoss: 0.477966\n",
      "Train Epoch: 5 [2000/27366 (7%)]\tLoss: 0.518274\n",
      "Train Epoch: 5 [3000/27366 (11%)]\tLoss: 0.561850\n",
      "Train Epoch: 5 [4000/27366 (15%)]\tLoss: 0.422203\n",
      "Train Epoch: 5 [5000/27366 (18%)]\tLoss: 0.440698\n",
      "Train Epoch: 5 [6000/27366 (22%)]\tLoss: 0.456243\n",
      "Train Epoch: 5 [7000/27366 (26%)]\tLoss: 0.505188\n",
      "Train Epoch: 5 [8000/27366 (29%)]\tLoss: 0.492826\n",
      "Train Epoch: 5 [9000/27366 (33%)]\tLoss: 0.414700\n",
      "Train Epoch: 5 [10000/27366 (36%)]\tLoss: 0.343073\n",
      "Train Epoch: 5 [11000/27366 (40%)]\tLoss: 0.481424\n",
      "Train Epoch: 5 [12000/27366 (44%)]\tLoss: 0.491798\n",
      "Train Epoch: 5 [13000/27366 (47%)]\tLoss: 0.356518\n",
      "Train Epoch: 5 [14000/27366 (51%)]\tLoss: 0.506379\n",
      "Train Epoch: 5 [15000/27366 (55%)]\tLoss: 0.583567\n",
      "Train Epoch: 5 [16000/27366 (58%)]\tLoss: 0.397496\n",
      "Train Epoch: 5 [17000/27366 (62%)]\tLoss: 0.581519\n",
      "Train Epoch: 5 [18000/27366 (66%)]\tLoss: 0.484965\n",
      "Train Epoch: 5 [19000/27366 (69%)]\tLoss: 0.408441\n",
      "Train Epoch: 5 [20000/27366 (73%)]\tLoss: 0.497069\n",
      "Train Epoch: 5 [21000/27366 (77%)]\tLoss: 0.427031\n",
      "Train Epoch: 5 [22000/27366 (80%)]\tLoss: 0.554750\n",
      "Train Epoch: 5 [23000/27366 (84%)]\tLoss: 0.366204\n",
      "Train Epoch: 5 [24000/27366 (88%)]\tLoss: 0.536410\n",
      "Train Epoch: 5 [25000/27366 (91%)]\tLoss: 0.398246\n",
      "Train Epoch: 5 [26000/27366 (95%)]\tLoss: 0.380460\n",
      "Train Epoch: 5 [27000/27366 (99%)]\tLoss: 0.579126\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/32634 (0%)]\tLoss: 0.480537\n",
      "Train Epoch: 1 [1000/32634 (3%)]\tLoss: 0.567887\n",
      "Train Epoch: 1 [2000/32634 (6%)]\tLoss: 0.470227\n",
      "Train Epoch: 1 [3000/32634 (9%)]\tLoss: 0.431472\n",
      "Train Epoch: 1 [4000/32634 (12%)]\tLoss: 0.367250\n",
      "Train Epoch: 1 [5000/32634 (15%)]\tLoss: 0.651298\n",
      "Train Epoch: 1 [6000/32634 (18%)]\tLoss: 0.424663\n",
      "Train Epoch: 1 [7000/32634 (21%)]\tLoss: 0.562385\n",
      "Train Epoch: 1 [8000/32634 (24%)]\tLoss: 0.453747\n",
      "Train Epoch: 1 [9000/32634 (28%)]\tLoss: 0.530732\n",
      "Train Epoch: 1 [10000/32634 (31%)]\tLoss: 0.474711\n",
      "Train Epoch: 1 [11000/32634 (34%)]\tLoss: 0.392568\n",
      "Train Epoch: 1 [12000/32634 (37%)]\tLoss: 0.501247\n",
      "Train Epoch: 1 [13000/32634 (40%)]\tLoss: 0.359100\n",
      "Train Epoch: 1 [14000/32634 (43%)]\tLoss: 0.511781\n",
      "Train Epoch: 1 [15000/32634 (46%)]\tLoss: 0.509596\n",
      "Train Epoch: 1 [16000/32634 (49%)]\tLoss: 0.544223\n",
      "Train Epoch: 1 [17000/32634 (52%)]\tLoss: 0.466822\n",
      "Train Epoch: 1 [18000/32634 (55%)]\tLoss: 0.499501\n",
      "Train Epoch: 1 [19000/32634 (58%)]\tLoss: 0.410363\n",
      "Train Epoch: 1 [20000/32634 (61%)]\tLoss: 0.471855\n",
      "Train Epoch: 1 [21000/32634 (64%)]\tLoss: 0.535640\n",
      "Train Epoch: 1 [22000/32634 (67%)]\tLoss: 0.419353\n",
      "Train Epoch: 1 [23000/32634 (70%)]\tLoss: 0.505532\n",
      "Train Epoch: 1 [24000/32634 (73%)]\tLoss: 0.544790\n",
      "Train Epoch: 1 [25000/32634 (76%)]\tLoss: 0.499313\n",
      "Train Epoch: 1 [26000/32634 (80%)]\tLoss: 0.426112\n",
      "Train Epoch: 1 [27000/32634 (83%)]\tLoss: 0.445045\n",
      "Train Epoch: 1 [28000/32634 (86%)]\tLoss: 0.470415\n",
      "Train Epoch: 1 [29000/32634 (89%)]\tLoss: 0.419072\n",
      "Train Epoch: 1 [30000/32634 (92%)]\tLoss: 0.557659\n",
      "Train Epoch: 1 [31000/32634 (95%)]\tLoss: 0.381008\n",
      "Train Epoch: 1 [32000/32634 (98%)]\tLoss: 0.522764\n",
      "Train Epoch: 2 [0/32634 (0%)]\tLoss: 0.440346\n",
      "Train Epoch: 2 [1000/32634 (3%)]\tLoss: 0.578684\n",
      "Train Epoch: 2 [2000/32634 (6%)]\tLoss: 0.534057\n",
      "Train Epoch: 2 [3000/32634 (9%)]\tLoss: 0.384574\n",
      "Train Epoch: 2 [4000/32634 (12%)]\tLoss: 0.410123\n",
      "Train Epoch: 2 [5000/32634 (15%)]\tLoss: 0.378780\n",
      "Train Epoch: 2 [6000/32634 (18%)]\tLoss: 0.497145\n",
      "Train Epoch: 2 [7000/32634 (21%)]\tLoss: 0.383464\n",
      "Train Epoch: 2 [8000/32634 (24%)]\tLoss: 0.556363\n",
      "Train Epoch: 2 [9000/32634 (28%)]\tLoss: 0.494098\n",
      "Train Epoch: 2 [10000/32634 (31%)]\tLoss: 0.294403\n",
      "Train Epoch: 2 [11000/32634 (34%)]\tLoss: 0.355466\n",
      "Train Epoch: 2 [12000/32634 (37%)]\tLoss: 0.269629\n",
      "Train Epoch: 2 [13000/32634 (40%)]\tLoss: 0.542010\n",
      "Train Epoch: 2 [14000/32634 (43%)]\tLoss: 0.593782\n",
      "Train Epoch: 2 [15000/32634 (46%)]\tLoss: 0.554876\n",
      "Train Epoch: 2 [16000/32634 (49%)]\tLoss: 0.375394\n",
      "Train Epoch: 2 [17000/32634 (52%)]\tLoss: 0.615597\n",
      "Train Epoch: 2 [18000/32634 (55%)]\tLoss: 0.537338\n",
      "Train Epoch: 2 [19000/32634 (58%)]\tLoss: 0.510046\n",
      "Train Epoch: 2 [20000/32634 (61%)]\tLoss: 0.492533\n",
      "Train Epoch: 2 [21000/32634 (64%)]\tLoss: 0.531911\n",
      "Train Epoch: 2 [22000/32634 (67%)]\tLoss: 0.402418\n",
      "Train Epoch: 2 [23000/32634 (70%)]\tLoss: 0.487143\n",
      "Train Epoch: 2 [24000/32634 (73%)]\tLoss: 0.431673\n",
      "Train Epoch: 2 [25000/32634 (76%)]\tLoss: 0.530250\n",
      "Train Epoch: 2 [26000/32634 (80%)]\tLoss: 0.374348\n",
      "Train Epoch: 2 [27000/32634 (83%)]\tLoss: 0.475278\n",
      "Train Epoch: 2 [28000/32634 (86%)]\tLoss: 0.405813\n",
      "Train Epoch: 2 [29000/32634 (89%)]\tLoss: 0.526831\n",
      "Train Epoch: 2 [30000/32634 (92%)]\tLoss: 0.516582\n",
      "Train Epoch: 2 [31000/32634 (95%)]\tLoss: 0.491685\n",
      "Train Epoch: 2 [32000/32634 (98%)]\tLoss: 0.430744\n",
      "Train Epoch: 3 [0/32634 (0%)]\tLoss: 0.494547\n",
      "Train Epoch: 3 [1000/32634 (3%)]\tLoss: 0.616695\n",
      "Train Epoch: 3 [2000/32634 (6%)]\tLoss: 0.356216\n",
      "Train Epoch: 3 [3000/32634 (9%)]\tLoss: 0.373112\n",
      "Train Epoch: 3 [4000/32634 (12%)]\tLoss: 0.448008\n",
      "Train Epoch: 3 [5000/32634 (15%)]\tLoss: 0.527172\n",
      "Train Epoch: 3 [6000/32634 (18%)]\tLoss: 0.699851\n",
      "Train Epoch: 3 [7000/32634 (21%)]\tLoss: 0.407621\n",
      "Train Epoch: 3 [8000/32634 (24%)]\tLoss: 0.433049\n",
      "Train Epoch: 3 [9000/32634 (28%)]\tLoss: 0.420781\n",
      "Train Epoch: 3 [10000/32634 (31%)]\tLoss: 0.328931\n",
      "Train Epoch: 3 [11000/32634 (34%)]\tLoss: 0.424878\n",
      "Train Epoch: 3 [12000/32634 (37%)]\tLoss: 0.531957\n",
      "Train Epoch: 3 [13000/32634 (40%)]\tLoss: 0.499773\n",
      "Train Epoch: 3 [14000/32634 (43%)]\tLoss: 0.503923\n",
      "Train Epoch: 3 [15000/32634 (46%)]\tLoss: 0.460318\n",
      "Train Epoch: 3 [16000/32634 (49%)]\tLoss: 0.561717\n",
      "Train Epoch: 3 [17000/32634 (52%)]\tLoss: 0.447646\n",
      "Train Epoch: 3 [18000/32634 (55%)]\tLoss: 0.395528\n",
      "Train Epoch: 3 [19000/32634 (58%)]\tLoss: 0.675894\n",
      "Train Epoch: 3 [20000/32634 (61%)]\tLoss: 0.474209\n",
      "Train Epoch: 3 [21000/32634 (64%)]\tLoss: 0.434855\n",
      "Train Epoch: 3 [22000/32634 (67%)]\tLoss: 0.458766\n",
      "Train Epoch: 3 [23000/32634 (70%)]\tLoss: 0.327975\n",
      "Train Epoch: 3 [24000/32634 (73%)]\tLoss: 0.414086\n",
      "Train Epoch: 3 [25000/32634 (76%)]\tLoss: 0.557217\n",
      "Train Epoch: 3 [26000/32634 (80%)]\tLoss: 0.317849\n",
      "Train Epoch: 3 [27000/32634 (83%)]\tLoss: 0.449977\n",
      "Train Epoch: 3 [28000/32634 (86%)]\tLoss: 0.525605\n",
      "Train Epoch: 3 [29000/32634 (89%)]\tLoss: 0.494288\n",
      "Train Epoch: 3 [30000/32634 (92%)]\tLoss: 0.579323\n",
      "Train Epoch: 3 [31000/32634 (95%)]\tLoss: 0.436557\n",
      "Train Epoch: 3 [32000/32634 (98%)]\tLoss: 0.514572\n",
      "Train Epoch: 4 [0/32634 (0%)]\tLoss: 0.354610\n",
      "Train Epoch: 4 [1000/32634 (3%)]\tLoss: 0.478722\n",
      "Train Epoch: 4 [2000/32634 (6%)]\tLoss: 0.460886\n",
      "Train Epoch: 4 [3000/32634 (9%)]\tLoss: 0.487682\n",
      "Train Epoch: 4 [4000/32634 (12%)]\tLoss: 0.480174\n",
      "Train Epoch: 4 [5000/32634 (15%)]\tLoss: 0.395039\n",
      "Train Epoch: 4 [6000/32634 (18%)]\tLoss: 0.335048\n",
      "Train Epoch: 4 [7000/32634 (21%)]\tLoss: 0.378422\n",
      "Train Epoch: 4 [8000/32634 (24%)]\tLoss: 0.575627\n",
      "Train Epoch: 4 [9000/32634 (28%)]\tLoss: 0.365406\n",
      "Train Epoch: 4 [10000/32634 (31%)]\tLoss: 0.468862\n",
      "Train Epoch: 4 [11000/32634 (34%)]\tLoss: 0.580994\n",
      "Train Epoch: 4 [12000/32634 (37%)]\tLoss: 0.441436\n",
      "Train Epoch: 4 [13000/32634 (40%)]\tLoss: 0.486276\n",
      "Train Epoch: 4 [14000/32634 (43%)]\tLoss: 0.392597\n",
      "Train Epoch: 4 [15000/32634 (46%)]\tLoss: 0.484040\n",
      "Train Epoch: 4 [16000/32634 (49%)]\tLoss: 0.567971\n",
      "Train Epoch: 4 [17000/32634 (52%)]\tLoss: 0.482689\n",
      "Train Epoch: 4 [18000/32634 (55%)]\tLoss: 0.790029\n",
      "Train Epoch: 4 [19000/32634 (58%)]\tLoss: 0.411594\n",
      "Train Epoch: 4 [20000/32634 (61%)]\tLoss: 0.483930\n",
      "Train Epoch: 4 [21000/32634 (64%)]\tLoss: 0.483124\n",
      "Train Epoch: 4 [22000/32634 (67%)]\tLoss: 0.603396\n",
      "Train Epoch: 4 [23000/32634 (70%)]\tLoss: 0.476203\n",
      "Train Epoch: 4 [24000/32634 (73%)]\tLoss: 0.477630\n",
      "Train Epoch: 4 [25000/32634 (76%)]\tLoss: 0.439205\n",
      "Train Epoch: 4 [26000/32634 (80%)]\tLoss: 0.456883\n",
      "Train Epoch: 4 [27000/32634 (83%)]\tLoss: 0.433139\n",
      "Train Epoch: 4 [28000/32634 (86%)]\tLoss: 0.579293\n",
      "Train Epoch: 4 [29000/32634 (89%)]\tLoss: 0.446226\n",
      "Train Epoch: 4 [30000/32634 (92%)]\tLoss: 0.389136\n",
      "Train Epoch: 4 [31000/32634 (95%)]\tLoss: 0.422039\n",
      "Train Epoch: 4 [32000/32634 (98%)]\tLoss: 0.474599\n",
      "Train Epoch: 5 [0/32634 (0%)]\tLoss: 0.535817\n",
      "Train Epoch: 5 [1000/32634 (3%)]\tLoss: 0.344616\n",
      "Train Epoch: 5 [2000/32634 (6%)]\tLoss: 0.434364\n",
      "Train Epoch: 5 [3000/32634 (9%)]\tLoss: 0.298161\n",
      "Train Epoch: 5 [4000/32634 (12%)]\tLoss: 0.426893\n",
      "Train Epoch: 5 [5000/32634 (15%)]\tLoss: 0.407043\n",
      "Train Epoch: 5 [6000/32634 (18%)]\tLoss: 0.527202\n",
      "Train Epoch: 5 [7000/32634 (21%)]\tLoss: 0.505704\n",
      "Train Epoch: 5 [8000/32634 (24%)]\tLoss: 0.421092\n",
      "Train Epoch: 5 [9000/32634 (28%)]\tLoss: 0.402151\n",
      "Train Epoch: 5 [10000/32634 (31%)]\tLoss: 0.427041\n",
      "Train Epoch: 5 [11000/32634 (34%)]\tLoss: 0.552669\n",
      "Train Epoch: 5 [12000/32634 (37%)]\tLoss: 0.363655\n",
      "Train Epoch: 5 [13000/32634 (40%)]\tLoss: 0.466614\n",
      "Train Epoch: 5 [14000/32634 (43%)]\tLoss: 0.437538\n",
      "Train Epoch: 5 [15000/32634 (46%)]\tLoss: 0.498880\n",
      "Train Epoch: 5 [16000/32634 (49%)]\tLoss: 0.402292\n",
      "Train Epoch: 5 [17000/32634 (52%)]\tLoss: 0.528872\n",
      "Train Epoch: 5 [18000/32634 (55%)]\tLoss: 0.412448\n",
      "Train Epoch: 5 [19000/32634 (58%)]\tLoss: 0.613566\n",
      "Train Epoch: 5 [20000/32634 (61%)]\tLoss: 0.455577\n",
      "Train Epoch: 5 [21000/32634 (64%)]\tLoss: 0.506167\n",
      "Train Epoch: 5 [22000/32634 (67%)]\tLoss: 0.435716\n",
      "Train Epoch: 5 [23000/32634 (70%)]\tLoss: 0.419825\n",
      "Train Epoch: 5 [24000/32634 (73%)]\tLoss: 0.597970\n",
      "Train Epoch: 5 [25000/32634 (76%)]\tLoss: 0.335871\n",
      "Train Epoch: 5 [26000/32634 (80%)]\tLoss: 0.510091\n",
      "Train Epoch: 5 [27000/32634 (83%)]\tLoss: 0.578080\n",
      "Train Epoch: 5 [28000/32634 (86%)]\tLoss: 0.528689\n",
      "Train Epoch: 5 [29000/32634 (89%)]\tLoss: 0.405129\n",
      "Train Epoch: 5 [30000/32634 (92%)]\tLoss: 0.524054\n",
      "Train Epoch: 5 [31000/32634 (95%)]\tLoss: 0.550654\n",
      "Train Epoch: 5 [32000/32634 (98%)]\tLoss: 0.502301\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8537, Accuracy: 7621/10000 (76%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/15622 (0%)]\tLoss: 0.376890\n",
      "Train Epoch: 1 [1000/15622 (6%)]\tLoss: 0.711890\n",
      "Train Epoch: 1 [2000/15622 (13%)]\tLoss: 0.378366\n",
      "Train Epoch: 1 [3000/15622 (19%)]\tLoss: 0.385146\n",
      "Train Epoch: 1 [4000/15622 (25%)]\tLoss: 0.433550\n",
      "Train Epoch: 1 [5000/15622 (32%)]\tLoss: 0.711389\n",
      "Train Epoch: 1 [6000/15622 (38%)]\tLoss: 0.415317\n",
      "Train Epoch: 1 [7000/15622 (45%)]\tLoss: 0.429858\n",
      "Train Epoch: 1 [8000/15622 (51%)]\tLoss: 0.552725\n",
      "Train Epoch: 1 [9000/15622 (57%)]\tLoss: 0.502785\n",
      "Train Epoch: 1 [10000/15622 (64%)]\tLoss: 0.570943\n",
      "Train Epoch: 1 [11000/15622 (70%)]\tLoss: 0.538997\n",
      "Train Epoch: 1 [12000/15622 (76%)]\tLoss: 0.399424\n",
      "Train Epoch: 1 [13000/15622 (83%)]\tLoss: 0.354408\n",
      "Train Epoch: 1 [14000/15622 (89%)]\tLoss: 0.441385\n",
      "Train Epoch: 1 [15000/15622 (96%)]\tLoss: 0.523837\n",
      "Train Epoch: 2 [0/15622 (0%)]\tLoss: 0.373571\n",
      "Train Epoch: 2 [1000/15622 (6%)]\tLoss: 0.341491\n",
      "Train Epoch: 2 [2000/15622 (13%)]\tLoss: 0.421489\n",
      "Train Epoch: 2 [3000/15622 (19%)]\tLoss: 0.571502\n",
      "Train Epoch: 2 [4000/15622 (25%)]\tLoss: 0.453739\n",
      "Train Epoch: 2 [5000/15622 (32%)]\tLoss: 0.308467\n",
      "Train Epoch: 2 [6000/15622 (38%)]\tLoss: 0.528375\n",
      "Train Epoch: 2 [7000/15622 (45%)]\tLoss: 0.459498\n",
      "Train Epoch: 2 [8000/15622 (51%)]\tLoss: 0.350933\n",
      "Train Epoch: 2 [9000/15622 (57%)]\tLoss: 0.486830\n",
      "Train Epoch: 2 [10000/15622 (64%)]\tLoss: 0.418539\n",
      "Train Epoch: 2 [11000/15622 (70%)]\tLoss: 0.361476\n",
      "Train Epoch: 2 [12000/15622 (76%)]\tLoss: 0.506967\n",
      "Train Epoch: 2 [13000/15622 (83%)]\tLoss: 0.439668\n",
      "Train Epoch: 2 [14000/15622 (89%)]\tLoss: 0.573978\n",
      "Train Epoch: 2 [15000/15622 (96%)]\tLoss: 0.387608\n",
      "Train Epoch: 3 [0/15622 (0%)]\tLoss: 0.385123\n",
      "Train Epoch: 3 [1000/15622 (6%)]\tLoss: 0.527747\n",
      "Train Epoch: 3 [2000/15622 (13%)]\tLoss: 0.595027\n",
      "Train Epoch: 3 [3000/15622 (19%)]\tLoss: 0.380729\n",
      "Train Epoch: 3 [4000/15622 (25%)]\tLoss: 0.490248\n",
      "Train Epoch: 3 [5000/15622 (32%)]\tLoss: 0.459610\n",
      "Train Epoch: 3 [6000/15622 (38%)]\tLoss: 0.447263\n",
      "Train Epoch: 3 [7000/15622 (45%)]\tLoss: 0.442626\n",
      "Train Epoch: 3 [8000/15622 (51%)]\tLoss: 0.454319\n",
      "Train Epoch: 3 [9000/15622 (57%)]\tLoss: 0.514655\n",
      "Train Epoch: 3 [10000/15622 (64%)]\tLoss: 0.435744\n",
      "Train Epoch: 3 [11000/15622 (70%)]\tLoss: 0.514194\n",
      "Train Epoch: 3 [12000/15622 (76%)]\tLoss: 0.480313\n",
      "Train Epoch: 3 [13000/15622 (83%)]\tLoss: 0.523029\n",
      "Train Epoch: 3 [14000/15622 (89%)]\tLoss: 0.401657\n",
      "Train Epoch: 3 [15000/15622 (96%)]\tLoss: 0.452340\n",
      "Train Epoch: 4 [0/15622 (0%)]\tLoss: 0.610842\n",
      "Train Epoch: 4 [1000/15622 (6%)]\tLoss: 0.292799\n",
      "Train Epoch: 4 [2000/15622 (13%)]\tLoss: 0.300041\n",
      "Train Epoch: 4 [3000/15622 (19%)]\tLoss: 0.365948\n",
      "Train Epoch: 4 [4000/15622 (25%)]\tLoss: 0.486506\n",
      "Train Epoch: 4 [5000/15622 (32%)]\tLoss: 0.509542\n",
      "Train Epoch: 4 [6000/15622 (38%)]\tLoss: 0.338920\n",
      "Train Epoch: 4 [7000/15622 (45%)]\tLoss: 0.429180\n",
      "Train Epoch: 4 [8000/15622 (51%)]\tLoss: 0.418562\n",
      "Train Epoch: 4 [9000/15622 (57%)]\tLoss: 0.527867\n",
      "Train Epoch: 4 [10000/15622 (64%)]\tLoss: 0.416621\n",
      "Train Epoch: 4 [11000/15622 (70%)]\tLoss: 0.491113\n",
      "Train Epoch: 4 [12000/15622 (76%)]\tLoss: 0.371146\n",
      "Train Epoch: 4 [13000/15622 (83%)]\tLoss: 0.525938\n",
      "Train Epoch: 4 [14000/15622 (89%)]\tLoss: 0.498108\n",
      "Train Epoch: 4 [15000/15622 (96%)]\tLoss: 0.467352\n",
      "Train Epoch: 5 [0/15622 (0%)]\tLoss: 0.388625\n",
      "Train Epoch: 5 [1000/15622 (6%)]\tLoss: 0.489246\n",
      "Train Epoch: 5 [2000/15622 (13%)]\tLoss: 0.431894\n",
      "Train Epoch: 5 [3000/15622 (19%)]\tLoss: 0.384333\n",
      "Train Epoch: 5 [4000/15622 (25%)]\tLoss: 0.468428\n",
      "Train Epoch: 5 [5000/15622 (32%)]\tLoss: 0.411908\n",
      "Train Epoch: 5 [6000/15622 (38%)]\tLoss: 0.431048\n",
      "Train Epoch: 5 [7000/15622 (45%)]\tLoss: 0.436971\n",
      "Train Epoch: 5 [8000/15622 (51%)]\tLoss: 0.390764\n",
      "Train Epoch: 5 [9000/15622 (57%)]\tLoss: 0.452364\n",
      "Train Epoch: 5 [10000/15622 (64%)]\tLoss: 0.526007\n",
      "Train Epoch: 5 [11000/15622 (70%)]\tLoss: 0.416120\n",
      "Train Epoch: 5 [12000/15622 (76%)]\tLoss: 0.382419\n",
      "Train Epoch: 5 [13000/15622 (83%)]\tLoss: 0.301547\n",
      "Train Epoch: 5 [14000/15622 (89%)]\tLoss: 0.350006\n",
      "Train Epoch: 5 [15000/15622 (96%)]\tLoss: 0.368764\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/19274 (0%)]\tLoss: 0.389248\n",
      "Train Epoch: 1 [1000/19274 (5%)]\tLoss: 0.211917\n",
      "Train Epoch: 1 [2000/19274 (10%)]\tLoss: 0.415322\n",
      "Train Epoch: 1 [3000/19274 (16%)]\tLoss: 0.338782\n",
      "Train Epoch: 1 [4000/19274 (21%)]\tLoss: 0.353550\n",
      "Train Epoch: 1 [5000/19274 (26%)]\tLoss: 0.454921\n",
      "Train Epoch: 1 [6000/19274 (31%)]\tLoss: 0.289261\n",
      "Train Epoch: 1 [7000/19274 (36%)]\tLoss: 0.361669\n",
      "Train Epoch: 1 [8000/19274 (41%)]\tLoss: 0.362486\n",
      "Train Epoch: 1 [9000/19274 (47%)]\tLoss: 0.295012\n",
      "Train Epoch: 1 [10000/19274 (52%)]\tLoss: 0.367195\n",
      "Train Epoch: 1 [11000/19274 (57%)]\tLoss: 0.340362\n",
      "Train Epoch: 1 [12000/19274 (62%)]\tLoss: 0.318764\n",
      "Train Epoch: 1 [13000/19274 (67%)]\tLoss: 0.353744\n",
      "Train Epoch: 1 [14000/19274 (73%)]\tLoss: 0.554138\n",
      "Train Epoch: 1 [15000/19274 (78%)]\tLoss: 0.494969\n",
      "Train Epoch: 1 [16000/19274 (83%)]\tLoss: 0.640068\n",
      "Train Epoch: 1 [17000/19274 (88%)]\tLoss: 0.516787\n",
      "Train Epoch: 1 [18000/19274 (93%)]\tLoss: 0.225627\n",
      "Train Epoch: 1 [19000/19274 (98%)]\tLoss: 0.421541\n",
      "Train Epoch: 2 [0/19274 (0%)]\tLoss: 0.398873\n",
      "Train Epoch: 2 [1000/19274 (5%)]\tLoss: 0.277429\n",
      "Train Epoch: 2 [2000/19274 (10%)]\tLoss: 0.522480\n",
      "Train Epoch: 2 [3000/19274 (16%)]\tLoss: 0.388728\n",
      "Train Epoch: 2 [4000/19274 (21%)]\tLoss: 0.352112\n",
      "Train Epoch: 2 [5000/19274 (26%)]\tLoss: 0.393544\n",
      "Train Epoch: 2 [6000/19274 (31%)]\tLoss: 0.463119\n",
      "Train Epoch: 2 [7000/19274 (36%)]\tLoss: 0.455535\n",
      "Train Epoch: 2 [8000/19274 (41%)]\tLoss: 0.301352\n",
      "Train Epoch: 2 [9000/19274 (47%)]\tLoss: 0.337169\n",
      "Train Epoch: 2 [10000/19274 (52%)]\tLoss: 0.351561\n",
      "Train Epoch: 2 [11000/19274 (57%)]\tLoss: 0.378684\n",
      "Train Epoch: 2 [12000/19274 (62%)]\tLoss: 0.463466\n",
      "Train Epoch: 2 [13000/19274 (67%)]\tLoss: 0.437290\n",
      "Train Epoch: 2 [14000/19274 (73%)]\tLoss: 0.467709\n",
      "Train Epoch: 2 [15000/19274 (78%)]\tLoss: 0.346387\n",
      "Train Epoch: 2 [16000/19274 (83%)]\tLoss: 0.255738\n",
      "Train Epoch: 2 [17000/19274 (88%)]\tLoss: 0.516145\n",
      "Train Epoch: 2 [18000/19274 (93%)]\tLoss: 0.490164\n",
      "Train Epoch: 2 [19000/19274 (98%)]\tLoss: 0.431649\n",
      "Train Epoch: 3 [0/19274 (0%)]\tLoss: 0.508169\n",
      "Train Epoch: 3 [1000/19274 (5%)]\tLoss: 0.421660\n",
      "Train Epoch: 3 [2000/19274 (10%)]\tLoss: 0.375943\n",
      "Train Epoch: 3 [3000/19274 (16%)]\tLoss: 0.324057\n",
      "Train Epoch: 3 [4000/19274 (21%)]\tLoss: 0.339982\n",
      "Train Epoch: 3 [5000/19274 (26%)]\tLoss: 0.377329\n",
      "Train Epoch: 3 [6000/19274 (31%)]\tLoss: 0.445848\n",
      "Train Epoch: 3 [7000/19274 (36%)]\tLoss: 0.462793\n",
      "Train Epoch: 3 [8000/19274 (41%)]\tLoss: 0.484480\n",
      "Train Epoch: 3 [9000/19274 (47%)]\tLoss: 0.301475\n",
      "Train Epoch: 3 [10000/19274 (52%)]\tLoss: 0.420084\n",
      "Train Epoch: 3 [11000/19274 (57%)]\tLoss: 0.410384\n",
      "Train Epoch: 3 [12000/19274 (62%)]\tLoss: 0.247673\n",
      "Train Epoch: 3 [13000/19274 (67%)]\tLoss: 0.473145\n",
      "Train Epoch: 3 [14000/19274 (73%)]\tLoss: 0.485802\n",
      "Train Epoch: 3 [15000/19274 (78%)]\tLoss: 0.380401\n",
      "Train Epoch: 3 [16000/19274 (83%)]\tLoss: 0.390141\n",
      "Train Epoch: 3 [17000/19274 (88%)]\tLoss: 0.367259\n",
      "Train Epoch: 3 [18000/19274 (93%)]\tLoss: 0.390956\n",
      "Train Epoch: 3 [19000/19274 (98%)]\tLoss: 0.358345\n",
      "Train Epoch: 4 [0/19274 (0%)]\tLoss: 0.526225\n",
      "Train Epoch: 4 [1000/19274 (5%)]\tLoss: 0.439323\n",
      "Train Epoch: 4 [2000/19274 (10%)]\tLoss: 0.294635\n",
      "Train Epoch: 4 [3000/19274 (16%)]\tLoss: 0.553046\n",
      "Train Epoch: 4 [4000/19274 (21%)]\tLoss: 0.441294\n",
      "Train Epoch: 4 [5000/19274 (26%)]\tLoss: 0.365368\n",
      "Train Epoch: 4 [6000/19274 (31%)]\tLoss: 0.404243\n",
      "Train Epoch: 4 [7000/19274 (36%)]\tLoss: 0.398421\n",
      "Train Epoch: 4 [8000/19274 (41%)]\tLoss: 0.297340\n",
      "Train Epoch: 4 [9000/19274 (47%)]\tLoss: 0.451918\n",
      "Train Epoch: 4 [10000/19274 (52%)]\tLoss: 0.356315\n",
      "Train Epoch: 4 [11000/19274 (57%)]\tLoss: 0.379316\n",
      "Train Epoch: 4 [12000/19274 (62%)]\tLoss: 0.370788\n",
      "Train Epoch: 4 [13000/19274 (67%)]\tLoss: 0.431737\n",
      "Train Epoch: 4 [14000/19274 (73%)]\tLoss: 0.355644\n",
      "Train Epoch: 4 [15000/19274 (78%)]\tLoss: 0.508271\n",
      "Train Epoch: 4 [16000/19274 (83%)]\tLoss: 0.429297\n",
      "Train Epoch: 4 [17000/19274 (88%)]\tLoss: 0.318276\n",
      "Train Epoch: 4 [18000/19274 (93%)]\tLoss: 0.461944\n",
      "Train Epoch: 4 [19000/19274 (98%)]\tLoss: 0.234312\n",
      "Train Epoch: 5 [0/19274 (0%)]\tLoss: 0.333531\n",
      "Train Epoch: 5 [1000/19274 (5%)]\tLoss: 0.423212\n",
      "Train Epoch: 5 [2000/19274 (10%)]\tLoss: 0.411377\n",
      "Train Epoch: 5 [3000/19274 (16%)]\tLoss: 0.328744\n",
      "Train Epoch: 5 [4000/19274 (21%)]\tLoss: 0.418504\n",
      "Train Epoch: 5 [5000/19274 (26%)]\tLoss: 0.385644\n",
      "Train Epoch: 5 [6000/19274 (31%)]\tLoss: 0.448817\n",
      "Train Epoch: 5 [7000/19274 (36%)]\tLoss: 0.523785\n",
      "Train Epoch: 5 [8000/19274 (41%)]\tLoss: 0.302843\n",
      "Train Epoch: 5 [9000/19274 (47%)]\tLoss: 0.278779\n",
      "Train Epoch: 5 [10000/19274 (52%)]\tLoss: 0.390291\n",
      "Train Epoch: 5 [11000/19274 (57%)]\tLoss: 0.510118\n",
      "Train Epoch: 5 [12000/19274 (62%)]\tLoss: 0.317567\n",
      "Train Epoch: 5 [13000/19274 (67%)]\tLoss: 0.426307\n",
      "Train Epoch: 5 [14000/19274 (73%)]\tLoss: 0.305803\n",
      "Train Epoch: 5 [15000/19274 (78%)]\tLoss: 0.296618\n",
      "Train Epoch: 5 [16000/19274 (83%)]\tLoss: 0.385188\n",
      "Train Epoch: 5 [17000/19274 (88%)]\tLoss: 0.352928\n",
      "Train Epoch: 5 [18000/19274 (93%)]\tLoss: 0.333031\n",
      "Train Epoch: 5 [19000/19274 (98%)]\tLoss: 0.284632\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/16239 (0%)]\tLoss: 0.466985\n",
      "Train Epoch: 1 [1000/16239 (6%)]\tLoss: 0.349246\n",
      "Train Epoch: 1 [2000/16239 (12%)]\tLoss: 0.364364\n",
      "Train Epoch: 1 [3000/16239 (18%)]\tLoss: 0.329435\n",
      "Train Epoch: 1 [4000/16239 (25%)]\tLoss: 0.303899\n",
      "Train Epoch: 1 [5000/16239 (31%)]\tLoss: 0.428825\n",
      "Train Epoch: 1 [6000/16239 (37%)]\tLoss: 0.543709\n",
      "Train Epoch: 1 [7000/16239 (43%)]\tLoss: 0.324363\n",
      "Train Epoch: 1 [8000/16239 (49%)]\tLoss: 0.385964\n",
      "Train Epoch: 1 [9000/16239 (55%)]\tLoss: 0.524159\n",
      "Train Epoch: 1 [10000/16239 (61%)]\tLoss: 0.290463\n",
      "Train Epoch: 1 [11000/16239 (67%)]\tLoss: 0.344241\n",
      "Train Epoch: 1 [12000/16239 (74%)]\tLoss: 0.338852\n",
      "Train Epoch: 1 [13000/16239 (80%)]\tLoss: 0.374199\n",
      "Train Epoch: 1 [14000/16239 (86%)]\tLoss: 0.317120\n",
      "Train Epoch: 1 [15000/16239 (92%)]\tLoss: 0.306060\n",
      "Train Epoch: 1 [16000/16239 (98%)]\tLoss: 0.407783\n",
      "Train Epoch: 2 [0/16239 (0%)]\tLoss: 0.456412\n",
      "Train Epoch: 2 [1000/16239 (6%)]\tLoss: 0.231515\n",
      "Train Epoch: 2 [2000/16239 (12%)]\tLoss: 0.365202\n",
      "Train Epoch: 2 [3000/16239 (18%)]\tLoss: 0.358010\n",
      "Train Epoch: 2 [4000/16239 (25%)]\tLoss: 0.518551\n",
      "Train Epoch: 2 [5000/16239 (31%)]\tLoss: 0.410362\n",
      "Train Epoch: 2 [6000/16239 (37%)]\tLoss: 0.429060\n",
      "Train Epoch: 2 [7000/16239 (43%)]\tLoss: 0.472357\n",
      "Train Epoch: 2 [8000/16239 (49%)]\tLoss: 0.368682\n",
      "Train Epoch: 2 [9000/16239 (55%)]\tLoss: 0.295090\n",
      "Train Epoch: 2 [10000/16239 (61%)]\tLoss: 0.354261\n",
      "Train Epoch: 2 [11000/16239 (67%)]\tLoss: 0.444039\n",
      "Train Epoch: 2 [12000/16239 (74%)]\tLoss: 0.348550\n",
      "Train Epoch: 2 [13000/16239 (80%)]\tLoss: 0.439828\n",
      "Train Epoch: 2 [14000/16239 (86%)]\tLoss: 0.519739\n",
      "Train Epoch: 2 [15000/16239 (92%)]\tLoss: 0.283563\n",
      "Train Epoch: 2 [16000/16239 (98%)]\tLoss: 0.409485\n",
      "Train Epoch: 3 [0/16239 (0%)]\tLoss: 0.331962\n",
      "Train Epoch: 3 [1000/16239 (6%)]\tLoss: 0.416979\n",
      "Train Epoch: 3 [2000/16239 (12%)]\tLoss: 0.320553\n",
      "Train Epoch: 3 [3000/16239 (18%)]\tLoss: 0.428896\n",
      "Train Epoch: 3 [4000/16239 (25%)]\tLoss: 0.432929\n",
      "Train Epoch: 3 [5000/16239 (31%)]\tLoss: 0.329928\n",
      "Train Epoch: 3 [6000/16239 (37%)]\tLoss: 0.364529\n",
      "Train Epoch: 3 [7000/16239 (43%)]\tLoss: 0.497205\n",
      "Train Epoch: 3 [8000/16239 (49%)]\tLoss: 0.417310\n",
      "Train Epoch: 3 [9000/16239 (55%)]\tLoss: 0.419453\n",
      "Train Epoch: 3 [10000/16239 (61%)]\tLoss: 0.326711\n",
      "Train Epoch: 3 [11000/16239 (67%)]\tLoss: 0.445333\n",
      "Train Epoch: 3 [12000/16239 (74%)]\tLoss: 0.440695\n",
      "Train Epoch: 3 [13000/16239 (80%)]\tLoss: 0.403793\n",
      "Train Epoch: 3 [14000/16239 (86%)]\tLoss: 0.448517\n",
      "Train Epoch: 3 [15000/16239 (92%)]\tLoss: 0.392741\n",
      "Train Epoch: 3 [16000/16239 (98%)]\tLoss: 0.483732\n",
      "Train Epoch: 4 [0/16239 (0%)]\tLoss: 0.386077\n",
      "Train Epoch: 4 [1000/16239 (6%)]\tLoss: 0.308580\n",
      "Train Epoch: 4 [2000/16239 (12%)]\tLoss: 0.375004\n",
      "Train Epoch: 4 [3000/16239 (18%)]\tLoss: 0.370434\n",
      "Train Epoch: 4 [4000/16239 (25%)]\tLoss: 0.365792\n",
      "Train Epoch: 4 [5000/16239 (31%)]\tLoss: 0.352906\n",
      "Train Epoch: 4 [6000/16239 (37%)]\tLoss: 0.378202\n",
      "Train Epoch: 4 [7000/16239 (43%)]\tLoss: 0.389213\n",
      "Train Epoch: 4 [8000/16239 (49%)]\tLoss: 0.452368\n",
      "Train Epoch: 4 [9000/16239 (55%)]\tLoss: 0.401328\n",
      "Train Epoch: 4 [10000/16239 (61%)]\tLoss: 0.366353\n",
      "Train Epoch: 4 [11000/16239 (67%)]\tLoss: 0.532490\n",
      "Train Epoch: 4 [12000/16239 (74%)]\tLoss: 0.423813\n",
      "Train Epoch: 4 [13000/16239 (80%)]\tLoss: 0.288884\n",
      "Train Epoch: 4 [14000/16239 (86%)]\tLoss: 0.428658\n",
      "Train Epoch: 4 [15000/16239 (92%)]\tLoss: 0.408720\n",
      "Train Epoch: 4 [16000/16239 (98%)]\tLoss: 0.378202\n",
      "Train Epoch: 5 [0/16239 (0%)]\tLoss: 0.598872\n",
      "Train Epoch: 5 [1000/16239 (6%)]\tLoss: 0.358937\n",
      "Train Epoch: 5 [2000/16239 (12%)]\tLoss: 0.310126\n",
      "Train Epoch: 5 [3000/16239 (18%)]\tLoss: 0.266018\n",
      "Train Epoch: 5 [4000/16239 (25%)]\tLoss: 0.466886\n",
      "Train Epoch: 5 [5000/16239 (31%)]\tLoss: 0.480912\n",
      "Train Epoch: 5 [6000/16239 (37%)]\tLoss: 0.399393\n",
      "Train Epoch: 5 [7000/16239 (43%)]\tLoss: 0.412368\n",
      "Train Epoch: 5 [8000/16239 (49%)]\tLoss: 0.311456\n",
      "Train Epoch: 5 [9000/16239 (55%)]\tLoss: 0.429128\n",
      "Train Epoch: 5 [10000/16239 (61%)]\tLoss: 0.238406\n",
      "Train Epoch: 5 [11000/16239 (67%)]\tLoss: 0.350728\n",
      "Train Epoch: 5 [12000/16239 (74%)]\tLoss: 0.426797\n",
      "Train Epoch: 5 [13000/16239 (80%)]\tLoss: 0.356065\n",
      "Train Epoch: 5 [14000/16239 (86%)]\tLoss: 0.302194\n",
      "Train Epoch: 5 [15000/16239 (92%)]\tLoss: 0.238297\n",
      "Train Epoch: 5 [16000/16239 (98%)]\tLoss: 0.374804\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/8865 (0%)]\tLoss: 0.340317\n",
      "Train Epoch: 1 [1000/8865 (11%)]\tLoss: 0.394939\n",
      "Train Epoch: 1 [2000/8865 (22%)]\tLoss: 0.288895\n",
      "Train Epoch: 1 [3000/8865 (34%)]\tLoss: 0.574123\n",
      "Train Epoch: 1 [4000/8865 (45%)]\tLoss: 0.506019\n",
      "Train Epoch: 1 [5000/8865 (56%)]\tLoss: 0.522061\n",
      "Train Epoch: 1 [6000/8865 (67%)]\tLoss: 0.288750\n",
      "Train Epoch: 1 [7000/8865 (79%)]\tLoss: 0.506829\n",
      "Train Epoch: 1 [8000/8865 (90%)]\tLoss: 0.633386\n",
      "Train Epoch: 2 [0/8865 (0%)]\tLoss: 0.456783\n",
      "Train Epoch: 2 [1000/8865 (11%)]\tLoss: 0.333502\n",
      "Train Epoch: 2 [2000/8865 (22%)]\tLoss: 0.445757\n",
      "Train Epoch: 2 [3000/8865 (34%)]\tLoss: 0.388257\n",
      "Train Epoch: 2 [4000/8865 (45%)]\tLoss: 0.286218\n",
      "Train Epoch: 2 [5000/8865 (56%)]\tLoss: 0.503239\n",
      "Train Epoch: 2 [6000/8865 (67%)]\tLoss: 0.364609\n",
      "Train Epoch: 2 [7000/8865 (79%)]\tLoss: 0.421084\n",
      "Train Epoch: 2 [8000/8865 (90%)]\tLoss: 0.347212\n",
      "Train Epoch: 3 [0/8865 (0%)]\tLoss: 0.371472\n",
      "Train Epoch: 3 [1000/8865 (11%)]\tLoss: 0.481676\n",
      "Train Epoch: 3 [2000/8865 (22%)]\tLoss: 0.425462\n",
      "Train Epoch: 3 [3000/8865 (34%)]\tLoss: 0.311487\n",
      "Train Epoch: 3 [4000/8865 (45%)]\tLoss: 0.377734\n",
      "Train Epoch: 3 [5000/8865 (56%)]\tLoss: 0.321249\n",
      "Train Epoch: 3 [6000/8865 (67%)]\tLoss: 0.383966\n",
      "Train Epoch: 3 [7000/8865 (79%)]\tLoss: 0.455201\n",
      "Train Epoch: 3 [8000/8865 (90%)]\tLoss: 0.249365\n",
      "Train Epoch: 4 [0/8865 (0%)]\tLoss: 0.455918\n",
      "Train Epoch: 4 [1000/8865 (11%)]\tLoss: 0.468844\n",
      "Train Epoch: 4 [2000/8865 (22%)]\tLoss: 0.434955\n",
      "Train Epoch: 4 [3000/8865 (34%)]\tLoss: 0.419331\n",
      "Train Epoch: 4 [4000/8865 (45%)]\tLoss: 0.453960\n",
      "Train Epoch: 4 [5000/8865 (56%)]\tLoss: 0.357716\n",
      "Train Epoch: 4 [6000/8865 (67%)]\tLoss: 0.484864\n",
      "Train Epoch: 4 [7000/8865 (79%)]\tLoss: 0.418979\n",
      "Train Epoch: 4 [8000/8865 (90%)]\tLoss: 0.356354\n",
      "Train Epoch: 5 [0/8865 (0%)]\tLoss: 0.425141\n",
      "Train Epoch: 5 [1000/8865 (11%)]\tLoss: 0.354917\n",
      "Train Epoch: 5 [2000/8865 (22%)]\tLoss: 0.394424\n",
      "Train Epoch: 5 [3000/8865 (34%)]\tLoss: 0.335288\n",
      "Train Epoch: 5 [4000/8865 (45%)]\tLoss: 0.363737\n",
      "Train Epoch: 5 [5000/8865 (56%)]\tLoss: 0.431233\n",
      "Train Epoch: 5 [6000/8865 (67%)]\tLoss: 0.344708\n",
      "Train Epoch: 5 [7000/8865 (79%)]\tLoss: 0.415866\n",
      "Train Epoch: 5 [8000/8865 (90%)]\tLoss: 0.522926\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.7713, Accuracy: 7804/10000 (78%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/15622 (0%)]\tLoss: 0.585501\n",
      "Train Epoch: 1 [1000/15622 (6%)]\tLoss: 0.407688\n",
      "Train Epoch: 1 [2000/15622 (13%)]\tLoss: 0.466394\n",
      "Train Epoch: 1 [3000/15622 (19%)]\tLoss: 0.476574\n",
      "Train Epoch: 1 [4000/15622 (25%)]\tLoss: 0.325931\n",
      "Train Epoch: 1 [5000/15622 (32%)]\tLoss: 0.486161\n",
      "Train Epoch: 1 [6000/15622 (38%)]\tLoss: 0.554839\n",
      "Train Epoch: 1 [7000/15622 (45%)]\tLoss: 0.407904\n",
      "Train Epoch: 1 [8000/15622 (51%)]\tLoss: 0.354575\n",
      "Train Epoch: 1 [9000/15622 (57%)]\tLoss: 0.476519\n",
      "Train Epoch: 1 [10000/15622 (64%)]\tLoss: 0.397517\n",
      "Train Epoch: 1 [11000/15622 (70%)]\tLoss: 0.619765\n",
      "Train Epoch: 1 [12000/15622 (76%)]\tLoss: 0.511174\n",
      "Train Epoch: 1 [13000/15622 (83%)]\tLoss: 0.469191\n",
      "Train Epoch: 1 [14000/15622 (89%)]\tLoss: 0.406539\n",
      "Train Epoch: 1 [15000/15622 (96%)]\tLoss: 0.453320\n",
      "Train Epoch: 2 [0/15622 (0%)]\tLoss: 0.470046\n",
      "Train Epoch: 2 [1000/15622 (6%)]\tLoss: 0.333436\n",
      "Train Epoch: 2 [2000/15622 (13%)]\tLoss: 0.521570\n",
      "Train Epoch: 2 [3000/15622 (19%)]\tLoss: 0.493923\n",
      "Train Epoch: 2 [4000/15622 (25%)]\tLoss: 0.370767\n",
      "Train Epoch: 2 [5000/15622 (32%)]\tLoss: 0.376038\n",
      "Train Epoch: 2 [6000/15622 (38%)]\tLoss: 0.516026\n",
      "Train Epoch: 2 [7000/15622 (45%)]\tLoss: 0.409226\n",
      "Train Epoch: 2 [8000/15622 (51%)]\tLoss: 0.630781\n",
      "Train Epoch: 2 [9000/15622 (57%)]\tLoss: 0.280792\n",
      "Train Epoch: 2 [10000/15622 (64%)]\tLoss: 0.548639\n",
      "Train Epoch: 2 [11000/15622 (70%)]\tLoss: 0.562715\n",
      "Train Epoch: 2 [12000/15622 (76%)]\tLoss: 0.566900\n",
      "Train Epoch: 2 [13000/15622 (83%)]\tLoss: 0.370472\n",
      "Train Epoch: 2 [14000/15622 (89%)]\tLoss: 0.397952\n",
      "Train Epoch: 2 [15000/15622 (96%)]\tLoss: 0.421599\n",
      "Train Epoch: 3 [0/15622 (0%)]\tLoss: 0.495017\n",
      "Train Epoch: 3 [1000/15622 (6%)]\tLoss: 0.305831\n",
      "Train Epoch: 3 [2000/15622 (13%)]\tLoss: 0.494273\n",
      "Train Epoch: 3 [3000/15622 (19%)]\tLoss: 0.380806\n",
      "Train Epoch: 3 [4000/15622 (25%)]\tLoss: 0.467985\n",
      "Train Epoch: 3 [5000/15622 (32%)]\tLoss: 0.496456\n",
      "Train Epoch: 3 [6000/15622 (38%)]\tLoss: 0.469835\n",
      "Train Epoch: 3 [7000/15622 (45%)]\tLoss: 0.508162\n",
      "Train Epoch: 3 [8000/15622 (51%)]\tLoss: 0.463400\n",
      "Train Epoch: 3 [9000/15622 (57%)]\tLoss: 0.432420\n",
      "Train Epoch: 3 [10000/15622 (64%)]\tLoss: 0.404906\n",
      "Train Epoch: 3 [11000/15622 (70%)]\tLoss: 0.390079\n",
      "Train Epoch: 3 [12000/15622 (76%)]\tLoss: 0.471077\n",
      "Train Epoch: 3 [13000/15622 (83%)]\tLoss: 0.378418\n",
      "Train Epoch: 3 [14000/15622 (89%)]\tLoss: 0.477997\n",
      "Train Epoch: 3 [15000/15622 (96%)]\tLoss: 0.406004\n",
      "Train Epoch: 4 [0/15622 (0%)]\tLoss: 0.326459\n",
      "Train Epoch: 4 [1000/15622 (6%)]\tLoss: 0.462816\n",
      "Train Epoch: 4 [2000/15622 (13%)]\tLoss: 0.323080\n",
      "Train Epoch: 4 [3000/15622 (19%)]\tLoss: 0.480126\n",
      "Train Epoch: 4 [4000/15622 (25%)]\tLoss: 0.407429\n",
      "Train Epoch: 4 [5000/15622 (32%)]\tLoss: 0.392958\n",
      "Train Epoch: 4 [6000/15622 (38%)]\tLoss: 0.384203\n",
      "Train Epoch: 4 [7000/15622 (45%)]\tLoss: 0.369588\n",
      "Train Epoch: 4 [8000/15622 (51%)]\tLoss: 0.496690\n",
      "Train Epoch: 4 [9000/15622 (57%)]\tLoss: 0.500777\n",
      "Train Epoch: 4 [10000/15622 (64%)]\tLoss: 0.466804\n",
      "Train Epoch: 4 [11000/15622 (70%)]\tLoss: 0.407021\n",
      "Train Epoch: 4 [12000/15622 (76%)]\tLoss: 0.469764\n",
      "Train Epoch: 4 [13000/15622 (83%)]\tLoss: 0.393337\n",
      "Train Epoch: 4 [14000/15622 (89%)]\tLoss: 0.433210\n",
      "Train Epoch: 4 [15000/15622 (96%)]\tLoss: 0.369378\n",
      "Train Epoch: 5 [0/15622 (0%)]\tLoss: 0.383664\n",
      "Train Epoch: 5 [1000/15622 (6%)]\tLoss: 0.383610\n",
      "Train Epoch: 5 [2000/15622 (13%)]\tLoss: 0.362910\n",
      "Train Epoch: 5 [3000/15622 (19%)]\tLoss: 0.366571\n",
      "Train Epoch: 5 [4000/15622 (25%)]\tLoss: 0.525575\n",
      "Train Epoch: 5 [5000/15622 (32%)]\tLoss: 0.505938\n",
      "Train Epoch: 5 [6000/15622 (38%)]\tLoss: 0.460540\n",
      "Train Epoch: 5 [7000/15622 (45%)]\tLoss: 0.585548\n",
      "Train Epoch: 5 [8000/15622 (51%)]\tLoss: 0.473436\n",
      "Train Epoch: 5 [9000/15622 (57%)]\tLoss: 0.331116\n",
      "Train Epoch: 5 [10000/15622 (64%)]\tLoss: 0.492666\n",
      "Train Epoch: 5 [11000/15622 (70%)]\tLoss: 0.424795\n",
      "Train Epoch: 5 [12000/15622 (76%)]\tLoss: 0.412842\n",
      "Train Epoch: 5 [13000/15622 (83%)]\tLoss: 0.369074\n",
      "Train Epoch: 5 [14000/15622 (89%)]\tLoss: 0.399680\n",
      "Train Epoch: 5 [15000/15622 (96%)]\tLoss: 0.429338\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/19274 (0%)]\tLoss: 0.429398\n",
      "Train Epoch: 1 [1000/19274 (5%)]\tLoss: 0.222152\n",
      "Train Epoch: 1 [2000/19274 (10%)]\tLoss: 0.494576\n",
      "Train Epoch: 1 [3000/19274 (16%)]\tLoss: 0.279286\n",
      "Train Epoch: 1 [4000/19274 (21%)]\tLoss: 0.544095\n",
      "Train Epoch: 1 [5000/19274 (26%)]\tLoss: 0.420266\n",
      "Train Epoch: 1 [6000/19274 (31%)]\tLoss: 0.440338\n",
      "Train Epoch: 1 [7000/19274 (36%)]\tLoss: 0.413990\n",
      "Train Epoch: 1 [8000/19274 (41%)]\tLoss: 0.131781\n",
      "Train Epoch: 1 [9000/19274 (47%)]\tLoss: 0.419232\n",
      "Train Epoch: 1 [10000/19274 (52%)]\tLoss: 0.346061\n",
      "Train Epoch: 1 [11000/19274 (57%)]\tLoss: 0.224509\n",
      "Train Epoch: 1 [12000/19274 (62%)]\tLoss: 0.385716\n",
      "Train Epoch: 1 [13000/19274 (67%)]\tLoss: 0.534960\n",
      "Train Epoch: 1 [14000/19274 (73%)]\tLoss: 0.426755\n",
      "Train Epoch: 1 [15000/19274 (78%)]\tLoss: 0.347415\n",
      "Train Epoch: 1 [16000/19274 (83%)]\tLoss: 0.480114\n",
      "Train Epoch: 1 [17000/19274 (88%)]\tLoss: 0.459533\n",
      "Train Epoch: 1 [18000/19274 (93%)]\tLoss: 0.387281\n",
      "Train Epoch: 1 [19000/19274 (98%)]\tLoss: 0.477283\n",
      "Train Epoch: 2 [0/19274 (0%)]\tLoss: 0.484250\n",
      "Train Epoch: 2 [1000/19274 (5%)]\tLoss: 0.506184\n",
      "Train Epoch: 2 [2000/19274 (10%)]\tLoss: 0.426680\n",
      "Train Epoch: 2 [3000/19274 (16%)]\tLoss: 0.324314\n",
      "Train Epoch: 2 [4000/19274 (21%)]\tLoss: 0.321794\n",
      "Train Epoch: 2 [5000/19274 (26%)]\tLoss: 0.527039\n",
      "Train Epoch: 2 [6000/19274 (31%)]\tLoss: 0.348618\n",
      "Train Epoch: 2 [7000/19274 (36%)]\tLoss: 0.223384\n",
      "Train Epoch: 2 [8000/19274 (41%)]\tLoss: 0.258864\n",
      "Train Epoch: 2 [9000/19274 (47%)]\tLoss: 0.380221\n",
      "Train Epoch: 2 [10000/19274 (52%)]\tLoss: 0.367225\n",
      "Train Epoch: 2 [11000/19274 (57%)]\tLoss: 0.458010\n",
      "Train Epoch: 2 [12000/19274 (62%)]\tLoss: 0.298786\n",
      "Train Epoch: 2 [13000/19274 (67%)]\tLoss: 0.507012\n",
      "Train Epoch: 2 [14000/19274 (73%)]\tLoss: 0.391223\n",
      "Train Epoch: 2 [15000/19274 (78%)]\tLoss: 0.361588\n",
      "Train Epoch: 2 [16000/19274 (83%)]\tLoss: 0.420886\n",
      "Train Epoch: 2 [17000/19274 (88%)]\tLoss: 0.397483\n",
      "Train Epoch: 2 [18000/19274 (93%)]\tLoss: 0.386037\n",
      "Train Epoch: 2 [19000/19274 (98%)]\tLoss: 0.393182\n",
      "Train Epoch: 3 [0/19274 (0%)]\tLoss: 0.391990\n",
      "Train Epoch: 3 [1000/19274 (5%)]\tLoss: 0.340640\n",
      "Train Epoch: 3 [2000/19274 (10%)]\tLoss: 0.330305\n",
      "Train Epoch: 3 [3000/19274 (16%)]\tLoss: 0.189013\n",
      "Train Epoch: 3 [4000/19274 (21%)]\tLoss: 0.479703\n",
      "Train Epoch: 3 [5000/19274 (26%)]\tLoss: 0.451803\n",
      "Train Epoch: 3 [6000/19274 (31%)]\tLoss: 0.302087\n",
      "Train Epoch: 3 [7000/19274 (36%)]\tLoss: 0.352176\n",
      "Train Epoch: 3 [8000/19274 (41%)]\tLoss: 0.284927\n",
      "Train Epoch: 3 [9000/19274 (47%)]\tLoss: 0.282988\n",
      "Train Epoch: 3 [10000/19274 (52%)]\tLoss: 0.335758\n",
      "Train Epoch: 3 [11000/19274 (57%)]\tLoss: 0.420710\n",
      "Train Epoch: 3 [12000/19274 (62%)]\tLoss: 0.367491\n",
      "Train Epoch: 3 [13000/19274 (67%)]\tLoss: 0.490030\n",
      "Train Epoch: 3 [14000/19274 (73%)]\tLoss: 0.449433\n",
      "Train Epoch: 3 [15000/19274 (78%)]\tLoss: 0.314704\n",
      "Train Epoch: 3 [16000/19274 (83%)]\tLoss: 0.489296\n",
      "Train Epoch: 3 [17000/19274 (88%)]\tLoss: 0.253449\n",
      "Train Epoch: 3 [18000/19274 (93%)]\tLoss: 0.330706\n",
      "Train Epoch: 3 [19000/19274 (98%)]\tLoss: 0.385537\n",
      "Train Epoch: 4 [0/19274 (0%)]\tLoss: 0.303772\n",
      "Train Epoch: 4 [1000/19274 (5%)]\tLoss: 0.242116\n",
      "Train Epoch: 4 [2000/19274 (10%)]\tLoss: 0.493598\n",
      "Train Epoch: 4 [3000/19274 (16%)]\tLoss: 0.465162\n",
      "Train Epoch: 4 [4000/19274 (21%)]\tLoss: 0.494242\n",
      "Train Epoch: 4 [5000/19274 (26%)]\tLoss: 0.383205\n",
      "Train Epoch: 4 [6000/19274 (31%)]\tLoss: 0.322476\n",
      "Train Epoch: 4 [7000/19274 (36%)]\tLoss: 0.271037\n",
      "Train Epoch: 4 [8000/19274 (41%)]\tLoss: 0.412128\n",
      "Train Epoch: 4 [9000/19274 (47%)]\tLoss: 0.357256\n",
      "Train Epoch: 4 [10000/19274 (52%)]\tLoss: 0.269629\n",
      "Train Epoch: 4 [11000/19274 (57%)]\tLoss: 0.365247\n",
      "Train Epoch: 4 [12000/19274 (62%)]\tLoss: 0.382271\n",
      "Train Epoch: 4 [13000/19274 (67%)]\tLoss: 0.367457\n",
      "Train Epoch: 4 [14000/19274 (73%)]\tLoss: 0.345161\n",
      "Train Epoch: 4 [15000/19274 (78%)]\tLoss: 0.337598\n",
      "Train Epoch: 4 [16000/19274 (83%)]\tLoss: 0.344964\n",
      "Train Epoch: 4 [17000/19274 (88%)]\tLoss: 0.294507\n",
      "Train Epoch: 4 [18000/19274 (93%)]\tLoss: 0.281081\n",
      "Train Epoch: 4 [19000/19274 (98%)]\tLoss: 0.374027\n",
      "Train Epoch: 5 [0/19274 (0%)]\tLoss: 0.399544\n",
      "Train Epoch: 5 [1000/19274 (5%)]\tLoss: 0.318405\n",
      "Train Epoch: 5 [2000/19274 (10%)]\tLoss: 0.486904\n",
      "Train Epoch: 5 [3000/19274 (16%)]\tLoss: 0.442802\n",
      "Train Epoch: 5 [4000/19274 (21%)]\tLoss: 0.335068\n",
      "Train Epoch: 5 [5000/19274 (26%)]\tLoss: 0.437440\n",
      "Train Epoch: 5 [6000/19274 (31%)]\tLoss: 0.478753\n",
      "Train Epoch: 5 [7000/19274 (36%)]\tLoss: 0.443944\n",
      "Train Epoch: 5 [8000/19274 (41%)]\tLoss: 0.274983\n",
      "Train Epoch: 5 [9000/19274 (47%)]\tLoss: 0.365827\n",
      "Train Epoch: 5 [10000/19274 (52%)]\tLoss: 0.407615\n",
      "Train Epoch: 5 [11000/19274 (57%)]\tLoss: 0.337291\n",
      "Train Epoch: 5 [12000/19274 (62%)]\tLoss: 0.465778\n",
      "Train Epoch: 5 [13000/19274 (67%)]\tLoss: 0.454639\n",
      "Train Epoch: 5 [14000/19274 (73%)]\tLoss: 0.360695\n",
      "Train Epoch: 5 [15000/19274 (78%)]\tLoss: 0.460809\n",
      "Train Epoch: 5 [16000/19274 (83%)]\tLoss: 0.400649\n",
      "Train Epoch: 5 [17000/19274 (88%)]\tLoss: 0.194023\n",
      "Train Epoch: 5 [18000/19274 (93%)]\tLoss: 0.411845\n",
      "Train Epoch: 5 [19000/19274 (98%)]\tLoss: 0.430876\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/16239 (0%)]\tLoss: 0.523185\n",
      "Train Epoch: 1 [1000/16239 (6%)]\tLoss: 0.451828\n",
      "Train Epoch: 1 [2000/16239 (12%)]\tLoss: 0.342717\n",
      "Train Epoch: 1 [3000/16239 (18%)]\tLoss: 0.336988\n",
      "Train Epoch: 1 [4000/16239 (25%)]\tLoss: 0.311556\n",
      "Train Epoch: 1 [5000/16239 (31%)]\tLoss: 0.490501\n",
      "Train Epoch: 1 [6000/16239 (37%)]\tLoss: 0.507768\n",
      "Train Epoch: 1 [7000/16239 (43%)]\tLoss: 0.453684\n",
      "Train Epoch: 1 [8000/16239 (49%)]\tLoss: 0.301198\n",
      "Train Epoch: 1 [9000/16239 (55%)]\tLoss: 0.436279\n",
      "Train Epoch: 1 [10000/16239 (61%)]\tLoss: 0.495855\n",
      "Train Epoch: 1 [11000/16239 (67%)]\tLoss: 0.472091\n",
      "Train Epoch: 1 [12000/16239 (74%)]\tLoss: 0.393170\n",
      "Train Epoch: 1 [13000/16239 (80%)]\tLoss: 0.353024\n",
      "Train Epoch: 1 [14000/16239 (86%)]\tLoss: 0.281191\n",
      "Train Epoch: 1 [15000/16239 (92%)]\tLoss: 0.391302\n",
      "Train Epoch: 1 [16000/16239 (98%)]\tLoss: 0.293246\n",
      "Train Epoch: 2 [0/16239 (0%)]\tLoss: 0.461119\n",
      "Train Epoch: 2 [1000/16239 (6%)]\tLoss: 0.360790\n",
      "Train Epoch: 2 [2000/16239 (12%)]\tLoss: 0.335206\n",
      "Train Epoch: 2 [3000/16239 (18%)]\tLoss: 0.536183\n",
      "Train Epoch: 2 [4000/16239 (25%)]\tLoss: 0.495576\n",
      "Train Epoch: 2 [5000/16239 (31%)]\tLoss: 0.410482\n",
      "Train Epoch: 2 [6000/16239 (37%)]\tLoss: 0.345600\n",
      "Train Epoch: 2 [7000/16239 (43%)]\tLoss: 0.424900\n",
      "Train Epoch: 2 [8000/16239 (49%)]\tLoss: 0.333193\n",
      "Train Epoch: 2 [9000/16239 (55%)]\tLoss: 0.483562\n",
      "Train Epoch: 2 [10000/16239 (61%)]\tLoss: 0.446609\n",
      "Train Epoch: 2 [11000/16239 (67%)]\tLoss: 0.501988\n",
      "Train Epoch: 2 [12000/16239 (74%)]\tLoss: 0.494333\n",
      "Train Epoch: 2 [13000/16239 (80%)]\tLoss: 0.423681\n",
      "Train Epoch: 2 [14000/16239 (86%)]\tLoss: 0.455374\n",
      "Train Epoch: 2 [15000/16239 (92%)]\tLoss: 0.424963\n",
      "Train Epoch: 2 [16000/16239 (98%)]\tLoss: 0.342118\n",
      "Train Epoch: 3 [0/16239 (0%)]\tLoss: 0.487485\n",
      "Train Epoch: 3 [1000/16239 (6%)]\tLoss: 0.290897\n",
      "Train Epoch: 3 [2000/16239 (12%)]\tLoss: 0.520220\n",
      "Train Epoch: 3 [3000/16239 (18%)]\tLoss: 0.316910\n",
      "Train Epoch: 3 [4000/16239 (25%)]\tLoss: 0.334271\n",
      "Train Epoch: 3 [5000/16239 (31%)]\tLoss: 0.351905\n",
      "Train Epoch: 3 [6000/16239 (37%)]\tLoss: 0.353910\n",
      "Train Epoch: 3 [7000/16239 (43%)]\tLoss: 0.411101\n",
      "Train Epoch: 3 [8000/16239 (49%)]\tLoss: 0.515669\n",
      "Train Epoch: 3 [9000/16239 (55%)]\tLoss: 0.387221\n",
      "Train Epoch: 3 [10000/16239 (61%)]\tLoss: 0.486868\n",
      "Train Epoch: 3 [11000/16239 (67%)]\tLoss: 0.229714\n",
      "Train Epoch: 3 [12000/16239 (74%)]\tLoss: 0.448728\n",
      "Train Epoch: 3 [13000/16239 (80%)]\tLoss: 0.428112\n",
      "Train Epoch: 3 [14000/16239 (86%)]\tLoss: 0.356086\n",
      "Train Epoch: 3 [15000/16239 (92%)]\tLoss: 0.367771\n",
      "Train Epoch: 3 [16000/16239 (98%)]\tLoss: 0.489363\n",
      "Train Epoch: 4 [0/16239 (0%)]\tLoss: 0.432431\n",
      "Train Epoch: 4 [1000/16239 (6%)]\tLoss: 0.376919\n",
      "Train Epoch: 4 [2000/16239 (12%)]\tLoss: 0.306294\n",
      "Train Epoch: 4 [3000/16239 (18%)]\tLoss: 0.352448\n",
      "Train Epoch: 4 [4000/16239 (25%)]\tLoss: 0.488314\n",
      "Train Epoch: 4 [5000/16239 (31%)]\tLoss: 0.323743\n",
      "Train Epoch: 4 [6000/16239 (37%)]\tLoss: 0.379241\n",
      "Train Epoch: 4 [7000/16239 (43%)]\tLoss: 0.434798\n",
      "Train Epoch: 4 [8000/16239 (49%)]\tLoss: 0.465461\n",
      "Train Epoch: 4 [9000/16239 (55%)]\tLoss: 0.324693\n",
      "Train Epoch: 4 [10000/16239 (61%)]\tLoss: 0.522685\n",
      "Train Epoch: 4 [11000/16239 (67%)]\tLoss: 0.368190\n",
      "Train Epoch: 4 [12000/16239 (74%)]\tLoss: 0.322485\n",
      "Train Epoch: 4 [13000/16239 (80%)]\tLoss: 0.501159\n",
      "Train Epoch: 4 [14000/16239 (86%)]\tLoss: 0.322138\n",
      "Train Epoch: 4 [15000/16239 (92%)]\tLoss: 0.312968\n",
      "Train Epoch: 4 [16000/16239 (98%)]\tLoss: 0.361353\n",
      "Train Epoch: 5 [0/16239 (0%)]\tLoss: 0.289700\n",
      "Train Epoch: 5 [1000/16239 (6%)]\tLoss: 0.297830\n",
      "Train Epoch: 5 [2000/16239 (12%)]\tLoss: 0.377587\n",
      "Train Epoch: 5 [3000/16239 (18%)]\tLoss: 0.285923\n",
      "Train Epoch: 5 [4000/16239 (25%)]\tLoss: 0.461308\n",
      "Train Epoch: 5 [5000/16239 (31%)]\tLoss: 0.401201\n",
      "Train Epoch: 5 [6000/16239 (37%)]\tLoss: 0.309049\n",
      "Train Epoch: 5 [7000/16239 (43%)]\tLoss: 0.348460\n",
      "Train Epoch: 5 [8000/16239 (49%)]\tLoss: 0.411780\n",
      "Train Epoch: 5 [9000/16239 (55%)]\tLoss: 0.492034\n",
      "Train Epoch: 5 [10000/16239 (61%)]\tLoss: 0.419218\n",
      "Train Epoch: 5 [11000/16239 (67%)]\tLoss: 0.312284\n",
      "Train Epoch: 5 [12000/16239 (74%)]\tLoss: 0.369811\n",
      "Train Epoch: 5 [13000/16239 (80%)]\tLoss: 0.354561\n",
      "Train Epoch: 5 [14000/16239 (86%)]\tLoss: 0.356798\n",
      "Train Epoch: 5 [15000/16239 (92%)]\tLoss: 0.499261\n",
      "Train Epoch: 5 [16000/16239 (98%)]\tLoss: 0.545422\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/8865 (0%)]\tLoss: 0.387870\n",
      "Train Epoch: 1 [1000/8865 (11%)]\tLoss: 0.426531\n",
      "Train Epoch: 1 [2000/8865 (22%)]\tLoss: 0.480387\n",
      "Train Epoch: 1 [3000/8865 (34%)]\tLoss: 0.305973\n",
      "Train Epoch: 1 [4000/8865 (45%)]\tLoss: 0.276708\n",
      "Train Epoch: 1 [5000/8865 (56%)]\tLoss: 0.200441\n",
      "Train Epoch: 1 [6000/8865 (67%)]\tLoss: 0.441815\n",
      "Train Epoch: 1 [7000/8865 (79%)]\tLoss: 0.491582\n",
      "Train Epoch: 1 [8000/8865 (90%)]\tLoss: 0.534068\n",
      "Train Epoch: 2 [0/8865 (0%)]\tLoss: 0.197885\n",
      "Train Epoch: 2 [1000/8865 (11%)]\tLoss: 0.387857\n",
      "Train Epoch: 2 [2000/8865 (22%)]\tLoss: 0.344478\n",
      "Train Epoch: 2 [3000/8865 (34%)]\tLoss: 0.428641\n",
      "Train Epoch: 2 [4000/8865 (45%)]\tLoss: 0.427215\n",
      "Train Epoch: 2 [5000/8865 (56%)]\tLoss: 0.363810\n",
      "Train Epoch: 2 [6000/8865 (67%)]\tLoss: 0.497083\n",
      "Train Epoch: 2 [7000/8865 (79%)]\tLoss: 0.236548\n",
      "Train Epoch: 2 [8000/8865 (90%)]\tLoss: 0.426582\n",
      "Train Epoch: 3 [0/8865 (0%)]\tLoss: 0.361685\n",
      "Train Epoch: 3 [1000/8865 (11%)]\tLoss: 0.317100\n",
      "Train Epoch: 3 [2000/8865 (22%)]\tLoss: 0.443927\n",
      "Train Epoch: 3 [3000/8865 (34%)]\tLoss: 0.415270\n",
      "Train Epoch: 3 [4000/8865 (45%)]\tLoss: 0.259174\n",
      "Train Epoch: 3 [5000/8865 (56%)]\tLoss: 0.349513\n",
      "Train Epoch: 3 [6000/8865 (67%)]\tLoss: 0.357470\n",
      "Train Epoch: 3 [7000/8865 (79%)]\tLoss: 0.428043\n",
      "Train Epoch: 3 [8000/8865 (90%)]\tLoss: 0.491282\n",
      "Train Epoch: 4 [0/8865 (0%)]\tLoss: 0.454495\n",
      "Train Epoch: 4 [1000/8865 (11%)]\tLoss: 0.300877\n",
      "Train Epoch: 4 [2000/8865 (22%)]\tLoss: 0.287467\n",
      "Train Epoch: 4 [3000/8865 (34%)]\tLoss: 0.461745\n",
      "Train Epoch: 4 [4000/8865 (45%)]\tLoss: 0.357145\n",
      "Train Epoch: 4 [5000/8865 (56%)]\tLoss: 0.273918\n",
      "Train Epoch: 4 [6000/8865 (67%)]\tLoss: 0.383407\n",
      "Train Epoch: 4 [7000/8865 (79%)]\tLoss: 0.327299\n",
      "Train Epoch: 4 [8000/8865 (90%)]\tLoss: 0.466273\n",
      "Train Epoch: 5 [0/8865 (0%)]\tLoss: 0.388659\n",
      "Train Epoch: 5 [1000/8865 (11%)]\tLoss: 0.432621\n",
      "Train Epoch: 5 [2000/8865 (22%)]\tLoss: 0.344476\n",
      "Train Epoch: 5 [3000/8865 (34%)]\tLoss: 0.394232\n",
      "Train Epoch: 5 [4000/8865 (45%)]\tLoss: 0.410125\n",
      "Train Epoch: 5 [5000/8865 (56%)]\tLoss: 0.488371\n",
      "Train Epoch: 5 [6000/8865 (67%)]\tLoss: 0.513160\n",
      "Train Epoch: 5 [7000/8865 (79%)]\tLoss: 0.441651\n",
      "Train Epoch: 5 [8000/8865 (90%)]\tLoss: 0.295061\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8615, Accuracy: 7640/10000 (76%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/15622 (0%)]\tLoss: 0.389673\n",
      "Train Epoch: 1 [1000/15622 (6%)]\tLoss: 0.418704\n",
      "Train Epoch: 1 [2000/15622 (13%)]\tLoss: 0.516649\n",
      "Train Epoch: 1 [3000/15622 (19%)]\tLoss: 0.398381\n",
      "Train Epoch: 1 [4000/15622 (25%)]\tLoss: 0.450284\n",
      "Train Epoch: 1 [5000/15622 (32%)]\tLoss: 0.382363\n",
      "Train Epoch: 1 [6000/15622 (38%)]\tLoss: 0.298362\n",
      "Train Epoch: 1 [7000/15622 (45%)]\tLoss: 0.315891\n",
      "Train Epoch: 1 [8000/15622 (51%)]\tLoss: 0.464390\n",
      "Train Epoch: 1 [9000/15622 (57%)]\tLoss: 0.502090\n",
      "Train Epoch: 1 [10000/15622 (64%)]\tLoss: 0.546029\n",
      "Train Epoch: 1 [11000/15622 (70%)]\tLoss: 0.335252\n",
      "Train Epoch: 1 [12000/15622 (76%)]\tLoss: 0.568212\n",
      "Train Epoch: 1 [13000/15622 (83%)]\tLoss: 0.340954\n",
      "Train Epoch: 1 [14000/15622 (89%)]\tLoss: 0.454630\n",
      "Train Epoch: 1 [15000/15622 (96%)]\tLoss: 0.370166\n",
      "Train Epoch: 2 [0/15622 (0%)]\tLoss: 0.602925\n",
      "Train Epoch: 2 [1000/15622 (6%)]\tLoss: 0.365335\n",
      "Train Epoch: 2 [2000/15622 (13%)]\tLoss: 0.420132\n",
      "Train Epoch: 2 [3000/15622 (19%)]\tLoss: 0.377726\n",
      "Train Epoch: 2 [4000/15622 (25%)]\tLoss: 0.556673\n",
      "Train Epoch: 2 [5000/15622 (32%)]\tLoss: 0.464532\n",
      "Train Epoch: 2 [6000/15622 (38%)]\tLoss: 0.475014\n",
      "Train Epoch: 2 [7000/15622 (45%)]\tLoss: 0.408075\n",
      "Train Epoch: 2 [8000/15622 (51%)]\tLoss: 0.512111\n",
      "Train Epoch: 2 [9000/15622 (57%)]\tLoss: 0.477092\n",
      "Train Epoch: 2 [10000/15622 (64%)]\tLoss: 0.644166\n",
      "Train Epoch: 2 [11000/15622 (70%)]\tLoss: 0.423610\n",
      "Train Epoch: 2 [12000/15622 (76%)]\tLoss: 0.387905\n",
      "Train Epoch: 2 [13000/15622 (83%)]\tLoss: 0.402413\n",
      "Train Epoch: 2 [14000/15622 (89%)]\tLoss: 0.388885\n",
      "Train Epoch: 2 [15000/15622 (96%)]\tLoss: 0.428449\n",
      "Train Epoch: 3 [0/15622 (0%)]\tLoss: 0.502596\n",
      "Train Epoch: 3 [1000/15622 (6%)]\tLoss: 0.403879\n",
      "Train Epoch: 3 [2000/15622 (13%)]\tLoss: 0.447584\n",
      "Train Epoch: 3 [3000/15622 (19%)]\tLoss: 0.298738\n",
      "Train Epoch: 3 [4000/15622 (25%)]\tLoss: 0.427579\n",
      "Train Epoch: 3 [5000/15622 (32%)]\tLoss: 0.459820\n",
      "Train Epoch: 3 [6000/15622 (38%)]\tLoss: 0.369287\n",
      "Train Epoch: 3 [7000/15622 (45%)]\tLoss: 0.519219\n",
      "Train Epoch: 3 [8000/15622 (51%)]\tLoss: 0.314596\n",
      "Train Epoch: 3 [9000/15622 (57%)]\tLoss: 0.321158\n",
      "Train Epoch: 3 [10000/15622 (64%)]\tLoss: 0.394262\n",
      "Train Epoch: 3 [11000/15622 (70%)]\tLoss: 0.336733\n",
      "Train Epoch: 3 [12000/15622 (76%)]\tLoss: 0.379351\n",
      "Train Epoch: 3 [13000/15622 (83%)]\tLoss: 0.470071\n",
      "Train Epoch: 3 [14000/15622 (89%)]\tLoss: 0.305472\n",
      "Train Epoch: 3 [15000/15622 (96%)]\tLoss: 0.491049\n",
      "Train Epoch: 4 [0/15622 (0%)]\tLoss: 0.470748\n",
      "Train Epoch: 4 [1000/15622 (6%)]\tLoss: 0.398080\n",
      "Train Epoch: 4 [2000/15622 (13%)]\tLoss: 0.340886\n",
      "Train Epoch: 4 [3000/15622 (19%)]\tLoss: 0.382691\n",
      "Train Epoch: 4 [4000/15622 (25%)]\tLoss: 0.433723\n",
      "Train Epoch: 4 [5000/15622 (32%)]\tLoss: 0.248611\n",
      "Train Epoch: 4 [6000/15622 (38%)]\tLoss: 0.365916\n",
      "Train Epoch: 4 [7000/15622 (45%)]\tLoss: 0.466563\n",
      "Train Epoch: 4 [8000/15622 (51%)]\tLoss: 0.597861\n",
      "Train Epoch: 4 [9000/15622 (57%)]\tLoss: 0.476523\n",
      "Train Epoch: 4 [10000/15622 (64%)]\tLoss: 0.540124\n",
      "Train Epoch: 4 [11000/15622 (70%)]\tLoss: 0.404123\n",
      "Train Epoch: 4 [12000/15622 (76%)]\tLoss: 0.301603\n",
      "Train Epoch: 4 [13000/15622 (83%)]\tLoss: 0.340772\n",
      "Train Epoch: 4 [14000/15622 (89%)]\tLoss: 0.391370\n",
      "Train Epoch: 4 [15000/15622 (96%)]\tLoss: 0.322119\n",
      "Train Epoch: 5 [0/15622 (0%)]\tLoss: 0.502492\n",
      "Train Epoch: 5 [1000/15622 (6%)]\tLoss: 0.432377\n",
      "Train Epoch: 5 [2000/15622 (13%)]\tLoss: 0.366053\n",
      "Train Epoch: 5 [3000/15622 (19%)]\tLoss: 0.474574\n",
      "Train Epoch: 5 [4000/15622 (25%)]\tLoss: 0.525007\n",
      "Train Epoch: 5 [5000/15622 (32%)]\tLoss: 0.449651\n",
      "Train Epoch: 5 [6000/15622 (38%)]\tLoss: 0.521278\n",
      "Train Epoch: 5 [7000/15622 (45%)]\tLoss: 0.694930\n",
      "Train Epoch: 5 [8000/15622 (51%)]\tLoss: 0.419292\n",
      "Train Epoch: 5 [9000/15622 (57%)]\tLoss: 0.475314\n",
      "Train Epoch: 5 [10000/15622 (64%)]\tLoss: 0.343507\n",
      "Train Epoch: 5 [11000/15622 (70%)]\tLoss: 0.497160\n",
      "Train Epoch: 5 [12000/15622 (76%)]\tLoss: 0.392770\n",
      "Train Epoch: 5 [13000/15622 (83%)]\tLoss: 0.512124\n",
      "Train Epoch: 5 [14000/15622 (89%)]\tLoss: 0.423700\n",
      "Train Epoch: 5 [15000/15622 (96%)]\tLoss: 0.311003\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/19274 (0%)]\tLoss: 0.433061\n",
      "Train Epoch: 1 [1000/19274 (5%)]\tLoss: 0.553184\n",
      "Train Epoch: 1 [2000/19274 (10%)]\tLoss: 0.239837\n",
      "Train Epoch: 1 [3000/19274 (16%)]\tLoss: 0.303118\n",
      "Train Epoch: 1 [4000/19274 (21%)]\tLoss: 0.464792\n",
      "Train Epoch: 1 [5000/19274 (26%)]\tLoss: 0.206179\n",
      "Train Epoch: 1 [6000/19274 (31%)]\tLoss: 0.311453\n",
      "Train Epoch: 1 [7000/19274 (36%)]\tLoss: 0.278334\n",
      "Train Epoch: 1 [8000/19274 (41%)]\tLoss: 0.459605\n",
      "Train Epoch: 1 [9000/19274 (47%)]\tLoss: 0.355848\n",
      "Train Epoch: 1 [10000/19274 (52%)]\tLoss: 0.377238\n",
      "Train Epoch: 1 [11000/19274 (57%)]\tLoss: 0.290569\n",
      "Train Epoch: 1 [12000/19274 (62%)]\tLoss: 0.309211\n",
      "Train Epoch: 1 [13000/19274 (67%)]\tLoss: 0.343749\n",
      "Train Epoch: 1 [14000/19274 (73%)]\tLoss: 0.436792\n",
      "Train Epoch: 1 [15000/19274 (78%)]\tLoss: 0.310259\n",
      "Train Epoch: 1 [16000/19274 (83%)]\tLoss: 0.347649\n",
      "Train Epoch: 1 [17000/19274 (88%)]\tLoss: 0.289977\n",
      "Train Epoch: 1 [18000/19274 (93%)]\tLoss: 0.393873\n",
      "Train Epoch: 1 [19000/19274 (98%)]\tLoss: 0.261370\n",
      "Train Epoch: 2 [0/19274 (0%)]\tLoss: 0.366899\n",
      "Train Epoch: 2 [1000/19274 (5%)]\tLoss: 0.427991\n",
      "Train Epoch: 2 [2000/19274 (10%)]\tLoss: 0.315591\n",
      "Train Epoch: 2 [3000/19274 (16%)]\tLoss: 0.293349\n",
      "Train Epoch: 2 [4000/19274 (21%)]\tLoss: 0.506368\n",
      "Train Epoch: 2 [5000/19274 (26%)]\tLoss: 0.295160\n",
      "Train Epoch: 2 [6000/19274 (31%)]\tLoss: 0.421431\n",
      "Train Epoch: 2 [7000/19274 (36%)]\tLoss: 0.358887\n",
      "Train Epoch: 2 [8000/19274 (41%)]\tLoss: 0.380798\n",
      "Train Epoch: 2 [9000/19274 (47%)]\tLoss: 0.230324\n",
      "Train Epoch: 2 [10000/19274 (52%)]\tLoss: 0.450695\n",
      "Train Epoch: 2 [11000/19274 (57%)]\tLoss: 0.517605\n",
      "Train Epoch: 2 [12000/19274 (62%)]\tLoss: 0.453617\n",
      "Train Epoch: 2 [13000/19274 (67%)]\tLoss: 0.464210\n",
      "Train Epoch: 2 [14000/19274 (73%)]\tLoss: 0.247990\n",
      "Train Epoch: 2 [15000/19274 (78%)]\tLoss: 0.379477\n",
      "Train Epoch: 2 [16000/19274 (83%)]\tLoss: 0.408817\n",
      "Train Epoch: 2 [17000/19274 (88%)]\tLoss: 0.282256\n",
      "Train Epoch: 2 [18000/19274 (93%)]\tLoss: 0.434667\n",
      "Train Epoch: 2 [19000/19274 (98%)]\tLoss: 0.413943\n",
      "Train Epoch: 3 [0/19274 (0%)]\tLoss: 0.289825\n",
      "Train Epoch: 3 [1000/19274 (5%)]\tLoss: 0.557284\n",
      "Train Epoch: 3 [2000/19274 (10%)]\tLoss: 0.394405\n",
      "Train Epoch: 3 [3000/19274 (16%)]\tLoss: 0.379876\n",
      "Train Epoch: 3 [4000/19274 (21%)]\tLoss: 0.385172\n",
      "Train Epoch: 3 [5000/19274 (26%)]\tLoss: 0.315737\n",
      "Train Epoch: 3 [6000/19274 (31%)]\tLoss: 0.236079\n",
      "Train Epoch: 3 [7000/19274 (36%)]\tLoss: 0.395847\n",
      "Train Epoch: 3 [8000/19274 (41%)]\tLoss: 0.397523\n",
      "Train Epoch: 3 [9000/19274 (47%)]\tLoss: 0.335049\n",
      "Train Epoch: 3 [10000/19274 (52%)]\tLoss: 0.376395\n",
      "Train Epoch: 3 [11000/19274 (57%)]\tLoss: 0.335366\n",
      "Train Epoch: 3 [12000/19274 (62%)]\tLoss: 0.542392\n",
      "Train Epoch: 3 [13000/19274 (67%)]\tLoss: 0.382160\n",
      "Train Epoch: 3 [14000/19274 (73%)]\tLoss: 0.458951\n",
      "Train Epoch: 3 [15000/19274 (78%)]\tLoss: 0.357208\n",
      "Train Epoch: 3 [16000/19274 (83%)]\tLoss: 0.401758\n",
      "Train Epoch: 3 [17000/19274 (88%)]\tLoss: 0.376462\n",
      "Train Epoch: 3 [18000/19274 (93%)]\tLoss: 0.425152\n",
      "Train Epoch: 3 [19000/19274 (98%)]\tLoss: 0.341360\n",
      "Train Epoch: 4 [0/19274 (0%)]\tLoss: 0.285969\n",
      "Train Epoch: 4 [1000/19274 (5%)]\tLoss: 0.256868\n",
      "Train Epoch: 4 [2000/19274 (10%)]\tLoss: 0.432686\n",
      "Train Epoch: 4 [3000/19274 (16%)]\tLoss: 0.428780\n",
      "Train Epoch: 4 [4000/19274 (21%)]\tLoss: 0.276809\n",
      "Train Epoch: 4 [5000/19274 (26%)]\tLoss: 0.332302\n",
      "Train Epoch: 4 [6000/19274 (31%)]\tLoss: 0.265954\n",
      "Train Epoch: 4 [7000/19274 (36%)]\tLoss: 0.374575\n",
      "Train Epoch: 4 [8000/19274 (41%)]\tLoss: 0.449822\n",
      "Train Epoch: 4 [9000/19274 (47%)]\tLoss: 0.424181\n",
      "Train Epoch: 4 [10000/19274 (52%)]\tLoss: 0.293383\n",
      "Train Epoch: 4 [11000/19274 (57%)]\tLoss: 0.232173\n",
      "Train Epoch: 4 [12000/19274 (62%)]\tLoss: 0.252366\n",
      "Train Epoch: 4 [13000/19274 (67%)]\tLoss: 0.319679\n",
      "Train Epoch: 4 [14000/19274 (73%)]\tLoss: 0.430945\n",
      "Train Epoch: 4 [15000/19274 (78%)]\tLoss: 0.347332\n",
      "Train Epoch: 4 [16000/19274 (83%)]\tLoss: 0.461324\n",
      "Train Epoch: 4 [17000/19274 (88%)]\tLoss: 0.385083\n",
      "Train Epoch: 4 [18000/19274 (93%)]\tLoss: 0.317945\n",
      "Train Epoch: 4 [19000/19274 (98%)]\tLoss: 0.498242\n",
      "Train Epoch: 5 [0/19274 (0%)]\tLoss: 0.433720\n",
      "Train Epoch: 5 [1000/19274 (5%)]\tLoss: 0.496902\n",
      "Train Epoch: 5 [2000/19274 (10%)]\tLoss: 0.303252\n",
      "Train Epoch: 5 [3000/19274 (16%)]\tLoss: 0.485701\n",
      "Train Epoch: 5 [4000/19274 (21%)]\tLoss: 0.295171\n",
      "Train Epoch: 5 [5000/19274 (26%)]\tLoss: 0.401752\n",
      "Train Epoch: 5 [6000/19274 (31%)]\tLoss: 0.279443\n",
      "Train Epoch: 5 [7000/19274 (36%)]\tLoss: 0.332940\n",
      "Train Epoch: 5 [8000/19274 (41%)]\tLoss: 0.319322\n",
      "Train Epoch: 5 [9000/19274 (47%)]\tLoss: 0.279435\n",
      "Train Epoch: 5 [10000/19274 (52%)]\tLoss: 0.416835\n",
      "Train Epoch: 5 [11000/19274 (57%)]\tLoss: 0.497224\n",
      "Train Epoch: 5 [12000/19274 (62%)]\tLoss: 0.523535\n",
      "Train Epoch: 5 [13000/19274 (67%)]\tLoss: 0.491799\n",
      "Train Epoch: 5 [14000/19274 (73%)]\tLoss: 0.468634\n",
      "Train Epoch: 5 [15000/19274 (78%)]\tLoss: 0.414171\n",
      "Train Epoch: 5 [16000/19274 (83%)]\tLoss: 0.343974\n",
      "Train Epoch: 5 [17000/19274 (88%)]\tLoss: 0.368662\n",
      "Train Epoch: 5 [18000/19274 (93%)]\tLoss: 0.434412\n",
      "Train Epoch: 5 [19000/19274 (98%)]\tLoss: 0.371273\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/16239 (0%)]\tLoss: 0.387323\n",
      "Train Epoch: 1 [1000/16239 (6%)]\tLoss: 0.264831\n",
      "Train Epoch: 1 [2000/16239 (12%)]\tLoss: 0.347908\n",
      "Train Epoch: 1 [3000/16239 (18%)]\tLoss: 0.336327\n",
      "Train Epoch: 1 [4000/16239 (25%)]\tLoss: 0.348343\n",
      "Train Epoch: 1 [5000/16239 (31%)]\tLoss: 0.440028\n",
      "Train Epoch: 1 [6000/16239 (37%)]\tLoss: 0.347173\n",
      "Train Epoch: 1 [7000/16239 (43%)]\tLoss: 0.348808\n",
      "Train Epoch: 1 [8000/16239 (49%)]\tLoss: 0.333739\n",
      "Train Epoch: 1 [9000/16239 (55%)]\tLoss: 0.301543\n",
      "Train Epoch: 1 [10000/16239 (61%)]\tLoss: 0.461775\n",
      "Train Epoch: 1 [11000/16239 (67%)]\tLoss: 0.292617\n",
      "Train Epoch: 1 [12000/16239 (74%)]\tLoss: 0.319059\n",
      "Train Epoch: 1 [13000/16239 (80%)]\tLoss: 0.451232\n",
      "Train Epoch: 1 [14000/16239 (86%)]\tLoss: 0.206172\n",
      "Train Epoch: 1 [15000/16239 (92%)]\tLoss: 0.266233\n",
      "Train Epoch: 1 [16000/16239 (98%)]\tLoss: 0.243469\n",
      "Train Epoch: 2 [0/16239 (0%)]\tLoss: 0.271455\n",
      "Train Epoch: 2 [1000/16239 (6%)]\tLoss: 0.526516\n",
      "Train Epoch: 2 [2000/16239 (12%)]\tLoss: 0.486379\n",
      "Train Epoch: 2 [3000/16239 (18%)]\tLoss: 0.332247\n",
      "Train Epoch: 2 [4000/16239 (25%)]\tLoss: 0.356997\n",
      "Train Epoch: 2 [5000/16239 (31%)]\tLoss: 0.379720\n",
      "Train Epoch: 2 [6000/16239 (37%)]\tLoss: 0.439003\n",
      "Train Epoch: 2 [7000/16239 (43%)]\tLoss: 0.239939\n",
      "Train Epoch: 2 [8000/16239 (49%)]\tLoss: 0.450115\n",
      "Train Epoch: 2 [9000/16239 (55%)]\tLoss: 0.260608\n",
      "Train Epoch: 2 [10000/16239 (61%)]\tLoss: 0.353113\n",
      "Train Epoch: 2 [11000/16239 (67%)]\tLoss: 0.478272\n",
      "Train Epoch: 2 [12000/16239 (74%)]\tLoss: 0.358870\n",
      "Train Epoch: 2 [13000/16239 (80%)]\tLoss: 0.361970\n",
      "Train Epoch: 2 [14000/16239 (86%)]\tLoss: 0.479452\n",
      "Train Epoch: 2 [15000/16239 (92%)]\tLoss: 0.503990\n",
      "Train Epoch: 2 [16000/16239 (98%)]\tLoss: 0.402568\n",
      "Train Epoch: 3 [0/16239 (0%)]\tLoss: 0.603699\n",
      "Train Epoch: 3 [1000/16239 (6%)]\tLoss: 0.476318\n",
      "Train Epoch: 3 [2000/16239 (12%)]\tLoss: 0.471744\n",
      "Train Epoch: 3 [3000/16239 (18%)]\tLoss: 0.271110\n",
      "Train Epoch: 3 [4000/16239 (25%)]\tLoss: 0.339526\n",
      "Train Epoch: 3 [5000/16239 (31%)]\tLoss: 0.272880\n",
      "Train Epoch: 3 [6000/16239 (37%)]\tLoss: 0.451796\n",
      "Train Epoch: 3 [7000/16239 (43%)]\tLoss: 0.501177\n",
      "Train Epoch: 3 [8000/16239 (49%)]\tLoss: 0.347073\n",
      "Train Epoch: 3 [9000/16239 (55%)]\tLoss: 0.279430\n",
      "Train Epoch: 3 [10000/16239 (61%)]\tLoss: 0.352873\n",
      "Train Epoch: 3 [11000/16239 (67%)]\tLoss: 0.389880\n",
      "Train Epoch: 3 [12000/16239 (74%)]\tLoss: 0.408796\n",
      "Train Epoch: 3 [13000/16239 (80%)]\tLoss: 0.463252\n",
      "Train Epoch: 3 [14000/16239 (86%)]\tLoss: 0.365699\n",
      "Train Epoch: 3 [15000/16239 (92%)]\tLoss: 0.348286\n",
      "Train Epoch: 3 [16000/16239 (98%)]\tLoss: 0.307079\n",
      "Train Epoch: 4 [0/16239 (0%)]\tLoss: 0.433527\n",
      "Train Epoch: 4 [1000/16239 (6%)]\tLoss: 0.378526\n",
      "Train Epoch: 4 [2000/16239 (12%)]\tLoss: 0.297093\n",
      "Train Epoch: 4 [3000/16239 (18%)]\tLoss: 0.429047\n",
      "Train Epoch: 4 [4000/16239 (25%)]\tLoss: 0.320254\n",
      "Train Epoch: 4 [5000/16239 (31%)]\tLoss: 0.395139\n",
      "Train Epoch: 4 [6000/16239 (37%)]\tLoss: 0.468281\n",
      "Train Epoch: 4 [7000/16239 (43%)]\tLoss: 0.418079\n",
      "Train Epoch: 4 [8000/16239 (49%)]\tLoss: 0.545567\n",
      "Train Epoch: 4 [9000/16239 (55%)]\tLoss: 0.445728\n",
      "Train Epoch: 4 [10000/16239 (61%)]\tLoss: 0.491987\n",
      "Train Epoch: 4 [11000/16239 (67%)]\tLoss: 0.298388\n",
      "Train Epoch: 4 [12000/16239 (74%)]\tLoss: 0.506324\n",
      "Train Epoch: 4 [13000/16239 (80%)]\tLoss: 0.342575\n",
      "Train Epoch: 4 [14000/16239 (86%)]\tLoss: 0.434360\n",
      "Train Epoch: 4 [15000/16239 (92%)]\tLoss: 0.263160\n",
      "Train Epoch: 4 [16000/16239 (98%)]\tLoss: 0.360824\n",
      "Train Epoch: 5 [0/16239 (0%)]\tLoss: 0.343374\n",
      "Train Epoch: 5 [1000/16239 (6%)]\tLoss: 0.491930\n",
      "Train Epoch: 5 [2000/16239 (12%)]\tLoss: 0.406591\n",
      "Train Epoch: 5 [3000/16239 (18%)]\tLoss: 0.329771\n",
      "Train Epoch: 5 [4000/16239 (25%)]\tLoss: 0.361125\n",
      "Train Epoch: 5 [5000/16239 (31%)]\tLoss: 0.469137\n",
      "Train Epoch: 5 [6000/16239 (37%)]\tLoss: 0.343498\n",
      "Train Epoch: 5 [7000/16239 (43%)]\tLoss: 0.389271\n",
      "Train Epoch: 5 [8000/16239 (49%)]\tLoss: 0.236219\n",
      "Train Epoch: 5 [9000/16239 (55%)]\tLoss: 0.333208\n",
      "Train Epoch: 5 [10000/16239 (61%)]\tLoss: 0.440647\n",
      "Train Epoch: 5 [11000/16239 (67%)]\tLoss: 0.401116\n",
      "Train Epoch: 5 [12000/16239 (74%)]\tLoss: 0.330421\n",
      "Train Epoch: 5 [13000/16239 (80%)]\tLoss: 0.471201\n",
      "Train Epoch: 5 [14000/16239 (86%)]\tLoss: 0.336203\n",
      "Train Epoch: 5 [15000/16239 (92%)]\tLoss: 0.391860\n",
      "Train Epoch: 5 [16000/16239 (98%)]\tLoss: 0.363394\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/8865 (0%)]\tLoss: 0.446819\n",
      "Train Epoch: 1 [1000/8865 (11%)]\tLoss: 0.475365\n",
      "Train Epoch: 1 [2000/8865 (22%)]\tLoss: 0.361676\n",
      "Train Epoch: 1 [3000/8865 (34%)]\tLoss: 0.334066\n",
      "Train Epoch: 1 [4000/8865 (45%)]\tLoss: 0.363775\n",
      "Train Epoch: 1 [5000/8865 (56%)]\tLoss: 0.348193\n",
      "Train Epoch: 1 [6000/8865 (67%)]\tLoss: 0.390546\n",
      "Train Epoch: 1 [7000/8865 (79%)]\tLoss: 0.490287\n",
      "Train Epoch: 1 [8000/8865 (90%)]\tLoss: 0.394389\n",
      "Train Epoch: 2 [0/8865 (0%)]\tLoss: 0.419773\n",
      "Train Epoch: 2 [1000/8865 (11%)]\tLoss: 0.439225\n",
      "Train Epoch: 2 [2000/8865 (22%)]\tLoss: 0.408098\n",
      "Train Epoch: 2 [3000/8865 (34%)]\tLoss: 0.437367\n",
      "Train Epoch: 2 [4000/8865 (45%)]\tLoss: 0.374810\n",
      "Train Epoch: 2 [5000/8865 (56%)]\tLoss: 0.339791\n",
      "Train Epoch: 2 [6000/8865 (67%)]\tLoss: 0.421417\n",
      "Train Epoch: 2 [7000/8865 (79%)]\tLoss: 0.405893\n",
      "Train Epoch: 2 [8000/8865 (90%)]\tLoss: 0.440719\n",
      "Train Epoch: 3 [0/8865 (0%)]\tLoss: 0.319940\n",
      "Train Epoch: 3 [1000/8865 (11%)]\tLoss: 0.539887\n",
      "Train Epoch: 3 [2000/8865 (22%)]\tLoss: 0.443016\n",
      "Train Epoch: 3 [3000/8865 (34%)]\tLoss: 0.375175\n",
      "Train Epoch: 3 [4000/8865 (45%)]\tLoss: 0.322405\n",
      "Train Epoch: 3 [5000/8865 (56%)]\tLoss: 0.304458\n",
      "Train Epoch: 3 [6000/8865 (67%)]\tLoss: 0.315676\n",
      "Train Epoch: 3 [7000/8865 (79%)]\tLoss: 0.339973\n",
      "Train Epoch: 3 [8000/8865 (90%)]\tLoss: 0.355760\n",
      "Train Epoch: 4 [0/8865 (0%)]\tLoss: 0.406857\n",
      "Train Epoch: 4 [1000/8865 (11%)]\tLoss: 0.254985\n",
      "Train Epoch: 4 [2000/8865 (22%)]\tLoss: 0.362977\n",
      "Train Epoch: 4 [3000/8865 (34%)]\tLoss: 0.414463\n",
      "Train Epoch: 4 [4000/8865 (45%)]\tLoss: 0.438675\n",
      "Train Epoch: 4 [5000/8865 (56%)]\tLoss: 0.429874\n",
      "Train Epoch: 4 [6000/8865 (67%)]\tLoss: 0.444551\n",
      "Train Epoch: 4 [7000/8865 (79%)]\tLoss: 0.473336\n",
      "Train Epoch: 4 [8000/8865 (90%)]\tLoss: 0.446211\n",
      "Train Epoch: 5 [0/8865 (0%)]\tLoss: 0.389706\n",
      "Train Epoch: 5 [1000/8865 (11%)]\tLoss: 0.390182\n",
      "Train Epoch: 5 [2000/8865 (22%)]\tLoss: 0.280804\n",
      "Train Epoch: 5 [3000/8865 (34%)]\tLoss: 0.448550\n",
      "Train Epoch: 5 [4000/8865 (45%)]\tLoss: 0.410757\n",
      "Train Epoch: 5 [5000/8865 (56%)]\tLoss: 0.382035\n",
      "Train Epoch: 5 [6000/8865 (67%)]\tLoss: 0.438382\n",
      "Train Epoch: 5 [7000/8865 (79%)]\tLoss: 0.327106\n",
      "Train Epoch: 5 [8000/8865 (90%)]\tLoss: 0.381807\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8043, Accuracy: 7781/10000 (78%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/15622 (0%)]\tLoss: 0.493654\n",
      "Train Epoch: 1 [1000/15622 (6%)]\tLoss: 0.407046\n",
      "Train Epoch: 1 [2000/15622 (13%)]\tLoss: 0.468795\n",
      "Train Epoch: 1 [3000/15622 (19%)]\tLoss: 0.663212\n",
      "Train Epoch: 1 [4000/15622 (25%)]\tLoss: 0.450646\n",
      "Train Epoch: 1 [5000/15622 (32%)]\tLoss: 0.496532\n",
      "Train Epoch: 1 [6000/15622 (38%)]\tLoss: 0.422519\n",
      "Train Epoch: 1 [7000/15622 (45%)]\tLoss: 0.397774\n",
      "Train Epoch: 1 [8000/15622 (51%)]\tLoss: 0.356094\n",
      "Train Epoch: 1 [9000/15622 (57%)]\tLoss: 0.500907\n",
      "Train Epoch: 1 [10000/15622 (64%)]\tLoss: 0.458543\n",
      "Train Epoch: 1 [11000/15622 (70%)]\tLoss: 0.335694\n",
      "Train Epoch: 1 [12000/15622 (76%)]\tLoss: 0.473014\n",
      "Train Epoch: 1 [13000/15622 (83%)]\tLoss: 0.387883\n",
      "Train Epoch: 1 [14000/15622 (89%)]\tLoss: 0.415618\n",
      "Train Epoch: 1 [15000/15622 (96%)]\tLoss: 0.464763\n",
      "Train Epoch: 2 [0/15622 (0%)]\tLoss: 0.338838\n",
      "Train Epoch: 2 [1000/15622 (6%)]\tLoss: 0.425271\n",
      "Train Epoch: 2 [2000/15622 (13%)]\tLoss: 0.538234\n",
      "Train Epoch: 2 [3000/15622 (19%)]\tLoss: 0.470088\n",
      "Train Epoch: 2 [4000/15622 (25%)]\tLoss: 0.479293\n",
      "Train Epoch: 2 [5000/15622 (32%)]\tLoss: 0.538257\n",
      "Train Epoch: 2 [6000/15622 (38%)]\tLoss: 0.511272\n",
      "Train Epoch: 2 [7000/15622 (45%)]\tLoss: 0.504447\n",
      "Train Epoch: 2 [8000/15622 (51%)]\tLoss: 0.373535\n",
      "Train Epoch: 2 [9000/15622 (57%)]\tLoss: 0.327205\n",
      "Train Epoch: 2 [10000/15622 (64%)]\tLoss: 0.488162\n",
      "Train Epoch: 2 [11000/15622 (70%)]\tLoss: 0.556525\n",
      "Train Epoch: 2 [12000/15622 (76%)]\tLoss: 0.462376\n",
      "Train Epoch: 2 [13000/15622 (83%)]\tLoss: 0.309730\n",
      "Train Epoch: 2 [14000/15622 (89%)]\tLoss: 0.404306\n",
      "Train Epoch: 2 [15000/15622 (96%)]\tLoss: 0.361606\n",
      "Train Epoch: 3 [0/15622 (0%)]\tLoss: 0.588453\n",
      "Train Epoch: 3 [1000/15622 (6%)]\tLoss: 0.453616\n",
      "Train Epoch: 3 [2000/15622 (13%)]\tLoss: 0.509210\n",
      "Train Epoch: 3 [3000/15622 (19%)]\tLoss: 0.357962\n",
      "Train Epoch: 3 [4000/15622 (25%)]\tLoss: 0.389060\n",
      "Train Epoch: 3 [5000/15622 (32%)]\tLoss: 0.300842\n",
      "Train Epoch: 3 [6000/15622 (38%)]\tLoss: 0.349272\n",
      "Train Epoch: 3 [7000/15622 (45%)]\tLoss: 0.309030\n",
      "Train Epoch: 3 [8000/15622 (51%)]\tLoss: 0.431466\n",
      "Train Epoch: 3 [9000/15622 (57%)]\tLoss: 0.380489\n",
      "Train Epoch: 3 [10000/15622 (64%)]\tLoss: 0.439807\n",
      "Train Epoch: 3 [11000/15622 (70%)]\tLoss: 0.462713\n",
      "Train Epoch: 3 [12000/15622 (76%)]\tLoss: 0.403213\n",
      "Train Epoch: 3 [13000/15622 (83%)]\tLoss: 0.417588\n",
      "Train Epoch: 3 [14000/15622 (89%)]\tLoss: 0.599350\n",
      "Train Epoch: 3 [15000/15622 (96%)]\tLoss: 0.385609\n",
      "Train Epoch: 4 [0/15622 (0%)]\tLoss: 0.519414\n",
      "Train Epoch: 4 [1000/15622 (6%)]\tLoss: 0.369139\n",
      "Train Epoch: 4 [2000/15622 (13%)]\tLoss: 0.551447\n",
      "Train Epoch: 4 [3000/15622 (19%)]\tLoss: 0.406830\n",
      "Train Epoch: 4 [4000/15622 (25%)]\tLoss: 0.437148\n",
      "Train Epoch: 4 [5000/15622 (32%)]\tLoss: 0.487929\n",
      "Train Epoch: 4 [6000/15622 (38%)]\tLoss: 0.380092\n",
      "Train Epoch: 4 [7000/15622 (45%)]\tLoss: 0.420779\n",
      "Train Epoch: 4 [8000/15622 (51%)]\tLoss: 0.478888\n",
      "Train Epoch: 4 [9000/15622 (57%)]\tLoss: 0.425007\n",
      "Train Epoch: 4 [10000/15622 (64%)]\tLoss: 0.451161\n",
      "Train Epoch: 4 [11000/15622 (70%)]\tLoss: 0.288110\n",
      "Train Epoch: 4 [12000/15622 (76%)]\tLoss: 0.413344\n",
      "Train Epoch: 4 [13000/15622 (83%)]\tLoss: 0.650228\n",
      "Train Epoch: 4 [14000/15622 (89%)]\tLoss: 0.413087\n",
      "Train Epoch: 4 [15000/15622 (96%)]\tLoss: 0.392660\n",
      "Train Epoch: 5 [0/15622 (0%)]\tLoss: 0.511121\n",
      "Train Epoch: 5 [1000/15622 (6%)]\tLoss: 0.488315\n",
      "Train Epoch: 5 [2000/15622 (13%)]\tLoss: 0.440270\n",
      "Train Epoch: 5 [3000/15622 (19%)]\tLoss: 0.482847\n",
      "Train Epoch: 5 [4000/15622 (25%)]\tLoss: 0.345282\n",
      "Train Epoch: 5 [5000/15622 (32%)]\tLoss: 0.442740\n",
      "Train Epoch: 5 [6000/15622 (38%)]\tLoss: 0.337731\n",
      "Train Epoch: 5 [7000/15622 (45%)]\tLoss: 0.350524\n",
      "Train Epoch: 5 [8000/15622 (51%)]\tLoss: 0.326983\n",
      "Train Epoch: 5 [9000/15622 (57%)]\tLoss: 0.373419\n",
      "Train Epoch: 5 [10000/15622 (64%)]\tLoss: 0.434996\n",
      "Train Epoch: 5 [11000/15622 (70%)]\tLoss: 0.384335\n",
      "Train Epoch: 5 [12000/15622 (76%)]\tLoss: 0.318552\n",
      "Train Epoch: 5 [13000/15622 (83%)]\tLoss: 0.390758\n",
      "Train Epoch: 5 [14000/15622 (89%)]\tLoss: 0.605990\n",
      "Train Epoch: 5 [15000/15622 (96%)]\tLoss: 0.403320\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/19274 (0%)]\tLoss: 0.428403\n",
      "Train Epoch: 1 [1000/19274 (5%)]\tLoss: 0.467894\n",
      "Train Epoch: 1 [2000/19274 (10%)]\tLoss: 0.321400\n",
      "Train Epoch: 1 [3000/19274 (16%)]\tLoss: 0.404296\n",
      "Train Epoch: 1 [4000/19274 (21%)]\tLoss: 0.439896\n",
      "Train Epoch: 1 [5000/19274 (26%)]\tLoss: 0.282553\n",
      "Train Epoch: 1 [6000/19274 (31%)]\tLoss: 0.376583\n",
      "Train Epoch: 1 [7000/19274 (36%)]\tLoss: 0.262927\n",
      "Train Epoch: 1 [8000/19274 (41%)]\tLoss: 0.512739\n",
      "Train Epoch: 1 [9000/19274 (47%)]\tLoss: 0.436303\n",
      "Train Epoch: 1 [10000/19274 (52%)]\tLoss: 0.296063\n",
      "Train Epoch: 1 [11000/19274 (57%)]\tLoss: 0.304798\n",
      "Train Epoch: 1 [12000/19274 (62%)]\tLoss: 0.367564\n",
      "Train Epoch: 1 [13000/19274 (67%)]\tLoss: 0.360031\n",
      "Train Epoch: 1 [14000/19274 (73%)]\tLoss: 0.372449\n",
      "Train Epoch: 1 [15000/19274 (78%)]\tLoss: 0.379961\n",
      "Train Epoch: 1 [16000/19274 (83%)]\tLoss: 0.361537\n",
      "Train Epoch: 1 [17000/19274 (88%)]\tLoss: 0.475921\n",
      "Train Epoch: 1 [18000/19274 (93%)]\tLoss: 0.237763\n",
      "Train Epoch: 1 [19000/19274 (98%)]\tLoss: 0.358116\n",
      "Train Epoch: 2 [0/19274 (0%)]\tLoss: 0.319965\n",
      "Train Epoch: 2 [1000/19274 (5%)]\tLoss: 0.509882\n",
      "Train Epoch: 2 [2000/19274 (10%)]\tLoss: 0.482308\n",
      "Train Epoch: 2 [3000/19274 (16%)]\tLoss: 0.472098\n",
      "Train Epoch: 2 [4000/19274 (21%)]\tLoss: 0.534559\n",
      "Train Epoch: 2 [5000/19274 (26%)]\tLoss: 0.430555\n",
      "Train Epoch: 2 [6000/19274 (31%)]\tLoss: 0.338725\n",
      "Train Epoch: 2 [7000/19274 (36%)]\tLoss: 0.359467\n",
      "Train Epoch: 2 [8000/19274 (41%)]\tLoss: 0.308753\n",
      "Train Epoch: 2 [9000/19274 (47%)]\tLoss: 0.299899\n",
      "Train Epoch: 2 [10000/19274 (52%)]\tLoss: 0.325865\n",
      "Train Epoch: 2 [11000/19274 (57%)]\tLoss: 0.258902\n",
      "Train Epoch: 2 [12000/19274 (62%)]\tLoss: 0.318416\n",
      "Train Epoch: 2 [13000/19274 (67%)]\tLoss: 0.373718\n",
      "Train Epoch: 2 [14000/19274 (73%)]\tLoss: 0.284115\n",
      "Train Epoch: 2 [15000/19274 (78%)]\tLoss: 0.335455\n",
      "Train Epoch: 2 [16000/19274 (83%)]\tLoss: 0.319027\n",
      "Train Epoch: 2 [17000/19274 (88%)]\tLoss: 0.348975\n",
      "Train Epoch: 2 [18000/19274 (93%)]\tLoss: 0.331989\n",
      "Train Epoch: 2 [19000/19274 (98%)]\tLoss: 0.334410\n",
      "Train Epoch: 3 [0/19274 (0%)]\tLoss: 0.340192\n",
      "Train Epoch: 3 [1000/19274 (5%)]\tLoss: 0.591993\n",
      "Train Epoch: 3 [2000/19274 (10%)]\tLoss: 0.402173\n",
      "Train Epoch: 3 [3000/19274 (16%)]\tLoss: 0.481306\n",
      "Train Epoch: 3 [4000/19274 (21%)]\tLoss: 0.244028\n",
      "Train Epoch: 3 [5000/19274 (26%)]\tLoss: 0.279109\n",
      "Train Epoch: 3 [6000/19274 (31%)]\tLoss: 0.381215\n",
      "Train Epoch: 3 [7000/19274 (36%)]\tLoss: 0.453761\n",
      "Train Epoch: 3 [8000/19274 (41%)]\tLoss: 0.355985\n",
      "Train Epoch: 3 [9000/19274 (47%)]\tLoss: 0.311468\n",
      "Train Epoch: 3 [10000/19274 (52%)]\tLoss: 0.347269\n",
      "Train Epoch: 3 [11000/19274 (57%)]\tLoss: 0.328492\n",
      "Train Epoch: 3 [12000/19274 (62%)]\tLoss: 0.384359\n",
      "Train Epoch: 3 [13000/19274 (67%)]\tLoss: 0.292525\n",
      "Train Epoch: 3 [14000/19274 (73%)]\tLoss: 0.321278\n",
      "Train Epoch: 3 [15000/19274 (78%)]\tLoss: 0.338340\n",
      "Train Epoch: 3 [16000/19274 (83%)]\tLoss: 0.374983\n",
      "Train Epoch: 3 [17000/19274 (88%)]\tLoss: 0.380390\n",
      "Train Epoch: 3 [18000/19274 (93%)]\tLoss: 0.351265\n",
      "Train Epoch: 3 [19000/19274 (98%)]\tLoss: 0.426302\n",
      "Train Epoch: 4 [0/19274 (0%)]\tLoss: 0.420350\n",
      "Train Epoch: 4 [1000/19274 (5%)]\tLoss: 0.462716\n",
      "Train Epoch: 4 [2000/19274 (10%)]\tLoss: 0.367252\n",
      "Train Epoch: 4 [3000/19274 (16%)]\tLoss: 0.357604\n",
      "Train Epoch: 4 [4000/19274 (21%)]\tLoss: 0.416405\n",
      "Train Epoch: 4 [5000/19274 (26%)]\tLoss: 0.265662\n",
      "Train Epoch: 4 [6000/19274 (31%)]\tLoss: 0.236291\n",
      "Train Epoch: 4 [7000/19274 (36%)]\tLoss: 0.270363\n",
      "Train Epoch: 4 [8000/19274 (41%)]\tLoss: 0.370632\n",
      "Train Epoch: 4 [9000/19274 (47%)]\tLoss: 0.370590\n",
      "Train Epoch: 4 [10000/19274 (52%)]\tLoss: 0.305279\n",
      "Train Epoch: 4 [11000/19274 (57%)]\tLoss: 0.238237\n",
      "Train Epoch: 4 [12000/19274 (62%)]\tLoss: 0.440433\n",
      "Train Epoch: 4 [13000/19274 (67%)]\tLoss: 0.359843\n",
      "Train Epoch: 4 [14000/19274 (73%)]\tLoss: 0.384333\n",
      "Train Epoch: 4 [15000/19274 (78%)]\tLoss: 0.318657\n",
      "Train Epoch: 4 [16000/19274 (83%)]\tLoss: 0.476078\n",
      "Train Epoch: 4 [17000/19274 (88%)]\tLoss: 0.472747\n",
      "Train Epoch: 4 [18000/19274 (93%)]\tLoss: 0.386134\n",
      "Train Epoch: 4 [19000/19274 (98%)]\tLoss: 0.271901\n",
      "Train Epoch: 5 [0/19274 (0%)]\tLoss: 0.330099\n",
      "Train Epoch: 5 [1000/19274 (5%)]\tLoss: 0.384956\n",
      "Train Epoch: 5 [2000/19274 (10%)]\tLoss: 0.381362\n",
      "Train Epoch: 5 [3000/19274 (16%)]\tLoss: 0.286707\n",
      "Train Epoch: 5 [4000/19274 (21%)]\tLoss: 0.303027\n",
      "Train Epoch: 5 [5000/19274 (26%)]\tLoss: 0.401481\n",
      "Train Epoch: 5 [6000/19274 (31%)]\tLoss: 0.240482\n",
      "Train Epoch: 5 [7000/19274 (36%)]\tLoss: 0.334629\n",
      "Train Epoch: 5 [8000/19274 (41%)]\tLoss: 0.274497\n",
      "Train Epoch: 5 [9000/19274 (47%)]\tLoss: 0.344538\n",
      "Train Epoch: 5 [10000/19274 (52%)]\tLoss: 0.378277\n",
      "Train Epoch: 5 [11000/19274 (57%)]\tLoss: 0.320202\n",
      "Train Epoch: 5 [12000/19274 (62%)]\tLoss: 0.483751\n",
      "Train Epoch: 5 [13000/19274 (67%)]\tLoss: 0.301472\n",
      "Train Epoch: 5 [14000/19274 (73%)]\tLoss: 0.458520\n",
      "Train Epoch: 5 [15000/19274 (78%)]\tLoss: 0.319548\n",
      "Train Epoch: 5 [16000/19274 (83%)]\tLoss: 0.375894\n",
      "Train Epoch: 5 [17000/19274 (88%)]\tLoss: 0.273081\n",
      "Train Epoch: 5 [18000/19274 (93%)]\tLoss: 0.176184\n",
      "Train Epoch: 5 [19000/19274 (98%)]\tLoss: 0.472549\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/16239 (0%)]\tLoss: 0.471700\n",
      "Train Epoch: 1 [1000/16239 (6%)]\tLoss: 0.349435\n",
      "Train Epoch: 1 [2000/16239 (12%)]\tLoss: 0.383346\n",
      "Train Epoch: 1 [3000/16239 (18%)]\tLoss: 0.403057\n",
      "Train Epoch: 1 [4000/16239 (25%)]\tLoss: 0.228201\n",
      "Train Epoch: 1 [5000/16239 (31%)]\tLoss: 0.388526\n",
      "Train Epoch: 1 [6000/16239 (37%)]\tLoss: 0.498953\n",
      "Train Epoch: 1 [7000/16239 (43%)]\tLoss: 0.305167\n",
      "Train Epoch: 1 [8000/16239 (49%)]\tLoss: 0.465329\n",
      "Train Epoch: 1 [9000/16239 (55%)]\tLoss: 0.435878\n",
      "Train Epoch: 1 [10000/16239 (61%)]\tLoss: 0.354677\n",
      "Train Epoch: 1 [11000/16239 (67%)]\tLoss: 0.484067\n",
      "Train Epoch: 1 [12000/16239 (74%)]\tLoss: 0.304691\n",
      "Train Epoch: 1 [13000/16239 (80%)]\tLoss: 0.361519\n",
      "Train Epoch: 1 [14000/16239 (86%)]\tLoss: 0.547469\n",
      "Train Epoch: 1 [15000/16239 (92%)]\tLoss: 0.486765\n",
      "Train Epoch: 1 [16000/16239 (98%)]\tLoss: 0.296226\n",
      "Train Epoch: 2 [0/16239 (0%)]\tLoss: 0.335179\n",
      "Train Epoch: 2 [1000/16239 (6%)]\tLoss: 0.310575\n",
      "Train Epoch: 2 [2000/16239 (12%)]\tLoss: 0.564324\n",
      "Train Epoch: 2 [3000/16239 (18%)]\tLoss: 0.339138\n",
      "Train Epoch: 2 [4000/16239 (25%)]\tLoss: 0.390782\n",
      "Train Epoch: 2 [5000/16239 (31%)]\tLoss: 0.376387\n",
      "Train Epoch: 2 [6000/16239 (37%)]\tLoss: 0.398835\n",
      "Train Epoch: 2 [7000/16239 (43%)]\tLoss: 0.356539\n",
      "Train Epoch: 2 [8000/16239 (49%)]\tLoss: 0.328456\n",
      "Train Epoch: 2 [9000/16239 (55%)]\tLoss: 0.279566\n",
      "Train Epoch: 2 [10000/16239 (61%)]\tLoss: 0.302040\n",
      "Train Epoch: 2 [11000/16239 (67%)]\tLoss: 0.459834\n",
      "Train Epoch: 2 [12000/16239 (74%)]\tLoss: 0.369973\n",
      "Train Epoch: 2 [13000/16239 (80%)]\tLoss: 0.449836\n",
      "Train Epoch: 2 [14000/16239 (86%)]\tLoss: 0.320406\n",
      "Train Epoch: 2 [15000/16239 (92%)]\tLoss: 0.313353\n",
      "Train Epoch: 2 [16000/16239 (98%)]\tLoss: 0.290304\n",
      "Train Epoch: 3 [0/16239 (0%)]\tLoss: 0.299530\n",
      "Train Epoch: 3 [1000/16239 (6%)]\tLoss: 0.470779\n",
      "Train Epoch: 3 [2000/16239 (12%)]\tLoss: 0.357683\n",
      "Train Epoch: 3 [3000/16239 (18%)]\tLoss: 0.346689\n",
      "Train Epoch: 3 [4000/16239 (25%)]\tLoss: 0.397649\n",
      "Train Epoch: 3 [5000/16239 (31%)]\tLoss: 0.428696\n",
      "Train Epoch: 3 [6000/16239 (37%)]\tLoss: 0.290749\n",
      "Train Epoch: 3 [7000/16239 (43%)]\tLoss: 0.285542\n",
      "Train Epoch: 3 [8000/16239 (49%)]\tLoss: 0.280782\n",
      "Train Epoch: 3 [9000/16239 (55%)]\tLoss: 0.370530\n",
      "Train Epoch: 3 [10000/16239 (61%)]\tLoss: 0.387583\n",
      "Train Epoch: 3 [11000/16239 (67%)]\tLoss: 0.234912\n",
      "Train Epoch: 3 [12000/16239 (74%)]\tLoss: 0.389751\n",
      "Train Epoch: 3 [13000/16239 (80%)]\tLoss: 0.355237\n",
      "Train Epoch: 3 [14000/16239 (86%)]\tLoss: 0.293538\n",
      "Train Epoch: 3 [15000/16239 (92%)]\tLoss: 0.444598\n",
      "Train Epoch: 3 [16000/16239 (98%)]\tLoss: 0.358401\n",
      "Train Epoch: 4 [0/16239 (0%)]\tLoss: 0.645267\n",
      "Train Epoch: 4 [1000/16239 (6%)]\tLoss: 0.385248\n",
      "Train Epoch: 4 [2000/16239 (12%)]\tLoss: 0.243245\n",
      "Train Epoch: 4 [3000/16239 (18%)]\tLoss: 0.436391\n",
      "Train Epoch: 4 [4000/16239 (25%)]\tLoss: 0.494838\n",
      "Train Epoch: 4 [5000/16239 (31%)]\tLoss: 0.363270\n",
      "Train Epoch: 4 [6000/16239 (37%)]\tLoss: 0.373691\n",
      "Train Epoch: 4 [7000/16239 (43%)]\tLoss: 0.434307\n",
      "Train Epoch: 4 [8000/16239 (49%)]\tLoss: 0.345650\n",
      "Train Epoch: 4 [9000/16239 (55%)]\tLoss: 0.496428\n",
      "Train Epoch: 4 [10000/16239 (61%)]\tLoss: 0.378603\n",
      "Train Epoch: 4 [11000/16239 (67%)]\tLoss: 0.372877\n",
      "Train Epoch: 4 [12000/16239 (74%)]\tLoss: 0.269193\n",
      "Train Epoch: 4 [13000/16239 (80%)]\tLoss: 0.391893\n",
      "Train Epoch: 4 [14000/16239 (86%)]\tLoss: 0.364356\n",
      "Train Epoch: 4 [15000/16239 (92%)]\tLoss: 0.369345\n",
      "Train Epoch: 4 [16000/16239 (98%)]\tLoss: 0.275082\n",
      "Train Epoch: 5 [0/16239 (0%)]\tLoss: 0.379786\n",
      "Train Epoch: 5 [1000/16239 (6%)]\tLoss: 0.363686\n",
      "Train Epoch: 5 [2000/16239 (12%)]\tLoss: 0.476586\n",
      "Train Epoch: 5 [3000/16239 (18%)]\tLoss: 0.344413\n",
      "Train Epoch: 5 [4000/16239 (25%)]\tLoss: 0.361935\n",
      "Train Epoch: 5 [5000/16239 (31%)]\tLoss: 0.271492\n",
      "Train Epoch: 5 [6000/16239 (37%)]\tLoss: 0.420903\n",
      "Train Epoch: 5 [7000/16239 (43%)]\tLoss: 0.381430\n",
      "Train Epoch: 5 [8000/16239 (49%)]\tLoss: 0.451543\n",
      "Train Epoch: 5 [9000/16239 (55%)]\tLoss: 0.355094\n",
      "Train Epoch: 5 [10000/16239 (61%)]\tLoss: 0.421641\n",
      "Train Epoch: 5 [11000/16239 (67%)]\tLoss: 0.474305\n",
      "Train Epoch: 5 [12000/16239 (74%)]\tLoss: 0.321614\n",
      "Train Epoch: 5 [13000/16239 (80%)]\tLoss: 0.296706\n",
      "Train Epoch: 5 [14000/16239 (86%)]\tLoss: 0.556220\n",
      "Train Epoch: 5 [15000/16239 (92%)]\tLoss: 0.295689\n",
      "Train Epoch: 5 [16000/16239 (98%)]\tLoss: 0.499304\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/8865 (0%)]\tLoss: 0.442442\n",
      "Train Epoch: 1 [1000/8865 (11%)]\tLoss: 0.519605\n",
      "Train Epoch: 1 [2000/8865 (22%)]\tLoss: 0.458120\n",
      "Train Epoch: 1 [3000/8865 (34%)]\tLoss: 0.286704\n",
      "Train Epoch: 1 [4000/8865 (45%)]\tLoss: 0.425123\n",
      "Train Epoch: 1 [5000/8865 (56%)]\tLoss: 0.446590\n",
      "Train Epoch: 1 [6000/8865 (67%)]\tLoss: 0.382212\n",
      "Train Epoch: 1 [7000/8865 (79%)]\tLoss: 0.423227\n",
      "Train Epoch: 1 [8000/8865 (90%)]\tLoss: 0.358830\n",
      "Train Epoch: 2 [0/8865 (0%)]\tLoss: 0.331003\n",
      "Train Epoch: 2 [1000/8865 (11%)]\tLoss: 0.356700\n",
      "Train Epoch: 2 [2000/8865 (22%)]\tLoss: 0.326378\n",
      "Train Epoch: 2 [3000/8865 (34%)]\tLoss: 0.390429\n",
      "Train Epoch: 2 [4000/8865 (45%)]\tLoss: 0.398559\n",
      "Train Epoch: 2 [5000/8865 (56%)]\tLoss: 0.416840\n",
      "Train Epoch: 2 [6000/8865 (67%)]\tLoss: 0.471201\n",
      "Train Epoch: 2 [7000/8865 (79%)]\tLoss: 0.545914\n",
      "Train Epoch: 2 [8000/8865 (90%)]\tLoss: 0.296043\n",
      "Train Epoch: 3 [0/8865 (0%)]\tLoss: 0.422491\n",
      "Train Epoch: 3 [1000/8865 (11%)]\tLoss: 0.407594\n",
      "Train Epoch: 3 [2000/8865 (22%)]\tLoss: 0.362269\n",
      "Train Epoch: 3 [3000/8865 (34%)]\tLoss: 0.352048\n",
      "Train Epoch: 3 [4000/8865 (45%)]\tLoss: 0.288649\n",
      "Train Epoch: 3 [5000/8865 (56%)]\tLoss: 0.326331\n",
      "Train Epoch: 3 [6000/8865 (67%)]\tLoss: 0.263818\n",
      "Train Epoch: 3 [7000/8865 (79%)]\tLoss: 0.321239\n",
      "Train Epoch: 3 [8000/8865 (90%)]\tLoss: 0.374681\n",
      "Train Epoch: 4 [0/8865 (0%)]\tLoss: 0.398407\n",
      "Train Epoch: 4 [1000/8865 (11%)]\tLoss: 0.425241\n",
      "Train Epoch: 4 [2000/8865 (22%)]\tLoss: 0.307074\n",
      "Train Epoch: 4 [3000/8865 (34%)]\tLoss: 0.335603\n",
      "Train Epoch: 4 [4000/8865 (45%)]\tLoss: 0.501909\n",
      "Train Epoch: 4 [5000/8865 (56%)]\tLoss: 0.291121\n",
      "Train Epoch: 4 [6000/8865 (67%)]\tLoss: 0.320221\n",
      "Train Epoch: 4 [7000/8865 (79%)]\tLoss: 0.261931\n",
      "Train Epoch: 4 [8000/8865 (90%)]\tLoss: 0.351602\n",
      "Train Epoch: 5 [0/8865 (0%)]\tLoss: 0.288011\n",
      "Train Epoch: 5 [1000/8865 (11%)]\tLoss: 0.373931\n",
      "Train Epoch: 5 [2000/8865 (22%)]\tLoss: 0.432078\n",
      "Train Epoch: 5 [3000/8865 (34%)]\tLoss: 0.466686\n",
      "Train Epoch: 5 [4000/8865 (45%)]\tLoss: 0.449056\n",
      "Train Epoch: 5 [5000/8865 (56%)]\tLoss: 0.237726\n",
      "Train Epoch: 5 [6000/8865 (67%)]\tLoss: 0.405131\n",
      "Train Epoch: 5 [7000/8865 (79%)]\tLoss: 0.334688\n",
      "Train Epoch: 5 [8000/8865 (90%)]\tLoss: 0.362977\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8359, Accuracy: 7725/10000 (77%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/9140 (0%)]\tLoss: 0.571641\n",
      "Train Epoch: 1 [1000/9140 (11%)]\tLoss: 0.439669\n",
      "Train Epoch: 1 [2000/9140 (22%)]\tLoss: 0.390501\n",
      "Train Epoch: 1 [3000/9140 (33%)]\tLoss: 0.521798\n",
      "Train Epoch: 1 [4000/9140 (43%)]\tLoss: 0.335348\n",
      "Train Epoch: 1 [5000/9140 (54%)]\tLoss: 0.506367\n",
      "Train Epoch: 1 [6000/9140 (65%)]\tLoss: 0.300461\n",
      "Train Epoch: 1 [7000/9140 (76%)]\tLoss: 0.377948\n",
      "Train Epoch: 1 [8000/9140 (87%)]\tLoss: 0.448660\n",
      "Train Epoch: 1 [9000/9140 (98%)]\tLoss: 0.386405\n",
      "Train Epoch: 2 [0/9140 (0%)]\tLoss: 0.317633\n",
      "Train Epoch: 2 [1000/9140 (11%)]\tLoss: 0.382678\n",
      "Train Epoch: 2 [2000/9140 (22%)]\tLoss: 0.418725\n",
      "Train Epoch: 2 [3000/9140 (33%)]\tLoss: 0.321603\n",
      "Train Epoch: 2 [4000/9140 (43%)]\tLoss: 0.376907\n",
      "Train Epoch: 2 [5000/9140 (54%)]\tLoss: 0.399528\n",
      "Train Epoch: 2 [6000/9140 (65%)]\tLoss: 0.343116\n",
      "Train Epoch: 2 [7000/9140 (76%)]\tLoss: 0.378394\n",
      "Train Epoch: 2 [8000/9140 (87%)]\tLoss: 0.237416\n",
      "Train Epoch: 2 [9000/9140 (98%)]\tLoss: 0.366773\n",
      "Train Epoch: 3 [0/9140 (0%)]\tLoss: 0.522866\n",
      "Train Epoch: 3 [1000/9140 (11%)]\tLoss: 0.396753\n",
      "Train Epoch: 3 [2000/9140 (22%)]\tLoss: 0.401623\n",
      "Train Epoch: 3 [3000/9140 (33%)]\tLoss: 0.417800\n",
      "Train Epoch: 3 [4000/9140 (43%)]\tLoss: 0.411474\n",
      "Train Epoch: 3 [5000/9140 (54%)]\tLoss: 0.298984\n",
      "Train Epoch: 3 [6000/9140 (65%)]\tLoss: 0.351334\n",
      "Train Epoch: 3 [7000/9140 (76%)]\tLoss: 0.418866\n",
      "Train Epoch: 3 [8000/9140 (87%)]\tLoss: 0.470470\n",
      "Train Epoch: 3 [9000/9140 (98%)]\tLoss: 0.401783\n",
      "Train Epoch: 4 [0/9140 (0%)]\tLoss: 0.351595\n",
      "Train Epoch: 4 [1000/9140 (11%)]\tLoss: 0.277040\n",
      "Train Epoch: 4 [2000/9140 (22%)]\tLoss: 0.370233\n",
      "Train Epoch: 4 [3000/9140 (33%)]\tLoss: 0.288681\n",
      "Train Epoch: 4 [4000/9140 (43%)]\tLoss: 0.293404\n",
      "Train Epoch: 4 [5000/9140 (54%)]\tLoss: 0.320661\n",
      "Train Epoch: 4 [6000/9140 (65%)]\tLoss: 0.304728\n",
      "Train Epoch: 4 [7000/9140 (76%)]\tLoss: 0.466769\n",
      "Train Epoch: 4 [8000/9140 (87%)]\tLoss: 0.428464\n",
      "Train Epoch: 4 [9000/9140 (98%)]\tLoss: 0.408154\n",
      "Train Epoch: 5 [0/9140 (0%)]\tLoss: 0.460207\n",
      "Train Epoch: 5 [1000/9140 (11%)]\tLoss: 0.273961\n",
      "Train Epoch: 5 [2000/9140 (22%)]\tLoss: 0.295402\n",
      "Train Epoch: 5 [3000/9140 (33%)]\tLoss: 0.301688\n",
      "Train Epoch: 5 [4000/9140 (43%)]\tLoss: 0.355341\n",
      "Train Epoch: 5 [5000/9140 (54%)]\tLoss: 0.322944\n",
      "Train Epoch: 5 [6000/9140 (65%)]\tLoss: 0.284916\n",
      "Train Epoch: 5 [7000/9140 (76%)]\tLoss: 0.485456\n",
      "Train Epoch: 5 [8000/9140 (87%)]\tLoss: 0.380558\n",
      "Train Epoch: 5 [9000/9140 (98%)]\tLoss: 0.467858\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/14160 (0%)]\tLoss: 0.398301\n",
      "Train Epoch: 1 [1000/14160 (7%)]\tLoss: 0.210155\n",
      "Train Epoch: 1 [2000/14160 (14%)]\tLoss: 0.239342\n",
      "Train Epoch: 1 [3000/14160 (21%)]\tLoss: 0.366910\n",
      "Train Epoch: 1 [4000/14160 (28%)]\tLoss: 0.245291\n",
      "Train Epoch: 1 [5000/14160 (35%)]\tLoss: 0.298101\n",
      "Train Epoch: 1 [6000/14160 (42%)]\tLoss: 0.265966\n",
      "Train Epoch: 1 [7000/14160 (49%)]\tLoss: 0.260576\n",
      "Train Epoch: 1 [8000/14160 (56%)]\tLoss: 0.285093\n",
      "Train Epoch: 1 [9000/14160 (63%)]\tLoss: 0.366875\n",
      "Train Epoch: 1 [10000/14160 (70%)]\tLoss: 0.389929\n",
      "Train Epoch: 1 [11000/14160 (77%)]\tLoss: 0.405727\n",
      "Train Epoch: 1 [12000/14160 (85%)]\tLoss: 0.252659\n",
      "Train Epoch: 1 [13000/14160 (92%)]\tLoss: 0.232729\n",
      "Train Epoch: 1 [14000/14160 (99%)]\tLoss: 0.304805\n",
      "Train Epoch: 2 [0/14160 (0%)]\tLoss: 0.296498\n",
      "Train Epoch: 2 [1000/14160 (7%)]\tLoss: 0.164538\n",
      "Train Epoch: 2 [2000/14160 (14%)]\tLoss: 0.317624\n",
      "Train Epoch: 2 [3000/14160 (21%)]\tLoss: 0.148066\n",
      "Train Epoch: 2 [4000/14160 (28%)]\tLoss: 0.204061\n",
      "Train Epoch: 2 [5000/14160 (35%)]\tLoss: 0.390355\n",
      "Train Epoch: 2 [6000/14160 (42%)]\tLoss: 0.194620\n",
      "Train Epoch: 2 [7000/14160 (49%)]\tLoss: 0.217041\n",
      "Train Epoch: 2 [8000/14160 (56%)]\tLoss: 0.242447\n",
      "Train Epoch: 2 [9000/14160 (63%)]\tLoss: 0.281936\n",
      "Train Epoch: 2 [10000/14160 (70%)]\tLoss: 0.305955\n",
      "Train Epoch: 2 [11000/14160 (77%)]\tLoss: 0.330409\n",
      "Train Epoch: 2 [12000/14160 (85%)]\tLoss: 0.212309\n",
      "Train Epoch: 2 [13000/14160 (92%)]\tLoss: 0.357661\n",
      "Train Epoch: 2 [14000/14160 (99%)]\tLoss: 0.230991\n",
      "Train Epoch: 3 [0/14160 (0%)]\tLoss: 0.387669\n",
      "Train Epoch: 3 [1000/14160 (7%)]\tLoss: 0.320494\n",
      "Train Epoch: 3 [2000/14160 (14%)]\tLoss: 0.178680\n",
      "Train Epoch: 3 [3000/14160 (21%)]\tLoss: 0.245515\n",
      "Train Epoch: 3 [4000/14160 (28%)]\tLoss: 0.191547\n",
      "Train Epoch: 3 [5000/14160 (35%)]\tLoss: 0.367615\n",
      "Train Epoch: 3 [6000/14160 (42%)]\tLoss: 0.209659\n",
      "Train Epoch: 3 [7000/14160 (49%)]\tLoss: 0.324201\n",
      "Train Epoch: 3 [8000/14160 (56%)]\tLoss: 0.239880\n",
      "Train Epoch: 3 [9000/14160 (63%)]\tLoss: 0.295697\n",
      "Train Epoch: 3 [10000/14160 (70%)]\tLoss: 0.273222\n",
      "Train Epoch: 3 [11000/14160 (77%)]\tLoss: 0.302844\n",
      "Train Epoch: 3 [12000/14160 (85%)]\tLoss: 0.189095\n",
      "Train Epoch: 3 [13000/14160 (92%)]\tLoss: 0.278469\n",
      "Train Epoch: 3 [14000/14160 (99%)]\tLoss: 0.284273\n",
      "Train Epoch: 4 [0/14160 (0%)]\tLoss: 0.223872\n",
      "Train Epoch: 4 [1000/14160 (7%)]\tLoss: 0.171678\n",
      "Train Epoch: 4 [2000/14160 (14%)]\tLoss: 0.296367\n",
      "Train Epoch: 4 [3000/14160 (21%)]\tLoss: 0.347129\n",
      "Train Epoch: 4 [4000/14160 (28%)]\tLoss: 0.328218\n",
      "Train Epoch: 4 [5000/14160 (35%)]\tLoss: 0.264347\n",
      "Train Epoch: 4 [6000/14160 (42%)]\tLoss: 0.269780\n",
      "Train Epoch: 4 [7000/14160 (49%)]\tLoss: 0.160536\n",
      "Train Epoch: 4 [8000/14160 (56%)]\tLoss: 0.208217\n",
      "Train Epoch: 4 [9000/14160 (63%)]\tLoss: 0.217255\n",
      "Train Epoch: 4 [10000/14160 (70%)]\tLoss: 0.176859\n",
      "Train Epoch: 4 [11000/14160 (77%)]\tLoss: 0.333409\n",
      "Train Epoch: 4 [12000/14160 (85%)]\tLoss: 0.297096\n",
      "Train Epoch: 4 [13000/14160 (92%)]\tLoss: 0.180228\n",
      "Train Epoch: 4 [14000/14160 (99%)]\tLoss: 0.274799\n",
      "Train Epoch: 5 [0/14160 (0%)]\tLoss: 0.237901\n",
      "Train Epoch: 5 [1000/14160 (7%)]\tLoss: 0.357643\n",
      "Train Epoch: 5 [2000/14160 (14%)]\tLoss: 0.177950\n",
      "Train Epoch: 5 [3000/14160 (21%)]\tLoss: 0.376446\n",
      "Train Epoch: 5 [4000/14160 (28%)]\tLoss: 0.277893\n",
      "Train Epoch: 5 [5000/14160 (35%)]\tLoss: 0.193207\n",
      "Train Epoch: 5 [6000/14160 (42%)]\tLoss: 0.339220\n",
      "Train Epoch: 5 [7000/14160 (49%)]\tLoss: 0.274786\n",
      "Train Epoch: 5 [8000/14160 (56%)]\tLoss: 0.308044\n",
      "Train Epoch: 5 [9000/14160 (63%)]\tLoss: 0.350649\n",
      "Train Epoch: 5 [10000/14160 (70%)]\tLoss: 0.183711\n",
      "Train Epoch: 5 [11000/14160 (77%)]\tLoss: 0.322583\n",
      "Train Epoch: 5 [12000/14160 (85%)]\tLoss: 0.326337\n",
      "Train Epoch: 5 [13000/14160 (92%)]\tLoss: 0.200188\n",
      "Train Epoch: 5 [14000/14160 (99%)]\tLoss: 0.242436\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/16239 (0%)]\tLoss: 0.561462\n",
      "Train Epoch: 1 [1000/16239 (6%)]\tLoss: 0.269999\n",
      "Train Epoch: 1 [2000/16239 (12%)]\tLoss: 0.364589\n",
      "Train Epoch: 1 [3000/16239 (18%)]\tLoss: 0.375934\n",
      "Train Epoch: 1 [4000/16239 (25%)]\tLoss: 0.392111\n",
      "Train Epoch: 1 [5000/16239 (31%)]\tLoss: 0.336733\n",
      "Train Epoch: 1 [6000/16239 (37%)]\tLoss: 0.377318\n",
      "Train Epoch: 1 [7000/16239 (43%)]\tLoss: 0.391246\n",
      "Train Epoch: 1 [8000/16239 (49%)]\tLoss: 0.634761\n",
      "Train Epoch: 1 [9000/16239 (55%)]\tLoss: 0.311621\n",
      "Train Epoch: 1 [10000/16239 (61%)]\tLoss: 0.298945\n",
      "Train Epoch: 1 [11000/16239 (67%)]\tLoss: 0.355140\n",
      "Train Epoch: 1 [12000/16239 (74%)]\tLoss: 0.299528\n",
      "Train Epoch: 1 [13000/16239 (80%)]\tLoss: 0.425957\n",
      "Train Epoch: 1 [14000/16239 (86%)]\tLoss: 0.384040\n",
      "Train Epoch: 1 [15000/16239 (92%)]\tLoss: 0.395278\n",
      "Train Epoch: 1 [16000/16239 (98%)]\tLoss: 0.351920\n",
      "Train Epoch: 2 [0/16239 (0%)]\tLoss: 0.347009\n",
      "Train Epoch: 2 [1000/16239 (6%)]\tLoss: 0.201842\n",
      "Train Epoch: 2 [2000/16239 (12%)]\tLoss: 0.488982\n",
      "Train Epoch: 2 [3000/16239 (18%)]\tLoss: 0.347268\n",
      "Train Epoch: 2 [4000/16239 (25%)]\tLoss: 0.405314\n",
      "Train Epoch: 2 [5000/16239 (31%)]\tLoss: 0.289005\n",
      "Train Epoch: 2 [6000/16239 (37%)]\tLoss: 0.341329\n",
      "Train Epoch: 2 [7000/16239 (43%)]\tLoss: 0.367679\n",
      "Train Epoch: 2 [8000/16239 (49%)]\tLoss: 0.500348\n",
      "Train Epoch: 2 [9000/16239 (55%)]\tLoss: 0.409870\n",
      "Train Epoch: 2 [10000/16239 (61%)]\tLoss: 0.382341\n",
      "Train Epoch: 2 [11000/16239 (67%)]\tLoss: 0.387677\n",
      "Train Epoch: 2 [12000/16239 (74%)]\tLoss: 0.389374\n",
      "Train Epoch: 2 [13000/16239 (80%)]\tLoss: 0.192924\n",
      "Train Epoch: 2 [14000/16239 (86%)]\tLoss: 0.423856\n",
      "Train Epoch: 2 [15000/16239 (92%)]\tLoss: 0.302331\n",
      "Train Epoch: 2 [16000/16239 (98%)]\tLoss: 0.298432\n",
      "Train Epoch: 3 [0/16239 (0%)]\tLoss: 0.327532\n",
      "Train Epoch: 3 [1000/16239 (6%)]\tLoss: 0.391603\n",
      "Train Epoch: 3 [2000/16239 (12%)]\tLoss: 0.258448\n",
      "Train Epoch: 3 [3000/16239 (18%)]\tLoss: 0.434446\n",
      "Train Epoch: 3 [4000/16239 (25%)]\tLoss: 0.260393\n",
      "Train Epoch: 3 [5000/16239 (31%)]\tLoss: 0.465579\n",
      "Train Epoch: 3 [6000/16239 (37%)]\tLoss: 0.368736\n",
      "Train Epoch: 3 [7000/16239 (43%)]\tLoss: 0.372731\n",
      "Train Epoch: 3 [8000/16239 (49%)]\tLoss: 0.287241\n",
      "Train Epoch: 3 [9000/16239 (55%)]\tLoss: 0.249618\n",
      "Train Epoch: 3 [10000/16239 (61%)]\tLoss: 0.396129\n",
      "Train Epoch: 3 [11000/16239 (67%)]\tLoss: 0.318636\n",
      "Train Epoch: 3 [12000/16239 (74%)]\tLoss: 0.369997\n",
      "Train Epoch: 3 [13000/16239 (80%)]\tLoss: 0.311910\n",
      "Train Epoch: 3 [14000/16239 (86%)]\tLoss: 0.284552\n",
      "Train Epoch: 3 [15000/16239 (92%)]\tLoss: 0.296381\n",
      "Train Epoch: 3 [16000/16239 (98%)]\tLoss: 0.386698\n",
      "Train Epoch: 4 [0/16239 (0%)]\tLoss: 0.333258\n",
      "Train Epoch: 4 [1000/16239 (6%)]\tLoss: 0.458778\n",
      "Train Epoch: 4 [2000/16239 (12%)]\tLoss: 0.393146\n",
      "Train Epoch: 4 [3000/16239 (18%)]\tLoss: 0.402989\n",
      "Train Epoch: 4 [4000/16239 (25%)]\tLoss: 0.397293\n",
      "Train Epoch: 4 [5000/16239 (31%)]\tLoss: 0.352795\n",
      "Train Epoch: 4 [6000/16239 (37%)]\tLoss: 0.285224\n",
      "Train Epoch: 4 [7000/16239 (43%)]\tLoss: 0.283349\n",
      "Train Epoch: 4 [8000/16239 (49%)]\tLoss: 0.318513\n",
      "Train Epoch: 4 [9000/16239 (55%)]\tLoss: 0.224663\n",
      "Train Epoch: 4 [10000/16239 (61%)]\tLoss: 0.390712\n",
      "Train Epoch: 4 [11000/16239 (67%)]\tLoss: 0.239667\n",
      "Train Epoch: 4 [12000/16239 (74%)]\tLoss: 0.240793\n",
      "Train Epoch: 4 [13000/16239 (80%)]\tLoss: 0.350023\n",
      "Train Epoch: 4 [14000/16239 (86%)]\tLoss: 0.363567\n",
      "Train Epoch: 4 [15000/16239 (92%)]\tLoss: 0.284047\n",
      "Train Epoch: 4 [16000/16239 (98%)]\tLoss: 0.339606\n",
      "Train Epoch: 5 [0/16239 (0%)]\tLoss: 0.402541\n",
      "Train Epoch: 5 [1000/16239 (6%)]\tLoss: 0.283273\n",
      "Train Epoch: 5 [2000/16239 (12%)]\tLoss: 0.336562\n",
      "Train Epoch: 5 [3000/16239 (18%)]\tLoss: 0.429577\n",
      "Train Epoch: 5 [4000/16239 (25%)]\tLoss: 0.314719\n",
      "Train Epoch: 5 [5000/16239 (31%)]\tLoss: 0.207153\n",
      "Train Epoch: 5 [6000/16239 (37%)]\tLoss: 0.427510\n",
      "Train Epoch: 5 [7000/16239 (43%)]\tLoss: 0.274427\n",
      "Train Epoch: 5 [8000/16239 (49%)]\tLoss: 0.305610\n",
      "Train Epoch: 5 [9000/16239 (55%)]\tLoss: 0.380828\n",
      "Train Epoch: 5 [10000/16239 (61%)]\tLoss: 0.356166\n",
      "Train Epoch: 5 [11000/16239 (67%)]\tLoss: 0.329342\n",
      "Train Epoch: 5 [12000/16239 (74%)]\tLoss: 0.469474\n",
      "Train Epoch: 5 [13000/16239 (80%)]\tLoss: 0.250928\n",
      "Train Epoch: 5 [14000/16239 (86%)]\tLoss: 0.461577\n",
      "Train Epoch: 5 [15000/16239 (92%)]\tLoss: 0.196304\n",
      "Train Epoch: 5 [16000/16239 (98%)]\tLoss: 0.327087\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.446754\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.315230\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.206225\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.318705\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.285668\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.428911\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.387528\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.291263\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.162971\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.385314\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.215847\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.272201\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.217581\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.249796\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.223589\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.152900\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.320701\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.360656\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.203452\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.167764\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.177076\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.307670\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.253675\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.233098\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.321970\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.220799\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.204317\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.257355\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.269418\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.237104\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/11596 (0%)]\tLoss: 0.426388\n",
      "Train Epoch: 1 [1000/11596 (9%)]\tLoss: 0.334509\n",
      "Train Epoch: 1 [2000/11596 (17%)]\tLoss: 0.398347\n",
      "Train Epoch: 1 [3000/11596 (26%)]\tLoss: 0.297672\n",
      "Train Epoch: 1 [4000/11596 (34%)]\tLoss: 0.310877\n",
      "Train Epoch: 1 [5000/11596 (43%)]\tLoss: 0.227646\n",
      "Train Epoch: 1 [6000/11596 (52%)]\tLoss: 0.311826\n",
      "Train Epoch: 1 [7000/11596 (60%)]\tLoss: 0.298750\n",
      "Train Epoch: 1 [8000/11596 (69%)]\tLoss: 0.367158\n",
      "Train Epoch: 1 [9000/11596 (78%)]\tLoss: 0.454908\n",
      "Train Epoch: 1 [10000/11596 (86%)]\tLoss: 0.424514\n",
      "Train Epoch: 1 [11000/11596 (95%)]\tLoss: 0.547297\n",
      "Train Epoch: 2 [0/11596 (0%)]\tLoss: 0.477606\n",
      "Train Epoch: 2 [1000/11596 (9%)]\tLoss: 0.347470\n",
      "Train Epoch: 2 [2000/11596 (17%)]\tLoss: 0.224803\n",
      "Train Epoch: 2 [3000/11596 (26%)]\tLoss: 0.418310\n",
      "Train Epoch: 2 [4000/11596 (34%)]\tLoss: 0.399512\n",
      "Train Epoch: 2 [5000/11596 (43%)]\tLoss: 0.236579\n",
      "Train Epoch: 2 [6000/11596 (52%)]\tLoss: 0.430657\n",
      "Train Epoch: 2 [7000/11596 (60%)]\tLoss: 0.272559\n",
      "Train Epoch: 2 [8000/11596 (69%)]\tLoss: 0.285225\n",
      "Train Epoch: 2 [9000/11596 (78%)]\tLoss: 0.278751\n",
      "Train Epoch: 2 [10000/11596 (86%)]\tLoss: 0.323030\n",
      "Train Epoch: 2 [11000/11596 (95%)]\tLoss: 0.259487\n",
      "Train Epoch: 3 [0/11596 (0%)]\tLoss: 0.281654\n",
      "Train Epoch: 3 [1000/11596 (9%)]\tLoss: 0.303133\n",
      "Train Epoch: 3 [2000/11596 (17%)]\tLoss: 0.485737\n",
      "Train Epoch: 3 [3000/11596 (26%)]\tLoss: 0.383578\n",
      "Train Epoch: 3 [4000/11596 (34%)]\tLoss: 0.374847\n",
      "Train Epoch: 3 [5000/11596 (43%)]\tLoss: 0.271987\n",
      "Train Epoch: 3 [6000/11596 (52%)]\tLoss: 0.374916\n",
      "Train Epoch: 3 [7000/11596 (60%)]\tLoss: 0.353023\n",
      "Train Epoch: 3 [8000/11596 (69%)]\tLoss: 0.328163\n",
      "Train Epoch: 3 [9000/11596 (78%)]\tLoss: 0.308597\n",
      "Train Epoch: 3 [10000/11596 (86%)]\tLoss: 0.359390\n",
      "Train Epoch: 3 [11000/11596 (95%)]\tLoss: 0.252951\n",
      "Train Epoch: 4 [0/11596 (0%)]\tLoss: 0.370052\n",
      "Train Epoch: 4 [1000/11596 (9%)]\tLoss: 0.350525\n",
      "Train Epoch: 4 [2000/11596 (17%)]\tLoss: 0.343010\n",
      "Train Epoch: 4 [3000/11596 (26%)]\tLoss: 0.288676\n",
      "Train Epoch: 4 [4000/11596 (34%)]\tLoss: 0.271755\n",
      "Train Epoch: 4 [5000/11596 (43%)]\tLoss: 0.252556\n",
      "Train Epoch: 4 [6000/11596 (52%)]\tLoss: 0.332547\n",
      "Train Epoch: 4 [7000/11596 (60%)]\tLoss: 0.284921\n",
      "Train Epoch: 4 [8000/11596 (69%)]\tLoss: 0.214465\n",
      "Train Epoch: 4 [9000/11596 (78%)]\tLoss: 0.407650\n",
      "Train Epoch: 4 [10000/11596 (86%)]\tLoss: 0.347878\n",
      "Train Epoch: 4 [11000/11596 (95%)]\tLoss: 0.332624\n",
      "Train Epoch: 5 [0/11596 (0%)]\tLoss: 0.341011\n",
      "Train Epoch: 5 [1000/11596 (9%)]\tLoss: 0.175671\n",
      "Train Epoch: 5 [2000/11596 (17%)]\tLoss: 0.356400\n",
      "Train Epoch: 5 [3000/11596 (26%)]\tLoss: 0.357878\n",
      "Train Epoch: 5 [4000/11596 (34%)]\tLoss: 0.255667\n",
      "Train Epoch: 5 [5000/11596 (43%)]\tLoss: 0.275513\n",
      "Train Epoch: 5 [6000/11596 (52%)]\tLoss: 0.451571\n",
      "Train Epoch: 5 [7000/11596 (60%)]\tLoss: 0.236836\n",
      "Train Epoch: 5 [8000/11596 (69%)]\tLoss: 0.340638\n",
      "Train Epoch: 5 [9000/11596 (78%)]\tLoss: 0.311435\n",
      "Train Epoch: 5 [10000/11596 (86%)]\tLoss: 0.385742\n",
      "Train Epoch: 5 [11000/11596 (95%)]\tLoss: 0.207054\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.384303\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.252547\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.269962\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.424485\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.442380\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.382756\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.281409\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.466235\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.294315\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.361555\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.211757\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.429861\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.378623\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.396578\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.296827\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.313233\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.388422\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.237864\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.395749\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.274795\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8393, Accuracy: 7722/10000 (77%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/9140 (0%)]\tLoss: 0.514657\n",
      "Train Epoch: 1 [1000/9140 (11%)]\tLoss: 0.463108\n",
      "Train Epoch: 1 [2000/9140 (22%)]\tLoss: 0.296842\n",
      "Train Epoch: 1 [3000/9140 (33%)]\tLoss: 0.482778\n",
      "Train Epoch: 1 [4000/9140 (43%)]\tLoss: 0.516375\n",
      "Train Epoch: 1 [5000/9140 (54%)]\tLoss: 0.377634\n",
      "Train Epoch: 1 [6000/9140 (65%)]\tLoss: 0.355388\n",
      "Train Epoch: 1 [7000/9140 (76%)]\tLoss: 0.429026\n",
      "Train Epoch: 1 [8000/9140 (87%)]\tLoss: 0.401950\n",
      "Train Epoch: 1 [9000/9140 (98%)]\tLoss: 0.340321\n",
      "Train Epoch: 2 [0/9140 (0%)]\tLoss: 0.435206\n",
      "Train Epoch: 2 [1000/9140 (11%)]\tLoss: 0.410828\n",
      "Train Epoch: 2 [2000/9140 (22%)]\tLoss: 0.386993\n",
      "Train Epoch: 2 [3000/9140 (33%)]\tLoss: 0.368516\n",
      "Train Epoch: 2 [4000/9140 (43%)]\tLoss: 0.348074\n",
      "Train Epoch: 2 [5000/9140 (54%)]\tLoss: 0.339620\n",
      "Train Epoch: 2 [6000/9140 (65%)]\tLoss: 0.318126\n",
      "Train Epoch: 2 [7000/9140 (76%)]\tLoss: 0.470920\n",
      "Train Epoch: 2 [8000/9140 (87%)]\tLoss: 0.419105\n",
      "Train Epoch: 2 [9000/9140 (98%)]\tLoss: 0.432155\n",
      "Train Epoch: 3 [0/9140 (0%)]\tLoss: 0.515081\n",
      "Train Epoch: 3 [1000/9140 (11%)]\tLoss: 0.385227\n",
      "Train Epoch: 3 [2000/9140 (22%)]\tLoss: 0.286029\n",
      "Train Epoch: 3 [3000/9140 (33%)]\tLoss: 0.440273\n",
      "Train Epoch: 3 [4000/9140 (43%)]\tLoss: 0.452487\n",
      "Train Epoch: 3 [5000/9140 (54%)]\tLoss: 0.362521\n",
      "Train Epoch: 3 [6000/9140 (65%)]\tLoss: 0.435712\n",
      "Train Epoch: 3 [7000/9140 (76%)]\tLoss: 0.377936\n",
      "Train Epoch: 3 [8000/9140 (87%)]\tLoss: 0.265563\n",
      "Train Epoch: 3 [9000/9140 (98%)]\tLoss: 0.314039\n",
      "Train Epoch: 4 [0/9140 (0%)]\tLoss: 0.287910\n",
      "Train Epoch: 4 [1000/9140 (11%)]\tLoss: 0.275448\n",
      "Train Epoch: 4 [2000/9140 (22%)]\tLoss: 0.319142\n",
      "Train Epoch: 4 [3000/9140 (33%)]\tLoss: 0.306006\n",
      "Train Epoch: 4 [4000/9140 (43%)]\tLoss: 0.417045\n",
      "Train Epoch: 4 [5000/9140 (54%)]\tLoss: 0.408490\n",
      "Train Epoch: 4 [6000/9140 (65%)]\tLoss: 0.353792\n",
      "Train Epoch: 4 [7000/9140 (76%)]\tLoss: 0.480083\n",
      "Train Epoch: 4 [8000/9140 (87%)]\tLoss: 0.297754\n",
      "Train Epoch: 4 [9000/9140 (98%)]\tLoss: 0.507778\n",
      "Train Epoch: 5 [0/9140 (0%)]\tLoss: 0.328308\n",
      "Train Epoch: 5 [1000/9140 (11%)]\tLoss: 0.372255\n",
      "Train Epoch: 5 [2000/9140 (22%)]\tLoss: 0.429990\n",
      "Train Epoch: 5 [3000/9140 (33%)]\tLoss: 0.276442\n",
      "Train Epoch: 5 [4000/9140 (43%)]\tLoss: 0.369090\n",
      "Train Epoch: 5 [5000/9140 (54%)]\tLoss: 0.257532\n",
      "Train Epoch: 5 [6000/9140 (65%)]\tLoss: 0.374838\n",
      "Train Epoch: 5 [7000/9140 (76%)]\tLoss: 0.348280\n",
      "Train Epoch: 5 [8000/9140 (87%)]\tLoss: 0.370946\n",
      "Train Epoch: 5 [9000/9140 (98%)]\tLoss: 0.345146\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/14160 (0%)]\tLoss: 0.495184\n",
      "Train Epoch: 1 [1000/14160 (7%)]\tLoss: 0.310644\n",
      "Train Epoch: 1 [2000/14160 (14%)]\tLoss: 0.214649\n",
      "Train Epoch: 1 [3000/14160 (21%)]\tLoss: 0.371283\n",
      "Train Epoch: 1 [4000/14160 (28%)]\tLoss: 0.300813\n",
      "Train Epoch: 1 [5000/14160 (35%)]\tLoss: 0.212254\n",
      "Train Epoch: 1 [6000/14160 (42%)]\tLoss: 0.245524\n",
      "Train Epoch: 1 [7000/14160 (49%)]\tLoss: 0.224033\n",
      "Train Epoch: 1 [8000/14160 (56%)]\tLoss: 0.432673\n",
      "Train Epoch: 1 [9000/14160 (63%)]\tLoss: 0.570064\n",
      "Train Epoch: 1 [10000/14160 (70%)]\tLoss: 0.341280\n",
      "Train Epoch: 1 [11000/14160 (77%)]\tLoss: 0.297431\n",
      "Train Epoch: 1 [12000/14160 (85%)]\tLoss: 0.362379\n",
      "Train Epoch: 1 [13000/14160 (92%)]\tLoss: 0.312062\n",
      "Train Epoch: 1 [14000/14160 (99%)]\tLoss: 0.282013\n",
      "Train Epoch: 2 [0/14160 (0%)]\tLoss: 0.153958\n",
      "Train Epoch: 2 [1000/14160 (7%)]\tLoss: 0.232564\n",
      "Train Epoch: 2 [2000/14160 (14%)]\tLoss: 0.307297\n",
      "Train Epoch: 2 [3000/14160 (21%)]\tLoss: 0.331037\n",
      "Train Epoch: 2 [4000/14160 (28%)]\tLoss: 0.248067\n",
      "Train Epoch: 2 [5000/14160 (35%)]\tLoss: 0.254255\n",
      "Train Epoch: 2 [6000/14160 (42%)]\tLoss: 0.334604\n",
      "Train Epoch: 2 [7000/14160 (49%)]\tLoss: 0.240916\n",
      "Train Epoch: 2 [8000/14160 (56%)]\tLoss: 0.246262\n",
      "Train Epoch: 2 [9000/14160 (63%)]\tLoss: 0.325370\n",
      "Train Epoch: 2 [10000/14160 (70%)]\tLoss: 0.259420\n",
      "Train Epoch: 2 [11000/14160 (77%)]\tLoss: 0.337449\n",
      "Train Epoch: 2 [12000/14160 (85%)]\tLoss: 0.193290\n",
      "Train Epoch: 2 [13000/14160 (92%)]\tLoss: 0.354228\n",
      "Train Epoch: 2 [14000/14160 (99%)]\tLoss: 0.378001\n",
      "Train Epoch: 3 [0/14160 (0%)]\tLoss: 0.230817\n",
      "Train Epoch: 3 [1000/14160 (7%)]\tLoss: 0.337067\n",
      "Train Epoch: 3 [2000/14160 (14%)]\tLoss: 0.211945\n",
      "Train Epoch: 3 [3000/14160 (21%)]\tLoss: 0.188140\n",
      "Train Epoch: 3 [4000/14160 (28%)]\tLoss: 0.142780\n",
      "Train Epoch: 3 [5000/14160 (35%)]\tLoss: 0.224176\n",
      "Train Epoch: 3 [6000/14160 (42%)]\tLoss: 0.237755\n",
      "Train Epoch: 3 [7000/14160 (49%)]\tLoss: 0.449014\n",
      "Train Epoch: 3 [8000/14160 (56%)]\tLoss: 0.262975\n",
      "Train Epoch: 3 [9000/14160 (63%)]\tLoss: 0.402690\n",
      "Train Epoch: 3 [10000/14160 (70%)]\tLoss: 0.303829\n",
      "Train Epoch: 3 [11000/14160 (77%)]\tLoss: 0.318752\n",
      "Train Epoch: 3 [12000/14160 (85%)]\tLoss: 0.373259\n",
      "Train Epoch: 3 [13000/14160 (92%)]\tLoss: 0.281475\n",
      "Train Epoch: 3 [14000/14160 (99%)]\tLoss: 0.432256\n",
      "Train Epoch: 4 [0/14160 (0%)]\tLoss: 0.207485\n",
      "Train Epoch: 4 [1000/14160 (7%)]\tLoss: 0.390609\n",
      "Train Epoch: 4 [2000/14160 (14%)]\tLoss: 0.341409\n",
      "Train Epoch: 4 [3000/14160 (21%)]\tLoss: 0.196323\n",
      "Train Epoch: 4 [4000/14160 (28%)]\tLoss: 0.250592\n",
      "Train Epoch: 4 [5000/14160 (35%)]\tLoss: 0.336354\n",
      "Train Epoch: 4 [6000/14160 (42%)]\tLoss: 0.258190\n",
      "Train Epoch: 4 [7000/14160 (49%)]\tLoss: 0.133186\n",
      "Train Epoch: 4 [8000/14160 (56%)]\tLoss: 0.218560\n",
      "Train Epoch: 4 [9000/14160 (63%)]\tLoss: 0.295887\n",
      "Train Epoch: 4 [10000/14160 (70%)]\tLoss: 0.246237\n",
      "Train Epoch: 4 [11000/14160 (77%)]\tLoss: 0.162854\n",
      "Train Epoch: 4 [12000/14160 (85%)]\tLoss: 0.193862\n",
      "Train Epoch: 4 [13000/14160 (92%)]\tLoss: 0.181674\n",
      "Train Epoch: 4 [14000/14160 (99%)]\tLoss: 0.234048\n",
      "Train Epoch: 5 [0/14160 (0%)]\tLoss: 0.289693\n",
      "Train Epoch: 5 [1000/14160 (7%)]\tLoss: 0.256915\n",
      "Train Epoch: 5 [2000/14160 (14%)]\tLoss: 0.246190\n",
      "Train Epoch: 5 [3000/14160 (21%)]\tLoss: 0.201778\n",
      "Train Epoch: 5 [4000/14160 (28%)]\tLoss: 0.239873\n",
      "Train Epoch: 5 [5000/14160 (35%)]\tLoss: 0.348140\n",
      "Train Epoch: 5 [6000/14160 (42%)]\tLoss: 0.254014\n",
      "Train Epoch: 5 [7000/14160 (49%)]\tLoss: 0.174453\n",
      "Train Epoch: 5 [8000/14160 (56%)]\tLoss: 0.186928\n",
      "Train Epoch: 5 [9000/14160 (63%)]\tLoss: 0.313851\n",
      "Train Epoch: 5 [10000/14160 (70%)]\tLoss: 0.190080\n",
      "Train Epoch: 5 [11000/14160 (77%)]\tLoss: 0.275158\n",
      "Train Epoch: 5 [12000/14160 (85%)]\tLoss: 0.230824\n",
      "Train Epoch: 5 [13000/14160 (92%)]\tLoss: 0.205664\n",
      "Train Epoch: 5 [14000/14160 (99%)]\tLoss: 0.202782\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/16239 (0%)]\tLoss: 0.361219\n",
      "Train Epoch: 1 [1000/16239 (6%)]\tLoss: 0.337088\n",
      "Train Epoch: 1 [2000/16239 (12%)]\tLoss: 0.355714\n",
      "Train Epoch: 1 [3000/16239 (18%)]\tLoss: 0.242300\n",
      "Train Epoch: 1 [4000/16239 (25%)]\tLoss: 0.430409\n",
      "Train Epoch: 1 [5000/16239 (31%)]\tLoss: 0.271591\n",
      "Train Epoch: 1 [6000/16239 (37%)]\tLoss: 0.339873\n",
      "Train Epoch: 1 [7000/16239 (43%)]\tLoss: 0.452063\n",
      "Train Epoch: 1 [8000/16239 (49%)]\tLoss: 0.274584\n",
      "Train Epoch: 1 [9000/16239 (55%)]\tLoss: 0.167238\n",
      "Train Epoch: 1 [10000/16239 (61%)]\tLoss: 0.282579\n",
      "Train Epoch: 1 [11000/16239 (67%)]\tLoss: 0.229084\n",
      "Train Epoch: 1 [12000/16239 (74%)]\tLoss: 0.415272\n",
      "Train Epoch: 1 [13000/16239 (80%)]\tLoss: 0.262726\n",
      "Train Epoch: 1 [14000/16239 (86%)]\tLoss: 0.308240\n",
      "Train Epoch: 1 [15000/16239 (92%)]\tLoss: 0.447160\n",
      "Train Epoch: 1 [16000/16239 (98%)]\tLoss: 0.415453\n",
      "Train Epoch: 2 [0/16239 (0%)]\tLoss: 0.361093\n",
      "Train Epoch: 2 [1000/16239 (6%)]\tLoss: 0.358193\n",
      "Train Epoch: 2 [2000/16239 (12%)]\tLoss: 0.359080\n",
      "Train Epoch: 2 [3000/16239 (18%)]\tLoss: 0.407332\n",
      "Train Epoch: 2 [4000/16239 (25%)]\tLoss: 0.357591\n",
      "Train Epoch: 2 [5000/16239 (31%)]\tLoss: 0.266082\n",
      "Train Epoch: 2 [6000/16239 (37%)]\tLoss: 0.288012\n",
      "Train Epoch: 2 [7000/16239 (43%)]\tLoss: 0.257503\n",
      "Train Epoch: 2 [8000/16239 (49%)]\tLoss: 0.319151\n",
      "Train Epoch: 2 [9000/16239 (55%)]\tLoss: 0.435122\n",
      "Train Epoch: 2 [10000/16239 (61%)]\tLoss: 0.355036\n",
      "Train Epoch: 2 [11000/16239 (67%)]\tLoss: 0.320029\n",
      "Train Epoch: 2 [12000/16239 (74%)]\tLoss: 0.411332\n",
      "Train Epoch: 2 [13000/16239 (80%)]\tLoss: 0.370259\n",
      "Train Epoch: 2 [14000/16239 (86%)]\tLoss: 0.350745\n",
      "Train Epoch: 2 [15000/16239 (92%)]\tLoss: 0.380204\n",
      "Train Epoch: 2 [16000/16239 (98%)]\tLoss: 0.278080\n",
      "Train Epoch: 3 [0/16239 (0%)]\tLoss: 0.269702\n",
      "Train Epoch: 3 [1000/16239 (6%)]\tLoss: 0.320022\n",
      "Train Epoch: 3 [2000/16239 (12%)]\tLoss: 0.448315\n",
      "Train Epoch: 3 [3000/16239 (18%)]\tLoss: 0.362075\n",
      "Train Epoch: 3 [4000/16239 (25%)]\tLoss: 0.549980\n",
      "Train Epoch: 3 [5000/16239 (31%)]\tLoss: 0.328482\n",
      "Train Epoch: 3 [6000/16239 (37%)]\tLoss: 0.467755\n",
      "Train Epoch: 3 [7000/16239 (43%)]\tLoss: 0.438568\n",
      "Train Epoch: 3 [8000/16239 (49%)]\tLoss: 0.366437\n",
      "Train Epoch: 3 [9000/16239 (55%)]\tLoss: 0.601657\n",
      "Train Epoch: 3 [10000/16239 (61%)]\tLoss: 0.262574\n",
      "Train Epoch: 3 [11000/16239 (67%)]\tLoss: 0.463339\n",
      "Train Epoch: 3 [12000/16239 (74%)]\tLoss: 0.324080\n",
      "Train Epoch: 3 [13000/16239 (80%)]\tLoss: 0.380251\n",
      "Train Epoch: 3 [14000/16239 (86%)]\tLoss: 0.332326\n",
      "Train Epoch: 3 [15000/16239 (92%)]\tLoss: 0.361216\n",
      "Train Epoch: 3 [16000/16239 (98%)]\tLoss: 0.381422\n",
      "Train Epoch: 4 [0/16239 (0%)]\tLoss: 0.341499\n",
      "Train Epoch: 4 [1000/16239 (6%)]\tLoss: 0.416876\n",
      "Train Epoch: 4 [2000/16239 (12%)]\tLoss: 0.304900\n",
      "Train Epoch: 4 [3000/16239 (18%)]\tLoss: 0.216477\n",
      "Train Epoch: 4 [4000/16239 (25%)]\tLoss: 0.359470\n",
      "Train Epoch: 4 [5000/16239 (31%)]\tLoss: 0.351180\n",
      "Train Epoch: 4 [6000/16239 (37%)]\tLoss: 0.292433\n",
      "Train Epoch: 4 [7000/16239 (43%)]\tLoss: 0.450297\n",
      "Train Epoch: 4 [8000/16239 (49%)]\tLoss: 0.302098\n",
      "Train Epoch: 4 [9000/16239 (55%)]\tLoss: 0.329365\n",
      "Train Epoch: 4 [10000/16239 (61%)]\tLoss: 0.404031\n",
      "Train Epoch: 4 [11000/16239 (67%)]\tLoss: 0.404110\n",
      "Train Epoch: 4 [12000/16239 (74%)]\tLoss: 0.283834\n",
      "Train Epoch: 4 [13000/16239 (80%)]\tLoss: 0.505740\n",
      "Train Epoch: 4 [14000/16239 (86%)]\tLoss: 0.431593\n",
      "Train Epoch: 4 [15000/16239 (92%)]\tLoss: 0.291166\n",
      "Train Epoch: 4 [16000/16239 (98%)]\tLoss: 0.343972\n",
      "Train Epoch: 5 [0/16239 (0%)]\tLoss: 0.317618\n",
      "Train Epoch: 5 [1000/16239 (6%)]\tLoss: 0.388820\n",
      "Train Epoch: 5 [2000/16239 (12%)]\tLoss: 0.366490\n",
      "Train Epoch: 5 [3000/16239 (18%)]\tLoss: 0.562198\n",
      "Train Epoch: 5 [4000/16239 (25%)]\tLoss: 0.303866\n",
      "Train Epoch: 5 [5000/16239 (31%)]\tLoss: 0.424537\n",
      "Train Epoch: 5 [6000/16239 (37%)]\tLoss: 0.385354\n",
      "Train Epoch: 5 [7000/16239 (43%)]\tLoss: 0.453993\n",
      "Train Epoch: 5 [8000/16239 (49%)]\tLoss: 0.416842\n",
      "Train Epoch: 5 [9000/16239 (55%)]\tLoss: 0.493091\n",
      "Train Epoch: 5 [10000/16239 (61%)]\tLoss: 0.319902\n",
      "Train Epoch: 5 [11000/16239 (67%)]\tLoss: 0.366090\n",
      "Train Epoch: 5 [12000/16239 (74%)]\tLoss: 0.398907\n",
      "Train Epoch: 5 [13000/16239 (80%)]\tLoss: 0.352477\n",
      "Train Epoch: 5 [14000/16239 (86%)]\tLoss: 0.425073\n",
      "Train Epoch: 5 [15000/16239 (92%)]\tLoss: 0.400053\n",
      "Train Epoch: 5 [16000/16239 (98%)]\tLoss: 0.399072\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.453912\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.238451\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.281304\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.406881\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.235718\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.274713\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.236945\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.254755\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.250419\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.301975\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.163807\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.150498\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.242429\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.200998\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.229044\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.244512\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.114097\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.215600\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.350843\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.429115\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.236796\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.301848\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.287681\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.150808\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.291241\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.249412\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.152153\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.179083\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.165544\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.243368\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/11596 (0%)]\tLoss: 0.418057\n",
      "Train Epoch: 1 [1000/11596 (9%)]\tLoss: 0.319163\n",
      "Train Epoch: 1 [2000/11596 (17%)]\tLoss: 0.314969\n",
      "Train Epoch: 1 [3000/11596 (26%)]\tLoss: 0.356442\n",
      "Train Epoch: 1 [4000/11596 (34%)]\tLoss: 0.275988\n",
      "Train Epoch: 1 [5000/11596 (43%)]\tLoss: 0.236584\n",
      "Train Epoch: 1 [6000/11596 (52%)]\tLoss: 0.283529\n",
      "Train Epoch: 1 [7000/11596 (60%)]\tLoss: 0.410107\n",
      "Train Epoch: 1 [8000/11596 (69%)]\tLoss: 0.318180\n",
      "Train Epoch: 1 [9000/11596 (78%)]\tLoss: 0.359121\n",
      "Train Epoch: 1 [10000/11596 (86%)]\tLoss: 0.224425\n",
      "Train Epoch: 1 [11000/11596 (95%)]\tLoss: 0.328689\n",
      "Train Epoch: 2 [0/11596 (0%)]\tLoss: 0.339376\n",
      "Train Epoch: 2 [1000/11596 (9%)]\tLoss: 0.321583\n",
      "Train Epoch: 2 [2000/11596 (17%)]\tLoss: 0.316302\n",
      "Train Epoch: 2 [3000/11596 (26%)]\tLoss: 0.309720\n",
      "Train Epoch: 2 [4000/11596 (34%)]\tLoss: 0.294340\n",
      "Train Epoch: 2 [5000/11596 (43%)]\tLoss: 0.378826\n",
      "Train Epoch: 2 [6000/11596 (52%)]\tLoss: 0.301280\n",
      "Train Epoch: 2 [7000/11596 (60%)]\tLoss: 0.327735\n",
      "Train Epoch: 2 [8000/11596 (69%)]\tLoss: 0.240982\n",
      "Train Epoch: 2 [9000/11596 (78%)]\tLoss: 0.330905\n",
      "Train Epoch: 2 [10000/11596 (86%)]\tLoss: 0.374689\n",
      "Train Epoch: 2 [11000/11596 (95%)]\tLoss: 0.268787\n",
      "Train Epoch: 3 [0/11596 (0%)]\tLoss: 0.299429\n",
      "Train Epoch: 3 [1000/11596 (9%)]\tLoss: 0.341751\n",
      "Train Epoch: 3 [2000/11596 (17%)]\tLoss: 0.348007\n",
      "Train Epoch: 3 [3000/11596 (26%)]\tLoss: 0.301612\n",
      "Train Epoch: 3 [4000/11596 (34%)]\tLoss: 0.382905\n",
      "Train Epoch: 3 [5000/11596 (43%)]\tLoss: 0.346646\n",
      "Train Epoch: 3 [6000/11596 (52%)]\tLoss: 0.233052\n",
      "Train Epoch: 3 [7000/11596 (60%)]\tLoss: 0.398676\n",
      "Train Epoch: 3 [8000/11596 (69%)]\tLoss: 0.328793\n",
      "Train Epoch: 3 [9000/11596 (78%)]\tLoss: 0.413678\n",
      "Train Epoch: 3 [10000/11596 (86%)]\tLoss: 0.337828\n",
      "Train Epoch: 3 [11000/11596 (95%)]\tLoss: 0.364627\n",
      "Train Epoch: 4 [0/11596 (0%)]\tLoss: 0.300522\n",
      "Train Epoch: 4 [1000/11596 (9%)]\tLoss: 0.362824\n",
      "Train Epoch: 4 [2000/11596 (17%)]\tLoss: 0.443106\n",
      "Train Epoch: 4 [3000/11596 (26%)]\tLoss: 0.377967\n",
      "Train Epoch: 4 [4000/11596 (34%)]\tLoss: 0.265514\n",
      "Train Epoch: 4 [5000/11596 (43%)]\tLoss: 0.315483\n",
      "Train Epoch: 4 [6000/11596 (52%)]\tLoss: 0.376312\n",
      "Train Epoch: 4 [7000/11596 (60%)]\tLoss: 0.193823\n",
      "Train Epoch: 4 [8000/11596 (69%)]\tLoss: 0.327082\n",
      "Train Epoch: 4 [9000/11596 (78%)]\tLoss: 0.168389\n",
      "Train Epoch: 4 [10000/11596 (86%)]\tLoss: 0.312431\n",
      "Train Epoch: 4 [11000/11596 (95%)]\tLoss: 0.355566\n",
      "Train Epoch: 5 [0/11596 (0%)]\tLoss: 0.294337\n",
      "Train Epoch: 5 [1000/11596 (9%)]\tLoss: 0.269451\n",
      "Train Epoch: 5 [2000/11596 (17%)]\tLoss: 0.319398\n",
      "Train Epoch: 5 [3000/11596 (26%)]\tLoss: 0.363451\n",
      "Train Epoch: 5 [4000/11596 (34%)]\tLoss: 0.296937\n",
      "Train Epoch: 5 [5000/11596 (43%)]\tLoss: 0.289047\n",
      "Train Epoch: 5 [6000/11596 (52%)]\tLoss: 0.336471\n",
      "Train Epoch: 5 [7000/11596 (60%)]\tLoss: 0.391417\n",
      "Train Epoch: 5 [8000/11596 (69%)]\tLoss: 0.269869\n",
      "Train Epoch: 5 [9000/11596 (78%)]\tLoss: 0.405306\n",
      "Train Epoch: 5 [10000/11596 (86%)]\tLoss: 0.294136\n",
      "Train Epoch: 5 [11000/11596 (95%)]\tLoss: 0.300230\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.600942\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.296692\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.356487\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.232966\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.266888\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.395295\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.362528\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.358844\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.388920\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.303002\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.289486\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.300741\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.303378\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.260900\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.359054\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.305079\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.437147\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.245666\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.401837\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.319241\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8608, Accuracy: 7677/10000 (77%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/9140 (0%)]\tLoss: 0.359616\n",
      "Train Epoch: 1 [1000/9140 (11%)]\tLoss: 0.431019\n",
      "Train Epoch: 1 [2000/9140 (22%)]\tLoss: 0.584420\n",
      "Train Epoch: 1 [3000/9140 (33%)]\tLoss: 0.340740\n",
      "Train Epoch: 1 [4000/9140 (43%)]\tLoss: 0.405672\n",
      "Train Epoch: 1 [5000/9140 (54%)]\tLoss: 0.575840\n",
      "Train Epoch: 1 [6000/9140 (65%)]\tLoss: 0.398282\n",
      "Train Epoch: 1 [7000/9140 (76%)]\tLoss: 0.359347\n",
      "Train Epoch: 1 [8000/9140 (87%)]\tLoss: 0.317833\n",
      "Train Epoch: 1 [9000/9140 (98%)]\tLoss: 0.451544\n",
      "Train Epoch: 2 [0/9140 (0%)]\tLoss: 0.352561\n",
      "Train Epoch: 2 [1000/9140 (11%)]\tLoss: 0.435758\n",
      "Train Epoch: 2 [2000/9140 (22%)]\tLoss: 0.593616\n",
      "Train Epoch: 2 [3000/9140 (33%)]\tLoss: 0.408117\n",
      "Train Epoch: 2 [4000/9140 (43%)]\tLoss: 0.277418\n",
      "Train Epoch: 2 [5000/9140 (54%)]\tLoss: 0.395290\n",
      "Train Epoch: 2 [6000/9140 (65%)]\tLoss: 0.386279\n",
      "Train Epoch: 2 [7000/9140 (76%)]\tLoss: 0.341919\n",
      "Train Epoch: 2 [8000/9140 (87%)]\tLoss: 0.339772\n",
      "Train Epoch: 2 [9000/9140 (98%)]\tLoss: 0.472988\n",
      "Train Epoch: 3 [0/9140 (0%)]\tLoss: 0.476202\n",
      "Train Epoch: 3 [1000/9140 (11%)]\tLoss: 0.470901\n",
      "Train Epoch: 3 [2000/9140 (22%)]\tLoss: 0.254167\n",
      "Train Epoch: 3 [3000/9140 (33%)]\tLoss: 0.361983\n",
      "Train Epoch: 3 [4000/9140 (43%)]\tLoss: 0.339505\n",
      "Train Epoch: 3 [5000/9140 (54%)]\tLoss: 0.488910\n",
      "Train Epoch: 3 [6000/9140 (65%)]\tLoss: 0.296177\n",
      "Train Epoch: 3 [7000/9140 (76%)]\tLoss: 0.221403\n",
      "Train Epoch: 3 [8000/9140 (87%)]\tLoss: 0.345444\n",
      "Train Epoch: 3 [9000/9140 (98%)]\tLoss: 0.336846\n",
      "Train Epoch: 4 [0/9140 (0%)]\tLoss: 0.382197\n",
      "Train Epoch: 4 [1000/9140 (11%)]\tLoss: 0.398283\n",
      "Train Epoch: 4 [2000/9140 (22%)]\tLoss: 0.333219\n",
      "Train Epoch: 4 [3000/9140 (33%)]\tLoss: 0.398133\n",
      "Train Epoch: 4 [4000/9140 (43%)]\tLoss: 0.411100\n",
      "Train Epoch: 4 [5000/9140 (54%)]\tLoss: 0.292983\n",
      "Train Epoch: 4 [6000/9140 (65%)]\tLoss: 0.326741\n",
      "Train Epoch: 4 [7000/9140 (76%)]\tLoss: 0.431455\n",
      "Train Epoch: 4 [8000/9140 (87%)]\tLoss: 0.296839\n",
      "Train Epoch: 4 [9000/9140 (98%)]\tLoss: 0.382241\n",
      "Train Epoch: 5 [0/9140 (0%)]\tLoss: 0.560260\n",
      "Train Epoch: 5 [1000/9140 (11%)]\tLoss: 0.288979\n",
      "Train Epoch: 5 [2000/9140 (22%)]\tLoss: 0.406105\n",
      "Train Epoch: 5 [3000/9140 (33%)]\tLoss: 0.332801\n",
      "Train Epoch: 5 [4000/9140 (43%)]\tLoss: 0.276132\n",
      "Train Epoch: 5 [5000/9140 (54%)]\tLoss: 0.243734\n",
      "Train Epoch: 5 [6000/9140 (65%)]\tLoss: 0.315959\n",
      "Train Epoch: 5 [7000/9140 (76%)]\tLoss: 0.329757\n",
      "Train Epoch: 5 [8000/9140 (87%)]\tLoss: 0.378538\n",
      "Train Epoch: 5 [9000/9140 (98%)]\tLoss: 0.421506\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/14160 (0%)]\tLoss: 0.352891\n",
      "Train Epoch: 1 [1000/14160 (7%)]\tLoss: 0.302775\n",
      "Train Epoch: 1 [2000/14160 (14%)]\tLoss: 0.203311\n",
      "Train Epoch: 1 [3000/14160 (21%)]\tLoss: 0.426448\n",
      "Train Epoch: 1 [4000/14160 (28%)]\tLoss: 0.194460\n",
      "Train Epoch: 1 [5000/14160 (35%)]\tLoss: 0.398806\n",
      "Train Epoch: 1 [6000/14160 (42%)]\tLoss: 0.338264\n",
      "Train Epoch: 1 [7000/14160 (49%)]\tLoss: 0.194396\n",
      "Train Epoch: 1 [8000/14160 (56%)]\tLoss: 0.418976\n",
      "Train Epoch: 1 [9000/14160 (63%)]\tLoss: 0.248330\n",
      "Train Epoch: 1 [10000/14160 (70%)]\tLoss: 0.364003\n",
      "Train Epoch: 1 [11000/14160 (77%)]\tLoss: 0.430220\n",
      "Train Epoch: 1 [12000/14160 (85%)]\tLoss: 0.331204\n",
      "Train Epoch: 1 [13000/14160 (92%)]\tLoss: 0.359761\n",
      "Train Epoch: 1 [14000/14160 (99%)]\tLoss: 0.185247\n",
      "Train Epoch: 2 [0/14160 (0%)]\tLoss: 0.176018\n",
      "Train Epoch: 2 [1000/14160 (7%)]\tLoss: 0.300157\n",
      "Train Epoch: 2 [2000/14160 (14%)]\tLoss: 0.330708\n",
      "Train Epoch: 2 [3000/14160 (21%)]\tLoss: 0.237550\n",
      "Train Epoch: 2 [4000/14160 (28%)]\tLoss: 0.198883\n",
      "Train Epoch: 2 [5000/14160 (35%)]\tLoss: 0.407098\n",
      "Train Epoch: 2 [6000/14160 (42%)]\tLoss: 0.185910\n",
      "Train Epoch: 2 [7000/14160 (49%)]\tLoss: 0.241138\n",
      "Train Epoch: 2 [8000/14160 (56%)]\tLoss: 0.255854\n",
      "Train Epoch: 2 [9000/14160 (63%)]\tLoss: 0.219760\n",
      "Train Epoch: 2 [10000/14160 (70%)]\tLoss: 0.202806\n",
      "Train Epoch: 2 [11000/14160 (77%)]\tLoss: 0.243450\n",
      "Train Epoch: 2 [12000/14160 (85%)]\tLoss: 0.234885\n",
      "Train Epoch: 2 [13000/14160 (92%)]\tLoss: 0.295139\n",
      "Train Epoch: 2 [14000/14160 (99%)]\tLoss: 0.267485\n",
      "Train Epoch: 3 [0/14160 (0%)]\tLoss: 0.245564\n",
      "Train Epoch: 3 [1000/14160 (7%)]\tLoss: 0.259356\n",
      "Train Epoch: 3 [2000/14160 (14%)]\tLoss: 0.338408\n",
      "Train Epoch: 3 [3000/14160 (21%)]\tLoss: 0.148051\n",
      "Train Epoch: 3 [4000/14160 (28%)]\tLoss: 0.190578\n",
      "Train Epoch: 3 [5000/14160 (35%)]\tLoss: 0.137189\n",
      "Train Epoch: 3 [6000/14160 (42%)]\tLoss: 0.335142\n",
      "Train Epoch: 3 [7000/14160 (49%)]\tLoss: 0.236311\n",
      "Train Epoch: 3 [8000/14160 (56%)]\tLoss: 0.227796\n",
      "Train Epoch: 3 [9000/14160 (63%)]\tLoss: 0.325973\n",
      "Train Epoch: 3 [10000/14160 (70%)]\tLoss: 0.417922\n",
      "Train Epoch: 3 [11000/14160 (77%)]\tLoss: 0.144486\n",
      "Train Epoch: 3 [12000/14160 (85%)]\tLoss: 0.409596\n",
      "Train Epoch: 3 [13000/14160 (92%)]\tLoss: 0.242382\n",
      "Train Epoch: 3 [14000/14160 (99%)]\tLoss: 0.213931\n",
      "Train Epoch: 4 [0/14160 (0%)]\tLoss: 0.287375\n",
      "Train Epoch: 4 [1000/14160 (7%)]\tLoss: 0.251373\n",
      "Train Epoch: 4 [2000/14160 (14%)]\tLoss: 0.290868\n",
      "Train Epoch: 4 [3000/14160 (21%)]\tLoss: 0.343833\n",
      "Train Epoch: 4 [4000/14160 (28%)]\tLoss: 0.148408\n",
      "Train Epoch: 4 [5000/14160 (35%)]\tLoss: 0.243006\n",
      "Train Epoch: 4 [6000/14160 (42%)]\tLoss: 0.177680\n",
      "Train Epoch: 4 [7000/14160 (49%)]\tLoss: 0.280620\n",
      "Train Epoch: 4 [8000/14160 (56%)]\tLoss: 0.421770\n",
      "Train Epoch: 4 [9000/14160 (63%)]\tLoss: 0.283261\n",
      "Train Epoch: 4 [10000/14160 (70%)]\tLoss: 0.311329\n",
      "Train Epoch: 4 [11000/14160 (77%)]\tLoss: 0.348112\n",
      "Train Epoch: 4 [12000/14160 (85%)]\tLoss: 0.226063\n",
      "Train Epoch: 4 [13000/14160 (92%)]\tLoss: 0.134722\n",
      "Train Epoch: 4 [14000/14160 (99%)]\tLoss: 0.172477\n",
      "Train Epoch: 5 [0/14160 (0%)]\tLoss: 0.316629\n",
      "Train Epoch: 5 [1000/14160 (7%)]\tLoss: 0.433632\n",
      "Train Epoch: 5 [2000/14160 (14%)]\tLoss: 0.264050\n",
      "Train Epoch: 5 [3000/14160 (21%)]\tLoss: 0.267815\n",
      "Train Epoch: 5 [4000/14160 (28%)]\tLoss: 0.140231\n",
      "Train Epoch: 5 [5000/14160 (35%)]\tLoss: 0.241643\n",
      "Train Epoch: 5 [6000/14160 (42%)]\tLoss: 0.146033\n",
      "Train Epoch: 5 [7000/14160 (49%)]\tLoss: 0.283072\n",
      "Train Epoch: 5 [8000/14160 (56%)]\tLoss: 0.357386\n",
      "Train Epoch: 5 [9000/14160 (63%)]\tLoss: 0.292970\n",
      "Train Epoch: 5 [10000/14160 (70%)]\tLoss: 0.159159\n",
      "Train Epoch: 5 [11000/14160 (77%)]\tLoss: 0.203353\n",
      "Train Epoch: 5 [12000/14160 (85%)]\tLoss: 0.217870\n",
      "Train Epoch: 5 [13000/14160 (92%)]\tLoss: 0.326445\n",
      "Train Epoch: 5 [14000/14160 (99%)]\tLoss: 0.109233\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/16239 (0%)]\tLoss: 0.613724\n",
      "Train Epoch: 1 [1000/16239 (6%)]\tLoss: 0.405449\n",
      "Train Epoch: 1 [2000/16239 (12%)]\tLoss: 0.512460\n",
      "Train Epoch: 1 [3000/16239 (18%)]\tLoss: 0.313343\n",
      "Train Epoch: 1 [4000/16239 (25%)]\tLoss: 0.396044\n",
      "Train Epoch: 1 [5000/16239 (31%)]\tLoss: 0.263045\n",
      "Train Epoch: 1 [6000/16239 (37%)]\tLoss: 0.243034\n",
      "Train Epoch: 1 [7000/16239 (43%)]\tLoss: 0.257142\n",
      "Train Epoch: 1 [8000/16239 (49%)]\tLoss: 0.302656\n",
      "Train Epoch: 1 [9000/16239 (55%)]\tLoss: 0.393108\n",
      "Train Epoch: 1 [10000/16239 (61%)]\tLoss: 0.272283\n",
      "Train Epoch: 1 [11000/16239 (67%)]\tLoss: 0.531259\n",
      "Train Epoch: 1 [12000/16239 (74%)]\tLoss: 0.417400\n",
      "Train Epoch: 1 [13000/16239 (80%)]\tLoss: 0.430717\n",
      "Train Epoch: 1 [14000/16239 (86%)]\tLoss: 0.407777\n",
      "Train Epoch: 1 [15000/16239 (92%)]\tLoss: 0.494978\n",
      "Train Epoch: 1 [16000/16239 (98%)]\tLoss: 0.347883\n",
      "Train Epoch: 2 [0/16239 (0%)]\tLoss: 0.272045\n",
      "Train Epoch: 2 [1000/16239 (6%)]\tLoss: 0.405270\n",
      "Train Epoch: 2 [2000/16239 (12%)]\tLoss: 0.384949\n",
      "Train Epoch: 2 [3000/16239 (18%)]\tLoss: 0.340940\n",
      "Train Epoch: 2 [4000/16239 (25%)]\tLoss: 0.436449\n",
      "Train Epoch: 2 [5000/16239 (31%)]\tLoss: 0.277400\n",
      "Train Epoch: 2 [6000/16239 (37%)]\tLoss: 0.254585\n",
      "Train Epoch: 2 [7000/16239 (43%)]\tLoss: 0.415384\n",
      "Train Epoch: 2 [8000/16239 (49%)]\tLoss: 0.328647\n",
      "Train Epoch: 2 [9000/16239 (55%)]\tLoss: 0.419930\n",
      "Train Epoch: 2 [10000/16239 (61%)]\tLoss: 0.457010\n",
      "Train Epoch: 2 [11000/16239 (67%)]\tLoss: 0.436540\n",
      "Train Epoch: 2 [12000/16239 (74%)]\tLoss: 0.381319\n",
      "Train Epoch: 2 [13000/16239 (80%)]\tLoss: 0.514789\n",
      "Train Epoch: 2 [14000/16239 (86%)]\tLoss: 0.299194\n",
      "Train Epoch: 2 [15000/16239 (92%)]\tLoss: 0.406742\n",
      "Train Epoch: 2 [16000/16239 (98%)]\tLoss: 0.395894\n",
      "Train Epoch: 3 [0/16239 (0%)]\tLoss: 0.403367\n",
      "Train Epoch: 3 [1000/16239 (6%)]\tLoss: 0.472771\n",
      "Train Epoch: 3 [2000/16239 (12%)]\tLoss: 0.292236\n",
      "Train Epoch: 3 [3000/16239 (18%)]\tLoss: 0.377301\n",
      "Train Epoch: 3 [4000/16239 (25%)]\tLoss: 0.332309\n",
      "Train Epoch: 3 [5000/16239 (31%)]\tLoss: 0.507739\n",
      "Train Epoch: 3 [6000/16239 (37%)]\tLoss: 0.252588\n",
      "Train Epoch: 3 [7000/16239 (43%)]\tLoss: 0.429388\n",
      "Train Epoch: 3 [8000/16239 (49%)]\tLoss: 0.480347\n",
      "Train Epoch: 3 [9000/16239 (55%)]\tLoss: 0.320119\n",
      "Train Epoch: 3 [10000/16239 (61%)]\tLoss: 0.322231\n",
      "Train Epoch: 3 [11000/16239 (67%)]\tLoss: 0.527529\n",
      "Train Epoch: 3 [12000/16239 (74%)]\tLoss: 0.368588\n",
      "Train Epoch: 3 [13000/16239 (80%)]\tLoss: 0.438142\n",
      "Train Epoch: 3 [14000/16239 (86%)]\tLoss: 0.339696\n",
      "Train Epoch: 3 [15000/16239 (92%)]\tLoss: 0.420823\n",
      "Train Epoch: 3 [16000/16239 (98%)]\tLoss: 0.367659\n",
      "Train Epoch: 4 [0/16239 (0%)]\tLoss: 0.383715\n",
      "Train Epoch: 4 [1000/16239 (6%)]\tLoss: 0.307536\n",
      "Train Epoch: 4 [2000/16239 (12%)]\tLoss: 0.395272\n",
      "Train Epoch: 4 [3000/16239 (18%)]\tLoss: 0.407261\n",
      "Train Epoch: 4 [4000/16239 (25%)]\tLoss: 0.318111\n",
      "Train Epoch: 4 [5000/16239 (31%)]\tLoss: 0.458443\n",
      "Train Epoch: 4 [6000/16239 (37%)]\tLoss: 0.295951\n",
      "Train Epoch: 4 [7000/16239 (43%)]\tLoss: 0.324778\n",
      "Train Epoch: 4 [8000/16239 (49%)]\tLoss: 0.290772\n",
      "Train Epoch: 4 [9000/16239 (55%)]\tLoss: 0.434637\n",
      "Train Epoch: 4 [10000/16239 (61%)]\tLoss: 0.419065\n",
      "Train Epoch: 4 [11000/16239 (67%)]\tLoss: 0.522231\n",
      "Train Epoch: 4 [12000/16239 (74%)]\tLoss: 0.507307\n",
      "Train Epoch: 4 [13000/16239 (80%)]\tLoss: 0.285671\n",
      "Train Epoch: 4 [14000/16239 (86%)]\tLoss: 0.519451\n",
      "Train Epoch: 4 [15000/16239 (92%)]\tLoss: 0.238771\n",
      "Train Epoch: 4 [16000/16239 (98%)]\tLoss: 0.384714\n",
      "Train Epoch: 5 [0/16239 (0%)]\tLoss: 0.337197\n",
      "Train Epoch: 5 [1000/16239 (6%)]\tLoss: 0.483521\n",
      "Train Epoch: 5 [2000/16239 (12%)]\tLoss: 0.412713\n",
      "Train Epoch: 5 [3000/16239 (18%)]\tLoss: 0.535168\n",
      "Train Epoch: 5 [4000/16239 (25%)]\tLoss: 0.409273\n",
      "Train Epoch: 5 [5000/16239 (31%)]\tLoss: 0.416661\n",
      "Train Epoch: 5 [6000/16239 (37%)]\tLoss: 0.410816\n",
      "Train Epoch: 5 [7000/16239 (43%)]\tLoss: 0.554294\n",
      "Train Epoch: 5 [8000/16239 (49%)]\tLoss: 0.169587\n",
      "Train Epoch: 5 [9000/16239 (55%)]\tLoss: 0.403666\n",
      "Train Epoch: 5 [10000/16239 (61%)]\tLoss: 0.422651\n",
      "Train Epoch: 5 [11000/16239 (67%)]\tLoss: 0.362372\n",
      "Train Epoch: 5 [12000/16239 (74%)]\tLoss: 0.365389\n",
      "Train Epoch: 5 [13000/16239 (80%)]\tLoss: 0.256217\n",
      "Train Epoch: 5 [14000/16239 (86%)]\tLoss: 0.521674\n",
      "Train Epoch: 5 [15000/16239 (92%)]\tLoss: 0.399553\n",
      "Train Epoch: 5 [16000/16239 (98%)]\tLoss: 0.351936\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.391960\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.294532\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.202865\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.227099\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.345066\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.289881\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.384567\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.261288\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.255255\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.222269\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.266741\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.146103\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.153684\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.326019\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.232148\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.222245\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.288354\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.332382\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.272084\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.226374\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.235483\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.206541\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.304107\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.346585\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.295519\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.176298\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.231945\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.205437\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.188271\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.242809\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/11596 (0%)]\tLoss: 0.400633\n",
      "Train Epoch: 1 [1000/11596 (9%)]\tLoss: 0.397053\n",
      "Train Epoch: 1 [2000/11596 (17%)]\tLoss: 0.401331\n",
      "Train Epoch: 1 [3000/11596 (26%)]\tLoss: 0.310392\n",
      "Train Epoch: 1 [4000/11596 (34%)]\tLoss: 0.214762\n",
      "Train Epoch: 1 [5000/11596 (43%)]\tLoss: 0.247065\n",
      "Train Epoch: 1 [6000/11596 (52%)]\tLoss: 0.318215\n",
      "Train Epoch: 1 [7000/11596 (60%)]\tLoss: 0.393924\n",
      "Train Epoch: 1 [8000/11596 (69%)]\tLoss: 0.359754\n",
      "Train Epoch: 1 [9000/11596 (78%)]\tLoss: 0.311497\n",
      "Train Epoch: 1 [10000/11596 (86%)]\tLoss: 0.256755\n",
      "Train Epoch: 1 [11000/11596 (95%)]\tLoss: 0.382307\n",
      "Train Epoch: 2 [0/11596 (0%)]\tLoss: 0.223116\n",
      "Train Epoch: 2 [1000/11596 (9%)]\tLoss: 0.300665\n",
      "Train Epoch: 2 [2000/11596 (17%)]\tLoss: 0.313253\n",
      "Train Epoch: 2 [3000/11596 (26%)]\tLoss: 0.573212\n",
      "Train Epoch: 2 [4000/11596 (34%)]\tLoss: 0.306919\n",
      "Train Epoch: 2 [5000/11596 (43%)]\tLoss: 0.260079\n",
      "Train Epoch: 2 [6000/11596 (52%)]\tLoss: 0.292618\n",
      "Train Epoch: 2 [7000/11596 (60%)]\tLoss: 0.423936\n",
      "Train Epoch: 2 [8000/11596 (69%)]\tLoss: 0.383788\n",
      "Train Epoch: 2 [9000/11596 (78%)]\tLoss: 0.353278\n",
      "Train Epoch: 2 [10000/11596 (86%)]\tLoss: 0.252880\n",
      "Train Epoch: 2 [11000/11596 (95%)]\tLoss: 0.408929\n",
      "Train Epoch: 3 [0/11596 (0%)]\tLoss: 0.277137\n",
      "Train Epoch: 3 [1000/11596 (9%)]\tLoss: 0.313700\n",
      "Train Epoch: 3 [2000/11596 (17%)]\tLoss: 0.425589\n",
      "Train Epoch: 3 [3000/11596 (26%)]\tLoss: 0.301623\n",
      "Train Epoch: 3 [4000/11596 (34%)]\tLoss: 0.357846\n",
      "Train Epoch: 3 [5000/11596 (43%)]\tLoss: 0.302967\n",
      "Train Epoch: 3 [6000/11596 (52%)]\tLoss: 0.342233\n",
      "Train Epoch: 3 [7000/11596 (60%)]\tLoss: 0.227753\n",
      "Train Epoch: 3 [8000/11596 (69%)]\tLoss: 0.336416\n",
      "Train Epoch: 3 [9000/11596 (78%)]\tLoss: 0.304992\n",
      "Train Epoch: 3 [10000/11596 (86%)]\tLoss: 0.249659\n",
      "Train Epoch: 3 [11000/11596 (95%)]\tLoss: 0.327362\n",
      "Train Epoch: 4 [0/11596 (0%)]\tLoss: 0.299228\n",
      "Train Epoch: 4 [1000/11596 (9%)]\tLoss: 0.355802\n",
      "Train Epoch: 4 [2000/11596 (17%)]\tLoss: 0.345810\n",
      "Train Epoch: 4 [3000/11596 (26%)]\tLoss: 0.331730\n",
      "Train Epoch: 4 [4000/11596 (34%)]\tLoss: 0.421850\n",
      "Train Epoch: 4 [5000/11596 (43%)]\tLoss: 0.398824\n",
      "Train Epoch: 4 [6000/11596 (52%)]\tLoss: 0.397026\n",
      "Train Epoch: 4 [7000/11596 (60%)]\tLoss: 0.265509\n",
      "Train Epoch: 4 [8000/11596 (69%)]\tLoss: 0.493053\n",
      "Train Epoch: 4 [9000/11596 (78%)]\tLoss: 0.203984\n",
      "Train Epoch: 4 [10000/11596 (86%)]\tLoss: 0.228947\n",
      "Train Epoch: 4 [11000/11596 (95%)]\tLoss: 0.249648\n",
      "Train Epoch: 5 [0/11596 (0%)]\tLoss: 0.404550\n",
      "Train Epoch: 5 [1000/11596 (9%)]\tLoss: 0.274763\n",
      "Train Epoch: 5 [2000/11596 (17%)]\tLoss: 0.319901\n",
      "Train Epoch: 5 [3000/11596 (26%)]\tLoss: 0.348851\n",
      "Train Epoch: 5 [4000/11596 (34%)]\tLoss: 0.235317\n",
      "Train Epoch: 5 [5000/11596 (43%)]\tLoss: 0.308195\n",
      "Train Epoch: 5 [6000/11596 (52%)]\tLoss: 0.174050\n",
      "Train Epoch: 5 [7000/11596 (60%)]\tLoss: 0.406686\n",
      "Train Epoch: 5 [8000/11596 (69%)]\tLoss: 0.378290\n",
      "Train Epoch: 5 [9000/11596 (78%)]\tLoss: 0.200395\n",
      "Train Epoch: 5 [10000/11596 (86%)]\tLoss: 0.180216\n",
      "Train Epoch: 5 [11000/11596 (95%)]\tLoss: 0.336307\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.308805\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.283235\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.307253\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.390154\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.329529\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.351710\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.443340\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.223809\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.396709\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.279884\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.232714\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.300756\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.314045\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.254908\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.288492\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.354541\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.255216\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.229647\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.261831\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.260838\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8652, Accuracy: 7676/10000 (77%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/9140 (0%)]\tLoss: 0.429445\n",
      "Train Epoch: 1 [1000/9140 (11%)]\tLoss: 0.402399\n",
      "Train Epoch: 1 [2000/9140 (22%)]\tLoss: 0.404643\n",
      "Train Epoch: 1 [3000/9140 (33%)]\tLoss: 0.440801\n",
      "Train Epoch: 1 [4000/9140 (43%)]\tLoss: 0.362506\n",
      "Train Epoch: 1 [5000/9140 (54%)]\tLoss: 0.290924\n",
      "Train Epoch: 1 [6000/9140 (65%)]\tLoss: 0.376171\n",
      "Train Epoch: 1 [7000/9140 (76%)]\tLoss: 0.330383\n",
      "Train Epoch: 1 [8000/9140 (87%)]\tLoss: 0.513329\n",
      "Train Epoch: 1 [9000/9140 (98%)]\tLoss: 0.409139\n",
      "Train Epoch: 2 [0/9140 (0%)]\tLoss: 0.414608\n",
      "Train Epoch: 2 [1000/9140 (11%)]\tLoss: 0.271527\n",
      "Train Epoch: 2 [2000/9140 (22%)]\tLoss: 0.416502\n",
      "Train Epoch: 2 [3000/9140 (33%)]\tLoss: 0.406937\n",
      "Train Epoch: 2 [4000/9140 (43%)]\tLoss: 0.371218\n",
      "Train Epoch: 2 [5000/9140 (54%)]\tLoss: 0.368761\n",
      "Train Epoch: 2 [6000/9140 (65%)]\tLoss: 0.273654\n",
      "Train Epoch: 2 [7000/9140 (76%)]\tLoss: 0.284130\n",
      "Train Epoch: 2 [8000/9140 (87%)]\tLoss: 0.322010\n",
      "Train Epoch: 2 [9000/9140 (98%)]\tLoss: 0.287275\n",
      "Train Epoch: 3 [0/9140 (0%)]\tLoss: 0.490169\n",
      "Train Epoch: 3 [1000/9140 (11%)]\tLoss: 0.250120\n",
      "Train Epoch: 3 [2000/9140 (22%)]\tLoss: 0.277636\n",
      "Train Epoch: 3 [3000/9140 (33%)]\tLoss: 0.360186\n",
      "Train Epoch: 3 [4000/9140 (43%)]\tLoss: 0.445644\n",
      "Train Epoch: 3 [5000/9140 (54%)]\tLoss: 0.357067\n",
      "Train Epoch: 3 [6000/9140 (65%)]\tLoss: 0.284424\n",
      "Train Epoch: 3 [7000/9140 (76%)]\tLoss: 0.449783\n",
      "Train Epoch: 3 [8000/9140 (87%)]\tLoss: 0.302335\n",
      "Train Epoch: 3 [9000/9140 (98%)]\tLoss: 0.278599\n",
      "Train Epoch: 4 [0/9140 (0%)]\tLoss: 0.372789\n",
      "Train Epoch: 4 [1000/9140 (11%)]\tLoss: 0.325478\n",
      "Train Epoch: 4 [2000/9140 (22%)]\tLoss: 0.425162\n",
      "Train Epoch: 4 [3000/9140 (33%)]\tLoss: 0.362766\n",
      "Train Epoch: 4 [4000/9140 (43%)]\tLoss: 0.338165\n",
      "Train Epoch: 4 [5000/9140 (54%)]\tLoss: 0.436131\n",
      "Train Epoch: 4 [6000/9140 (65%)]\tLoss: 0.405961\n",
      "Train Epoch: 4 [7000/9140 (76%)]\tLoss: 0.451871\n",
      "Train Epoch: 4 [8000/9140 (87%)]\tLoss: 0.360118\n",
      "Train Epoch: 4 [9000/9140 (98%)]\tLoss: 0.402809\n",
      "Train Epoch: 5 [0/9140 (0%)]\tLoss: 0.329659\n",
      "Train Epoch: 5 [1000/9140 (11%)]\tLoss: 0.340433\n",
      "Train Epoch: 5 [2000/9140 (22%)]\tLoss: 0.409900\n",
      "Train Epoch: 5 [3000/9140 (33%)]\tLoss: 0.341352\n",
      "Train Epoch: 5 [4000/9140 (43%)]\tLoss: 0.427181\n",
      "Train Epoch: 5 [5000/9140 (54%)]\tLoss: 0.312014\n",
      "Train Epoch: 5 [6000/9140 (65%)]\tLoss: 0.351437\n",
      "Train Epoch: 5 [7000/9140 (76%)]\tLoss: 0.513810\n",
      "Train Epoch: 5 [8000/9140 (87%)]\tLoss: 0.283312\n",
      "Train Epoch: 5 [9000/9140 (98%)]\tLoss: 0.278957\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/14160 (0%)]\tLoss: 0.450370\n",
      "Train Epoch: 1 [1000/14160 (7%)]\tLoss: 0.226734\n",
      "Train Epoch: 1 [2000/14160 (14%)]\tLoss: 0.277275\n",
      "Train Epoch: 1 [3000/14160 (21%)]\tLoss: 0.331369\n",
      "Train Epoch: 1 [4000/14160 (28%)]\tLoss: 0.239149\n",
      "Train Epoch: 1 [5000/14160 (35%)]\tLoss: 0.297855\n",
      "Train Epoch: 1 [6000/14160 (42%)]\tLoss: 0.356176\n",
      "Train Epoch: 1 [7000/14160 (49%)]\tLoss: 0.292781\n",
      "Train Epoch: 1 [8000/14160 (56%)]\tLoss: 0.282329\n",
      "Train Epoch: 1 [9000/14160 (63%)]\tLoss: 0.189394\n",
      "Train Epoch: 1 [10000/14160 (70%)]\tLoss: 0.223422\n",
      "Train Epoch: 1 [11000/14160 (77%)]\tLoss: 0.264194\n",
      "Train Epoch: 1 [12000/14160 (85%)]\tLoss: 0.150724\n",
      "Train Epoch: 1 [13000/14160 (92%)]\tLoss: 0.223321\n",
      "Train Epoch: 1 [14000/14160 (99%)]\tLoss: 0.208312\n",
      "Train Epoch: 2 [0/14160 (0%)]\tLoss: 0.341036\n",
      "Train Epoch: 2 [1000/14160 (7%)]\tLoss: 0.172628\n",
      "Train Epoch: 2 [2000/14160 (14%)]\tLoss: 0.211753\n",
      "Train Epoch: 2 [3000/14160 (21%)]\tLoss: 0.273396\n",
      "Train Epoch: 2 [4000/14160 (28%)]\tLoss: 0.200897\n",
      "Train Epoch: 2 [5000/14160 (35%)]\tLoss: 0.235082\n",
      "Train Epoch: 2 [6000/14160 (42%)]\tLoss: 0.179322\n",
      "Train Epoch: 2 [7000/14160 (49%)]\tLoss: 0.341303\n",
      "Train Epoch: 2 [8000/14160 (56%)]\tLoss: 0.306602\n",
      "Train Epoch: 2 [9000/14160 (63%)]\tLoss: 0.281820\n",
      "Train Epoch: 2 [10000/14160 (70%)]\tLoss: 0.361008\n",
      "Train Epoch: 2 [11000/14160 (77%)]\tLoss: 0.303766\n",
      "Train Epoch: 2 [12000/14160 (85%)]\tLoss: 0.195996\n",
      "Train Epoch: 2 [13000/14160 (92%)]\tLoss: 0.281091\n",
      "Train Epoch: 2 [14000/14160 (99%)]\tLoss: 0.187146\n",
      "Train Epoch: 3 [0/14160 (0%)]\tLoss: 0.328815\n",
      "Train Epoch: 3 [1000/14160 (7%)]\tLoss: 0.263718\n",
      "Train Epoch: 3 [2000/14160 (14%)]\tLoss: 0.154384\n",
      "Train Epoch: 3 [3000/14160 (21%)]\tLoss: 0.283461\n",
      "Train Epoch: 3 [4000/14160 (28%)]\tLoss: 0.352168\n",
      "Train Epoch: 3 [5000/14160 (35%)]\tLoss: 0.329852\n",
      "Train Epoch: 3 [6000/14160 (42%)]\tLoss: 0.216780\n",
      "Train Epoch: 3 [7000/14160 (49%)]\tLoss: 0.350076\n",
      "Train Epoch: 3 [8000/14160 (56%)]\tLoss: 0.282638\n",
      "Train Epoch: 3 [9000/14160 (63%)]\tLoss: 0.227061\n",
      "Train Epoch: 3 [10000/14160 (70%)]\tLoss: 0.248074\n",
      "Train Epoch: 3 [11000/14160 (77%)]\tLoss: 0.184643\n",
      "Train Epoch: 3 [12000/14160 (85%)]\tLoss: 0.170489\n",
      "Train Epoch: 3 [13000/14160 (92%)]\tLoss: 0.298644\n",
      "Train Epoch: 3 [14000/14160 (99%)]\tLoss: 0.225602\n",
      "Train Epoch: 4 [0/14160 (0%)]\tLoss: 0.291918\n",
      "Train Epoch: 4 [1000/14160 (7%)]\tLoss: 0.307931\n",
      "Train Epoch: 4 [2000/14160 (14%)]\tLoss: 0.343319\n",
      "Train Epoch: 4 [3000/14160 (21%)]\tLoss: 0.198381\n",
      "Train Epoch: 4 [4000/14160 (28%)]\tLoss: 0.331264\n",
      "Train Epoch: 4 [5000/14160 (35%)]\tLoss: 0.257055\n",
      "Train Epoch: 4 [6000/14160 (42%)]\tLoss: 0.233699\n",
      "Train Epoch: 4 [7000/14160 (49%)]\tLoss: 0.281610\n",
      "Train Epoch: 4 [8000/14160 (56%)]\tLoss: 0.288272\n",
      "Train Epoch: 4 [9000/14160 (63%)]\tLoss: 0.169332\n",
      "Train Epoch: 4 [10000/14160 (70%)]\tLoss: 0.249169\n",
      "Train Epoch: 4 [11000/14160 (77%)]\tLoss: 0.213392\n",
      "Train Epoch: 4 [12000/14160 (85%)]\tLoss: 0.232814\n",
      "Train Epoch: 4 [13000/14160 (92%)]\tLoss: 0.184618\n",
      "Train Epoch: 4 [14000/14160 (99%)]\tLoss: 0.359363\n",
      "Train Epoch: 5 [0/14160 (0%)]\tLoss: 0.196215\n",
      "Train Epoch: 5 [1000/14160 (7%)]\tLoss: 0.311272\n",
      "Train Epoch: 5 [2000/14160 (14%)]\tLoss: 0.210096\n",
      "Train Epoch: 5 [3000/14160 (21%)]\tLoss: 0.205450\n",
      "Train Epoch: 5 [4000/14160 (28%)]\tLoss: 0.281665\n",
      "Train Epoch: 5 [5000/14160 (35%)]\tLoss: 0.313962\n",
      "Train Epoch: 5 [6000/14160 (42%)]\tLoss: 0.291768\n",
      "Train Epoch: 5 [7000/14160 (49%)]\tLoss: 0.276356\n",
      "Train Epoch: 5 [8000/14160 (56%)]\tLoss: 0.323132\n",
      "Train Epoch: 5 [9000/14160 (63%)]\tLoss: 0.298696\n",
      "Train Epoch: 5 [10000/14160 (70%)]\tLoss: 0.230193\n",
      "Train Epoch: 5 [11000/14160 (77%)]\tLoss: 0.226073\n",
      "Train Epoch: 5 [12000/14160 (85%)]\tLoss: 0.247137\n",
      "Train Epoch: 5 [13000/14160 (92%)]\tLoss: 0.182883\n",
      "Train Epoch: 5 [14000/14160 (99%)]\tLoss: 0.208394\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/16239 (0%)]\tLoss: 0.514072\n",
      "Train Epoch: 1 [1000/16239 (6%)]\tLoss: 0.388024\n",
      "Train Epoch: 1 [2000/16239 (12%)]\tLoss: 0.343485\n",
      "Train Epoch: 1 [3000/16239 (18%)]\tLoss: 0.442321\n",
      "Train Epoch: 1 [4000/16239 (25%)]\tLoss: 0.322953\n",
      "Train Epoch: 1 [5000/16239 (31%)]\tLoss: 0.436924\n",
      "Train Epoch: 1 [6000/16239 (37%)]\tLoss: 0.273303\n",
      "Train Epoch: 1 [7000/16239 (43%)]\tLoss: 0.329891\n",
      "Train Epoch: 1 [8000/16239 (49%)]\tLoss: 0.313550\n",
      "Train Epoch: 1 [9000/16239 (55%)]\tLoss: 0.281017\n",
      "Train Epoch: 1 [10000/16239 (61%)]\tLoss: 0.403786\n",
      "Train Epoch: 1 [11000/16239 (67%)]\tLoss: 0.364220\n",
      "Train Epoch: 1 [12000/16239 (74%)]\tLoss: 0.425516\n",
      "Train Epoch: 1 [13000/16239 (80%)]\tLoss: 0.318937\n",
      "Train Epoch: 1 [14000/16239 (86%)]\tLoss: 0.575251\n",
      "Train Epoch: 1 [15000/16239 (92%)]\tLoss: 0.350408\n",
      "Train Epoch: 1 [16000/16239 (98%)]\tLoss: 0.330188\n",
      "Train Epoch: 2 [0/16239 (0%)]\tLoss: 0.251765\n",
      "Train Epoch: 2 [1000/16239 (6%)]\tLoss: 0.411496\n",
      "Train Epoch: 2 [2000/16239 (12%)]\tLoss: 0.217278\n",
      "Train Epoch: 2 [3000/16239 (18%)]\tLoss: 0.296105\n",
      "Train Epoch: 2 [4000/16239 (25%)]\tLoss: 0.368190\n",
      "Train Epoch: 2 [5000/16239 (31%)]\tLoss: 0.344225\n",
      "Train Epoch: 2 [6000/16239 (37%)]\tLoss: 0.273823\n",
      "Train Epoch: 2 [7000/16239 (43%)]\tLoss: 0.303579\n",
      "Train Epoch: 2 [8000/16239 (49%)]\tLoss: 0.287610\n",
      "Train Epoch: 2 [9000/16239 (55%)]\tLoss: 0.316570\n",
      "Train Epoch: 2 [10000/16239 (61%)]\tLoss: 0.343416\n",
      "Train Epoch: 2 [11000/16239 (67%)]\tLoss: 0.374967\n",
      "Train Epoch: 2 [12000/16239 (74%)]\tLoss: 0.363914\n",
      "Train Epoch: 2 [13000/16239 (80%)]\tLoss: 0.340611\n",
      "Train Epoch: 2 [14000/16239 (86%)]\tLoss: 0.277510\n",
      "Train Epoch: 2 [15000/16239 (92%)]\tLoss: 0.279197\n",
      "Train Epoch: 2 [16000/16239 (98%)]\tLoss: 0.284197\n",
      "Train Epoch: 3 [0/16239 (0%)]\tLoss: 0.212482\n",
      "Train Epoch: 3 [1000/16239 (6%)]\tLoss: 0.288243\n",
      "Train Epoch: 3 [2000/16239 (12%)]\tLoss: 0.264198\n",
      "Train Epoch: 3 [3000/16239 (18%)]\tLoss: 0.448257\n",
      "Train Epoch: 3 [4000/16239 (25%)]\tLoss: 0.354963\n",
      "Train Epoch: 3 [5000/16239 (31%)]\tLoss: 0.279055\n",
      "Train Epoch: 3 [6000/16239 (37%)]\tLoss: 0.389718\n",
      "Train Epoch: 3 [7000/16239 (43%)]\tLoss: 0.367762\n",
      "Train Epoch: 3 [8000/16239 (49%)]\tLoss: 0.436567\n",
      "Train Epoch: 3 [9000/16239 (55%)]\tLoss: 0.296094\n",
      "Train Epoch: 3 [10000/16239 (61%)]\tLoss: 0.262743\n",
      "Train Epoch: 3 [11000/16239 (67%)]\tLoss: 0.335089\n",
      "Train Epoch: 3 [12000/16239 (74%)]\tLoss: 0.420425\n",
      "Train Epoch: 3 [13000/16239 (80%)]\tLoss: 0.203216\n",
      "Train Epoch: 3 [14000/16239 (86%)]\tLoss: 0.275671\n",
      "Train Epoch: 3 [15000/16239 (92%)]\tLoss: 0.250272\n",
      "Train Epoch: 3 [16000/16239 (98%)]\tLoss: 0.311450\n",
      "Train Epoch: 4 [0/16239 (0%)]\tLoss: 0.320149\n",
      "Train Epoch: 4 [1000/16239 (6%)]\tLoss: 0.318400\n",
      "Train Epoch: 4 [2000/16239 (12%)]\tLoss: 0.176260\n",
      "Train Epoch: 4 [3000/16239 (18%)]\tLoss: 0.390340\n",
      "Train Epoch: 4 [4000/16239 (25%)]\tLoss: 0.276516\n",
      "Train Epoch: 4 [5000/16239 (31%)]\tLoss: 0.224260\n",
      "Train Epoch: 4 [6000/16239 (37%)]\tLoss: 0.269671\n",
      "Train Epoch: 4 [7000/16239 (43%)]\tLoss: 0.241119\n",
      "Train Epoch: 4 [8000/16239 (49%)]\tLoss: 0.336119\n",
      "Train Epoch: 4 [9000/16239 (55%)]\tLoss: 0.476820\n",
      "Train Epoch: 4 [10000/16239 (61%)]\tLoss: 0.368020\n",
      "Train Epoch: 4 [11000/16239 (67%)]\tLoss: 0.337309\n",
      "Train Epoch: 4 [12000/16239 (74%)]\tLoss: 0.392212\n",
      "Train Epoch: 4 [13000/16239 (80%)]\tLoss: 0.327762\n",
      "Train Epoch: 4 [14000/16239 (86%)]\tLoss: 0.252743\n",
      "Train Epoch: 4 [15000/16239 (92%)]\tLoss: 0.356165\n",
      "Train Epoch: 4 [16000/16239 (98%)]\tLoss: 0.272985\n",
      "Train Epoch: 5 [0/16239 (0%)]\tLoss: 0.312321\n",
      "Train Epoch: 5 [1000/16239 (6%)]\tLoss: 0.305149\n",
      "Train Epoch: 5 [2000/16239 (12%)]\tLoss: 0.316999\n",
      "Train Epoch: 5 [3000/16239 (18%)]\tLoss: 0.262306\n",
      "Train Epoch: 5 [4000/16239 (25%)]\tLoss: 0.297704\n",
      "Train Epoch: 5 [5000/16239 (31%)]\tLoss: 0.394099\n",
      "Train Epoch: 5 [6000/16239 (37%)]\tLoss: 0.174735\n",
      "Train Epoch: 5 [7000/16239 (43%)]\tLoss: 0.314726\n",
      "Train Epoch: 5 [8000/16239 (49%)]\tLoss: 0.257636\n",
      "Train Epoch: 5 [9000/16239 (55%)]\tLoss: 0.428587\n",
      "Train Epoch: 5 [10000/16239 (61%)]\tLoss: 0.275162\n",
      "Train Epoch: 5 [11000/16239 (67%)]\tLoss: 0.272818\n",
      "Train Epoch: 5 [12000/16239 (74%)]\tLoss: 0.439262\n",
      "Train Epoch: 5 [13000/16239 (80%)]\tLoss: 0.409755\n",
      "Train Epoch: 5 [14000/16239 (86%)]\tLoss: 0.410890\n",
      "Train Epoch: 5 [15000/16239 (92%)]\tLoss: 0.291361\n",
      "Train Epoch: 5 [16000/16239 (98%)]\tLoss: 0.307652\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.307305\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.243329\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.239937\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.249854\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.307938\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.192981\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.237567\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.257873\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.288302\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.321964\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.351715\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.178745\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.207726\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.189615\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.219856\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.288179\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.339189\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.301814\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.211705\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.294293\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.211285\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.321440\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.176623\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.343903\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.271679\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.361046\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.306975\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.144781\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.172958\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.201333\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/11596 (0%)]\tLoss: 0.500235\n",
      "Train Epoch: 1 [1000/11596 (9%)]\tLoss: 0.400715\n",
      "Train Epoch: 1 [2000/11596 (17%)]\tLoss: 0.306883\n",
      "Train Epoch: 1 [3000/11596 (26%)]\tLoss: 0.186953\n",
      "Train Epoch: 1 [4000/11596 (34%)]\tLoss: 0.395737\n",
      "Train Epoch: 1 [5000/11596 (43%)]\tLoss: 0.235427\n",
      "Train Epoch: 1 [6000/11596 (52%)]\tLoss: 0.245235\n",
      "Train Epoch: 1 [7000/11596 (60%)]\tLoss: 0.384984\n",
      "Train Epoch: 1 [8000/11596 (69%)]\tLoss: 0.322597\n",
      "Train Epoch: 1 [9000/11596 (78%)]\tLoss: 0.377306\n",
      "Train Epoch: 1 [10000/11596 (86%)]\tLoss: 0.405675\n",
      "Train Epoch: 1 [11000/11596 (95%)]\tLoss: 0.238750\n",
      "Train Epoch: 2 [0/11596 (0%)]\tLoss: 0.216573\n",
      "Train Epoch: 2 [1000/11596 (9%)]\tLoss: 0.303627\n",
      "Train Epoch: 2 [2000/11596 (17%)]\tLoss: 0.413928\n",
      "Train Epoch: 2 [3000/11596 (26%)]\tLoss: 0.352946\n",
      "Train Epoch: 2 [4000/11596 (34%)]\tLoss: 0.298550\n",
      "Train Epoch: 2 [5000/11596 (43%)]\tLoss: 0.277427\n",
      "Train Epoch: 2 [6000/11596 (52%)]\tLoss: 0.242999\n",
      "Train Epoch: 2 [7000/11596 (60%)]\tLoss: 0.256213\n",
      "Train Epoch: 2 [8000/11596 (69%)]\tLoss: 0.382247\n",
      "Train Epoch: 2 [9000/11596 (78%)]\tLoss: 0.315266\n",
      "Train Epoch: 2 [10000/11596 (86%)]\tLoss: 0.385798\n",
      "Train Epoch: 2 [11000/11596 (95%)]\tLoss: 0.417625\n",
      "Train Epoch: 3 [0/11596 (0%)]\tLoss: 0.241953\n",
      "Train Epoch: 3 [1000/11596 (9%)]\tLoss: 0.277586\n",
      "Train Epoch: 3 [2000/11596 (17%)]\tLoss: 0.290326\n",
      "Train Epoch: 3 [3000/11596 (26%)]\tLoss: 0.477998\n",
      "Train Epoch: 3 [4000/11596 (34%)]\tLoss: 0.258340\n",
      "Train Epoch: 3 [5000/11596 (43%)]\tLoss: 0.327093\n",
      "Train Epoch: 3 [6000/11596 (52%)]\tLoss: 0.416568\n",
      "Train Epoch: 3 [7000/11596 (60%)]\tLoss: 0.293384\n",
      "Train Epoch: 3 [8000/11596 (69%)]\tLoss: 0.300513\n",
      "Train Epoch: 3 [9000/11596 (78%)]\tLoss: 0.227481\n",
      "Train Epoch: 3 [10000/11596 (86%)]\tLoss: 0.276378\n",
      "Train Epoch: 3 [11000/11596 (95%)]\tLoss: 0.502366\n",
      "Train Epoch: 4 [0/11596 (0%)]\tLoss: 0.316415\n",
      "Train Epoch: 4 [1000/11596 (9%)]\tLoss: 0.260927\n",
      "Train Epoch: 4 [2000/11596 (17%)]\tLoss: 0.241230\n",
      "Train Epoch: 4 [3000/11596 (26%)]\tLoss: 0.235919\n",
      "Train Epoch: 4 [4000/11596 (34%)]\tLoss: 0.404396\n",
      "Train Epoch: 4 [5000/11596 (43%)]\tLoss: 0.437102\n",
      "Train Epoch: 4 [6000/11596 (52%)]\tLoss: 0.326790\n",
      "Train Epoch: 4 [7000/11596 (60%)]\tLoss: 0.342906\n",
      "Train Epoch: 4 [8000/11596 (69%)]\tLoss: 0.242879\n",
      "Train Epoch: 4 [9000/11596 (78%)]\tLoss: 0.254889\n",
      "Train Epoch: 4 [10000/11596 (86%)]\tLoss: 0.339472\n",
      "Train Epoch: 4 [11000/11596 (95%)]\tLoss: 0.234872\n",
      "Train Epoch: 5 [0/11596 (0%)]\tLoss: 0.313638\n",
      "Train Epoch: 5 [1000/11596 (9%)]\tLoss: 0.427881\n",
      "Train Epoch: 5 [2000/11596 (17%)]\tLoss: 0.258353\n",
      "Train Epoch: 5 [3000/11596 (26%)]\tLoss: 0.305218\n",
      "Train Epoch: 5 [4000/11596 (34%)]\tLoss: 0.391939\n",
      "Train Epoch: 5 [5000/11596 (43%)]\tLoss: 0.368741\n",
      "Train Epoch: 5 [6000/11596 (52%)]\tLoss: 0.350435\n",
      "Train Epoch: 5 [7000/11596 (60%)]\tLoss: 0.253933\n",
      "Train Epoch: 5 [8000/11596 (69%)]\tLoss: 0.280298\n",
      "Train Epoch: 5 [9000/11596 (78%)]\tLoss: 0.276747\n",
      "Train Epoch: 5 [10000/11596 (86%)]\tLoss: 0.455221\n",
      "Train Epoch: 5 [11000/11596 (95%)]\tLoss: 0.253412\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.412510\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.332293\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.407675\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.233362\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.197528\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.265502\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.274310\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.360139\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.299712\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.247071\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.307085\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.268351\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.218326\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.259692\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.287722\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.210350\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.329685\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.276558\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.311064\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.362196\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8987, Accuracy: 7637/10000 (76%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/9140 (0%)]\tLoss: 0.468490\n",
      "Train Epoch: 1 [1000/9140 (11%)]\tLoss: 0.308127\n",
      "Train Epoch: 1 [2000/9140 (22%)]\tLoss: 0.349259\n",
      "Train Epoch: 1 [3000/9140 (33%)]\tLoss: 0.338377\n",
      "Train Epoch: 1 [4000/9140 (43%)]\tLoss: 0.491486\n",
      "Train Epoch: 1 [5000/9140 (54%)]\tLoss: 0.415126\n",
      "Train Epoch: 1 [6000/9140 (65%)]\tLoss: 0.296016\n",
      "Train Epoch: 1 [7000/9140 (76%)]\tLoss: 0.490472\n",
      "Train Epoch: 1 [8000/9140 (87%)]\tLoss: 0.264493\n",
      "Train Epoch: 1 [9000/9140 (98%)]\tLoss: 0.284400\n",
      "Train Epoch: 2 [0/9140 (0%)]\tLoss: 0.230656\n",
      "Train Epoch: 2 [1000/9140 (11%)]\tLoss: 0.412246\n",
      "Train Epoch: 2 [2000/9140 (22%)]\tLoss: 0.315202\n",
      "Train Epoch: 2 [3000/9140 (33%)]\tLoss: 0.488075\n",
      "Train Epoch: 2 [4000/9140 (43%)]\tLoss: 0.317413\n",
      "Train Epoch: 2 [5000/9140 (54%)]\tLoss: 0.386681\n",
      "Train Epoch: 2 [6000/9140 (65%)]\tLoss: 0.383760\n",
      "Train Epoch: 2 [7000/9140 (76%)]\tLoss: 0.427316\n",
      "Train Epoch: 2 [8000/9140 (87%)]\tLoss: 0.346629\n",
      "Train Epoch: 2 [9000/9140 (98%)]\tLoss: 0.267185\n",
      "Train Epoch: 3 [0/9140 (0%)]\tLoss: 0.457176\n",
      "Train Epoch: 3 [1000/9140 (11%)]\tLoss: 0.278724\n",
      "Train Epoch: 3 [2000/9140 (22%)]\tLoss: 0.281318\n",
      "Train Epoch: 3 [3000/9140 (33%)]\tLoss: 0.320222\n",
      "Train Epoch: 3 [4000/9140 (43%)]\tLoss: 0.341184\n",
      "Train Epoch: 3 [5000/9140 (54%)]\tLoss: 0.353713\n",
      "Train Epoch: 3 [6000/9140 (65%)]\tLoss: 0.397358\n",
      "Train Epoch: 3 [7000/9140 (76%)]\tLoss: 0.428607\n",
      "Train Epoch: 3 [8000/9140 (87%)]\tLoss: 0.381684\n",
      "Train Epoch: 3 [9000/9140 (98%)]\tLoss: 0.255608\n",
      "Train Epoch: 4 [0/9140 (0%)]\tLoss: 0.361109\n",
      "Train Epoch: 4 [1000/9140 (11%)]\tLoss: 0.370930\n",
      "Train Epoch: 4 [2000/9140 (22%)]\tLoss: 0.414728\n",
      "Train Epoch: 4 [3000/9140 (33%)]\tLoss: 0.349216\n",
      "Train Epoch: 4 [4000/9140 (43%)]\tLoss: 0.350568\n",
      "Train Epoch: 4 [5000/9140 (54%)]\tLoss: 0.391435\n",
      "Train Epoch: 4 [6000/9140 (65%)]\tLoss: 0.369416\n",
      "Train Epoch: 4 [7000/9140 (76%)]\tLoss: 0.430452\n",
      "Train Epoch: 4 [8000/9140 (87%)]\tLoss: 0.263239\n",
      "Train Epoch: 4 [9000/9140 (98%)]\tLoss: 0.388746\n",
      "Train Epoch: 5 [0/9140 (0%)]\tLoss: 0.311467\n",
      "Train Epoch: 5 [1000/9140 (11%)]\tLoss: 0.400518\n",
      "Train Epoch: 5 [2000/9140 (22%)]\tLoss: 0.522806\n",
      "Train Epoch: 5 [3000/9140 (33%)]\tLoss: 0.453223\n",
      "Train Epoch: 5 [4000/9140 (43%)]\tLoss: 0.345199\n",
      "Train Epoch: 5 [5000/9140 (54%)]\tLoss: 0.260533\n",
      "Train Epoch: 5 [6000/9140 (65%)]\tLoss: 0.334338\n",
      "Train Epoch: 5 [7000/9140 (76%)]\tLoss: 0.420636\n",
      "Train Epoch: 5 [8000/9140 (87%)]\tLoss: 0.250216\n",
      "Train Epoch: 5 [9000/9140 (98%)]\tLoss: 0.278957\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.488161\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.235393\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.141951\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.299989\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.173010\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.305096\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.238901\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.079868\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.160244\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.151153\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.094118\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.123725\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.240721\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.155946\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.081241\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.134189\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.167556\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.270467\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.172064\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.120302\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.214140\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.141443\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.108922\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.129545\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.109750\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.085213\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.178777\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.176399\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.090147\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.202584\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.192893\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.160848\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.234301\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.084386\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.080287\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.144138\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.149782\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.146567\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.122313\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.152939\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.548063\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.232740\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.318148\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.287353\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.268217\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.251067\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.226016\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.136358\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.192317\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.300442\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.210993\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.275955\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.278890\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.253309\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.421804\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.191986\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.211754\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.240164\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.195375\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.242540\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.112811\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.290450\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.252418\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.419162\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.258030\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.387162\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.268511\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.273454\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.205383\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.218101\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.255346\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.168788\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.245376\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.197944\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.154513\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.423965\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.273058\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.345508\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.240261\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.325497\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.241025\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.270360\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.265477\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.181231\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.306777\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.259845\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.199779\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.277277\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.169701\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.346294\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.196351\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.317082\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.332737\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.150397\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.306729\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.209532\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.164396\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.207679\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.267661\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.300890\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.153222\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.220318\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.240044\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.172995\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.246864\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.337584\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.205842\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.323020\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.281173\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.270988\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.393179\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.371304\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.307001\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.237182\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.405965\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.239755\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.293025\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.207963\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.273720\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.365940\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.289866\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.334883\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.364046\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.338300\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.253239\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.337214\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.337122\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.277206\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.339886\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.244288\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.204372\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.240838\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.325739\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.445706\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.252809\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.413429\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.513129\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.359907\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.290813\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.250110\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.288549\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.263456\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.277612\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.354838\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.252442\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.368266\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.325755\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.339215\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.369395\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.178186\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.239813\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.285933\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.298788\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.361662\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.302305\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.485150\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.468900\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.455321\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.407236\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.299809\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.403050\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.332325\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.338133\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.377447\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.382902\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.406376\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.453449\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.415482\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.300423\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.470013\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.340544\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.350148\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.381566\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.332852\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.342398\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.438492\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.300539\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.305526\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.357009\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.448583\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.482680\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.342568\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.405894\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.292380\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.318885\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.353893\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.438753\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.427985\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.354507\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.389690\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.394687\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.329393\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.311635\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.343616\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.444027\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.366421\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.350228\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.539904\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.339103\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.303599\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.327577\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.378822\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.332502\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.357338\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.314111\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/13300 (0%)]\tLoss: 0.394467\n",
      "Train Epoch: 1 [1000/13300 (8%)]\tLoss: 0.217278\n",
      "Train Epoch: 1 [2000/13300 (15%)]\tLoss: 0.505247\n",
      "Train Epoch: 1 [3000/13300 (23%)]\tLoss: 0.382471\n",
      "Train Epoch: 1 [4000/13300 (30%)]\tLoss: 0.390427\n",
      "Train Epoch: 1 [5000/13300 (38%)]\tLoss: 0.241942\n",
      "Train Epoch: 1 [6000/13300 (45%)]\tLoss: 0.377825\n",
      "Train Epoch: 1 [7000/13300 (53%)]\tLoss: 0.272640\n",
      "Train Epoch: 1 [8000/13300 (60%)]\tLoss: 0.204328\n",
      "Train Epoch: 1 [9000/13300 (68%)]\tLoss: 0.238807\n",
      "Train Epoch: 1 [10000/13300 (75%)]\tLoss: 0.311053\n",
      "Train Epoch: 1 [11000/13300 (83%)]\tLoss: 0.227512\n",
      "Train Epoch: 1 [12000/13300 (90%)]\tLoss: 0.441301\n",
      "Train Epoch: 1 [13000/13300 (98%)]\tLoss: 0.292737\n",
      "Train Epoch: 2 [0/13300 (0%)]\tLoss: 0.324172\n",
      "Train Epoch: 2 [1000/13300 (8%)]\tLoss: 0.259488\n",
      "Train Epoch: 2 [2000/13300 (15%)]\tLoss: 0.194311\n",
      "Train Epoch: 2 [3000/13300 (23%)]\tLoss: 0.303383\n",
      "Train Epoch: 2 [4000/13300 (30%)]\tLoss: 0.383843\n",
      "Train Epoch: 2 [5000/13300 (38%)]\tLoss: 0.311280\n",
      "Train Epoch: 2 [6000/13300 (45%)]\tLoss: 0.282169\n",
      "Train Epoch: 2 [7000/13300 (53%)]\tLoss: 0.197567\n",
      "Train Epoch: 2 [8000/13300 (60%)]\tLoss: 0.352851\n",
      "Train Epoch: 2 [9000/13300 (68%)]\tLoss: 0.209447\n",
      "Train Epoch: 2 [10000/13300 (75%)]\tLoss: 0.311352\n",
      "Train Epoch: 2 [11000/13300 (83%)]\tLoss: 0.149754\n",
      "Train Epoch: 2 [12000/13300 (90%)]\tLoss: 0.271366\n",
      "Train Epoch: 2 [13000/13300 (98%)]\tLoss: 0.294033\n",
      "Train Epoch: 3 [0/13300 (0%)]\tLoss: 0.289990\n",
      "Train Epoch: 3 [1000/13300 (8%)]\tLoss: 0.291896\n",
      "Train Epoch: 3 [2000/13300 (15%)]\tLoss: 0.247176\n",
      "Train Epoch: 3 [3000/13300 (23%)]\tLoss: 0.309820\n",
      "Train Epoch: 3 [4000/13300 (30%)]\tLoss: 0.300303\n",
      "Train Epoch: 3 [5000/13300 (38%)]\tLoss: 0.182828\n",
      "Train Epoch: 3 [6000/13300 (45%)]\tLoss: 0.203355\n",
      "Train Epoch: 3 [7000/13300 (53%)]\tLoss: 0.390976\n",
      "Train Epoch: 3 [8000/13300 (60%)]\tLoss: 0.335057\n",
      "Train Epoch: 3 [9000/13300 (68%)]\tLoss: 0.245149\n",
      "Train Epoch: 3 [10000/13300 (75%)]\tLoss: 0.383779\n",
      "Train Epoch: 3 [11000/13300 (83%)]\tLoss: 0.276425\n",
      "Train Epoch: 3 [12000/13300 (90%)]\tLoss: 0.268346\n",
      "Train Epoch: 3 [13000/13300 (98%)]\tLoss: 0.321526\n",
      "Train Epoch: 4 [0/13300 (0%)]\tLoss: 0.262153\n",
      "Train Epoch: 4 [1000/13300 (8%)]\tLoss: 0.366874\n",
      "Train Epoch: 4 [2000/13300 (15%)]\tLoss: 0.323451\n",
      "Train Epoch: 4 [3000/13300 (23%)]\tLoss: 0.232062\n",
      "Train Epoch: 4 [4000/13300 (30%)]\tLoss: 0.298683\n",
      "Train Epoch: 4 [5000/13300 (38%)]\tLoss: 0.221158\n",
      "Train Epoch: 4 [6000/13300 (45%)]\tLoss: 0.341190\n",
      "Train Epoch: 4 [7000/13300 (53%)]\tLoss: 0.373175\n",
      "Train Epoch: 4 [8000/13300 (60%)]\tLoss: 0.369714\n",
      "Train Epoch: 4 [9000/13300 (68%)]\tLoss: 0.233364\n",
      "Train Epoch: 4 [10000/13300 (75%)]\tLoss: 0.308909\n",
      "Train Epoch: 4 [11000/13300 (83%)]\tLoss: 0.336298\n",
      "Train Epoch: 4 [12000/13300 (90%)]\tLoss: 0.241843\n",
      "Train Epoch: 4 [13000/13300 (98%)]\tLoss: 0.271596\n",
      "Train Epoch: 5 [0/13300 (0%)]\tLoss: 0.220891\n",
      "Train Epoch: 5 [1000/13300 (8%)]\tLoss: 0.223342\n",
      "Train Epoch: 5 [2000/13300 (15%)]\tLoss: 0.307248\n",
      "Train Epoch: 5 [3000/13300 (23%)]\tLoss: 0.315174\n",
      "Train Epoch: 5 [4000/13300 (30%)]\tLoss: 0.434404\n",
      "Train Epoch: 5 [5000/13300 (38%)]\tLoss: 0.317685\n",
      "Train Epoch: 5 [6000/13300 (45%)]\tLoss: 0.345278\n",
      "Train Epoch: 5 [7000/13300 (53%)]\tLoss: 0.140597\n",
      "Train Epoch: 5 [8000/13300 (60%)]\tLoss: 0.352000\n",
      "Train Epoch: 5 [9000/13300 (68%)]\tLoss: 0.309240\n",
      "Train Epoch: 5 [10000/13300 (75%)]\tLoss: 0.339006\n",
      "Train Epoch: 5 [11000/13300 (83%)]\tLoss: 0.256446\n",
      "Train Epoch: 5 [12000/13300 (90%)]\tLoss: 0.222044\n",
      "Train Epoch: 5 [13000/13300 (98%)]\tLoss: 0.310051\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9013, Accuracy: 7621/10000 (76%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/9140 (0%)]\tLoss: 0.407302\n",
      "Train Epoch: 1 [1000/9140 (11%)]\tLoss: 0.437569\n",
      "Train Epoch: 1 [2000/9140 (22%)]\tLoss: 0.366918\n",
      "Train Epoch: 1 [3000/9140 (33%)]\tLoss: 0.411097\n",
      "Train Epoch: 1 [4000/9140 (43%)]\tLoss: 0.372921\n",
      "Train Epoch: 1 [5000/9140 (54%)]\tLoss: 0.256050\n",
      "Train Epoch: 1 [6000/9140 (65%)]\tLoss: 0.262544\n",
      "Train Epoch: 1 [7000/9140 (76%)]\tLoss: 0.374853\n",
      "Train Epoch: 1 [8000/9140 (87%)]\tLoss: 0.307215\n",
      "Train Epoch: 1 [9000/9140 (98%)]\tLoss: 0.396139\n",
      "Train Epoch: 2 [0/9140 (0%)]\tLoss: 0.363167\n",
      "Train Epoch: 2 [1000/9140 (11%)]\tLoss: 0.276567\n",
      "Train Epoch: 2 [2000/9140 (22%)]\tLoss: 0.315176\n",
      "Train Epoch: 2 [3000/9140 (33%)]\tLoss: 0.350382\n",
      "Train Epoch: 2 [4000/9140 (43%)]\tLoss: 0.249036\n",
      "Train Epoch: 2 [5000/9140 (54%)]\tLoss: 0.289806\n",
      "Train Epoch: 2 [6000/9140 (65%)]\tLoss: 0.331260\n",
      "Train Epoch: 2 [7000/9140 (76%)]\tLoss: 0.357012\n",
      "Train Epoch: 2 [8000/9140 (87%)]\tLoss: 0.467133\n",
      "Train Epoch: 2 [9000/9140 (98%)]\tLoss: 0.342532\n",
      "Train Epoch: 3 [0/9140 (0%)]\tLoss: 0.372317\n",
      "Train Epoch: 3 [1000/9140 (11%)]\tLoss: 0.264988\n",
      "Train Epoch: 3 [2000/9140 (22%)]\tLoss: 0.366907\n",
      "Train Epoch: 3 [3000/9140 (33%)]\tLoss: 0.501285\n",
      "Train Epoch: 3 [4000/9140 (43%)]\tLoss: 0.250646\n",
      "Train Epoch: 3 [5000/9140 (54%)]\tLoss: 0.299466\n",
      "Train Epoch: 3 [6000/9140 (65%)]\tLoss: 0.315724\n",
      "Train Epoch: 3 [7000/9140 (76%)]\tLoss: 0.433689\n",
      "Train Epoch: 3 [8000/9140 (87%)]\tLoss: 0.419450\n",
      "Train Epoch: 3 [9000/9140 (98%)]\tLoss: 0.270135\n",
      "Train Epoch: 4 [0/9140 (0%)]\tLoss: 0.296963\n",
      "Train Epoch: 4 [1000/9140 (11%)]\tLoss: 0.334768\n",
      "Train Epoch: 4 [2000/9140 (22%)]\tLoss: 0.285965\n",
      "Train Epoch: 4 [3000/9140 (33%)]\tLoss: 0.271546\n",
      "Train Epoch: 4 [4000/9140 (43%)]\tLoss: 0.490042\n",
      "Train Epoch: 4 [5000/9140 (54%)]\tLoss: 0.439591\n",
      "Train Epoch: 4 [6000/9140 (65%)]\tLoss: 0.338546\n",
      "Train Epoch: 4 [7000/9140 (76%)]\tLoss: 0.382784\n",
      "Train Epoch: 4 [8000/9140 (87%)]\tLoss: 0.385562\n",
      "Train Epoch: 4 [9000/9140 (98%)]\tLoss: 0.283549\n",
      "Train Epoch: 5 [0/9140 (0%)]\tLoss: 0.409483\n",
      "Train Epoch: 5 [1000/9140 (11%)]\tLoss: 0.354113\n",
      "Train Epoch: 5 [2000/9140 (22%)]\tLoss: 0.274186\n",
      "Train Epoch: 5 [3000/9140 (33%)]\tLoss: 0.354503\n",
      "Train Epoch: 5 [4000/9140 (43%)]\tLoss: 0.437818\n",
      "Train Epoch: 5 [5000/9140 (54%)]\tLoss: 0.335322\n",
      "Train Epoch: 5 [6000/9140 (65%)]\tLoss: 0.337930\n",
      "Train Epoch: 5 [7000/9140 (76%)]\tLoss: 0.373783\n",
      "Train Epoch: 5 [8000/9140 (87%)]\tLoss: 0.367778\n",
      "Train Epoch: 5 [9000/9140 (98%)]\tLoss: 0.454674\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.474528\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.331746\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.128217\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.225719\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.334144\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.056259\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.090881\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.110375\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.192207\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.124074\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.175688\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.157151\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.113448\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.184217\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.296714\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.100018\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.188297\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.190646\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.158498\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.155226\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.121134\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.109905\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.176803\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.188311\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.175808\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.190881\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.132074\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.169440\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.183112\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.208740\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.199234\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.149308\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.072949\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.120407\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.102653\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.120437\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.216633\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.078621\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.115422\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.099676\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.422030\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.208678\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.219641\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.303663\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.232049\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.282253\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.253390\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.152923\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.140072\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.142031\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.240406\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.164075\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.250470\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.204296\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.234070\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.265227\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.304495\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.429212\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.245964\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.180491\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.132040\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.344413\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.143661\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.326972\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.135222\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.225440\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.341566\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.152573\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.211269\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.289055\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.173394\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.206781\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.152665\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.336696\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.151588\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.419262\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.254458\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.278625\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.254046\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.255590\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.346199\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.219566\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.193106\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.230269\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.175433\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.291401\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.217494\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.226051\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.262153\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.321371\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.117546\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.268302\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.255384\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.367632\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.253280\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.317929\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.295374\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.177823\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.336427\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.171458\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.162343\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.269875\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.193960\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.398290\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.111339\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.423222\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.188779\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.242770\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.264479\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.325894\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.264732\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.162949\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.279593\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.197391\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.296484\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.188048\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.254743\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.293196\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.329127\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.296135\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.284230\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.405536\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.264759\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.269336\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.283252\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.180798\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.320612\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.195924\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.189076\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.244269\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.364685\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.325932\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.331395\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.338705\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.196095\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.410779\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.277297\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.354582\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.164063\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.287591\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.364405\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.312170\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.436767\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.300725\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.297342\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.342576\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.406852\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.328302\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.309113\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.397947\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.326869\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.274636\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.342927\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.245620\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.316003\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.502264\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.451423\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.379036\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.308165\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.388116\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.328587\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.590303\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.373157\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.308857\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.399990\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.386363\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.406476\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.366787\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.224880\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.519636\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.331958\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.471849\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.319800\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.342783\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.424934\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.432794\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.326335\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.282635\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.261662\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.296068\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.356513\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.393444\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.250754\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.570484\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.297402\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.378441\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.490769\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.408950\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.419555\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.489217\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.336783\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.293387\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.278574\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.290564\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.372806\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.330180\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.266487\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.369395\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.361018\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.340302\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.285937\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.484393\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.199686\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.262530\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.280133\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/13300 (0%)]\tLoss: 0.459429\n",
      "Train Epoch: 1 [1000/13300 (8%)]\tLoss: 0.275216\n",
      "Train Epoch: 1 [2000/13300 (15%)]\tLoss: 0.375908\n",
      "Train Epoch: 1 [3000/13300 (23%)]\tLoss: 0.382214\n",
      "Train Epoch: 1 [4000/13300 (30%)]\tLoss: 0.416202\n",
      "Train Epoch: 1 [5000/13300 (38%)]\tLoss: 0.289604\n",
      "Train Epoch: 1 [6000/13300 (45%)]\tLoss: 0.505594\n",
      "Train Epoch: 1 [7000/13300 (53%)]\tLoss: 0.399480\n",
      "Train Epoch: 1 [8000/13300 (60%)]\tLoss: 0.296398\n",
      "Train Epoch: 1 [9000/13300 (68%)]\tLoss: 0.288737\n",
      "Train Epoch: 1 [10000/13300 (75%)]\tLoss: 0.196931\n",
      "Train Epoch: 1 [11000/13300 (83%)]\tLoss: 0.383920\n",
      "Train Epoch: 1 [12000/13300 (90%)]\tLoss: 0.329646\n",
      "Train Epoch: 1 [13000/13300 (98%)]\tLoss: 0.222305\n",
      "Train Epoch: 2 [0/13300 (0%)]\tLoss: 0.288805\n",
      "Train Epoch: 2 [1000/13300 (8%)]\tLoss: 0.291592\n",
      "Train Epoch: 2 [2000/13300 (15%)]\tLoss: 0.381561\n",
      "Train Epoch: 2 [3000/13300 (23%)]\tLoss: 0.415887\n",
      "Train Epoch: 2 [4000/13300 (30%)]\tLoss: 0.562373\n",
      "Train Epoch: 2 [5000/13300 (38%)]\tLoss: 0.195725\n",
      "Train Epoch: 2 [6000/13300 (45%)]\tLoss: 0.223288\n",
      "Train Epoch: 2 [7000/13300 (53%)]\tLoss: 0.222582\n",
      "Train Epoch: 2 [8000/13300 (60%)]\tLoss: 0.307762\n",
      "Train Epoch: 2 [9000/13300 (68%)]\tLoss: 0.277680\n",
      "Train Epoch: 2 [10000/13300 (75%)]\tLoss: 0.212754\n",
      "Train Epoch: 2 [11000/13300 (83%)]\tLoss: 0.241558\n",
      "Train Epoch: 2 [12000/13300 (90%)]\tLoss: 0.247668\n",
      "Train Epoch: 2 [13000/13300 (98%)]\tLoss: 0.301106\n",
      "Train Epoch: 3 [0/13300 (0%)]\tLoss: 0.333791\n",
      "Train Epoch: 3 [1000/13300 (8%)]\tLoss: 0.303361\n",
      "Train Epoch: 3 [2000/13300 (15%)]\tLoss: 0.282086\n",
      "Train Epoch: 3 [3000/13300 (23%)]\tLoss: 0.189334\n",
      "Train Epoch: 3 [4000/13300 (30%)]\tLoss: 0.343524\n",
      "Train Epoch: 3 [5000/13300 (38%)]\tLoss: 0.200408\n",
      "Train Epoch: 3 [6000/13300 (45%)]\tLoss: 0.307708\n",
      "Train Epoch: 3 [7000/13300 (53%)]\tLoss: 0.292978\n",
      "Train Epoch: 3 [8000/13300 (60%)]\tLoss: 0.250638\n",
      "Train Epoch: 3 [9000/13300 (68%)]\tLoss: 0.233624\n",
      "Train Epoch: 3 [10000/13300 (75%)]\tLoss: 0.312448\n",
      "Train Epoch: 3 [11000/13300 (83%)]\tLoss: 0.315212\n",
      "Train Epoch: 3 [12000/13300 (90%)]\tLoss: 0.295156\n",
      "Train Epoch: 3 [13000/13300 (98%)]\tLoss: 0.447398\n",
      "Train Epoch: 4 [0/13300 (0%)]\tLoss: 0.314607\n",
      "Train Epoch: 4 [1000/13300 (8%)]\tLoss: 0.169920\n",
      "Train Epoch: 4 [2000/13300 (15%)]\tLoss: 0.547785\n",
      "Train Epoch: 4 [3000/13300 (23%)]\tLoss: 0.232006\n",
      "Train Epoch: 4 [4000/13300 (30%)]\tLoss: 0.469436\n",
      "Train Epoch: 4 [5000/13300 (38%)]\tLoss: 0.248684\n",
      "Train Epoch: 4 [6000/13300 (45%)]\tLoss: 0.355815\n",
      "Train Epoch: 4 [7000/13300 (53%)]\tLoss: 0.283546\n",
      "Train Epoch: 4 [8000/13300 (60%)]\tLoss: 0.288151\n",
      "Train Epoch: 4 [9000/13300 (68%)]\tLoss: 0.386729\n",
      "Train Epoch: 4 [10000/13300 (75%)]\tLoss: 0.281396\n",
      "Train Epoch: 4 [11000/13300 (83%)]\tLoss: 0.216195\n",
      "Train Epoch: 4 [12000/13300 (90%)]\tLoss: 0.207898\n",
      "Train Epoch: 4 [13000/13300 (98%)]\tLoss: 0.215296\n",
      "Train Epoch: 5 [0/13300 (0%)]\tLoss: 0.300978\n",
      "Train Epoch: 5 [1000/13300 (8%)]\tLoss: 0.321808\n",
      "Train Epoch: 5 [2000/13300 (15%)]\tLoss: 0.398831\n",
      "Train Epoch: 5 [3000/13300 (23%)]\tLoss: 0.231795\n",
      "Train Epoch: 5 [4000/13300 (30%)]\tLoss: 0.152398\n",
      "Train Epoch: 5 [5000/13300 (38%)]\tLoss: 0.272027\n",
      "Train Epoch: 5 [6000/13300 (45%)]\tLoss: 0.210707\n",
      "Train Epoch: 5 [7000/13300 (53%)]\tLoss: 0.272669\n",
      "Train Epoch: 5 [8000/13300 (60%)]\tLoss: 0.285436\n",
      "Train Epoch: 5 [9000/13300 (68%)]\tLoss: 0.324659\n",
      "Train Epoch: 5 [10000/13300 (75%)]\tLoss: 0.298247\n",
      "Train Epoch: 5 [11000/13300 (83%)]\tLoss: 0.342929\n",
      "Train Epoch: 5 [12000/13300 (90%)]\tLoss: 0.235731\n",
      "Train Epoch: 5 [13000/13300 (98%)]\tLoss: 0.151285\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.8865, Accuracy: 7659/10000 (77%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/9140 (0%)]\tLoss: 0.420723\n",
      "Train Epoch: 1 [1000/9140 (11%)]\tLoss: 0.364940\n",
      "Train Epoch: 1 [2000/9140 (22%)]\tLoss: 0.383907\n",
      "Train Epoch: 1 [3000/9140 (33%)]\tLoss: 0.332070\n",
      "Train Epoch: 1 [4000/9140 (43%)]\tLoss: 0.318102\n",
      "Train Epoch: 1 [5000/9140 (54%)]\tLoss: 0.468752\n",
      "Train Epoch: 1 [6000/9140 (65%)]\tLoss: 0.322082\n",
      "Train Epoch: 1 [7000/9140 (76%)]\tLoss: 0.318766\n",
      "Train Epoch: 1 [8000/9140 (87%)]\tLoss: 0.470694\n",
      "Train Epoch: 1 [9000/9140 (98%)]\tLoss: 0.410737\n",
      "Train Epoch: 2 [0/9140 (0%)]\tLoss: 0.460426\n",
      "Train Epoch: 2 [1000/9140 (11%)]\tLoss: 0.564687\n",
      "Train Epoch: 2 [2000/9140 (22%)]\tLoss: 0.371883\n",
      "Train Epoch: 2 [3000/9140 (33%)]\tLoss: 0.326389\n",
      "Train Epoch: 2 [4000/9140 (43%)]\tLoss: 0.286247\n",
      "Train Epoch: 2 [5000/9140 (54%)]\tLoss: 0.331268\n",
      "Train Epoch: 2 [6000/9140 (65%)]\tLoss: 0.292056\n",
      "Train Epoch: 2 [7000/9140 (76%)]\tLoss: 0.366080\n",
      "Train Epoch: 2 [8000/9140 (87%)]\tLoss: 0.379878\n",
      "Train Epoch: 2 [9000/9140 (98%)]\tLoss: 0.495377\n",
      "Train Epoch: 3 [0/9140 (0%)]\tLoss: 0.406472\n",
      "Train Epoch: 3 [1000/9140 (11%)]\tLoss: 0.332836\n",
      "Train Epoch: 3 [2000/9140 (22%)]\tLoss: 0.206529\n",
      "Train Epoch: 3 [3000/9140 (33%)]\tLoss: 0.229289\n",
      "Train Epoch: 3 [4000/9140 (43%)]\tLoss: 0.367990\n",
      "Train Epoch: 3 [5000/9140 (54%)]\tLoss: 0.395780\n",
      "Train Epoch: 3 [6000/9140 (65%)]\tLoss: 0.287749\n",
      "Train Epoch: 3 [7000/9140 (76%)]\tLoss: 0.339877\n",
      "Train Epoch: 3 [8000/9140 (87%)]\tLoss: 0.354205\n",
      "Train Epoch: 3 [9000/9140 (98%)]\tLoss: 0.363783\n",
      "Train Epoch: 4 [0/9140 (0%)]\tLoss: 0.347986\n",
      "Train Epoch: 4 [1000/9140 (11%)]\tLoss: 0.386851\n",
      "Train Epoch: 4 [2000/9140 (22%)]\tLoss: 0.315225\n",
      "Train Epoch: 4 [3000/9140 (33%)]\tLoss: 0.280604\n",
      "Train Epoch: 4 [4000/9140 (43%)]\tLoss: 0.397906\n",
      "Train Epoch: 4 [5000/9140 (54%)]\tLoss: 0.334824\n",
      "Train Epoch: 4 [6000/9140 (65%)]\tLoss: 0.389859\n",
      "Train Epoch: 4 [7000/9140 (76%)]\tLoss: 0.290800\n",
      "Train Epoch: 4 [8000/9140 (87%)]\tLoss: 0.303664\n",
      "Train Epoch: 4 [9000/9140 (98%)]\tLoss: 0.243197\n",
      "Train Epoch: 5 [0/9140 (0%)]\tLoss: 0.419984\n",
      "Train Epoch: 5 [1000/9140 (11%)]\tLoss: 0.230719\n",
      "Train Epoch: 5 [2000/9140 (22%)]\tLoss: 0.348052\n",
      "Train Epoch: 5 [3000/9140 (33%)]\tLoss: 0.286790\n",
      "Train Epoch: 5 [4000/9140 (43%)]\tLoss: 0.317685\n",
      "Train Epoch: 5 [5000/9140 (54%)]\tLoss: 0.260803\n",
      "Train Epoch: 5 [6000/9140 (65%)]\tLoss: 0.376957\n",
      "Train Epoch: 5 [7000/9140 (76%)]\tLoss: 0.380903\n",
      "Train Epoch: 5 [8000/9140 (87%)]\tLoss: 0.416039\n",
      "Train Epoch: 5 [9000/9140 (98%)]\tLoss: 0.431128\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.347632\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.166901\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.190455\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.137328\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.129891\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.264437\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.250562\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.264949\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.163560\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.105843\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.145346\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.170862\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.078096\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.164327\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.156895\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.290684\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.187824\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.185493\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.194717\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.162945\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.028707\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.175933\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.056421\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.146920\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.183398\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.128032\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.085659\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.086762\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.138584\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.143759\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.103118\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.130488\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.235318\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.141352\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.224115\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.122912\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.085596\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.090276\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.118488\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.190234\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.246002\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.213686\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.287251\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.200540\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.131326\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.133464\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.220770\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.326946\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.125075\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.334357\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.275000\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.189060\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.129484\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.217429\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.215809\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.182837\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.279270\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.183462\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.139240\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.205144\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.129953\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.273751\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.170416\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.267926\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.142258\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.277325\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.225638\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.216672\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.274289\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.199541\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.267839\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.132836\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.209894\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.257254\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.156714\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.369483\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.261951\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.325045\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.407023\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.245087\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.281129\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.250848\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.332672\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.199420\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.227453\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.220078\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.303194\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.307120\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.305629\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.121076\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.225871\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.273510\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.198885\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.226963\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.277001\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.284300\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.269641\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.307657\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.162963\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.224957\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.370456\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.226009\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.211900\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.181319\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.305961\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.331882\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.276716\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.255718\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.220796\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.225016\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.288400\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.327587\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.215692\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.339485\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.233199\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.224340\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.295452\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.304249\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.294330\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.242481\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.377706\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.326180\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.302146\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.298517\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.232927\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.195372\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.295852\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.236588\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.260345\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.309841\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.321734\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.257690\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.256942\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.312722\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.422827\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.385245\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.221545\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.362243\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.284780\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.304371\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.384209\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.349997\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.352016\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.289404\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.309252\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.308488\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.397059\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.326676\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.161294\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.345267\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.243981\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.217404\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.278971\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.323953\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.222320\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.506773\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.415167\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.287431\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.226735\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.363995\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.275569\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.447745\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.332696\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.418197\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.433046\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.361894\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.326276\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.369688\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.419835\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.283117\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.333211\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.375774\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.288905\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.507323\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.359267\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.341104\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.357152\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.370165\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.433639\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.301557\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.332127\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.302238\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.298449\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.350273\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.441602\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.348473\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.499376\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.342820\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.324037\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.342926\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.376344\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.289421\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.283183\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.267335\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.366534\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.260139\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.351169\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.432941\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.387817\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.386529\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.580811\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.352320\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.325323\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.349421\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.313361\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/13300 (0%)]\tLoss: 0.395933\n",
      "Train Epoch: 1 [1000/13300 (8%)]\tLoss: 0.159833\n",
      "Train Epoch: 1 [2000/13300 (15%)]\tLoss: 0.322843\n",
      "Train Epoch: 1 [3000/13300 (23%)]\tLoss: 0.241624\n",
      "Train Epoch: 1 [4000/13300 (30%)]\tLoss: 0.385113\n",
      "Train Epoch: 1 [5000/13300 (38%)]\tLoss: 0.272682\n",
      "Train Epoch: 1 [6000/13300 (45%)]\tLoss: 0.312987\n",
      "Train Epoch: 1 [7000/13300 (53%)]\tLoss: 0.260330\n",
      "Train Epoch: 1 [8000/13300 (60%)]\tLoss: 0.276493\n",
      "Train Epoch: 1 [9000/13300 (68%)]\tLoss: 0.219310\n",
      "Train Epoch: 1 [10000/13300 (75%)]\tLoss: 0.289897\n",
      "Train Epoch: 1 [11000/13300 (83%)]\tLoss: 0.259857\n",
      "Train Epoch: 1 [12000/13300 (90%)]\tLoss: 0.320288\n",
      "Train Epoch: 1 [13000/13300 (98%)]\tLoss: 0.378682\n",
      "Train Epoch: 2 [0/13300 (0%)]\tLoss: 0.247443\n",
      "Train Epoch: 2 [1000/13300 (8%)]\tLoss: 0.234447\n",
      "Train Epoch: 2 [2000/13300 (15%)]\tLoss: 0.259834\n",
      "Train Epoch: 2 [3000/13300 (23%)]\tLoss: 0.274536\n",
      "Train Epoch: 2 [4000/13300 (30%)]\tLoss: 0.401512\n",
      "Train Epoch: 2 [5000/13300 (38%)]\tLoss: 0.543402\n",
      "Train Epoch: 2 [6000/13300 (45%)]\tLoss: 0.279036\n",
      "Train Epoch: 2 [7000/13300 (53%)]\tLoss: 0.350695\n",
      "Train Epoch: 2 [8000/13300 (60%)]\tLoss: 0.249083\n",
      "Train Epoch: 2 [9000/13300 (68%)]\tLoss: 0.173580\n",
      "Train Epoch: 2 [10000/13300 (75%)]\tLoss: 0.343406\n",
      "Train Epoch: 2 [11000/13300 (83%)]\tLoss: 0.222389\n",
      "Train Epoch: 2 [12000/13300 (90%)]\tLoss: 0.281094\n",
      "Train Epoch: 2 [13000/13300 (98%)]\tLoss: 0.211697\n",
      "Train Epoch: 3 [0/13300 (0%)]\tLoss: 0.355419\n",
      "Train Epoch: 3 [1000/13300 (8%)]\tLoss: 0.204064\n",
      "Train Epoch: 3 [2000/13300 (15%)]\tLoss: 0.173975\n",
      "Train Epoch: 3 [3000/13300 (23%)]\tLoss: 0.300980\n",
      "Train Epoch: 3 [4000/13300 (30%)]\tLoss: 0.356177\n",
      "Train Epoch: 3 [5000/13300 (38%)]\tLoss: 0.333207\n",
      "Train Epoch: 3 [6000/13300 (45%)]\tLoss: 0.187081\n",
      "Train Epoch: 3 [7000/13300 (53%)]\tLoss: 0.238026\n",
      "Train Epoch: 3 [8000/13300 (60%)]\tLoss: 0.408755\n",
      "Train Epoch: 3 [9000/13300 (68%)]\tLoss: 0.213912\n",
      "Train Epoch: 3 [10000/13300 (75%)]\tLoss: 0.295444\n",
      "Train Epoch: 3 [11000/13300 (83%)]\tLoss: 0.216588\n",
      "Train Epoch: 3 [12000/13300 (90%)]\tLoss: 0.274128\n",
      "Train Epoch: 3 [13000/13300 (98%)]\tLoss: 0.205783\n",
      "Train Epoch: 4 [0/13300 (0%)]\tLoss: 0.279646\n",
      "Train Epoch: 4 [1000/13300 (8%)]\tLoss: 0.257807\n",
      "Train Epoch: 4 [2000/13300 (15%)]\tLoss: 0.349215\n",
      "Train Epoch: 4 [3000/13300 (23%)]\tLoss: 0.272042\n",
      "Train Epoch: 4 [4000/13300 (30%)]\tLoss: 0.269493\n",
      "Train Epoch: 4 [5000/13300 (38%)]\tLoss: 0.207354\n",
      "Train Epoch: 4 [6000/13300 (45%)]\tLoss: 0.271325\n",
      "Train Epoch: 4 [7000/13300 (53%)]\tLoss: 0.283580\n",
      "Train Epoch: 4 [8000/13300 (60%)]\tLoss: 0.150674\n",
      "Train Epoch: 4 [9000/13300 (68%)]\tLoss: 0.283916\n",
      "Train Epoch: 4 [10000/13300 (75%)]\tLoss: 0.308547\n",
      "Train Epoch: 4 [11000/13300 (83%)]\tLoss: 0.311789\n",
      "Train Epoch: 4 [12000/13300 (90%)]\tLoss: 0.210094\n",
      "Train Epoch: 4 [13000/13300 (98%)]\tLoss: 0.248866\n",
      "Train Epoch: 5 [0/13300 (0%)]\tLoss: 0.298618\n",
      "Train Epoch: 5 [1000/13300 (8%)]\tLoss: 0.319554\n",
      "Train Epoch: 5 [2000/13300 (15%)]\tLoss: 0.315325\n",
      "Train Epoch: 5 [3000/13300 (23%)]\tLoss: 0.228670\n",
      "Train Epoch: 5 [4000/13300 (30%)]\tLoss: 0.345607\n",
      "Train Epoch: 5 [5000/13300 (38%)]\tLoss: 0.330229\n",
      "Train Epoch: 5 [6000/13300 (45%)]\tLoss: 0.473579\n",
      "Train Epoch: 5 [7000/13300 (53%)]\tLoss: 0.410873\n",
      "Train Epoch: 5 [8000/13300 (60%)]\tLoss: 0.376429\n",
      "Train Epoch: 5 [9000/13300 (68%)]\tLoss: 0.261352\n",
      "Train Epoch: 5 [10000/13300 (75%)]\tLoss: 0.241886\n",
      "Train Epoch: 5 [11000/13300 (83%)]\tLoss: 0.243496\n",
      "Train Epoch: 5 [12000/13300 (90%)]\tLoss: 0.331820\n",
      "Train Epoch: 5 [13000/13300 (98%)]\tLoss: 0.186537\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9200, Accuracy: 7605/10000 (76%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/9140 (0%)]\tLoss: 0.517680\n",
      "Train Epoch: 1 [1000/9140 (11%)]\tLoss: 0.558844\n",
      "Train Epoch: 1 [2000/9140 (22%)]\tLoss: 0.482565\n",
      "Train Epoch: 1 [3000/9140 (33%)]\tLoss: 0.492666\n",
      "Train Epoch: 1 [4000/9140 (43%)]\tLoss: 0.297634\n",
      "Train Epoch: 1 [5000/9140 (54%)]\tLoss: 0.269655\n",
      "Train Epoch: 1 [6000/9140 (65%)]\tLoss: 0.315416\n",
      "Train Epoch: 1 [7000/9140 (76%)]\tLoss: 0.359159\n",
      "Train Epoch: 1 [8000/9140 (87%)]\tLoss: 0.386896\n",
      "Train Epoch: 1 [9000/9140 (98%)]\tLoss: 0.378432\n",
      "Train Epoch: 2 [0/9140 (0%)]\tLoss: 0.382108\n",
      "Train Epoch: 2 [1000/9140 (11%)]\tLoss: 0.259435\n",
      "Train Epoch: 2 [2000/9140 (22%)]\tLoss: 0.282459\n",
      "Train Epoch: 2 [3000/9140 (33%)]\tLoss: 0.234884\n",
      "Train Epoch: 2 [4000/9140 (43%)]\tLoss: 0.355282\n",
      "Train Epoch: 2 [5000/9140 (54%)]\tLoss: 0.299133\n",
      "Train Epoch: 2 [6000/9140 (65%)]\tLoss: 0.363182\n",
      "Train Epoch: 2 [7000/9140 (76%)]\tLoss: 0.384808\n",
      "Train Epoch: 2 [8000/9140 (87%)]\tLoss: 0.358534\n",
      "Train Epoch: 2 [9000/9140 (98%)]\tLoss: 0.364229\n",
      "Train Epoch: 3 [0/9140 (0%)]\tLoss: 0.395686\n",
      "Train Epoch: 3 [1000/9140 (11%)]\tLoss: 0.241165\n",
      "Train Epoch: 3 [2000/9140 (22%)]\tLoss: 0.341705\n",
      "Train Epoch: 3 [3000/9140 (33%)]\tLoss: 0.406365\n",
      "Train Epoch: 3 [4000/9140 (43%)]\tLoss: 0.453338\n",
      "Train Epoch: 3 [5000/9140 (54%)]\tLoss: 0.341599\n",
      "Train Epoch: 3 [6000/9140 (65%)]\tLoss: 0.363570\n",
      "Train Epoch: 3 [7000/9140 (76%)]\tLoss: 0.290193\n",
      "Train Epoch: 3 [8000/9140 (87%)]\tLoss: 0.246619\n",
      "Train Epoch: 3 [9000/9140 (98%)]\tLoss: 0.278005\n",
      "Train Epoch: 4 [0/9140 (0%)]\tLoss: 0.432534\n",
      "Train Epoch: 4 [1000/9140 (11%)]\tLoss: 0.211456\n",
      "Train Epoch: 4 [2000/9140 (22%)]\tLoss: 0.395268\n",
      "Train Epoch: 4 [3000/9140 (33%)]\tLoss: 0.250076\n",
      "Train Epoch: 4 [4000/9140 (43%)]\tLoss: 0.424165\n",
      "Train Epoch: 4 [5000/9140 (54%)]\tLoss: 0.405085\n",
      "Train Epoch: 4 [6000/9140 (65%)]\tLoss: 0.389406\n",
      "Train Epoch: 4 [7000/9140 (76%)]\tLoss: 0.321111\n",
      "Train Epoch: 4 [8000/9140 (87%)]\tLoss: 0.304107\n",
      "Train Epoch: 4 [9000/9140 (98%)]\tLoss: 0.424133\n",
      "Train Epoch: 5 [0/9140 (0%)]\tLoss: 0.326181\n",
      "Train Epoch: 5 [1000/9140 (11%)]\tLoss: 0.355249\n",
      "Train Epoch: 5 [2000/9140 (22%)]\tLoss: 0.347585\n",
      "Train Epoch: 5 [3000/9140 (33%)]\tLoss: 0.297529\n",
      "Train Epoch: 5 [4000/9140 (43%)]\tLoss: 0.423162\n",
      "Train Epoch: 5 [5000/9140 (54%)]\tLoss: 0.270761\n",
      "Train Epoch: 5 [6000/9140 (65%)]\tLoss: 0.360986\n",
      "Train Epoch: 5 [7000/9140 (76%)]\tLoss: 0.300871\n",
      "Train Epoch: 5 [8000/9140 (87%)]\tLoss: 0.427378\n",
      "Train Epoch: 5 [9000/9140 (98%)]\tLoss: 0.312288\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.418872\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.201671\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.239619\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.104456\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.165665\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.085043\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.138701\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.105199\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.098217\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.093609\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.103902\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.156919\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.149023\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.194430\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.149777\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.095689\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.185389\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.083590\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.101380\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.182204\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.216045\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.097041\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.170422\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.305923\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.148453\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.138183\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.224141\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.149049\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.128988\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.246946\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.086677\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.077226\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.121668\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.134656\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.381351\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.115508\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.126379\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.118747\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.063405\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.228083\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.331908\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.255043\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.249274\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.197807\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.157660\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.233692\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.123193\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.153973\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.255584\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.140545\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.217606\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.197236\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.283891\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.270024\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.329664\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.122009\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.184497\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.300262\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.217859\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.204163\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.322380\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.198312\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.403793\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.210085\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.185969\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.309210\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.256108\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.223856\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.124439\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.237017\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.217345\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.208432\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.202964\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.211141\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.271232\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.383304\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.258161\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.201903\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.332801\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.291200\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.486727\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.361436\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.239594\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.187067\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.139169\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.242927\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.200010\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.290672\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.274723\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.233545\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.175712\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.362558\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.225417\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.247929\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.214249\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.341456\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.190453\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.278510\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.322766\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.144702\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.190425\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.256607\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.189853\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.318778\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.212465\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.233151\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.335128\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.221877\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.182574\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.297008\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.224528\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.265298\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.240424\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.193705\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.232520\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.234583\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.363456\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.352477\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.343793\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.194699\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.251259\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.363971\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.264676\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.436326\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.242032\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.269578\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.187150\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.261024\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.369775\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.291934\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.251512\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.310094\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.266415\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.322203\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.299090\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.332462\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.234567\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.298880\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.293029\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.223040\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.315967\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.276148\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.372612\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.358206\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.347556\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.210543\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.359247\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.216180\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.227294\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.297883\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.379278\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.383006\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.214836\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.323903\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.361249\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.332502\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.355447\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.445305\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.364059\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.381974\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.483029\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.409992\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.347246\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.506456\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.336138\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.384280\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.482213\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.323947\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.254612\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.246570\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.482086\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.369935\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.438445\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.343785\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.242883\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.595974\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.317290\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.529685\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.303433\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.470127\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.324899\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.379311\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.383365\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.485563\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.262808\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.310144\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.383949\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.334227\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.520371\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.523257\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.315949\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.316875\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.347761\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.456729\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.450929\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.374441\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.310233\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.565875\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.382021\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.243621\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.237440\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.370272\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.306242\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.258853\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.510453\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/13300 (0%)]\tLoss: 0.472868\n",
      "Train Epoch: 1 [1000/13300 (8%)]\tLoss: 0.290971\n",
      "Train Epoch: 1 [2000/13300 (15%)]\tLoss: 0.273632\n",
      "Train Epoch: 1 [3000/13300 (23%)]\tLoss: 0.435243\n",
      "Train Epoch: 1 [4000/13300 (30%)]\tLoss: 0.158600\n",
      "Train Epoch: 1 [5000/13300 (38%)]\tLoss: 0.200116\n",
      "Train Epoch: 1 [6000/13300 (45%)]\tLoss: 0.315878\n",
      "Train Epoch: 1 [7000/13300 (53%)]\tLoss: 0.238537\n",
      "Train Epoch: 1 [8000/13300 (60%)]\tLoss: 0.393195\n",
      "Train Epoch: 1 [9000/13300 (68%)]\tLoss: 0.404287\n",
      "Train Epoch: 1 [10000/13300 (75%)]\tLoss: 0.292686\n",
      "Train Epoch: 1 [11000/13300 (83%)]\tLoss: 0.299744\n",
      "Train Epoch: 1 [12000/13300 (90%)]\tLoss: 0.320654\n",
      "Train Epoch: 1 [13000/13300 (98%)]\tLoss: 0.346306\n",
      "Train Epoch: 2 [0/13300 (0%)]\tLoss: 0.250915\n",
      "Train Epoch: 2 [1000/13300 (8%)]\tLoss: 0.227958\n",
      "Train Epoch: 2 [2000/13300 (15%)]\tLoss: 0.197226\n",
      "Train Epoch: 2 [3000/13300 (23%)]\tLoss: 0.304944\n",
      "Train Epoch: 2 [4000/13300 (30%)]\tLoss: 0.343024\n",
      "Train Epoch: 2 [5000/13300 (38%)]\tLoss: 0.277048\n",
      "Train Epoch: 2 [6000/13300 (45%)]\tLoss: 0.413898\n",
      "Train Epoch: 2 [7000/13300 (53%)]\tLoss: 0.331773\n",
      "Train Epoch: 2 [8000/13300 (60%)]\tLoss: 0.255518\n",
      "Train Epoch: 2 [9000/13300 (68%)]\tLoss: 0.348349\n",
      "Train Epoch: 2 [10000/13300 (75%)]\tLoss: 0.247038\n",
      "Train Epoch: 2 [11000/13300 (83%)]\tLoss: 0.345958\n",
      "Train Epoch: 2 [12000/13300 (90%)]\tLoss: 0.245476\n",
      "Train Epoch: 2 [13000/13300 (98%)]\tLoss: 0.286110\n",
      "Train Epoch: 3 [0/13300 (0%)]\tLoss: 0.417774\n",
      "Train Epoch: 3 [1000/13300 (8%)]\tLoss: 0.349824\n",
      "Train Epoch: 3 [2000/13300 (15%)]\tLoss: 0.272538\n",
      "Train Epoch: 3 [3000/13300 (23%)]\tLoss: 0.282646\n",
      "Train Epoch: 3 [4000/13300 (30%)]\tLoss: 0.239461\n",
      "Train Epoch: 3 [5000/13300 (38%)]\tLoss: 0.367206\n",
      "Train Epoch: 3 [6000/13300 (45%)]\tLoss: 0.278719\n",
      "Train Epoch: 3 [7000/13300 (53%)]\tLoss: 0.404919\n",
      "Train Epoch: 3 [8000/13300 (60%)]\tLoss: 0.257422\n",
      "Train Epoch: 3 [9000/13300 (68%)]\tLoss: 0.315199\n",
      "Train Epoch: 3 [10000/13300 (75%)]\tLoss: 0.410209\n",
      "Train Epoch: 3 [11000/13300 (83%)]\tLoss: 0.399675\n",
      "Train Epoch: 3 [12000/13300 (90%)]\tLoss: 0.260441\n",
      "Train Epoch: 3 [13000/13300 (98%)]\tLoss: 0.262661\n",
      "Train Epoch: 4 [0/13300 (0%)]\tLoss: 0.209174\n",
      "Train Epoch: 4 [1000/13300 (8%)]\tLoss: 0.190603\n",
      "Train Epoch: 4 [2000/13300 (15%)]\tLoss: 0.391998\n",
      "Train Epoch: 4 [3000/13300 (23%)]\tLoss: 0.377895\n",
      "Train Epoch: 4 [4000/13300 (30%)]\tLoss: 0.190017\n",
      "Train Epoch: 4 [5000/13300 (38%)]\tLoss: 0.355222\n",
      "Train Epoch: 4 [6000/13300 (45%)]\tLoss: 0.334030\n",
      "Train Epoch: 4 [7000/13300 (53%)]\tLoss: 0.269190\n",
      "Train Epoch: 4 [8000/13300 (60%)]\tLoss: 0.283119\n",
      "Train Epoch: 4 [9000/13300 (68%)]\tLoss: 0.289378\n",
      "Train Epoch: 4 [10000/13300 (75%)]\tLoss: 0.357980\n",
      "Train Epoch: 4 [11000/13300 (83%)]\tLoss: 0.250373\n",
      "Train Epoch: 4 [12000/13300 (90%)]\tLoss: 0.265132\n",
      "Train Epoch: 4 [13000/13300 (98%)]\tLoss: 0.242207\n",
      "Train Epoch: 5 [0/13300 (0%)]\tLoss: 0.340417\n",
      "Train Epoch: 5 [1000/13300 (8%)]\tLoss: 0.307935\n",
      "Train Epoch: 5 [2000/13300 (15%)]\tLoss: 0.278560\n",
      "Train Epoch: 5 [3000/13300 (23%)]\tLoss: 0.171478\n",
      "Train Epoch: 5 [4000/13300 (30%)]\tLoss: 0.318851\n",
      "Train Epoch: 5 [5000/13300 (38%)]\tLoss: 0.311028\n",
      "Train Epoch: 5 [6000/13300 (45%)]\tLoss: 0.186721\n",
      "Train Epoch: 5 [7000/13300 (53%)]\tLoss: 0.254735\n",
      "Train Epoch: 5 [8000/13300 (60%)]\tLoss: 0.225202\n",
      "Train Epoch: 5 [9000/13300 (68%)]\tLoss: 0.249404\n",
      "Train Epoch: 5 [10000/13300 (75%)]\tLoss: 0.356225\n",
      "Train Epoch: 5 [11000/13300 (83%)]\tLoss: 0.274488\n",
      "Train Epoch: 5 [12000/13300 (90%)]\tLoss: 0.334401\n",
      "Train Epoch: 5 [13000/13300 (98%)]\tLoss: 0.222362\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9310, Accuracy: 7575/10000 (76%)\n",
      "\n",
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.452428\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.377622\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.353107\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.299143\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.563788\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.422267\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.432249\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.377385\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.514512\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.312911\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.360489\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.440313\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.318003\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.401662\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.375455\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.472688\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.210349\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.176591\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.122694\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.118886\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.151034\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.226991\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.161890\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.179254\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.162830\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.112443\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.214737\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.158552\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.159334\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.131499\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.065875\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.167927\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.070640\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.171869\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.175586\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.057472\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.185979\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.169003\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.206799\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.076564\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.086469\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.174977\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.146365\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.176827\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.167863\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.112300\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.157449\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.171603\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.110803\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.156482\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.250303\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.132844\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.106944\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.125228\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.191672\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.417126\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.251763\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.232684\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.435469\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.349651\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.288270\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.237726\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.257617\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.260159\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.258097\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.199867\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.304830\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.229906\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.178925\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.119289\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.161020\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.203488\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.207894\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.099818\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.203512\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.160262\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.175820\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.177510\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.255790\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.240605\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.167800\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.267444\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.232587\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.131346\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.237996\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.168762\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.188453\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.212513\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.183621\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.138180\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.290193\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.323699\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.147446\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.224672\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.318745\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.279193\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.178645\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.261712\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.251982\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.207607\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.229393\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.267480\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.296617\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.322465\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.286482\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.257514\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.238238\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.356071\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.261651\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.274593\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.268930\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.295110\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.197382\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.258799\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.173147\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.280509\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.264181\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.222480\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.265585\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.240845\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.347560\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.277307\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.292575\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.366974\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.311996\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.300559\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.209188\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.295665\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.161941\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.275462\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.248251\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.275339\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.453908\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.257289\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.272885\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.342020\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.264699\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.260274\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.287210\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.227471\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.328233\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.290134\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.263225\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.304417\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.315183\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.290937\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.221874\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.363411\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.183265\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.181440\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.430543\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.190150\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.321541\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.351863\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.358496\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.273948\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.300445\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.278954\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.346483\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.251945\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.223410\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.410538\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.292345\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.270934\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.242146\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.306529\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.247039\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.309669\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.292555\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.313361\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.282630\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.410989\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.342910\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.347064\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.446148\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.456408\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.336392\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.690677\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.399746\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.395702\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.462962\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.544457\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.282205\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.491103\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.427655\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.304456\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.347424\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.359921\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.267231\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.275238\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.338950\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.436207\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.507011\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.336872\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.393345\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.318589\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.520223\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.297377\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.243369\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.321107\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.429703\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.284365\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.375575\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.342627\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.441267\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.295755\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.427190\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.363030\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.508814\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.499920\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.460124\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.254672\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.434538\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.364763\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.280816\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.520064\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.319328\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.497361\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.351066\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.402202\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.600655\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.272579\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.199300\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.295605\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.284046\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.221362\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.265096\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.284265\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.262868\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.186746\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.106304\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.201671\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.129003\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.213318\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.268756\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.130651\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.240998\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.307622\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.285619\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.196950\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.221117\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.296168\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.153364\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.187702\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.278964\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.214522\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.147218\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.267270\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.144899\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.215574\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.133290\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.314606\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.276137\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.168825\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.209723\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.474838\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.327434\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.386823\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.374141\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.326499\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.310771\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.286805\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.302209\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.310219\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.330304\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.272172\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.367891\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.308178\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.294321\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.334770\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.200057\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.351359\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.192979\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.358557\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.279370\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.279885\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.319100\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.282359\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.318334\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.360300\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.220171\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.200401\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.318917\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.222733\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.354620\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.338841\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.278586\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.272095\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.312071\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.285086\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.310057\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.324483\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.254540\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.387999\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.406544\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.287040\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.386510\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.225643\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.232672\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.185962\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.251162\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.188809\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.201262\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.183559\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.258640\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.262719\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.206455\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.206560\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.195775\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.263210\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.390777\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.317071\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.241951\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.145147\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.193219\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.247265\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.318901\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.318956\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.310925\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.324225\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.301504\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.414101\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.216838\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.192479\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.200708\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9813, Accuracy: 7478/10000 (75%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.507641\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.391037\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.373277\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.276895\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.346955\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.393273\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.310776\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.400627\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.537945\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.303220\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.504894\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.421342\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.405612\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.384321\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.374422\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.442573\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.232256\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.234667\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.212453\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.156881\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.124309\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.057974\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.178145\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.062320\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.135411\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.224789\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.190041\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.140269\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.113753\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.139770\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.097727\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.200853\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.082805\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.090123\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.105269\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.132976\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.092967\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.130308\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.213918\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.072654\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.071204\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.110358\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.087551\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.121192\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.159353\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.132324\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.121746\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.181018\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.147274\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.200395\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.123664\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.187619\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.117968\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.268362\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.092629\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.285787\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.145704\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.171367\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.156761\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.269524\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.278439\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.287589\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.205767\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.251398\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.358508\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.168138\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.324695\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.222154\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.286577\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.182554\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.194288\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.262060\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.191346\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.280538\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.238480\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.193239\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.238902\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.258167\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.184465\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.210155\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.263432\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.196003\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.205794\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.215876\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.199572\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.174288\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.268537\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.124883\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.280044\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.162930\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.305187\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.395553\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.196250\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.286648\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.260621\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.268458\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.287601\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.401727\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.226318\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.345413\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.135047\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.334314\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.205015\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.309937\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.313917\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.293589\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.260767\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.156644\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.249434\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.248922\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.137067\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.280244\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.263573\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.170606\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.196682\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.222292\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.318884\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.288588\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.216887\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.181657\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.314543\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.313173\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.255391\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.151815\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.307435\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.403803\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.244598\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.282785\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.255978\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.316784\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.294940\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.346652\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.342056\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.259497\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.207629\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.275681\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.402634\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.282989\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.177158\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.240762\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.284055\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.272190\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.149044\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.271810\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.343306\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.195577\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.218749\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.298173\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.387918\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.205827\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.392908\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.347838\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.345352\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.251021\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.351265\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.233170\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.274873\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.299542\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.336298\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.321430\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.320937\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.270162\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.385119\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.283871\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.248983\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.454933\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.361185\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.240030\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.272000\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.264937\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.385002\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.296469\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.463476\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.507883\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.319142\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.375292\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.369333\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.367130\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.388129\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.395332\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.398859\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.356848\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.343985\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.309889\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.442942\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.388095\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.473944\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.396968\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.337901\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.359460\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.212365\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.221838\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.318578\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.333642\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.540387\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.324788\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.282523\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.327864\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.333055\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.306151\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.384655\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.351333\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.264784\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.391157\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.351431\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.441998\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.216817\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.309003\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.289417\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.407733\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.368220\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.288362\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.424879\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.410158\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.452768\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.361276\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.343189\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.401596\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.405173\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.313304\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.379323\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.169409\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.299468\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.254272\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.157909\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.328783\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.195441\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.189366\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.164683\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.157978\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.179353\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.315365\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.120514\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.224434\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.201848\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.279955\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.221968\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.201642\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.178931\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.161054\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.160467\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.247501\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.246422\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.265503\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.213116\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.150650\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.122048\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.156897\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.286594\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.255101\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.201621\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.299081\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.216300\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.108018\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.105264\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.359501\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.328853\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.298549\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.461150\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.317880\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.287121\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.262327\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.276815\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.333526\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.321365\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.157581\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.397770\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.282003\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.347024\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.348922\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.425042\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.361417\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.223378\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.297647\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.396626\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.311673\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.163538\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.288019\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.373722\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.289023\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.354698\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.406017\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.305370\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.296151\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.298907\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.311496\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.212178\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.332690\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.406421\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.197376\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.384472\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.178213\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.293385\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.302509\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.233148\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.249370\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.293019\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.131432\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.302467\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.157930\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.193267\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.330334\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.233036\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.321160\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.248851\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.183051\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.309433\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.188622\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.415655\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.161747\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.445567\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.304114\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.155158\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.221935\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.237484\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.237675\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.247498\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.230407\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.225959\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.190596\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.303443\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.283361\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.242163\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.221408\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.183593\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 0.9935, Accuracy: 7482/10000 (75%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.396499\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.281448\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.342136\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.379229\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.437814\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.384457\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.299295\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.336855\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.354121\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.342670\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.364441\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.321286\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.362451\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.428677\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.438700\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.573526\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.128614\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.095292\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.197976\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.200784\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.171440\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.174197\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.149005\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.142781\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.181647\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.185490\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.076880\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.111970\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.063111\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.154299\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.173638\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.161210\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.223477\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.110528\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.309400\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.183685\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.235067\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.175094\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.125593\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.129397\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.163976\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.187447\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.157398\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.201410\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.063400\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.211168\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.107520\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.051253\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.154566\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.217574\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.145334\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.095684\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.192107\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.133763\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.154482\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.332078\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.196666\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.259375\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.233229\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.183123\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.225584\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.269701\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.184545\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.181644\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.144677\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.264685\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.234858\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.229079\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.176748\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.194525\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.165042\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.183687\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.199599\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.213771\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.226883\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.272231\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.176697\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.170734\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.172260\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.130719\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.185265\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.235660\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.282532\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.203204\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.153042\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.267650\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.233288\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.122971\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.168566\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.298319\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.332675\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.206841\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.308754\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.248236\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.238743\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.232112\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.255870\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.263923\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.273921\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.252775\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.295113\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.207275\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.306072\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.176462\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.259799\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.226224\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.176197\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.255585\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.173168\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.213498\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.341159\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.192259\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.241039\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.101704\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.295835\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.360433\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.157292\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.318642\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.260988\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.196957\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.415675\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.235573\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.293597\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.266856\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.330730\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.215634\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.205192\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.229208\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.327385\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.434991\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.325301\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.261710\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.300636\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.295580\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.209319\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.311569\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.284618\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.297763\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.215437\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.275633\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.323885\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.216386\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.276667\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.247020\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.272394\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.219272\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.161576\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.231729\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.280612\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.321803\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.386831\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.274644\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.300142\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.347448\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.356837\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.332216\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.315822\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.273177\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.403460\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.212164\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.371210\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.278174\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.196704\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.247621\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.285008\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.295522\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.268603\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.398564\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.188387\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.388687\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.428533\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.371873\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.314512\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.240028\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.510857\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.314071\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.279588\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.365647\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.389014\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.497827\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.376414\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.339425\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.285283\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.375977\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.277408\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.435311\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.417490\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.281552\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.376370\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.390386\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.500375\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.276863\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.346673\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.396769\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.406036\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.452177\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.307971\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.179474\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.381556\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.231122\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.381013\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.510752\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.373828\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.335361\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.398488\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.291170\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.427361\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.360620\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.344173\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.307048\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.475951\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.325355\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.270406\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.262148\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.499642\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.428196\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.289755\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.366409\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.315624\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.330185\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.485856\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.210912\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.240530\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.194350\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.252989\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.173088\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.180365\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.183912\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.224782\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.281242\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.103728\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.131829\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.143203\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.219956\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.258924\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.189870\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.144902\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.259671\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.106804\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.186207\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.340888\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.360533\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.178090\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.195806\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.112966\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.315627\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.146945\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.182854\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.384342\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.217641\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.152864\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.191211\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.166377\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.297788\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.175445\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.429870\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.266532\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.413605\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.292387\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.346347\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.301595\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.313768\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.334572\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.237074\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.253058\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.232929\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.196340\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.440939\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.194548\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.231124\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.261887\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.355800\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.291621\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.278660\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.242833\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.193455\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.392852\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.145940\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.229602\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.328336\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.270631\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.227747\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.229327\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.652792\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.269042\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.334064\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.309016\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.305838\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.258690\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.318872\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.380540\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.174341\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.319493\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.339296\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.139490\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.241279\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.257050\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.383455\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.187130\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.363356\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.266760\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.188001\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.241328\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.266217\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.225991\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.154716\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.459002\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.246706\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.362565\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.120745\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.201958\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.254373\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.329138\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.170711\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.201661\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.306027\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.272903\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.241144\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.322308\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.170786\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.425104\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.257253\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.274550\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.272832\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.216759\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.0345, Accuracy: 7430/10000 (74%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/2540 (0%)]\tLoss: 0.447070\n",
      "Train Epoch: 1 [1000/2540 (38%)]\tLoss: 0.723626\n",
      "Train Epoch: 1 [2000/2540 (77%)]\tLoss: 0.492055\n",
      "Train Epoch: 2 [0/2540 (0%)]\tLoss: 0.414633\n",
      "Train Epoch: 2 [1000/2540 (38%)]\tLoss: 0.361828\n",
      "Train Epoch: 2 [2000/2540 (77%)]\tLoss: 0.419948\n",
      "Train Epoch: 3 [0/2540 (0%)]\tLoss: 0.249920\n",
      "Train Epoch: 3 [1000/2540 (38%)]\tLoss: 0.366992\n",
      "Train Epoch: 3 [2000/2540 (77%)]\tLoss: 0.367373\n",
      "Train Epoch: 4 [0/2540 (0%)]\tLoss: 0.451406\n",
      "Train Epoch: 4 [1000/2540 (38%)]\tLoss: 0.354797\n",
      "Train Epoch: 4 [2000/2540 (77%)]\tLoss: 0.467754\n",
      "Train Epoch: 5 [0/2540 (0%)]\tLoss: 0.387980\n",
      "Train Epoch: 5 [1000/2540 (38%)]\tLoss: 0.320413\n",
      "Train Epoch: 5 [2000/2540 (77%)]\tLoss: 0.396725\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/7342 (0%)]\tLoss: 0.406020\n",
      "Train Epoch: 1 [1000/7342 (14%)]\tLoss: 0.166839\n",
      "Train Epoch: 1 [2000/7342 (27%)]\tLoss: 0.241085\n",
      "Train Epoch: 1 [3000/7342 (41%)]\tLoss: 0.143258\n",
      "Train Epoch: 1 [4000/7342 (54%)]\tLoss: 0.180612\n",
      "Train Epoch: 1 [5000/7342 (68%)]\tLoss: 0.089761\n",
      "Train Epoch: 1 [6000/7342 (81%)]\tLoss: 0.358183\n",
      "Train Epoch: 1 [7000/7342 (95%)]\tLoss: 0.271874\n",
      "Train Epoch: 2 [0/7342 (0%)]\tLoss: 0.118880\n",
      "Train Epoch: 2 [1000/7342 (14%)]\tLoss: 0.088543\n",
      "Train Epoch: 2 [2000/7342 (27%)]\tLoss: 0.143925\n",
      "Train Epoch: 2 [3000/7342 (41%)]\tLoss: 0.219329\n",
      "Train Epoch: 2 [4000/7342 (54%)]\tLoss: 0.117558\n",
      "Train Epoch: 2 [5000/7342 (68%)]\tLoss: 0.117036\n",
      "Train Epoch: 2 [6000/7342 (81%)]\tLoss: 0.156515\n",
      "Train Epoch: 2 [7000/7342 (95%)]\tLoss: 0.177263\n",
      "Train Epoch: 3 [0/7342 (0%)]\tLoss: 0.147041\n",
      "Train Epoch: 3 [1000/7342 (14%)]\tLoss: 0.153843\n",
      "Train Epoch: 3 [2000/7342 (27%)]\tLoss: 0.207976\n",
      "Train Epoch: 3 [3000/7342 (41%)]\tLoss: 0.121475\n",
      "Train Epoch: 3 [4000/7342 (54%)]\tLoss: 0.193287\n",
      "Train Epoch: 3 [5000/7342 (68%)]\tLoss: 0.147264\n",
      "Train Epoch: 3 [6000/7342 (81%)]\tLoss: 0.135004\n",
      "Train Epoch: 3 [7000/7342 (95%)]\tLoss: 0.113019\n",
      "Train Epoch: 4 [0/7342 (0%)]\tLoss: 0.070195\n",
      "Train Epoch: 4 [1000/7342 (14%)]\tLoss: 0.141377\n",
      "Train Epoch: 4 [2000/7342 (27%)]\tLoss: 0.151955\n",
      "Train Epoch: 4 [3000/7342 (41%)]\tLoss: 0.087965\n",
      "Train Epoch: 4 [4000/7342 (54%)]\tLoss: 0.101207\n",
      "Train Epoch: 4 [5000/7342 (68%)]\tLoss: 0.119053\n",
      "Train Epoch: 4 [6000/7342 (81%)]\tLoss: 0.049866\n",
      "Train Epoch: 4 [7000/7342 (95%)]\tLoss: 0.148118\n",
      "Train Epoch: 5 [0/7342 (0%)]\tLoss: 0.107309\n",
      "Train Epoch: 5 [1000/7342 (14%)]\tLoss: 0.183113\n",
      "Train Epoch: 5 [2000/7342 (27%)]\tLoss: 0.094372\n",
      "Train Epoch: 5 [3000/7342 (41%)]\tLoss: 0.242778\n",
      "Train Epoch: 5 [4000/7342 (54%)]\tLoss: 0.104812\n",
      "Train Epoch: 5 [5000/7342 (68%)]\tLoss: 0.170016\n",
      "Train Epoch: 5 [6000/7342 (81%)]\tLoss: 0.138696\n",
      "Train Epoch: 5 [7000/7342 (95%)]\tLoss: 0.148882\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/6412 (0%)]\tLoss: 0.371217\n",
      "Train Epoch: 1 [1000/6412 (15%)]\tLoss: 0.250037\n",
      "Train Epoch: 1 [2000/6412 (31%)]\tLoss: 0.320764\n",
      "Train Epoch: 1 [3000/6412 (46%)]\tLoss: 0.212359\n",
      "Train Epoch: 1 [4000/6412 (62%)]\tLoss: 0.339641\n",
      "Train Epoch: 1 [5000/6412 (77%)]\tLoss: 0.235172\n",
      "Train Epoch: 1 [6000/6412 (92%)]\tLoss: 0.248604\n",
      "Train Epoch: 2 [0/6412 (0%)]\tLoss: 0.198992\n",
      "Train Epoch: 2 [1000/6412 (15%)]\tLoss: 0.370043\n",
      "Train Epoch: 2 [2000/6412 (31%)]\tLoss: 0.207469\n",
      "Train Epoch: 2 [3000/6412 (46%)]\tLoss: 0.204646\n",
      "Train Epoch: 2 [4000/6412 (62%)]\tLoss: 0.146837\n",
      "Train Epoch: 2 [5000/6412 (77%)]\tLoss: 0.221250\n",
      "Train Epoch: 2 [6000/6412 (92%)]\tLoss: 0.184344\n",
      "Train Epoch: 3 [0/6412 (0%)]\tLoss: 0.194331\n",
      "Train Epoch: 3 [1000/6412 (15%)]\tLoss: 0.246538\n",
      "Train Epoch: 3 [2000/6412 (31%)]\tLoss: 0.254410\n",
      "Train Epoch: 3 [3000/6412 (46%)]\tLoss: 0.217600\n",
      "Train Epoch: 3 [4000/6412 (62%)]\tLoss: 0.135053\n",
      "Train Epoch: 3 [5000/6412 (77%)]\tLoss: 0.202234\n",
      "Train Epoch: 3 [6000/6412 (92%)]\tLoss: 0.376594\n",
      "Train Epoch: 4 [0/6412 (0%)]\tLoss: 0.244589\n",
      "Train Epoch: 4 [1000/6412 (15%)]\tLoss: 0.202266\n",
      "Train Epoch: 4 [2000/6412 (31%)]\tLoss: 0.180973\n",
      "Train Epoch: 4 [3000/6412 (46%)]\tLoss: 0.157581\n",
      "Train Epoch: 4 [4000/6412 (62%)]\tLoss: 0.154550\n",
      "Train Epoch: 4 [5000/6412 (77%)]\tLoss: 0.293545\n",
      "Train Epoch: 4 [6000/6412 (92%)]\tLoss: 0.152462\n",
      "Train Epoch: 5 [0/6412 (0%)]\tLoss: 0.261311\n",
      "Train Epoch: 5 [1000/6412 (15%)]\tLoss: 0.170869\n",
      "Train Epoch: 5 [2000/6412 (31%)]\tLoss: 0.247615\n",
      "Train Epoch: 5 [3000/6412 (46%)]\tLoss: 0.275671\n",
      "Train Epoch: 5 [4000/6412 (62%)]\tLoss: 0.284448\n",
      "Train Epoch: 5 [5000/6412 (77%)]\tLoss: 0.185271\n",
      "Train Epoch: 5 [6000/6412 (92%)]\tLoss: 0.325723\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/5470 (0%)]\tLoss: 0.425821\n",
      "Train Epoch: 1 [1000/5470 (18%)]\tLoss: 0.186965\n",
      "Train Epoch: 1 [2000/5470 (36%)]\tLoss: 0.100034\n",
      "Train Epoch: 1 [3000/5470 (55%)]\tLoss: 0.167950\n",
      "Train Epoch: 1 [4000/5470 (73%)]\tLoss: 0.277043\n",
      "Train Epoch: 1 [5000/5470 (91%)]\tLoss: 0.323658\n",
      "Train Epoch: 2 [0/5470 (0%)]\tLoss: 0.315834\n",
      "Train Epoch: 2 [1000/5470 (18%)]\tLoss: 0.192061\n",
      "Train Epoch: 2 [2000/5470 (36%)]\tLoss: 0.226112\n",
      "Train Epoch: 2 [3000/5470 (55%)]\tLoss: 0.195775\n",
      "Train Epoch: 2 [4000/5470 (73%)]\tLoss: 0.368251\n",
      "Train Epoch: 2 [5000/5470 (91%)]\tLoss: 0.233479\n",
      "Train Epoch: 3 [0/5470 (0%)]\tLoss: 0.239790\n",
      "Train Epoch: 3 [1000/5470 (18%)]\tLoss: 0.198777\n",
      "Train Epoch: 3 [2000/5470 (36%)]\tLoss: 0.234654\n",
      "Train Epoch: 3 [3000/5470 (55%)]\tLoss: 0.416837\n",
      "Train Epoch: 3 [4000/5470 (73%)]\tLoss: 0.201333\n",
      "Train Epoch: 3 [5000/5470 (91%)]\tLoss: 0.463334\n",
      "Train Epoch: 4 [0/5470 (0%)]\tLoss: 0.278638\n",
      "Train Epoch: 4 [1000/5470 (18%)]\tLoss: 0.235182\n",
      "Train Epoch: 4 [2000/5470 (36%)]\tLoss: 0.187392\n",
      "Train Epoch: 4 [3000/5470 (55%)]\tLoss: 0.195273\n",
      "Train Epoch: 4 [4000/5470 (73%)]\tLoss: 0.176765\n",
      "Train Epoch: 4 [5000/5470 (91%)]\tLoss: 0.261102\n",
      "Train Epoch: 5 [0/5470 (0%)]\tLoss: 0.251782\n",
      "Train Epoch: 5 [1000/5470 (18%)]\tLoss: 0.305057\n",
      "Train Epoch: 5 [2000/5470 (36%)]\tLoss: 0.246803\n",
      "Train Epoch: 5 [3000/5470 (55%)]\tLoss: 0.307049\n",
      "Train Epoch: 5 [4000/5470 (73%)]\tLoss: 0.168966\n",
      "Train Epoch: 5 [5000/5470 (91%)]\tLoss: 0.340071\n",
      "Training client 5\n",
      "Train Epoch: 1 [0/5114 (0%)]\tLoss: 0.272967\n",
      "Train Epoch: 1 [1000/5114 (19%)]\tLoss: 0.321072\n",
      "Train Epoch: 1 [2000/5114 (38%)]\tLoss: 0.270445\n",
      "Train Epoch: 1 [3000/5114 (58%)]\tLoss: 0.256693\n",
      "Train Epoch: 1 [4000/5114 (77%)]\tLoss: 0.399585\n",
      "Train Epoch: 1 [5000/5114 (96%)]\tLoss: 0.173456\n",
      "Train Epoch: 2 [0/5114 (0%)]\tLoss: 0.265964\n",
      "Train Epoch: 2 [1000/5114 (19%)]\tLoss: 0.198233\n",
      "Train Epoch: 2 [2000/5114 (38%)]\tLoss: 0.305692\n",
      "Train Epoch: 2 [3000/5114 (58%)]\tLoss: 0.270021\n",
      "Train Epoch: 2 [4000/5114 (77%)]\tLoss: 0.350352\n",
      "Train Epoch: 2 [5000/5114 (96%)]\tLoss: 0.230070\n",
      "Train Epoch: 3 [0/5114 (0%)]\tLoss: 0.213703\n",
      "Train Epoch: 3 [1000/5114 (19%)]\tLoss: 0.318769\n",
      "Train Epoch: 3 [2000/5114 (38%)]\tLoss: 0.275433\n",
      "Train Epoch: 3 [3000/5114 (58%)]\tLoss: 0.237027\n",
      "Train Epoch: 3 [4000/5114 (77%)]\tLoss: 0.161437\n",
      "Train Epoch: 3 [5000/5114 (96%)]\tLoss: 0.381816\n",
      "Train Epoch: 4 [0/5114 (0%)]\tLoss: 0.323764\n",
      "Train Epoch: 4 [1000/5114 (19%)]\tLoss: 0.163210\n",
      "Train Epoch: 4 [2000/5114 (38%)]\tLoss: 0.246611\n",
      "Train Epoch: 4 [3000/5114 (58%)]\tLoss: 0.235162\n",
      "Train Epoch: 4 [4000/5114 (77%)]\tLoss: 0.297323\n",
      "Train Epoch: 4 [5000/5114 (96%)]\tLoss: 0.320019\n",
      "Train Epoch: 5 [0/5114 (0%)]\tLoss: 0.338477\n",
      "Train Epoch: 5 [1000/5114 (19%)]\tLoss: 0.243606\n",
      "Train Epoch: 5 [2000/5114 (38%)]\tLoss: 0.206697\n",
      "Train Epoch: 5 [3000/5114 (58%)]\tLoss: 0.228634\n",
      "Train Epoch: 5 [4000/5114 (77%)]\tLoss: 0.191569\n",
      "Train Epoch: 5 [5000/5114 (96%)]\tLoss: 0.193249\n",
      "Training client 6\n",
      "Train Epoch: 1 [0/3395 (0%)]\tLoss: 0.453218\n",
      "Train Epoch: 1 [1000/3395 (29%)]\tLoss: 0.300318\n",
      "Train Epoch: 1 [2000/3395 (59%)]\tLoss: 0.333350\n",
      "Train Epoch: 1 [3000/3395 (88%)]\tLoss: 0.324718\n",
      "Train Epoch: 2 [0/3395 (0%)]\tLoss: 0.280990\n",
      "Train Epoch: 2 [1000/3395 (29%)]\tLoss: 0.299672\n",
      "Train Epoch: 2 [2000/3395 (59%)]\tLoss: 0.419497\n",
      "Train Epoch: 2 [3000/3395 (88%)]\tLoss: 0.306046\n",
      "Train Epoch: 3 [0/3395 (0%)]\tLoss: 0.219146\n",
      "Train Epoch: 3 [1000/3395 (29%)]\tLoss: 0.238966\n",
      "Train Epoch: 3 [2000/3395 (59%)]\tLoss: 0.305816\n",
      "Train Epoch: 3 [3000/3395 (88%)]\tLoss: 0.348552\n",
      "Train Epoch: 4 [0/3395 (0%)]\tLoss: 0.249192\n",
      "Train Epoch: 4 [1000/3395 (29%)]\tLoss: 0.323270\n",
      "Train Epoch: 4 [2000/3395 (59%)]\tLoss: 0.262586\n",
      "Train Epoch: 4 [3000/3395 (88%)]\tLoss: 0.244089\n",
      "Train Epoch: 5 [0/3395 (0%)]\tLoss: 0.338069\n",
      "Train Epoch: 5 [1000/3395 (29%)]\tLoss: 0.267389\n",
      "Train Epoch: 5 [2000/3395 (59%)]\tLoss: 0.259516\n",
      "Train Epoch: 5 [3000/3395 (88%)]\tLoss: 0.324926\n",
      "Training client 7\n",
      "Train Epoch: 1 [0/9827 (0%)]\tLoss: 0.433104\n",
      "Train Epoch: 1 [1000/9827 (10%)]\tLoss: 0.469906\n",
      "Train Epoch: 1 [2000/9827 (20%)]\tLoss: 0.319842\n",
      "Train Epoch: 1 [3000/9827 (30%)]\tLoss: 0.426699\n",
      "Train Epoch: 1 [4000/9827 (40%)]\tLoss: 0.193603\n",
      "Train Epoch: 1 [5000/9827 (51%)]\tLoss: 0.366576\n",
      "Train Epoch: 1 [6000/9827 (61%)]\tLoss: 0.346412\n",
      "Train Epoch: 1 [7000/9827 (71%)]\tLoss: 0.346510\n",
      "Train Epoch: 1 [8000/9827 (81%)]\tLoss: 0.388740\n",
      "Train Epoch: 1 [9000/9827 (91%)]\tLoss: 0.501674\n",
      "Train Epoch: 2 [0/9827 (0%)]\tLoss: 0.340894\n",
      "Train Epoch: 2 [1000/9827 (10%)]\tLoss: 0.365503\n",
      "Train Epoch: 2 [2000/9827 (20%)]\tLoss: 0.501203\n",
      "Train Epoch: 2 [3000/9827 (30%)]\tLoss: 0.449686\n",
      "Train Epoch: 2 [4000/9827 (40%)]\tLoss: 0.396840\n",
      "Train Epoch: 2 [5000/9827 (51%)]\tLoss: 0.379397\n",
      "Train Epoch: 2 [6000/9827 (61%)]\tLoss: 0.327676\n",
      "Train Epoch: 2 [7000/9827 (71%)]\tLoss: 0.405502\n",
      "Train Epoch: 2 [8000/9827 (81%)]\tLoss: 0.371983\n",
      "Train Epoch: 2 [9000/9827 (91%)]\tLoss: 0.390396\n",
      "Train Epoch: 3 [0/9827 (0%)]\tLoss: 0.499881\n",
      "Train Epoch: 3 [1000/9827 (10%)]\tLoss: 0.370687\n",
      "Train Epoch: 3 [2000/9827 (20%)]\tLoss: 0.277011\n",
      "Train Epoch: 3 [3000/9827 (30%)]\tLoss: 0.437064\n",
      "Train Epoch: 3 [4000/9827 (40%)]\tLoss: 0.384831\n",
      "Train Epoch: 3 [5000/9827 (51%)]\tLoss: 0.266008\n",
      "Train Epoch: 3 [6000/9827 (61%)]\tLoss: 0.463960\n",
      "Train Epoch: 3 [7000/9827 (71%)]\tLoss: 0.374279\n",
      "Train Epoch: 3 [8000/9827 (81%)]\tLoss: 0.364594\n",
      "Train Epoch: 3 [9000/9827 (91%)]\tLoss: 0.443318\n",
      "Train Epoch: 4 [0/9827 (0%)]\tLoss: 0.279107\n",
      "Train Epoch: 4 [1000/9827 (10%)]\tLoss: 0.291706\n",
      "Train Epoch: 4 [2000/9827 (20%)]\tLoss: 0.347161\n",
      "Train Epoch: 4 [3000/9827 (30%)]\tLoss: 0.401806\n",
      "Train Epoch: 4 [4000/9827 (40%)]\tLoss: 0.354779\n",
      "Train Epoch: 4 [5000/9827 (51%)]\tLoss: 0.429910\n",
      "Train Epoch: 4 [6000/9827 (61%)]\tLoss: 0.372309\n",
      "Train Epoch: 4 [7000/9827 (71%)]\tLoss: 0.302436\n",
      "Train Epoch: 4 [8000/9827 (81%)]\tLoss: 0.381559\n",
      "Train Epoch: 4 [9000/9827 (91%)]\tLoss: 0.363671\n",
      "Train Epoch: 5 [0/9827 (0%)]\tLoss: 0.361676\n",
      "Train Epoch: 5 [1000/9827 (10%)]\tLoss: 0.485781\n",
      "Train Epoch: 5 [2000/9827 (20%)]\tLoss: 0.273720\n",
      "Train Epoch: 5 [3000/9827 (30%)]\tLoss: 0.380320\n",
      "Train Epoch: 5 [4000/9827 (40%)]\tLoss: 0.354971\n",
      "Train Epoch: 5 [5000/9827 (51%)]\tLoss: 0.349389\n",
      "Train Epoch: 5 [6000/9827 (61%)]\tLoss: 0.391605\n",
      "Train Epoch: 5 [7000/9827 (71%)]\tLoss: 0.395070\n",
      "Train Epoch: 5 [8000/9827 (81%)]\tLoss: 0.242973\n",
      "Train Epoch: 5 [9000/9827 (91%)]\tLoss: 0.324817\n",
      "Training client 8\n",
      "Train Epoch: 1 [0/6482 (0%)]\tLoss: 0.423121\n",
      "Train Epoch: 1 [1000/6482 (15%)]\tLoss: 0.169122\n",
      "Train Epoch: 1 [2000/6482 (31%)]\tLoss: 0.210534\n",
      "Train Epoch: 1 [3000/6482 (46%)]\tLoss: 0.201816\n",
      "Train Epoch: 1 [4000/6482 (62%)]\tLoss: 0.187731\n",
      "Train Epoch: 1 [5000/6482 (77%)]\tLoss: 0.308688\n",
      "Train Epoch: 1 [6000/6482 (92%)]\tLoss: 0.113618\n",
      "Train Epoch: 2 [0/6482 (0%)]\tLoss: 0.176250\n",
      "Train Epoch: 2 [1000/6482 (15%)]\tLoss: 0.263494\n",
      "Train Epoch: 2 [2000/6482 (31%)]\tLoss: 0.275556\n",
      "Train Epoch: 2 [3000/6482 (46%)]\tLoss: 0.162880\n",
      "Train Epoch: 2 [4000/6482 (62%)]\tLoss: 0.109161\n",
      "Train Epoch: 2 [5000/6482 (77%)]\tLoss: 0.189463\n",
      "Train Epoch: 2 [6000/6482 (92%)]\tLoss: 0.159867\n",
      "Train Epoch: 3 [0/6482 (0%)]\tLoss: 0.270355\n",
      "Train Epoch: 3 [1000/6482 (15%)]\tLoss: 0.170680\n",
      "Train Epoch: 3 [2000/6482 (31%)]\tLoss: 0.230219\n",
      "Train Epoch: 3 [3000/6482 (46%)]\tLoss: 0.196196\n",
      "Train Epoch: 3 [4000/6482 (62%)]\tLoss: 0.186381\n",
      "Train Epoch: 3 [5000/6482 (77%)]\tLoss: 0.226131\n",
      "Train Epoch: 3 [6000/6482 (92%)]\tLoss: 0.203400\n",
      "Train Epoch: 4 [0/6482 (0%)]\tLoss: 0.178606\n",
      "Train Epoch: 4 [1000/6482 (15%)]\tLoss: 0.193461\n",
      "Train Epoch: 4 [2000/6482 (31%)]\tLoss: 0.150014\n",
      "Train Epoch: 4 [3000/6482 (46%)]\tLoss: 0.204323\n",
      "Train Epoch: 4 [4000/6482 (62%)]\tLoss: 0.091744\n",
      "Train Epoch: 4 [5000/6482 (77%)]\tLoss: 0.209983\n",
      "Train Epoch: 4 [6000/6482 (92%)]\tLoss: 0.188357\n",
      "Train Epoch: 5 [0/6482 (0%)]\tLoss: 0.200538\n",
      "Train Epoch: 5 [1000/6482 (15%)]\tLoss: 0.131543\n",
      "Train Epoch: 5 [2000/6482 (31%)]\tLoss: 0.274267\n",
      "Train Epoch: 5 [3000/6482 (46%)]\tLoss: 0.130739\n",
      "Train Epoch: 5 [4000/6482 (62%)]\tLoss: 0.325930\n",
      "Train Epoch: 5 [5000/6482 (77%)]\tLoss: 0.179287\n",
      "Train Epoch: 5 [6000/6482 (92%)]\tLoss: 0.162982\n",
      "Training client 9\n",
      "Train Epoch: 1 [0/6600 (0%)]\tLoss: 0.348217\n",
      "Train Epoch: 1 [1000/6600 (15%)]\tLoss: 0.263323\n",
      "Train Epoch: 1 [2000/6600 (30%)]\tLoss: 0.223440\n",
      "Train Epoch: 1 [3000/6600 (45%)]\tLoss: 0.332158\n",
      "Train Epoch: 1 [4000/6600 (61%)]\tLoss: 0.203751\n",
      "Train Epoch: 1 [5000/6600 (76%)]\tLoss: 0.211004\n",
      "Train Epoch: 1 [6000/6600 (91%)]\tLoss: 0.330528\n",
      "Train Epoch: 2 [0/6600 (0%)]\tLoss: 0.430282\n",
      "Train Epoch: 2 [1000/6600 (15%)]\tLoss: 0.295577\n",
      "Train Epoch: 2 [2000/6600 (30%)]\tLoss: 0.344945\n",
      "Train Epoch: 2 [3000/6600 (45%)]\tLoss: 0.273367\n",
      "Train Epoch: 2 [4000/6600 (61%)]\tLoss: 0.241656\n",
      "Train Epoch: 2 [5000/6600 (76%)]\tLoss: 0.311263\n",
      "Train Epoch: 2 [6000/6600 (91%)]\tLoss: 0.345120\n",
      "Train Epoch: 3 [0/6600 (0%)]\tLoss: 0.224638\n",
      "Train Epoch: 3 [1000/6600 (15%)]\tLoss: 0.285789\n",
      "Train Epoch: 3 [2000/6600 (30%)]\tLoss: 0.332009\n",
      "Train Epoch: 3 [3000/6600 (45%)]\tLoss: 0.312107\n",
      "Train Epoch: 3 [4000/6600 (61%)]\tLoss: 0.326749\n",
      "Train Epoch: 3 [5000/6600 (76%)]\tLoss: 0.309516\n",
      "Train Epoch: 3 [6000/6600 (91%)]\tLoss: 0.296890\n",
      "Train Epoch: 4 [0/6600 (0%)]\tLoss: 0.282270\n",
      "Train Epoch: 4 [1000/6600 (15%)]\tLoss: 0.231067\n",
      "Train Epoch: 4 [2000/6600 (30%)]\tLoss: 0.362588\n",
      "Train Epoch: 4 [3000/6600 (45%)]\tLoss: 0.395376\n",
      "Train Epoch: 4 [4000/6600 (61%)]\tLoss: 0.212270\n",
      "Train Epoch: 4 [5000/6600 (76%)]\tLoss: 0.221939\n",
      "Train Epoch: 4 [6000/6600 (91%)]\tLoss: 0.210268\n",
      "Train Epoch: 5 [0/6600 (0%)]\tLoss: 0.447888\n",
      "Train Epoch: 5 [1000/6600 (15%)]\tLoss: 0.317852\n",
      "Train Epoch: 5 [2000/6600 (30%)]\tLoss: 0.310616\n",
      "Train Epoch: 5 [3000/6600 (45%)]\tLoss: 0.254550\n",
      "Train Epoch: 5 [4000/6600 (61%)]\tLoss: 0.268646\n",
      "Train Epoch: 5 [5000/6600 (76%)]\tLoss: 0.269886\n",
      "Train Epoch: 5 [6000/6600 (91%)]\tLoss: 0.184934\n",
      "Training client 10\n",
      "Train Epoch: 1 [0/6818 (0%)]\tLoss: 0.298494\n",
      "Train Epoch: 1 [1000/6818 (14%)]\tLoss: 0.273613\n",
      "Train Epoch: 1 [2000/6818 (29%)]\tLoss: 0.432729\n",
      "Train Epoch: 1 [3000/6818 (43%)]\tLoss: 0.169647\n",
      "Train Epoch: 1 [4000/6818 (58%)]\tLoss: 0.331034\n",
      "Train Epoch: 1 [5000/6818 (72%)]\tLoss: 0.239820\n",
      "Train Epoch: 1 [6000/6818 (87%)]\tLoss: 0.205381\n",
      "Train Epoch: 2 [0/6818 (0%)]\tLoss: 0.446801\n",
      "Train Epoch: 2 [1000/6818 (14%)]\tLoss: 0.177039\n",
      "Train Epoch: 2 [2000/6818 (29%)]\tLoss: 0.313492\n",
      "Train Epoch: 2 [3000/6818 (43%)]\tLoss: 0.222606\n",
      "Train Epoch: 2 [4000/6818 (58%)]\tLoss: 0.308158\n",
      "Train Epoch: 2 [5000/6818 (72%)]\tLoss: 0.176331\n",
      "Train Epoch: 2 [6000/6818 (87%)]\tLoss: 0.320234\n",
      "Train Epoch: 3 [0/6818 (0%)]\tLoss: 0.236000\n",
      "Train Epoch: 3 [1000/6818 (14%)]\tLoss: 0.339288\n",
      "Train Epoch: 3 [2000/6818 (29%)]\tLoss: 0.370367\n",
      "Train Epoch: 3 [3000/6818 (43%)]\tLoss: 0.218564\n",
      "Train Epoch: 3 [4000/6818 (58%)]\tLoss: 0.149566\n",
      "Train Epoch: 3 [5000/6818 (72%)]\tLoss: 0.372823\n",
      "Train Epoch: 3 [6000/6818 (87%)]\tLoss: 0.249615\n",
      "Train Epoch: 4 [0/6818 (0%)]\tLoss: 0.289767\n",
      "Train Epoch: 4 [1000/6818 (14%)]\tLoss: 0.226181\n",
      "Train Epoch: 4 [2000/6818 (29%)]\tLoss: 0.237945\n",
      "Train Epoch: 4 [3000/6818 (43%)]\tLoss: 0.237665\n",
      "Train Epoch: 4 [4000/6818 (58%)]\tLoss: 0.353594\n",
      "Train Epoch: 4 [5000/6818 (72%)]\tLoss: 0.248709\n",
      "Train Epoch: 4 [6000/6818 (87%)]\tLoss: 0.278683\n",
      "Train Epoch: 5 [0/6818 (0%)]\tLoss: 0.211331\n",
      "Train Epoch: 5 [1000/6818 (14%)]\tLoss: 0.313828\n",
      "Train Epoch: 5 [2000/6818 (29%)]\tLoss: 0.209733\n",
      "Train Epoch: 5 [3000/6818 (43%)]\tLoss: 0.243224\n",
      "Train Epoch: 5 [4000/6818 (58%)]\tLoss: 0.296387\n",
      "Train Epoch: 5 [5000/6818 (72%)]\tLoss: 0.185247\n",
      "Train Epoch: 5 [6000/6818 (87%)]\tLoss: 0.166397\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      "), MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "10\n",
      "local_models in the distribute function [MultilayerPerceptron(\n",
      "  (fc1): Linear(in_features=784, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.0435, Accuracy: 7418/10000 (74%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "partitioned_data_auto = partition.balanced_dirichlet_partition(trainingset_auto, partitions_number=num_clients, alpha=alpha)\n",
    "auto_client_loaders = [\n",
    "    DataLoader(Subset(trainingset_auto, indices), batch_size=batch_size_train, shuffle=True)\n",
    "    for indices in partitioned_data_auto.values()\n",
    "]\n",
    "\n",
    "local_model_autoencoder_strong = [copy.deepcopy(global_model_auto_strong) for _ in range(num_clients)]\n",
    "\n",
    "optimizer = optim.SGD(trial_model_auto_strong.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):  \n",
    "    train_fashion(epoch, trial_model_auto_strong, reduced_train_loader_auto, optimizer, log_interval, train_losses, train_counter)\n",
    "\n",
    "test_losses_auto_strong = []\n",
    "test_fashion(trial_model_auto_strong, reduced_train_loader_auto, test_losses_auto_strong)\n",
    "\n",
    "rounds_auto = 4\n",
    "for round_idx in range(rounds_auto):\n",
    "    print(f\"Round {round_idx + 1}/{rounds_auto}\")\n",
    "    \n",
    "    local_weights_auto = []\n",
    "    for client_idx, client_model in enumerate(local_model_autoencoder_strong):\n",
    "        print(f\"Training client {client_idx + 1}\")\n",
    "        \n",
    "        optimizer = optim.SGD(client_model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        \n",
    "        train_losses = []\n",
    "        train_counter = []\n",
    "    \n",
    "        for epoch in range(1, n_epochs + 1):  \n",
    "            train_fashion(epoch, client_model, auto_client_loaders[client_idx], optimizer, log_interval, train_losses, train_counter)\n",
    "        \n",
    "        client_weights = [param.data.numpy() for param in client_model.parameters()]\n",
    "        local_weights_auto.append(client_weights)\n",
    "    \n",
    "    global_weights_auto = federated_averaging(local_weights_auto)\n",
    "    \n",
    "    distribute_global_model(global_weights_auto, local_model_autoencoder_strong, single=False)\n",
    "    distribute_global_model(global_weights_auto, global_model_auto_strong, single=True)\n",
    "    \n",
    "    test_losses = []\n",
    "    test_fashion(global_model_auto_strong, test_loader_auto, test_losses)\n",
    "    \n",
    "    test_accuracies_classic = []\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader_auto:\n",
    "            data = data.view(data.shape[0], -1)\n",
    "            output = global_model_auto_strong(data)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "    accuracy = 100. * correct / len(test_loader_auto.dataset)\n",
    "    test_accuracies_classic.append(accuracy)\n",
    "    \n",
    "    # Save results for non-clustered classic\n",
    "    results[\"autoencoder\"][\"NoCluster\"] = {\"losses\": [], \"accuracy\": []}\n",
    "    \n",
    "    results[\"autoencoder\"][\"NoCluster\"][\"losses\"].extend(test_losses)\n",
    "    results[\"autoencoder\"][\"NoCluster\"][\"accuracy\"].extend(test_accuracies_classic)\n",
    "\n",
    "    ######################\n",
    "    # Clustering process\n",
    "for num_cluster in num_clusters:\n",
    "    import cluster2\n",
    "\n",
    "    targets = trainingset.targets\n",
    "    num_classes = len(set(targets)) \n",
    "    # Erstelle Clients\n",
    "    clients = [cluster2.FederatedClient(cid, indices, targets, num_classes) for cid, indices in partitioned_data_auto.items()]\n",
    "    \n",
    "    # Jeder Client berechnet seine Labelverteilung\n",
    "    client_distributions = [client.compute_label_distribution() for client in clients]\n",
    "    \n",
    "    # Server fhrt Clustering durch\n",
    "    server = cluster2.FederatedClusterServer(num_cluster)\n",
    "    aggregated_data = server.aggregate_client_data(client_distributions)\n",
    "    clustered_data = server.perform_greedy_clustering(aggregated_data, partitioned_data_auto)\n",
    "    \n",
    "    partitioned_data_auto_clustered = clustered_data\n",
    "    \"\"\"\n",
    "    \n",
    "    import cluster\n",
    "    cluster = cluster.Cluster(num_clusters=num_cluster)\n",
    "    \n",
    "    targets = trainingset_auto.targets\n",
    "    num_classes = len(set(targets)) \n",
    "    clustered_data = cluster.apply_clustering(partitioned_data_auto, targets, num_classes)\n",
    "    \n",
    "    partitioned_data_auto_clustered = clustered_data\n",
    "    \"\"\"\n",
    "    \n",
    "    auto_client_loaders_clustered = [\n",
    "        DataLoader(Subset(trainingset_auto, indices), batch_size=batch_size_train, shuffle=True)\n",
    "        for indices in partitioned_data_auto_clustered.values()\n",
    "    ]\n",
    "    \n",
    "    for round_idx in range(rounds_auto):\n",
    "        print(f\"Round {round_idx + 1}/{rounds_auto}\")\n",
    "        \n",
    "        local_weights_auto = []\n",
    "        for client_idx, client_model in enumerate(local_model_autoencoder_strong[0:num_cluster]):\n",
    "            print(f\"Training client {client_idx + 1}\")\n",
    "            \n",
    "            optimizer = optim.SGD(client_model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "            \n",
    "            train_losses = []\n",
    "            train_counter = []\n",
    "        \n",
    "            for epoch in range(1, n_epochs + 1):  \n",
    "                train_fashion(epoch, client_model, auto_client_loaders_clustered[client_idx], optimizer, log_interval, train_losses, train_counter)\n",
    "            \n",
    "            client_weights = [param.data.numpy() for param in client_model.parameters()]\n",
    "            local_weights_auto.append(client_weights)\n",
    "        \n",
    "        global_weights_auto = federated_averaging(local_weights_auto)\n",
    "        \n",
    "        distribute_global_model(global_weights_auto, local_model_autoencoder_strong, single=False)\n",
    "        distribute_global_model(global_weights_auto, global_model_auto_strong, single=True)\n",
    "        \n",
    "        test_losses = []\n",
    "        test_fashion(global_model_auto_strong, test_loader_auto, test_losses)\n",
    "        \n",
    "        test_accuracies_classic = []\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader_auto:\n",
    "                data = data.view(data.shape[0], -1)\n",
    "                output = global_model_auto_strong(data)\n",
    "                pred = output.data.max(1, keepdim=True)[1]\n",
    "                correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "        accuracy = 100. * correct / len(test_loader_auto.dataset)\n",
    "        test_accuracies_classic.append(accuracy)\n",
    "        \n",
    "        # Save results for clustered classic\n",
    "        if num_cluster not in clusteredResults[\"autoencoder\"]:\n",
    "            clusteredResults[\"autoencoder\"][num_cluster] = {\"losses\": [], \"accuracy\": []}\n",
    "\n",
    "        clusteredResults[\"autoencoder\"][num_cluster][\"losses\"].extend(test_losses)\n",
    "        clusteredResults[\"autoencoder\"][num_cluster][\"accuracy\"].extend(test_accuracies_classic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results (Non-Clustered): {'classic': {'NoCluster': {'losses': [0.5188619812011719], 'accuracy': [80.19]}}, 'pca': {'NoCluster': {'losses': [0.9589244445800781], 'accuracy': [82.98]}}, 'autoencoder': {'NoCluster': {'losses': [0.9626321166992188], 'accuracy': [69.05]}}}\n",
      "Final Results (Clustered): {'classic': {2: {'losses': [0.6111913330078125, 0.5729868041992188, 0.5778576416015625, 0.5886122863769532], 'accuracy': [77.31, 78.64, 78.81, 78.37]}, 4: {'losses': [0.5569269927978515, 0.5164715148925781, 0.5319765411376953, 0.5280328765869141], 'accuracy': [79.38, 80.76, 80.22, 80.34]}, 6: {'losses': [0.4632906616210937, 0.4644641296386719, 0.4652772644042969, 0.44572009887695313], 'accuracy': [82.79, 82.6, 82.67, 83.38]}, 8: {'losses': [0.4280053955078125, 0.4304277587890625, 0.41870563354492185, 0.41287210998535157], 'accuracy': [84.37, 84.18, 84.51, 85.12]}, 10: {'losses': [0.4158003601074219, 0.4127583312988281, 0.4012933013916016, 0.39449208984375], 'accuracy': [84.9, 84.82, 85.3, 85.84]}}, 'pca': {2: {'losses': [0.9835310729980469, 0.9530772888183594, 0.9494121459960938, 0.9241965759277344], 'accuracy': [82.98, 78.18, 82.98, 78.18, 79.27, 82.98, 78.18, 79.27, 78.92, 82.98, 78.18, 79.27, 78.92, 79.95]}, 4: {'losses': [0.9022241882324219, 0.8804853637695312, 0.8694283996582032, 0.8524799865722656], 'accuracy': [82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 81.74, 82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 81.74, 80.67, 82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 81.74, 80.67, 81.83]}, 6: {'losses': [0.843761083984375, 0.8239902954101562, 0.8075113098144531, 0.7894371398925781], 'accuracy': [82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 81.74, 80.67, 81.83, 83.77, 82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 81.74, 80.67, 81.83, 83.77, 84.13, 82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 81.74, 80.67, 81.83, 83.77, 84.13, 84.63, 82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 81.74, 80.67, 81.83, 83.77, 84.13, 84.63, 84.85]}, 8: {'losses': [0.7941073120117188, 0.7832655151367187, 0.7690023315429687, 0.7600245178222657], 'accuracy': [82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 81.74, 80.67, 81.83, 83.77, 84.13, 84.63, 84.85, 85.56, 82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 81.74, 80.67, 81.83, 83.77, 84.13, 84.63, 84.85, 85.56, 85.05, 82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 81.74, 80.67, 81.83, 83.77, 84.13, 84.63, 84.85, 85.56, 85.05, 85.99, 82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 81.74, 80.67, 81.83, 83.77, 84.13, 84.63, 84.85, 85.56, 85.05, 85.99, 85.62]}, 10: {'losses': [0.7523985046386719, 0.7419623474121094, 0.7239168029785156, 0.7174635925292969], 'accuracy': [82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 81.74, 80.67, 81.83, 83.77, 84.13, 84.63, 84.85, 85.56, 85.05, 85.99, 85.62, 86.01, 82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 81.74, 80.67, 81.83, 83.77, 84.13, 84.63, 84.85, 85.56, 85.05, 85.99, 85.62, 86.01, 86.05, 82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 81.74, 80.67, 81.83, 83.77, 84.13, 84.63, 84.85, 85.56, 85.05, 85.99, 85.62, 86.01, 86.05, 86.49, 82.98, 78.18, 79.27, 78.92, 79.95, 81.16, 81.74, 80.67, 81.83, 83.77, 84.13, 84.63, 84.85, 85.56, 85.05, 85.99, 85.62, 86.01, 86.05, 86.49, 86.49]}}, 'autoencoder': {2: {'losses': [0.8754416198730469, 0.8261541687011719, 0.8267806396484375, 0.8536565979003906], 'accuracy': [74.36, 75.99, 76.68, 76.21]}, 4: {'losses': [0.7712946411132813, 0.86146513671875, 0.8042761962890626, 0.8359471923828125], 'accuracy': [78.04, 76.4, 77.81, 77.25]}, 6: {'losses': [0.8393199279785156, 0.8608291259765625, 0.865208056640625, 0.8986694763183594], 'accuracy': [77.22, 76.77, 76.76, 76.37]}, 8: {'losses': [0.9012599182128906, 0.8864687133789062, 0.9199573547363281, 0.9309667236328125], 'accuracy': [76.21, 76.59, 76.05, 75.75]}, 10: {'losses': [0.9812873229980469, 0.9935104248046875, 1.034534375, 1.043503204345703], 'accuracy': [74.78, 74.82, 74.3, 74.18]}}}\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Results (Non-Clustered):\", results)\n",
    "print(\"Final Results (Clustered):\", clusteredResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Non-Clustered Results:\n",
      "classic:\n",
      "  Average Loss: {'NoCluster': 0.5188619812011719}\n",
      "  Average Accuracy: {'NoCluster': 80.19}\n",
      "pca:\n",
      "  Average Loss: {'NoCluster': 0.9589244445800781}\n",
      "  Average Accuracy: {'NoCluster': 82.98}\n",
      "autoencoder:\n",
      "  Average Loss: {'NoCluster': 0.9626321166992188}\n",
      "  Average Accuracy: {'NoCluster': 69.05}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clustered Results:\n",
      "classic:\n",
      "  Average Loss: {2: 0.5876620162963867, 4: 0.5333519813537598, 6: 0.4596880386352539, 8: 0.42250272445678716, 10: 0.4060860206604004}\n",
      "  Average Accuracy: {2: 78.2825, 4: 80.175, 6: 82.86, 8: 84.545, 10: 85.215}\n",
      "pca:\n",
      "  Average Loss: {2: 0.9525542709350585, 4: 0.8761544845581055, 6: 0.8161749572753907, 8: 0.776599919128418, 10: 0.7339353118896486}\n",
      "  Average Accuracy: {2: 80.01714285714286, 4: 80.34099999999998, 6: 81.31260869565217, 8: 82.31145161290323, 10: 83.06230769230767}\n",
      "autoencoder:\n",
      "  Average Loss: {2: 0.8455082565307617, 4: 0.8182457916259765, 6: 0.8660066467285156, 8: 0.9096631774902344, 10: 1.0132088317871095}\n",
      "  Average Accuracy: {2: 75.81, 4: 77.375, 6: 76.78, 8: 76.15, 10: 74.52}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_avg(metrics):\n",
    "    avg_loss = {alpha: np.mean(data['losses']) for alpha, data in metrics.items()}\n",
    "    avg_accuracy = {alpha: np.mean(data['accuracy']) for alpha, data in metrics.items()}\n",
    "    return avg_loss, avg_accuracy\n",
    "\n",
    "def print_results(results, title):\n",
    "    print(f\"\\n{title}:\")\n",
    "    for method in results.keys():\n",
    "        avg_loss, avg_accuracy = compute_avg(results[method])\n",
    "        print(f\"{method}:\")\n",
    "        print(\"  Average Loss:\", avg_loss)\n",
    "        print(\"  Average Accuracy:\", avg_accuracy)\n",
    "\n",
    "def plot_results(results, title, filename):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Loss Plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for method in results.keys():\n",
    "        avg_loss, _ = compute_avg(results[method])\n",
    "        plt.plot(avg_loss.keys(), avg_loss.values(), marker='o', label=method)\n",
    "    plt.xlabel('clients')\n",
    "    plt.ylabel('Average Loss')\n",
    "    plt.title(f'{title}')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Accuracy Plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for method in results.keys():\n",
    "        _, avg_accuracy = compute_avg(results[method])\n",
    "        plt.plot(avg_accuracy.keys(), avg_accuracy.values(), marker='o', label=method)\n",
    "    plt.xlabel('clients')\n",
    "    plt.ylabel('Average Accuracy')\n",
    "    plt.title(f'{title}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print_results(results, \"Non-Clustered Results\")\n",
    "plot_results(results, \"Non-Clustered Results\", \"non_clustered_results.png\")\n",
    "print_results(clusteredResults, \"Clustered Results\")\n",
    "plot_results(clusteredResults, \"Clustered Results\", \"clustered_results.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
