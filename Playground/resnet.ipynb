{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset,TensorDataset\n",
    "from autoencoder import Autoencoder\n",
    "from cifar_autoencoder import Cifar_Autoencoder\n",
    "import torchvision\n",
    "from model2 import classification_model\n",
    "from model import cifar_classification_model\n",
    "import copy\n",
    "import partition\n",
    "from pca import PCADigitReducer\n",
    "from autoencoder import reduce_dimensions\n",
    "from training import train,test,train_resnet,test_resnet\n",
    "from federated_learning import distribute_global_model, federated_averaging\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.models import mobilenet_v2\n",
    "from model3 import MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\micha\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\micha\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\micha/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "c:\\Users\\micha\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model2 = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = MobileNetV2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1eba64e09f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predefined stuff\n",
    "\n",
    "n_epochs = 8\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "num_clusters = 2\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar10_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))  # https://pytorch.org/hub/pytorch_vision_resnet/\n",
    "])\n",
    "\n",
    "cifar10_train_loader = DataLoader(\n",
    "    datasets.CIFAR10('/files/', train=True, download=True, transform=cifar10_transform),\n",
    "    batch_size=batch_size_train, shuffle=True\n",
    ")\n",
    "\n",
    "cifar10_test_loader = DataLoader(\n",
    "    datasets.CIFAR10('/files/', train=False, download=True, transform=cifar10_transform),\n",
    "    batch_size=batch_size_test, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTensorDataset(TensorDataset):\n",
    "    def __init__(self, *tensors):\n",
    "        super().__init__(*tensors)\n",
    "        self.data = tensors[0]\n",
    "        self.targets = tensors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_pca = copy.copy(cifar10_train_loader)\n",
    "test_loader_pca = copy.copy(cifar10_test_loader)\n",
    "\n",
    "train_loader_auto = copy.copy(cifar10_train_loader)\n",
    "test_loader_auto = copy.copy(cifar10_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "train_labels = []\n",
    "for data, labels in train_loader_pca:  # Use your CIFAR-10 DataLoader here\n",
    "    train_data.append(data.view(data.size(0), -1))  # Flatten images\n",
    "    train_labels.append(labels)\n",
    "train_data = torch.cat(train_data, dim=0)  # Combine all batches\n",
    "train_labels = torch.cat(train_labels, dim=0)\n",
    "\n",
    "# Convert to numpy for PCA\n",
    "train_data_np = train_data.numpy()\n",
    "\n",
    "# Perform PCA\n",
    "n_components = 100  # Set the desired number of components\n",
    "pca = PCADigitReducer(n_components)\n",
    "train_data_reduced = pca.fit_transform(train_data_np)  # Reduce dimensions\n",
    "\n",
    "# Reconstruct the dataset from the reduced dimensions\n",
    "train_data_reconstructed_np = pca.inverse_transform(train_data_reduced) \n",
    "train_data_reconstructed = torch.tensor(train_data_reconstructed_np, dtype=torch.float32)\n",
    "\n",
    "# Reshape the reconstructed data back into the original image dimensions\n",
    "train_data_reconstructed = train_data_reconstructed.view(-1, 3, 32, 32)\n",
    "\n",
    "# Normalize the reconstructed dataset (use CIFAR-10 mean and std)\n",
    "train_data_reconstructed = (train_data_reconstructed - torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)) / \\\n",
    "                           torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)\n",
    "\n",
    "# Create a new DataLoader for the reconstructed data\n",
    "batch_size_train = cifar10_train_loader.batch_size\n",
    "train_dataset_pca = CustomTensorDataset(train_data_reconstructed, train_labels)\n",
    "train_loader_reduced_pca = DataLoader(train_dataset_pca, batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.7032589912414551\n",
      "Epoch [2/5], Loss: 0.7096912860870361\n",
      "Epoch [3/5], Loss: 0.6233389377593994\n",
      "Epoch [4/5], Loss: 0.5864422917366028\n",
      "Epoch [5/5], Loss: 0.6471503376960754\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 100  # Adjust latent dimension as needed\n",
    "autoencoder = Cifar_Autoencoder(latent_dim=latent_dim)\n",
    "auto_criterion = nn.MSELoss()\n",
    "auto_optimizer = torch.optim.Adam(autoencoder.parameters(), lr=1e-3)\n",
    "auto_num_epochs = 5\n",
    "\n",
    "for epoch in range(auto_num_epochs):\n",
    "    for images, _ in cifar10_train_loader:  # Use your CIFAR-10 DataLoader here\n",
    "        auto_optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        reconstructed = autoencoder(images)\n",
    "        \n",
    "        # Compute reconstruction loss\n",
    "        loss = auto_criterion(reconstructed, images)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        auto_optimizer.step()\n",
    "        \n",
    "    print(f\"Epoch [{epoch+1}/{auto_num_epochs}], Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.eval()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "latent_features, labels = reduce_dimensions(train_loader_auto, autoencoder.encoder, device)\n",
    "latent_features = latent_features.detach()\n",
    "\n",
    "reconstructed_images = autoencoder.decoder(latent_features.to(device))  \n",
    "reconstructed_images = reconstructed_images.view(-1, 3, 32, 32) # Reshape to [batch_size, channels, height, width]\n",
    "\n",
    "reconstructed_dataset = CustomTensorDataset(reconstructed_images.cpu(), labels)  \n",
    "reduced_train_loader_auto = DataLoader(reconstructed_dataset, batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18580\n",
      "9043\n",
      "14723\n",
      "7654\n"
     ]
    }
   ],
   "source": [
    "# Now partition them into 4 clients for federated learning\n",
    "# pca 4 clients\n",
    "trainingset_pca = train_loader_reduced_pca.dataset\n",
    "partitioned_data_pca = partition.balanced_dirichlet_partition(trainingset_pca, partitions_number=4, alpha=0.5)\n",
    "# Check sizes\n",
    "\n",
    "for i in partitioned_data_pca:\n",
    "    print(len(partitioned_data_pca[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_client_loaders = [\n",
    "    DataLoader(Subset(trainingset_pca, indices), batch_size=batch_size_train, shuffle=True)\n",
    "    for indices in partitioned_data_pca.values()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classic\n",
    "trainingset = cifar10_train_loader.dataset\n",
    "partitioned_data_classic = partition.balanced_dirichlet_partition(trainingset, partitions_number=4, alpha=0.5)\n",
    "\n",
    "classic_client_loaders = [\n",
    "    DataLoader(Subset(trainingset, indices), batch_size=batch_size_train, shuffle=True)\n",
    "    for indices in partitioned_data_classic.values()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto 4 clients\n",
    "trainingset_auto = reduced_train_loader_auto.dataset\n",
    "partitioned_data_auto = partition.balanced_dirichlet_partition(trainingset_auto, partitions_number=4, alpha=0.5)\n",
    "\n",
    "auto_client_loaders = [\n",
    "    DataLoader(Subset(trainingset_auto, indices), batch_size=batch_size_train, shuffle=True)\n",
    "    for indices in partitioned_data_auto.values()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining model for pca and autoencoder\n",
    "\n",
    "global_model_pca = model\n",
    "global_model_auto = model\n",
    "gloabl_model_classic = model\n",
    "\n",
    "num_clients = 4\n",
    "# classic model\n",
    "local_models_classic = [copy.deepcopy(global_model_pca) for _ in range(num_clients)]\n",
    "# pca models \n",
    "local_models_pca = [copy.deepcopy(global_model_pca) for _ in range(num_clients)]\n",
    "# autoencodere models\n",
    "local_model_autoencoder = [copy.deepcopy(global_model_pca) for _ in range(num_clients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "testmodel = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 0.042231\n",
      "Train Epoch: 1 [640/50000 (1%)]\tLoss: 0.069573\n",
      "Train Epoch: 1 [1280/50000 (3%)]\tLoss: 0.011470\n",
      "Train Epoch: 1 [1920/50000 (4%)]\tLoss: 0.003030\n",
      "Train Epoch: 1 [2560/50000 (5%)]\tLoss: 0.007982\n",
      "Train Epoch: 1 [3200/50000 (6%)]\tLoss: 0.004587\n",
      "Train Epoch: 1 [3840/50000 (8%)]\tLoss: 0.007837\n",
      "Train Epoch: 1 [4480/50000 (9%)]\tLoss: 0.046453\n",
      "Train Epoch: 1 [5120/50000 (10%)]\tLoss: 0.001544\n",
      "Train Epoch: 1 [5760/50000 (12%)]\tLoss: 0.026832\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 0.073292\n",
      "Train Epoch: 1 [7040/50000 (14%)]\tLoss: 0.015311\n",
      "Train Epoch: 1 [7680/50000 (15%)]\tLoss: 0.002939\n",
      "Train Epoch: 1 [8320/50000 (17%)]\tLoss: 0.010287\n",
      "Train Epoch: 1 [8960/50000 (18%)]\tLoss: 0.013606\n",
      "Train Epoch: 1 [9600/50000 (19%)]\tLoss: 0.021687\n",
      "Train Epoch: 1 [10240/50000 (20%)]\tLoss: 0.007346\n",
      "Train Epoch: 1 [10880/50000 (22%)]\tLoss: 0.021030\n",
      "Train Epoch: 1 [11520/50000 (23%)]\tLoss: 0.007495\n",
      "Train Epoch: 1 [12160/50000 (24%)]\tLoss: 0.050750\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 0.009993\n",
      "Train Epoch: 1 [13440/50000 (27%)]\tLoss: 0.002609\n",
      "Train Epoch: 1 [14080/50000 (28%)]\tLoss: 0.040326\n",
      "Train Epoch: 1 [14720/50000 (29%)]\tLoss: 0.014331\n",
      "Train Epoch: 1 [15360/50000 (31%)]\tLoss: 0.053423\n",
      "Train Epoch: 1 [16000/50000 (32%)]\tLoss: 0.059069\n",
      "Train Epoch: 1 [16640/50000 (33%)]\tLoss: 0.052719\n",
      "Train Epoch: 1 [17280/50000 (35%)]\tLoss: 0.023989\n",
      "Train Epoch: 1 [17920/50000 (36%)]\tLoss: 0.015963\n",
      "Train Epoch: 1 [18560/50000 (37%)]\tLoss: 0.007637\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 0.001131\n",
      "Train Epoch: 1 [19840/50000 (40%)]\tLoss: 0.007135\n",
      "Train Epoch: 1 [20480/50000 (41%)]\tLoss: 0.010245\n",
      "Train Epoch: 1 [21120/50000 (42%)]\tLoss: 0.014326\n",
      "Train Epoch: 1 [21760/50000 (43%)]\tLoss: 0.050434\n",
      "Train Epoch: 1 [22400/50000 (45%)]\tLoss: 0.032212\n",
      "Train Epoch: 1 [23040/50000 (46%)]\tLoss: 0.029500\n",
      "Train Epoch: 1 [23680/50000 (47%)]\tLoss: 0.059318\n",
      "Train Epoch: 1 [24320/50000 (49%)]\tLoss: 0.018030\n",
      "Train Epoch: 1 [24960/50000 (50%)]\tLoss: 0.014508\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 0.024704\n",
      "Train Epoch: 1 [26240/50000 (52%)]\tLoss: 0.008665\n",
      "Train Epoch: 1 [26880/50000 (54%)]\tLoss: 0.010553\n",
      "Train Epoch: 1 [27520/50000 (55%)]\tLoss: 0.091027\n",
      "Train Epoch: 1 [28160/50000 (56%)]\tLoss: 0.050958\n",
      "Train Epoch: 1 [28800/50000 (58%)]\tLoss: 0.012399\n",
      "Train Epoch: 1 [29440/50000 (59%)]\tLoss: 0.089381\n",
      "Train Epoch: 1 [30080/50000 (60%)]\tLoss: 0.016894\n",
      "Train Epoch: 1 [30720/50000 (61%)]\tLoss: 0.009712\n",
      "Train Epoch: 1 [31360/50000 (63%)]\tLoss: 0.007761\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 0.054151\n",
      "Train Epoch: 1 [32640/50000 (65%)]\tLoss: 0.008536\n",
      "Train Epoch: 1 [33280/50000 (66%)]\tLoss: 0.050190\n",
      "Train Epoch: 1 [33920/50000 (68%)]\tLoss: 0.064061\n",
      "Train Epoch: 1 [34560/50000 (69%)]\tLoss: 0.052713\n",
      "Train Epoch: 1 [35200/50000 (70%)]\tLoss: 0.047530\n",
      "Train Epoch: 1 [35840/50000 (72%)]\tLoss: 0.000626\n",
      "Train Epoch: 1 [36480/50000 (73%)]\tLoss: 0.010858\n",
      "Train Epoch: 1 [37120/50000 (74%)]\tLoss: 0.027813\n",
      "Train Epoch: 1 [37760/50000 (75%)]\tLoss: 0.140112\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 0.006244\n",
      "Train Epoch: 1 [39040/50000 (78%)]\tLoss: 0.055212\n",
      "Train Epoch: 1 [39680/50000 (79%)]\tLoss: 0.005012\n",
      "Train Epoch: 1 [40320/50000 (81%)]\tLoss: 0.071942\n",
      "Train Epoch: 1 [40960/50000 (82%)]\tLoss: 0.018456\n",
      "Train Epoch: 1 [41600/50000 (83%)]\tLoss: 0.051387\n",
      "Train Epoch: 1 [42240/50000 (84%)]\tLoss: 0.044359\n",
      "Train Epoch: 1 [42880/50000 (86%)]\tLoss: 0.044429\n",
      "Train Epoch: 1 [43520/50000 (87%)]\tLoss: 0.097307\n",
      "Train Epoch: 1 [44160/50000 (88%)]\tLoss: 0.086032\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 0.049500\n",
      "Train Epoch: 1 [45440/50000 (91%)]\tLoss: 0.030189\n",
      "Train Epoch: 1 [46080/50000 (92%)]\tLoss: 0.019617\n",
      "Train Epoch: 1 [46720/50000 (93%)]\tLoss: 0.110848\n",
      "Train Epoch: 1 [47360/50000 (95%)]\tLoss: 0.031651\n",
      "Train Epoch: 1 [48000/50000 (96%)]\tLoss: 0.063964\n",
      "Train Epoch: 1 [48640/50000 (97%)]\tLoss: 0.005788\n",
      "Train Epoch: 1 [49280/50000 (98%)]\tLoss: 0.009650\n",
      "Train Epoch: 1 [49920/50000 (100%)]\tLoss: 0.004078\n",
      "\n",
      "Test set: Avg. loss: 1.1432, Accuracy: 7910/10000 (79%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 0.069051\n",
      "Train Epoch: 2 [640/50000 (1%)]\tLoss: 0.037357\n",
      "Train Epoch: 2 [1280/50000 (3%)]\tLoss: 0.171327\n",
      "Train Epoch: 2 [1920/50000 (4%)]\tLoss: 0.032423\n",
      "Train Epoch: 2 [2560/50000 (5%)]\tLoss: 0.035900\n",
      "Train Epoch: 2 [3200/50000 (6%)]\tLoss: 0.052270\n",
      "Train Epoch: 2 [3840/50000 (8%)]\tLoss: 0.028400\n",
      "Train Epoch: 2 [4480/50000 (9%)]\tLoss: 0.011112\n",
      "Train Epoch: 2 [5120/50000 (10%)]\tLoss: 0.078950\n",
      "Train Epoch: 2 [5760/50000 (12%)]\tLoss: 0.072576\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 0.059555\n",
      "Train Epoch: 2 [7040/50000 (14%)]\tLoss: 0.013156\n",
      "Train Epoch: 2 [7680/50000 (15%)]\tLoss: 0.084482\n",
      "Train Epoch: 2 [8320/50000 (17%)]\tLoss: 0.006403\n",
      "Train Epoch: 2 [8960/50000 (18%)]\tLoss: 0.055149\n",
      "Train Epoch: 2 [9600/50000 (19%)]\tLoss: 0.029252\n",
      "Train Epoch: 2 [10240/50000 (20%)]\tLoss: 0.013107\n",
      "Train Epoch: 2 [10880/50000 (22%)]\tLoss: 0.027439\n",
      "Train Epoch: 2 [11520/50000 (23%)]\tLoss: 0.025217\n",
      "Train Epoch: 2 [12160/50000 (24%)]\tLoss: 0.016368\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 0.025126\n",
      "Train Epoch: 2 [13440/50000 (27%)]\tLoss: 0.010342\n",
      "Train Epoch: 2 [14080/50000 (28%)]\tLoss: 0.009947\n",
      "Train Epoch: 2 [14720/50000 (29%)]\tLoss: 0.006046\n",
      "Train Epoch: 2 [15360/50000 (31%)]\tLoss: 0.002342\n",
      "Train Epoch: 2 [16000/50000 (32%)]\tLoss: 0.026251\n",
      "Train Epoch: 2 [16640/50000 (33%)]\tLoss: 0.003745\n",
      "Train Epoch: 2 [17280/50000 (35%)]\tLoss: 0.097317\n",
      "Train Epoch: 2 [17920/50000 (36%)]\tLoss: 0.013628\n",
      "Train Epoch: 2 [18560/50000 (37%)]\tLoss: 0.008068\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 0.006175\n",
      "Train Epoch: 2 [19840/50000 (40%)]\tLoss: 0.109907\n",
      "Train Epoch: 2 [20480/50000 (41%)]\tLoss: 0.030890\n",
      "Train Epoch: 2 [21120/50000 (42%)]\tLoss: 0.020704\n",
      "Train Epoch: 2 [21760/50000 (43%)]\tLoss: 0.045273\n",
      "Train Epoch: 2 [22400/50000 (45%)]\tLoss: 0.024206\n",
      "Train Epoch: 2 [23040/50000 (46%)]\tLoss: 0.023948\n",
      "Train Epoch: 2 [23680/50000 (47%)]\tLoss: 0.007045\n",
      "Train Epoch: 2 [24320/50000 (49%)]\tLoss: 0.015294\n",
      "Train Epoch: 2 [24960/50000 (50%)]\tLoss: 0.020270\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 0.078973\n",
      "Train Epoch: 2 [26240/50000 (52%)]\tLoss: 0.020262\n",
      "Train Epoch: 2 [26880/50000 (54%)]\tLoss: 0.132411\n",
      "Train Epoch: 2 [27520/50000 (55%)]\tLoss: 0.023724\n",
      "Train Epoch: 2 [28160/50000 (56%)]\tLoss: 0.037483\n",
      "Train Epoch: 2 [28800/50000 (58%)]\tLoss: 0.036562\n",
      "Train Epoch: 2 [29440/50000 (59%)]\tLoss: 0.044607\n",
      "Train Epoch: 2 [30080/50000 (60%)]\tLoss: 0.010455\n",
      "Train Epoch: 2 [30720/50000 (61%)]\tLoss: 0.122799\n",
      "Train Epoch: 2 [31360/50000 (63%)]\tLoss: 0.030435\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 0.008426\n",
      "Train Epoch: 2 [32640/50000 (65%)]\tLoss: 0.072825\n",
      "Train Epoch: 2 [33280/50000 (66%)]\tLoss: 0.059590\n",
      "Train Epoch: 2 [33920/50000 (68%)]\tLoss: 0.049747\n",
      "Train Epoch: 2 [34560/50000 (69%)]\tLoss: 0.083888\n",
      "Train Epoch: 2 [35200/50000 (70%)]\tLoss: 0.072774\n",
      "Train Epoch: 2 [35840/50000 (72%)]\tLoss: 0.096270\n",
      "Train Epoch: 2 [36480/50000 (73%)]\tLoss: 0.045405\n",
      "Train Epoch: 2 [37120/50000 (74%)]\tLoss: 0.119132\n",
      "Train Epoch: 2 [37760/50000 (75%)]\tLoss: 0.013722\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 0.023059\n",
      "Train Epoch: 2 [39040/50000 (78%)]\tLoss: 0.118162\n",
      "Train Epoch: 2 [39680/50000 (79%)]\tLoss: 0.082115\n",
      "Train Epoch: 2 [40320/50000 (81%)]\tLoss: 0.024928\n",
      "Train Epoch: 2 [40960/50000 (82%)]\tLoss: 0.040473\n",
      "Train Epoch: 2 [41600/50000 (83%)]\tLoss: 0.007001\n",
      "Train Epoch: 2 [42240/50000 (84%)]\tLoss: 0.086697\n",
      "Train Epoch: 2 [42880/50000 (86%)]\tLoss: 0.025716\n",
      "Train Epoch: 2 [43520/50000 (87%)]\tLoss: 0.008298\n",
      "Train Epoch: 2 [44160/50000 (88%)]\tLoss: 0.064746\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 0.007590\n",
      "Train Epoch: 2 [45440/50000 (91%)]\tLoss: 0.013441\n",
      "Train Epoch: 2 [46080/50000 (92%)]\tLoss: 0.045245\n",
      "Train Epoch: 2 [46720/50000 (93%)]\tLoss: 0.075291\n",
      "Train Epoch: 2 [47360/50000 (95%)]\tLoss: 0.024743\n",
      "Train Epoch: 2 [48000/50000 (96%)]\tLoss: 0.024364\n",
      "Train Epoch: 2 [48640/50000 (97%)]\tLoss: 0.027307\n",
      "Train Epoch: 2 [49280/50000 (98%)]\tLoss: 0.075431\n",
      "Train Epoch: 2 [49920/50000 (100%)]\tLoss: 0.032887\n",
      "\n",
      "Test set: Avg. loss: 1.1585, Accuracy: 7877/10000 (79%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 0.029000\n",
      "Train Epoch: 3 [640/50000 (1%)]\tLoss: 0.033422\n",
      "Train Epoch: 3 [1280/50000 (3%)]\tLoss: 0.099352\n",
      "Train Epoch: 3 [1920/50000 (4%)]\tLoss: 0.069717\n",
      "Train Epoch: 3 [2560/50000 (5%)]\tLoss: 0.015541\n",
      "Train Epoch: 3 [3200/50000 (6%)]\tLoss: 0.110713\n",
      "Train Epoch: 3 [3840/50000 (8%)]\tLoss: 0.060968\n",
      "Train Epoch: 3 [4480/50000 (9%)]\tLoss: 0.010295\n",
      "Train Epoch: 3 [5120/50000 (10%)]\tLoss: 0.143816\n",
      "Train Epoch: 3 [5760/50000 (12%)]\tLoss: 0.071559\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 0.109072\n",
      "Train Epoch: 3 [7040/50000 (14%)]\tLoss: 0.091405\n",
      "Train Epoch: 3 [7680/50000 (15%)]\tLoss: 0.026532\n",
      "Train Epoch: 3 [8320/50000 (17%)]\tLoss: 0.120255\n",
      "Train Epoch: 3 [8960/50000 (18%)]\tLoss: 0.079308\n",
      "Train Epoch: 3 [9600/50000 (19%)]\tLoss: 0.012277\n",
      "Train Epoch: 3 [10240/50000 (20%)]\tLoss: 0.004587\n",
      "Train Epoch: 3 [10880/50000 (22%)]\tLoss: 0.035629\n",
      "Train Epoch: 3 [11520/50000 (23%)]\tLoss: 0.042051\n",
      "Train Epoch: 3 [12160/50000 (24%)]\tLoss: 0.036951\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 0.066809\n",
      "Train Epoch: 3 [13440/50000 (27%)]\tLoss: 0.003909\n",
      "Train Epoch: 3 [14080/50000 (28%)]\tLoss: 0.008028\n",
      "Train Epoch: 3 [14720/50000 (29%)]\tLoss: 0.012891\n",
      "Train Epoch: 3 [15360/50000 (31%)]\tLoss: 0.011687\n",
      "Train Epoch: 3 [16000/50000 (32%)]\tLoss: 0.017170\n",
      "Train Epoch: 3 [16640/50000 (33%)]\tLoss: 0.193209\n",
      "Train Epoch: 3 [17280/50000 (35%)]\tLoss: 0.002472\n",
      "Train Epoch: 3 [17920/50000 (36%)]\tLoss: 0.011896\n",
      "Train Epoch: 3 [18560/50000 (37%)]\tLoss: 0.027393\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 0.088412\n",
      "Train Epoch: 3 [19840/50000 (40%)]\tLoss: 0.147835\n",
      "Train Epoch: 3 [20480/50000 (41%)]\tLoss: 0.028323\n",
      "Train Epoch: 3 [21120/50000 (42%)]\tLoss: 0.018781\n",
      "Train Epoch: 3 [21760/50000 (43%)]\tLoss: 0.023360\n",
      "Train Epoch: 3 [22400/50000 (45%)]\tLoss: 0.066341\n",
      "Train Epoch: 3 [23040/50000 (46%)]\tLoss: 0.098813\n",
      "Train Epoch: 3 [23680/50000 (47%)]\tLoss: 0.044982\n",
      "Train Epoch: 3 [24320/50000 (49%)]\tLoss: 0.075912\n",
      "Train Epoch: 3 [24960/50000 (50%)]\tLoss: 0.023937\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.163157\n",
      "Train Epoch: 3 [26240/50000 (52%)]\tLoss: 0.104761\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m train_counter \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, n_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):  \n\u001b[1;32m----> 8\u001b[0m     train_resnet(epoch, model, cifar10_train_loader, optimizer, log_interval, train_losses, train_counter)\n\u001b[0;32m      9\u001b[0m     test_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     10\u001b[0m     test_resnet(model,test_loader_pca,test_losses)\n",
      "File \u001b[1;32mc:\\Users\\micha\\Downloads\\Federated-Dimensionality-Reduction\\training.py:47\u001b[0m, in \u001b[0;36mtrain_resnet\u001b[1;34m(epoch, network, train_loader, optimizer, log_interval, train_losses, train_counter)\u001b[0m\n\u001b[0;32m     45\u001b[0m output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog_softmax(network(data), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Apply log-softmax\u001b[39;00m\n\u001b[0;32m     46\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnll_loss(output, target)  \u001b[38;5;66;03m# Compute negative log-likelihood loss\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     48\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_idx \u001b[38;5;241m%\u001b[39m log_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\micha\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    527\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\micha\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m _engine_run_backward(\n\u001b[0;32m    268\u001b[0m     tensors,\n\u001b[0;32m    269\u001b[0m     grad_tensors_,\n\u001b[0;32m    270\u001b[0m     retain_graph,\n\u001b[0;32m    271\u001b[0m     create_graph,\n\u001b[0;32m    272\u001b[0m     inputs,\n\u001b[0;32m    273\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    274\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\micha\\anaconda3\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):  \n",
    "    train_resnet(epoch, model, cifar10_train_loader, optimizer, log_interval, train_losses, train_counter)\n",
    "    test_losses = []\n",
    "    test_resnet(model,test_loader_pca,test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 0.050591\n",
      "Train Epoch: 1 [640/50000 (1%)]\tLoss: 0.108985\n",
      "Train Epoch: 1 [1280/50000 (3%)]\tLoss: 0.126027\n",
      "Train Epoch: 1 [1920/50000 (4%)]\tLoss: 0.117060\n",
      "Train Epoch: 1 [2560/50000 (5%)]\tLoss: 0.216151\n",
      "Train Epoch: 1 [3200/50000 (6%)]\tLoss: 0.053155\n",
      "Train Epoch: 1 [3840/50000 (8%)]\tLoss: 0.125457\n",
      "Train Epoch: 1 [4480/50000 (9%)]\tLoss: 0.098552\n",
      "Train Epoch: 1 [5120/50000 (10%)]\tLoss: 0.107360\n",
      "Train Epoch: 1 [5760/50000 (12%)]\tLoss: 0.071858\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 0.073997\n",
      "Train Epoch: 1 [7040/50000 (14%)]\tLoss: 0.215753\n",
      "Train Epoch: 1 [7680/50000 (15%)]\tLoss: 0.227913\n",
      "Train Epoch: 1 [8320/50000 (17%)]\tLoss: 0.097784\n",
      "Train Epoch: 1 [8960/50000 (18%)]\tLoss: 0.162740\n",
      "Train Epoch: 1 [9600/50000 (19%)]\tLoss: 0.174905\n",
      "Train Epoch: 1 [10240/50000 (20%)]\tLoss: 0.156967\n",
      "Train Epoch: 1 [10880/50000 (22%)]\tLoss: 0.151476\n",
      "Train Epoch: 1 [11520/50000 (23%)]\tLoss: 0.196193\n",
      "Train Epoch: 1 [12160/50000 (24%)]\tLoss: 0.174179\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 0.256151\n",
      "Train Epoch: 1 [13440/50000 (27%)]\tLoss: 0.145697\n",
      "Train Epoch: 1 [14080/50000 (28%)]\tLoss: 0.105575\n",
      "Train Epoch: 1 [14720/50000 (29%)]\tLoss: 0.200837\n",
      "Train Epoch: 1 [15360/50000 (31%)]\tLoss: 0.263938\n",
      "Train Epoch: 1 [16000/50000 (32%)]\tLoss: 0.139694\n",
      "Train Epoch: 1 [16640/50000 (33%)]\tLoss: 0.180957\n",
      "Train Epoch: 1 [17280/50000 (35%)]\tLoss: 0.158500\n",
      "Train Epoch: 1 [17920/50000 (36%)]\tLoss: 0.231289\n",
      "Train Epoch: 1 [18560/50000 (37%)]\tLoss: 0.150967\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 0.077527\n",
      "Train Epoch: 1 [19840/50000 (40%)]\tLoss: 0.180317\n",
      "Train Epoch: 1 [20480/50000 (41%)]\tLoss: 0.149994\n",
      "Train Epoch: 1 [21120/50000 (42%)]\tLoss: 0.168458\n",
      "Train Epoch: 1 [21760/50000 (43%)]\tLoss: 0.341006\n",
      "Train Epoch: 1 [22400/50000 (45%)]\tLoss: 0.201842\n",
      "Train Epoch: 1 [23040/50000 (46%)]\tLoss: 0.129844\n",
      "Train Epoch: 1 [23680/50000 (47%)]\tLoss: 0.256979\n",
      "Train Epoch: 1 [24320/50000 (49%)]\tLoss: 0.209880\n",
      "Train Epoch: 1 [24960/50000 (50%)]\tLoss: 0.174592\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 0.329460\n",
      "Train Epoch: 1 [26240/50000 (52%)]\tLoss: 0.279910\n",
      "Train Epoch: 1 [26880/50000 (54%)]\tLoss: 0.123262\n",
      "Train Epoch: 1 [27520/50000 (55%)]\tLoss: 0.237650\n",
      "Train Epoch: 1 [28160/50000 (56%)]\tLoss: 0.069176\n",
      "Train Epoch: 1 [28800/50000 (58%)]\tLoss: 0.134153\n",
      "Train Epoch: 1 [29440/50000 (59%)]\tLoss: 0.274315\n",
      "Train Epoch: 1 [30080/50000 (60%)]\tLoss: 0.235493\n",
      "Train Epoch: 1 [30720/50000 (61%)]\tLoss: 0.163733\n",
      "Train Epoch: 1 [31360/50000 (63%)]\tLoss: 0.215430\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 0.304959\n",
      "Train Epoch: 1 [32640/50000 (65%)]\tLoss: 0.212586\n",
      "Train Epoch: 1 [33280/50000 (66%)]\tLoss: 0.121259\n",
      "Train Epoch: 1 [33920/50000 (68%)]\tLoss: 0.088836\n",
      "Train Epoch: 1 [34560/50000 (69%)]\tLoss: 0.171989\n",
      "Train Epoch: 1 [35200/50000 (70%)]\tLoss: 0.155582\n",
      "Train Epoch: 1 [35840/50000 (72%)]\tLoss: 0.199142\n",
      "Train Epoch: 1 [36480/50000 (73%)]\tLoss: 0.259885\n",
      "Train Epoch: 1 [37120/50000 (74%)]\tLoss: 0.292579\n",
      "Train Epoch: 1 [37760/50000 (75%)]\tLoss: 0.052703\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 0.129718\n",
      "Train Epoch: 1 [39040/50000 (78%)]\tLoss: 0.315168\n",
      "Train Epoch: 1 [39680/50000 (79%)]\tLoss: 0.119345\n",
      "Train Epoch: 1 [40320/50000 (81%)]\tLoss: 0.217552\n",
      "Train Epoch: 1 [40960/50000 (82%)]\tLoss: 0.162099\n",
      "Train Epoch: 1 [41600/50000 (83%)]\tLoss: 0.192307\n",
      "Train Epoch: 1 [42240/50000 (84%)]\tLoss: 0.240363\n",
      "Train Epoch: 1 [42880/50000 (86%)]\tLoss: 0.120117\n",
      "Train Epoch: 1 [43520/50000 (87%)]\tLoss: 0.276718\n",
      "Train Epoch: 1 [44160/50000 (88%)]\tLoss: 0.349665\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 0.252467\n",
      "Train Epoch: 1 [45440/50000 (91%)]\tLoss: 0.185179\n",
      "Train Epoch: 1 [46080/50000 (92%)]\tLoss: 0.183894\n",
      "Train Epoch: 1 [46720/50000 (93%)]\tLoss: 0.143428\n",
      "Train Epoch: 1 [47360/50000 (95%)]\tLoss: 0.137332\n",
      "Train Epoch: 1 [48000/50000 (96%)]\tLoss: 0.286984\n",
      "Train Epoch: 1 [48640/50000 (97%)]\tLoss: 0.063742\n",
      "Train Epoch: 1 [49280/50000 (98%)]\tLoss: 0.256932\n",
      "Train Epoch: 1 [49920/50000 (100%)]\tLoss: 0.302204\n",
      "\n",
      "Test set: Avg. loss: 0.8699, Accuracy: 7756/10000 (78%)\n",
      "\n",
      "Train Epoch: 2 [0/50000 (0%)]\tLoss: 0.040455\n",
      "Train Epoch: 2 [640/50000 (1%)]\tLoss: 0.272946\n",
      "Train Epoch: 2 [1280/50000 (3%)]\tLoss: 0.111723\n",
      "Train Epoch: 2 [1920/50000 (4%)]\tLoss: 0.078339\n",
      "Train Epoch: 2 [2560/50000 (5%)]\tLoss: 0.195478\n",
      "Train Epoch: 2 [3200/50000 (6%)]\tLoss: 0.116418\n",
      "Train Epoch: 2 [3840/50000 (8%)]\tLoss: 0.070881\n",
      "Train Epoch: 2 [4480/50000 (9%)]\tLoss: 0.060590\n",
      "Train Epoch: 2 [5120/50000 (10%)]\tLoss: 0.195175\n",
      "Train Epoch: 2 [5760/50000 (12%)]\tLoss: 0.084978\n",
      "Train Epoch: 2 [6400/50000 (13%)]\tLoss: 0.095172\n",
      "Train Epoch: 2 [7040/50000 (14%)]\tLoss: 0.181805\n",
      "Train Epoch: 2 [7680/50000 (15%)]\tLoss: 0.085308\n",
      "Train Epoch: 2 [8320/50000 (17%)]\tLoss: 0.164902\n",
      "Train Epoch: 2 [8960/50000 (18%)]\tLoss: 0.133304\n",
      "Train Epoch: 2 [9600/50000 (19%)]\tLoss: 0.149914\n",
      "Train Epoch: 2 [10240/50000 (20%)]\tLoss: 0.052461\n",
      "Train Epoch: 2 [10880/50000 (22%)]\tLoss: 0.118291\n",
      "Train Epoch: 2 [11520/50000 (23%)]\tLoss: 0.169037\n",
      "Train Epoch: 2 [12160/50000 (24%)]\tLoss: 0.026033\n",
      "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 0.170858\n",
      "Train Epoch: 2 [13440/50000 (27%)]\tLoss: 0.106998\n",
      "Train Epoch: 2 [14080/50000 (28%)]\tLoss: 0.349693\n",
      "Train Epoch: 2 [14720/50000 (29%)]\tLoss: 0.194515\n",
      "Train Epoch: 2 [15360/50000 (31%)]\tLoss: 0.105614\n",
      "Train Epoch: 2 [16000/50000 (32%)]\tLoss: 0.085501\n",
      "Train Epoch: 2 [16640/50000 (33%)]\tLoss: 0.130685\n",
      "Train Epoch: 2 [17280/50000 (35%)]\tLoss: 0.184591\n",
      "Train Epoch: 2 [17920/50000 (36%)]\tLoss: 0.132343\n",
      "Train Epoch: 2 [18560/50000 (37%)]\tLoss: 0.045546\n",
      "Train Epoch: 2 [19200/50000 (38%)]\tLoss: 0.178383\n",
      "Train Epoch: 2 [19840/50000 (40%)]\tLoss: 0.111732\n",
      "Train Epoch: 2 [20480/50000 (41%)]\tLoss: 0.083728\n",
      "Train Epoch: 2 [21120/50000 (42%)]\tLoss: 0.114140\n",
      "Train Epoch: 2 [21760/50000 (43%)]\tLoss: 0.144106\n",
      "Train Epoch: 2 [22400/50000 (45%)]\tLoss: 0.163441\n",
      "Train Epoch: 2 [23040/50000 (46%)]\tLoss: 0.107575\n",
      "Train Epoch: 2 [23680/50000 (47%)]\tLoss: 0.143723\n",
      "Train Epoch: 2 [24320/50000 (49%)]\tLoss: 0.181384\n",
      "Train Epoch: 2 [24960/50000 (50%)]\tLoss: 0.155652\n",
      "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 0.186518\n",
      "Train Epoch: 2 [26240/50000 (52%)]\tLoss: 0.109711\n",
      "Train Epoch: 2 [26880/50000 (54%)]\tLoss: 0.264527\n",
      "Train Epoch: 2 [27520/50000 (55%)]\tLoss: 0.115724\n",
      "Train Epoch: 2 [28160/50000 (56%)]\tLoss: 0.080723\n",
      "Train Epoch: 2 [28800/50000 (58%)]\tLoss: 0.154117\n",
      "Train Epoch: 2 [29440/50000 (59%)]\tLoss: 0.154720\n",
      "Train Epoch: 2 [30080/50000 (60%)]\tLoss: 0.040852\n",
      "Train Epoch: 2 [30720/50000 (61%)]\tLoss: 0.247013\n",
      "Train Epoch: 2 [31360/50000 (63%)]\tLoss: 0.069789\n",
      "Train Epoch: 2 [32000/50000 (64%)]\tLoss: 0.117389\n",
      "Train Epoch: 2 [32640/50000 (65%)]\tLoss: 0.286687\n",
      "Train Epoch: 2 [33280/50000 (66%)]\tLoss: 0.126533\n",
      "Train Epoch: 2 [33920/50000 (68%)]\tLoss: 0.129905\n",
      "Train Epoch: 2 [34560/50000 (69%)]\tLoss: 0.267255\n",
      "Train Epoch: 2 [35200/50000 (70%)]\tLoss: 0.172862\n",
      "Train Epoch: 2 [35840/50000 (72%)]\tLoss: 0.293523\n",
      "Train Epoch: 2 [36480/50000 (73%)]\tLoss: 0.161059\n",
      "Train Epoch: 2 [37120/50000 (74%)]\tLoss: 0.132463\n",
      "Train Epoch: 2 [37760/50000 (75%)]\tLoss: 0.205026\n",
      "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 0.298991\n",
      "Train Epoch: 2 [39040/50000 (78%)]\tLoss: 0.286998\n",
      "Train Epoch: 2 [39680/50000 (79%)]\tLoss: 0.204317\n",
      "Train Epoch: 2 [40320/50000 (81%)]\tLoss: 0.146746\n",
      "Train Epoch: 2 [40960/50000 (82%)]\tLoss: 0.105612\n",
      "Train Epoch: 2 [41600/50000 (83%)]\tLoss: 0.117209\n",
      "Train Epoch: 2 [42240/50000 (84%)]\tLoss: 0.256738\n",
      "Train Epoch: 2 [42880/50000 (86%)]\tLoss: 0.115854\n",
      "Train Epoch: 2 [43520/50000 (87%)]\tLoss: 0.194118\n",
      "Train Epoch: 2 [44160/50000 (88%)]\tLoss: 0.226126\n",
      "Train Epoch: 2 [44800/50000 (90%)]\tLoss: 0.113200\n",
      "Train Epoch: 2 [45440/50000 (91%)]\tLoss: 0.212914\n",
      "Train Epoch: 2 [46080/50000 (92%)]\tLoss: 0.231078\n",
      "Train Epoch: 2 [46720/50000 (93%)]\tLoss: 0.202333\n",
      "Train Epoch: 2 [47360/50000 (95%)]\tLoss: 0.209479\n",
      "Train Epoch: 2 [48000/50000 (96%)]\tLoss: 0.167731\n",
      "Train Epoch: 2 [48640/50000 (97%)]\tLoss: 0.189969\n",
      "Train Epoch: 2 [49280/50000 (98%)]\tLoss: 0.179370\n",
      "Train Epoch: 2 [49920/50000 (100%)]\tLoss: 0.141534\n",
      "\n",
      "Test set: Avg. loss: 0.8846, Accuracy: 7791/10000 (78%)\n",
      "\n",
      "Train Epoch: 3 [0/50000 (0%)]\tLoss: 0.150704\n",
      "Train Epoch: 3 [640/50000 (1%)]\tLoss: 0.175263\n",
      "Train Epoch: 3 [1280/50000 (3%)]\tLoss: 0.125420\n",
      "Train Epoch: 3 [1920/50000 (4%)]\tLoss: 0.093635\n",
      "Train Epoch: 3 [2560/50000 (5%)]\tLoss: 0.266117\n",
      "Train Epoch: 3 [3200/50000 (6%)]\tLoss: 0.046808\n",
      "Train Epoch: 3 [3840/50000 (8%)]\tLoss: 0.034494\n",
      "Train Epoch: 3 [4480/50000 (9%)]\tLoss: 0.064047\n",
      "Train Epoch: 3 [5120/50000 (10%)]\tLoss: 0.132464\n",
      "Train Epoch: 3 [5760/50000 (12%)]\tLoss: 0.063327\n",
      "Train Epoch: 3 [6400/50000 (13%)]\tLoss: 0.033924\n",
      "Train Epoch: 3 [7040/50000 (14%)]\tLoss: 0.122354\n",
      "Train Epoch: 3 [7680/50000 (15%)]\tLoss: 0.115858\n",
      "Train Epoch: 3 [8320/50000 (17%)]\tLoss: 0.235945\n",
      "Train Epoch: 3 [8960/50000 (18%)]\tLoss: 0.031058\n",
      "Train Epoch: 3 [9600/50000 (19%)]\tLoss: 0.130087\n",
      "Train Epoch: 3 [10240/50000 (20%)]\tLoss: 0.195380\n",
      "Train Epoch: 3 [10880/50000 (22%)]\tLoss: 0.058196\n",
      "Train Epoch: 3 [11520/50000 (23%)]\tLoss: 0.165578\n",
      "Train Epoch: 3 [12160/50000 (24%)]\tLoss: 0.098343\n",
      "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 0.132104\n",
      "Train Epoch: 3 [13440/50000 (27%)]\tLoss: 0.201056\n",
      "Train Epoch: 3 [14080/50000 (28%)]\tLoss: 0.048717\n",
      "Train Epoch: 3 [14720/50000 (29%)]\tLoss: 0.097540\n",
      "Train Epoch: 3 [15360/50000 (31%)]\tLoss: 0.069936\n",
      "Train Epoch: 3 [16000/50000 (32%)]\tLoss: 0.214444\n",
      "Train Epoch: 3 [16640/50000 (33%)]\tLoss: 0.093359\n",
      "Train Epoch: 3 [17280/50000 (35%)]\tLoss: 0.110978\n",
      "Train Epoch: 3 [17920/50000 (36%)]\tLoss: 0.121538\n",
      "Train Epoch: 3 [18560/50000 (37%)]\tLoss: 0.173964\n",
      "Train Epoch: 3 [19200/50000 (38%)]\tLoss: 0.052865\n",
      "Train Epoch: 3 [19840/50000 (40%)]\tLoss: 0.187022\n",
      "Train Epoch: 3 [20480/50000 (41%)]\tLoss: 0.107720\n",
      "Train Epoch: 3 [21120/50000 (42%)]\tLoss: 0.123678\n",
      "Train Epoch: 3 [21760/50000 (43%)]\tLoss: 0.115434\n",
      "Train Epoch: 3 [22400/50000 (45%)]\tLoss: 0.040516\n",
      "Train Epoch: 3 [23040/50000 (46%)]\tLoss: 0.044324\n",
      "Train Epoch: 3 [23680/50000 (47%)]\tLoss: 0.094916\n",
      "Train Epoch: 3 [24320/50000 (49%)]\tLoss: 0.064904\n",
      "Train Epoch: 3 [24960/50000 (50%)]\tLoss: 0.066506\n",
      "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 0.060747\n",
      "Train Epoch: 3 [26240/50000 (52%)]\tLoss: 0.081479\n",
      "Train Epoch: 3 [26880/50000 (54%)]\tLoss: 0.098914\n",
      "Train Epoch: 3 [27520/50000 (55%)]\tLoss: 0.120038\n",
      "Train Epoch: 3 [28160/50000 (56%)]\tLoss: 0.034340\n",
      "Train Epoch: 3 [28800/50000 (58%)]\tLoss: 0.058392\n",
      "Train Epoch: 3 [29440/50000 (59%)]\tLoss: 0.091833\n",
      "Train Epoch: 3 [30080/50000 (60%)]\tLoss: 0.053701\n",
      "Train Epoch: 3 [30720/50000 (61%)]\tLoss: 0.098761\n",
      "Train Epoch: 3 [31360/50000 (63%)]\tLoss: 0.140277\n",
      "Train Epoch: 3 [32000/50000 (64%)]\tLoss: 0.138278\n",
      "Train Epoch: 3 [32640/50000 (65%)]\tLoss: 0.040485\n",
      "Train Epoch: 3 [33280/50000 (66%)]\tLoss: 0.060102\n",
      "Train Epoch: 3 [33920/50000 (68%)]\tLoss: 0.214595\n",
      "Train Epoch: 3 [34560/50000 (69%)]\tLoss: 0.098269\n",
      "Train Epoch: 3 [35200/50000 (70%)]\tLoss: 0.136652\n",
      "Train Epoch: 3 [35840/50000 (72%)]\tLoss: 0.053514\n",
      "Train Epoch: 3 [36480/50000 (73%)]\tLoss: 0.038987\n",
      "Train Epoch: 3 [37120/50000 (74%)]\tLoss: 0.093661\n",
      "Train Epoch: 3 [37760/50000 (75%)]\tLoss: 0.145518\n",
      "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 0.067250\n",
      "Train Epoch: 3 [39040/50000 (78%)]\tLoss: 0.109388\n",
      "Train Epoch: 3 [39680/50000 (79%)]\tLoss: 0.237825\n",
      "Train Epoch: 3 [40320/50000 (81%)]\tLoss: 0.091388\n",
      "Train Epoch: 3 [40960/50000 (82%)]\tLoss: 0.072410\n",
      "Train Epoch: 3 [41600/50000 (83%)]\tLoss: 0.116349\n",
      "Train Epoch: 3 [42240/50000 (84%)]\tLoss: 0.119303\n",
      "Train Epoch: 3 [42880/50000 (86%)]\tLoss: 0.189702\n",
      "Train Epoch: 3 [43520/50000 (87%)]\tLoss: 0.135074\n",
      "Train Epoch: 3 [44160/50000 (88%)]\tLoss: 0.104113\n",
      "Train Epoch: 3 [44800/50000 (90%)]\tLoss: 0.031930\n",
      "Train Epoch: 3 [45440/50000 (91%)]\tLoss: 0.072814\n",
      "Train Epoch: 3 [46080/50000 (92%)]\tLoss: 0.099928\n",
      "Train Epoch: 3 [46720/50000 (93%)]\tLoss: 0.190070\n",
      "Train Epoch: 3 [47360/50000 (95%)]\tLoss: 0.030974\n",
      "Train Epoch: 3 [48000/50000 (96%)]\tLoss: 0.191535\n",
      "Train Epoch: 3 [48640/50000 (97%)]\tLoss: 0.124588\n",
      "Train Epoch: 3 [49280/50000 (98%)]\tLoss: 0.099294\n",
      "Train Epoch: 3 [49920/50000 (100%)]\tLoss: 0.151413\n",
      "\n",
      "Test set: Avg. loss: 0.9090, Accuracy: 7905/10000 (79%)\n",
      "\n",
      "Train Epoch: 4 [0/50000 (0%)]\tLoss: 0.057548\n",
      "Train Epoch: 4 [640/50000 (1%)]\tLoss: 0.163413\n",
      "Train Epoch: 4 [1280/50000 (3%)]\tLoss: 0.059890\n",
      "Train Epoch: 4 [1920/50000 (4%)]\tLoss: 0.069070\n",
      "Train Epoch: 4 [2560/50000 (5%)]\tLoss: 0.088159\n",
      "Train Epoch: 4 [3200/50000 (6%)]\tLoss: 0.050379\n",
      "Train Epoch: 4 [3840/50000 (8%)]\tLoss: 0.085396\n",
      "Train Epoch: 4 [4480/50000 (9%)]\tLoss: 0.280014\n",
      "Train Epoch: 4 [5120/50000 (10%)]\tLoss: 0.080581\n",
      "Train Epoch: 4 [5760/50000 (12%)]\tLoss: 0.053812\n",
      "Train Epoch: 4 [6400/50000 (13%)]\tLoss: 0.030169\n",
      "Train Epoch: 4 [7040/50000 (14%)]\tLoss: 0.135434\n",
      "Train Epoch: 4 [7680/50000 (15%)]\tLoss: 0.011765\n",
      "Train Epoch: 4 [8320/50000 (17%)]\tLoss: 0.132901\n",
      "Train Epoch: 4 [8960/50000 (18%)]\tLoss: 0.075472\n",
      "Train Epoch: 4 [9600/50000 (19%)]\tLoss: 0.144046\n",
      "Train Epoch: 4 [10240/50000 (20%)]\tLoss: 0.025751\n",
      "Train Epoch: 4 [10880/50000 (22%)]\tLoss: 0.150028\n",
      "Train Epoch: 4 [11520/50000 (23%)]\tLoss: 0.027110\n",
      "Train Epoch: 4 [12160/50000 (24%)]\tLoss: 0.055399\n",
      "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 0.045246\n",
      "Train Epoch: 4 [13440/50000 (27%)]\tLoss: 0.053893\n",
      "Train Epoch: 4 [14080/50000 (28%)]\tLoss: 0.071490\n",
      "Train Epoch: 4 [14720/50000 (29%)]\tLoss: 0.109812\n",
      "Train Epoch: 4 [15360/50000 (31%)]\tLoss: 0.040168\n",
      "Train Epoch: 4 [16000/50000 (32%)]\tLoss: 0.070783\n",
      "Train Epoch: 4 [16640/50000 (33%)]\tLoss: 0.048935\n",
      "Train Epoch: 4 [17280/50000 (35%)]\tLoss: 0.092238\n",
      "Train Epoch: 4 [17920/50000 (36%)]\tLoss: 0.055492\n",
      "Train Epoch: 4 [18560/50000 (37%)]\tLoss: 0.057155\n",
      "Train Epoch: 4 [19200/50000 (38%)]\tLoss: 0.181432\n",
      "Train Epoch: 4 [19840/50000 (40%)]\tLoss: 0.050760\n",
      "Train Epoch: 4 [20480/50000 (41%)]\tLoss: 0.306772\n",
      "Train Epoch: 4 [21120/50000 (42%)]\tLoss: 0.040264\n",
      "Train Epoch: 4 [21760/50000 (43%)]\tLoss: 0.218804\n",
      "Train Epoch: 4 [22400/50000 (45%)]\tLoss: 0.031326\n",
      "Train Epoch: 4 [23040/50000 (46%)]\tLoss: 0.113937\n",
      "Train Epoch: 4 [23680/50000 (47%)]\tLoss: 0.058561\n",
      "Train Epoch: 4 [24320/50000 (49%)]\tLoss: 0.081395\n",
      "Train Epoch: 4 [24960/50000 (50%)]\tLoss: 0.069601\n",
      "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 0.195012\n",
      "Train Epoch: 4 [26240/50000 (52%)]\tLoss: 0.102785\n",
      "Train Epoch: 4 [26880/50000 (54%)]\tLoss: 0.098168\n",
      "Train Epoch: 4 [27520/50000 (55%)]\tLoss: 0.090724\n",
      "Train Epoch: 4 [28160/50000 (56%)]\tLoss: 0.099605\n",
      "Train Epoch: 4 [28800/50000 (58%)]\tLoss: 0.192221\n",
      "Train Epoch: 4 [29440/50000 (59%)]\tLoss: 0.167577\n",
      "Train Epoch: 4 [30080/50000 (60%)]\tLoss: 0.111034\n",
      "Train Epoch: 4 [30720/50000 (61%)]\tLoss: 0.153454\n",
      "Train Epoch: 4 [31360/50000 (63%)]\tLoss: 0.113032\n",
      "Train Epoch: 4 [32000/50000 (64%)]\tLoss: 0.049884\n",
      "Train Epoch: 4 [32640/50000 (65%)]\tLoss: 0.143698\n",
      "Train Epoch: 4 [33280/50000 (66%)]\tLoss: 0.071059\n",
      "Train Epoch: 4 [33920/50000 (68%)]\tLoss: 0.028575\n",
      "Train Epoch: 4 [34560/50000 (69%)]\tLoss: 0.157314\n",
      "Train Epoch: 4 [35200/50000 (70%)]\tLoss: 0.067282\n",
      "Train Epoch: 4 [35840/50000 (72%)]\tLoss: 0.119607\n",
      "Train Epoch: 4 [36480/50000 (73%)]\tLoss: 0.153362\n",
      "Train Epoch: 4 [37120/50000 (74%)]\tLoss: 0.085948\n",
      "Train Epoch: 4 [37760/50000 (75%)]\tLoss: 0.067532\n",
      "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 0.098550\n",
      "Train Epoch: 4 [39040/50000 (78%)]\tLoss: 0.223304\n",
      "Train Epoch: 4 [39680/50000 (79%)]\tLoss: 0.186841\n",
      "Train Epoch: 4 [40320/50000 (81%)]\tLoss: 0.270099\n",
      "Train Epoch: 4 [40960/50000 (82%)]\tLoss: 0.112037\n",
      "Train Epoch: 4 [41600/50000 (83%)]\tLoss: 0.153987\n",
      "Train Epoch: 4 [42240/50000 (84%)]\tLoss: 0.161541\n",
      "Train Epoch: 4 [42880/50000 (86%)]\tLoss: 0.074554\n",
      "Train Epoch: 4 [43520/50000 (87%)]\tLoss: 0.099661\n",
      "Train Epoch: 4 [44160/50000 (88%)]\tLoss: 0.044262\n",
      "Train Epoch: 4 [44800/50000 (90%)]\tLoss: 0.208423\n",
      "Train Epoch: 4 [45440/50000 (91%)]\tLoss: 0.074181\n",
      "Train Epoch: 4 [46080/50000 (92%)]\tLoss: 0.132041\n",
      "Train Epoch: 4 [46720/50000 (93%)]\tLoss: 0.142609\n",
      "Train Epoch: 4 [47360/50000 (95%)]\tLoss: 0.137194\n",
      "Train Epoch: 4 [48000/50000 (96%)]\tLoss: 0.067548\n",
      "Train Epoch: 4 [48640/50000 (97%)]\tLoss: 0.142324\n",
      "Train Epoch: 4 [49280/50000 (98%)]\tLoss: 0.093435\n",
      "Train Epoch: 4 [49920/50000 (100%)]\tLoss: 0.106682\n",
      "\n",
      "Test set: Avg. loss: 0.9544, Accuracy: 7851/10000 (79%)\n",
      "\n",
      "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.043861\n",
      "Train Epoch: 5 [640/50000 (1%)]\tLoss: 0.133215\n",
      "Train Epoch: 5 [1280/50000 (3%)]\tLoss: 0.117540\n",
      "Train Epoch: 5 [1920/50000 (4%)]\tLoss: 0.115881\n",
      "Train Epoch: 5 [2560/50000 (5%)]\tLoss: 0.123584\n",
      "Train Epoch: 5 [3200/50000 (6%)]\tLoss: 0.029720\n",
      "Train Epoch: 5 [3840/50000 (8%)]\tLoss: 0.055916\n",
      "Train Epoch: 5 [4480/50000 (9%)]\tLoss: 0.028864\n",
      "Train Epoch: 5 [5120/50000 (10%)]\tLoss: 0.083981\n",
      "Train Epoch: 5 [5760/50000 (12%)]\tLoss: 0.050875\n",
      "Train Epoch: 5 [6400/50000 (13%)]\tLoss: 0.242633\n",
      "Train Epoch: 5 [7040/50000 (14%)]\tLoss: 0.049277\n",
      "Train Epoch: 5 [7680/50000 (15%)]\tLoss: 0.040446\n",
      "Train Epoch: 5 [8320/50000 (17%)]\tLoss: 0.138863\n",
      "Train Epoch: 5 [8960/50000 (18%)]\tLoss: 0.014042\n",
      "Train Epoch: 5 [9600/50000 (19%)]\tLoss: 0.042918\n",
      "Train Epoch: 5 [10240/50000 (20%)]\tLoss: 0.085230\n",
      "Train Epoch: 5 [10880/50000 (22%)]\tLoss: 0.066734\n",
      "Train Epoch: 5 [11520/50000 (23%)]\tLoss: 0.112814\n",
      "Train Epoch: 5 [12160/50000 (24%)]\tLoss: 0.054372\n",
      "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 0.113170\n",
      "Train Epoch: 5 [13440/50000 (27%)]\tLoss: 0.049290\n",
      "Train Epoch: 5 [14080/50000 (28%)]\tLoss: 0.039533\n",
      "Train Epoch: 5 [14720/50000 (29%)]\tLoss: 0.046434\n",
      "Train Epoch: 5 [15360/50000 (31%)]\tLoss: 0.046257\n",
      "Train Epoch: 5 [16000/50000 (32%)]\tLoss: 0.133067\n",
      "Train Epoch: 5 [16640/50000 (33%)]\tLoss: 0.026627\n",
      "Train Epoch: 5 [17280/50000 (35%)]\tLoss: 0.133167\n",
      "Train Epoch: 5 [17920/50000 (36%)]\tLoss: 0.069740\n",
      "Train Epoch: 5 [18560/50000 (37%)]\tLoss: 0.127283\n",
      "Train Epoch: 5 [19200/50000 (38%)]\tLoss: 0.031827\n",
      "Train Epoch: 5 [19840/50000 (40%)]\tLoss: 0.105093\n",
      "Train Epoch: 5 [20480/50000 (41%)]\tLoss: 0.120108\n",
      "Train Epoch: 5 [21120/50000 (42%)]\tLoss: 0.066946\n",
      "Train Epoch: 5 [21760/50000 (43%)]\tLoss: 0.124003\n",
      "Train Epoch: 5 [22400/50000 (45%)]\tLoss: 0.119904\n",
      "Train Epoch: 5 [23040/50000 (46%)]\tLoss: 0.110284\n",
      "Train Epoch: 5 [23680/50000 (47%)]\tLoss: 0.054948\n",
      "Train Epoch: 5 [24320/50000 (49%)]\tLoss: 0.045586\n",
      "Train Epoch: 5 [24960/50000 (50%)]\tLoss: 0.021619\n",
      "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 0.076566\n",
      "Train Epoch: 5 [26240/50000 (52%)]\tLoss: 0.121131\n",
      "Train Epoch: 5 [26880/50000 (54%)]\tLoss: 0.035724\n",
      "Train Epoch: 5 [27520/50000 (55%)]\tLoss: 0.068869\n",
      "Train Epoch: 5 [28160/50000 (56%)]\tLoss: 0.056112\n",
      "Train Epoch: 5 [28800/50000 (58%)]\tLoss: 0.050712\n",
      "Train Epoch: 5 [29440/50000 (59%)]\tLoss: 0.026933\n",
      "Train Epoch: 5 [30080/50000 (60%)]\tLoss: 0.097579\n",
      "Train Epoch: 5 [30720/50000 (61%)]\tLoss: 0.097921\n",
      "Train Epoch: 5 [31360/50000 (63%)]\tLoss: 0.018893\n",
      "Train Epoch: 5 [32000/50000 (64%)]\tLoss: 0.045412\n",
      "Train Epoch: 5 [32640/50000 (65%)]\tLoss: 0.200205\n",
      "Train Epoch: 5 [33280/50000 (66%)]\tLoss: 0.130280\n",
      "Train Epoch: 5 [33920/50000 (68%)]\tLoss: 0.197134\n",
      "Train Epoch: 5 [34560/50000 (69%)]\tLoss: 0.103988\n",
      "Train Epoch: 5 [35200/50000 (70%)]\tLoss: 0.090516\n",
      "Train Epoch: 5 [35840/50000 (72%)]\tLoss: 0.041734\n",
      "Train Epoch: 5 [36480/50000 (73%)]\tLoss: 0.070521\n",
      "Train Epoch: 5 [37120/50000 (74%)]\tLoss: 0.045162\n",
      "Train Epoch: 5 [37760/50000 (75%)]\tLoss: 0.203162\n",
      "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 0.159651\n",
      "Train Epoch: 5 [39040/50000 (78%)]\tLoss: 0.094653\n",
      "Train Epoch: 5 [39680/50000 (79%)]\tLoss: 0.089037\n",
      "Train Epoch: 5 [40320/50000 (81%)]\tLoss: 0.079832\n",
      "Train Epoch: 5 [40960/50000 (82%)]\tLoss: 0.026747\n",
      "Train Epoch: 5 [41600/50000 (83%)]\tLoss: 0.030771\n",
      "Train Epoch: 5 [42240/50000 (84%)]\tLoss: 0.056271\n",
      "Train Epoch: 5 [42880/50000 (86%)]\tLoss: 0.020456\n",
      "Train Epoch: 5 [43520/50000 (87%)]\tLoss: 0.115381\n",
      "Train Epoch: 5 [44160/50000 (88%)]\tLoss: 0.041955\n",
      "Train Epoch: 5 [44800/50000 (90%)]\tLoss: 0.072352\n",
      "Train Epoch: 5 [45440/50000 (91%)]\tLoss: 0.073398\n",
      "Train Epoch: 5 [46080/50000 (92%)]\tLoss: 0.106336\n",
      "Train Epoch: 5 [46720/50000 (93%)]\tLoss: 0.168155\n",
      "Train Epoch: 5 [47360/50000 (95%)]\tLoss: 0.033854\n",
      "Train Epoch: 5 [48000/50000 (96%)]\tLoss: 0.131439\n",
      "Train Epoch: 5 [48640/50000 (97%)]\tLoss: 0.011803\n",
      "Train Epoch: 5 [49280/50000 (98%)]\tLoss: 0.094879\n",
      "Train Epoch: 5 [49920/50000 (100%)]\tLoss: 0.260149\n",
      "\n",
      "Test set: Avg. loss: 1.0256, Accuracy: 7846/10000 (78%)\n",
      "\n",
      "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.104280\n",
      "Train Epoch: 6 [640/50000 (1%)]\tLoss: 0.111439\n",
      "Train Epoch: 6 [1280/50000 (3%)]\tLoss: 0.046663\n",
      "Train Epoch: 6 [1920/50000 (4%)]\tLoss: 0.165910\n",
      "Train Epoch: 6 [2560/50000 (5%)]\tLoss: 0.068587\n",
      "Train Epoch: 6 [3200/50000 (6%)]\tLoss: 0.047124\n",
      "Train Epoch: 6 [3840/50000 (8%)]\tLoss: 0.016573\n",
      "Train Epoch: 6 [4480/50000 (9%)]\tLoss: 0.046798\n",
      "Train Epoch: 6 [5120/50000 (10%)]\tLoss: 0.134304\n",
      "Train Epoch: 6 [5760/50000 (12%)]\tLoss: 0.103091\n",
      "Train Epoch: 6 [6400/50000 (13%)]\tLoss: 0.046588\n",
      "Train Epoch: 6 [7040/50000 (14%)]\tLoss: 0.082531\n",
      "Train Epoch: 6 [7680/50000 (15%)]\tLoss: 0.057390\n",
      "Train Epoch: 6 [8320/50000 (17%)]\tLoss: 0.049452\n",
      "Train Epoch: 6 [8960/50000 (18%)]\tLoss: 0.066237\n",
      "Train Epoch: 6 [9600/50000 (19%)]\tLoss: 0.057216\n",
      "Train Epoch: 6 [10240/50000 (20%)]\tLoss: 0.078236\n",
      "Train Epoch: 6 [10880/50000 (22%)]\tLoss: 0.055340\n",
      "Train Epoch: 6 [11520/50000 (23%)]\tLoss: 0.050227\n",
      "Train Epoch: 6 [12160/50000 (24%)]\tLoss: 0.058502\n",
      "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.117046\n",
      "Train Epoch: 6 [13440/50000 (27%)]\tLoss: 0.036308\n",
      "Train Epoch: 6 [14080/50000 (28%)]\tLoss: 0.026630\n",
      "Train Epoch: 6 [14720/50000 (29%)]\tLoss: 0.072533\n",
      "Train Epoch: 6 [15360/50000 (31%)]\tLoss: 0.031117\n",
      "Train Epoch: 6 [16000/50000 (32%)]\tLoss: 0.057756\n",
      "Train Epoch: 6 [16640/50000 (33%)]\tLoss: 0.085878\n",
      "Train Epoch: 6 [17280/50000 (35%)]\tLoss: 0.029255\n",
      "Train Epoch: 6 [17920/50000 (36%)]\tLoss: 0.019976\n",
      "Train Epoch: 6 [18560/50000 (37%)]\tLoss: 0.065154\n",
      "Train Epoch: 6 [19200/50000 (38%)]\tLoss: 0.018739\n",
      "Train Epoch: 6 [19840/50000 (40%)]\tLoss: 0.077348\n",
      "Train Epoch: 6 [20480/50000 (41%)]\tLoss: 0.103777\n",
      "Train Epoch: 6 [21120/50000 (42%)]\tLoss: 0.023008\n",
      "Train Epoch: 6 [21760/50000 (43%)]\tLoss: 0.018027\n",
      "Train Epoch: 6 [22400/50000 (45%)]\tLoss: 0.010858\n",
      "Train Epoch: 6 [23040/50000 (46%)]\tLoss: 0.070396\n",
      "Train Epoch: 6 [23680/50000 (47%)]\tLoss: 0.080334\n",
      "Train Epoch: 6 [24320/50000 (49%)]\tLoss: 0.102009\n",
      "Train Epoch: 6 [24960/50000 (50%)]\tLoss: 0.027037\n",
      "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.104858\n",
      "Train Epoch: 6 [26240/50000 (52%)]\tLoss: 0.016729\n",
      "Train Epoch: 6 [26880/50000 (54%)]\tLoss: 0.064450\n",
      "Train Epoch: 6 [27520/50000 (55%)]\tLoss: 0.058027\n",
      "Train Epoch: 6 [28160/50000 (56%)]\tLoss: 0.040179\n",
      "Train Epoch: 6 [28800/50000 (58%)]\tLoss: 0.082437\n",
      "Train Epoch: 6 [29440/50000 (59%)]\tLoss: 0.014477\n",
      "Train Epoch: 6 [30080/50000 (60%)]\tLoss: 0.076304\n",
      "Train Epoch: 6 [30720/50000 (61%)]\tLoss: 0.016620\n",
      "Train Epoch: 6 [31360/50000 (63%)]\tLoss: 0.022137\n",
      "Train Epoch: 6 [32000/50000 (64%)]\tLoss: 0.058364\n",
      "Train Epoch: 6 [32640/50000 (65%)]\tLoss: 0.059057\n",
      "Train Epoch: 6 [33280/50000 (66%)]\tLoss: 0.031227\n",
      "Train Epoch: 6 [33920/50000 (68%)]\tLoss: 0.012860\n",
      "Train Epoch: 6 [34560/50000 (69%)]\tLoss: 0.048024\n",
      "Train Epoch: 6 [35200/50000 (70%)]\tLoss: 0.122311\n",
      "Train Epoch: 6 [35840/50000 (72%)]\tLoss: 0.027270\n",
      "Train Epoch: 6 [36480/50000 (73%)]\tLoss: 0.055436\n",
      "Train Epoch: 6 [37120/50000 (74%)]\tLoss: 0.015528\n",
      "Train Epoch: 6 [37760/50000 (75%)]\tLoss: 0.035853\n",
      "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 0.066077\n",
      "Train Epoch: 6 [39040/50000 (78%)]\tLoss: 0.097209\n",
      "Train Epoch: 6 [39680/50000 (79%)]\tLoss: 0.035554\n",
      "Train Epoch: 6 [40320/50000 (81%)]\tLoss: 0.022208\n",
      "Train Epoch: 6 [40960/50000 (82%)]\tLoss: 0.092110\n",
      "Train Epoch: 6 [41600/50000 (83%)]\tLoss: 0.096430\n",
      "Train Epoch: 6 [42240/50000 (84%)]\tLoss: 0.060678\n",
      "Train Epoch: 6 [42880/50000 (86%)]\tLoss: 0.054433\n",
      "Train Epoch: 6 [43520/50000 (87%)]\tLoss: 0.266137\n",
      "Train Epoch: 6 [44160/50000 (88%)]\tLoss: 0.064423\n",
      "Train Epoch: 6 [44800/50000 (90%)]\tLoss: 0.116044\n",
      "Train Epoch: 6 [45440/50000 (91%)]\tLoss: 0.050475\n",
      "Train Epoch: 6 [46080/50000 (92%)]\tLoss: 0.116027\n",
      "Train Epoch: 6 [46720/50000 (93%)]\tLoss: 0.033095\n",
      "Train Epoch: 6 [47360/50000 (95%)]\tLoss: 0.023315\n",
      "Train Epoch: 6 [48000/50000 (96%)]\tLoss: 0.071202\n",
      "Train Epoch: 6 [48640/50000 (97%)]\tLoss: 0.085732\n",
      "Train Epoch: 6 [49280/50000 (98%)]\tLoss: 0.144921\n",
      "Train Epoch: 6 [49920/50000 (100%)]\tLoss: 0.172906\n",
      "\n",
      "Test set: Avg. loss: 1.0660, Accuracy: 7891/10000 (79%)\n",
      "\n",
      "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.069166\n",
      "Train Epoch: 7 [640/50000 (1%)]\tLoss: 0.064162\n",
      "Train Epoch: 7 [1280/50000 (3%)]\tLoss: 0.009959\n",
      "Train Epoch: 7 [1920/50000 (4%)]\tLoss: 0.043959\n",
      "Train Epoch: 7 [2560/50000 (5%)]\tLoss: 0.010779\n",
      "Train Epoch: 7 [3200/50000 (6%)]\tLoss: 0.005641\n",
      "Train Epoch: 7 [3840/50000 (8%)]\tLoss: 0.051746\n",
      "Train Epoch: 7 [4480/50000 (9%)]\tLoss: 0.114408\n",
      "Train Epoch: 7 [5120/50000 (10%)]\tLoss: 0.091205\n",
      "Train Epoch: 7 [5760/50000 (12%)]\tLoss: 0.144106\n",
      "Train Epoch: 7 [6400/50000 (13%)]\tLoss: 0.042510\n",
      "Train Epoch: 7 [7040/50000 (14%)]\tLoss: 0.021793\n",
      "Train Epoch: 7 [7680/50000 (15%)]\tLoss: 0.021203\n",
      "Train Epoch: 7 [8320/50000 (17%)]\tLoss: 0.010744\n",
      "Train Epoch: 7 [8960/50000 (18%)]\tLoss: 0.175177\n",
      "Train Epoch: 7 [9600/50000 (19%)]\tLoss: 0.156709\n",
      "Train Epoch: 7 [10240/50000 (20%)]\tLoss: 0.010296\n",
      "Train Epoch: 7 [10880/50000 (22%)]\tLoss: 0.029837\n",
      "Train Epoch: 7 [11520/50000 (23%)]\tLoss: 0.059561\n",
      "Train Epoch: 7 [12160/50000 (24%)]\tLoss: 0.058909\n",
      "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.052915\n",
      "Train Epoch: 7 [13440/50000 (27%)]\tLoss: 0.011942\n",
      "Train Epoch: 7 [14080/50000 (28%)]\tLoss: 0.007316\n",
      "Train Epoch: 7 [14720/50000 (29%)]\tLoss: 0.080451\n",
      "Train Epoch: 7 [15360/50000 (31%)]\tLoss: 0.116947\n",
      "Train Epoch: 7 [16000/50000 (32%)]\tLoss: 0.196538\n",
      "Train Epoch: 7 [16640/50000 (33%)]\tLoss: 0.011819\n",
      "Train Epoch: 7 [17280/50000 (35%)]\tLoss: 0.129205\n",
      "Train Epoch: 7 [17920/50000 (36%)]\tLoss: 0.041435\n",
      "Train Epoch: 7 [18560/50000 (37%)]\tLoss: 0.034907\n",
      "Train Epoch: 7 [19200/50000 (38%)]\tLoss: 0.063678\n",
      "Train Epoch: 7 [19840/50000 (40%)]\tLoss: 0.075541\n",
      "Train Epoch: 7 [20480/50000 (41%)]\tLoss: 0.001776\n",
      "Train Epoch: 7 [21120/50000 (42%)]\tLoss: 0.024608\n",
      "Train Epoch: 7 [21760/50000 (43%)]\tLoss: 0.019544\n",
      "Train Epoch: 7 [22400/50000 (45%)]\tLoss: 0.071125\n",
      "Train Epoch: 7 [23040/50000 (46%)]\tLoss: 0.036615\n",
      "Train Epoch: 7 [23680/50000 (47%)]\tLoss: 0.090196\n",
      "Train Epoch: 7 [24320/50000 (49%)]\tLoss: 0.024908\n",
      "Train Epoch: 7 [24960/50000 (50%)]\tLoss: 0.081749\n",
      "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.040939\n",
      "Train Epoch: 7 [26240/50000 (52%)]\tLoss: 0.047689\n",
      "Train Epoch: 7 [26880/50000 (54%)]\tLoss: 0.128334\n",
      "Train Epoch: 7 [27520/50000 (55%)]\tLoss: 0.044228\n",
      "Train Epoch: 7 [28160/50000 (56%)]\tLoss: 0.074856\n",
      "Train Epoch: 7 [28800/50000 (58%)]\tLoss: 0.049627\n",
      "Train Epoch: 7 [29440/50000 (59%)]\tLoss: 0.059065\n",
      "Train Epoch: 7 [30080/50000 (60%)]\tLoss: 0.040578\n",
      "Train Epoch: 7 [30720/50000 (61%)]\tLoss: 0.061017\n",
      "Train Epoch: 7 [31360/50000 (63%)]\tLoss: 0.118314\n",
      "Train Epoch: 7 [32000/50000 (64%)]\tLoss: 0.066212\n",
      "Train Epoch: 7 [32640/50000 (65%)]\tLoss: 0.163057\n",
      "Train Epoch: 7 [33280/50000 (66%)]\tLoss: 0.073364\n",
      "Train Epoch: 7 [33920/50000 (68%)]\tLoss: 0.021993\n",
      "Train Epoch: 7 [34560/50000 (69%)]\tLoss: 0.080552\n",
      "Train Epoch: 7 [35200/50000 (70%)]\tLoss: 0.017133\n",
      "Train Epoch: 7 [35840/50000 (72%)]\tLoss: 0.076744\n",
      "Train Epoch: 7 [36480/50000 (73%)]\tLoss: 0.013210\n",
      "Train Epoch: 7 [37120/50000 (74%)]\tLoss: 0.021906\n",
      "Train Epoch: 7 [37760/50000 (75%)]\tLoss: 0.016818\n",
      "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.025145\n",
      "Train Epoch: 7 [39040/50000 (78%)]\tLoss: 0.019893\n",
      "Train Epoch: 7 [39680/50000 (79%)]\tLoss: 0.080131\n",
      "Train Epoch: 7 [40320/50000 (81%)]\tLoss: 0.028272\n",
      "Train Epoch: 7 [40960/50000 (82%)]\tLoss: 0.009804\n",
      "Train Epoch: 7 [41600/50000 (83%)]\tLoss: 0.072752\n",
      "Train Epoch: 7 [42240/50000 (84%)]\tLoss: 0.051132\n",
      "Train Epoch: 7 [42880/50000 (86%)]\tLoss: 0.084392\n",
      "Train Epoch: 7 [43520/50000 (87%)]\tLoss: 0.020876\n",
      "Train Epoch: 7 [44160/50000 (88%)]\tLoss: 0.061977\n",
      "Train Epoch: 7 [44800/50000 (90%)]\tLoss: 0.057961\n",
      "Train Epoch: 7 [45440/50000 (91%)]\tLoss: 0.223229\n",
      "Train Epoch: 7 [46080/50000 (92%)]\tLoss: 0.039750\n",
      "Train Epoch: 7 [46720/50000 (93%)]\tLoss: 0.198877\n",
      "Train Epoch: 7 [47360/50000 (95%)]\tLoss: 0.024012\n",
      "Train Epoch: 7 [48000/50000 (96%)]\tLoss: 0.040854\n",
      "Train Epoch: 7 [48640/50000 (97%)]\tLoss: 0.014108\n",
      "Train Epoch: 7 [49280/50000 (98%)]\tLoss: 0.115551\n",
      "Train Epoch: 7 [49920/50000 (100%)]\tLoss: 0.167127\n",
      "\n",
      "Test set: Avg. loss: 1.0936, Accuracy: 7914/10000 (79%)\n",
      "\n",
      "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.074396\n",
      "Train Epoch: 8 [640/50000 (1%)]\tLoss: 0.147920\n",
      "Train Epoch: 8 [1280/50000 (3%)]\tLoss: 0.059834\n",
      "Train Epoch: 8 [1920/50000 (4%)]\tLoss: 0.062112\n",
      "Train Epoch: 8 [2560/50000 (5%)]\tLoss: 0.018400\n",
      "Train Epoch: 8 [3200/50000 (6%)]\tLoss: 0.044138\n",
      "Train Epoch: 8 [3840/50000 (8%)]\tLoss: 0.083315\n",
      "Train Epoch: 8 [4480/50000 (9%)]\tLoss: 0.032910\n",
      "Train Epoch: 8 [5120/50000 (10%)]\tLoss: 0.013552\n",
      "Train Epoch: 8 [5760/50000 (12%)]\tLoss: 0.008477\n",
      "Train Epoch: 8 [6400/50000 (13%)]\tLoss: 0.147818\n",
      "Train Epoch: 8 [7040/50000 (14%)]\tLoss: 0.021769\n",
      "Train Epoch: 8 [7680/50000 (15%)]\tLoss: 0.015471\n",
      "Train Epoch: 8 [8320/50000 (17%)]\tLoss: 0.058176\n",
      "Train Epoch: 8 [8960/50000 (18%)]\tLoss: 0.022286\n",
      "Train Epoch: 8 [9600/50000 (19%)]\tLoss: 0.049439\n",
      "Train Epoch: 8 [10240/50000 (20%)]\tLoss: 0.019725\n",
      "Train Epoch: 8 [10880/50000 (22%)]\tLoss: 0.087787\n",
      "Train Epoch: 8 [11520/50000 (23%)]\tLoss: 0.071873\n",
      "Train Epoch: 8 [12160/50000 (24%)]\tLoss: 0.068848\n",
      "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.017650\n",
      "Train Epoch: 8 [13440/50000 (27%)]\tLoss: 0.128110\n",
      "Train Epoch: 8 [14080/50000 (28%)]\tLoss: 0.072305\n",
      "Train Epoch: 8 [14720/50000 (29%)]\tLoss: 0.047053\n",
      "Train Epoch: 8 [15360/50000 (31%)]\tLoss: 0.011041\n",
      "Train Epoch: 8 [16000/50000 (32%)]\tLoss: 0.058708\n",
      "Train Epoch: 8 [16640/50000 (33%)]\tLoss: 0.014007\n",
      "Train Epoch: 8 [17280/50000 (35%)]\tLoss: 0.014045\n",
      "Train Epoch: 8 [17920/50000 (36%)]\tLoss: 0.065771\n",
      "Train Epoch: 8 [18560/50000 (37%)]\tLoss: 0.032195\n",
      "Train Epoch: 8 [19200/50000 (38%)]\tLoss: 0.011141\n",
      "Train Epoch: 8 [19840/50000 (40%)]\tLoss: 0.129656\n",
      "Train Epoch: 8 [20480/50000 (41%)]\tLoss: 0.048746\n",
      "Train Epoch: 8 [21120/50000 (42%)]\tLoss: 0.038179\n",
      "Train Epoch: 8 [21760/50000 (43%)]\tLoss: 0.044090\n",
      "Train Epoch: 8 [22400/50000 (45%)]\tLoss: 0.056175\n",
      "Train Epoch: 8 [23040/50000 (46%)]\tLoss: 0.059108\n",
      "Train Epoch: 8 [23680/50000 (47%)]\tLoss: 0.058241\n",
      "Train Epoch: 8 [24320/50000 (49%)]\tLoss: 0.048110\n",
      "Train Epoch: 8 [24960/50000 (50%)]\tLoss: 0.024343\n",
      "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.108690\n",
      "Train Epoch: 8 [26240/50000 (52%)]\tLoss: 0.084068\n",
      "Train Epoch: 8 [26880/50000 (54%)]\tLoss: 0.130542\n",
      "Train Epoch: 8 [27520/50000 (55%)]\tLoss: 0.075057\n",
      "Train Epoch: 8 [28160/50000 (56%)]\tLoss: 0.009971\n",
      "Train Epoch: 8 [28800/50000 (58%)]\tLoss: 0.012081\n",
      "Train Epoch: 8 [29440/50000 (59%)]\tLoss: 0.105357\n",
      "Train Epoch: 8 [30080/50000 (60%)]\tLoss: 0.019373\n",
      "Train Epoch: 8 [30720/50000 (61%)]\tLoss: 0.105635\n",
      "Train Epoch: 8 [31360/50000 (63%)]\tLoss: 0.051858\n",
      "Train Epoch: 8 [32000/50000 (64%)]\tLoss: 0.110830\n",
      "Train Epoch: 8 [32640/50000 (65%)]\tLoss: 0.036891\n",
      "Train Epoch: 8 [33280/50000 (66%)]\tLoss: 0.026745\n",
      "Train Epoch: 8 [33920/50000 (68%)]\tLoss: 0.055528\n",
      "Train Epoch: 8 [34560/50000 (69%)]\tLoss: 0.067483\n",
      "Train Epoch: 8 [35200/50000 (70%)]\tLoss: 0.014468\n",
      "Train Epoch: 8 [35840/50000 (72%)]\tLoss: 0.077995\n",
      "Train Epoch: 8 [36480/50000 (73%)]\tLoss: 0.003969\n",
      "Train Epoch: 8 [37120/50000 (74%)]\tLoss: 0.030252\n",
      "Train Epoch: 8 [37760/50000 (75%)]\tLoss: 0.013159\n",
      "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.082743\n",
      "Train Epoch: 8 [39040/50000 (78%)]\tLoss: 0.055910\n",
      "Train Epoch: 8 [39680/50000 (79%)]\tLoss: 0.043939\n",
      "Train Epoch: 8 [40320/50000 (81%)]\tLoss: 0.151010\n",
      "Train Epoch: 8 [40960/50000 (82%)]\tLoss: 0.180752\n",
      "Train Epoch: 8 [41600/50000 (83%)]\tLoss: 0.033641\n",
      "Train Epoch: 8 [42240/50000 (84%)]\tLoss: 0.034178\n",
      "Train Epoch: 8 [42880/50000 (86%)]\tLoss: 0.113227\n",
      "Train Epoch: 8 [43520/50000 (87%)]\tLoss: 0.026813\n",
      "Train Epoch: 8 [44160/50000 (88%)]\tLoss: 0.144910\n",
      "Train Epoch: 8 [44800/50000 (90%)]\tLoss: 0.032255\n",
      "Train Epoch: 8 [45440/50000 (91%)]\tLoss: 0.114102\n",
      "Train Epoch: 8 [46080/50000 (92%)]\tLoss: 0.053520\n",
      "Train Epoch: 8 [46720/50000 (93%)]\tLoss: 0.079627\n",
      "Train Epoch: 8 [47360/50000 (95%)]\tLoss: 0.011723\n",
      "Train Epoch: 8 [48000/50000 (96%)]\tLoss: 0.119030\n",
      "Train Epoch: 8 [48640/50000 (97%)]\tLoss: 0.125242\n",
      "Train Epoch: 8 [49280/50000 (98%)]\tLoss: 0.049860\n",
      "Train Epoch: 8 [49920/50000 (100%)]\tLoss: 0.085919\n",
      "\n",
      "Test set: Avg. loss: 1.0466, Accuracy: 7885/10000 (79%)\n",
      "\n",
      "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.001666\n",
      "Train Epoch: 9 [640/50000 (1%)]\tLoss: 0.038288\n",
      "Train Epoch: 9 [1280/50000 (3%)]\tLoss: 0.062854\n",
      "Train Epoch: 9 [1920/50000 (4%)]\tLoss: 0.017941\n",
      "Train Epoch: 9 [2560/50000 (5%)]\tLoss: 0.013781\n",
      "Train Epoch: 9 [3200/50000 (6%)]\tLoss: 0.043492\n",
      "Train Epoch: 9 [3840/50000 (8%)]\tLoss: 0.003363\n",
      "Train Epoch: 9 [4480/50000 (9%)]\tLoss: 0.028752\n",
      "Train Epoch: 9 [5120/50000 (10%)]\tLoss: 0.004203\n",
      "Train Epoch: 9 [5760/50000 (12%)]\tLoss: 0.018387\n",
      "Train Epoch: 9 [6400/50000 (13%)]\tLoss: 0.016442\n",
      "Train Epoch: 9 [7040/50000 (14%)]\tLoss: 0.004911\n",
      "Train Epoch: 9 [7680/50000 (15%)]\tLoss: 0.010451\n",
      "Train Epoch: 9 [8320/50000 (17%)]\tLoss: 0.082005\n",
      "Train Epoch: 9 [8960/50000 (18%)]\tLoss: 0.008459\n",
      "Train Epoch: 9 [9600/50000 (19%)]\tLoss: 0.060029\n",
      "Train Epoch: 9 [10240/50000 (20%)]\tLoss: 0.005501\n",
      "Train Epoch: 9 [10880/50000 (22%)]\tLoss: 0.007220\n",
      "Train Epoch: 9 [11520/50000 (23%)]\tLoss: 0.012909\n",
      "Train Epoch: 9 [12160/50000 (24%)]\tLoss: 0.015507\n",
      "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.025382\n",
      "Train Epoch: 9 [13440/50000 (27%)]\tLoss: 0.025750\n",
      "Train Epoch: 9 [14080/50000 (28%)]\tLoss: 0.024408\n",
      "Train Epoch: 9 [14720/50000 (29%)]\tLoss: 0.058922\n",
      "Train Epoch: 9 [15360/50000 (31%)]\tLoss: 0.009541\n",
      "Train Epoch: 9 [16000/50000 (32%)]\tLoss: 0.110078\n",
      "Train Epoch: 9 [16640/50000 (33%)]\tLoss: 0.043231\n",
      "Train Epoch: 9 [17280/50000 (35%)]\tLoss: 0.067896\n",
      "Train Epoch: 9 [17920/50000 (36%)]\tLoss: 0.052550\n",
      "Train Epoch: 9 [18560/50000 (37%)]\tLoss: 0.033031\n",
      "Train Epoch: 9 [19200/50000 (38%)]\tLoss: 0.015256\n",
      "Train Epoch: 9 [19840/50000 (40%)]\tLoss: 0.005716\n",
      "Train Epoch: 9 [20480/50000 (41%)]\tLoss: 0.004623\n",
      "Train Epoch: 9 [21120/50000 (42%)]\tLoss: 0.008724\n",
      "Train Epoch: 9 [21760/50000 (43%)]\tLoss: 0.060919\n",
      "Train Epoch: 9 [22400/50000 (45%)]\tLoss: 0.093572\n",
      "Train Epoch: 9 [23040/50000 (46%)]\tLoss: 0.069888\n",
      "Train Epoch: 9 [23680/50000 (47%)]\tLoss: 0.073114\n",
      "Train Epoch: 9 [24320/50000 (49%)]\tLoss: 0.044948\n",
      "Train Epoch: 9 [24960/50000 (50%)]\tLoss: 0.046702\n",
      "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.032230\n",
      "Train Epoch: 9 [26240/50000 (52%)]\tLoss: 0.033719\n",
      "Train Epoch: 9 [26880/50000 (54%)]\tLoss: 0.006146\n",
      "Train Epoch: 9 [27520/50000 (55%)]\tLoss: 0.019161\n",
      "Train Epoch: 9 [28160/50000 (56%)]\tLoss: 0.008137\n",
      "Train Epoch: 9 [28800/50000 (58%)]\tLoss: 0.029002\n",
      "Train Epoch: 9 [29440/50000 (59%)]\tLoss: 0.057292\n",
      "Train Epoch: 9 [30080/50000 (60%)]\tLoss: 0.011759\n",
      "Train Epoch: 9 [30720/50000 (61%)]\tLoss: 0.014075\n",
      "Train Epoch: 9 [31360/50000 (63%)]\tLoss: 0.051377\n",
      "Train Epoch: 9 [32000/50000 (64%)]\tLoss: 0.007404\n",
      "Train Epoch: 9 [32640/50000 (65%)]\tLoss: 0.088647\n",
      "Train Epoch: 9 [33280/50000 (66%)]\tLoss: 0.052982\n",
      "Train Epoch: 9 [33920/50000 (68%)]\tLoss: 0.023342\n",
      "Train Epoch: 9 [34560/50000 (69%)]\tLoss: 0.010424\n",
      "Train Epoch: 9 [35200/50000 (70%)]\tLoss: 0.004727\n",
      "Train Epoch: 9 [35840/50000 (72%)]\tLoss: 0.037906\n",
      "Train Epoch: 9 [36480/50000 (73%)]\tLoss: 0.144556\n",
      "Train Epoch: 9 [37120/50000 (74%)]\tLoss: 0.034670\n",
      "Train Epoch: 9 [37760/50000 (75%)]\tLoss: 0.018749\n",
      "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.126586\n",
      "Train Epoch: 9 [39040/50000 (78%)]\tLoss: 0.017303\n",
      "Train Epoch: 9 [39680/50000 (79%)]\tLoss: 0.033773\n",
      "Train Epoch: 9 [40320/50000 (81%)]\tLoss: 0.015433\n",
      "Train Epoch: 9 [40960/50000 (82%)]\tLoss: 0.008497\n",
      "Train Epoch: 9 [41600/50000 (83%)]\tLoss: 0.043888\n",
      "Train Epoch: 9 [42240/50000 (84%)]\tLoss: 0.063273\n",
      "Train Epoch: 9 [42880/50000 (86%)]\tLoss: 0.049886\n",
      "Train Epoch: 9 [43520/50000 (87%)]\tLoss: 0.029364\n",
      "Train Epoch: 9 [44160/50000 (88%)]\tLoss: 0.032706\n",
      "Train Epoch: 9 [44800/50000 (90%)]\tLoss: 0.088845\n",
      "Train Epoch: 9 [45440/50000 (91%)]\tLoss: 0.036312\n",
      "Train Epoch: 9 [46080/50000 (92%)]\tLoss: 0.095278\n",
      "Train Epoch: 9 [46720/50000 (93%)]\tLoss: 0.098779\n",
      "Train Epoch: 9 [47360/50000 (95%)]\tLoss: 0.048700\n",
      "Train Epoch: 9 [48000/50000 (96%)]\tLoss: 0.006952\n",
      "Train Epoch: 9 [48640/50000 (97%)]\tLoss: 0.069690\n",
      "Train Epoch: 9 [49280/50000 (98%)]\tLoss: 0.066212\n",
      "Train Epoch: 9 [49920/50000 (100%)]\tLoss: 0.018746\n",
      "\n",
      "Test set: Avg. loss: 1.0934, Accuracy: 7925/10000 (79%)\n",
      "\n",
      "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.043628\n",
      "Train Epoch: 10 [640/50000 (1%)]\tLoss: 0.042560\n",
      "Train Epoch: 10 [1280/50000 (3%)]\tLoss: 0.028417\n",
      "Train Epoch: 10 [1920/50000 (4%)]\tLoss: 0.006850\n",
      "Train Epoch: 10 [2560/50000 (5%)]\tLoss: 0.055389\n",
      "Train Epoch: 10 [3200/50000 (6%)]\tLoss: 0.106787\n",
      "Train Epoch: 10 [3840/50000 (8%)]\tLoss: 0.016333\n",
      "Train Epoch: 10 [4480/50000 (9%)]\tLoss: 0.014841\n",
      "Train Epoch: 10 [5120/50000 (10%)]\tLoss: 0.042779\n",
      "Train Epoch: 10 [5760/50000 (12%)]\tLoss: 0.008746\n",
      "Train Epoch: 10 [6400/50000 (13%)]\tLoss: 0.114565\n",
      "Train Epoch: 10 [7040/50000 (14%)]\tLoss: 0.035597\n",
      "Train Epoch: 10 [7680/50000 (15%)]\tLoss: 0.055969\n",
      "Train Epoch: 10 [8320/50000 (17%)]\tLoss: 0.055535\n",
      "Train Epoch: 10 [8960/50000 (18%)]\tLoss: 0.089338\n",
      "Train Epoch: 10 [9600/50000 (19%)]\tLoss: 0.006207\n",
      "Train Epoch: 10 [10240/50000 (20%)]\tLoss: 0.041899\n",
      "Train Epoch: 10 [10880/50000 (22%)]\tLoss: 0.074840\n",
      "Train Epoch: 10 [11520/50000 (23%)]\tLoss: 0.072630\n",
      "Train Epoch: 10 [12160/50000 (24%)]\tLoss: 0.011843\n",
      "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 0.022750\n",
      "Train Epoch: 10 [13440/50000 (27%)]\tLoss: 0.019048\n",
      "Train Epoch: 10 [14080/50000 (28%)]\tLoss: 0.053422\n",
      "Train Epoch: 10 [14720/50000 (29%)]\tLoss: 0.039376\n",
      "Train Epoch: 10 [15360/50000 (31%)]\tLoss: 0.006884\n",
      "Train Epoch: 10 [16000/50000 (32%)]\tLoss: 0.006812\n",
      "Train Epoch: 10 [16640/50000 (33%)]\tLoss: 0.111167\n",
      "Train Epoch: 10 [17280/50000 (35%)]\tLoss: 0.057906\n",
      "Train Epoch: 10 [17920/50000 (36%)]\tLoss: 0.089771\n",
      "Train Epoch: 10 [18560/50000 (37%)]\tLoss: 0.036589\n",
      "Train Epoch: 10 [19200/50000 (38%)]\tLoss: 0.020622\n",
      "Train Epoch: 10 [19840/50000 (40%)]\tLoss: 0.022405\n",
      "Train Epoch: 10 [20480/50000 (41%)]\tLoss: 0.042148\n",
      "Train Epoch: 10 [21120/50000 (42%)]\tLoss: 0.023158\n",
      "Train Epoch: 10 [21760/50000 (43%)]\tLoss: 0.008685\n",
      "Train Epoch: 10 [22400/50000 (45%)]\tLoss: 0.053642\n",
      "Train Epoch: 10 [23040/50000 (46%)]\tLoss: 0.029969\n",
      "Train Epoch: 10 [23680/50000 (47%)]\tLoss: 0.038925\n",
      "Train Epoch: 10 [24320/50000 (49%)]\tLoss: 0.088078\n",
      "Train Epoch: 10 [24960/50000 (50%)]\tLoss: 0.019046\n",
      "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.031326\n",
      "Train Epoch: 10 [26240/50000 (52%)]\tLoss: 0.067503\n",
      "Train Epoch: 10 [26880/50000 (54%)]\tLoss: 0.019600\n",
      "Train Epoch: 10 [27520/50000 (55%)]\tLoss: 0.003532\n",
      "Train Epoch: 10 [28160/50000 (56%)]\tLoss: 0.067907\n",
      "Train Epoch: 10 [28800/50000 (58%)]\tLoss: 0.073415\n",
      "Train Epoch: 10 [29440/50000 (59%)]\tLoss: 0.117322\n",
      "Train Epoch: 10 [30080/50000 (60%)]\tLoss: 0.074448\n",
      "Train Epoch: 10 [30720/50000 (61%)]\tLoss: 0.007855\n",
      "Train Epoch: 10 [31360/50000 (63%)]\tLoss: 0.102196\n",
      "Train Epoch: 10 [32000/50000 (64%)]\tLoss: 0.012909\n",
      "Train Epoch: 10 [32640/50000 (65%)]\tLoss: 0.023119\n",
      "Train Epoch: 10 [33280/50000 (66%)]\tLoss: 0.031251\n",
      "Train Epoch: 10 [33920/50000 (68%)]\tLoss: 0.028180\n",
      "Train Epoch: 10 [34560/50000 (69%)]\tLoss: 0.040020\n",
      "Train Epoch: 10 [35200/50000 (70%)]\tLoss: 0.114039\n",
      "Train Epoch: 10 [35840/50000 (72%)]\tLoss: 0.013153\n",
      "Train Epoch: 10 [36480/50000 (73%)]\tLoss: 0.038980\n",
      "Train Epoch: 10 [37120/50000 (74%)]\tLoss: 0.031421\n",
      "Train Epoch: 10 [37760/50000 (75%)]\tLoss: 0.025949\n",
      "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 0.041078\n",
      "Train Epoch: 10 [39040/50000 (78%)]\tLoss: 0.031888\n",
      "Train Epoch: 10 [39680/50000 (79%)]\tLoss: 0.041248\n",
      "Train Epoch: 10 [40320/50000 (81%)]\tLoss: 0.005686\n",
      "Train Epoch: 10 [40960/50000 (82%)]\tLoss: 0.012445\n",
      "Train Epoch: 10 [41600/50000 (83%)]\tLoss: 0.024050\n",
      "Train Epoch: 10 [42240/50000 (84%)]\tLoss: 0.010614\n",
      "Train Epoch: 10 [42880/50000 (86%)]\tLoss: 0.049362\n",
      "Train Epoch: 10 [43520/50000 (87%)]\tLoss: 0.018769\n",
      "Train Epoch: 10 [44160/50000 (88%)]\tLoss: 0.069592\n",
      "Train Epoch: 10 [44800/50000 (90%)]\tLoss: 0.090715\n",
      "Train Epoch: 10 [45440/50000 (91%)]\tLoss: 0.125090\n",
      "Train Epoch: 10 [46080/50000 (92%)]\tLoss: 0.139162\n",
      "Train Epoch: 10 [46720/50000 (93%)]\tLoss: 0.047226\n",
      "Train Epoch: 10 [47360/50000 (95%)]\tLoss: 0.084308\n",
      "Train Epoch: 10 [48000/50000 (96%)]\tLoss: 0.046520\n",
      "Train Epoch: 10 [48640/50000 (97%)]\tLoss: 0.081508\n",
      "Train Epoch: 10 [49280/50000 (98%)]\tLoss: 0.007682\n",
      "Train Epoch: 10 [49920/50000 (100%)]\tLoss: 0.031443\n",
      "\n",
      "Test set: Avg. loss: 1.1522, Accuracy: 7895/10000 (79%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):  \n",
    "    train_resnet(epoch, model, cifar10_train_loader, optimizer, log_interval, train_losses, train_counter)\n",
    "    test_losses = []\n",
    "    test_resnet(testmodel,test_loader_pca,test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.292453\n",
      "Train Epoch: 1 [640/50000 (1%)]\tLoss: 2.288550\n",
      "Train Epoch: 1 [1280/50000 (3%)]\tLoss: 2.327415\n",
      "Train Epoch: 1 [1920/50000 (4%)]\tLoss: 2.294276\n",
      "Train Epoch: 1 [2560/50000 (5%)]\tLoss: 2.319928\n",
      "Train Epoch: 1 [3200/50000 (6%)]\tLoss: 2.334350\n",
      "Train Epoch: 1 [3840/50000 (8%)]\tLoss: 2.333319\n",
      "Train Epoch: 1 [4480/50000 (9%)]\tLoss: 2.300523\n",
      "Train Epoch: 1 [5120/50000 (10%)]\tLoss: 2.361311\n",
      "Train Epoch: 1 [5760/50000 (12%)]\tLoss: 2.352684\n",
      "Train Epoch: 1 [6400/50000 (13%)]\tLoss: 2.300988\n",
      "Train Epoch: 1 [7040/50000 (14%)]\tLoss: 2.318786\n",
      "Train Epoch: 1 [7680/50000 (15%)]\tLoss: 2.326198\n",
      "Train Epoch: 1 [8320/50000 (17%)]\tLoss: 2.306401\n",
      "Train Epoch: 1 [8960/50000 (18%)]\tLoss: 2.318380\n",
      "Train Epoch: 1 [9600/50000 (19%)]\tLoss: 2.336225\n",
      "Train Epoch: 1 [10240/50000 (20%)]\tLoss: 2.326647\n",
      "Train Epoch: 1 [10880/50000 (22%)]\tLoss: 2.315620\n",
      "Train Epoch: 1 [11520/50000 (23%)]\tLoss: 2.314243\n",
      "Train Epoch: 1 [12160/50000 (24%)]\tLoss: 2.304264\n",
      "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 2.315890\n",
      "Train Epoch: 1 [13440/50000 (27%)]\tLoss: 2.285996\n",
      "Train Epoch: 1 [14080/50000 (28%)]\tLoss: 2.264592\n",
      "Train Epoch: 1 [14720/50000 (29%)]\tLoss: 2.302531\n",
      "Train Epoch: 1 [15360/50000 (31%)]\tLoss: 2.335203\n",
      "Train Epoch: 1 [16000/50000 (32%)]\tLoss: 2.304984\n",
      "Train Epoch: 1 [16640/50000 (33%)]\tLoss: 2.338575\n",
      "Train Epoch: 1 [17280/50000 (35%)]\tLoss: 2.338130\n",
      "Train Epoch: 1 [17920/50000 (36%)]\tLoss: 2.303442\n",
      "Train Epoch: 1 [18560/50000 (37%)]\tLoss: 2.316226\n",
      "Train Epoch: 1 [19200/50000 (38%)]\tLoss: 2.321287\n",
      "Train Epoch: 1 [19840/50000 (40%)]\tLoss: 2.315712\n",
      "Train Epoch: 1 [20480/50000 (41%)]\tLoss: 2.326022\n",
      "Train Epoch: 1 [21120/50000 (42%)]\tLoss: 2.292960\n",
      "Train Epoch: 1 [21760/50000 (43%)]\tLoss: 2.317163\n",
      "Train Epoch: 1 [22400/50000 (45%)]\tLoss: 2.253783\n",
      "Train Epoch: 1 [23040/50000 (46%)]\tLoss: 2.312580\n",
      "Train Epoch: 1 [23680/50000 (47%)]\tLoss: 2.318295\n",
      "Train Epoch: 1 [24320/50000 (49%)]\tLoss: 2.280211\n",
      "Train Epoch: 1 [24960/50000 (50%)]\tLoss: 2.313699\n",
      "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 2.308209\n",
      "Train Epoch: 1 [26240/50000 (52%)]\tLoss: 2.334424\n",
      "Train Epoch: 1 [26880/50000 (54%)]\tLoss: 2.263385\n",
      "Train Epoch: 1 [27520/50000 (55%)]\tLoss: 2.347969\n",
      "Train Epoch: 1 [28160/50000 (56%)]\tLoss: 2.320027\n",
      "Train Epoch: 1 [28800/50000 (58%)]\tLoss: 2.299025\n",
      "Train Epoch: 1 [29440/50000 (59%)]\tLoss: 2.301343\n",
      "Train Epoch: 1 [30080/50000 (60%)]\tLoss: 2.273691\n",
      "Train Epoch: 1 [30720/50000 (61%)]\tLoss: 2.282498\n",
      "Train Epoch: 1 [31360/50000 (63%)]\tLoss: 2.300063\n",
      "Train Epoch: 1 [32000/50000 (64%)]\tLoss: 2.237855\n",
      "Train Epoch: 1 [32640/50000 (65%)]\tLoss: 2.315060\n",
      "Train Epoch: 1 [33280/50000 (66%)]\tLoss: 2.319311\n",
      "Train Epoch: 1 [33920/50000 (68%)]\tLoss: 2.295962\n",
      "Train Epoch: 1 [34560/50000 (69%)]\tLoss: 2.287288\n",
      "Train Epoch: 1 [35200/50000 (70%)]\tLoss: 2.288057\n",
      "Train Epoch: 1 [35840/50000 (72%)]\tLoss: 2.331403\n",
      "Train Epoch: 1 [36480/50000 (73%)]\tLoss: 2.313112\n",
      "Train Epoch: 1 [37120/50000 (74%)]\tLoss: 2.309431\n",
      "Train Epoch: 1 [37760/50000 (75%)]\tLoss: 2.312208\n",
      "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 2.323333\n",
      "Train Epoch: 1 [39040/50000 (78%)]\tLoss: 2.286194\n",
      "Train Epoch: 1 [39680/50000 (79%)]\tLoss: 2.310295\n",
      "Train Epoch: 1 [40320/50000 (81%)]\tLoss: 2.310166\n",
      "Train Epoch: 1 [40960/50000 (82%)]\tLoss: 2.333804\n",
      "Train Epoch: 1 [41600/50000 (83%)]\tLoss: 2.296281\n",
      "Train Epoch: 1 [42240/50000 (84%)]\tLoss: 2.344252\n",
      "Train Epoch: 1 [42880/50000 (86%)]\tLoss: 2.318836\n",
      "Train Epoch: 1 [43520/50000 (87%)]\tLoss: 2.354200\n",
      "Train Epoch: 1 [44160/50000 (88%)]\tLoss: 2.280679\n",
      "Train Epoch: 1 [44800/50000 (90%)]\tLoss: 2.298301\n",
      "Train Epoch: 1 [45440/50000 (91%)]\tLoss: 2.326714\n",
      "Train Epoch: 1 [46080/50000 (92%)]\tLoss: 2.306606\n",
      "Train Epoch: 1 [46720/50000 (93%)]\tLoss: 2.281533\n",
      "Train Epoch: 1 [47360/50000 (95%)]\tLoss: 2.276623\n",
      "Train Epoch: 1 [48000/50000 (96%)]\tLoss: 2.281560\n",
      "Train Epoch: 1 [48640/50000 (97%)]\tLoss: 2.288945\n",
      "Train Epoch: 1 [49280/50000 (98%)]\tLoss: 2.322955\n",
      "Train Epoch: 1 [49920/50000 (100%)]\tLoss: 2.311350\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "train_resnet() missing 4 required positional arguments: 'optimizer', 'log_interval', 'train_losses', and 'train_counter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m train_resnet(epoch, model3, cifar10_train_loader, optimizer, log_interval, train_losses2, train_counter2)\n\u001b[0;32m      9\u001b[0m test_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 10\u001b[0m train_resnet(model3,test_loader_pca,test_losses)\n",
      "\u001b[1;31mTypeError\u001b[0m: train_resnet() missing 4 required positional arguments: 'optimizer', 'log_interval', 'train_losses', and 'train_counter'"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "\n",
    "train_losses2 = []\n",
    "train_counter2 = []\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):  \n",
    "    train_resnet(epoch, model3, cifar10_train_loader, optimizer, log_interval, train_losses2, train_counter2)\n",
    "    test_losses = []\n",
    "    test_resnet(model3,test_loader_pca,test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3115, Accuracy: 970/10000 (10%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_resnet(model3,test_loader_pca,test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/18580 (0%)]\tLoss: 1.272864\n",
      "Train Epoch: 1 [640/18580 (3%)]\tLoss: 0.395788\n",
      "Train Epoch: 1 [1280/18580 (7%)]\tLoss: 0.549133\n",
      "Train Epoch: 1 [1920/18580 (10%)]\tLoss: 0.684713\n",
      "Train Epoch: 1 [2560/18580 (14%)]\tLoss: 0.362403\n",
      "Train Epoch: 1 [3200/18580 (17%)]\tLoss: 0.319676\n",
      "Train Epoch: 1 [3840/18580 (21%)]\tLoss: 0.682662\n",
      "Train Epoch: 1 [4480/18580 (24%)]\tLoss: 0.539573\n",
      "Train Epoch: 1 [5120/18580 (27%)]\tLoss: 0.584719\n",
      "Train Epoch: 1 [5760/18580 (31%)]\tLoss: 0.337060\n",
      "Train Epoch: 1 [6400/18580 (34%)]\tLoss: 0.730592\n",
      "Train Epoch: 1 [7040/18580 (38%)]\tLoss: 0.541934\n",
      "Train Epoch: 1 [7680/18580 (41%)]\tLoss: 0.612196\n",
      "Train Epoch: 1 [8320/18580 (45%)]\tLoss: 0.350242\n",
      "Train Epoch: 1 [8960/18580 (48%)]\tLoss: 0.718655\n",
      "Train Epoch: 1 [9600/18580 (52%)]\tLoss: 0.459587\n",
      "Train Epoch: 1 [10240/18580 (55%)]\tLoss: 0.487602\n",
      "Train Epoch: 1 [10880/18580 (58%)]\tLoss: 0.585782\n",
      "Train Epoch: 1 [11520/18580 (62%)]\tLoss: 0.619536\n",
      "Train Epoch: 1 [12160/18580 (65%)]\tLoss: 0.454008\n",
      "Train Epoch: 1 [12800/18580 (69%)]\tLoss: 0.691275\n",
      "Train Epoch: 1 [13440/18580 (72%)]\tLoss: 0.600331\n",
      "Train Epoch: 1 [14080/18580 (76%)]\tLoss: 0.513626\n",
      "Train Epoch: 1 [14720/18580 (79%)]\tLoss: 0.416460\n",
      "Train Epoch: 1 [15360/18580 (82%)]\tLoss: 0.679658\n",
      "Train Epoch: 1 [16000/18580 (86%)]\tLoss: 0.400200\n",
      "Train Epoch: 1 [16640/18580 (89%)]\tLoss: 0.439658\n",
      "Train Epoch: 1 [17280/18580 (93%)]\tLoss: 0.366376\n",
      "Train Epoch: 1 [17920/18580 (96%)]\tLoss: 0.478968\n",
      "Train Epoch: 1 [5800/18580 (100%)]\tLoss: 0.772861\n",
      "Train Epoch: 2 [0/18580 (0%)]\tLoss: 0.334871\n",
      "Train Epoch: 2 [640/18580 (3%)]\tLoss: 0.328196\n",
      "Train Epoch: 2 [1280/18580 (7%)]\tLoss: 0.254752\n",
      "Train Epoch: 2 [1920/18580 (10%)]\tLoss: 0.219491\n",
      "Train Epoch: 2 [2560/18580 (14%)]\tLoss: 0.202547\n",
      "Train Epoch: 2 [3200/18580 (17%)]\tLoss: 0.440678\n",
      "Train Epoch: 2 [3840/18580 (21%)]\tLoss: 0.367428\n",
      "Train Epoch: 2 [4480/18580 (24%)]\tLoss: 0.333829\n",
      "Train Epoch: 2 [5120/18580 (27%)]\tLoss: 0.325195\n",
      "Train Epoch: 2 [5760/18580 (31%)]\tLoss: 0.265966\n",
      "Train Epoch: 2 [6400/18580 (34%)]\tLoss: 0.379522\n",
      "Train Epoch: 2 [7040/18580 (38%)]\tLoss: 0.218956\n",
      "Train Epoch: 2 [7680/18580 (41%)]\tLoss: 0.473453\n",
      "Train Epoch: 2 [8320/18580 (45%)]\tLoss: 0.269254\n",
      "Train Epoch: 2 [8960/18580 (48%)]\tLoss: 0.481220\n",
      "Train Epoch: 2 [9600/18580 (52%)]\tLoss: 0.460361\n",
      "Train Epoch: 2 [10240/18580 (55%)]\tLoss: 0.269068\n",
      "Train Epoch: 2 [10880/18580 (58%)]\tLoss: 0.159086\n",
      "Train Epoch: 2 [11520/18580 (62%)]\tLoss: 0.201950\n",
      "Train Epoch: 2 [12160/18580 (65%)]\tLoss: 0.265124\n",
      "Train Epoch: 2 [12800/18580 (69%)]\tLoss: 0.370339\n",
      "Train Epoch: 2 [13440/18580 (72%)]\tLoss: 0.334752\n",
      "Train Epoch: 2 [14080/18580 (76%)]\tLoss: 0.427710\n",
      "Train Epoch: 2 [14720/18580 (79%)]\tLoss: 0.398353\n",
      "Train Epoch: 2 [15360/18580 (82%)]\tLoss: 0.302400\n",
      "Train Epoch: 2 [16000/18580 (86%)]\tLoss: 0.479436\n",
      "Train Epoch: 2 [16640/18580 (89%)]\tLoss: 0.370346\n",
      "Train Epoch: 2 [17280/18580 (93%)]\tLoss: 0.177777\n",
      "Train Epoch: 2 [17920/18580 (96%)]\tLoss: 0.264234\n",
      "Train Epoch: 2 [5800/18580 (100%)]\tLoss: 0.209836\n",
      "Train Epoch: 3 [0/18580 (0%)]\tLoss: 0.264762\n",
      "Train Epoch: 3 [640/18580 (3%)]\tLoss: 0.279054\n",
      "Train Epoch: 3 [1280/18580 (7%)]\tLoss: 0.296560\n",
      "Train Epoch: 3 [1920/18580 (10%)]\tLoss: 0.127887\n",
      "Train Epoch: 3 [2560/18580 (14%)]\tLoss: 0.305799\n",
      "Train Epoch: 3 [3200/18580 (17%)]\tLoss: 0.394857\n",
      "Train Epoch: 3 [3840/18580 (21%)]\tLoss: 0.192472\n",
      "Train Epoch: 3 [4480/18580 (24%)]\tLoss: 0.296266\n",
      "Train Epoch: 3 [5120/18580 (27%)]\tLoss: 0.106225\n",
      "Train Epoch: 3 [5760/18580 (31%)]\tLoss: 0.229752\n",
      "Train Epoch: 3 [6400/18580 (34%)]\tLoss: 0.488393\n",
      "Train Epoch: 3 [7040/18580 (38%)]\tLoss: 0.156226\n",
      "Train Epoch: 3 [7680/18580 (41%)]\tLoss: 0.115345\n",
      "Train Epoch: 3 [8320/18580 (45%)]\tLoss: 0.299529\n",
      "Train Epoch: 3 [8960/18580 (48%)]\tLoss: 0.175798\n",
      "Train Epoch: 3 [9600/18580 (52%)]\tLoss: 0.268082\n",
      "Train Epoch: 3 [10240/18580 (55%)]\tLoss: 0.367105\n",
      "Train Epoch: 3 [10880/18580 (58%)]\tLoss: 0.332686\n",
      "Train Epoch: 3 [11520/18580 (62%)]\tLoss: 0.260412\n",
      "Train Epoch: 3 [12160/18580 (65%)]\tLoss: 0.114558\n",
      "Train Epoch: 3 [12800/18580 (69%)]\tLoss: 0.155928\n",
      "Train Epoch: 3 [13440/18580 (72%)]\tLoss: 0.276233\n",
      "Train Epoch: 3 [14080/18580 (76%)]\tLoss: 0.330381\n",
      "Train Epoch: 3 [14720/18580 (79%)]\tLoss: 0.456160\n",
      "Train Epoch: 3 [15360/18580 (82%)]\tLoss: 0.174314\n",
      "Train Epoch: 3 [16000/18580 (86%)]\tLoss: 0.176518\n",
      "Train Epoch: 3 [16640/18580 (89%)]\tLoss: 0.548679\n",
      "Train Epoch: 3 [17280/18580 (93%)]\tLoss: 0.147539\n",
      "Train Epoch: 3 [17920/18580 (96%)]\tLoss: 0.140809\n",
      "Train Epoch: 3 [5800/18580 (100%)]\tLoss: 0.431765\n",
      "Train Epoch: 4 [0/18580 (0%)]\tLoss: 0.144560\n",
      "Train Epoch: 4 [640/18580 (3%)]\tLoss: 0.216200\n",
      "Train Epoch: 4 [1280/18580 (7%)]\tLoss: 0.178821\n",
      "Train Epoch: 4 [1920/18580 (10%)]\tLoss: 0.118212\n",
      "Train Epoch: 4 [2560/18580 (14%)]\tLoss: 0.176729\n",
      "Train Epoch: 4 [3200/18580 (17%)]\tLoss: 0.132270\n",
      "Train Epoch: 4 [3840/18580 (21%)]\tLoss: 0.213660\n",
      "Train Epoch: 4 [4480/18580 (24%)]\tLoss: 0.112736\n",
      "Train Epoch: 4 [5120/18580 (27%)]\tLoss: 0.104189\n",
      "Train Epoch: 4 [5760/18580 (31%)]\tLoss: 0.156217\n",
      "Train Epoch: 4 [6400/18580 (34%)]\tLoss: 0.336690\n",
      "Train Epoch: 4 [7040/18580 (38%)]\tLoss: 0.137323\n",
      "Train Epoch: 4 [7680/18580 (41%)]\tLoss: 0.201920\n",
      "Train Epoch: 4 [8320/18580 (45%)]\tLoss: 0.106036\n",
      "Train Epoch: 4 [8960/18580 (48%)]\tLoss: 0.350316\n",
      "Train Epoch: 4 [9600/18580 (52%)]\tLoss: 0.144800\n",
      "Train Epoch: 4 [10240/18580 (55%)]\tLoss: 0.145288\n",
      "Train Epoch: 4 [10880/18580 (58%)]\tLoss: 0.310491\n",
      "Train Epoch: 4 [11520/18580 (62%)]\tLoss: 0.102846\n",
      "Train Epoch: 4 [12160/18580 (65%)]\tLoss: 0.218403\n",
      "Train Epoch: 4 [12800/18580 (69%)]\tLoss: 0.203220\n",
      "Train Epoch: 4 [13440/18580 (72%)]\tLoss: 0.233638\n",
      "Train Epoch: 4 [14080/18580 (76%)]\tLoss: 0.160169\n",
      "Train Epoch: 4 [14720/18580 (79%)]\tLoss: 0.139475\n",
      "Train Epoch: 4 [15360/18580 (82%)]\tLoss: 0.293575\n",
      "Train Epoch: 4 [16000/18580 (86%)]\tLoss: 0.151344\n",
      "Train Epoch: 4 [16640/18580 (89%)]\tLoss: 0.149207\n",
      "Train Epoch: 4 [17280/18580 (93%)]\tLoss: 0.246616\n",
      "Train Epoch: 4 [17920/18580 (96%)]\tLoss: 0.148858\n",
      "Train Epoch: 4 [5800/18580 (100%)]\tLoss: 0.813941\n",
      "Train Epoch: 5 [0/18580 (0%)]\tLoss: 0.185042\n",
      "Train Epoch: 5 [640/18580 (3%)]\tLoss: 0.131534\n",
      "Train Epoch: 5 [1280/18580 (7%)]\tLoss: 0.163957\n",
      "Train Epoch: 5 [1920/18580 (10%)]\tLoss: 0.138878\n",
      "Train Epoch: 5 [2560/18580 (14%)]\tLoss: 0.098634\n",
      "Train Epoch: 5 [3200/18580 (17%)]\tLoss: 0.201797\n",
      "Train Epoch: 5 [3840/18580 (21%)]\tLoss: 0.196109\n",
      "Train Epoch: 5 [4480/18580 (24%)]\tLoss: 0.153203\n",
      "Train Epoch: 5 [5120/18580 (27%)]\tLoss: 0.091331\n",
      "Train Epoch: 5 [5760/18580 (31%)]\tLoss: 0.108028\n",
      "Train Epoch: 5 [6400/18580 (34%)]\tLoss: 0.165259\n",
      "Train Epoch: 5 [7040/18580 (38%)]\tLoss: 0.052337\n",
      "Train Epoch: 5 [7680/18580 (41%)]\tLoss: 0.220070\n",
      "Train Epoch: 5 [8320/18580 (45%)]\tLoss: 0.168343\n",
      "Train Epoch: 5 [8960/18580 (48%)]\tLoss: 0.163552\n",
      "Train Epoch: 5 [9600/18580 (52%)]\tLoss: 0.135485\n",
      "Train Epoch: 5 [10240/18580 (55%)]\tLoss: 0.148645\n",
      "Train Epoch: 5 [10880/18580 (58%)]\tLoss: 0.196733\n",
      "Train Epoch: 5 [11520/18580 (62%)]\tLoss: 0.202237\n",
      "Train Epoch: 5 [12160/18580 (65%)]\tLoss: 0.117422\n",
      "Train Epoch: 5 [12800/18580 (69%)]\tLoss: 0.143824\n",
      "Train Epoch: 5 [13440/18580 (72%)]\tLoss: 0.160807\n",
      "Train Epoch: 5 [14080/18580 (76%)]\tLoss: 0.094835\n",
      "Train Epoch: 5 [14720/18580 (79%)]\tLoss: 0.119792\n",
      "Train Epoch: 5 [15360/18580 (82%)]\tLoss: 0.288561\n",
      "Train Epoch: 5 [16000/18580 (86%)]\tLoss: 0.115187\n",
      "Train Epoch: 5 [16640/18580 (89%)]\tLoss: 0.081530\n",
      "Train Epoch: 5 [17280/18580 (93%)]\tLoss: 0.179919\n",
      "Train Epoch: 5 [17920/18580 (96%)]\tLoss: 0.164258\n",
      "Train Epoch: 5 [5800/18580 (100%)]\tLoss: 0.123366\n",
      "Train Epoch: 6 [0/18580 (0%)]\tLoss: 0.094753\n",
      "Train Epoch: 6 [640/18580 (3%)]\tLoss: 0.055312\n",
      "Train Epoch: 6 [1280/18580 (7%)]\tLoss: 0.069185\n",
      "Train Epoch: 6 [1920/18580 (10%)]\tLoss: 0.107840\n",
      "Train Epoch: 6 [2560/18580 (14%)]\tLoss: 0.143000\n",
      "Train Epoch: 6 [3200/18580 (17%)]\tLoss: 0.129897\n",
      "Train Epoch: 6 [3840/18580 (21%)]\tLoss: 0.076518\n",
      "Train Epoch: 6 [4480/18580 (24%)]\tLoss: 0.209181\n",
      "Train Epoch: 6 [5120/18580 (27%)]\tLoss: 0.135781\n",
      "Train Epoch: 6 [5760/18580 (31%)]\tLoss: 0.183958\n",
      "Train Epoch: 6 [6400/18580 (34%)]\tLoss: 0.232355\n",
      "Train Epoch: 6 [7040/18580 (38%)]\tLoss: 0.048599\n",
      "Train Epoch: 6 [7680/18580 (41%)]\tLoss: 0.225793\n",
      "Train Epoch: 6 [8320/18580 (45%)]\tLoss: 0.191861\n",
      "Train Epoch: 6 [8960/18580 (48%)]\tLoss: 0.224173\n",
      "Train Epoch: 6 [9600/18580 (52%)]\tLoss: 0.185118\n",
      "Train Epoch: 6 [10240/18580 (55%)]\tLoss: 0.149727\n",
      "Train Epoch: 6 [10880/18580 (58%)]\tLoss: 0.143466\n",
      "Train Epoch: 6 [11520/18580 (62%)]\tLoss: 0.175346\n",
      "Train Epoch: 6 [12160/18580 (65%)]\tLoss: 0.116851\n",
      "Train Epoch: 6 [12800/18580 (69%)]\tLoss: 0.206524\n",
      "Train Epoch: 6 [13440/18580 (72%)]\tLoss: 0.269621\n",
      "Train Epoch: 6 [14080/18580 (76%)]\tLoss: 0.442782\n",
      "Train Epoch: 6 [14720/18580 (79%)]\tLoss: 0.109154\n",
      "Train Epoch: 6 [15360/18580 (82%)]\tLoss: 0.035780\n",
      "Train Epoch: 6 [16000/18580 (86%)]\tLoss: 0.138136\n",
      "Train Epoch: 6 [16640/18580 (89%)]\tLoss: 0.127279\n",
      "Train Epoch: 6 [17280/18580 (93%)]\tLoss: 0.114524\n",
      "Train Epoch: 6 [17920/18580 (96%)]\tLoss: 0.168863\n",
      "Train Epoch: 6 [5800/18580 (100%)]\tLoss: 0.388351\n",
      "Train Epoch: 7 [0/18580 (0%)]\tLoss: 0.223587\n",
      "Train Epoch: 7 [640/18580 (3%)]\tLoss: 0.079330\n",
      "Train Epoch: 7 [1280/18580 (7%)]\tLoss: 0.162920\n",
      "Train Epoch: 7 [1920/18580 (10%)]\tLoss: 0.143273\n",
      "Train Epoch: 7 [2560/18580 (14%)]\tLoss: 0.088235\n",
      "Train Epoch: 7 [3200/18580 (17%)]\tLoss: 0.086333\n",
      "Train Epoch: 7 [3840/18580 (21%)]\tLoss: 0.130294\n",
      "Train Epoch: 7 [4480/18580 (24%)]\tLoss: 0.116568\n",
      "Train Epoch: 7 [5120/18580 (27%)]\tLoss: 0.122095\n",
      "Train Epoch: 7 [5760/18580 (31%)]\tLoss: 0.072018\n",
      "Train Epoch: 7 [6400/18580 (34%)]\tLoss: 0.112896\n",
      "Train Epoch: 7 [7040/18580 (38%)]\tLoss: 0.020394\n",
      "Train Epoch: 7 [7680/18580 (41%)]\tLoss: 0.052404\n",
      "Train Epoch: 7 [8320/18580 (45%)]\tLoss: 0.148733\n",
      "Train Epoch: 7 [8960/18580 (48%)]\tLoss: 0.237067\n",
      "Train Epoch: 7 [9600/18580 (52%)]\tLoss: 0.087390\n",
      "Train Epoch: 7 [10240/18580 (55%)]\tLoss: 0.083160\n",
      "Train Epoch: 7 [10880/18580 (58%)]\tLoss: 0.067717\n",
      "Train Epoch: 7 [11520/18580 (62%)]\tLoss: 0.117687\n",
      "Train Epoch: 7 [12160/18580 (65%)]\tLoss: 0.173233\n",
      "Train Epoch: 7 [12800/18580 (69%)]\tLoss: 0.102889\n",
      "Train Epoch: 7 [13440/18580 (72%)]\tLoss: 0.169729\n",
      "Train Epoch: 7 [14080/18580 (76%)]\tLoss: 0.285337\n",
      "Train Epoch: 7 [14720/18580 (79%)]\tLoss: 0.076430\n",
      "Train Epoch: 7 [15360/18580 (82%)]\tLoss: 0.118253\n",
      "Train Epoch: 7 [16000/18580 (86%)]\tLoss: 0.208256\n",
      "Train Epoch: 7 [16640/18580 (89%)]\tLoss: 0.193974\n",
      "Train Epoch: 7 [17280/18580 (93%)]\tLoss: 0.045787\n",
      "Train Epoch: 7 [17920/18580 (96%)]\tLoss: 0.195356\n",
      "Train Epoch: 7 [5800/18580 (100%)]\tLoss: 0.652183\n",
      "Train Epoch: 8 [0/18580 (0%)]\tLoss: 0.158394\n",
      "Train Epoch: 8 [640/18580 (3%)]\tLoss: 0.069371\n",
      "Train Epoch: 8 [1280/18580 (7%)]\tLoss: 0.058821\n",
      "Train Epoch: 8 [1920/18580 (10%)]\tLoss: 0.062723\n",
      "Train Epoch: 8 [2560/18580 (14%)]\tLoss: 0.030389\n",
      "Train Epoch: 8 [3200/18580 (17%)]\tLoss: 0.217487\n",
      "Train Epoch: 8 [3840/18580 (21%)]\tLoss: 0.066385\n",
      "Train Epoch: 8 [4480/18580 (24%)]\tLoss: 0.110072\n",
      "Train Epoch: 8 [5120/18580 (27%)]\tLoss: 0.072374\n",
      "Train Epoch: 8 [5760/18580 (31%)]\tLoss: 0.024101\n",
      "Train Epoch: 8 [6400/18580 (34%)]\tLoss: 0.159612\n",
      "Train Epoch: 8 [7040/18580 (38%)]\tLoss: 0.025440\n",
      "Train Epoch: 8 [7680/18580 (41%)]\tLoss: 0.165493\n",
      "Train Epoch: 8 [8320/18580 (45%)]\tLoss: 0.068669\n",
      "Train Epoch: 8 [8960/18580 (48%)]\tLoss: 0.061906\n",
      "Train Epoch: 8 [9600/18580 (52%)]\tLoss: 0.021651\n",
      "Train Epoch: 8 [10240/18580 (55%)]\tLoss: 0.090782\n",
      "Train Epoch: 8 [10880/18580 (58%)]\tLoss: 0.080834\n",
      "Train Epoch: 8 [11520/18580 (62%)]\tLoss: 0.070472\n",
      "Train Epoch: 8 [12160/18580 (65%)]\tLoss: 0.171928\n",
      "Train Epoch: 8 [12800/18580 (69%)]\tLoss: 0.192007\n",
      "Train Epoch: 8 [13440/18580 (72%)]\tLoss: 0.176062\n",
      "Train Epoch: 8 [14080/18580 (76%)]\tLoss: 0.093422\n",
      "Train Epoch: 8 [14720/18580 (79%)]\tLoss: 0.131161\n",
      "Train Epoch: 8 [15360/18580 (82%)]\tLoss: 0.130751\n",
      "Train Epoch: 8 [16000/18580 (86%)]\tLoss: 0.048660\n",
      "Train Epoch: 8 [16640/18580 (89%)]\tLoss: 0.099387\n",
      "Train Epoch: 8 [17280/18580 (93%)]\tLoss: 0.076009\n",
      "Train Epoch: 8 [17920/18580 (96%)]\tLoss: 0.038706\n",
      "Train Epoch: 8 [5800/18580 (100%)]\tLoss: 0.151543\n",
      "Train Epoch: 9 [0/18580 (0%)]\tLoss: 0.036243\n",
      "Train Epoch: 9 [640/18580 (3%)]\tLoss: 0.075230\n",
      "Train Epoch: 9 [1280/18580 (7%)]\tLoss: 0.008901\n",
      "Train Epoch: 9 [1920/18580 (10%)]\tLoss: 0.039910\n",
      "Train Epoch: 9 [2560/18580 (14%)]\tLoss: 0.122848\n",
      "Train Epoch: 9 [3200/18580 (17%)]\tLoss: 0.030150\n",
      "Train Epoch: 9 [3840/18580 (21%)]\tLoss: 0.013850\n",
      "Train Epoch: 9 [4480/18580 (24%)]\tLoss: 0.019771\n",
      "Train Epoch: 9 [5120/18580 (27%)]\tLoss: 0.025107\n",
      "Train Epoch: 9 [5760/18580 (31%)]\tLoss: 0.077305\n",
      "Train Epoch: 9 [6400/18580 (34%)]\tLoss: 0.057700\n",
      "Train Epoch: 9 [7040/18580 (38%)]\tLoss: 0.056486\n",
      "Train Epoch: 9 [7680/18580 (41%)]\tLoss: 0.042421\n",
      "Train Epoch: 9 [8320/18580 (45%)]\tLoss: 0.076611\n",
      "Train Epoch: 9 [8960/18580 (48%)]\tLoss: 0.080125\n",
      "Train Epoch: 9 [9600/18580 (52%)]\tLoss: 0.068566\n",
      "Train Epoch: 9 [10240/18580 (55%)]\tLoss: 0.057039\n",
      "Train Epoch: 9 [10880/18580 (58%)]\tLoss: 0.024827\n",
      "Train Epoch: 9 [11520/18580 (62%)]\tLoss: 0.034980\n",
      "Train Epoch: 9 [12160/18580 (65%)]\tLoss: 0.056026\n",
      "Train Epoch: 9 [12800/18580 (69%)]\tLoss: 0.082882\n",
      "Train Epoch: 9 [13440/18580 (72%)]\tLoss: 0.111793\n",
      "Train Epoch: 9 [14080/18580 (76%)]\tLoss: 0.046956\n",
      "Train Epoch: 9 [14720/18580 (79%)]\tLoss: 0.069819\n",
      "Train Epoch: 9 [15360/18580 (82%)]\tLoss: 0.174415\n",
      "Train Epoch: 9 [16000/18580 (86%)]\tLoss: 0.039808\n",
      "Train Epoch: 9 [16640/18580 (89%)]\tLoss: 0.033650\n",
      "Train Epoch: 9 [17280/18580 (93%)]\tLoss: 0.071099\n",
      "Train Epoch: 9 [17920/18580 (96%)]\tLoss: 0.009217\n",
      "Train Epoch: 9 [5800/18580 (100%)]\tLoss: 0.268379\n",
      "Train Epoch: 10 [0/18580 (0%)]\tLoss: 0.067986\n",
      "Train Epoch: 10 [640/18580 (3%)]\tLoss: 0.036227\n",
      "Train Epoch: 10 [1280/18580 (7%)]\tLoss: 0.043860\n",
      "Train Epoch: 10 [1920/18580 (10%)]\tLoss: 0.058273\n",
      "Train Epoch: 10 [2560/18580 (14%)]\tLoss: 0.067712\n",
      "Train Epoch: 10 [3200/18580 (17%)]\tLoss: 0.080142\n",
      "Train Epoch: 10 [3840/18580 (21%)]\tLoss: 0.081638\n",
      "Train Epoch: 10 [4480/18580 (24%)]\tLoss: 0.034752\n",
      "Train Epoch: 10 [5120/18580 (27%)]\tLoss: 0.208415\n",
      "Train Epoch: 10 [5760/18580 (31%)]\tLoss: 0.124108\n",
      "Train Epoch: 10 [6400/18580 (34%)]\tLoss: 0.126875\n",
      "Train Epoch: 10 [7040/18580 (38%)]\tLoss: 0.021978\n",
      "Train Epoch: 10 [7680/18580 (41%)]\tLoss: 0.005644\n",
      "Train Epoch: 10 [8320/18580 (45%)]\tLoss: 0.027199\n",
      "Train Epoch: 10 [8960/18580 (48%)]\tLoss: 0.083416\n",
      "Train Epoch: 10 [9600/18580 (52%)]\tLoss: 0.010301\n",
      "Train Epoch: 10 [10240/18580 (55%)]\tLoss: 0.012222\n",
      "Train Epoch: 10 [10880/18580 (58%)]\tLoss: 0.090159\n",
      "Train Epoch: 10 [11520/18580 (62%)]\tLoss: 0.042237\n",
      "Train Epoch: 10 [12160/18580 (65%)]\tLoss: 0.019650\n",
      "Train Epoch: 10 [12800/18580 (69%)]\tLoss: 0.073355\n",
      "Train Epoch: 10 [13440/18580 (72%)]\tLoss: 0.089331\n",
      "Train Epoch: 10 [14080/18580 (76%)]\tLoss: 0.078318\n",
      "Train Epoch: 10 [14720/18580 (79%)]\tLoss: 0.054122\n",
      "Train Epoch: 10 [15360/18580 (82%)]\tLoss: 0.076180\n",
      "Train Epoch: 10 [16000/18580 (86%)]\tLoss: 0.019808\n",
      "Train Epoch: 10 [16640/18580 (89%)]\tLoss: 0.016878\n",
      "Train Epoch: 10 [17280/18580 (93%)]\tLoss: 0.134959\n",
      "Train Epoch: 10 [17920/18580 (96%)]\tLoss: 0.169681\n",
      "Train Epoch: 10 [5800/18580 (100%)]\tLoss: 0.048071\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/9043 (0%)]\tLoss: 1.652664\n",
      "Train Epoch: 1 [640/9043 (7%)]\tLoss: 0.882735\n",
      "Train Epoch: 1 [1280/9043 (14%)]\tLoss: 0.403016\n",
      "Train Epoch: 1 [1920/9043 (21%)]\tLoss: 0.604351\n",
      "Train Epoch: 1 [2560/9043 (28%)]\tLoss: 0.746723\n",
      "Train Epoch: 1 [3200/9043 (35%)]\tLoss: 0.539304\n",
      "Train Epoch: 1 [3840/9043 (42%)]\tLoss: 0.545378\n",
      "Train Epoch: 1 [4480/9043 (49%)]\tLoss: 0.475437\n",
      "Train Epoch: 1 [5120/9043 (56%)]\tLoss: 0.564354\n",
      "Train Epoch: 1 [5760/9043 (63%)]\tLoss: 0.930415\n",
      "Train Epoch: 1 [6400/9043 (70%)]\tLoss: 0.645362\n",
      "Train Epoch: 1 [7040/9043 (77%)]\tLoss: 0.560283\n",
      "Train Epoch: 1 [7680/9043 (85%)]\tLoss: 0.714831\n",
      "Train Epoch: 1 [8320/9043 (92%)]\tLoss: 0.477788\n",
      "Train Epoch: 1 [8960/9043 (99%)]\tLoss: 0.425154\n",
      "Train Epoch: 2 [0/9043 (0%)]\tLoss: 0.309264\n",
      "Train Epoch: 2 [640/9043 (7%)]\tLoss: 0.355177\n",
      "Train Epoch: 2 [1280/9043 (14%)]\tLoss: 0.309148\n",
      "Train Epoch: 2 [1920/9043 (21%)]\tLoss: 0.219223\n",
      "Train Epoch: 2 [2560/9043 (28%)]\tLoss: 0.236083\n",
      "Train Epoch: 2 [3200/9043 (35%)]\tLoss: 0.289067\n",
      "Train Epoch: 2 [3840/9043 (42%)]\tLoss: 0.271493\n",
      "Train Epoch: 2 [4480/9043 (49%)]\tLoss: 0.245831\n",
      "Train Epoch: 2 [5120/9043 (56%)]\tLoss: 0.410301\n",
      "Train Epoch: 2 [5760/9043 (63%)]\tLoss: 0.452424\n",
      "Train Epoch: 2 [6400/9043 (70%)]\tLoss: 0.287856\n",
      "Train Epoch: 2 [7040/9043 (77%)]\tLoss: 0.261552\n",
      "Train Epoch: 2 [7680/9043 (85%)]\tLoss: 0.453778\n",
      "Train Epoch: 2 [8320/9043 (92%)]\tLoss: 0.323887\n",
      "Train Epoch: 2 [8960/9043 (99%)]\tLoss: 0.530792\n",
      "Train Epoch: 3 [0/9043 (0%)]\tLoss: 0.430496\n",
      "Train Epoch: 3 [640/9043 (7%)]\tLoss: 0.194021\n",
      "Train Epoch: 3 [1280/9043 (14%)]\tLoss: 0.158547\n",
      "Train Epoch: 3 [1920/9043 (21%)]\tLoss: 0.312927\n",
      "Train Epoch: 3 [2560/9043 (28%)]\tLoss: 0.172091\n",
      "Train Epoch: 3 [3200/9043 (35%)]\tLoss: 0.225169\n",
      "Train Epoch: 3 [3840/9043 (42%)]\tLoss: 0.361175\n",
      "Train Epoch: 3 [4480/9043 (49%)]\tLoss: 0.192932\n",
      "Train Epoch: 3 [5120/9043 (56%)]\tLoss: 0.222372\n",
      "Train Epoch: 3 [5760/9043 (63%)]\tLoss: 0.307291\n",
      "Train Epoch: 3 [6400/9043 (70%)]\tLoss: 0.492412\n",
      "Train Epoch: 3 [7040/9043 (77%)]\tLoss: 0.230686\n",
      "Train Epoch: 3 [7680/9043 (85%)]\tLoss: 0.118038\n",
      "Train Epoch: 3 [8320/9043 (92%)]\tLoss: 0.167262\n",
      "Train Epoch: 3 [8960/9043 (99%)]\tLoss: 0.111295\n",
      "Train Epoch: 4 [0/9043 (0%)]\tLoss: 0.141190\n",
      "Train Epoch: 4 [640/9043 (7%)]\tLoss: 0.168399\n",
      "Train Epoch: 4 [1280/9043 (14%)]\tLoss: 0.057701\n",
      "Train Epoch: 4 [1920/9043 (21%)]\tLoss: 0.131107\n",
      "Train Epoch: 4 [2560/9043 (28%)]\tLoss: 0.165543\n",
      "Train Epoch: 4 [3200/9043 (35%)]\tLoss: 0.116104\n",
      "Train Epoch: 4 [3840/9043 (42%)]\tLoss: 0.209682\n",
      "Train Epoch: 4 [4480/9043 (49%)]\tLoss: 0.172691\n",
      "Train Epoch: 4 [5120/9043 (56%)]\tLoss: 0.183342\n",
      "Train Epoch: 4 [5760/9043 (63%)]\tLoss: 0.154584\n",
      "Train Epoch: 4 [6400/9043 (70%)]\tLoss: 0.195144\n",
      "Train Epoch: 4 [7040/9043 (77%)]\tLoss: 0.047114\n",
      "Train Epoch: 4 [7680/9043 (85%)]\tLoss: 0.219019\n",
      "Train Epoch: 4 [8320/9043 (92%)]\tLoss: 0.098749\n",
      "Train Epoch: 4 [8960/9043 (99%)]\tLoss: 0.352672\n",
      "Train Epoch: 5 [0/9043 (0%)]\tLoss: 0.084872\n",
      "Train Epoch: 5 [640/9043 (7%)]\tLoss: 0.156759\n",
      "Train Epoch: 5 [1280/9043 (14%)]\tLoss: 0.164881\n",
      "Train Epoch: 5 [1920/9043 (21%)]\tLoss: 0.143789\n",
      "Train Epoch: 5 [2560/9043 (28%)]\tLoss: 0.063070\n",
      "Train Epoch: 5 [3200/9043 (35%)]\tLoss: 0.086083\n",
      "Train Epoch: 5 [3840/9043 (42%)]\tLoss: 0.110359\n",
      "Train Epoch: 5 [4480/9043 (49%)]\tLoss: 0.220979\n",
      "Train Epoch: 5 [5120/9043 (56%)]\tLoss: 0.127066\n",
      "Train Epoch: 5 [5760/9043 (63%)]\tLoss: 0.281219\n",
      "Train Epoch: 5 [6400/9043 (70%)]\tLoss: 0.104870\n",
      "Train Epoch: 5 [7040/9043 (77%)]\tLoss: 0.204792\n",
      "Train Epoch: 5 [7680/9043 (85%)]\tLoss: 0.035598\n",
      "Train Epoch: 5 [8320/9043 (92%)]\tLoss: 0.235363\n",
      "Train Epoch: 5 [8960/9043 (99%)]\tLoss: 0.110523\n",
      "Train Epoch: 6 [0/9043 (0%)]\tLoss: 0.236361\n",
      "Train Epoch: 6 [640/9043 (7%)]\tLoss: 0.095541\n",
      "Train Epoch: 6 [1280/9043 (14%)]\tLoss: 0.043312\n",
      "Train Epoch: 6 [1920/9043 (21%)]\tLoss: 0.145401\n",
      "Train Epoch: 6 [2560/9043 (28%)]\tLoss: 0.096476\n",
      "Train Epoch: 6 [3200/9043 (35%)]\tLoss: 0.092314\n",
      "Train Epoch: 6 [3840/9043 (42%)]\tLoss: 0.163441\n",
      "Train Epoch: 6 [4480/9043 (49%)]\tLoss: 0.050152\n",
      "Train Epoch: 6 [5120/9043 (56%)]\tLoss: 0.208565\n",
      "Train Epoch: 6 [5760/9043 (63%)]\tLoss: 0.045993\n",
      "Train Epoch: 6 [6400/9043 (70%)]\tLoss: 0.127175\n",
      "Train Epoch: 6 [7040/9043 (77%)]\tLoss: 0.078712\n",
      "Train Epoch: 6 [7680/9043 (85%)]\tLoss: 0.220156\n",
      "Train Epoch: 6 [8320/9043 (92%)]\tLoss: 0.053755\n",
      "Train Epoch: 6 [8960/9043 (99%)]\tLoss: 0.086370\n",
      "Train Epoch: 7 [0/9043 (0%)]\tLoss: 0.140151\n",
      "Train Epoch: 7 [640/9043 (7%)]\tLoss: 0.132282\n",
      "Train Epoch: 7 [1280/9043 (14%)]\tLoss: 0.192769\n",
      "Train Epoch: 7 [1920/9043 (21%)]\tLoss: 0.122058\n",
      "Train Epoch: 7 [2560/9043 (28%)]\tLoss: 0.138057\n",
      "Train Epoch: 7 [3200/9043 (35%)]\tLoss: 0.090267\n",
      "Train Epoch: 7 [3840/9043 (42%)]\tLoss: 0.088848\n",
      "Train Epoch: 7 [4480/9043 (49%)]\tLoss: 0.016557\n",
      "Train Epoch: 7 [5120/9043 (56%)]\tLoss: 0.033921\n",
      "Train Epoch: 7 [5760/9043 (63%)]\tLoss: 0.054238\n",
      "Train Epoch: 7 [6400/9043 (70%)]\tLoss: 0.051539\n",
      "Train Epoch: 7 [7040/9043 (77%)]\tLoss: 0.058622\n",
      "Train Epoch: 7 [7680/9043 (85%)]\tLoss: 0.025631\n",
      "Train Epoch: 7 [8320/9043 (92%)]\tLoss: 0.125315\n",
      "Train Epoch: 7 [8960/9043 (99%)]\tLoss: 0.078254\n",
      "Train Epoch: 8 [0/9043 (0%)]\tLoss: 0.102745\n",
      "Train Epoch: 8 [640/9043 (7%)]\tLoss: 0.023854\n",
      "Train Epoch: 8 [1280/9043 (14%)]\tLoss: 0.037330\n",
      "Train Epoch: 8 [1920/9043 (21%)]\tLoss: 0.142509\n",
      "Train Epoch: 8 [2560/9043 (28%)]\tLoss: 0.144221\n",
      "Train Epoch: 8 [3200/9043 (35%)]\tLoss: 0.093212\n",
      "Train Epoch: 8 [3840/9043 (42%)]\tLoss: 0.063711\n",
      "Train Epoch: 8 [4480/9043 (49%)]\tLoss: 0.080858\n",
      "Train Epoch: 8 [5120/9043 (56%)]\tLoss: 0.022167\n",
      "Train Epoch: 8 [5760/9043 (63%)]\tLoss: 0.172268\n",
      "Train Epoch: 8 [6400/9043 (70%)]\tLoss: 0.008856\n",
      "Train Epoch: 8 [7040/9043 (77%)]\tLoss: 0.038255\n",
      "Train Epoch: 8 [7680/9043 (85%)]\tLoss: 0.207993\n",
      "Train Epoch: 8 [8320/9043 (92%)]\tLoss: 0.167551\n",
      "Train Epoch: 8 [8960/9043 (99%)]\tLoss: 0.089142\n",
      "Train Epoch: 9 [0/9043 (0%)]\tLoss: 0.042619\n",
      "Train Epoch: 9 [640/9043 (7%)]\tLoss: 0.011278\n",
      "Train Epoch: 9 [1280/9043 (14%)]\tLoss: 0.051121\n",
      "Train Epoch: 9 [1920/9043 (21%)]\tLoss: 0.087544\n",
      "Train Epoch: 9 [2560/9043 (28%)]\tLoss: 0.173086\n",
      "Train Epoch: 9 [3200/9043 (35%)]\tLoss: 0.088640\n",
      "Train Epoch: 9 [3840/9043 (42%)]\tLoss: 0.054640\n",
      "Train Epoch: 9 [4480/9043 (49%)]\tLoss: 0.048001\n",
      "Train Epoch: 9 [5120/9043 (56%)]\tLoss: 0.059830\n",
      "Train Epoch: 9 [5760/9043 (63%)]\tLoss: 0.041202\n",
      "Train Epoch: 9 [6400/9043 (70%)]\tLoss: 0.071391\n",
      "Train Epoch: 9 [7040/9043 (77%)]\tLoss: 0.102227\n",
      "Train Epoch: 9 [7680/9043 (85%)]\tLoss: 0.052122\n",
      "Train Epoch: 9 [8320/9043 (92%)]\tLoss: 0.173748\n",
      "Train Epoch: 9 [8960/9043 (99%)]\tLoss: 0.035061\n",
      "Train Epoch: 10 [0/9043 (0%)]\tLoss: 0.017551\n",
      "Train Epoch: 10 [640/9043 (7%)]\tLoss: 0.074050\n",
      "Train Epoch: 10 [1280/9043 (14%)]\tLoss: 0.033099\n",
      "Train Epoch: 10 [1920/9043 (21%)]\tLoss: 0.130444\n",
      "Train Epoch: 10 [2560/9043 (28%)]\tLoss: 0.007046\n",
      "Train Epoch: 10 [3200/9043 (35%)]\tLoss: 0.017503\n",
      "Train Epoch: 10 [3840/9043 (42%)]\tLoss: 0.039888\n",
      "Train Epoch: 10 [4480/9043 (49%)]\tLoss: 0.286010\n",
      "Train Epoch: 10 [5120/9043 (56%)]\tLoss: 0.014959\n",
      "Train Epoch: 10 [5760/9043 (63%)]\tLoss: 0.028877\n",
      "Train Epoch: 10 [6400/9043 (70%)]\tLoss: 0.061339\n",
      "Train Epoch: 10 [7040/9043 (77%)]\tLoss: 0.024827\n",
      "Train Epoch: 10 [7680/9043 (85%)]\tLoss: 0.023861\n",
      "Train Epoch: 10 [8320/9043 (92%)]\tLoss: 0.066620\n",
      "Train Epoch: 10 [8960/9043 (99%)]\tLoss: 0.089173\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/14723 (0%)]\tLoss: 0.955123\n",
      "Train Epoch: 1 [640/14723 (4%)]\tLoss: 0.693180\n",
      "Train Epoch: 1 [1280/14723 (9%)]\tLoss: 0.770863\n",
      "Train Epoch: 1 [1920/14723 (13%)]\tLoss: 0.667999\n",
      "Train Epoch: 1 [2560/14723 (17%)]\tLoss: 0.703054\n",
      "Train Epoch: 1 [3200/14723 (22%)]\tLoss: 0.807285\n",
      "Train Epoch: 1 [3840/14723 (26%)]\tLoss: 0.698375\n",
      "Train Epoch: 1 [4480/14723 (30%)]\tLoss: 0.681678\n",
      "Train Epoch: 1 [5120/14723 (35%)]\tLoss: 0.541243\n",
      "Train Epoch: 1 [5760/14723 (39%)]\tLoss: 1.103352\n",
      "Train Epoch: 1 [6400/14723 (43%)]\tLoss: 0.730304\n",
      "Train Epoch: 1 [7040/14723 (48%)]\tLoss: 0.776858\n",
      "Train Epoch: 1 [7680/14723 (52%)]\tLoss: 0.771110\n",
      "Train Epoch: 1 [8320/14723 (56%)]\tLoss: 0.781598\n",
      "Train Epoch: 1 [8960/14723 (61%)]\tLoss: 1.009187\n",
      "Train Epoch: 1 [9600/14723 (65%)]\tLoss: 0.693409\n",
      "Train Epoch: 1 [10240/14723 (69%)]\tLoss: 0.964081\n",
      "Train Epoch: 1 [10880/14723 (74%)]\tLoss: 0.746508\n",
      "Train Epoch: 1 [11520/14723 (78%)]\tLoss: 0.737873\n",
      "Train Epoch: 1 [12160/14723 (82%)]\tLoss: 0.503439\n",
      "Train Epoch: 1 [12800/14723 (87%)]\tLoss: 0.637543\n",
      "Train Epoch: 1 [13440/14723 (91%)]\tLoss: 0.584685\n",
      "Train Epoch: 1 [14080/14723 (95%)]\tLoss: 1.026327\n",
      "Train Epoch: 1 [690/14723 (100%)]\tLoss: 1.079635\n",
      "Train Epoch: 2 [0/14723 (0%)]\tLoss: 0.842321\n",
      "Train Epoch: 2 [640/14723 (4%)]\tLoss: 0.947925\n",
      "Train Epoch: 2 [1280/14723 (9%)]\tLoss: 0.912559\n",
      "Train Epoch: 2 [1920/14723 (13%)]\tLoss: 0.896345\n",
      "Train Epoch: 2 [2560/14723 (17%)]\tLoss: 0.863601\n",
      "Train Epoch: 2 [3200/14723 (22%)]\tLoss: 0.543188\n",
      "Train Epoch: 2 [3840/14723 (26%)]\tLoss: 0.819728\n",
      "Train Epoch: 2 [4480/14723 (30%)]\tLoss: 0.644570\n",
      "Train Epoch: 2 [5120/14723 (35%)]\tLoss: 0.695217\n",
      "Train Epoch: 2 [5760/14723 (39%)]\tLoss: 0.948007\n",
      "Train Epoch: 2 [6400/14723 (43%)]\tLoss: 0.748468\n",
      "Train Epoch: 2 [7040/14723 (48%)]\tLoss: 0.585633\n",
      "Train Epoch: 2 [7680/14723 (52%)]\tLoss: 0.752295\n",
      "Train Epoch: 2 [8320/14723 (56%)]\tLoss: 0.749551\n",
      "Train Epoch: 2 [8960/14723 (61%)]\tLoss: 0.672796\n",
      "Train Epoch: 2 [9600/14723 (65%)]\tLoss: 0.630461\n",
      "Train Epoch: 2 [10240/14723 (69%)]\tLoss: 0.747920\n",
      "Train Epoch: 2 [10880/14723 (74%)]\tLoss: 0.760315\n",
      "Train Epoch: 2 [11520/14723 (78%)]\tLoss: 0.643457\n",
      "Train Epoch: 2 [12160/14723 (82%)]\tLoss: 0.651374\n",
      "Train Epoch: 2 [12800/14723 (87%)]\tLoss: 0.447578\n",
      "Train Epoch: 2 [13440/14723 (91%)]\tLoss: 0.851767\n",
      "Train Epoch: 2 [14080/14723 (95%)]\tLoss: 0.628726\n",
      "Train Epoch: 2 [690/14723 (100%)]\tLoss: 2.177665\n",
      "Train Epoch: 3 [0/14723 (0%)]\tLoss: 1.414760\n",
      "Train Epoch: 3 [640/14723 (4%)]\tLoss: 0.872081\n",
      "Train Epoch: 3 [1280/14723 (9%)]\tLoss: 0.710522\n",
      "Train Epoch: 3 [1920/14723 (13%)]\tLoss: 0.647008\n",
      "Train Epoch: 3 [2560/14723 (17%)]\tLoss: 0.698563\n",
      "Train Epoch: 3 [3200/14723 (22%)]\tLoss: 0.851630\n",
      "Train Epoch: 3 [3840/14723 (26%)]\tLoss: 0.719019\n",
      "Train Epoch: 3 [4480/14723 (30%)]\tLoss: 0.844852\n",
      "Train Epoch: 3 [5120/14723 (35%)]\tLoss: 0.830325\n",
      "Train Epoch: 3 [5760/14723 (39%)]\tLoss: 0.603980\n",
      "Train Epoch: 3 [6400/14723 (43%)]\tLoss: 0.843587\n",
      "Train Epoch: 3 [7040/14723 (48%)]\tLoss: 0.541798\n",
      "Train Epoch: 3 [7680/14723 (52%)]\tLoss: 0.753888\n",
      "Train Epoch: 3 [8320/14723 (56%)]\tLoss: 0.999668\n",
      "Train Epoch: 3 [8960/14723 (61%)]\tLoss: 0.558123\n",
      "Train Epoch: 3 [9600/14723 (65%)]\tLoss: 0.268593\n",
      "Train Epoch: 3 [10240/14723 (69%)]\tLoss: 0.499240\n",
      "Train Epoch: 3 [10880/14723 (74%)]\tLoss: 0.510874\n",
      "Train Epoch: 3 [11520/14723 (78%)]\tLoss: 0.787382\n",
      "Train Epoch: 3 [12160/14723 (82%)]\tLoss: 0.473977\n",
      "Train Epoch: 3 [12800/14723 (87%)]\tLoss: 0.592085\n",
      "Train Epoch: 3 [13440/14723 (91%)]\tLoss: 0.636500\n",
      "Train Epoch: 3 [14080/14723 (95%)]\tLoss: 0.547658\n",
      "Train Epoch: 3 [690/14723 (100%)]\tLoss: 1.068877\n",
      "Train Epoch: 4 [0/14723 (0%)]\tLoss: 1.710781\n",
      "Train Epoch: 4 [640/14723 (4%)]\tLoss: 1.408797\n",
      "Train Epoch: 4 [1280/14723 (9%)]\tLoss: 0.967934\n",
      "Train Epoch: 4 [1920/14723 (13%)]\tLoss: 0.965811\n",
      "Train Epoch: 4 [2560/14723 (17%)]\tLoss: 0.963051\n",
      "Train Epoch: 4 [3200/14723 (22%)]\tLoss: 1.011657\n",
      "Train Epoch: 4 [3840/14723 (26%)]\tLoss: 1.250622\n",
      "Train Epoch: 4 [4480/14723 (30%)]\tLoss: 0.677013\n",
      "Train Epoch: 4 [5120/14723 (35%)]\tLoss: 1.202192\n",
      "Train Epoch: 4 [5760/14723 (39%)]\tLoss: 0.836804\n",
      "Train Epoch: 4 [6400/14723 (43%)]\tLoss: 0.883599\n",
      "Train Epoch: 4 [7040/14723 (48%)]\tLoss: 0.795126\n",
      "Train Epoch: 4 [7680/14723 (52%)]\tLoss: 0.863776\n",
      "Train Epoch: 4 [8320/14723 (56%)]\tLoss: 0.811654\n",
      "Train Epoch: 4 [8960/14723 (61%)]\tLoss: 0.777950\n",
      "Train Epoch: 4 [9600/14723 (65%)]\tLoss: 0.898934\n",
      "Train Epoch: 4 [10240/14723 (69%)]\tLoss: 0.528345\n",
      "Train Epoch: 4 [10880/14723 (74%)]\tLoss: 0.900664\n",
      "Train Epoch: 4 [11520/14723 (78%)]\tLoss: 0.636111\n",
      "Train Epoch: 4 [12160/14723 (82%)]\tLoss: 0.711413\n",
      "Train Epoch: 4 [12800/14723 (87%)]\tLoss: 0.524584\n",
      "Train Epoch: 4 [13440/14723 (91%)]\tLoss: 0.788980\n",
      "Train Epoch: 4 [14080/14723 (95%)]\tLoss: 0.701031\n",
      "Train Epoch: 4 [690/14723 (100%)]\tLoss: 2.089481\n",
      "Train Epoch: 5 [0/14723 (0%)]\tLoss: 0.903656\n",
      "Train Epoch: 5 [640/14723 (4%)]\tLoss: 0.676880\n",
      "Train Epoch: 5 [1280/14723 (9%)]\tLoss: 0.496269\n",
      "Train Epoch: 5 [1920/14723 (13%)]\tLoss: 0.588354\n",
      "Train Epoch: 5 [2560/14723 (17%)]\tLoss: 0.508861\n",
      "Train Epoch: 5 [3200/14723 (22%)]\tLoss: 0.574304\n",
      "Train Epoch: 5 [3840/14723 (26%)]\tLoss: 0.613912\n",
      "Train Epoch: 5 [4480/14723 (30%)]\tLoss: 0.387408\n",
      "Train Epoch: 5 [5120/14723 (35%)]\tLoss: 0.567962\n",
      "Train Epoch: 5 [5760/14723 (39%)]\tLoss: 0.444763\n",
      "Train Epoch: 5 [6400/14723 (43%)]\tLoss: 0.763302\n",
      "Train Epoch: 5 [7040/14723 (48%)]\tLoss: 0.425069\n",
      "Train Epoch: 5 [7680/14723 (52%)]\tLoss: 0.627647\n",
      "Train Epoch: 5 [8320/14723 (56%)]\tLoss: 0.406613\n",
      "Train Epoch: 5 [8960/14723 (61%)]\tLoss: 0.475741\n",
      "Train Epoch: 5 [9600/14723 (65%)]\tLoss: 0.493962\n",
      "Train Epoch: 5 [10240/14723 (69%)]\tLoss: 0.515782\n",
      "Train Epoch: 5 [10880/14723 (74%)]\tLoss: 0.531762\n",
      "Train Epoch: 5 [11520/14723 (78%)]\tLoss: 0.708372\n",
      "Train Epoch: 5 [12160/14723 (82%)]\tLoss: 0.462707\n",
      "Train Epoch: 5 [12800/14723 (87%)]\tLoss: 0.511911\n",
      "Train Epoch: 5 [13440/14723 (91%)]\tLoss: 0.482931\n",
      "Train Epoch: 5 [14080/14723 (95%)]\tLoss: 0.337221\n",
      "Train Epoch: 5 [690/14723 (100%)]\tLoss: 2.534280\n",
      "Train Epoch: 6 [0/14723 (0%)]\tLoss: 1.094784\n",
      "Train Epoch: 6 [640/14723 (4%)]\tLoss: 1.421741\n",
      "Train Epoch: 6 [1280/14723 (9%)]\tLoss: 0.906748\n",
      "Train Epoch: 6 [1920/14723 (13%)]\tLoss: 0.747619\n",
      "Train Epoch: 6 [2560/14723 (17%)]\tLoss: 0.657337\n",
      "Train Epoch: 6 [3200/14723 (22%)]\tLoss: 0.543409\n",
      "Train Epoch: 6 [3840/14723 (26%)]\tLoss: 0.646406\n",
      "Train Epoch: 6 [4480/14723 (30%)]\tLoss: 0.734437\n",
      "Train Epoch: 6 [5120/14723 (35%)]\tLoss: 0.837932\n",
      "Train Epoch: 6 [5760/14723 (39%)]\tLoss: 0.772446\n",
      "Train Epoch: 6 [6400/14723 (43%)]\tLoss: 0.907501\n",
      "Train Epoch: 6 [7040/14723 (48%)]\tLoss: 0.760599\n",
      "Train Epoch: 6 [7680/14723 (52%)]\tLoss: 0.681245\n",
      "Train Epoch: 6 [8320/14723 (56%)]\tLoss: 0.474870\n",
      "Train Epoch: 6 [8960/14723 (61%)]\tLoss: 0.576465\n",
      "Train Epoch: 6 [9600/14723 (65%)]\tLoss: 0.700112\n",
      "Train Epoch: 6 [10240/14723 (69%)]\tLoss: 0.687479\n",
      "Train Epoch: 6 [10880/14723 (74%)]\tLoss: 0.587768\n",
      "Train Epoch: 6 [11520/14723 (78%)]\tLoss: 0.775746\n",
      "Train Epoch: 6 [12160/14723 (82%)]\tLoss: 0.893206\n",
      "Train Epoch: 6 [12800/14723 (87%)]\tLoss: 0.564328\n",
      "Train Epoch: 6 [13440/14723 (91%)]\tLoss: 0.623831\n",
      "Train Epoch: 6 [14080/14723 (95%)]\tLoss: 0.516531\n",
      "Train Epoch: 6 [690/14723 (100%)]\tLoss: 0.936277\n",
      "Train Epoch: 7 [0/14723 (0%)]\tLoss: 0.894268\n",
      "Train Epoch: 7 [640/14723 (4%)]\tLoss: 0.579188\n",
      "Train Epoch: 7 [1280/14723 (9%)]\tLoss: 0.487939\n",
      "Train Epoch: 7 [1920/14723 (13%)]\tLoss: 0.394222\n",
      "Train Epoch: 7 [2560/14723 (17%)]\tLoss: 0.577556\n",
      "Train Epoch: 7 [3200/14723 (22%)]\tLoss: 0.604451\n",
      "Train Epoch: 7 [3840/14723 (26%)]\tLoss: 0.574011\n",
      "Train Epoch: 7 [4480/14723 (30%)]\tLoss: 0.423662\n",
      "Train Epoch: 7 [5120/14723 (35%)]\tLoss: 0.490337\n",
      "Train Epoch: 7 [5760/14723 (39%)]\tLoss: 0.658144\n",
      "Train Epoch: 7 [6400/14723 (43%)]\tLoss: 0.509302\n",
      "Train Epoch: 7 [7040/14723 (48%)]\tLoss: 0.371566\n",
      "Train Epoch: 7 [7680/14723 (52%)]\tLoss: 0.485427\n",
      "Train Epoch: 7 [8320/14723 (56%)]\tLoss: 0.533664\n",
      "Train Epoch: 7 [8960/14723 (61%)]\tLoss: 0.364983\n",
      "Train Epoch: 7 [9600/14723 (65%)]\tLoss: 0.535144\n",
      "Train Epoch: 7 [10240/14723 (69%)]\tLoss: 0.351754\n",
      "Train Epoch: 7 [10880/14723 (74%)]\tLoss: 0.356792\n",
      "Train Epoch: 7 [11520/14723 (78%)]\tLoss: 0.487134\n",
      "Train Epoch: 7 [12160/14723 (82%)]\tLoss: 0.360006\n",
      "Train Epoch: 7 [12800/14723 (87%)]\tLoss: 0.393471\n",
      "Train Epoch: 7 [13440/14723 (91%)]\tLoss: 0.368562\n",
      "Train Epoch: 7 [14080/14723 (95%)]\tLoss: 0.662481\n",
      "Train Epoch: 7 [690/14723 (100%)]\tLoss: 4.437484\n",
      "Train Epoch: 8 [0/14723 (0%)]\tLoss: 1.211625\n",
      "Train Epoch: 8 [640/14723 (4%)]\tLoss: 0.790712\n",
      "Train Epoch: 8 [1280/14723 (9%)]\tLoss: 0.492682\n",
      "Train Epoch: 8 [1920/14723 (13%)]\tLoss: 0.636471\n",
      "Train Epoch: 8 [2560/14723 (17%)]\tLoss: 0.668495\n",
      "Train Epoch: 8 [3200/14723 (22%)]\tLoss: 0.510652\n",
      "Train Epoch: 8 [3840/14723 (26%)]\tLoss: 0.566748\n",
      "Train Epoch: 8 [4480/14723 (30%)]\tLoss: 0.385151\n",
      "Train Epoch: 8 [5120/14723 (35%)]\tLoss: 0.571025\n",
      "Train Epoch: 8 [5760/14723 (39%)]\tLoss: 0.348321\n",
      "Train Epoch: 8 [6400/14723 (43%)]\tLoss: 0.554580\n",
      "Train Epoch: 8 [7040/14723 (48%)]\tLoss: 0.443497\n",
      "Train Epoch: 8 [7680/14723 (52%)]\tLoss: 0.689101\n",
      "Train Epoch: 8 [8320/14723 (56%)]\tLoss: 0.392794\n",
      "Train Epoch: 8 [8960/14723 (61%)]\tLoss: 0.444482\n",
      "Train Epoch: 8 [9600/14723 (65%)]\tLoss: 0.483140\n",
      "Train Epoch: 8 [10240/14723 (69%)]\tLoss: 0.441150\n",
      "Train Epoch: 8 [10880/14723 (74%)]\tLoss: 0.584082\n",
      "Train Epoch: 8 [11520/14723 (78%)]\tLoss: 0.676100\n",
      "Train Epoch: 8 [12160/14723 (82%)]\tLoss: 0.455575\n",
      "Train Epoch: 8 [12800/14723 (87%)]\tLoss: 0.393343\n",
      "Train Epoch: 8 [13440/14723 (91%)]\tLoss: 0.443951\n",
      "Train Epoch: 8 [14080/14723 (95%)]\tLoss: 0.288221\n",
      "Train Epoch: 8 [690/14723 (100%)]\tLoss: 0.427367\n",
      "Train Epoch: 9 [0/14723 (0%)]\tLoss: 0.363683\n",
      "Train Epoch: 9 [640/14723 (4%)]\tLoss: 0.284124\n",
      "Train Epoch: 9 [1280/14723 (9%)]\tLoss: 0.280380\n",
      "Train Epoch: 9 [1920/14723 (13%)]\tLoss: 0.289636\n",
      "Train Epoch: 9 [2560/14723 (17%)]\tLoss: 0.330744\n",
      "Train Epoch: 9 [3200/14723 (22%)]\tLoss: 0.288965\n",
      "Train Epoch: 9 [3840/14723 (26%)]\tLoss: 0.522597\n",
      "Train Epoch: 9 [4480/14723 (30%)]\tLoss: 0.236078\n",
      "Train Epoch: 9 [5120/14723 (35%)]\tLoss: 0.345898\n",
      "Train Epoch: 9 [5760/14723 (39%)]\tLoss: 0.315058\n",
      "Train Epoch: 9 [6400/14723 (43%)]\tLoss: 0.505244\n",
      "Train Epoch: 9 [7040/14723 (48%)]\tLoss: 0.289611\n",
      "Train Epoch: 9 [7680/14723 (52%)]\tLoss: 0.388598\n",
      "Train Epoch: 9 [8320/14723 (56%)]\tLoss: 0.244477\n",
      "Train Epoch: 9 [8960/14723 (61%)]\tLoss: 0.255785\n",
      "Train Epoch: 9 [9600/14723 (65%)]\tLoss: 0.228802\n",
      "Train Epoch: 9 [10240/14723 (69%)]\tLoss: 0.156691\n",
      "Train Epoch: 9 [10880/14723 (74%)]\tLoss: 0.324906\n",
      "Train Epoch: 9 [11520/14723 (78%)]\tLoss: 0.514388\n",
      "Train Epoch: 9 [12160/14723 (82%)]\tLoss: 0.439829\n",
      "Train Epoch: 9 [12800/14723 (87%)]\tLoss: 0.346283\n",
      "Train Epoch: 9 [13440/14723 (91%)]\tLoss: 0.341044\n",
      "Train Epoch: 9 [14080/14723 (95%)]\tLoss: 0.401581\n",
      "Train Epoch: 9 [690/14723 (100%)]\tLoss: 0.221674\n",
      "Train Epoch: 10 [0/14723 (0%)]\tLoss: 0.150720\n",
      "Train Epoch: 10 [640/14723 (4%)]\tLoss: 0.333375\n",
      "Train Epoch: 10 [1280/14723 (9%)]\tLoss: 0.173060\n",
      "Train Epoch: 10 [1920/14723 (13%)]\tLoss: 0.201006\n",
      "Train Epoch: 10 [2560/14723 (17%)]\tLoss: 0.153328\n",
      "Train Epoch: 10 [3200/14723 (22%)]\tLoss: 0.101513\n",
      "Train Epoch: 10 [3840/14723 (26%)]\tLoss: 0.183368\n",
      "Train Epoch: 10 [4480/14723 (30%)]\tLoss: 0.122491\n",
      "Train Epoch: 10 [5120/14723 (35%)]\tLoss: 0.158221\n",
      "Train Epoch: 10 [5760/14723 (39%)]\tLoss: 0.163484\n",
      "Train Epoch: 10 [6400/14723 (43%)]\tLoss: 0.260476\n",
      "Train Epoch: 10 [7040/14723 (48%)]\tLoss: 0.324901\n",
      "Train Epoch: 10 [7680/14723 (52%)]\tLoss: 0.096280\n",
      "Train Epoch: 10 [8320/14723 (56%)]\tLoss: 0.161162\n",
      "Train Epoch: 10 [8960/14723 (61%)]\tLoss: 0.183444\n",
      "Train Epoch: 10 [9600/14723 (65%)]\tLoss: 0.265939\n",
      "Train Epoch: 10 [10240/14723 (69%)]\tLoss: 0.127370\n",
      "Train Epoch: 10 [10880/14723 (74%)]\tLoss: 0.186630\n",
      "Train Epoch: 10 [11520/14723 (78%)]\tLoss: 0.268675\n",
      "Train Epoch: 10 [12160/14723 (82%)]\tLoss: 0.149469\n",
      "Train Epoch: 10 [12800/14723 (87%)]\tLoss: 0.369440\n",
      "Train Epoch: 10 [13440/14723 (91%)]\tLoss: 0.258992\n",
      "Train Epoch: 10 [14080/14723 (95%)]\tLoss: 0.162923\n",
      "Train Epoch: 10 [690/14723 (100%)]\tLoss: 3.916664\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/7654 (0%)]\tLoss: 1.971996\n",
      "Train Epoch: 1 [640/7654 (8%)]\tLoss: 0.418368\n",
      "Train Epoch: 1 [1280/7654 (17%)]\tLoss: 0.149276\n",
      "Train Epoch: 1 [1920/7654 (25%)]\tLoss: 0.381261\n",
      "Train Epoch: 1 [2560/7654 (33%)]\tLoss: 0.339155\n",
      "Train Epoch: 1 [3200/7654 (42%)]\tLoss: 0.349017\n",
      "Train Epoch: 1 [3840/7654 (50%)]\tLoss: 0.291171\n",
      "Train Epoch: 1 [4480/7654 (58%)]\tLoss: 0.237189\n",
      "Train Epoch: 1 [5120/7654 (67%)]\tLoss: 0.492552\n",
      "Train Epoch: 1 [5760/7654 (75%)]\tLoss: 0.308067\n",
      "Train Epoch: 1 [6400/7654 (83%)]\tLoss: 0.476767\n",
      "Train Epoch: 1 [7040/7654 (92%)]\tLoss: 0.475383\n",
      "Train Epoch: 2 [0/7654 (0%)]\tLoss: 0.190763\n",
      "Train Epoch: 2 [640/7654 (8%)]\tLoss: 0.164751\n",
      "Train Epoch: 2 [1280/7654 (17%)]\tLoss: 0.248780\n",
      "Train Epoch: 2 [1920/7654 (25%)]\tLoss: 0.183006\n",
      "Train Epoch: 2 [2560/7654 (33%)]\tLoss: 0.217325\n",
      "Train Epoch: 2 [3200/7654 (42%)]\tLoss: 0.222893\n",
      "Train Epoch: 2 [3840/7654 (50%)]\tLoss: 0.166053\n",
      "Train Epoch: 2 [4480/7654 (58%)]\tLoss: 0.216279\n",
      "Train Epoch: 2 [5120/7654 (67%)]\tLoss: 0.177210\n",
      "Train Epoch: 2 [5760/7654 (75%)]\tLoss: 0.202441\n",
      "Train Epoch: 2 [6400/7654 (83%)]\tLoss: 0.179692\n",
      "Train Epoch: 2 [7040/7654 (92%)]\tLoss: 0.289375\n",
      "Train Epoch: 3 [0/7654 (0%)]\tLoss: 0.077299\n",
      "Train Epoch: 3 [640/7654 (8%)]\tLoss: 0.072167\n",
      "Train Epoch: 3 [1280/7654 (17%)]\tLoss: 0.135061\n",
      "Train Epoch: 3 [1920/7654 (25%)]\tLoss: 0.168312\n",
      "Train Epoch: 3 [2560/7654 (33%)]\tLoss: 0.029629\n",
      "Train Epoch: 3 [3200/7654 (42%)]\tLoss: 0.133632\n",
      "Train Epoch: 3 [3840/7654 (50%)]\tLoss: 0.068646\n",
      "Train Epoch: 3 [4480/7654 (58%)]\tLoss: 0.037440\n",
      "Train Epoch: 3 [5120/7654 (67%)]\tLoss: 0.160142\n",
      "Train Epoch: 3 [5760/7654 (75%)]\tLoss: 0.067716\n",
      "Train Epoch: 3 [6400/7654 (83%)]\tLoss: 0.065968\n",
      "Train Epoch: 3 [7040/7654 (92%)]\tLoss: 0.126706\n",
      "Train Epoch: 4 [0/7654 (0%)]\tLoss: 0.056041\n",
      "Train Epoch: 4 [640/7654 (8%)]\tLoss: 0.194486\n",
      "Train Epoch: 4 [1280/7654 (17%)]\tLoss: 0.061727\n",
      "Train Epoch: 4 [1920/7654 (25%)]\tLoss: 0.164743\n",
      "Train Epoch: 4 [2560/7654 (33%)]\tLoss: 0.025930\n",
      "Train Epoch: 4 [3200/7654 (42%)]\tLoss: 0.040344\n",
      "Train Epoch: 4 [3840/7654 (50%)]\tLoss: 0.103805\n",
      "Train Epoch: 4 [4480/7654 (58%)]\tLoss: 0.052719\n",
      "Train Epoch: 4 [5120/7654 (67%)]\tLoss: 0.116625\n",
      "Train Epoch: 4 [5760/7654 (75%)]\tLoss: 0.077078\n",
      "Train Epoch: 4 [6400/7654 (83%)]\tLoss: 0.071083\n",
      "Train Epoch: 4 [7040/7654 (92%)]\tLoss: 0.093066\n",
      "Train Epoch: 5 [0/7654 (0%)]\tLoss: 0.020810\n",
      "Train Epoch: 5 [640/7654 (8%)]\tLoss: 0.008388\n",
      "Train Epoch: 5 [1280/7654 (17%)]\tLoss: 0.025902\n",
      "Train Epoch: 5 [1920/7654 (25%)]\tLoss: 0.078041\n",
      "Train Epoch: 5 [2560/7654 (33%)]\tLoss: 0.066744\n",
      "Train Epoch: 5 [3200/7654 (42%)]\tLoss: 0.081635\n",
      "Train Epoch: 5 [3840/7654 (50%)]\tLoss: 0.088641\n",
      "Train Epoch: 5 [4480/7654 (58%)]\tLoss: 0.053482\n",
      "Train Epoch: 5 [5120/7654 (67%)]\tLoss: 0.035050\n",
      "Train Epoch: 5 [5760/7654 (75%)]\tLoss: 0.022325\n",
      "Train Epoch: 5 [6400/7654 (83%)]\tLoss: 0.040896\n",
      "Train Epoch: 5 [7040/7654 (92%)]\tLoss: 0.065947\n",
      "Train Epoch: 6 [0/7654 (0%)]\tLoss: 0.034006\n",
      "Train Epoch: 6 [640/7654 (8%)]\tLoss: 0.006675\n",
      "Train Epoch: 6 [1280/7654 (17%)]\tLoss: 0.008866\n",
      "Train Epoch: 6 [1920/7654 (25%)]\tLoss: 0.023886\n",
      "Train Epoch: 6 [2560/7654 (33%)]\tLoss: 0.050715\n",
      "Train Epoch: 6 [3200/7654 (42%)]\tLoss: 0.137148\n",
      "Train Epoch: 6 [3840/7654 (50%)]\tLoss: 0.019723\n",
      "Train Epoch: 6 [4480/7654 (58%)]\tLoss: 0.031480\n",
      "Train Epoch: 6 [5120/7654 (67%)]\tLoss: 0.019810\n",
      "Train Epoch: 6 [5760/7654 (75%)]\tLoss: 0.061486\n",
      "Train Epoch: 6 [6400/7654 (83%)]\tLoss: 0.026903\n",
      "Train Epoch: 6 [7040/7654 (92%)]\tLoss: 0.021807\n",
      "Train Epoch: 7 [0/7654 (0%)]\tLoss: 0.025129\n",
      "Train Epoch: 7 [640/7654 (8%)]\tLoss: 0.005650\n",
      "Train Epoch: 7 [1280/7654 (17%)]\tLoss: 0.004892\n",
      "Train Epoch: 7 [1920/7654 (25%)]\tLoss: 0.024651\n",
      "Train Epoch: 7 [2560/7654 (33%)]\tLoss: 0.024514\n",
      "Train Epoch: 7 [3200/7654 (42%)]\tLoss: 0.020767\n",
      "Train Epoch: 7 [3840/7654 (50%)]\tLoss: 0.022289\n",
      "Train Epoch: 7 [4480/7654 (58%)]\tLoss: 0.010261\n",
      "Train Epoch: 7 [5120/7654 (67%)]\tLoss: 0.006522\n",
      "Train Epoch: 7 [5760/7654 (75%)]\tLoss: 0.016627\n",
      "Train Epoch: 7 [6400/7654 (83%)]\tLoss: 0.012558\n",
      "Train Epoch: 7 [7040/7654 (92%)]\tLoss: 0.058351\n",
      "Train Epoch: 8 [0/7654 (0%)]\tLoss: 0.014736\n",
      "Train Epoch: 8 [640/7654 (8%)]\tLoss: 0.030837\n",
      "Train Epoch: 8 [1280/7654 (17%)]\tLoss: 0.139916\n",
      "Train Epoch: 8 [1920/7654 (25%)]\tLoss: 0.069582\n",
      "Train Epoch: 8 [2560/7654 (33%)]\tLoss: 0.054623\n",
      "Train Epoch: 8 [3200/7654 (42%)]\tLoss: 0.005014\n",
      "Train Epoch: 8 [3840/7654 (50%)]\tLoss: 0.014523\n",
      "Train Epoch: 8 [4480/7654 (58%)]\tLoss: 0.106884\n",
      "Train Epoch: 8 [5120/7654 (67%)]\tLoss: 0.021084\n",
      "Train Epoch: 8 [5760/7654 (75%)]\tLoss: 0.033782\n",
      "Train Epoch: 8 [6400/7654 (83%)]\tLoss: 0.044733\n",
      "Train Epoch: 8 [7040/7654 (92%)]\tLoss: 0.067708\n",
      "Train Epoch: 9 [0/7654 (0%)]\tLoss: 0.027201\n",
      "Train Epoch: 9 [640/7654 (8%)]\tLoss: 0.079976\n",
      "Train Epoch: 9 [1280/7654 (17%)]\tLoss: 0.014554\n",
      "Train Epoch: 9 [1920/7654 (25%)]\tLoss: 0.016212\n",
      "Train Epoch: 9 [2560/7654 (33%)]\tLoss: 0.055402\n",
      "Train Epoch: 9 [3200/7654 (42%)]\tLoss: 0.052017\n",
      "Train Epoch: 9 [3840/7654 (50%)]\tLoss: 0.062959\n",
      "Train Epoch: 9 [4480/7654 (58%)]\tLoss: 0.074549\n",
      "Train Epoch: 9 [5120/7654 (67%)]\tLoss: 0.010282\n",
      "Train Epoch: 9 [5760/7654 (75%)]\tLoss: 0.075054\n",
      "Train Epoch: 9 [6400/7654 (83%)]\tLoss: 0.039300\n",
      "Train Epoch: 9 [7040/7654 (92%)]\tLoss: 0.008297\n",
      "Train Epoch: 10 [0/7654 (0%)]\tLoss: 0.105874\n",
      "Train Epoch: 10 [640/7654 (8%)]\tLoss: 0.060585\n",
      "Train Epoch: 10 [1280/7654 (17%)]\tLoss: 0.159205\n",
      "Train Epoch: 10 [1920/7654 (25%)]\tLoss: 0.019839\n",
      "Train Epoch: 10 [2560/7654 (33%)]\tLoss: 0.018406\n",
      "Train Epoch: 10 [3200/7654 (42%)]\tLoss: 0.007478\n",
      "Train Epoch: 10 [3840/7654 (50%)]\tLoss: 0.031084\n",
      "Train Epoch: 10 [4480/7654 (58%)]\tLoss: 0.056203\n",
      "Train Epoch: 10 [5120/7654 (67%)]\tLoss: 0.011881\n",
      "Train Epoch: 10 [5760/7654 (75%)]\tLoss: 0.135397\n",
      "Train Epoch: 10 [6400/7654 (83%)]\tLoss: 0.184867\n",
      "Train Epoch: 10 [7040/7654 (92%)]\tLoss: 0.008571\n",
      "after training[ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")]\n",
      "after fedaveraging[ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")]\n",
      "local_models in the distribute function [ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")]\n",
      "4\n",
      "local_models in the distribute function [ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.9505, Accuracy: 4180/10000 (42%)\n",
      "\n",
      "Round 2/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/18580 (0%)]\tLoss: 1.248492\n",
      "Train Epoch: 1 [640/18580 (3%)]\tLoss: 0.486408\n",
      "Train Epoch: 1 [1280/18580 (7%)]\tLoss: 0.482033\n",
      "Train Epoch: 1 [1920/18580 (10%)]\tLoss: 0.704556\n",
      "Train Epoch: 1 [2560/18580 (14%)]\tLoss: 0.349430\n",
      "Train Epoch: 1 [3200/18580 (17%)]\tLoss: 0.578132\n",
      "Train Epoch: 1 [3840/18580 (21%)]\tLoss: 0.663273\n",
      "Train Epoch: 1 [4480/18580 (24%)]\tLoss: 0.565103\n",
      "Train Epoch: 1 [5120/18580 (27%)]\tLoss: 0.378362\n",
      "Train Epoch: 1 [5760/18580 (31%)]\tLoss: 0.307043\n",
      "Train Epoch: 1 [6400/18580 (34%)]\tLoss: 0.412132\n",
      "Train Epoch: 1 [7040/18580 (38%)]\tLoss: 0.476733\n",
      "Train Epoch: 1 [7680/18580 (41%)]\tLoss: 0.437567\n",
      "Train Epoch: 1 [8320/18580 (45%)]\tLoss: 0.199267\n",
      "Train Epoch: 1 [8960/18580 (48%)]\tLoss: 0.525136\n",
      "Train Epoch: 1 [9600/18580 (52%)]\tLoss: 0.600419\n",
      "Train Epoch: 1 [10240/18580 (55%)]\tLoss: 0.305574\n",
      "Train Epoch: 1 [10880/18580 (58%)]\tLoss: 0.467298\n",
      "Train Epoch: 1 [11520/18580 (62%)]\tLoss: 0.269787\n",
      "Train Epoch: 1 [12160/18580 (65%)]\tLoss: 0.208846\n",
      "Train Epoch: 1 [12800/18580 (69%)]\tLoss: 0.655799\n",
      "Train Epoch: 1 [13440/18580 (72%)]\tLoss: 0.377339\n",
      "Train Epoch: 1 [14080/18580 (76%)]\tLoss: 0.281875\n",
      "Train Epoch: 1 [14720/18580 (79%)]\tLoss: 0.668502\n",
      "Train Epoch: 1 [15360/18580 (82%)]\tLoss: 0.425114\n",
      "Train Epoch: 1 [16000/18580 (86%)]\tLoss: 0.462448\n",
      "Train Epoch: 1 [16640/18580 (89%)]\tLoss: 0.366483\n",
      "Train Epoch: 1 [17280/18580 (93%)]\tLoss: 0.614110\n",
      "Train Epoch: 1 [17920/18580 (96%)]\tLoss: 0.472042\n",
      "Train Epoch: 1 [5800/18580 (100%)]\tLoss: 0.209316\n",
      "Train Epoch: 2 [0/18580 (0%)]\tLoss: 0.153361\n",
      "Train Epoch: 2 [640/18580 (3%)]\tLoss: 0.153955\n",
      "Train Epoch: 2 [1280/18580 (7%)]\tLoss: 0.248720\n",
      "Train Epoch: 2 [1920/18580 (10%)]\tLoss: 0.227853\n",
      "Train Epoch: 2 [2560/18580 (14%)]\tLoss: 0.112131\n",
      "Train Epoch: 2 [3200/18580 (17%)]\tLoss: 0.107763\n",
      "Train Epoch: 2 [3840/18580 (21%)]\tLoss: 0.245189\n",
      "Train Epoch: 2 [4480/18580 (24%)]\tLoss: 0.157799\n",
      "Train Epoch: 2 [5120/18580 (27%)]\tLoss: 0.206707\n",
      "Train Epoch: 2 [5760/18580 (31%)]\tLoss: 0.141265\n",
      "Train Epoch: 2 [6400/18580 (34%)]\tLoss: 0.230594\n",
      "Train Epoch: 2 [7040/18580 (38%)]\tLoss: 0.295225\n",
      "Train Epoch: 2 [7680/18580 (41%)]\tLoss: 0.143744\n",
      "Train Epoch: 2 [8320/18580 (45%)]\tLoss: 0.061528\n",
      "Train Epoch: 2 [8960/18580 (48%)]\tLoss: 0.141477\n",
      "Train Epoch: 2 [9600/18580 (52%)]\tLoss: 0.030906\n",
      "Train Epoch: 2 [10240/18580 (55%)]\tLoss: 0.406929\n",
      "Train Epoch: 2 [10880/18580 (58%)]\tLoss: 0.223223\n",
      "Train Epoch: 2 [11520/18580 (62%)]\tLoss: 0.209234\n",
      "Train Epoch: 2 [12160/18580 (65%)]\tLoss: 0.380613\n",
      "Train Epoch: 2 [12800/18580 (69%)]\tLoss: 0.195103\n",
      "Train Epoch: 2 [13440/18580 (72%)]\tLoss: 0.294623\n",
      "Train Epoch: 2 [14080/18580 (76%)]\tLoss: 0.254978\n",
      "Train Epoch: 2 [14720/18580 (79%)]\tLoss: 0.211856\n",
      "Train Epoch: 2 [15360/18580 (82%)]\tLoss: 0.265882\n",
      "Train Epoch: 2 [16000/18580 (86%)]\tLoss: 0.194649\n",
      "Train Epoch: 2 [16640/18580 (89%)]\tLoss: 0.270260\n",
      "Train Epoch: 2 [17280/18580 (93%)]\tLoss: 0.273360\n",
      "Train Epoch: 2 [17920/18580 (96%)]\tLoss: 0.201714\n",
      "Train Epoch: 2 [5800/18580 (100%)]\tLoss: 0.724993\n",
      "Train Epoch: 3 [0/18580 (0%)]\tLoss: 0.223716\n",
      "Train Epoch: 3 [640/18580 (3%)]\tLoss: 0.216751\n",
      "Train Epoch: 3 [1280/18580 (7%)]\tLoss: 0.104589\n",
      "Train Epoch: 3 [1920/18580 (10%)]\tLoss: 0.102503\n",
      "Train Epoch: 3 [2560/18580 (14%)]\tLoss: 0.044716\n",
      "Train Epoch: 3 [3200/18580 (17%)]\tLoss: 0.075169\n",
      "Train Epoch: 3 [3840/18580 (21%)]\tLoss: 0.072581\n",
      "Train Epoch: 3 [4480/18580 (24%)]\tLoss: 0.156338\n",
      "Train Epoch: 3 [5120/18580 (27%)]\tLoss: 0.032989\n",
      "Train Epoch: 3 [5760/18580 (31%)]\tLoss: 0.146255\n",
      "Train Epoch: 3 [6400/18580 (34%)]\tLoss: 0.170271\n",
      "Train Epoch: 3 [7040/18580 (38%)]\tLoss: 0.106798\n",
      "Train Epoch: 3 [7680/18580 (41%)]\tLoss: 0.184215\n",
      "Train Epoch: 3 [8320/18580 (45%)]\tLoss: 0.066162\n",
      "Train Epoch: 3 [8960/18580 (48%)]\tLoss: 0.126736\n",
      "Train Epoch: 3 [9600/18580 (52%)]\tLoss: 0.060724\n",
      "Train Epoch: 3 [10240/18580 (55%)]\tLoss: 0.196527\n",
      "Train Epoch: 3 [10880/18580 (58%)]\tLoss: 0.104790\n",
      "Train Epoch: 3 [11520/18580 (62%)]\tLoss: 0.212023\n",
      "Train Epoch: 3 [12160/18580 (65%)]\tLoss: 0.119048\n",
      "Train Epoch: 3 [12800/18580 (69%)]\tLoss: 0.098427\n",
      "Train Epoch: 3 [13440/18580 (72%)]\tLoss: 0.220594\n",
      "Train Epoch: 3 [14080/18580 (76%)]\tLoss: 0.280420\n",
      "Train Epoch: 3 [14720/18580 (79%)]\tLoss: 0.207490\n",
      "Train Epoch: 3 [15360/18580 (82%)]\tLoss: 0.255843\n",
      "Train Epoch: 3 [16000/18580 (86%)]\tLoss: 0.167824\n",
      "Train Epoch: 3 [16640/18580 (89%)]\tLoss: 0.199679\n",
      "Train Epoch: 3 [17280/18580 (93%)]\tLoss: 0.110339\n",
      "Train Epoch: 3 [17920/18580 (96%)]\tLoss: 0.130025\n",
      "Train Epoch: 3 [5800/18580 (100%)]\tLoss: 0.403338\n",
      "Train Epoch: 4 [0/18580 (0%)]\tLoss: 0.080467\n",
      "Train Epoch: 4 [640/18580 (3%)]\tLoss: 0.177982\n",
      "Train Epoch: 4 [1280/18580 (7%)]\tLoss: 0.049026\n",
      "Train Epoch: 4 [1920/18580 (10%)]\tLoss: 0.086525\n",
      "Train Epoch: 4 [2560/18580 (14%)]\tLoss: 0.096414\n",
      "Train Epoch: 4 [3200/18580 (17%)]\tLoss: 0.109595\n",
      "Train Epoch: 4 [3840/18580 (21%)]\tLoss: 0.092588\n",
      "Train Epoch: 4 [4480/18580 (24%)]\tLoss: 0.076555\n",
      "Train Epoch: 4 [5120/18580 (27%)]\tLoss: 0.040085\n",
      "Train Epoch: 4 [5760/18580 (31%)]\tLoss: 0.066445\n",
      "Train Epoch: 4 [6400/18580 (34%)]\tLoss: 0.205159\n",
      "Train Epoch: 4 [7040/18580 (38%)]\tLoss: 0.054285\n",
      "Train Epoch: 4 [7680/18580 (41%)]\tLoss: 0.156592\n",
      "Train Epoch: 4 [8320/18580 (45%)]\tLoss: 0.054435\n",
      "Train Epoch: 4 [8960/18580 (48%)]\tLoss: 0.051816\n",
      "Train Epoch: 4 [9600/18580 (52%)]\tLoss: 0.061303\n",
      "Train Epoch: 4 [10240/18580 (55%)]\tLoss: 0.112242\n",
      "Train Epoch: 4 [10880/18580 (58%)]\tLoss: 0.057063\n",
      "Train Epoch: 4 [11520/18580 (62%)]\tLoss: 0.057645\n",
      "Train Epoch: 4 [12160/18580 (65%)]\tLoss: 0.188061\n",
      "Train Epoch: 4 [12800/18580 (69%)]\tLoss: 0.045789\n",
      "Train Epoch: 4 [13440/18580 (72%)]\tLoss: 0.069871\n",
      "Train Epoch: 4 [14080/18580 (76%)]\tLoss: 0.105397\n",
      "Train Epoch: 4 [14720/18580 (79%)]\tLoss: 0.124179\n",
      "Train Epoch: 4 [15360/18580 (82%)]\tLoss: 0.070192\n",
      "Train Epoch: 4 [16000/18580 (86%)]\tLoss: 0.153946\n",
      "Train Epoch: 4 [16640/18580 (89%)]\tLoss: 0.070309\n",
      "Train Epoch: 4 [17280/18580 (93%)]\tLoss: 0.208590\n",
      "Train Epoch: 4 [17920/18580 (96%)]\tLoss: 0.216245\n",
      "Train Epoch: 4 [5800/18580 (100%)]\tLoss: 0.008737\n",
      "Train Epoch: 5 [0/18580 (0%)]\tLoss: 0.114060\n",
      "Train Epoch: 5 [640/18580 (3%)]\tLoss: 0.062627\n",
      "Train Epoch: 5 [1280/18580 (7%)]\tLoss: 0.110236\n",
      "Train Epoch: 5 [1920/18580 (10%)]\tLoss: 0.113365\n",
      "Train Epoch: 5 [2560/18580 (14%)]\tLoss: 0.007363\n",
      "Train Epoch: 5 [3200/18580 (17%)]\tLoss: 0.039270\n",
      "Train Epoch: 5 [3840/18580 (21%)]\tLoss: 0.222605\n",
      "Train Epoch: 5 [4480/18580 (24%)]\tLoss: 0.072652\n",
      "Train Epoch: 5 [5120/18580 (27%)]\tLoss: 0.128602\n",
      "Train Epoch: 5 [5760/18580 (31%)]\tLoss: 0.032200\n",
      "Train Epoch: 5 [6400/18580 (34%)]\tLoss: 0.145225\n",
      "Train Epoch: 5 [7040/18580 (38%)]\tLoss: 0.241419\n",
      "Train Epoch: 5 [7680/18580 (41%)]\tLoss: 0.059699\n",
      "Train Epoch: 5 [8320/18580 (45%)]\tLoss: 0.056288\n",
      "Train Epoch: 5 [8960/18580 (48%)]\tLoss: 0.040956\n",
      "Train Epoch: 5 [9600/18580 (52%)]\tLoss: 0.069031\n",
      "Train Epoch: 5 [10240/18580 (55%)]\tLoss: 0.075767\n",
      "Train Epoch: 5 [10880/18580 (58%)]\tLoss: 0.019279\n",
      "Train Epoch: 5 [11520/18580 (62%)]\tLoss: 0.112219\n",
      "Train Epoch: 5 [12160/18580 (65%)]\tLoss: 0.090567\n",
      "Train Epoch: 5 [12800/18580 (69%)]\tLoss: 0.047935\n",
      "Train Epoch: 5 [13440/18580 (72%)]\tLoss: 0.049345\n",
      "Train Epoch: 5 [14080/18580 (76%)]\tLoss: 0.141144\n",
      "Train Epoch: 5 [14720/18580 (79%)]\tLoss: 0.154463\n",
      "Train Epoch: 5 [15360/18580 (82%)]\tLoss: 0.071078\n",
      "Train Epoch: 5 [16000/18580 (86%)]\tLoss: 0.117535\n",
      "Train Epoch: 5 [16640/18580 (89%)]\tLoss: 0.094787\n",
      "Train Epoch: 5 [17280/18580 (93%)]\tLoss: 0.211595\n",
      "Train Epoch: 5 [17920/18580 (96%)]\tLoss: 0.157281\n",
      "Train Epoch: 5 [5800/18580 (100%)]\tLoss: 0.397023\n",
      "Train Epoch: 6 [0/18580 (0%)]\tLoss: 0.224557\n",
      "Train Epoch: 6 [640/18580 (3%)]\tLoss: 0.134918\n",
      "Train Epoch: 6 [1280/18580 (7%)]\tLoss: 0.052792\n",
      "Train Epoch: 6 [1920/18580 (10%)]\tLoss: 0.023854\n",
      "Train Epoch: 6 [2560/18580 (14%)]\tLoss: 0.063948\n",
      "Train Epoch: 6 [3200/18580 (17%)]\tLoss: 0.096907\n",
      "Train Epoch: 6 [3840/18580 (21%)]\tLoss: 0.069628\n",
      "Train Epoch: 6 [4480/18580 (24%)]\tLoss: 0.076790\n",
      "Train Epoch: 6 [5120/18580 (27%)]\tLoss: 0.061880\n",
      "Train Epoch: 6 [5760/18580 (31%)]\tLoss: 0.127375\n",
      "Train Epoch: 6 [6400/18580 (34%)]\tLoss: 0.082342\n",
      "Train Epoch: 6 [7040/18580 (38%)]\tLoss: 0.094569\n",
      "Train Epoch: 6 [7680/18580 (41%)]\tLoss: 0.107504\n",
      "Train Epoch: 6 [8320/18580 (45%)]\tLoss: 0.249206\n",
      "Train Epoch: 6 [8960/18580 (48%)]\tLoss: 0.070220\n",
      "Train Epoch: 6 [9600/18580 (52%)]\tLoss: 0.062323\n",
      "Train Epoch: 6 [10240/18580 (55%)]\tLoss: 0.054923\n",
      "Train Epoch: 6 [10880/18580 (58%)]\tLoss: 0.056444\n",
      "Train Epoch: 6 [11520/18580 (62%)]\tLoss: 0.129022\n",
      "Train Epoch: 6 [12160/18580 (65%)]\tLoss: 0.046241\n",
      "Train Epoch: 6 [12800/18580 (69%)]\tLoss: 0.110893\n",
      "Train Epoch: 6 [13440/18580 (72%)]\tLoss: 0.047659\n",
      "Train Epoch: 6 [14080/18580 (76%)]\tLoss: 0.192672\n",
      "Train Epoch: 6 [14720/18580 (79%)]\tLoss: 0.090285\n",
      "Train Epoch: 6 [15360/18580 (82%)]\tLoss: 0.095248\n",
      "Train Epoch: 6 [16000/18580 (86%)]\tLoss: 0.220755\n",
      "Train Epoch: 6 [16640/18580 (89%)]\tLoss: 0.138618\n",
      "Train Epoch: 6 [17280/18580 (93%)]\tLoss: 0.070573\n",
      "Train Epoch: 6 [17920/18580 (96%)]\tLoss: 0.092089\n",
      "Train Epoch: 6 [5800/18580 (100%)]\tLoss: 0.158839\n",
      "Train Epoch: 7 [0/18580 (0%)]\tLoss: 0.064721\n",
      "Train Epoch: 7 [640/18580 (3%)]\tLoss: 0.020407\n",
      "Train Epoch: 7 [1280/18580 (7%)]\tLoss: 0.141447\n",
      "Train Epoch: 7 [1920/18580 (10%)]\tLoss: 0.178977\n",
      "Train Epoch: 7 [2560/18580 (14%)]\tLoss: 0.122870\n",
      "Train Epoch: 7 [3200/18580 (17%)]\tLoss: 0.021581\n",
      "Train Epoch: 7 [3840/18580 (21%)]\tLoss: 0.055034\n",
      "Train Epoch: 7 [4480/18580 (24%)]\tLoss: 0.089131\n",
      "Train Epoch: 7 [5120/18580 (27%)]\tLoss: 0.042313\n",
      "Train Epoch: 7 [5760/18580 (31%)]\tLoss: 0.159914\n",
      "Train Epoch: 7 [6400/18580 (34%)]\tLoss: 0.060084\n",
      "Train Epoch: 7 [7040/18580 (38%)]\tLoss: 0.170796\n",
      "Train Epoch: 7 [7680/18580 (41%)]\tLoss: 0.093182\n",
      "Train Epoch: 7 [8320/18580 (45%)]\tLoss: 0.133805\n",
      "Train Epoch: 7 [8960/18580 (48%)]\tLoss: 0.054841\n",
      "Train Epoch: 7 [9600/18580 (52%)]\tLoss: 0.016924\n",
      "Train Epoch: 7 [10240/18580 (55%)]\tLoss: 0.029502\n",
      "Train Epoch: 7 [10880/18580 (58%)]\tLoss: 0.030251\n",
      "Train Epoch: 7 [11520/18580 (62%)]\tLoss: 0.061457\n",
      "Train Epoch: 7 [12160/18580 (65%)]\tLoss: 0.047236\n",
      "Train Epoch: 7 [12800/18580 (69%)]\tLoss: 0.063656\n",
      "Train Epoch: 7 [13440/18580 (72%)]\tLoss: 0.205668\n",
      "Train Epoch: 7 [14080/18580 (76%)]\tLoss: 0.132713\n",
      "Train Epoch: 7 [14720/18580 (79%)]\tLoss: 0.067502\n",
      "Train Epoch: 7 [15360/18580 (82%)]\tLoss: 0.051453\n",
      "Train Epoch: 7 [16000/18580 (86%)]\tLoss: 0.064384\n",
      "Train Epoch: 7 [16640/18580 (89%)]\tLoss: 0.065242\n",
      "Train Epoch: 7 [17280/18580 (93%)]\tLoss: 0.165290\n",
      "Train Epoch: 7 [17920/18580 (96%)]\tLoss: 0.063617\n",
      "Train Epoch: 7 [5800/18580 (100%)]\tLoss: 0.209320\n",
      "Train Epoch: 8 [0/18580 (0%)]\tLoss: 0.118113\n",
      "Train Epoch: 8 [640/18580 (3%)]\tLoss: 0.054976\n",
      "Train Epoch: 8 [1280/18580 (7%)]\tLoss: 0.079139\n",
      "Train Epoch: 8 [1920/18580 (10%)]\tLoss: 0.011464\n",
      "Train Epoch: 8 [2560/18580 (14%)]\tLoss: 0.095830\n",
      "Train Epoch: 8 [3200/18580 (17%)]\tLoss: 0.127242\n",
      "Train Epoch: 8 [3840/18580 (21%)]\tLoss: 0.059293\n",
      "Train Epoch: 8 [4480/18580 (24%)]\tLoss: 0.043773\n",
      "Train Epoch: 8 [5120/18580 (27%)]\tLoss: 0.048217\n",
      "Train Epoch: 8 [5760/18580 (31%)]\tLoss: 0.041657\n",
      "Train Epoch: 8 [6400/18580 (34%)]\tLoss: 0.075214\n",
      "Train Epoch: 8 [7040/18580 (38%)]\tLoss: 0.012929\n",
      "Train Epoch: 8 [7680/18580 (41%)]\tLoss: 0.013815\n",
      "Train Epoch: 8 [8320/18580 (45%)]\tLoss: 0.048720\n",
      "Train Epoch: 8 [8960/18580 (48%)]\tLoss: 0.037740\n",
      "Train Epoch: 8 [9600/18580 (52%)]\tLoss: 0.041041\n",
      "Train Epoch: 8 [10240/18580 (55%)]\tLoss: 0.067196\n",
      "Train Epoch: 8 [10880/18580 (58%)]\tLoss: 0.012260\n",
      "Train Epoch: 8 [11520/18580 (62%)]\tLoss: 0.011647\n",
      "Train Epoch: 8 [12160/18580 (65%)]\tLoss: 0.060264\n",
      "Train Epoch: 8 [12800/18580 (69%)]\tLoss: 0.101017\n",
      "Train Epoch: 8 [13440/18580 (72%)]\tLoss: 0.005599\n",
      "Train Epoch: 8 [14080/18580 (76%)]\tLoss: 0.009971\n",
      "Train Epoch: 8 [14720/18580 (79%)]\tLoss: 0.042194\n",
      "Train Epoch: 8 [15360/18580 (82%)]\tLoss: 0.024413\n",
      "Train Epoch: 8 [16000/18580 (86%)]\tLoss: 0.011497\n",
      "Train Epoch: 8 [16640/18580 (89%)]\tLoss: 0.086307\n",
      "Train Epoch: 8 [17280/18580 (93%)]\tLoss: 0.027001\n",
      "Train Epoch: 8 [17920/18580 (96%)]\tLoss: 0.050651\n",
      "Train Epoch: 8 [5800/18580 (100%)]\tLoss: 0.019110\n",
      "Train Epoch: 9 [0/18580 (0%)]\tLoss: 0.080854\n",
      "Train Epoch: 9 [640/18580 (3%)]\tLoss: 0.024112\n",
      "Train Epoch: 9 [1280/18580 (7%)]\tLoss: 0.009960\n",
      "Train Epoch: 9 [1920/18580 (10%)]\tLoss: 0.035448\n",
      "Train Epoch: 9 [2560/18580 (14%)]\tLoss: 0.051715\n",
      "Train Epoch: 9 [3200/18580 (17%)]\tLoss: 0.115911\n",
      "Train Epoch: 9 [3840/18580 (21%)]\tLoss: 0.020236\n",
      "Train Epoch: 9 [4480/18580 (24%)]\tLoss: 0.022586\n",
      "Train Epoch: 9 [5120/18580 (27%)]\tLoss: 0.031116\n",
      "Train Epoch: 9 [5760/18580 (31%)]\tLoss: 0.090401\n",
      "Train Epoch: 9 [6400/18580 (34%)]\tLoss: 0.059628\n",
      "Train Epoch: 9 [7040/18580 (38%)]\tLoss: 0.024864\n",
      "Train Epoch: 9 [7680/18580 (41%)]\tLoss: 0.041020\n",
      "Train Epoch: 9 [8320/18580 (45%)]\tLoss: 0.055009\n",
      "Train Epoch: 9 [8960/18580 (48%)]\tLoss: 0.078271\n",
      "Train Epoch: 9 [9600/18580 (52%)]\tLoss: 0.123304\n",
      "Train Epoch: 9 [10240/18580 (55%)]\tLoss: 0.016111\n",
      "Train Epoch: 9 [10880/18580 (58%)]\tLoss: 0.031090\n",
      "Train Epoch: 9 [11520/18580 (62%)]\tLoss: 0.029886\n",
      "Train Epoch: 9 [12160/18580 (65%)]\tLoss: 0.014814\n",
      "Train Epoch: 9 [12800/18580 (69%)]\tLoss: 0.022327\n",
      "Train Epoch: 9 [13440/18580 (72%)]\tLoss: 0.007835\n",
      "Train Epoch: 9 [14080/18580 (76%)]\tLoss: 0.051991\n",
      "Train Epoch: 9 [14720/18580 (79%)]\tLoss: 0.059320\n",
      "Train Epoch: 9 [15360/18580 (82%)]\tLoss: 0.041254\n",
      "Train Epoch: 9 [16000/18580 (86%)]\tLoss: 0.004744\n",
      "Train Epoch: 9 [16640/18580 (89%)]\tLoss: 0.029051\n",
      "Train Epoch: 9 [17280/18580 (93%)]\tLoss: 0.012749\n",
      "Train Epoch: 9 [17920/18580 (96%)]\tLoss: 0.058328\n",
      "Train Epoch: 9 [5800/18580 (100%)]\tLoss: 0.039762\n",
      "Train Epoch: 10 [0/18580 (0%)]\tLoss: 0.008640\n",
      "Train Epoch: 10 [640/18580 (3%)]\tLoss: 0.020874\n",
      "Train Epoch: 10 [1280/18580 (7%)]\tLoss: 0.033122\n",
      "Train Epoch: 10 [1920/18580 (10%)]\tLoss: 0.087220\n",
      "Train Epoch: 10 [2560/18580 (14%)]\tLoss: 0.029668\n",
      "Train Epoch: 10 [3200/18580 (17%)]\tLoss: 0.064203\n",
      "Train Epoch: 10 [3840/18580 (21%)]\tLoss: 0.007887\n",
      "Train Epoch: 10 [4480/18580 (24%)]\tLoss: 0.028848\n",
      "Train Epoch: 10 [5120/18580 (27%)]\tLoss: 0.012829\n",
      "Train Epoch: 10 [5760/18580 (31%)]\tLoss: 0.004249\n",
      "Train Epoch: 10 [6400/18580 (34%)]\tLoss: 0.192611\n",
      "Train Epoch: 10 [7040/18580 (38%)]\tLoss: 0.006743\n",
      "Train Epoch: 10 [7680/18580 (41%)]\tLoss: 0.025960\n",
      "Train Epoch: 10 [8320/18580 (45%)]\tLoss: 0.023179\n",
      "Train Epoch: 10 [8960/18580 (48%)]\tLoss: 0.100360\n",
      "Train Epoch: 10 [9600/18580 (52%)]\tLoss: 0.044181\n",
      "Train Epoch: 10 [10240/18580 (55%)]\tLoss: 0.043879\n",
      "Train Epoch: 10 [10880/18580 (58%)]\tLoss: 0.013137\n",
      "Train Epoch: 10 [11520/18580 (62%)]\tLoss: 0.025810\n",
      "Train Epoch: 10 [12160/18580 (65%)]\tLoss: 0.018314\n",
      "Train Epoch: 10 [12800/18580 (69%)]\tLoss: 0.108115\n",
      "Train Epoch: 10 [13440/18580 (72%)]\tLoss: 0.194967\n",
      "Train Epoch: 10 [14080/18580 (76%)]\tLoss: 0.027512\n",
      "Train Epoch: 10 [14720/18580 (79%)]\tLoss: 0.035538\n",
      "Train Epoch: 10 [15360/18580 (82%)]\tLoss: 0.083630\n",
      "Train Epoch: 10 [16000/18580 (86%)]\tLoss: 0.109041\n",
      "Train Epoch: 10 [16640/18580 (89%)]\tLoss: 0.049511\n",
      "Train Epoch: 10 [17280/18580 (93%)]\tLoss: 0.043238\n",
      "Train Epoch: 10 [17920/18580 (96%)]\tLoss: 0.007641\n",
      "Train Epoch: 10 [5800/18580 (100%)]\tLoss: 0.283285\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/9043 (0%)]\tLoss: 1.833347\n",
      "Train Epoch: 1 [640/9043 (7%)]\tLoss: 0.470327\n",
      "Train Epoch: 1 [1280/9043 (14%)]\tLoss: 0.465157\n",
      "Train Epoch: 1 [1920/9043 (21%)]\tLoss: 0.451755\n",
      "Train Epoch: 1 [2560/9043 (28%)]\tLoss: 0.686004\n",
      "Train Epoch: 1 [3200/9043 (35%)]\tLoss: 0.723875\n",
      "Train Epoch: 1 [3840/9043 (42%)]\tLoss: 0.461775\n",
      "Train Epoch: 1 [4480/9043 (49%)]\tLoss: 0.339018\n",
      "Train Epoch: 1 [5120/9043 (56%)]\tLoss: 0.353660\n",
      "Train Epoch: 1 [5760/9043 (63%)]\tLoss: 0.503522\n",
      "Train Epoch: 1 [6400/9043 (70%)]\tLoss: 0.375098\n",
      "Train Epoch: 1 [7040/9043 (77%)]\tLoss: 0.370838\n",
      "Train Epoch: 1 [7680/9043 (85%)]\tLoss: 0.389268\n",
      "Train Epoch: 1 [8320/9043 (92%)]\tLoss: 0.405580\n",
      "Train Epoch: 1 [8960/9043 (99%)]\tLoss: 0.499000\n",
      "Train Epoch: 2 [0/9043 (0%)]\tLoss: 0.222268\n",
      "Train Epoch: 2 [640/9043 (7%)]\tLoss: 0.141543\n",
      "Train Epoch: 2 [1280/9043 (14%)]\tLoss: 0.132682\n",
      "Train Epoch: 2 [1920/9043 (21%)]\tLoss: 0.235871\n",
      "Train Epoch: 2 [2560/9043 (28%)]\tLoss: 0.270922\n",
      "Train Epoch: 2 [3200/9043 (35%)]\tLoss: 0.253029\n",
      "Train Epoch: 2 [3840/9043 (42%)]\tLoss: 0.185104\n",
      "Train Epoch: 2 [4480/9043 (49%)]\tLoss: 0.094658\n",
      "Train Epoch: 2 [5120/9043 (56%)]\tLoss: 0.113586\n",
      "Train Epoch: 2 [5760/9043 (63%)]\tLoss: 0.199438\n",
      "Train Epoch: 2 [6400/9043 (70%)]\tLoss: 0.258569\n",
      "Train Epoch: 2 [7040/9043 (77%)]\tLoss: 0.127928\n",
      "Train Epoch: 2 [7680/9043 (85%)]\tLoss: 0.258036\n",
      "Train Epoch: 2 [8320/9043 (92%)]\tLoss: 0.122814\n",
      "Train Epoch: 2 [8960/9043 (99%)]\tLoss: 0.215446\n",
      "Train Epoch: 3 [0/9043 (0%)]\tLoss: 0.161390\n",
      "Train Epoch: 3 [640/9043 (7%)]\tLoss: 0.098836\n",
      "Train Epoch: 3 [1280/9043 (14%)]\tLoss: 0.100422\n",
      "Train Epoch: 3 [1920/9043 (21%)]\tLoss: 0.113507\n",
      "Train Epoch: 3 [2560/9043 (28%)]\tLoss: 0.069610\n",
      "Train Epoch: 3 [3200/9043 (35%)]\tLoss: 0.128801\n",
      "Train Epoch: 3 [3840/9043 (42%)]\tLoss: 0.155372\n",
      "Train Epoch: 3 [4480/9043 (49%)]\tLoss: 0.215266\n",
      "Train Epoch: 3 [5120/9043 (56%)]\tLoss: 0.077090\n",
      "Train Epoch: 3 [5760/9043 (63%)]\tLoss: 0.135197\n",
      "Train Epoch: 3 [6400/9043 (70%)]\tLoss: 0.189882\n",
      "Train Epoch: 3 [7040/9043 (77%)]\tLoss: 0.132838\n",
      "Train Epoch: 3 [7680/9043 (85%)]\tLoss: 0.122265\n",
      "Train Epoch: 3 [8320/9043 (92%)]\tLoss: 0.167842\n",
      "Train Epoch: 3 [8960/9043 (99%)]\tLoss: 0.243228\n",
      "Train Epoch: 4 [0/9043 (0%)]\tLoss: 0.091358\n",
      "Train Epoch: 4 [640/9043 (7%)]\tLoss: 0.042820\n",
      "Train Epoch: 4 [1280/9043 (14%)]\tLoss: 0.027248\n",
      "Train Epoch: 4 [1920/9043 (21%)]\tLoss: 0.114408\n",
      "Train Epoch: 4 [2560/9043 (28%)]\tLoss: 0.100951\n",
      "Train Epoch: 4 [3200/9043 (35%)]\tLoss: 0.084469\n",
      "Train Epoch: 4 [3840/9043 (42%)]\tLoss: 0.056549\n",
      "Train Epoch: 4 [4480/9043 (49%)]\tLoss: 0.174822\n",
      "Train Epoch: 4 [5120/9043 (56%)]\tLoss: 0.245436\n",
      "Train Epoch: 4 [5760/9043 (63%)]\tLoss: 0.087555\n",
      "Train Epoch: 4 [6400/9043 (70%)]\tLoss: 0.168547\n",
      "Train Epoch: 4 [7040/9043 (77%)]\tLoss: 0.116712\n",
      "Train Epoch: 4 [7680/9043 (85%)]\tLoss: 0.079883\n",
      "Train Epoch: 4 [8320/9043 (92%)]\tLoss: 0.030817\n",
      "Train Epoch: 4 [8960/9043 (99%)]\tLoss: 0.041181\n",
      "Train Epoch: 5 [0/9043 (0%)]\tLoss: 0.062187\n",
      "Train Epoch: 5 [640/9043 (7%)]\tLoss: 0.090897\n",
      "Train Epoch: 5 [1280/9043 (14%)]\tLoss: 0.030771\n",
      "Train Epoch: 5 [1920/9043 (21%)]\tLoss: 0.091952\n",
      "Train Epoch: 5 [2560/9043 (28%)]\tLoss: 0.081888\n",
      "Train Epoch: 5 [3200/9043 (35%)]\tLoss: 0.049287\n",
      "Train Epoch: 5 [3840/9043 (42%)]\tLoss: 0.155467\n",
      "Train Epoch: 5 [4480/9043 (49%)]\tLoss: 0.008618\n",
      "Train Epoch: 5 [5120/9043 (56%)]\tLoss: 0.066119\n",
      "Train Epoch: 5 [5760/9043 (63%)]\tLoss: 0.079525\n",
      "Train Epoch: 5 [6400/9043 (70%)]\tLoss: 0.035443\n",
      "Train Epoch: 5 [7040/9043 (77%)]\tLoss: 0.332765\n",
      "Train Epoch: 5 [7680/9043 (85%)]\tLoss: 0.023389\n",
      "Train Epoch: 5 [8320/9043 (92%)]\tLoss: 0.116082\n",
      "Train Epoch: 5 [8960/9043 (99%)]\tLoss: 0.082652\n",
      "Train Epoch: 6 [0/9043 (0%)]\tLoss: 0.168677\n",
      "Train Epoch: 6 [640/9043 (7%)]\tLoss: 0.040784\n",
      "Train Epoch: 6 [1280/9043 (14%)]\tLoss: 0.272961\n",
      "Train Epoch: 6 [1920/9043 (21%)]\tLoss: 0.081602\n",
      "Train Epoch: 6 [2560/9043 (28%)]\tLoss: 0.228270\n",
      "Train Epoch: 6 [3200/9043 (35%)]\tLoss: 0.068816\n",
      "Train Epoch: 6 [3840/9043 (42%)]\tLoss: 0.054553\n",
      "Train Epoch: 6 [4480/9043 (49%)]\tLoss: 0.094250\n",
      "Train Epoch: 6 [5120/9043 (56%)]\tLoss: 0.064696\n",
      "Train Epoch: 6 [5760/9043 (63%)]\tLoss: 0.046622\n",
      "Train Epoch: 6 [6400/9043 (70%)]\tLoss: 0.070427\n",
      "Train Epoch: 6 [7040/9043 (77%)]\tLoss: 0.131525\n",
      "Train Epoch: 6 [7680/9043 (85%)]\tLoss: 0.039499\n",
      "Train Epoch: 6 [8320/9043 (92%)]\tLoss: 0.032508\n",
      "Train Epoch: 6 [8960/9043 (99%)]\tLoss: 0.019608\n",
      "Train Epoch: 7 [0/9043 (0%)]\tLoss: 0.079027\n",
      "Train Epoch: 7 [640/9043 (7%)]\tLoss: 0.052016\n",
      "Train Epoch: 7 [1280/9043 (14%)]\tLoss: 0.032445\n",
      "Train Epoch: 7 [1920/9043 (21%)]\tLoss: 0.092237\n",
      "Train Epoch: 7 [2560/9043 (28%)]\tLoss: 0.042040\n",
      "Train Epoch: 7 [3200/9043 (35%)]\tLoss: 0.037782\n",
      "Train Epoch: 7 [3840/9043 (42%)]\tLoss: 0.062286\n",
      "Train Epoch: 7 [4480/9043 (49%)]\tLoss: 0.082054\n",
      "Train Epoch: 7 [5120/9043 (56%)]\tLoss: 0.026447\n",
      "Train Epoch: 7 [5760/9043 (63%)]\tLoss: 0.038255\n",
      "Train Epoch: 7 [6400/9043 (70%)]\tLoss: 0.158929\n",
      "Train Epoch: 7 [7040/9043 (77%)]\tLoss: 0.081906\n",
      "Train Epoch: 7 [7680/9043 (85%)]\tLoss: 0.058028\n",
      "Train Epoch: 7 [8320/9043 (92%)]\tLoss: 0.060019\n",
      "Train Epoch: 7 [8960/9043 (99%)]\tLoss: 0.040279\n",
      "Train Epoch: 8 [0/9043 (0%)]\tLoss: 0.015257\n",
      "Train Epoch: 8 [640/9043 (7%)]\tLoss: 0.034284\n",
      "Train Epoch: 8 [1280/9043 (14%)]\tLoss: 0.046215\n",
      "Train Epoch: 8 [1920/9043 (21%)]\tLoss: 0.061516\n",
      "Train Epoch: 8 [2560/9043 (28%)]\tLoss: 0.017754\n",
      "Train Epoch: 8 [3200/9043 (35%)]\tLoss: 0.007439\n",
      "Train Epoch: 8 [3840/9043 (42%)]\tLoss: 0.026066\n",
      "Train Epoch: 8 [4480/9043 (49%)]\tLoss: 0.090689\n",
      "Train Epoch: 8 [5120/9043 (56%)]\tLoss: 0.015194\n",
      "Train Epoch: 8 [5760/9043 (63%)]\tLoss: 0.146349\n",
      "Train Epoch: 8 [6400/9043 (70%)]\tLoss: 0.070174\n",
      "Train Epoch: 8 [7040/9043 (77%)]\tLoss: 0.088440\n",
      "Train Epoch: 8 [7680/9043 (85%)]\tLoss: 0.044794\n",
      "Train Epoch: 8 [8320/9043 (92%)]\tLoss: 0.036972\n",
      "Train Epoch: 8 [8960/9043 (99%)]\tLoss: 0.057209\n",
      "Train Epoch: 9 [0/9043 (0%)]\tLoss: 0.012220\n",
      "Train Epoch: 9 [640/9043 (7%)]\tLoss: 0.263851\n",
      "Train Epoch: 9 [1280/9043 (14%)]\tLoss: 0.031180\n",
      "Train Epoch: 9 [1920/9043 (21%)]\tLoss: 0.115983\n",
      "Train Epoch: 9 [2560/9043 (28%)]\tLoss: 0.015649\n",
      "Train Epoch: 9 [3200/9043 (35%)]\tLoss: 0.070186\n",
      "Train Epoch: 9 [3840/9043 (42%)]\tLoss: 0.060979\n",
      "Train Epoch: 9 [4480/9043 (49%)]\tLoss: 0.021782\n",
      "Train Epoch: 9 [5120/9043 (56%)]\tLoss: 0.049812\n",
      "Train Epoch: 9 [5760/9043 (63%)]\tLoss: 0.063113\n",
      "Train Epoch: 9 [6400/9043 (70%)]\tLoss: 0.088426\n",
      "Train Epoch: 9 [7040/9043 (77%)]\tLoss: 0.058162\n",
      "Train Epoch: 9 [7680/9043 (85%)]\tLoss: 0.032353\n",
      "Train Epoch: 9 [8320/9043 (92%)]\tLoss: 0.034410\n",
      "Train Epoch: 9 [8960/9043 (99%)]\tLoss: 0.074699\n",
      "Train Epoch: 10 [0/9043 (0%)]\tLoss: 0.005828\n",
      "Train Epoch: 10 [640/9043 (7%)]\tLoss: 0.013363\n",
      "Train Epoch: 10 [1280/9043 (14%)]\tLoss: 0.016881\n",
      "Train Epoch: 10 [1920/9043 (21%)]\tLoss: 0.061186\n",
      "Train Epoch: 10 [2560/9043 (28%)]\tLoss: 0.018502\n",
      "Train Epoch: 10 [3200/9043 (35%)]\tLoss: 0.067730\n",
      "Train Epoch: 10 [3840/9043 (42%)]\tLoss: 0.017769\n",
      "Train Epoch: 10 [4480/9043 (49%)]\tLoss: 0.035863\n",
      "Train Epoch: 10 [5120/9043 (56%)]\tLoss: 0.043910\n",
      "Train Epoch: 10 [5760/9043 (63%)]\tLoss: 0.008573\n",
      "Train Epoch: 10 [6400/9043 (70%)]\tLoss: 0.029499\n",
      "Train Epoch: 10 [7040/9043 (77%)]\tLoss: 0.016537\n",
      "Train Epoch: 10 [7680/9043 (85%)]\tLoss: 0.057439\n",
      "Train Epoch: 10 [8320/9043 (92%)]\tLoss: 0.057943\n",
      "Train Epoch: 10 [8960/9043 (99%)]\tLoss: 0.017337\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/14723 (0%)]\tLoss: 0.848103\n",
      "Train Epoch: 1 [640/14723 (4%)]\tLoss: 0.585855\n",
      "Train Epoch: 1 [1280/14723 (9%)]\tLoss: 0.666177\n",
      "Train Epoch: 1 [1920/14723 (13%)]\tLoss: 0.465048\n",
      "Train Epoch: 1 [2560/14723 (17%)]\tLoss: 0.428427\n",
      "Train Epoch: 1 [3200/14723 (22%)]\tLoss: 0.370274\n",
      "Train Epoch: 1 [3840/14723 (26%)]\tLoss: 0.518185\n",
      "Train Epoch: 1 [4480/14723 (30%)]\tLoss: 0.741467\n",
      "Train Epoch: 1 [5120/14723 (35%)]\tLoss: 0.653742\n",
      "Train Epoch: 1 [5760/14723 (39%)]\tLoss: 0.740441\n",
      "Train Epoch: 1 [6400/14723 (43%)]\tLoss: 0.706960\n",
      "Train Epoch: 1 [7040/14723 (48%)]\tLoss: 0.696104\n",
      "Train Epoch: 1 [7680/14723 (52%)]\tLoss: 0.504508\n",
      "Train Epoch: 1 [8320/14723 (56%)]\tLoss: 0.476576\n",
      "Train Epoch: 1 [8960/14723 (61%)]\tLoss: 0.842378\n",
      "Train Epoch: 1 [9600/14723 (65%)]\tLoss: 0.671475\n",
      "Train Epoch: 1 [10240/14723 (69%)]\tLoss: 0.566745\n",
      "Train Epoch: 1 [10880/14723 (74%)]\tLoss: 0.543266\n",
      "Train Epoch: 1 [11520/14723 (78%)]\tLoss: 0.659777\n",
      "Train Epoch: 1 [12160/14723 (82%)]\tLoss: 0.514262\n",
      "Train Epoch: 1 [12800/14723 (87%)]\tLoss: 0.566844\n",
      "Train Epoch: 1 [13440/14723 (91%)]\tLoss: 0.516673\n",
      "Train Epoch: 1 [14080/14723 (95%)]\tLoss: 0.699930\n",
      "Train Epoch: 1 [690/14723 (100%)]\tLoss: 1.734516\n",
      "Train Epoch: 2 [0/14723 (0%)]\tLoss: 0.594727\n",
      "Train Epoch: 2 [640/14723 (4%)]\tLoss: 0.927928\n",
      "Train Epoch: 2 [1280/14723 (9%)]\tLoss: 1.044845\n",
      "Train Epoch: 2 [1920/14723 (13%)]\tLoss: 1.069745\n",
      "Train Epoch: 2 [2560/14723 (17%)]\tLoss: 0.896413\n",
      "Train Epoch: 2 [3200/14723 (22%)]\tLoss: 0.727380\n",
      "Train Epoch: 2 [3840/14723 (26%)]\tLoss: 0.665130\n",
      "Train Epoch: 2 [4480/14723 (30%)]\tLoss: 0.870626\n",
      "Train Epoch: 2 [5120/14723 (35%)]\tLoss: 0.812850\n",
      "Train Epoch: 2 [5760/14723 (39%)]\tLoss: 0.831363\n",
      "Train Epoch: 2 [6400/14723 (43%)]\tLoss: 0.774108\n",
      "Train Epoch: 2 [7040/14723 (48%)]\tLoss: 0.708568\n",
      "Train Epoch: 2 [7680/14723 (52%)]\tLoss: 1.049624\n",
      "Train Epoch: 2 [8320/14723 (56%)]\tLoss: 0.693948\n",
      "Train Epoch: 2 [8960/14723 (61%)]\tLoss: 0.908655\n",
      "Train Epoch: 2 [9600/14723 (65%)]\tLoss: 0.671483\n",
      "Train Epoch: 2 [10240/14723 (69%)]\tLoss: 0.550119\n",
      "Train Epoch: 2 [10880/14723 (74%)]\tLoss: 0.648067\n",
      "Train Epoch: 2 [11520/14723 (78%)]\tLoss: 0.783930\n",
      "Train Epoch: 2 [12160/14723 (82%)]\tLoss: 0.642220\n",
      "Train Epoch: 2 [12800/14723 (87%)]\tLoss: 0.609363\n",
      "Train Epoch: 2 [13440/14723 (91%)]\tLoss: 0.672451\n",
      "Train Epoch: 2 [14080/14723 (95%)]\tLoss: 0.936052\n",
      "Train Epoch: 2 [690/14723 (100%)]\tLoss: 3.289221\n",
      "Train Epoch: 3 [0/14723 (0%)]\tLoss: 1.399975\n",
      "Train Epoch: 3 [640/14723 (4%)]\tLoss: 0.994103\n",
      "Train Epoch: 3 [1280/14723 (9%)]\tLoss: 0.713448\n",
      "Train Epoch: 3 [1920/14723 (13%)]\tLoss: 0.971318\n",
      "Train Epoch: 3 [2560/14723 (17%)]\tLoss: 0.492865\n",
      "Train Epoch: 3 [3200/14723 (22%)]\tLoss: 0.870670\n",
      "Train Epoch: 3 [3840/14723 (26%)]\tLoss: 0.783650\n",
      "Train Epoch: 3 [4480/14723 (30%)]\tLoss: 0.346353\n",
      "Train Epoch: 3 [5120/14723 (35%)]\tLoss: 0.542863\n",
      "Train Epoch: 3 [5760/14723 (39%)]\tLoss: 0.637624\n",
      "Train Epoch: 3 [6400/14723 (43%)]\tLoss: 0.772689\n",
      "Train Epoch: 3 [7040/14723 (48%)]\tLoss: 0.532604\n",
      "Train Epoch: 3 [7680/14723 (52%)]\tLoss: 0.560009\n",
      "Train Epoch: 3 [8320/14723 (56%)]\tLoss: 0.864691\n",
      "Train Epoch: 3 [8960/14723 (61%)]\tLoss: 0.602207\n",
      "Train Epoch: 3 [9600/14723 (65%)]\tLoss: 0.658820\n",
      "Train Epoch: 3 [10240/14723 (69%)]\tLoss: 0.648908\n",
      "Train Epoch: 3 [10880/14723 (74%)]\tLoss: 0.626416\n",
      "Train Epoch: 3 [11520/14723 (78%)]\tLoss: 0.610038\n",
      "Train Epoch: 3 [12160/14723 (82%)]\tLoss: 0.737767\n",
      "Train Epoch: 3 [12800/14723 (87%)]\tLoss: 0.585417\n",
      "Train Epoch: 3 [13440/14723 (91%)]\tLoss: 0.566314\n",
      "Train Epoch: 3 [14080/14723 (95%)]\tLoss: 0.412219\n",
      "Train Epoch: 3 [690/14723 (100%)]\tLoss: 3.661546\n",
      "Train Epoch: 4 [0/14723 (0%)]\tLoss: 1.225198\n",
      "Train Epoch: 4 [640/14723 (4%)]\tLoss: 1.185621\n",
      "Train Epoch: 4 [1280/14723 (9%)]\tLoss: 1.200333\n",
      "Train Epoch: 4 [1920/14723 (13%)]\tLoss: 1.235079\n",
      "Train Epoch: 4 [2560/14723 (17%)]\tLoss: 1.056778\n",
      "Train Epoch: 4 [3200/14723 (22%)]\tLoss: 1.003698\n",
      "Train Epoch: 4 [3840/14723 (26%)]\tLoss: 0.848793\n",
      "Train Epoch: 4 [4480/14723 (30%)]\tLoss: 0.979625\n",
      "Train Epoch: 4 [5120/14723 (35%)]\tLoss: 0.934971\n",
      "Train Epoch: 4 [5760/14723 (39%)]\tLoss: 0.788315\n",
      "Train Epoch: 4 [6400/14723 (43%)]\tLoss: 0.989759\n",
      "Train Epoch: 4 [7040/14723 (48%)]\tLoss: 0.619014\n",
      "Train Epoch: 4 [7680/14723 (52%)]\tLoss: 0.865305\n",
      "Train Epoch: 4 [8320/14723 (56%)]\tLoss: 0.850576\n",
      "Train Epoch: 4 [8960/14723 (61%)]\tLoss: 0.642728\n",
      "Train Epoch: 4 [9600/14723 (65%)]\tLoss: 1.134166\n",
      "Train Epoch: 4 [10240/14723 (69%)]\tLoss: 0.744030\n",
      "Train Epoch: 4 [10880/14723 (74%)]\tLoss: 0.844397\n",
      "Train Epoch: 4 [11520/14723 (78%)]\tLoss: 0.740945\n",
      "Train Epoch: 4 [12160/14723 (82%)]\tLoss: 0.714194\n",
      "Train Epoch: 4 [12800/14723 (87%)]\tLoss: 0.837579\n",
      "Train Epoch: 4 [13440/14723 (91%)]\tLoss: 0.661338\n",
      "Train Epoch: 4 [14080/14723 (95%)]\tLoss: 0.830181\n",
      "Train Epoch: 4 [690/14723 (100%)]\tLoss: 0.316918\n",
      "Train Epoch: 5 [0/14723 (0%)]\tLoss: 0.426246\n",
      "Train Epoch: 5 [640/14723 (4%)]\tLoss: 0.400902\n",
      "Train Epoch: 5 [1280/14723 (9%)]\tLoss: 0.496892\n",
      "Train Epoch: 5 [1920/14723 (13%)]\tLoss: 0.427709\n",
      "Train Epoch: 5 [2560/14723 (17%)]\tLoss: 0.461956\n",
      "Train Epoch: 5 [3200/14723 (22%)]\tLoss: 0.601585\n",
      "Train Epoch: 5 [3840/14723 (26%)]\tLoss: 0.568931\n",
      "Train Epoch: 5 [4480/14723 (30%)]\tLoss: 0.441724\n",
      "Train Epoch: 5 [5120/14723 (35%)]\tLoss: 0.435524\n",
      "Train Epoch: 5 [5760/14723 (39%)]\tLoss: 0.386080\n",
      "Train Epoch: 5 [6400/14723 (43%)]\tLoss: 0.333583\n",
      "Train Epoch: 5 [7040/14723 (48%)]\tLoss: 0.391730\n",
      "Train Epoch: 5 [7680/14723 (52%)]\tLoss: 0.348664\n",
      "Train Epoch: 5 [8320/14723 (56%)]\tLoss: 0.623843\n",
      "Train Epoch: 5 [8960/14723 (61%)]\tLoss: 0.543323\n",
      "Train Epoch: 5 [9600/14723 (65%)]\tLoss: 0.530210\n",
      "Train Epoch: 5 [10240/14723 (69%)]\tLoss: 0.501536\n",
      "Train Epoch: 5 [10880/14723 (74%)]\tLoss: 0.286974\n",
      "Train Epoch: 5 [11520/14723 (78%)]\tLoss: 0.839890\n",
      "Train Epoch: 5 [12160/14723 (82%)]\tLoss: 0.462846\n",
      "Train Epoch: 5 [12800/14723 (87%)]\tLoss: 0.760351\n",
      "Train Epoch: 5 [13440/14723 (91%)]\tLoss: 0.527525\n",
      "Train Epoch: 5 [14080/14723 (95%)]\tLoss: 0.192761\n",
      "Train Epoch: 5 [690/14723 (100%)]\tLoss: 3.930360\n",
      "Train Epoch: 6 [0/14723 (0%)]\tLoss: 1.170698\n",
      "Train Epoch: 6 [640/14723 (4%)]\tLoss: 0.946090\n",
      "Train Epoch: 6 [1280/14723 (9%)]\tLoss: 0.751494\n",
      "Train Epoch: 6 [1920/14723 (13%)]\tLoss: 0.682065\n",
      "Train Epoch: 6 [2560/14723 (17%)]\tLoss: 0.647980\n",
      "Train Epoch: 6 [3200/14723 (22%)]\tLoss: 0.684128\n",
      "Train Epoch: 6 [3840/14723 (26%)]\tLoss: 0.751524\n",
      "Train Epoch: 6 [4480/14723 (30%)]\tLoss: 0.571060\n",
      "Train Epoch: 6 [5120/14723 (35%)]\tLoss: 0.490038\n",
      "Train Epoch: 6 [5760/14723 (39%)]\tLoss: 0.685377\n",
      "Train Epoch: 6 [6400/14723 (43%)]\tLoss: 0.649545\n",
      "Train Epoch: 6 [7040/14723 (48%)]\tLoss: 0.752627\n",
      "Train Epoch: 6 [7680/14723 (52%)]\tLoss: 0.453969\n",
      "Train Epoch: 6 [8320/14723 (56%)]\tLoss: 0.515245\n",
      "Train Epoch: 6 [8960/14723 (61%)]\tLoss: 0.364501\n",
      "Train Epoch: 6 [9600/14723 (65%)]\tLoss: 0.795414\n",
      "Train Epoch: 6 [10240/14723 (69%)]\tLoss: 0.537941\n",
      "Train Epoch: 6 [10880/14723 (74%)]\tLoss: 0.471809\n",
      "Train Epoch: 6 [11520/14723 (78%)]\tLoss: 0.418917\n",
      "Train Epoch: 6 [12160/14723 (82%)]\tLoss: 0.524808\n",
      "Train Epoch: 6 [12800/14723 (87%)]\tLoss: 0.560214\n",
      "Train Epoch: 6 [13440/14723 (91%)]\tLoss: 0.370298\n",
      "Train Epoch: 6 [14080/14723 (95%)]\tLoss: 0.559742\n",
      "Train Epoch: 6 [690/14723 (100%)]\tLoss: 0.225846\n",
      "Train Epoch: 7 [0/14723 (0%)]\tLoss: 0.415125\n",
      "Train Epoch: 7 [640/14723 (4%)]\tLoss: 0.463068\n",
      "Train Epoch: 7 [1280/14723 (9%)]\tLoss: 0.276990\n",
      "Train Epoch: 7 [1920/14723 (13%)]\tLoss: 0.338456\n",
      "Train Epoch: 7 [2560/14723 (17%)]\tLoss: 0.531859\n",
      "Train Epoch: 7 [3200/14723 (22%)]\tLoss: 0.365076\n",
      "Train Epoch: 7 [3840/14723 (26%)]\tLoss: 0.335775\n",
      "Train Epoch: 7 [4480/14723 (30%)]\tLoss: 0.243503\n",
      "Train Epoch: 7 [5120/14723 (35%)]\tLoss: 0.167345\n",
      "Train Epoch: 7 [5760/14723 (39%)]\tLoss: 0.132241\n",
      "Train Epoch: 7 [6400/14723 (43%)]\tLoss: 0.331362\n",
      "Train Epoch: 7 [7040/14723 (48%)]\tLoss: 0.271953\n",
      "Train Epoch: 7 [7680/14723 (52%)]\tLoss: 0.560547\n",
      "Train Epoch: 7 [8320/14723 (56%)]\tLoss: 0.190549\n",
      "Train Epoch: 7 [8960/14723 (61%)]\tLoss: 0.289658\n",
      "Train Epoch: 7 [9600/14723 (65%)]\tLoss: 0.368228\n",
      "Train Epoch: 7 [10240/14723 (69%)]\tLoss: 0.452886\n",
      "Train Epoch: 7 [10880/14723 (74%)]\tLoss: 0.284934\n",
      "Train Epoch: 7 [11520/14723 (78%)]\tLoss: 0.366954\n",
      "Train Epoch: 7 [12160/14723 (82%)]\tLoss: 0.355714\n",
      "Train Epoch: 7 [12800/14723 (87%)]\tLoss: 0.391892\n",
      "Train Epoch: 7 [13440/14723 (91%)]\tLoss: 0.212653\n",
      "Train Epoch: 7 [14080/14723 (95%)]\tLoss: 0.518149\n",
      "Train Epoch: 7 [690/14723 (100%)]\tLoss: 1.827542\n",
      "Train Epoch: 8 [0/14723 (0%)]\tLoss: 0.903745\n",
      "Train Epoch: 8 [640/14723 (4%)]\tLoss: 1.301309\n",
      "Train Epoch: 8 [1280/14723 (9%)]\tLoss: 0.978079\n",
      "Train Epoch: 8 [1920/14723 (13%)]\tLoss: 0.613085\n",
      "Train Epoch: 8 [2560/14723 (17%)]\tLoss: 0.827912\n",
      "Train Epoch: 8 [3200/14723 (22%)]\tLoss: 1.013305\n",
      "Train Epoch: 8 [3840/14723 (26%)]\tLoss: 0.815040\n",
      "Train Epoch: 8 [4480/14723 (30%)]\tLoss: 0.698462\n",
      "Train Epoch: 8 [5120/14723 (35%)]\tLoss: 0.719019\n",
      "Train Epoch: 8 [5760/14723 (39%)]\tLoss: 0.665695\n",
      "Train Epoch: 8 [6400/14723 (43%)]\tLoss: 0.595942\n",
      "Train Epoch: 8 [7040/14723 (48%)]\tLoss: 0.460471\n",
      "Train Epoch: 8 [7680/14723 (52%)]\tLoss: 0.690276\n",
      "Train Epoch: 8 [8320/14723 (56%)]\tLoss: 0.605317\n",
      "Train Epoch: 8 [8960/14723 (61%)]\tLoss: 0.579983\n",
      "Train Epoch: 8 [9600/14723 (65%)]\tLoss: 0.664360\n",
      "Train Epoch: 8 [10240/14723 (69%)]\tLoss: 0.586455\n",
      "Train Epoch: 8 [10880/14723 (74%)]\tLoss: 0.604464\n",
      "Train Epoch: 8 [11520/14723 (78%)]\tLoss: 0.378463\n",
      "Train Epoch: 8 [12160/14723 (82%)]\tLoss: 0.330455\n",
      "Train Epoch: 8 [12800/14723 (87%)]\tLoss: 0.503544\n",
      "Train Epoch: 8 [13440/14723 (91%)]\tLoss: 0.589661\n",
      "Train Epoch: 8 [14080/14723 (95%)]\tLoss: 0.606074\n",
      "Train Epoch: 8 [690/14723 (100%)]\tLoss: 4.255386\n",
      "Train Epoch: 9 [0/14723 (0%)]\tLoss: 0.990812\n",
      "Train Epoch: 9 [640/14723 (4%)]\tLoss: 0.471307\n",
      "Train Epoch: 9 [1280/14723 (9%)]\tLoss: 0.443821\n",
      "Train Epoch: 9 [1920/14723 (13%)]\tLoss: 0.561846\n",
      "Train Epoch: 9 [2560/14723 (17%)]\tLoss: 0.663251\n",
      "Train Epoch: 9 [3200/14723 (22%)]\tLoss: 0.575269\n",
      "Train Epoch: 9 [3840/14723 (26%)]\tLoss: 0.428732\n",
      "Train Epoch: 9 [4480/14723 (30%)]\tLoss: 0.351977\n",
      "Train Epoch: 9 [5120/14723 (35%)]\tLoss: 0.498447\n",
      "Train Epoch: 9 [5760/14723 (39%)]\tLoss: 0.443718\n",
      "Train Epoch: 9 [6400/14723 (43%)]\tLoss: 0.579294\n",
      "Train Epoch: 9 [7040/14723 (48%)]\tLoss: 0.440734\n",
      "Train Epoch: 9 [7680/14723 (52%)]\tLoss: 0.404535\n",
      "Train Epoch: 9 [8320/14723 (56%)]\tLoss: 0.544857\n",
      "Train Epoch: 9 [8960/14723 (61%)]\tLoss: 0.581963\n",
      "Train Epoch: 9 [9600/14723 (65%)]\tLoss: 0.317728\n",
      "Train Epoch: 9 [10240/14723 (69%)]\tLoss: 0.322999\n",
      "Train Epoch: 9 [10880/14723 (74%)]\tLoss: 0.275439\n",
      "Train Epoch: 9 [11520/14723 (78%)]\tLoss: 0.396705\n",
      "Train Epoch: 9 [12160/14723 (82%)]\tLoss: 0.406402\n",
      "Train Epoch: 9 [12800/14723 (87%)]\tLoss: 0.457602\n",
      "Train Epoch: 9 [13440/14723 (91%)]\tLoss: 0.388555\n",
      "Train Epoch: 9 [14080/14723 (95%)]\tLoss: 0.442696\n",
      "Train Epoch: 9 [690/14723 (100%)]\tLoss: 3.952520\n",
      "Train Epoch: 10 [0/14723 (0%)]\tLoss: 1.097614\n",
      "Train Epoch: 10 [640/14723 (4%)]\tLoss: 1.035450\n",
      "Train Epoch: 10 [1280/14723 (9%)]\tLoss: 1.248658\n",
      "Train Epoch: 10 [1920/14723 (13%)]\tLoss: 0.733031\n",
      "Train Epoch: 10 [2560/14723 (17%)]\tLoss: 0.913504\n",
      "Train Epoch: 10 [3200/14723 (22%)]\tLoss: 0.899847\n",
      "Train Epoch: 10 [3840/14723 (26%)]\tLoss: 0.953437\n",
      "Train Epoch: 10 [4480/14723 (30%)]\tLoss: 0.836337\n",
      "Train Epoch: 10 [5120/14723 (35%)]\tLoss: 0.762613\n",
      "Train Epoch: 10 [5760/14723 (39%)]\tLoss: 0.697315\n",
      "Train Epoch: 10 [6400/14723 (43%)]\tLoss: 0.742676\n",
      "Train Epoch: 10 [7040/14723 (48%)]\tLoss: 0.906657\n",
      "Train Epoch: 10 [7680/14723 (52%)]\tLoss: 0.479072\n",
      "Train Epoch: 10 [8320/14723 (56%)]\tLoss: 0.584748\n",
      "Train Epoch: 10 [8960/14723 (61%)]\tLoss: 0.665760\n",
      "Train Epoch: 10 [9600/14723 (65%)]\tLoss: 0.593510\n",
      "Train Epoch: 10 [10240/14723 (69%)]\tLoss: 0.494761\n",
      "Train Epoch: 10 [10880/14723 (74%)]\tLoss: 0.485646\n",
      "Train Epoch: 10 [11520/14723 (78%)]\tLoss: 0.437284\n",
      "Train Epoch: 10 [12160/14723 (82%)]\tLoss: 0.442223\n",
      "Train Epoch: 10 [12800/14723 (87%)]\tLoss: 0.432117\n",
      "Train Epoch: 10 [13440/14723 (91%)]\tLoss: 0.298096\n",
      "Train Epoch: 10 [14080/14723 (95%)]\tLoss: 0.362895\n",
      "Train Epoch: 10 [690/14723 (100%)]\tLoss: 0.169393\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/7654 (0%)]\tLoss: 1.893641\n",
      "Train Epoch: 1 [640/7654 (8%)]\tLoss: 0.527441\n",
      "Train Epoch: 1 [1280/7654 (17%)]\tLoss: 0.438468\n",
      "Train Epoch: 1 [1920/7654 (25%)]\tLoss: 0.340396\n",
      "Train Epoch: 1 [2560/7654 (33%)]\tLoss: 0.224356\n",
      "Train Epoch: 1 [3200/7654 (42%)]\tLoss: 0.603623\n",
      "Train Epoch: 1 [3840/7654 (50%)]\tLoss: 0.320392\n",
      "Train Epoch: 1 [4480/7654 (58%)]\tLoss: 0.448479\n",
      "Train Epoch: 1 [5120/7654 (67%)]\tLoss: 0.238790\n",
      "Train Epoch: 1 [5760/7654 (75%)]\tLoss: 0.239665\n",
      "Train Epoch: 1 [6400/7654 (83%)]\tLoss: 0.310379\n",
      "Train Epoch: 1 [7040/7654 (92%)]\tLoss: 0.564086\n",
      "Train Epoch: 2 [0/7654 (0%)]\tLoss: 0.147656\n",
      "Train Epoch: 2 [640/7654 (8%)]\tLoss: 0.108161\n",
      "Train Epoch: 2 [1280/7654 (17%)]\tLoss: 0.038778\n",
      "Train Epoch: 2 [1920/7654 (25%)]\tLoss: 0.126229\n",
      "Train Epoch: 2 [2560/7654 (33%)]\tLoss: 0.126571\n",
      "Train Epoch: 2 [3200/7654 (42%)]\tLoss: 0.055892\n",
      "Train Epoch: 2 [3840/7654 (50%)]\tLoss: 0.158779\n",
      "Train Epoch: 2 [4480/7654 (58%)]\tLoss: 0.025406\n",
      "Train Epoch: 2 [5120/7654 (67%)]\tLoss: 0.062273\n",
      "Train Epoch: 2 [5760/7654 (75%)]\tLoss: 0.142904\n",
      "Train Epoch: 2 [6400/7654 (83%)]\tLoss: 0.095899\n",
      "Train Epoch: 2 [7040/7654 (92%)]\tLoss: 0.178692\n",
      "Train Epoch: 3 [0/7654 (0%)]\tLoss: 0.058541\n",
      "Train Epoch: 3 [640/7654 (8%)]\tLoss: 0.079962\n",
      "Train Epoch: 3 [1280/7654 (17%)]\tLoss: 0.061164\n",
      "Train Epoch: 3 [1920/7654 (25%)]\tLoss: 0.081057\n",
      "Train Epoch: 3 [2560/7654 (33%)]\tLoss: 0.025091\n",
      "Train Epoch: 3 [3200/7654 (42%)]\tLoss: 0.023253\n",
      "Train Epoch: 3 [3840/7654 (50%)]\tLoss: 0.038505\n",
      "Train Epoch: 3 [4480/7654 (58%)]\tLoss: 0.073930\n",
      "Train Epoch: 3 [5120/7654 (67%)]\tLoss: 0.054470\n",
      "Train Epoch: 3 [5760/7654 (75%)]\tLoss: 0.084361\n",
      "Train Epoch: 3 [6400/7654 (83%)]\tLoss: 0.034316\n",
      "Train Epoch: 3 [7040/7654 (92%)]\tLoss: 0.028644\n",
      "Train Epoch: 4 [0/7654 (0%)]\tLoss: 0.066429\n",
      "Train Epoch: 4 [640/7654 (8%)]\tLoss: 0.011371\n",
      "Train Epoch: 4 [1280/7654 (17%)]\tLoss: 0.038060\n",
      "Train Epoch: 4 [1920/7654 (25%)]\tLoss: 0.027199\n",
      "Train Epoch: 4 [2560/7654 (33%)]\tLoss: 0.033564\n",
      "Train Epoch: 4 [3200/7654 (42%)]\tLoss: 0.026798\n",
      "Train Epoch: 4 [3840/7654 (50%)]\tLoss: 0.053597\n",
      "Train Epoch: 4 [4480/7654 (58%)]\tLoss: 0.039664\n",
      "Train Epoch: 4 [5120/7654 (67%)]\tLoss: 0.068776\n",
      "Train Epoch: 4 [5760/7654 (75%)]\tLoss: 0.002651\n",
      "Train Epoch: 4 [6400/7654 (83%)]\tLoss: 0.044461\n",
      "Train Epoch: 4 [7040/7654 (92%)]\tLoss: 0.046764\n",
      "Train Epoch: 5 [0/7654 (0%)]\tLoss: 0.079356\n",
      "Train Epoch: 5 [640/7654 (8%)]\tLoss: 0.032067\n",
      "Train Epoch: 5 [1280/7654 (17%)]\tLoss: 0.016511\n",
      "Train Epoch: 5 [1920/7654 (25%)]\tLoss: 0.005884\n",
      "Train Epoch: 5 [2560/7654 (33%)]\tLoss: 0.012007\n",
      "Train Epoch: 5 [3200/7654 (42%)]\tLoss: 0.034422\n",
      "Train Epoch: 5 [3840/7654 (50%)]\tLoss: 0.061132\n",
      "Train Epoch: 5 [4480/7654 (58%)]\tLoss: 0.020195\n",
      "Train Epoch: 5 [5120/7654 (67%)]\tLoss: 0.025690\n",
      "Train Epoch: 5 [5760/7654 (75%)]\tLoss: 0.009992\n",
      "Train Epoch: 5 [6400/7654 (83%)]\tLoss: 0.045192\n",
      "Train Epoch: 5 [7040/7654 (92%)]\tLoss: 0.068335\n",
      "Train Epoch: 6 [0/7654 (0%)]\tLoss: 0.051968\n",
      "Train Epoch: 6 [640/7654 (8%)]\tLoss: 0.002805\n",
      "Train Epoch: 6 [1280/7654 (17%)]\tLoss: 0.016376\n",
      "Train Epoch: 6 [1920/7654 (25%)]\tLoss: 0.007407\n",
      "Train Epoch: 6 [2560/7654 (33%)]\tLoss: 0.014826\n",
      "Train Epoch: 6 [3200/7654 (42%)]\tLoss: 0.123891\n",
      "Train Epoch: 6 [3840/7654 (50%)]\tLoss: 0.010413\n",
      "Train Epoch: 6 [4480/7654 (58%)]\tLoss: 0.036166\n",
      "Train Epoch: 6 [5120/7654 (67%)]\tLoss: 0.028259\n",
      "Train Epoch: 6 [5760/7654 (75%)]\tLoss: 0.022486\n",
      "Train Epoch: 6 [6400/7654 (83%)]\tLoss: 0.026679\n",
      "Train Epoch: 6 [7040/7654 (92%)]\tLoss: 0.060818\n",
      "Train Epoch: 7 [0/7654 (0%)]\tLoss: 0.031432\n",
      "Train Epoch: 7 [640/7654 (8%)]\tLoss: 0.011608\n",
      "Train Epoch: 7 [1280/7654 (17%)]\tLoss: 0.005632\n",
      "Train Epoch: 7 [1920/7654 (25%)]\tLoss: 0.012079\n",
      "Train Epoch: 7 [2560/7654 (33%)]\tLoss: 0.005698\n",
      "Train Epoch: 7 [3200/7654 (42%)]\tLoss: 0.005565\n",
      "Train Epoch: 7 [3840/7654 (50%)]\tLoss: 0.024015\n",
      "Train Epoch: 7 [4480/7654 (58%)]\tLoss: 0.017647\n",
      "Train Epoch: 7 [5120/7654 (67%)]\tLoss: 0.026794\n",
      "Train Epoch: 7 [5760/7654 (75%)]\tLoss: 0.005597\n",
      "Train Epoch: 7 [6400/7654 (83%)]\tLoss: 0.001971\n",
      "Train Epoch: 7 [7040/7654 (92%)]\tLoss: 0.132558\n",
      "Train Epoch: 8 [0/7654 (0%)]\tLoss: 0.022402\n",
      "Train Epoch: 8 [640/7654 (8%)]\tLoss: 0.009525\n",
      "Train Epoch: 8 [1280/7654 (17%)]\tLoss: 0.011375\n",
      "Train Epoch: 8 [1920/7654 (25%)]\tLoss: 0.001936\n",
      "Train Epoch: 8 [2560/7654 (33%)]\tLoss: 0.085604\n",
      "Train Epoch: 8 [3200/7654 (42%)]\tLoss: 0.013356\n",
      "Train Epoch: 8 [3840/7654 (50%)]\tLoss: 0.036674\n",
      "Train Epoch: 8 [4480/7654 (58%)]\tLoss: 0.024787\n",
      "Train Epoch: 8 [5120/7654 (67%)]\tLoss: 0.020602\n",
      "Train Epoch: 8 [5760/7654 (75%)]\tLoss: 0.085405\n",
      "Train Epoch: 8 [6400/7654 (83%)]\tLoss: 0.014982\n",
      "Train Epoch: 8 [7040/7654 (92%)]\tLoss: 0.022271\n",
      "Train Epoch: 9 [0/7654 (0%)]\tLoss: 0.003663\n",
      "Train Epoch: 9 [640/7654 (8%)]\tLoss: 0.003896\n",
      "Train Epoch: 9 [1280/7654 (17%)]\tLoss: 0.007127\n",
      "Train Epoch: 9 [1920/7654 (25%)]\tLoss: 0.009393\n",
      "Train Epoch: 9 [2560/7654 (33%)]\tLoss: 0.005697\n",
      "Train Epoch: 9 [3200/7654 (42%)]\tLoss: 0.015414\n",
      "Train Epoch: 9 [3840/7654 (50%)]\tLoss: 0.008082\n",
      "Train Epoch: 9 [4480/7654 (58%)]\tLoss: 0.026404\n",
      "Train Epoch: 9 [5120/7654 (67%)]\tLoss: 0.011530\n",
      "Train Epoch: 9 [5760/7654 (75%)]\tLoss: 0.009863\n",
      "Train Epoch: 9 [6400/7654 (83%)]\tLoss: 0.068032\n",
      "Train Epoch: 9 [7040/7654 (92%)]\tLoss: 0.011499\n",
      "Train Epoch: 10 [0/7654 (0%)]\tLoss: 0.003679\n",
      "Train Epoch: 10 [640/7654 (8%)]\tLoss: 0.003605\n",
      "Train Epoch: 10 [1280/7654 (17%)]\tLoss: 0.001620\n",
      "Train Epoch: 10 [1920/7654 (25%)]\tLoss: 0.051336\n",
      "Train Epoch: 10 [2560/7654 (33%)]\tLoss: 0.057207\n",
      "Train Epoch: 10 [3200/7654 (42%)]\tLoss: 0.243452\n",
      "Train Epoch: 10 [3840/7654 (50%)]\tLoss: 0.047264\n",
      "Train Epoch: 10 [4480/7654 (58%)]\tLoss: 0.008587\n",
      "Train Epoch: 10 [5120/7654 (67%)]\tLoss: 0.041538\n",
      "Train Epoch: 10 [5760/7654 (75%)]\tLoss: 0.006370\n",
      "Train Epoch: 10 [6400/7654 (83%)]\tLoss: 0.033072\n",
      "Train Epoch: 10 [7040/7654 (92%)]\tLoss: 0.064279\n",
      "after training[ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")]\n",
      "after fedaveraging[ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")]\n",
      "local_models in the distribute function [ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")]\n",
      "4\n",
      "local_models in the distribute function [ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 1.9541, Accuracy: 4343/10000 (43%)\n",
      "\n",
      "Round 3/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/18580 (0%)]\tLoss: 1.156487\n",
      "Train Epoch: 1 [640/18580 (3%)]\tLoss: 0.378906\n",
      "Train Epoch: 1 [1280/18580 (7%)]\tLoss: 0.281001\n",
      "Train Epoch: 1 [1920/18580 (10%)]\tLoss: 0.234678\n",
      "Train Epoch: 1 [2560/18580 (14%)]\tLoss: 0.333762\n",
      "Train Epoch: 1 [3200/18580 (17%)]\tLoss: 0.307600\n",
      "Train Epoch: 1 [3840/18580 (21%)]\tLoss: 0.505316\n",
      "Train Epoch: 1 [4480/18580 (24%)]\tLoss: 0.271708\n",
      "Train Epoch: 1 [5120/18580 (27%)]\tLoss: 0.244856\n",
      "Train Epoch: 1 [5760/18580 (31%)]\tLoss: 0.492429\n",
      "Train Epoch: 1 [6400/18580 (34%)]\tLoss: 0.207695\n",
      "Train Epoch: 1 [7040/18580 (38%)]\tLoss: 0.346668\n",
      "Train Epoch: 1 [7680/18580 (41%)]\tLoss: 0.433131\n",
      "Train Epoch: 1 [8320/18580 (45%)]\tLoss: 0.200947\n",
      "Train Epoch: 1 [8960/18580 (48%)]\tLoss: 0.295318\n",
      "Train Epoch: 1 [9600/18580 (52%)]\tLoss: 0.352334\n",
      "Train Epoch: 1 [10240/18580 (55%)]\tLoss: 0.426177\n",
      "Train Epoch: 1 [10880/18580 (58%)]\tLoss: 0.311371\n",
      "Train Epoch: 1 [11520/18580 (62%)]\tLoss: 0.405655\n",
      "Train Epoch: 1 [12160/18580 (65%)]\tLoss: 0.178541\n",
      "Train Epoch: 1 [12800/18580 (69%)]\tLoss: 0.338292\n",
      "Train Epoch: 1 [13440/18580 (72%)]\tLoss: 0.317255\n",
      "Train Epoch: 1 [14080/18580 (76%)]\tLoss: 0.388144\n",
      "Train Epoch: 1 [14720/18580 (79%)]\tLoss: 0.259515\n",
      "Train Epoch: 1 [15360/18580 (82%)]\tLoss: 0.219314\n",
      "Train Epoch: 1 [16000/18580 (86%)]\tLoss: 0.343115\n",
      "Train Epoch: 1 [16640/18580 (89%)]\tLoss: 0.326283\n",
      "Train Epoch: 1 [17280/18580 (93%)]\tLoss: 0.454617\n",
      "Train Epoch: 1 [17920/18580 (96%)]\tLoss: 0.273799\n",
      "Train Epoch: 1 [5800/18580 (100%)]\tLoss: 0.509750\n",
      "Train Epoch: 2 [0/18580 (0%)]\tLoss: 0.090583\n",
      "Train Epoch: 2 [640/18580 (3%)]\tLoss: 0.182456\n",
      "Train Epoch: 2 [1280/18580 (7%)]\tLoss: 0.237919\n",
      "Train Epoch: 2 [1920/18580 (10%)]\tLoss: 0.088584\n",
      "Train Epoch: 2 [2560/18580 (14%)]\tLoss: 0.135548\n",
      "Train Epoch: 2 [3200/18580 (17%)]\tLoss: 0.137090\n",
      "Train Epoch: 2 [3840/18580 (21%)]\tLoss: 0.036182\n",
      "Train Epoch: 2 [4480/18580 (24%)]\tLoss: 0.342618\n",
      "Train Epoch: 2 [5120/18580 (27%)]\tLoss: 0.142302\n",
      "Train Epoch: 2 [5760/18580 (31%)]\tLoss: 0.141781\n",
      "Train Epoch: 2 [6400/18580 (34%)]\tLoss: 0.135836\n",
      "Train Epoch: 2 [7040/18580 (38%)]\tLoss: 0.236670\n",
      "Train Epoch: 2 [7680/18580 (41%)]\tLoss: 0.068805\n",
      "Train Epoch: 2 [8320/18580 (45%)]\tLoss: 0.157544\n",
      "Train Epoch: 2 [8960/18580 (48%)]\tLoss: 0.137884\n",
      "Train Epoch: 2 [9600/18580 (52%)]\tLoss: 0.180852\n",
      "Train Epoch: 2 [10240/18580 (55%)]\tLoss: 0.058296\n",
      "Train Epoch: 2 [10880/18580 (58%)]\tLoss: 0.124732\n",
      "Train Epoch: 2 [11520/18580 (62%)]\tLoss: 0.082805\n",
      "Train Epoch: 2 [12160/18580 (65%)]\tLoss: 0.193947\n",
      "Train Epoch: 2 [12800/18580 (69%)]\tLoss: 0.098571\n",
      "Train Epoch: 2 [13440/18580 (72%)]\tLoss: 0.153703\n",
      "Train Epoch: 2 [14080/18580 (76%)]\tLoss: 0.068157\n",
      "Train Epoch: 2 [14720/18580 (79%)]\tLoss: 0.201965\n",
      "Train Epoch: 2 [15360/18580 (82%)]\tLoss: 0.156188\n",
      "Train Epoch: 2 [16000/18580 (86%)]\tLoss: 0.080385\n",
      "Train Epoch: 2 [16640/18580 (89%)]\tLoss: 0.234860\n",
      "Train Epoch: 2 [17280/18580 (93%)]\tLoss: 0.109203\n",
      "Train Epoch: 2 [17920/18580 (96%)]\tLoss: 0.307130\n",
      "Train Epoch: 2 [5800/18580 (100%)]\tLoss: 0.289009\n",
      "Train Epoch: 3 [0/18580 (0%)]\tLoss: 0.056755\n",
      "Train Epoch: 3 [640/18580 (3%)]\tLoss: 0.099523\n",
      "Train Epoch: 3 [1280/18580 (7%)]\tLoss: 0.161841\n",
      "Train Epoch: 3 [1920/18580 (10%)]\tLoss: 0.047162\n",
      "Train Epoch: 3 [2560/18580 (14%)]\tLoss: 0.094827\n",
      "Train Epoch: 3 [3200/18580 (17%)]\tLoss: 0.139211\n",
      "Train Epoch: 3 [3840/18580 (21%)]\tLoss: 0.074946\n",
      "Train Epoch: 3 [4480/18580 (24%)]\tLoss: 0.143587\n",
      "Train Epoch: 3 [5120/18580 (27%)]\tLoss: 0.054330\n",
      "Train Epoch: 3 [5760/18580 (31%)]\tLoss: 0.243977\n",
      "Train Epoch: 3 [6400/18580 (34%)]\tLoss: 0.203603\n",
      "Train Epoch: 3 [7040/18580 (38%)]\tLoss: 0.085787\n",
      "Train Epoch: 3 [7680/18580 (41%)]\tLoss: 0.099903\n",
      "Train Epoch: 3 [8320/18580 (45%)]\tLoss: 0.184012\n",
      "Train Epoch: 3 [8960/18580 (48%)]\tLoss: 0.039254\n",
      "Train Epoch: 3 [9600/18580 (52%)]\tLoss: 0.106285\n",
      "Train Epoch: 3 [10240/18580 (55%)]\tLoss: 0.049292\n",
      "Train Epoch: 3 [10880/18580 (58%)]\tLoss: 0.087495\n",
      "Train Epoch: 3 [11520/18580 (62%)]\tLoss: 0.076556\n",
      "Train Epoch: 3 [12160/18580 (65%)]\tLoss: 0.162369\n",
      "Train Epoch: 3 [12800/18580 (69%)]\tLoss: 0.072602\n",
      "Train Epoch: 3 [13440/18580 (72%)]\tLoss: 0.060430\n",
      "Train Epoch: 3 [14080/18580 (76%)]\tLoss: 0.047555\n",
      "Train Epoch: 3 [14720/18580 (79%)]\tLoss: 0.038189\n",
      "Train Epoch: 3 [15360/18580 (82%)]\tLoss: 0.029944\n",
      "Train Epoch: 3 [16000/18580 (86%)]\tLoss: 0.071018\n",
      "Train Epoch: 3 [16640/18580 (89%)]\tLoss: 0.118602\n",
      "Train Epoch: 3 [17280/18580 (93%)]\tLoss: 0.075096\n",
      "Train Epoch: 3 [17920/18580 (96%)]\tLoss: 0.179386\n",
      "Train Epoch: 3 [5800/18580 (100%)]\tLoss: 0.524843\n",
      "Train Epoch: 4 [0/18580 (0%)]\tLoss: 0.039733\n",
      "Train Epoch: 4 [640/18580 (3%)]\tLoss: 0.058222\n",
      "Train Epoch: 4 [1280/18580 (7%)]\tLoss: 0.040475\n",
      "Train Epoch: 4 [1920/18580 (10%)]\tLoss: 0.030530\n",
      "Train Epoch: 4 [2560/18580 (14%)]\tLoss: 0.066953\n",
      "Train Epoch: 4 [3200/18580 (17%)]\tLoss: 0.050181\n",
      "Train Epoch: 4 [3840/18580 (21%)]\tLoss: 0.158858\n",
      "Train Epoch: 4 [4480/18580 (24%)]\tLoss: 0.067894\n",
      "Train Epoch: 4 [5120/18580 (27%)]\tLoss: 0.049551\n",
      "Train Epoch: 4 [5760/18580 (31%)]\tLoss: 0.035088\n",
      "Train Epoch: 4 [6400/18580 (34%)]\tLoss: 0.105080\n",
      "Train Epoch: 4 [7040/18580 (38%)]\tLoss: 0.122910\n",
      "Train Epoch: 4 [7680/18580 (41%)]\tLoss: 0.016265\n",
      "Train Epoch: 4 [8320/18580 (45%)]\tLoss: 0.022047\n",
      "Train Epoch: 4 [8960/18580 (48%)]\tLoss: 0.073779\n",
      "Train Epoch: 4 [9600/18580 (52%)]\tLoss: 0.035317\n",
      "Train Epoch: 4 [10240/18580 (55%)]\tLoss: 0.072278\n",
      "Train Epoch: 4 [10880/18580 (58%)]\tLoss: 0.039840\n",
      "Train Epoch: 4 [11520/18580 (62%)]\tLoss: 0.167999\n",
      "Train Epoch: 4 [12160/18580 (65%)]\tLoss: 0.057242\n",
      "Train Epoch: 4 [12800/18580 (69%)]\tLoss: 0.061375\n",
      "Train Epoch: 4 [13440/18580 (72%)]\tLoss: 0.164168\n",
      "Train Epoch: 4 [14080/18580 (76%)]\tLoss: 0.102910\n",
      "Train Epoch: 4 [14720/18580 (79%)]\tLoss: 0.123873\n",
      "Train Epoch: 4 [15360/18580 (82%)]\tLoss: 0.064099\n",
      "Train Epoch: 4 [16000/18580 (86%)]\tLoss: 0.108022\n",
      "Train Epoch: 4 [16640/18580 (89%)]\tLoss: 0.036352\n",
      "Train Epoch: 4 [17280/18580 (93%)]\tLoss: 0.078569\n",
      "Train Epoch: 4 [17920/18580 (96%)]\tLoss: 0.036908\n",
      "Train Epoch: 4 [5800/18580 (100%)]\tLoss: 0.713846\n",
      "Train Epoch: 5 [0/18580 (0%)]\tLoss: 0.117734\n",
      "Train Epoch: 5 [640/18580 (3%)]\tLoss: 0.119470\n",
      "Train Epoch: 5 [1280/18580 (7%)]\tLoss: 0.057024\n",
      "Train Epoch: 5 [1920/18580 (10%)]\tLoss: 0.154773\n",
      "Train Epoch: 5 [2560/18580 (14%)]\tLoss: 0.113752\n",
      "Train Epoch: 5 [3200/18580 (17%)]\tLoss: 0.265177\n",
      "Train Epoch: 5 [3840/18580 (21%)]\tLoss: 0.143328\n",
      "Train Epoch: 5 [4480/18580 (24%)]\tLoss: 0.031578\n",
      "Train Epoch: 5 [5120/18580 (27%)]\tLoss: 0.056100\n",
      "Train Epoch: 5 [5760/18580 (31%)]\tLoss: 0.126508\n",
      "Train Epoch: 5 [6400/18580 (34%)]\tLoss: 0.030675\n",
      "Train Epoch: 5 [7040/18580 (38%)]\tLoss: 0.079632\n",
      "Train Epoch: 5 [7680/18580 (41%)]\tLoss: 0.071567\n",
      "Train Epoch: 5 [8320/18580 (45%)]\tLoss: 0.266345\n",
      "Train Epoch: 5 [8960/18580 (48%)]\tLoss: 0.067646\n",
      "Train Epoch: 5 [9600/18580 (52%)]\tLoss: 0.034311\n",
      "Train Epoch: 5 [10240/18580 (55%)]\tLoss: 0.030172\n",
      "Train Epoch: 5 [10880/18580 (58%)]\tLoss: 0.056622\n",
      "Train Epoch: 5 [11520/18580 (62%)]\tLoss: 0.051591\n",
      "Train Epoch: 5 [12160/18580 (65%)]\tLoss: 0.109813\n",
      "Train Epoch: 5 [12800/18580 (69%)]\tLoss: 0.049175\n",
      "Train Epoch: 5 [13440/18580 (72%)]\tLoss: 0.052278\n",
      "Train Epoch: 5 [14080/18580 (76%)]\tLoss: 0.161691\n",
      "Train Epoch: 5 [14720/18580 (79%)]\tLoss: 0.091423\n",
      "Train Epoch: 5 [15360/18580 (82%)]\tLoss: 0.074649\n",
      "Train Epoch: 5 [16000/18580 (86%)]\tLoss: 0.022851\n",
      "Train Epoch: 5 [16640/18580 (89%)]\tLoss: 0.040474\n",
      "Train Epoch: 5 [17280/18580 (93%)]\tLoss: 0.056617\n",
      "Train Epoch: 5 [17920/18580 (96%)]\tLoss: 0.155420\n",
      "Train Epoch: 5 [5800/18580 (100%)]\tLoss: 0.141418\n",
      "Train Epoch: 6 [0/18580 (0%)]\tLoss: 0.029938\n",
      "Train Epoch: 6 [640/18580 (3%)]\tLoss: 0.068013\n",
      "Train Epoch: 6 [1280/18580 (7%)]\tLoss: 0.062767\n",
      "Train Epoch: 6 [1920/18580 (10%)]\tLoss: 0.015313\n",
      "Train Epoch: 6 [2560/18580 (14%)]\tLoss: 0.071711\n",
      "Train Epoch: 6 [3200/18580 (17%)]\tLoss: 0.007514\n",
      "Train Epoch: 6 [3840/18580 (21%)]\tLoss: 0.170638\n",
      "Train Epoch: 6 [4480/18580 (24%)]\tLoss: 0.168862\n",
      "Train Epoch: 6 [5120/18580 (27%)]\tLoss: 0.045445\n",
      "Train Epoch: 6 [5760/18580 (31%)]\tLoss: 0.035429\n",
      "Train Epoch: 6 [6400/18580 (34%)]\tLoss: 0.061779\n",
      "Train Epoch: 6 [7040/18580 (38%)]\tLoss: 0.216143\n",
      "Train Epoch: 6 [7680/18580 (41%)]\tLoss: 0.025702\n",
      "Train Epoch: 6 [8320/18580 (45%)]\tLoss: 0.074668\n",
      "Train Epoch: 6 [8960/18580 (48%)]\tLoss: 0.086755\n",
      "Train Epoch: 6 [9600/18580 (52%)]\tLoss: 0.047277\n",
      "Train Epoch: 6 [10240/18580 (55%)]\tLoss: 0.102681\n",
      "Train Epoch: 6 [10880/18580 (58%)]\tLoss: 0.043026\n",
      "Train Epoch: 6 [11520/18580 (62%)]\tLoss: 0.045934\n",
      "Train Epoch: 6 [12160/18580 (65%)]\tLoss: 0.008859\n",
      "Train Epoch: 6 [12800/18580 (69%)]\tLoss: 0.157653\n",
      "Train Epoch: 6 [13440/18580 (72%)]\tLoss: 0.037859\n",
      "Train Epoch: 6 [14080/18580 (76%)]\tLoss: 0.071135\n",
      "Train Epoch: 6 [14720/18580 (79%)]\tLoss: 0.111314\n",
      "Train Epoch: 6 [15360/18580 (82%)]\tLoss: 0.016600\n",
      "Train Epoch: 6 [16000/18580 (86%)]\tLoss: 0.040376\n",
      "Train Epoch: 6 [16640/18580 (89%)]\tLoss: 0.034344\n",
      "Train Epoch: 6 [17280/18580 (93%)]\tLoss: 0.055276\n",
      "Train Epoch: 6 [17920/18580 (96%)]\tLoss: 0.027811\n",
      "Train Epoch: 6 [5800/18580 (100%)]\tLoss: 0.287077\n",
      "Train Epoch: 7 [0/18580 (0%)]\tLoss: 0.068981\n",
      "Train Epoch: 7 [640/18580 (3%)]\tLoss: 0.161384\n",
      "Train Epoch: 7 [1280/18580 (7%)]\tLoss: 0.054696\n",
      "Train Epoch: 7 [1920/18580 (10%)]\tLoss: 0.023696\n",
      "Train Epoch: 7 [2560/18580 (14%)]\tLoss: 0.043811\n",
      "Train Epoch: 7 [3200/18580 (17%)]\tLoss: 0.081250\n",
      "Train Epoch: 7 [3840/18580 (21%)]\tLoss: 0.091527\n",
      "Train Epoch: 7 [4480/18580 (24%)]\tLoss: 0.193651\n",
      "Train Epoch: 7 [5120/18580 (27%)]\tLoss: 0.063850\n",
      "Train Epoch: 7 [5760/18580 (31%)]\tLoss: 0.028054\n",
      "Train Epoch: 7 [6400/18580 (34%)]\tLoss: 0.039664\n",
      "Train Epoch: 7 [7040/18580 (38%)]\tLoss: 0.119003\n",
      "Train Epoch: 7 [7680/18580 (41%)]\tLoss: 0.059710\n",
      "Train Epoch: 7 [8320/18580 (45%)]\tLoss: 0.029833\n",
      "Train Epoch: 7 [8960/18580 (48%)]\tLoss: 0.081162\n",
      "Train Epoch: 7 [9600/18580 (52%)]\tLoss: 0.031560\n",
      "Train Epoch: 7 [10240/18580 (55%)]\tLoss: 0.037798\n",
      "Train Epoch: 7 [10880/18580 (58%)]\tLoss: 0.018655\n",
      "Train Epoch: 7 [11520/18580 (62%)]\tLoss: 0.078279\n",
      "Train Epoch: 7 [12160/18580 (65%)]\tLoss: 0.054612\n",
      "Train Epoch: 7 [12800/18580 (69%)]\tLoss: 0.102346\n",
      "Train Epoch: 7 [13440/18580 (72%)]\tLoss: 0.049009\n",
      "Train Epoch: 7 [14080/18580 (76%)]\tLoss: 0.031648\n",
      "Train Epoch: 7 [14720/18580 (79%)]\tLoss: 0.056622\n",
      "Train Epoch: 7 [15360/18580 (82%)]\tLoss: 0.007806\n",
      "Train Epoch: 7 [16000/18580 (86%)]\tLoss: 0.112396\n",
      "Train Epoch: 7 [16640/18580 (89%)]\tLoss: 0.023998\n",
      "Train Epoch: 7 [17280/18580 (93%)]\tLoss: 0.051854\n",
      "Train Epoch: 7 [17920/18580 (96%)]\tLoss: 0.021533\n",
      "Train Epoch: 7 [5800/18580 (100%)]\tLoss: 0.651191\n",
      "Train Epoch: 8 [0/18580 (0%)]\tLoss: 0.176292\n",
      "Train Epoch: 8 [640/18580 (3%)]\tLoss: 0.046920\n",
      "Train Epoch: 8 [1280/18580 (7%)]\tLoss: 0.021393\n",
      "Train Epoch: 8 [1920/18580 (10%)]\tLoss: 0.113179\n",
      "Train Epoch: 8 [2560/18580 (14%)]\tLoss: 0.083289\n",
      "Train Epoch: 8 [3200/18580 (17%)]\tLoss: 0.003738\n",
      "Train Epoch: 8 [3840/18580 (21%)]\tLoss: 0.009934\n",
      "Train Epoch: 8 [4480/18580 (24%)]\tLoss: 0.048431\n",
      "Train Epoch: 8 [5120/18580 (27%)]\tLoss: 0.022795\n",
      "Train Epoch: 8 [5760/18580 (31%)]\tLoss: 0.016059\n",
      "Train Epoch: 8 [6400/18580 (34%)]\tLoss: 0.074993\n",
      "Train Epoch: 8 [7040/18580 (38%)]\tLoss: 0.165136\n",
      "Train Epoch: 8 [7680/18580 (41%)]\tLoss: 0.056690\n",
      "Train Epoch: 8 [8320/18580 (45%)]\tLoss: 0.105288\n",
      "Train Epoch: 8 [8960/18580 (48%)]\tLoss: 0.065186\n",
      "Train Epoch: 8 [9600/18580 (52%)]\tLoss: 0.167741\n",
      "Train Epoch: 8 [10240/18580 (55%)]\tLoss: 0.015002\n",
      "Train Epoch: 8 [10880/18580 (58%)]\tLoss: 0.004869\n",
      "Train Epoch: 8 [11520/18580 (62%)]\tLoss: 0.064924\n",
      "Train Epoch: 8 [12160/18580 (65%)]\tLoss: 0.079680\n",
      "Train Epoch: 8 [12800/18580 (69%)]\tLoss: 0.090307\n",
      "Train Epoch: 8 [13440/18580 (72%)]\tLoss: 0.041187\n",
      "Train Epoch: 8 [14080/18580 (76%)]\tLoss: 0.092824\n",
      "Train Epoch: 8 [14720/18580 (79%)]\tLoss: 0.055010\n",
      "Train Epoch: 8 [15360/18580 (82%)]\tLoss: 0.007743\n",
      "Train Epoch: 8 [16000/18580 (86%)]\tLoss: 0.036755\n",
      "Train Epoch: 8 [16640/18580 (89%)]\tLoss: 0.035418\n",
      "Train Epoch: 8 [17280/18580 (93%)]\tLoss: 0.070680\n",
      "Train Epoch: 8 [17920/18580 (96%)]\tLoss: 0.085094\n",
      "Train Epoch: 8 [5800/18580 (100%)]\tLoss: 0.167326\n",
      "Train Epoch: 9 [0/18580 (0%)]\tLoss: 0.013576\n",
      "Train Epoch: 9 [640/18580 (3%)]\tLoss: 0.125536\n",
      "Train Epoch: 9 [1280/18580 (7%)]\tLoss: 0.062116\n",
      "Train Epoch: 9 [1920/18580 (10%)]\tLoss: 0.068381\n",
      "Train Epoch: 9 [2560/18580 (14%)]\tLoss: 0.060342\n",
      "Train Epoch: 9 [3200/18580 (17%)]\tLoss: 0.010166\n",
      "Train Epoch: 9 [3840/18580 (21%)]\tLoss: 0.062986\n",
      "Train Epoch: 9 [4480/18580 (24%)]\tLoss: 0.009952\n",
      "Train Epoch: 9 [5120/18580 (27%)]\tLoss: 0.006542\n",
      "Train Epoch: 9 [5760/18580 (31%)]\tLoss: 0.037189\n",
      "Train Epoch: 9 [6400/18580 (34%)]\tLoss: 0.037215\n",
      "Train Epoch: 9 [7040/18580 (38%)]\tLoss: 0.061246\n",
      "Train Epoch: 9 [7680/18580 (41%)]\tLoss: 0.009380\n",
      "Train Epoch: 9 [8320/18580 (45%)]\tLoss: 0.046692\n",
      "Train Epoch: 9 [8960/18580 (48%)]\tLoss: 0.084363\n",
      "Train Epoch: 9 [9600/18580 (52%)]\tLoss: 0.059289\n",
      "Train Epoch: 9 [10240/18580 (55%)]\tLoss: 0.032128\n",
      "Train Epoch: 9 [10880/18580 (58%)]\tLoss: 0.067393\n",
      "Train Epoch: 9 [11520/18580 (62%)]\tLoss: 0.022735\n",
      "Train Epoch: 9 [12160/18580 (65%)]\tLoss: 0.045400\n",
      "Train Epoch: 9 [12800/18580 (69%)]\tLoss: 0.008884\n",
      "Train Epoch: 9 [13440/18580 (72%)]\tLoss: 0.019107\n",
      "Train Epoch: 9 [14080/18580 (76%)]\tLoss: 0.125280\n",
      "Train Epoch: 9 [14720/18580 (79%)]\tLoss: 0.138574\n",
      "Train Epoch: 9 [15360/18580 (82%)]\tLoss: 0.061678\n",
      "Train Epoch: 9 [16000/18580 (86%)]\tLoss: 0.002449\n",
      "Train Epoch: 9 [16640/18580 (89%)]\tLoss: 0.062058\n",
      "Train Epoch: 9 [17280/18580 (93%)]\tLoss: 0.022216\n",
      "Train Epoch: 9 [17920/18580 (96%)]\tLoss: 0.067227\n",
      "Train Epoch: 9 [5800/18580 (100%)]\tLoss: 0.018972\n",
      "Train Epoch: 10 [0/18580 (0%)]\tLoss: 0.002224\n",
      "Train Epoch: 10 [640/18580 (3%)]\tLoss: 0.042163\n",
      "Train Epoch: 10 [1280/18580 (7%)]\tLoss: 0.022814\n",
      "Train Epoch: 10 [1920/18580 (10%)]\tLoss: 0.061343\n",
      "Train Epoch: 10 [2560/18580 (14%)]\tLoss: 0.042971\n",
      "Train Epoch: 10 [3200/18580 (17%)]\tLoss: 0.006844\n",
      "Train Epoch: 10 [3840/18580 (21%)]\tLoss: 0.050965\n",
      "Train Epoch: 10 [4480/18580 (24%)]\tLoss: 0.068876\n",
      "Train Epoch: 10 [5120/18580 (27%)]\tLoss: 0.102976\n",
      "Train Epoch: 10 [5760/18580 (31%)]\tLoss: 0.078962\n",
      "Train Epoch: 10 [6400/18580 (34%)]\tLoss: 0.062348\n",
      "Train Epoch: 10 [7040/18580 (38%)]\tLoss: 0.006383\n",
      "Train Epoch: 10 [7680/18580 (41%)]\tLoss: 0.088647\n",
      "Train Epoch: 10 [8320/18580 (45%)]\tLoss: 0.018063\n",
      "Train Epoch: 10 [8960/18580 (48%)]\tLoss: 0.123499\n",
      "Train Epoch: 10 [9600/18580 (52%)]\tLoss: 0.002887\n",
      "Train Epoch: 10 [10240/18580 (55%)]\tLoss: 0.036662\n",
      "Train Epoch: 10 [10880/18580 (58%)]\tLoss: 0.013780\n",
      "Train Epoch: 10 [11520/18580 (62%)]\tLoss: 0.007721\n",
      "Train Epoch: 10 [12160/18580 (65%)]\tLoss: 0.060355\n",
      "Train Epoch: 10 [12800/18580 (69%)]\tLoss: 0.044690\n",
      "Train Epoch: 10 [13440/18580 (72%)]\tLoss: 0.009635\n",
      "Train Epoch: 10 [14080/18580 (76%)]\tLoss: 0.014273\n",
      "Train Epoch: 10 [14720/18580 (79%)]\tLoss: 0.012430\n",
      "Train Epoch: 10 [15360/18580 (82%)]\tLoss: 0.013849\n",
      "Train Epoch: 10 [16000/18580 (86%)]\tLoss: 0.032718\n",
      "Train Epoch: 10 [16640/18580 (89%)]\tLoss: 0.035707\n",
      "Train Epoch: 10 [17280/18580 (93%)]\tLoss: 0.056010\n",
      "Train Epoch: 10 [17920/18580 (96%)]\tLoss: 0.049140\n",
      "Train Epoch: 10 [5800/18580 (100%)]\tLoss: 0.095626\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/9043 (0%)]\tLoss: 1.460759\n",
      "Train Epoch: 1 [640/9043 (7%)]\tLoss: 0.388351\n",
      "Train Epoch: 1 [1280/9043 (14%)]\tLoss: 0.511132\n",
      "Train Epoch: 1 [1920/9043 (21%)]\tLoss: 0.341844\n",
      "Train Epoch: 1 [2560/9043 (28%)]\tLoss: 0.487377\n",
      "Train Epoch: 1 [3200/9043 (35%)]\tLoss: 0.401744\n",
      "Train Epoch: 1 [3840/9043 (42%)]\tLoss: 0.332330\n",
      "Train Epoch: 1 [4480/9043 (49%)]\tLoss: 0.538849\n",
      "Train Epoch: 1 [5120/9043 (56%)]\tLoss: 0.402354\n",
      "Train Epoch: 1 [5760/9043 (63%)]\tLoss: 0.322549\n",
      "Train Epoch: 1 [6400/9043 (70%)]\tLoss: 0.440395\n",
      "Train Epoch: 1 [7040/9043 (77%)]\tLoss: 0.495755\n",
      "Train Epoch: 1 [7680/9043 (85%)]\tLoss: 0.291883\n",
      "Train Epoch: 1 [8320/9043 (92%)]\tLoss: 0.206592\n",
      "Train Epoch: 1 [8960/9043 (99%)]\tLoss: 0.302433\n",
      "Train Epoch: 2 [0/9043 (0%)]\tLoss: 0.172636\n",
      "Train Epoch: 2 [640/9043 (7%)]\tLoss: 0.124410\n",
      "Train Epoch: 2 [1280/9043 (14%)]\tLoss: 0.210729\n",
      "Train Epoch: 2 [1920/9043 (21%)]\tLoss: 0.056851\n",
      "Train Epoch: 2 [2560/9043 (28%)]\tLoss: 0.196058\n",
      "Train Epoch: 2 [3200/9043 (35%)]\tLoss: 0.160449\n",
      "Train Epoch: 2 [3840/9043 (42%)]\tLoss: 0.087881\n",
      "Train Epoch: 2 [4480/9043 (49%)]\tLoss: 0.182738\n",
      "Train Epoch: 2 [5120/9043 (56%)]\tLoss: 0.208660\n",
      "Train Epoch: 2 [5760/9043 (63%)]\tLoss: 0.120397\n",
      "Train Epoch: 2 [6400/9043 (70%)]\tLoss: 0.077269\n",
      "Train Epoch: 2 [7040/9043 (77%)]\tLoss: 0.177331\n",
      "Train Epoch: 2 [7680/9043 (85%)]\tLoss: 0.150855\n",
      "Train Epoch: 2 [8320/9043 (92%)]\tLoss: 0.218762\n",
      "Train Epoch: 2 [8960/9043 (99%)]\tLoss: 0.077013\n",
      "Train Epoch: 3 [0/9043 (0%)]\tLoss: 0.034705\n",
      "Train Epoch: 3 [640/9043 (7%)]\tLoss: 0.180021\n",
      "Train Epoch: 3 [1280/9043 (14%)]\tLoss: 0.062685\n",
      "Train Epoch: 3 [1920/9043 (21%)]\tLoss: 0.049554\n",
      "Train Epoch: 3 [2560/9043 (28%)]\tLoss: 0.118683\n",
      "Train Epoch: 3 [3200/9043 (35%)]\tLoss: 0.084008\n",
      "Train Epoch: 3 [3840/9043 (42%)]\tLoss: 0.033973\n",
      "Train Epoch: 3 [4480/9043 (49%)]\tLoss: 0.106955\n",
      "Train Epoch: 3 [5120/9043 (56%)]\tLoss: 0.031936\n",
      "Train Epoch: 3 [5760/9043 (63%)]\tLoss: 0.018712\n",
      "Train Epoch: 3 [6400/9043 (70%)]\tLoss: 0.086812\n",
      "Train Epoch: 3 [7040/9043 (77%)]\tLoss: 0.078065\n",
      "Train Epoch: 3 [7680/9043 (85%)]\tLoss: 0.044512\n",
      "Train Epoch: 3 [8320/9043 (92%)]\tLoss: 0.046103\n",
      "Train Epoch: 3 [8960/9043 (99%)]\tLoss: 0.074990\n",
      "Train Epoch: 4 [0/9043 (0%)]\tLoss: 0.198272\n",
      "Train Epoch: 4 [640/9043 (7%)]\tLoss: 0.013424\n",
      "Train Epoch: 4 [1280/9043 (14%)]\tLoss: 0.028433\n",
      "Train Epoch: 4 [1920/9043 (21%)]\tLoss: 0.144093\n",
      "Train Epoch: 4 [2560/9043 (28%)]\tLoss: 0.081720\n",
      "Train Epoch: 4 [3200/9043 (35%)]\tLoss: 0.105470\n",
      "Train Epoch: 4 [3840/9043 (42%)]\tLoss: 0.109848\n",
      "Train Epoch: 4 [4480/9043 (49%)]\tLoss: 0.054577\n",
      "Train Epoch: 4 [5120/9043 (56%)]\tLoss: 0.061186\n",
      "Train Epoch: 4 [5760/9043 (63%)]\tLoss: 0.075593\n",
      "Train Epoch: 4 [6400/9043 (70%)]\tLoss: 0.107487\n",
      "Train Epoch: 4 [7040/9043 (77%)]\tLoss: 0.060912\n",
      "Train Epoch: 4 [7680/9043 (85%)]\tLoss: 0.017622\n",
      "Train Epoch: 4 [8320/9043 (92%)]\tLoss: 0.186963\n",
      "Train Epoch: 4 [8960/9043 (99%)]\tLoss: 0.097775\n",
      "Train Epoch: 5 [0/9043 (0%)]\tLoss: 0.151724\n",
      "Train Epoch: 5 [640/9043 (7%)]\tLoss: 0.082566\n",
      "Train Epoch: 5 [1280/9043 (14%)]\tLoss: 0.068060\n",
      "Train Epoch: 5 [1920/9043 (21%)]\tLoss: 0.068579\n",
      "Train Epoch: 5 [2560/9043 (28%)]\tLoss: 0.039127\n",
      "Train Epoch: 5 [3200/9043 (35%)]\tLoss: 0.067068\n",
      "Train Epoch: 5 [3840/9043 (42%)]\tLoss: 0.030145\n",
      "Train Epoch: 5 [4480/9043 (49%)]\tLoss: 0.060403\n",
      "Train Epoch: 5 [5120/9043 (56%)]\tLoss: 0.054413\n",
      "Train Epoch: 5 [5760/9043 (63%)]\tLoss: 0.080830\n",
      "Train Epoch: 5 [6400/9043 (70%)]\tLoss: 0.072131\n",
      "Train Epoch: 5 [7040/9043 (77%)]\tLoss: 0.040239\n",
      "Train Epoch: 5 [7680/9043 (85%)]\tLoss: 0.109753\n",
      "Train Epoch: 5 [8320/9043 (92%)]\tLoss: 0.034455\n",
      "Train Epoch: 5 [8960/9043 (99%)]\tLoss: 0.095901\n",
      "Train Epoch: 6 [0/9043 (0%)]\tLoss: 0.046711\n",
      "Train Epoch: 6 [640/9043 (7%)]\tLoss: 0.059808\n",
      "Train Epoch: 6 [1280/9043 (14%)]\tLoss: 0.041130\n",
      "Train Epoch: 6 [1920/9043 (21%)]\tLoss: 0.024328\n",
      "Train Epoch: 6 [2560/9043 (28%)]\tLoss: 0.026072\n",
      "Train Epoch: 6 [3200/9043 (35%)]\tLoss: 0.058664\n",
      "Train Epoch: 6 [3840/9043 (42%)]\tLoss: 0.033382\n",
      "Train Epoch: 6 [4480/9043 (49%)]\tLoss: 0.068726\n",
      "Train Epoch: 6 [5120/9043 (56%)]\tLoss: 0.250062\n",
      "Train Epoch: 6 [5760/9043 (63%)]\tLoss: 0.143016\n",
      "Train Epoch: 6 [6400/9043 (70%)]\tLoss: 0.033172\n",
      "Train Epoch: 6 [7040/9043 (77%)]\tLoss: 0.025907\n",
      "Train Epoch: 6 [7680/9043 (85%)]\tLoss: 0.040831\n",
      "Train Epoch: 6 [8320/9043 (92%)]\tLoss: 0.094685\n",
      "Train Epoch: 6 [8960/9043 (99%)]\tLoss: 0.033905\n",
      "Train Epoch: 7 [0/9043 (0%)]\tLoss: 0.094363\n",
      "Train Epoch: 7 [640/9043 (7%)]\tLoss: 0.049382\n",
      "Train Epoch: 7 [1280/9043 (14%)]\tLoss: 0.048511\n",
      "Train Epoch: 7 [1920/9043 (21%)]\tLoss: 0.045491\n",
      "Train Epoch: 7 [2560/9043 (28%)]\tLoss: 0.163222\n",
      "Train Epoch: 7 [3200/9043 (35%)]\tLoss: 0.173429\n",
      "Train Epoch: 7 [3840/9043 (42%)]\tLoss: 0.074421\n",
      "Train Epoch: 7 [4480/9043 (49%)]\tLoss: 0.022566\n",
      "Train Epoch: 7 [5120/9043 (56%)]\tLoss: 0.051520\n",
      "Train Epoch: 7 [5760/9043 (63%)]\tLoss: 0.041570\n",
      "Train Epoch: 7 [6400/9043 (70%)]\tLoss: 0.124204\n",
      "Train Epoch: 7 [7040/9043 (77%)]\tLoss: 0.110375\n",
      "Train Epoch: 7 [7680/9043 (85%)]\tLoss: 0.051199\n",
      "Train Epoch: 7 [8320/9043 (92%)]\tLoss: 0.024424\n",
      "Train Epoch: 7 [8960/9043 (99%)]\tLoss: 0.110456\n",
      "Train Epoch: 8 [0/9043 (0%)]\tLoss: 0.044558\n",
      "Train Epoch: 8 [640/9043 (7%)]\tLoss: 0.016083\n",
      "Train Epoch: 8 [1280/9043 (14%)]\tLoss: 0.005697\n",
      "Train Epoch: 8 [1920/9043 (21%)]\tLoss: 0.013451\n",
      "Train Epoch: 8 [2560/9043 (28%)]\tLoss: 0.018997\n",
      "Train Epoch: 8 [3200/9043 (35%)]\tLoss: 0.123071\n",
      "Train Epoch: 8 [3840/9043 (42%)]\tLoss: 0.060071\n",
      "Train Epoch: 8 [4480/9043 (49%)]\tLoss: 0.024735\n",
      "Train Epoch: 8 [5120/9043 (56%)]\tLoss: 0.029390\n",
      "Train Epoch: 8 [5760/9043 (63%)]\tLoss: 0.037684\n",
      "Train Epoch: 8 [6400/9043 (70%)]\tLoss: 0.070584\n",
      "Train Epoch: 8 [7040/9043 (77%)]\tLoss: 0.029310\n",
      "Train Epoch: 8 [7680/9043 (85%)]\tLoss: 0.074116\n",
      "Train Epoch: 8 [8320/9043 (92%)]\tLoss: 0.040798\n",
      "Train Epoch: 8 [8960/9043 (99%)]\tLoss: 0.042586\n",
      "Train Epoch: 9 [0/9043 (0%)]\tLoss: 0.011047\n",
      "Train Epoch: 9 [640/9043 (7%)]\tLoss: 0.044303\n",
      "Train Epoch: 9 [1280/9043 (14%)]\tLoss: 0.053581\n",
      "Train Epoch: 9 [1920/9043 (21%)]\tLoss: 0.038439\n",
      "Train Epoch: 9 [2560/9043 (28%)]\tLoss: 0.011168\n",
      "Train Epoch: 9 [3200/9043 (35%)]\tLoss: 0.011555\n",
      "Train Epoch: 9 [3840/9043 (42%)]\tLoss: 0.028372\n",
      "Train Epoch: 9 [4480/9043 (49%)]\tLoss: 0.036717\n",
      "Train Epoch: 9 [5120/9043 (56%)]\tLoss: 0.056236\n",
      "Train Epoch: 9 [5760/9043 (63%)]\tLoss: 0.029359\n",
      "Train Epoch: 9 [6400/9043 (70%)]\tLoss: 0.079681\n",
      "Train Epoch: 9 [7040/9043 (77%)]\tLoss: 0.043985\n",
      "Train Epoch: 9 [7680/9043 (85%)]\tLoss: 0.033561\n",
      "Train Epoch: 9 [8320/9043 (92%)]\tLoss: 0.074653\n",
      "Train Epoch: 9 [8960/9043 (99%)]\tLoss: 0.080884\n",
      "Train Epoch: 10 [0/9043 (0%)]\tLoss: 0.055445\n",
      "Train Epoch: 10 [640/9043 (7%)]\tLoss: 0.054681\n",
      "Train Epoch: 10 [1280/9043 (14%)]\tLoss: 0.016849\n",
      "Train Epoch: 10 [1920/9043 (21%)]\tLoss: 0.047263\n",
      "Train Epoch: 10 [2560/9043 (28%)]\tLoss: 0.019160\n",
      "Train Epoch: 10 [3200/9043 (35%)]\tLoss: 0.041650\n",
      "Train Epoch: 10 [3840/9043 (42%)]\tLoss: 0.148181\n",
      "Train Epoch: 10 [4480/9043 (49%)]\tLoss: 0.009995\n",
      "Train Epoch: 10 [5120/9043 (56%)]\tLoss: 0.004276\n",
      "Train Epoch: 10 [5760/9043 (63%)]\tLoss: 0.029310\n",
      "Train Epoch: 10 [6400/9043 (70%)]\tLoss: 0.010565\n",
      "Train Epoch: 10 [7040/9043 (77%)]\tLoss: 0.008021\n",
      "Train Epoch: 10 [7680/9043 (85%)]\tLoss: 0.130609\n",
      "Train Epoch: 10 [8320/9043 (92%)]\tLoss: 0.005912\n",
      "Train Epoch: 10 [8960/9043 (99%)]\tLoss: 0.007979\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/14723 (0%)]\tLoss: 1.176749\n",
      "Train Epoch: 1 [640/14723 (4%)]\tLoss: 0.389828\n",
      "Train Epoch: 1 [1280/14723 (9%)]\tLoss: 0.448345\n",
      "Train Epoch: 1 [1920/14723 (13%)]\tLoss: 0.481998\n",
      "Train Epoch: 1 [2560/14723 (17%)]\tLoss: 0.481829\n",
      "Train Epoch: 1 [3200/14723 (22%)]\tLoss: 0.407929\n",
      "Train Epoch: 1 [3840/14723 (26%)]\tLoss: 0.703974\n",
      "Train Epoch: 1 [4480/14723 (30%)]\tLoss: 0.539875\n",
      "Train Epoch: 1 [5120/14723 (35%)]\tLoss: 0.428362\n",
      "Train Epoch: 1 [5760/14723 (39%)]\tLoss: 0.574033\n",
      "Train Epoch: 1 [6400/14723 (43%)]\tLoss: 0.505607\n",
      "Train Epoch: 1 [7040/14723 (48%)]\tLoss: 0.355925\n",
      "Train Epoch: 1 [7680/14723 (52%)]\tLoss: 0.512627\n",
      "Train Epoch: 1 [8320/14723 (56%)]\tLoss: 0.513139\n",
      "Train Epoch: 1 [8960/14723 (61%)]\tLoss: 0.481759\n",
      "Train Epoch: 1 [9600/14723 (65%)]\tLoss: 0.255653\n",
      "Train Epoch: 1 [10240/14723 (69%)]\tLoss: 0.514284\n",
      "Train Epoch: 1 [10880/14723 (74%)]\tLoss: 0.447143\n",
      "Train Epoch: 1 [11520/14723 (78%)]\tLoss: 0.447343\n",
      "Train Epoch: 1 [12160/14723 (82%)]\tLoss: 0.782406\n",
      "Train Epoch: 1 [12800/14723 (87%)]\tLoss: 0.660254\n",
      "Train Epoch: 1 [13440/14723 (91%)]\tLoss: 0.606152\n",
      "Train Epoch: 1 [14080/14723 (95%)]\tLoss: 0.455021\n",
      "Train Epoch: 1 [690/14723 (100%)]\tLoss: 0.852049\n",
      "Train Epoch: 2 [0/14723 (0%)]\tLoss: 0.526247\n",
      "Train Epoch: 2 [640/14723 (4%)]\tLoss: 0.664414\n",
      "Train Epoch: 2 [1280/14723 (9%)]\tLoss: 0.552079\n",
      "Train Epoch: 2 [1920/14723 (13%)]\tLoss: 0.720294\n",
      "Train Epoch: 2 [2560/14723 (17%)]\tLoss: 0.693920\n",
      "Train Epoch: 2 [3200/14723 (22%)]\tLoss: 0.608175\n",
      "Train Epoch: 2 [3840/14723 (26%)]\tLoss: 0.437754\n",
      "Train Epoch: 2 [4480/14723 (30%)]\tLoss: 0.365636\n",
      "Train Epoch: 2 [5120/14723 (35%)]\tLoss: 0.627519\n",
      "Train Epoch: 2 [5760/14723 (39%)]\tLoss: 0.644511\n",
      "Train Epoch: 2 [6400/14723 (43%)]\tLoss: 0.446610\n",
      "Train Epoch: 2 [7040/14723 (48%)]\tLoss: 0.391435\n",
      "Train Epoch: 2 [7680/14723 (52%)]\tLoss: 0.615256\n",
      "Train Epoch: 2 [8320/14723 (56%)]\tLoss: 0.423936\n",
      "Train Epoch: 2 [8960/14723 (61%)]\tLoss: 0.709581\n",
      "Train Epoch: 2 [9600/14723 (65%)]\tLoss: 0.654455\n",
      "Train Epoch: 2 [10240/14723 (69%)]\tLoss: 0.585941\n",
      "Train Epoch: 2 [10880/14723 (74%)]\tLoss: 0.392778\n",
      "Train Epoch: 2 [11520/14723 (78%)]\tLoss: 0.253921\n",
      "Train Epoch: 2 [12160/14723 (82%)]\tLoss: 0.576064\n",
      "Train Epoch: 2 [12800/14723 (87%)]\tLoss: 0.301549\n",
      "Train Epoch: 2 [13440/14723 (91%)]\tLoss: 0.530673\n",
      "Train Epoch: 2 [14080/14723 (95%)]\tLoss: 0.346418\n",
      "Train Epoch: 2 [690/14723 (100%)]\tLoss: 2.417437\n",
      "Train Epoch: 3 [0/14723 (0%)]\tLoss: 0.959187\n",
      "Train Epoch: 3 [640/14723 (4%)]\tLoss: 0.933549\n",
      "Train Epoch: 3 [1280/14723 (9%)]\tLoss: 1.156136\n",
      "Train Epoch: 3 [1920/14723 (13%)]\tLoss: 0.650858\n",
      "Train Epoch: 3 [2560/14723 (17%)]\tLoss: 0.965302\n",
      "Train Epoch: 3 [3200/14723 (22%)]\tLoss: 0.690694\n",
      "Train Epoch: 3 [3840/14723 (26%)]\tLoss: 0.667832\n",
      "Train Epoch: 3 [4480/14723 (30%)]\tLoss: 0.704425\n",
      "Train Epoch: 3 [5120/14723 (35%)]\tLoss: 0.562804\n",
      "Train Epoch: 3 [5760/14723 (39%)]\tLoss: 0.439202\n",
      "Train Epoch: 3 [6400/14723 (43%)]\tLoss: 0.596774\n",
      "Train Epoch: 3 [7040/14723 (48%)]\tLoss: 0.737020\n",
      "Train Epoch: 3 [7680/14723 (52%)]\tLoss: 0.412614\n",
      "Train Epoch: 3 [8320/14723 (56%)]\tLoss: 0.682820\n",
      "Train Epoch: 3 [8960/14723 (61%)]\tLoss: 0.405874\n",
      "Train Epoch: 3 [9600/14723 (65%)]\tLoss: 0.521382\n",
      "Train Epoch: 3 [10240/14723 (69%)]\tLoss: 0.817150\n",
      "Train Epoch: 3 [10880/14723 (74%)]\tLoss: 0.451386\n",
      "Train Epoch: 3 [11520/14723 (78%)]\tLoss: 0.528529\n",
      "Train Epoch: 3 [12160/14723 (82%)]\tLoss: 0.429224\n",
      "Train Epoch: 3 [12800/14723 (87%)]\tLoss: 0.614883\n",
      "Train Epoch: 3 [13440/14723 (91%)]\tLoss: 0.517151\n",
      "Train Epoch: 3 [14080/14723 (95%)]\tLoss: 0.550927\n",
      "Train Epoch: 3 [690/14723 (100%)]\tLoss: 1.091479\n",
      "Train Epoch: 4 [0/14723 (0%)]\tLoss: 0.818635\n",
      "Train Epoch: 4 [640/14723 (4%)]\tLoss: 0.518294\n",
      "Train Epoch: 4 [1280/14723 (9%)]\tLoss: 0.638526\n",
      "Train Epoch: 4 [1920/14723 (13%)]\tLoss: 0.551991\n",
      "Train Epoch: 4 [2560/14723 (17%)]\tLoss: 0.334133\n",
      "Train Epoch: 4 [3200/14723 (22%)]\tLoss: 0.729289\n",
      "Train Epoch: 4 [3840/14723 (26%)]\tLoss: 0.686209\n",
      "Train Epoch: 4 [4480/14723 (30%)]\tLoss: 0.613318\n",
      "Train Epoch: 4 [5120/14723 (35%)]\tLoss: 0.390039\n",
      "Train Epoch: 4 [5760/14723 (39%)]\tLoss: 0.617588\n",
      "Train Epoch: 4 [6400/14723 (43%)]\tLoss: 0.433382\n",
      "Train Epoch: 4 [7040/14723 (48%)]\tLoss: 0.683124\n",
      "Train Epoch: 4 [7680/14723 (52%)]\tLoss: 0.486853\n",
      "Train Epoch: 4 [8320/14723 (56%)]\tLoss: 0.511725\n",
      "Train Epoch: 4 [8960/14723 (61%)]\tLoss: 0.377408\n",
      "Train Epoch: 4 [9600/14723 (65%)]\tLoss: 0.320911\n",
      "Train Epoch: 4 [10240/14723 (69%)]\tLoss: 0.294238\n",
      "Train Epoch: 4 [10880/14723 (74%)]\tLoss: 0.253151\n",
      "Train Epoch: 4 [11520/14723 (78%)]\tLoss: 0.347676\n",
      "Train Epoch: 4 [12160/14723 (82%)]\tLoss: 0.242993\n",
      "Train Epoch: 4 [12800/14723 (87%)]\tLoss: 0.414544\n",
      "Train Epoch: 4 [13440/14723 (91%)]\tLoss: 0.510085\n",
      "Train Epoch: 4 [14080/14723 (95%)]\tLoss: 0.658906\n",
      "Train Epoch: 4 [690/14723 (100%)]\tLoss: 0.329582\n",
      "Train Epoch: 5 [0/14723 (0%)]\tLoss: 0.254701\n",
      "Train Epoch: 5 [640/14723 (4%)]\tLoss: 0.666257\n",
      "Train Epoch: 5 [1280/14723 (9%)]\tLoss: 0.416480\n",
      "Train Epoch: 5 [1920/14723 (13%)]\tLoss: 0.670923\n",
      "Train Epoch: 5 [2560/14723 (17%)]\tLoss: 0.378464\n",
      "Train Epoch: 5 [3200/14723 (22%)]\tLoss: 0.502872\n",
      "Train Epoch: 5 [3840/14723 (26%)]\tLoss: 0.253681\n",
      "Train Epoch: 5 [4480/14723 (30%)]\tLoss: 0.391201\n",
      "Train Epoch: 5 [5120/14723 (35%)]\tLoss: 0.444400\n",
      "Train Epoch: 5 [5760/14723 (39%)]\tLoss: 0.455304\n",
      "Train Epoch: 5 [6400/14723 (43%)]\tLoss: 0.330147\n",
      "Train Epoch: 5 [7040/14723 (48%)]\tLoss: 0.378365\n",
      "Train Epoch: 5 [7680/14723 (52%)]\tLoss: 0.287184\n",
      "Train Epoch: 5 [8320/14723 (56%)]\tLoss: 0.390380\n",
      "Train Epoch: 5 [8960/14723 (61%)]\tLoss: 0.519739\n",
      "Train Epoch: 5 [9600/14723 (65%)]\tLoss: 0.298613\n",
      "Train Epoch: 5 [10240/14723 (69%)]\tLoss: 0.365180\n",
      "Train Epoch: 5 [10880/14723 (74%)]\tLoss: 0.488019\n",
      "Train Epoch: 5 [11520/14723 (78%)]\tLoss: 0.273303\n",
      "Train Epoch: 5 [12160/14723 (82%)]\tLoss: 0.188560\n",
      "Train Epoch: 5 [12800/14723 (87%)]\tLoss: 0.160540\n",
      "Train Epoch: 5 [13440/14723 (91%)]\tLoss: 0.361024\n",
      "Train Epoch: 5 [14080/14723 (95%)]\tLoss: 0.417777\n",
      "Train Epoch: 5 [690/14723 (100%)]\tLoss: 4.522564\n",
      "Train Epoch: 6 [0/14723 (0%)]\tLoss: 0.897650\n",
      "Train Epoch: 6 [640/14723 (4%)]\tLoss: 1.338675\n",
      "Train Epoch: 6 [1280/14723 (9%)]\tLoss: 1.058366\n",
      "Train Epoch: 6 [1920/14723 (13%)]\tLoss: 0.969792\n",
      "Train Epoch: 6 [2560/14723 (17%)]\tLoss: 1.001893\n",
      "Train Epoch: 6 [3200/14723 (22%)]\tLoss: 0.548673\n",
      "Train Epoch: 6 [3840/14723 (26%)]\tLoss: 0.917827\n",
      "Train Epoch: 6 [4480/14723 (30%)]\tLoss: 0.488190\n",
      "Train Epoch: 6 [5120/14723 (35%)]\tLoss: 0.730753\n",
      "Train Epoch: 6 [5760/14723 (39%)]\tLoss: 0.649521\n",
      "Train Epoch: 6 [6400/14723 (43%)]\tLoss: 0.566947\n",
      "Train Epoch: 6 [7040/14723 (48%)]\tLoss: 0.693785\n",
      "Train Epoch: 6 [7680/14723 (52%)]\tLoss: 0.745146\n",
      "Train Epoch: 6 [8320/14723 (56%)]\tLoss: 0.419232\n",
      "Train Epoch: 6 [8960/14723 (61%)]\tLoss: 0.515195\n",
      "Train Epoch: 6 [9600/14723 (65%)]\tLoss: 0.568757\n",
      "Train Epoch: 6 [10240/14723 (69%)]\tLoss: 0.547032\n",
      "Train Epoch: 6 [10880/14723 (74%)]\tLoss: 0.584357\n",
      "Train Epoch: 6 [11520/14723 (78%)]\tLoss: 0.561145\n",
      "Train Epoch: 6 [12160/14723 (82%)]\tLoss: 0.419076\n",
      "Train Epoch: 6 [12800/14723 (87%)]\tLoss: 0.510643\n",
      "Train Epoch: 6 [13440/14723 (91%)]\tLoss: 0.547841\n",
      "Train Epoch: 6 [14080/14723 (95%)]\tLoss: 0.422912\n",
      "Train Epoch: 6 [690/14723 (100%)]\tLoss: 0.969512\n",
      "Train Epoch: 7 [0/14723 (0%)]\tLoss: 0.641349\n",
      "Train Epoch: 7 [640/14723 (4%)]\tLoss: 0.379304\n",
      "Train Epoch: 7 [1280/14723 (9%)]\tLoss: 0.524358\n",
      "Train Epoch: 7 [1920/14723 (13%)]\tLoss: 0.382745\n",
      "Train Epoch: 7 [2560/14723 (17%)]\tLoss: 0.306902\n",
      "Train Epoch: 7 [3200/14723 (22%)]\tLoss: 0.338323\n",
      "Train Epoch: 7 [3840/14723 (26%)]\tLoss: 0.295183\n",
      "Train Epoch: 7 [4480/14723 (30%)]\tLoss: 0.371471\n",
      "Train Epoch: 7 [5120/14723 (35%)]\tLoss: 0.309480\n",
      "Train Epoch: 7 [5760/14723 (39%)]\tLoss: 0.354202\n",
      "Train Epoch: 7 [6400/14723 (43%)]\tLoss: 0.293008\n",
      "Train Epoch: 7 [7040/14723 (48%)]\tLoss: 0.282565\n",
      "Train Epoch: 7 [7680/14723 (52%)]\tLoss: 0.210409\n",
      "Train Epoch: 7 [8320/14723 (56%)]\tLoss: 0.326788\n",
      "Train Epoch: 7 [8960/14723 (61%)]\tLoss: 0.216160\n",
      "Train Epoch: 7 [9600/14723 (65%)]\tLoss: 0.295174\n",
      "Train Epoch: 7 [10240/14723 (69%)]\tLoss: 0.468007\n",
      "Train Epoch: 7 [10880/14723 (74%)]\tLoss: 0.461537\n",
      "Train Epoch: 7 [11520/14723 (78%)]\tLoss: 0.315195\n",
      "Train Epoch: 7 [12160/14723 (82%)]\tLoss: 0.273136\n",
      "Train Epoch: 7 [12800/14723 (87%)]\tLoss: 0.368751\n",
      "Train Epoch: 7 [13440/14723 (91%)]\tLoss: 0.321127\n",
      "Train Epoch: 7 [14080/14723 (95%)]\tLoss: 0.278630\n",
      "Train Epoch: 7 [690/14723 (100%)]\tLoss: 0.472324\n",
      "Train Epoch: 8 [0/14723 (0%)]\tLoss: 0.668232\n",
      "Train Epoch: 8 [640/14723 (4%)]\tLoss: 0.644315\n",
      "Train Epoch: 8 [1280/14723 (9%)]\tLoss: 0.503137\n",
      "Train Epoch: 8 [1920/14723 (13%)]\tLoss: 0.578368\n",
      "Train Epoch: 8 [2560/14723 (17%)]\tLoss: 0.618456\n",
      "Train Epoch: 8 [3200/14723 (22%)]\tLoss: 0.541412\n",
      "Train Epoch: 8 [3840/14723 (26%)]\tLoss: 0.620209\n",
      "Train Epoch: 8 [4480/14723 (30%)]\tLoss: 0.563964\n",
      "Train Epoch: 8 [5120/14723 (35%)]\tLoss: 0.430711\n",
      "Train Epoch: 8 [5760/14723 (39%)]\tLoss: 0.323945\n",
      "Train Epoch: 8 [6400/14723 (43%)]\tLoss: 0.528690\n",
      "Train Epoch: 8 [7040/14723 (48%)]\tLoss: 0.571896\n",
      "Train Epoch: 8 [7680/14723 (52%)]\tLoss: 0.434247\n",
      "Train Epoch: 8 [8320/14723 (56%)]\tLoss: 0.257384\n",
      "Train Epoch: 8 [8960/14723 (61%)]\tLoss: 0.225391\n",
      "Train Epoch: 8 [9600/14723 (65%)]\tLoss: 0.375958\n",
      "Train Epoch: 8 [10240/14723 (69%)]\tLoss: 0.558215\n",
      "Train Epoch: 8 [10880/14723 (74%)]\tLoss: 0.457106\n",
      "Train Epoch: 8 [11520/14723 (78%)]\tLoss: 0.294002\n",
      "Train Epoch: 8 [12160/14723 (82%)]\tLoss: 0.537404\n",
      "Train Epoch: 8 [12800/14723 (87%)]\tLoss: 0.256648\n",
      "Train Epoch: 8 [13440/14723 (91%)]\tLoss: 0.395015\n",
      "Train Epoch: 8 [14080/14723 (95%)]\tLoss: 0.354776\n",
      "Train Epoch: 8 [690/14723 (100%)]\tLoss: 3.405474\n",
      "Train Epoch: 9 [0/14723 (0%)]\tLoss: 0.923939\n",
      "Train Epoch: 9 [640/14723 (4%)]\tLoss: 0.677327\n",
      "Train Epoch: 9 [1280/14723 (9%)]\tLoss: 0.848196\n",
      "Train Epoch: 9 [1920/14723 (13%)]\tLoss: 0.414868\n",
      "Train Epoch: 9 [2560/14723 (17%)]\tLoss: 0.571335\n",
      "Train Epoch: 9 [3200/14723 (22%)]\tLoss: 0.552080\n",
      "Train Epoch: 9 [3840/14723 (26%)]\tLoss: 0.355403\n",
      "Train Epoch: 9 [4480/14723 (30%)]\tLoss: 0.534051\n",
      "Train Epoch: 9 [5120/14723 (35%)]\tLoss: 0.407935\n",
      "Train Epoch: 9 [5760/14723 (39%)]\tLoss: 0.242245\n",
      "Train Epoch: 9 [6400/14723 (43%)]\tLoss: 0.494478\n",
      "Train Epoch: 9 [7040/14723 (48%)]\tLoss: 0.438672\n",
      "Train Epoch: 9 [7680/14723 (52%)]\tLoss: 0.289178\n",
      "Train Epoch: 9 [8320/14723 (56%)]\tLoss: 0.178602\n",
      "Train Epoch: 9 [8960/14723 (61%)]\tLoss: 0.164702\n",
      "Train Epoch: 9 [9600/14723 (65%)]\tLoss: 0.338980\n",
      "Train Epoch: 9 [10240/14723 (69%)]\tLoss: 0.247902\n",
      "Train Epoch: 9 [10880/14723 (74%)]\tLoss: 0.225323\n",
      "Train Epoch: 9 [11520/14723 (78%)]\tLoss: 0.336234\n",
      "Train Epoch: 9 [12160/14723 (82%)]\tLoss: 0.323851\n",
      "Train Epoch: 9 [12800/14723 (87%)]\tLoss: 0.245653\n",
      "Train Epoch: 9 [13440/14723 (91%)]\tLoss: 0.391255\n",
      "Train Epoch: 9 [14080/14723 (95%)]\tLoss: 0.410712\n",
      "Train Epoch: 9 [690/14723 (100%)]\tLoss: 0.032978\n",
      "Train Epoch: 10 [0/14723 (0%)]\tLoss: 0.225045\n",
      "Train Epoch: 10 [640/14723 (4%)]\tLoss: 0.125906\n",
      "Train Epoch: 10 [1280/14723 (9%)]\tLoss: 0.114589\n",
      "Train Epoch: 10 [1920/14723 (13%)]\tLoss: 0.182806\n",
      "Train Epoch: 10 [2560/14723 (17%)]\tLoss: 0.138104\n",
      "Train Epoch: 10 [3200/14723 (22%)]\tLoss: 0.118879\n",
      "Train Epoch: 10 [3840/14723 (26%)]\tLoss: 0.192118\n",
      "Train Epoch: 10 [4480/14723 (30%)]\tLoss: 0.101785\n",
      "Train Epoch: 10 [5120/14723 (35%)]\tLoss: 0.103531\n",
      "Train Epoch: 10 [5760/14723 (39%)]\tLoss: 0.103668\n",
      "Train Epoch: 10 [6400/14723 (43%)]\tLoss: 0.155033\n",
      "Train Epoch: 10 [7040/14723 (48%)]\tLoss: 0.123669\n",
      "Train Epoch: 10 [7680/14723 (52%)]\tLoss: 0.140081\n",
      "Train Epoch: 10 [8320/14723 (56%)]\tLoss: 0.072499\n",
      "Train Epoch: 10 [8960/14723 (61%)]\tLoss: 0.132109\n",
      "Train Epoch: 10 [9600/14723 (65%)]\tLoss: 0.089934\n",
      "Train Epoch: 10 [10240/14723 (69%)]\tLoss: 0.098133\n",
      "Train Epoch: 10 [10880/14723 (74%)]\tLoss: 0.098666\n",
      "Train Epoch: 10 [11520/14723 (78%)]\tLoss: 0.163827\n",
      "Train Epoch: 10 [12160/14723 (82%)]\tLoss: 0.040625\n",
      "Train Epoch: 10 [12800/14723 (87%)]\tLoss: 0.256460\n",
      "Train Epoch: 10 [13440/14723 (91%)]\tLoss: 0.134470\n",
      "Train Epoch: 10 [14080/14723 (95%)]\tLoss: 0.034605\n",
      "Train Epoch: 10 [690/14723 (100%)]\tLoss: 4.272594\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/7654 (0%)]\tLoss: 1.692836\n",
      "Train Epoch: 1 [640/7654 (8%)]\tLoss: 0.519141\n",
      "Train Epoch: 1 [1280/7654 (17%)]\tLoss: 0.334103\n",
      "Train Epoch: 1 [1920/7654 (25%)]\tLoss: 0.129387\n",
      "Train Epoch: 1 [2560/7654 (33%)]\tLoss: 0.363288\n",
      "Train Epoch: 1 [3200/7654 (42%)]\tLoss: 0.316271\n",
      "Train Epoch: 1 [3840/7654 (50%)]\tLoss: 0.176236\n",
      "Train Epoch: 1 [4480/7654 (58%)]\tLoss: 0.314250\n",
      "Train Epoch: 1 [5120/7654 (67%)]\tLoss: 0.386610\n",
      "Train Epoch: 1 [5760/7654 (75%)]\tLoss: 0.287300\n",
      "Train Epoch: 1 [6400/7654 (83%)]\tLoss: 0.451569\n",
      "Train Epoch: 1 [7040/7654 (92%)]\tLoss: 0.148745\n",
      "Train Epoch: 2 [0/7654 (0%)]\tLoss: 0.071858\n",
      "Train Epoch: 2 [640/7654 (8%)]\tLoss: 0.129685\n",
      "Train Epoch: 2 [1280/7654 (17%)]\tLoss: 0.120539\n",
      "Train Epoch: 2 [1920/7654 (25%)]\tLoss: 0.086280\n",
      "Train Epoch: 2 [2560/7654 (33%)]\tLoss: 0.076509\n",
      "Train Epoch: 2 [3200/7654 (42%)]\tLoss: 0.152417\n",
      "Train Epoch: 2 [3840/7654 (50%)]\tLoss: 0.050121\n",
      "Train Epoch: 2 [4480/7654 (58%)]\tLoss: 0.047346\n",
      "Train Epoch: 2 [5120/7654 (67%)]\tLoss: 0.113394\n",
      "Train Epoch: 2 [5760/7654 (75%)]\tLoss: 0.110771\n",
      "Train Epoch: 2 [6400/7654 (83%)]\tLoss: 0.044835\n",
      "Train Epoch: 2 [7040/7654 (92%)]\tLoss: 0.119633\n",
      "Train Epoch: 3 [0/7654 (0%)]\tLoss: 0.071076\n",
      "Train Epoch: 3 [640/7654 (8%)]\tLoss: 0.013673\n",
      "Train Epoch: 3 [1280/7654 (17%)]\tLoss: 0.047354\n",
      "Train Epoch: 3 [1920/7654 (25%)]\tLoss: 0.068601\n",
      "Train Epoch: 3 [2560/7654 (33%)]\tLoss: 0.073056\n",
      "Train Epoch: 3 [3200/7654 (42%)]\tLoss: 0.059333\n",
      "Train Epoch: 3 [3840/7654 (50%)]\tLoss: 0.013763\n",
      "Train Epoch: 3 [4480/7654 (58%)]\tLoss: 0.089955\n",
      "Train Epoch: 3 [5120/7654 (67%)]\tLoss: 0.023455\n",
      "Train Epoch: 3 [5760/7654 (75%)]\tLoss: 0.015005\n",
      "Train Epoch: 3 [6400/7654 (83%)]\tLoss: 0.018699\n",
      "Train Epoch: 3 [7040/7654 (92%)]\tLoss: 0.047718\n",
      "Train Epoch: 4 [0/7654 (0%)]\tLoss: 0.022720\n",
      "Train Epoch: 4 [640/7654 (8%)]\tLoss: 0.093470\n",
      "Train Epoch: 4 [1280/7654 (17%)]\tLoss: 0.005740\n",
      "Train Epoch: 4 [1920/7654 (25%)]\tLoss: 0.005136\n",
      "Train Epoch: 4 [2560/7654 (33%)]\tLoss: 0.054019\n",
      "Train Epoch: 4 [3200/7654 (42%)]\tLoss: 0.015769\n",
      "Train Epoch: 4 [3840/7654 (50%)]\tLoss: 0.041547\n",
      "Train Epoch: 4 [4480/7654 (58%)]\tLoss: 0.024887\n",
      "Train Epoch: 4 [5120/7654 (67%)]\tLoss: 0.020184\n",
      "Train Epoch: 4 [5760/7654 (75%)]\tLoss: 0.062805\n",
      "Train Epoch: 4 [6400/7654 (83%)]\tLoss: 0.032845\n",
      "Train Epoch: 4 [7040/7654 (92%)]\tLoss: 0.051756\n",
      "Train Epoch: 5 [0/7654 (0%)]\tLoss: 0.064365\n",
      "Train Epoch: 5 [640/7654 (8%)]\tLoss: 0.015976\n",
      "Train Epoch: 5 [1280/7654 (17%)]\tLoss: 0.084160\n",
      "Train Epoch: 5 [1920/7654 (25%)]\tLoss: 0.099271\n",
      "Train Epoch: 5 [2560/7654 (33%)]\tLoss: 0.004386\n",
      "Train Epoch: 5 [3200/7654 (42%)]\tLoss: 0.013101\n",
      "Train Epoch: 5 [3840/7654 (50%)]\tLoss: 0.016227\n",
      "Train Epoch: 5 [4480/7654 (58%)]\tLoss: 0.007760\n",
      "Train Epoch: 5 [5120/7654 (67%)]\tLoss: 0.035049\n",
      "Train Epoch: 5 [5760/7654 (75%)]\tLoss: 0.137385\n",
      "Train Epoch: 5 [6400/7654 (83%)]\tLoss: 0.001478\n",
      "Train Epoch: 5 [7040/7654 (92%)]\tLoss: 0.017921\n",
      "Train Epoch: 6 [0/7654 (0%)]\tLoss: 0.006483\n",
      "Train Epoch: 6 [640/7654 (8%)]\tLoss: 0.011982\n",
      "Train Epoch: 6 [1280/7654 (17%)]\tLoss: 0.018397\n",
      "Train Epoch: 6 [1920/7654 (25%)]\tLoss: 0.008764\n",
      "Train Epoch: 6 [2560/7654 (33%)]\tLoss: 0.010984\n",
      "Train Epoch: 6 [3200/7654 (42%)]\tLoss: 0.084986\n",
      "Train Epoch: 6 [3840/7654 (50%)]\tLoss: 0.007942\n",
      "Train Epoch: 6 [4480/7654 (58%)]\tLoss: 0.012252\n",
      "Train Epoch: 6 [5120/7654 (67%)]\tLoss: 0.027269\n",
      "Train Epoch: 6 [5760/7654 (75%)]\tLoss: 0.043028\n",
      "Train Epoch: 6 [6400/7654 (83%)]\tLoss: 0.011284\n",
      "Train Epoch: 6 [7040/7654 (92%)]\tLoss: 0.005789\n",
      "Train Epoch: 7 [0/7654 (0%)]\tLoss: 0.053510\n",
      "Train Epoch: 7 [640/7654 (8%)]\tLoss: 0.004695\n",
      "Train Epoch: 7 [1280/7654 (17%)]\tLoss: 0.005392\n",
      "Train Epoch: 7 [1920/7654 (25%)]\tLoss: 0.009591\n",
      "Train Epoch: 7 [2560/7654 (33%)]\tLoss: 0.007421\n",
      "Train Epoch: 7 [3200/7654 (42%)]\tLoss: 0.007142\n",
      "Train Epoch: 7 [3840/7654 (50%)]\tLoss: 0.006911\n",
      "Train Epoch: 7 [4480/7654 (58%)]\tLoss: 0.002339\n",
      "Train Epoch: 7 [5120/7654 (67%)]\tLoss: 0.004160\n",
      "Train Epoch: 7 [5760/7654 (75%)]\tLoss: 0.003465\n",
      "Train Epoch: 7 [6400/7654 (83%)]\tLoss: 0.008900\n",
      "Train Epoch: 7 [7040/7654 (92%)]\tLoss: 0.047901\n",
      "Train Epoch: 8 [0/7654 (0%)]\tLoss: 0.022173\n",
      "Train Epoch: 8 [640/7654 (8%)]\tLoss: 0.004105\n",
      "Train Epoch: 8 [1280/7654 (17%)]\tLoss: 0.026554\n",
      "Train Epoch: 8 [1920/7654 (25%)]\tLoss: 0.027279\n",
      "Train Epoch: 8 [2560/7654 (33%)]\tLoss: 0.012802\n",
      "Train Epoch: 8 [3200/7654 (42%)]\tLoss: 0.011579\n",
      "Train Epoch: 8 [3840/7654 (50%)]\tLoss: 0.032414\n",
      "Train Epoch: 8 [4480/7654 (58%)]\tLoss: 0.002654\n",
      "Train Epoch: 8 [5120/7654 (67%)]\tLoss: 0.001864\n",
      "Train Epoch: 8 [5760/7654 (75%)]\tLoss: 0.001683\n",
      "Train Epoch: 8 [6400/7654 (83%)]\tLoss: 0.016366\n",
      "Train Epoch: 8 [7040/7654 (92%)]\tLoss: 0.004027\n",
      "Train Epoch: 9 [0/7654 (0%)]\tLoss: 0.007593\n",
      "Train Epoch: 9 [640/7654 (8%)]\tLoss: 0.023767\n",
      "Train Epoch: 9 [1280/7654 (17%)]\tLoss: 0.002313\n",
      "Train Epoch: 9 [1920/7654 (25%)]\tLoss: 0.000556\n",
      "Train Epoch: 9 [2560/7654 (33%)]\tLoss: 0.015109\n",
      "Train Epoch: 9 [3200/7654 (42%)]\tLoss: 0.004792\n",
      "Train Epoch: 9 [3840/7654 (50%)]\tLoss: 0.004169\n",
      "Train Epoch: 9 [4480/7654 (58%)]\tLoss: 0.001543\n",
      "Train Epoch: 9 [5120/7654 (67%)]\tLoss: 0.028104\n",
      "Train Epoch: 9 [5760/7654 (75%)]\tLoss: 0.045646\n",
      "Train Epoch: 9 [6400/7654 (83%)]\tLoss: 0.010387\n",
      "Train Epoch: 9 [7040/7654 (92%)]\tLoss: 0.003465\n",
      "Train Epoch: 10 [0/7654 (0%)]\tLoss: 0.000928\n",
      "Train Epoch: 10 [640/7654 (8%)]\tLoss: 0.005529\n",
      "Train Epoch: 10 [1280/7654 (17%)]\tLoss: 0.032803\n",
      "Train Epoch: 10 [1920/7654 (25%)]\tLoss: 0.001756\n",
      "Train Epoch: 10 [2560/7654 (33%)]\tLoss: 0.000869\n",
      "Train Epoch: 10 [3200/7654 (42%)]\tLoss: 0.006394\n",
      "Train Epoch: 10 [3840/7654 (50%)]\tLoss: 0.009579\n",
      "Train Epoch: 10 [4480/7654 (58%)]\tLoss: 0.022487\n",
      "Train Epoch: 10 [5120/7654 (67%)]\tLoss: 0.001080\n",
      "Train Epoch: 10 [5760/7654 (75%)]\tLoss: 0.006151\n",
      "Train Epoch: 10 [6400/7654 (83%)]\tLoss: 0.004832\n",
      "Train Epoch: 10 [7040/7654 (92%)]\tLoss: 0.004492\n",
      "after training[ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")]\n",
      "after fedaveraging[ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")]\n",
      "local_models in the distribute function [ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")]\n",
      "4\n",
      "local_models in the distribute function [ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 2.4939, Accuracy: 3956/10000 (40%)\n",
      "\n",
      "Round 4/4\n",
      "Training client 1\n",
      "Train Epoch: 1 [0/18580 (0%)]\tLoss: 1.701210\n",
      "Train Epoch: 1 [640/18580 (3%)]\tLoss: 0.574930\n",
      "Train Epoch: 1 [1280/18580 (7%)]\tLoss: 0.485593\n",
      "Train Epoch: 1 [1920/18580 (10%)]\tLoss: 0.256168\n",
      "Train Epoch: 1 [2560/18580 (14%)]\tLoss: 0.319836\n",
      "Train Epoch: 1 [3200/18580 (17%)]\tLoss: 0.287901\n",
      "Train Epoch: 1 [3840/18580 (21%)]\tLoss: 0.327069\n",
      "Train Epoch: 1 [4480/18580 (24%)]\tLoss: 0.311503\n",
      "Train Epoch: 1 [5120/18580 (27%)]\tLoss: 0.257406\n",
      "Train Epoch: 1 [5760/18580 (31%)]\tLoss: 0.341935\n",
      "Train Epoch: 1 [6400/18580 (34%)]\tLoss: 0.361443\n",
      "Train Epoch: 1 [7040/18580 (38%)]\tLoss: 0.321798\n",
      "Train Epoch: 1 [7680/18580 (41%)]\tLoss: 0.256521\n",
      "Train Epoch: 1 [8320/18580 (45%)]\tLoss: 0.264737\n",
      "Train Epoch: 1 [8960/18580 (48%)]\tLoss: 0.246433\n",
      "Train Epoch: 1 [9600/18580 (52%)]\tLoss: 0.296217\n",
      "Train Epoch: 1 [10240/18580 (55%)]\tLoss: 0.777453\n",
      "Train Epoch: 1 [10880/18580 (58%)]\tLoss: 0.386507\n",
      "Train Epoch: 1 [11520/18580 (62%)]\tLoss: 0.462151\n",
      "Train Epoch: 1 [12160/18580 (65%)]\tLoss: 0.208448\n",
      "Train Epoch: 1 [12800/18580 (69%)]\tLoss: 0.258409\n",
      "Train Epoch: 1 [13440/18580 (72%)]\tLoss: 0.196949\n",
      "Train Epoch: 1 [14080/18580 (76%)]\tLoss: 0.231915\n",
      "Train Epoch: 1 [14720/18580 (79%)]\tLoss: 0.261965\n",
      "Train Epoch: 1 [15360/18580 (82%)]\tLoss: 0.286068\n",
      "Train Epoch: 1 [16000/18580 (86%)]\tLoss: 0.360328\n",
      "Train Epoch: 1 [16640/18580 (89%)]\tLoss: 0.173281\n",
      "Train Epoch: 1 [17280/18580 (93%)]\tLoss: 0.190916\n",
      "Train Epoch: 1 [17920/18580 (96%)]\tLoss: 0.177440\n",
      "Train Epoch: 1 [5800/18580 (100%)]\tLoss: 0.390140\n",
      "Train Epoch: 2 [0/18580 (0%)]\tLoss: 0.183590\n",
      "Train Epoch: 2 [640/18580 (3%)]\tLoss: 0.141697\n",
      "Train Epoch: 2 [1280/18580 (7%)]\tLoss: 0.081487\n",
      "Train Epoch: 2 [1920/18580 (10%)]\tLoss: 0.063856\n",
      "Train Epoch: 2 [2560/18580 (14%)]\tLoss: 0.122089\n",
      "Train Epoch: 2 [3200/18580 (17%)]\tLoss: 0.140783\n",
      "Train Epoch: 2 [3840/18580 (21%)]\tLoss: 0.125128\n",
      "Train Epoch: 2 [4480/18580 (24%)]\tLoss: 0.281184\n",
      "Train Epoch: 2 [5120/18580 (27%)]\tLoss: 0.092354\n",
      "Train Epoch: 2 [5760/18580 (31%)]\tLoss: 0.067637\n",
      "Train Epoch: 2 [6400/18580 (34%)]\tLoss: 0.043559\n",
      "Train Epoch: 2 [7040/18580 (38%)]\tLoss: 0.116547\n",
      "Train Epoch: 2 [7680/18580 (41%)]\tLoss: 0.082442\n",
      "Train Epoch: 2 [8320/18580 (45%)]\tLoss: 0.016302\n",
      "Train Epoch: 2 [8960/18580 (48%)]\tLoss: 0.029069\n",
      "Train Epoch: 2 [9600/18580 (52%)]\tLoss: 0.218953\n",
      "Train Epoch: 2 [10240/18580 (55%)]\tLoss: 0.099049\n",
      "Train Epoch: 2 [10880/18580 (58%)]\tLoss: 0.128257\n",
      "Train Epoch: 2 [11520/18580 (62%)]\tLoss: 0.053339\n",
      "Train Epoch: 2 [12160/18580 (65%)]\tLoss: 0.265056\n",
      "Train Epoch: 2 [12800/18580 (69%)]\tLoss: 0.056907\n",
      "Train Epoch: 2 [13440/18580 (72%)]\tLoss: 0.094180\n",
      "Train Epoch: 2 [14080/18580 (76%)]\tLoss: 0.024279\n",
      "Train Epoch: 2 [14720/18580 (79%)]\tLoss: 0.163918\n",
      "Train Epoch: 2 [15360/18580 (82%)]\tLoss: 0.023248\n",
      "Train Epoch: 2 [16000/18580 (86%)]\tLoss: 0.055213\n",
      "Train Epoch: 2 [16640/18580 (89%)]\tLoss: 0.112746\n",
      "Train Epoch: 2 [17280/18580 (93%)]\tLoss: 0.102644\n",
      "Train Epoch: 2 [17920/18580 (96%)]\tLoss: 0.180456\n",
      "Train Epoch: 2 [5800/18580 (100%)]\tLoss: 0.075153\n",
      "Train Epoch: 3 [0/18580 (0%)]\tLoss: 0.097853\n",
      "Train Epoch: 3 [640/18580 (3%)]\tLoss: 0.057369\n",
      "Train Epoch: 3 [1280/18580 (7%)]\tLoss: 0.078345\n",
      "Train Epoch: 3 [1920/18580 (10%)]\tLoss: 0.031357\n",
      "Train Epoch: 3 [2560/18580 (14%)]\tLoss: 0.058288\n",
      "Train Epoch: 3 [3200/18580 (17%)]\tLoss: 0.031020\n",
      "Train Epoch: 3 [3840/18580 (21%)]\tLoss: 0.074703\n",
      "Train Epoch: 3 [4480/18580 (24%)]\tLoss: 0.072282\n",
      "Train Epoch: 3 [5120/18580 (27%)]\tLoss: 0.045597\n",
      "Train Epoch: 3 [5760/18580 (31%)]\tLoss: 0.026146\n",
      "Train Epoch: 3 [6400/18580 (34%)]\tLoss: 0.027133\n",
      "Train Epoch: 3 [7040/18580 (38%)]\tLoss: 0.324108\n",
      "Train Epoch: 3 [7680/18580 (41%)]\tLoss: 0.126841\n",
      "Train Epoch: 3 [8320/18580 (45%)]\tLoss: 0.080290\n",
      "Train Epoch: 3 [8960/18580 (48%)]\tLoss: 0.059258\n",
      "Train Epoch: 3 [9600/18580 (52%)]\tLoss: 0.188966\n",
      "Train Epoch: 3 [10240/18580 (55%)]\tLoss: 0.065378\n",
      "Train Epoch: 3 [10880/18580 (58%)]\tLoss: 0.083828\n",
      "Train Epoch: 3 [11520/18580 (62%)]\tLoss: 0.128167\n",
      "Train Epoch: 3 [12160/18580 (65%)]\tLoss: 0.089105\n",
      "Train Epoch: 3 [12800/18580 (69%)]\tLoss: 0.058956\n",
      "Train Epoch: 3 [13440/18580 (72%)]\tLoss: 0.055599\n",
      "Train Epoch: 3 [14080/18580 (76%)]\tLoss: 0.041328\n",
      "Train Epoch: 3 [14720/18580 (79%)]\tLoss: 0.016602\n",
      "Train Epoch: 3 [15360/18580 (82%)]\tLoss: 0.017069\n",
      "Train Epoch: 3 [16000/18580 (86%)]\tLoss: 0.141758\n",
      "Train Epoch: 3 [16640/18580 (89%)]\tLoss: 0.063689\n",
      "Train Epoch: 3 [17280/18580 (93%)]\tLoss: 0.030330\n",
      "Train Epoch: 3 [17920/18580 (96%)]\tLoss: 0.112405\n",
      "Train Epoch: 3 [5800/18580 (100%)]\tLoss: 0.077669\n",
      "Train Epoch: 4 [0/18580 (0%)]\tLoss: 0.080857\n",
      "Train Epoch: 4 [640/18580 (3%)]\tLoss: 0.085519\n",
      "Train Epoch: 4 [1280/18580 (7%)]\tLoss: 0.036024\n",
      "Train Epoch: 4 [1920/18580 (10%)]\tLoss: 0.093559\n",
      "Train Epoch: 4 [2560/18580 (14%)]\tLoss: 0.026202\n",
      "Train Epoch: 4 [3200/18580 (17%)]\tLoss: 0.065104\n",
      "Train Epoch: 4 [3840/18580 (21%)]\tLoss: 0.092536\n",
      "Train Epoch: 4 [4480/18580 (24%)]\tLoss: 0.041209\n",
      "Train Epoch: 4 [5120/18580 (27%)]\tLoss: 0.052832\n",
      "Train Epoch: 4 [5760/18580 (31%)]\tLoss: 0.053048\n",
      "Train Epoch: 4 [6400/18580 (34%)]\tLoss: 0.024360\n",
      "Train Epoch: 4 [7040/18580 (38%)]\tLoss: 0.056470\n",
      "Train Epoch: 4 [7680/18580 (41%)]\tLoss: 0.086801\n",
      "Train Epoch: 4 [8320/18580 (45%)]\tLoss: 0.039105\n",
      "Train Epoch: 4 [8960/18580 (48%)]\tLoss: 0.015882\n",
      "Train Epoch: 4 [9600/18580 (52%)]\tLoss: 0.045769\n",
      "Train Epoch: 4 [10240/18580 (55%)]\tLoss: 0.028848\n",
      "Train Epoch: 4 [10880/18580 (58%)]\tLoss: 0.086713\n",
      "Train Epoch: 4 [11520/18580 (62%)]\tLoss: 0.032494\n",
      "Train Epoch: 4 [12160/18580 (65%)]\tLoss: 0.205156\n",
      "Train Epoch: 4 [12800/18580 (69%)]\tLoss: 0.039215\n",
      "Train Epoch: 4 [13440/18580 (72%)]\tLoss: 0.068766\n",
      "Train Epoch: 4 [14080/18580 (76%)]\tLoss: 0.047798\n",
      "Train Epoch: 4 [14720/18580 (79%)]\tLoss: 0.039881\n",
      "Train Epoch: 4 [15360/18580 (82%)]\tLoss: 0.085049\n",
      "Train Epoch: 4 [16000/18580 (86%)]\tLoss: 0.016039\n",
      "Train Epoch: 4 [16640/18580 (89%)]\tLoss: 0.023618\n",
      "Train Epoch: 4 [17280/18580 (93%)]\tLoss: 0.042608\n",
      "Train Epoch: 4 [17920/18580 (96%)]\tLoss: 0.051290\n",
      "Train Epoch: 4 [5800/18580 (100%)]\tLoss: 0.585121\n",
      "Train Epoch: 5 [0/18580 (0%)]\tLoss: 0.044483\n",
      "Train Epoch: 5 [640/18580 (3%)]\tLoss: 0.005418\n",
      "Train Epoch: 5 [1280/18580 (7%)]\tLoss: 0.026061\n",
      "Train Epoch: 5 [1920/18580 (10%)]\tLoss: 0.007905\n",
      "Train Epoch: 5 [2560/18580 (14%)]\tLoss: 0.006242\n",
      "Train Epoch: 5 [3200/18580 (17%)]\tLoss: 0.031887\n",
      "Train Epoch: 5 [3840/18580 (21%)]\tLoss: 0.006858\n",
      "Train Epoch: 5 [4480/18580 (24%)]\tLoss: 0.097830\n",
      "Train Epoch: 5 [5120/18580 (27%)]\tLoss: 0.084024\n",
      "Train Epoch: 5 [5760/18580 (31%)]\tLoss: 0.044629\n",
      "Train Epoch: 5 [6400/18580 (34%)]\tLoss: 0.050059\n",
      "Train Epoch: 5 [7040/18580 (38%)]\tLoss: 0.033205\n",
      "Train Epoch: 5 [7680/18580 (41%)]\tLoss: 0.034825\n",
      "Train Epoch: 5 [8320/18580 (45%)]\tLoss: 0.049929\n",
      "Train Epoch: 5 [8960/18580 (48%)]\tLoss: 0.185605\n",
      "Train Epoch: 5 [9600/18580 (52%)]\tLoss: 0.050728\n",
      "Train Epoch: 5 [10240/18580 (55%)]\tLoss: 0.023415\n",
      "Train Epoch: 5 [10880/18580 (58%)]\tLoss: 0.012308\n",
      "Train Epoch: 5 [11520/18580 (62%)]\tLoss: 0.020400\n",
      "Train Epoch: 5 [12160/18580 (65%)]\tLoss: 0.042633\n",
      "Train Epoch: 5 [12800/18580 (69%)]\tLoss: 0.021510\n",
      "Train Epoch: 5 [13440/18580 (72%)]\tLoss: 0.008177\n",
      "Train Epoch: 5 [14080/18580 (76%)]\tLoss: 0.089618\n",
      "Train Epoch: 5 [14720/18580 (79%)]\tLoss: 0.043273\n",
      "Train Epoch: 5 [15360/18580 (82%)]\tLoss: 0.057241\n",
      "Train Epoch: 5 [16000/18580 (86%)]\tLoss: 0.076494\n",
      "Train Epoch: 5 [16640/18580 (89%)]\tLoss: 0.044174\n",
      "Train Epoch: 5 [17280/18580 (93%)]\tLoss: 0.207297\n",
      "Train Epoch: 5 [17920/18580 (96%)]\tLoss: 0.007780\n",
      "Train Epoch: 5 [5800/18580 (100%)]\tLoss: 0.562781\n",
      "Train Epoch: 6 [0/18580 (0%)]\tLoss: 0.102055\n",
      "Train Epoch: 6 [640/18580 (3%)]\tLoss: 0.062167\n",
      "Train Epoch: 6 [1280/18580 (7%)]\tLoss: 0.015030\n",
      "Train Epoch: 6 [1920/18580 (10%)]\tLoss: 0.031921\n",
      "Train Epoch: 6 [2560/18580 (14%)]\tLoss: 0.004379\n",
      "Train Epoch: 6 [3200/18580 (17%)]\tLoss: 0.020233\n",
      "Train Epoch: 6 [3840/18580 (21%)]\tLoss: 0.008541\n",
      "Train Epoch: 6 [4480/18580 (24%)]\tLoss: 0.043805\n",
      "Train Epoch: 6 [5120/18580 (27%)]\tLoss: 0.018293\n",
      "Train Epoch: 6 [5760/18580 (31%)]\tLoss: 0.074554\n",
      "Train Epoch: 6 [6400/18580 (34%)]\tLoss: 0.023313\n",
      "Train Epoch: 6 [7040/18580 (38%)]\tLoss: 0.007091\n",
      "Train Epoch: 6 [7680/18580 (41%)]\tLoss: 0.138806\n",
      "Train Epoch: 6 [8320/18580 (45%)]\tLoss: 0.078870\n",
      "Train Epoch: 6 [8960/18580 (48%)]\tLoss: 0.010598\n",
      "Train Epoch: 6 [9600/18580 (52%)]\tLoss: 0.081688\n",
      "Train Epoch: 6 [10240/18580 (55%)]\tLoss: 0.147449\n",
      "Train Epoch: 6 [10880/18580 (58%)]\tLoss: 0.075765\n",
      "Train Epoch: 6 [11520/18580 (62%)]\tLoss: 0.031940\n",
      "Train Epoch: 6 [12160/18580 (65%)]\tLoss: 0.031935\n",
      "Train Epoch: 6 [12800/18580 (69%)]\tLoss: 0.005549\n",
      "Train Epoch: 6 [13440/18580 (72%)]\tLoss: 0.025257\n",
      "Train Epoch: 6 [14080/18580 (76%)]\tLoss: 0.047950\n",
      "Train Epoch: 6 [14720/18580 (79%)]\tLoss: 0.025381\n",
      "Train Epoch: 6 [15360/18580 (82%)]\tLoss: 0.007549\n",
      "Train Epoch: 6 [16000/18580 (86%)]\tLoss: 0.023124\n",
      "Train Epoch: 6 [16640/18580 (89%)]\tLoss: 0.023130\n",
      "Train Epoch: 6 [17280/18580 (93%)]\tLoss: 0.025280\n",
      "Train Epoch: 6 [17920/18580 (96%)]\tLoss: 0.067265\n",
      "Train Epoch: 6 [5800/18580 (100%)]\tLoss: 0.580599\n",
      "Train Epoch: 7 [0/18580 (0%)]\tLoss: 0.018099\n",
      "Train Epoch: 7 [640/18580 (3%)]\tLoss: 0.198882\n",
      "Train Epoch: 7 [1280/18580 (7%)]\tLoss: 0.023828\n",
      "Train Epoch: 7 [1920/18580 (10%)]\tLoss: 0.049795\n",
      "Train Epoch: 7 [2560/18580 (14%)]\tLoss: 0.201796\n",
      "Train Epoch: 7 [3200/18580 (17%)]\tLoss: 0.050815\n",
      "Train Epoch: 7 [3840/18580 (21%)]\tLoss: 0.027165\n",
      "Train Epoch: 7 [4480/18580 (24%)]\tLoss: 0.043356\n",
      "Train Epoch: 7 [5120/18580 (27%)]\tLoss: 0.021313\n",
      "Train Epoch: 7 [5760/18580 (31%)]\tLoss: 0.101884\n",
      "Train Epoch: 7 [6400/18580 (34%)]\tLoss: 0.048191\n",
      "Train Epoch: 7 [7040/18580 (38%)]\tLoss: 0.019316\n",
      "Train Epoch: 7 [7680/18580 (41%)]\tLoss: 0.048662\n",
      "Train Epoch: 7 [8320/18580 (45%)]\tLoss: 0.021530\n",
      "Train Epoch: 7 [8960/18580 (48%)]\tLoss: 0.008594\n",
      "Train Epoch: 7 [9600/18580 (52%)]\tLoss: 0.101321\n",
      "Train Epoch: 7 [10240/18580 (55%)]\tLoss: 0.063272\n",
      "Train Epoch: 7 [10880/18580 (58%)]\tLoss: 0.019380\n",
      "Train Epoch: 7 [11520/18580 (62%)]\tLoss: 0.011967\n",
      "Train Epoch: 7 [12160/18580 (65%)]\tLoss: 0.015963\n",
      "Train Epoch: 7 [12800/18580 (69%)]\tLoss: 0.083819\n",
      "Train Epoch: 7 [13440/18580 (72%)]\tLoss: 0.039422\n",
      "Train Epoch: 7 [14080/18580 (76%)]\tLoss: 0.165909\n",
      "Train Epoch: 7 [14720/18580 (79%)]\tLoss: 0.015655\n",
      "Train Epoch: 7 [15360/18580 (82%)]\tLoss: 0.140535\n",
      "Train Epoch: 7 [16000/18580 (86%)]\tLoss: 0.009542\n",
      "Train Epoch: 7 [16640/18580 (89%)]\tLoss: 0.009746\n",
      "Train Epoch: 7 [17280/18580 (93%)]\tLoss: 0.023676\n",
      "Train Epoch: 7 [17920/18580 (96%)]\tLoss: 0.038015\n",
      "Train Epoch: 7 [5800/18580 (100%)]\tLoss: 0.292859\n",
      "Train Epoch: 8 [0/18580 (0%)]\tLoss: 0.039746\n",
      "Train Epoch: 8 [640/18580 (3%)]\tLoss: 0.047545\n",
      "Train Epoch: 8 [1280/18580 (7%)]\tLoss: 0.022318\n",
      "Train Epoch: 8 [1920/18580 (10%)]\tLoss: 0.098935\n",
      "Train Epoch: 8 [2560/18580 (14%)]\tLoss: 0.058139\n",
      "Train Epoch: 8 [3200/18580 (17%)]\tLoss: 0.091913\n",
      "Train Epoch: 8 [3840/18580 (21%)]\tLoss: 0.086096\n",
      "Train Epoch: 8 [4480/18580 (24%)]\tLoss: 0.047087\n",
      "Train Epoch: 8 [5120/18580 (27%)]\tLoss: 0.049812\n",
      "Train Epoch: 8 [5760/18580 (31%)]\tLoss: 0.059138\n",
      "Train Epoch: 8 [6400/18580 (34%)]\tLoss: 0.015292\n",
      "Train Epoch: 8 [7040/18580 (38%)]\tLoss: 0.055895\n",
      "Train Epoch: 8 [7680/18580 (41%)]\tLoss: 0.002287\n",
      "Train Epoch: 8 [8320/18580 (45%)]\tLoss: 0.021268\n",
      "Train Epoch: 8 [8960/18580 (48%)]\tLoss: 0.008564\n",
      "Train Epoch: 8 [9600/18580 (52%)]\tLoss: 0.006180\n",
      "Train Epoch: 8 [10240/18580 (55%)]\tLoss: 0.015384\n",
      "Train Epoch: 8 [10880/18580 (58%)]\tLoss: 0.010370\n",
      "Train Epoch: 8 [11520/18580 (62%)]\tLoss: 0.020566\n",
      "Train Epoch: 8 [12160/18580 (65%)]\tLoss: 0.025871\n",
      "Train Epoch: 8 [12800/18580 (69%)]\tLoss: 0.028422\n",
      "Train Epoch: 8 [13440/18580 (72%)]\tLoss: 0.002926\n",
      "Train Epoch: 8 [14080/18580 (76%)]\tLoss: 0.076338\n",
      "Train Epoch: 8 [14720/18580 (79%)]\tLoss: 0.029992\n",
      "Train Epoch: 8 [15360/18580 (82%)]\tLoss: 0.029905\n",
      "Train Epoch: 8 [16000/18580 (86%)]\tLoss: 0.077859\n",
      "Train Epoch: 8 [16640/18580 (89%)]\tLoss: 0.012752\n",
      "Train Epoch: 8 [17280/18580 (93%)]\tLoss: 0.093810\n",
      "Train Epoch: 8 [17920/18580 (96%)]\tLoss: 0.138273\n",
      "Train Epoch: 8 [5800/18580 (100%)]\tLoss: 0.026102\n",
      "Train Epoch: 9 [0/18580 (0%)]\tLoss: 0.016044\n",
      "Train Epoch: 9 [640/18580 (3%)]\tLoss: 0.078919\n",
      "Train Epoch: 9 [1280/18580 (7%)]\tLoss: 0.004309\n",
      "Train Epoch: 9 [1920/18580 (10%)]\tLoss: 0.053587\n",
      "Train Epoch: 9 [2560/18580 (14%)]\tLoss: 0.007838\n",
      "Train Epoch: 9 [3200/18580 (17%)]\tLoss: 0.005295\n",
      "Train Epoch: 9 [3840/18580 (21%)]\tLoss: 0.014063\n",
      "Train Epoch: 9 [4480/18580 (24%)]\tLoss: 0.079770\n",
      "Train Epoch: 9 [5120/18580 (27%)]\tLoss: 0.010656\n",
      "Train Epoch: 9 [5760/18580 (31%)]\tLoss: 0.037975\n",
      "Train Epoch: 9 [6400/18580 (34%)]\tLoss: 0.099719\n",
      "Train Epoch: 9 [7040/18580 (38%)]\tLoss: 0.004291\n",
      "Train Epoch: 9 [7680/18580 (41%)]\tLoss: 0.052325\n",
      "Train Epoch: 9 [8320/18580 (45%)]\tLoss: 0.009381\n",
      "Train Epoch: 9 [8960/18580 (48%)]\tLoss: 0.133423\n",
      "Train Epoch: 9 [9600/18580 (52%)]\tLoss: 0.047418\n",
      "Train Epoch: 9 [10240/18580 (55%)]\tLoss: 0.026965\n",
      "Train Epoch: 9 [10880/18580 (58%)]\tLoss: 0.033975\n",
      "Train Epoch: 9 [11520/18580 (62%)]\tLoss: 0.014958\n",
      "Train Epoch: 9 [12160/18580 (65%)]\tLoss: 0.035097\n",
      "Train Epoch: 9 [12800/18580 (69%)]\tLoss: 0.007472\n",
      "Train Epoch: 9 [13440/18580 (72%)]\tLoss: 0.031343\n",
      "Train Epoch: 9 [14080/18580 (76%)]\tLoss: 0.010924\n",
      "Train Epoch: 9 [14720/18580 (79%)]\tLoss: 0.020534\n",
      "Train Epoch: 9 [15360/18580 (82%)]\tLoss: 0.005787\n",
      "Train Epoch: 9 [16000/18580 (86%)]\tLoss: 0.043044\n",
      "Train Epoch: 9 [16640/18580 (89%)]\tLoss: 0.027505\n",
      "Train Epoch: 9 [17280/18580 (93%)]\tLoss: 0.059008\n",
      "Train Epoch: 9 [17920/18580 (96%)]\tLoss: 0.018716\n",
      "Train Epoch: 9 [5800/18580 (100%)]\tLoss: 0.112911\n",
      "Train Epoch: 10 [0/18580 (0%)]\tLoss: 0.016741\n",
      "Train Epoch: 10 [640/18580 (3%)]\tLoss: 0.069171\n",
      "Train Epoch: 10 [1280/18580 (7%)]\tLoss: 0.018424\n",
      "Train Epoch: 10 [1920/18580 (10%)]\tLoss: 0.007368\n",
      "Train Epoch: 10 [2560/18580 (14%)]\tLoss: 0.030690\n",
      "Train Epoch: 10 [3200/18580 (17%)]\tLoss: 0.036904\n",
      "Train Epoch: 10 [3840/18580 (21%)]\tLoss: 0.009655\n",
      "Train Epoch: 10 [4480/18580 (24%)]\tLoss: 0.085303\n",
      "Train Epoch: 10 [5120/18580 (27%)]\tLoss: 0.027037\n",
      "Train Epoch: 10 [5760/18580 (31%)]\tLoss: 0.037847\n",
      "Train Epoch: 10 [6400/18580 (34%)]\tLoss: 0.007744\n",
      "Train Epoch: 10 [7040/18580 (38%)]\tLoss: 0.021519\n",
      "Train Epoch: 10 [7680/18580 (41%)]\tLoss: 0.004843\n",
      "Train Epoch: 10 [8320/18580 (45%)]\tLoss: 0.007184\n",
      "Train Epoch: 10 [8960/18580 (48%)]\tLoss: 0.052552\n",
      "Train Epoch: 10 [9600/18580 (52%)]\tLoss: 0.006219\n",
      "Train Epoch: 10 [10240/18580 (55%)]\tLoss: 0.008300\n",
      "Train Epoch: 10 [10880/18580 (58%)]\tLoss: 0.040205\n",
      "Train Epoch: 10 [11520/18580 (62%)]\tLoss: 0.169843\n",
      "Train Epoch: 10 [12160/18580 (65%)]\tLoss: 0.008357\n",
      "Train Epoch: 10 [12800/18580 (69%)]\tLoss: 0.046059\n",
      "Train Epoch: 10 [13440/18580 (72%)]\tLoss: 0.065002\n",
      "Train Epoch: 10 [14080/18580 (76%)]\tLoss: 0.073164\n",
      "Train Epoch: 10 [14720/18580 (79%)]\tLoss: 0.239163\n",
      "Train Epoch: 10 [15360/18580 (82%)]\tLoss: 0.020385\n",
      "Train Epoch: 10 [16000/18580 (86%)]\tLoss: 0.040110\n",
      "Train Epoch: 10 [16640/18580 (89%)]\tLoss: 0.016026\n",
      "Train Epoch: 10 [17280/18580 (93%)]\tLoss: 0.010173\n",
      "Train Epoch: 10 [17920/18580 (96%)]\tLoss: 0.000820\n",
      "Train Epoch: 10 [5800/18580 (100%)]\tLoss: 0.528512\n",
      "Training client 2\n",
      "Train Epoch: 1 [0/9043 (0%)]\tLoss: 1.678096\n",
      "Train Epoch: 1 [640/9043 (7%)]\tLoss: 0.467095\n",
      "Train Epoch: 1 [1280/9043 (14%)]\tLoss: 0.286455\n",
      "Train Epoch: 1 [1920/9043 (21%)]\tLoss: 0.522823\n",
      "Train Epoch: 1 [2560/9043 (28%)]\tLoss: 0.449910\n",
      "Train Epoch: 1 [3200/9043 (35%)]\tLoss: 0.474323\n",
      "Train Epoch: 1 [3840/9043 (42%)]\tLoss: 0.473643\n",
      "Train Epoch: 1 [4480/9043 (49%)]\tLoss: 0.377477\n",
      "Train Epoch: 1 [5120/9043 (56%)]\tLoss: 0.507378\n",
      "Train Epoch: 1 [5760/9043 (63%)]\tLoss: 0.366741\n",
      "Train Epoch: 1 [6400/9043 (70%)]\tLoss: 0.341354\n",
      "Train Epoch: 1 [7040/9043 (77%)]\tLoss: 0.333844\n",
      "Train Epoch: 1 [7680/9043 (85%)]\tLoss: 0.311356\n",
      "Train Epoch: 1 [8320/9043 (92%)]\tLoss: 0.097347\n",
      "Train Epoch: 1 [8960/9043 (99%)]\tLoss: 0.209999\n",
      "Train Epoch: 2 [0/9043 (0%)]\tLoss: 0.066047\n",
      "Train Epoch: 2 [640/9043 (7%)]\tLoss: 0.205554\n",
      "Train Epoch: 2 [1280/9043 (14%)]\tLoss: 0.132755\n",
      "Train Epoch: 2 [1920/9043 (21%)]\tLoss: 0.114359\n",
      "Train Epoch: 2 [2560/9043 (28%)]\tLoss: 0.256318\n",
      "Train Epoch: 2 [3200/9043 (35%)]\tLoss: 0.147517\n",
      "Train Epoch: 2 [3840/9043 (42%)]\tLoss: 0.073112\n",
      "Train Epoch: 2 [4480/9043 (49%)]\tLoss: 0.132090\n",
      "Train Epoch: 2 [5120/9043 (56%)]\tLoss: 0.109052\n",
      "Train Epoch: 2 [5760/9043 (63%)]\tLoss: 0.103349\n",
      "Train Epoch: 2 [6400/9043 (70%)]\tLoss: 0.097634\n",
      "Train Epoch: 2 [7040/9043 (77%)]\tLoss: 0.069129\n",
      "Train Epoch: 2 [7680/9043 (85%)]\tLoss: 0.195322\n",
      "Train Epoch: 2 [8320/9043 (92%)]\tLoss: 0.036680\n",
      "Train Epoch: 2 [8960/9043 (99%)]\tLoss: 0.057478\n",
      "Train Epoch: 3 [0/9043 (0%)]\tLoss: 0.075936\n",
      "Train Epoch: 3 [640/9043 (7%)]\tLoss: 0.087129\n",
      "Train Epoch: 3 [1280/9043 (14%)]\tLoss: 0.127334\n",
      "Train Epoch: 3 [1920/9043 (21%)]\tLoss: 0.039141\n",
      "Train Epoch: 3 [2560/9043 (28%)]\tLoss: 0.104892\n",
      "Train Epoch: 3 [3200/9043 (35%)]\tLoss: 0.139590\n",
      "Train Epoch: 3 [3840/9043 (42%)]\tLoss: 0.075248\n",
      "Train Epoch: 3 [4480/9043 (49%)]\tLoss: 0.033153\n",
      "Train Epoch: 3 [5120/9043 (56%)]\tLoss: 0.300537\n",
      "Train Epoch: 3 [5760/9043 (63%)]\tLoss: 0.025913\n",
      "Train Epoch: 3 [6400/9043 (70%)]\tLoss: 0.073258\n",
      "Train Epoch: 3 [7040/9043 (77%)]\tLoss: 0.086038\n",
      "Train Epoch: 3 [7680/9043 (85%)]\tLoss: 0.074895\n",
      "Train Epoch: 3 [8320/9043 (92%)]\tLoss: 0.059176\n",
      "Train Epoch: 3 [8960/9043 (99%)]\tLoss: 0.039543\n",
      "Train Epoch: 4 [0/9043 (0%)]\tLoss: 0.045546\n",
      "Train Epoch: 4 [640/9043 (7%)]\tLoss: 0.043452\n",
      "Train Epoch: 4 [1280/9043 (14%)]\tLoss: 0.077117\n",
      "Train Epoch: 4 [1920/9043 (21%)]\tLoss: 0.033124\n",
      "Train Epoch: 4 [2560/9043 (28%)]\tLoss: 0.046317\n",
      "Train Epoch: 4 [3200/9043 (35%)]\tLoss: 0.038774\n",
      "Train Epoch: 4 [3840/9043 (42%)]\tLoss: 0.032250\n",
      "Train Epoch: 4 [4480/9043 (49%)]\tLoss: 0.050021\n",
      "Train Epoch: 4 [5120/9043 (56%)]\tLoss: 0.006042\n",
      "Train Epoch: 4 [5760/9043 (63%)]\tLoss: 0.093866\n",
      "Train Epoch: 4 [6400/9043 (70%)]\tLoss: 0.036164\n",
      "Train Epoch: 4 [7040/9043 (77%)]\tLoss: 0.091985\n",
      "Train Epoch: 4 [7680/9043 (85%)]\tLoss: 0.044942\n",
      "Train Epoch: 4 [8320/9043 (92%)]\tLoss: 0.014333\n",
      "Train Epoch: 4 [8960/9043 (99%)]\tLoss: 0.063826\n",
      "Train Epoch: 5 [0/9043 (0%)]\tLoss: 0.027219\n",
      "Train Epoch: 5 [640/9043 (7%)]\tLoss: 0.124124\n",
      "Train Epoch: 5 [1280/9043 (14%)]\tLoss: 0.109152\n",
      "Train Epoch: 5 [1920/9043 (21%)]\tLoss: 0.076885\n",
      "Train Epoch: 5 [2560/9043 (28%)]\tLoss: 0.068880\n",
      "Train Epoch: 5 [3200/9043 (35%)]\tLoss: 0.083128\n",
      "Train Epoch: 5 [3840/9043 (42%)]\tLoss: 0.035444\n",
      "Train Epoch: 5 [4480/9043 (49%)]\tLoss: 0.006987\n",
      "Train Epoch: 5 [5120/9043 (56%)]\tLoss: 0.014017\n",
      "Train Epoch: 5 [5760/9043 (63%)]\tLoss: 0.087671\n",
      "Train Epoch: 5 [6400/9043 (70%)]\tLoss: 0.041962\n",
      "Train Epoch: 5 [7040/9043 (77%)]\tLoss: 0.055305\n",
      "Train Epoch: 5 [7680/9043 (85%)]\tLoss: 0.069926\n",
      "Train Epoch: 5 [8320/9043 (92%)]\tLoss: 0.048473\n",
      "Train Epoch: 5 [8960/9043 (99%)]\tLoss: 0.160411\n",
      "Train Epoch: 6 [0/9043 (0%)]\tLoss: 0.105664\n",
      "Train Epoch: 6 [640/9043 (7%)]\tLoss: 0.066042\n",
      "Train Epoch: 6 [1280/9043 (14%)]\tLoss: 0.005299\n",
      "Train Epoch: 6 [1920/9043 (21%)]\tLoss: 0.054583\n",
      "Train Epoch: 6 [2560/9043 (28%)]\tLoss: 0.056914\n",
      "Train Epoch: 6 [3200/9043 (35%)]\tLoss: 0.021794\n",
      "Train Epoch: 6 [3840/9043 (42%)]\tLoss: 0.017024\n",
      "Train Epoch: 6 [4480/9043 (49%)]\tLoss: 0.084824\n",
      "Train Epoch: 6 [5120/9043 (56%)]\tLoss: 0.013460\n",
      "Train Epoch: 6 [5760/9043 (63%)]\tLoss: 0.012961\n",
      "Train Epoch: 6 [6400/9043 (70%)]\tLoss: 0.016027\n",
      "Train Epoch: 6 [7040/9043 (77%)]\tLoss: 0.049681\n",
      "Train Epoch: 6 [7680/9043 (85%)]\tLoss: 0.017588\n",
      "Train Epoch: 6 [8320/9043 (92%)]\tLoss: 0.032413\n",
      "Train Epoch: 6 [8960/9043 (99%)]\tLoss: 0.128638\n",
      "Train Epoch: 7 [0/9043 (0%)]\tLoss: 0.084943\n",
      "Train Epoch: 7 [640/9043 (7%)]\tLoss: 0.040796\n",
      "Train Epoch: 7 [1280/9043 (14%)]\tLoss: 0.015130\n",
      "Train Epoch: 7 [1920/9043 (21%)]\tLoss: 0.022324\n",
      "Train Epoch: 7 [2560/9043 (28%)]\tLoss: 0.036040\n",
      "Train Epoch: 7 [3200/9043 (35%)]\tLoss: 0.032290\n",
      "Train Epoch: 7 [3840/9043 (42%)]\tLoss: 0.039919\n",
      "Train Epoch: 7 [4480/9043 (49%)]\tLoss: 0.030392\n",
      "Train Epoch: 7 [5120/9043 (56%)]\tLoss: 0.015801\n",
      "Train Epoch: 7 [5760/9043 (63%)]\tLoss: 0.060306\n",
      "Train Epoch: 7 [6400/9043 (70%)]\tLoss: 0.034857\n",
      "Train Epoch: 7 [7040/9043 (77%)]\tLoss: 0.061936\n",
      "Train Epoch: 7 [7680/9043 (85%)]\tLoss: 0.021427\n",
      "Train Epoch: 7 [8320/9043 (92%)]\tLoss: 0.017386\n",
      "Train Epoch: 7 [8960/9043 (99%)]\tLoss: 0.016196\n",
      "Train Epoch: 8 [0/9043 (0%)]\tLoss: 0.062420\n",
      "Train Epoch: 8 [640/9043 (7%)]\tLoss: 0.101110\n",
      "Train Epoch: 8 [1280/9043 (14%)]\tLoss: 0.025221\n",
      "Train Epoch: 8 [1920/9043 (21%)]\tLoss: 0.032521\n",
      "Train Epoch: 8 [2560/9043 (28%)]\tLoss: 0.019218\n",
      "Train Epoch: 8 [3200/9043 (35%)]\tLoss: 0.035923\n",
      "Train Epoch: 8 [3840/9043 (42%)]\tLoss: 0.025099\n",
      "Train Epoch: 8 [4480/9043 (49%)]\tLoss: 0.030021\n",
      "Train Epoch: 8 [5120/9043 (56%)]\tLoss: 0.003192\n",
      "Train Epoch: 8 [5760/9043 (63%)]\tLoss: 0.040721\n",
      "Train Epoch: 8 [6400/9043 (70%)]\tLoss: 0.016859\n",
      "Train Epoch: 8 [7040/9043 (77%)]\tLoss: 0.027601\n",
      "Train Epoch: 8 [7680/9043 (85%)]\tLoss: 0.025674\n",
      "Train Epoch: 8 [8320/9043 (92%)]\tLoss: 0.017316\n",
      "Train Epoch: 8 [8960/9043 (99%)]\tLoss: 0.046530\n",
      "Train Epoch: 9 [0/9043 (0%)]\tLoss: 0.042104\n",
      "Train Epoch: 9 [640/9043 (7%)]\tLoss: 0.006014\n",
      "Train Epoch: 9 [1280/9043 (14%)]\tLoss: 0.007647\n",
      "Train Epoch: 9 [1920/9043 (21%)]\tLoss: 0.011653\n",
      "Train Epoch: 9 [2560/9043 (28%)]\tLoss: 0.021909\n",
      "Train Epoch: 9 [3200/9043 (35%)]\tLoss: 0.040425\n",
      "Train Epoch: 9 [3840/9043 (42%)]\tLoss: 0.026577\n",
      "Train Epoch: 9 [4480/9043 (49%)]\tLoss: 0.071624\n",
      "Train Epoch: 9 [5120/9043 (56%)]\tLoss: 0.003459\n",
      "Train Epoch: 9 [5760/9043 (63%)]\tLoss: 0.004560\n",
      "Train Epoch: 9 [6400/9043 (70%)]\tLoss: 0.003231\n",
      "Train Epoch: 9 [7040/9043 (77%)]\tLoss: 0.043271\n",
      "Train Epoch: 9 [7680/9043 (85%)]\tLoss: 0.035688\n",
      "Train Epoch: 9 [8320/9043 (92%)]\tLoss: 0.030640\n",
      "Train Epoch: 9 [8960/9043 (99%)]\tLoss: 0.010922\n",
      "Train Epoch: 10 [0/9043 (0%)]\tLoss: 0.005399\n",
      "Train Epoch: 10 [640/9043 (7%)]\tLoss: 0.010696\n",
      "Train Epoch: 10 [1280/9043 (14%)]\tLoss: 0.062929\n",
      "Train Epoch: 10 [1920/9043 (21%)]\tLoss: 0.027690\n",
      "Train Epoch: 10 [2560/9043 (28%)]\tLoss: 0.018178\n",
      "Train Epoch: 10 [3200/9043 (35%)]\tLoss: 0.037045\n",
      "Train Epoch: 10 [3840/9043 (42%)]\tLoss: 0.030830\n",
      "Train Epoch: 10 [4480/9043 (49%)]\tLoss: 0.023355\n",
      "Train Epoch: 10 [5120/9043 (56%)]\tLoss: 0.206963\n",
      "Train Epoch: 10 [5760/9043 (63%)]\tLoss: 0.037734\n",
      "Train Epoch: 10 [6400/9043 (70%)]\tLoss: 0.016549\n",
      "Train Epoch: 10 [7040/9043 (77%)]\tLoss: 0.050517\n",
      "Train Epoch: 10 [7680/9043 (85%)]\tLoss: 0.074109\n",
      "Train Epoch: 10 [8320/9043 (92%)]\tLoss: 0.013955\n",
      "Train Epoch: 10 [8960/9043 (99%)]\tLoss: 0.006302\n",
      "Training client 3\n",
      "Train Epoch: 1 [0/14723 (0%)]\tLoss: 0.596768\n",
      "Train Epoch: 1 [640/14723 (4%)]\tLoss: 0.376935\n",
      "Train Epoch: 1 [1280/14723 (9%)]\tLoss: 0.368090\n",
      "Train Epoch: 1 [1920/14723 (13%)]\tLoss: 0.412915\n",
      "Train Epoch: 1 [2560/14723 (17%)]\tLoss: 0.444602\n",
      "Train Epoch: 1 [3200/14723 (22%)]\tLoss: 0.365405\n",
      "Train Epoch: 1 [3840/14723 (26%)]\tLoss: 0.447119\n",
      "Train Epoch: 1 [4480/14723 (30%)]\tLoss: 0.380607\n",
      "Train Epoch: 1 [5120/14723 (35%)]\tLoss: 0.260179\n",
      "Train Epoch: 1 [5760/14723 (39%)]\tLoss: 0.219845\n",
      "Train Epoch: 1 [6400/14723 (43%)]\tLoss: 0.330531\n",
      "Train Epoch: 1 [7040/14723 (48%)]\tLoss: 0.513938\n",
      "Train Epoch: 1 [7680/14723 (52%)]\tLoss: 0.550743\n",
      "Train Epoch: 1 [8320/14723 (56%)]\tLoss: 0.387692\n",
      "Train Epoch: 1 [8960/14723 (61%)]\tLoss: 0.526104\n",
      "Train Epoch: 1 [9600/14723 (65%)]\tLoss: 0.323446\n",
      "Train Epoch: 1 [10240/14723 (69%)]\tLoss: 0.588449\n",
      "Train Epoch: 1 [10880/14723 (74%)]\tLoss: 0.226860\n",
      "Train Epoch: 1 [11520/14723 (78%)]\tLoss: 0.341274\n",
      "Train Epoch: 1 [12160/14723 (82%)]\tLoss: 0.403631\n",
      "Train Epoch: 1 [12800/14723 (87%)]\tLoss: 0.324050\n",
      "Train Epoch: 1 [13440/14723 (91%)]\tLoss: 0.302461\n",
      "Train Epoch: 1 [14080/14723 (95%)]\tLoss: 0.458107\n",
      "Train Epoch: 1 [690/14723 (100%)]\tLoss: 5.516406\n",
      "Train Epoch: 2 [0/14723 (0%)]\tLoss: 1.392415\n",
      "Train Epoch: 2 [640/14723 (4%)]\tLoss: 0.931631\n",
      "Train Epoch: 2 [1280/14723 (9%)]\tLoss: 0.850616\n",
      "Train Epoch: 2 [1920/14723 (13%)]\tLoss: 0.992947\n",
      "Train Epoch: 2 [2560/14723 (17%)]\tLoss: 0.922759\n",
      "Train Epoch: 2 [3200/14723 (22%)]\tLoss: 0.768302\n",
      "Train Epoch: 2 [3840/14723 (26%)]\tLoss: 0.739794\n",
      "Train Epoch: 2 [4480/14723 (30%)]\tLoss: 0.619620\n",
      "Train Epoch: 2 [5120/14723 (35%)]\tLoss: 0.784038\n",
      "Train Epoch: 2 [5760/14723 (39%)]\tLoss: 0.738238\n",
      "Train Epoch: 2 [6400/14723 (43%)]\tLoss: 0.667642\n",
      "Train Epoch: 2 [7040/14723 (48%)]\tLoss: 0.622828\n",
      "Train Epoch: 2 [7680/14723 (52%)]\tLoss: 0.845921\n",
      "Train Epoch: 2 [8320/14723 (56%)]\tLoss: 0.589619\n",
      "Train Epoch: 2 [8960/14723 (61%)]\tLoss: 0.532345\n",
      "Train Epoch: 2 [9600/14723 (65%)]\tLoss: 0.700470\n",
      "Train Epoch: 2 [10240/14723 (69%)]\tLoss: 0.573068\n",
      "Train Epoch: 2 [10880/14723 (74%)]\tLoss: 0.422243\n",
      "Train Epoch: 2 [11520/14723 (78%)]\tLoss: 0.776769\n",
      "Train Epoch: 2 [12160/14723 (82%)]\tLoss: 0.530545\n",
      "Train Epoch: 2 [12800/14723 (87%)]\tLoss: 0.785441\n",
      "Train Epoch: 2 [13440/14723 (91%)]\tLoss: 0.373396\n",
      "Train Epoch: 2 [14080/14723 (95%)]\tLoss: 0.508613\n",
      "Train Epoch: 2 [690/14723 (100%)]\tLoss: 0.442240\n",
      "Train Epoch: 3 [0/14723 (0%)]\tLoss: 0.517612\n",
      "Train Epoch: 3 [640/14723 (4%)]\tLoss: 0.449855\n",
      "Train Epoch: 3 [1280/14723 (9%)]\tLoss: 0.572806\n",
      "Train Epoch: 3 [1920/14723 (13%)]\tLoss: 0.560426\n",
      "Train Epoch: 3 [2560/14723 (17%)]\tLoss: 0.309705\n",
      "Train Epoch: 3 [3200/14723 (22%)]\tLoss: 0.676720\n",
      "Train Epoch: 3 [3840/14723 (26%)]\tLoss: 0.367088\n",
      "Train Epoch: 3 [4480/14723 (30%)]\tLoss: 0.417382\n",
      "Train Epoch: 3 [5120/14723 (35%)]\tLoss: 0.273968\n",
      "Train Epoch: 3 [5760/14723 (39%)]\tLoss: 0.354904\n",
      "Train Epoch: 3 [6400/14723 (43%)]\tLoss: 0.339130\n",
      "Train Epoch: 3 [7040/14723 (48%)]\tLoss: 0.379871\n",
      "Train Epoch: 3 [7680/14723 (52%)]\tLoss: 0.219124\n",
      "Train Epoch: 3 [8320/14723 (56%)]\tLoss: 0.496348\n",
      "Train Epoch: 3 [8960/14723 (61%)]\tLoss: 0.651120\n",
      "Train Epoch: 3 [9600/14723 (65%)]\tLoss: 0.271543\n",
      "Train Epoch: 3 [10240/14723 (69%)]\tLoss: 0.407259\n",
      "Train Epoch: 3 [10880/14723 (74%)]\tLoss: 0.500343\n",
      "Train Epoch: 3 [11520/14723 (78%)]\tLoss: 0.827183\n",
      "Train Epoch: 3 [12160/14723 (82%)]\tLoss: 0.393340\n",
      "Train Epoch: 3 [12800/14723 (87%)]\tLoss: 0.294677\n",
      "Train Epoch: 3 [13440/14723 (91%)]\tLoss: 0.437746\n",
      "Train Epoch: 3 [14080/14723 (95%)]\tLoss: 0.481559\n",
      "Train Epoch: 3 [690/14723 (100%)]\tLoss: 1.251782\n",
      "Train Epoch: 4 [0/14723 (0%)]\tLoss: 0.311069\n",
      "Train Epoch: 4 [640/14723 (4%)]\tLoss: 0.566746\n",
      "Train Epoch: 4 [1280/14723 (9%)]\tLoss: 0.324250\n",
      "Train Epoch: 4 [1920/14723 (13%)]\tLoss: 0.224421\n",
      "Train Epoch: 4 [2560/14723 (17%)]\tLoss: 0.211903\n",
      "Train Epoch: 4 [3200/14723 (22%)]\tLoss: 0.230549\n",
      "Train Epoch: 4 [3840/14723 (26%)]\tLoss: 0.263944\n",
      "Train Epoch: 4 [4480/14723 (30%)]\tLoss: 0.266945\n",
      "Train Epoch: 4 [5120/14723 (35%)]\tLoss: 0.260312\n",
      "Train Epoch: 4 [5760/14723 (39%)]\tLoss: 0.174434\n",
      "Train Epoch: 4 [6400/14723 (43%)]\tLoss: 0.400113\n",
      "Train Epoch: 4 [7040/14723 (48%)]\tLoss: 0.136494\n",
      "Train Epoch: 4 [7680/14723 (52%)]\tLoss: 0.476186\n",
      "Train Epoch: 4 [8320/14723 (56%)]\tLoss: 0.174088\n",
      "Train Epoch: 4 [8960/14723 (61%)]\tLoss: 0.254912\n",
      "Train Epoch: 4 [9600/14723 (65%)]\tLoss: 0.185028\n",
      "Train Epoch: 4 [10240/14723 (69%)]\tLoss: 0.405609\n",
      "Train Epoch: 4 [10880/14723 (74%)]\tLoss: 0.236551\n",
      "Train Epoch: 4 [11520/14723 (78%)]\tLoss: 0.428612\n",
      "Train Epoch: 4 [12160/14723 (82%)]\tLoss: 0.244165\n",
      "Train Epoch: 4 [12800/14723 (87%)]\tLoss: 0.222107\n",
      "Train Epoch: 4 [13440/14723 (91%)]\tLoss: 0.324744\n",
      "Train Epoch: 4 [14080/14723 (95%)]\tLoss: 0.139963\n",
      "Train Epoch: 4 [690/14723 (100%)]\tLoss: 1.902632\n",
      "Train Epoch: 5 [0/14723 (0%)]\tLoss: 2.358793\n",
      "Train Epoch: 5 [640/14723 (4%)]\tLoss: 1.376604\n",
      "Train Epoch: 5 [1280/14723 (9%)]\tLoss: 1.414664\n",
      "Train Epoch: 5 [1920/14723 (13%)]\tLoss: 1.198882\n",
      "Train Epoch: 5 [2560/14723 (17%)]\tLoss: 1.250600\n",
      "Train Epoch: 5 [3200/14723 (22%)]\tLoss: 1.166392\n",
      "Train Epoch: 5 [3840/14723 (26%)]\tLoss: 1.193064\n",
      "Train Epoch: 5 [4480/14723 (30%)]\tLoss: 1.252687\n",
      "Train Epoch: 5 [5120/14723 (35%)]\tLoss: 0.897611\n",
      "Train Epoch: 5 [5760/14723 (39%)]\tLoss: 1.289273\n",
      "Train Epoch: 5 [6400/14723 (43%)]\tLoss: 0.889141\n",
      "Train Epoch: 5 [7040/14723 (48%)]\tLoss: 0.967251\n",
      "Train Epoch: 5 [7680/14723 (52%)]\tLoss: 0.991913\n",
      "Train Epoch: 5 [8320/14723 (56%)]\tLoss: 0.995026\n",
      "Train Epoch: 5 [8960/14723 (61%)]\tLoss: 0.713622\n",
      "Train Epoch: 5 [9600/14723 (65%)]\tLoss: 0.804941\n",
      "Train Epoch: 5 [10240/14723 (69%)]\tLoss: 0.786969\n",
      "Train Epoch: 5 [10880/14723 (74%)]\tLoss: 0.780122\n",
      "Train Epoch: 5 [11520/14723 (78%)]\tLoss: 0.652982\n",
      "Train Epoch: 5 [12160/14723 (82%)]\tLoss: 0.780794\n",
      "Train Epoch: 5 [12800/14723 (87%)]\tLoss: 0.763355\n",
      "Train Epoch: 5 [13440/14723 (91%)]\tLoss: 0.750416\n",
      "Train Epoch: 5 [14080/14723 (95%)]\tLoss: 0.887387\n",
      "Train Epoch: 5 [690/14723 (100%)]\tLoss: 1.008418\n",
      "Train Epoch: 6 [0/14723 (0%)]\tLoss: 1.433679\n",
      "Train Epoch: 6 [640/14723 (4%)]\tLoss: 1.009716\n",
      "Train Epoch: 6 [1280/14723 (9%)]\tLoss: 0.764969\n",
      "Train Epoch: 6 [1920/14723 (13%)]\tLoss: 0.794712\n",
      "Train Epoch: 6 [2560/14723 (17%)]\tLoss: 0.731029\n",
      "Train Epoch: 6 [3200/14723 (22%)]\tLoss: 0.684014\n",
      "Train Epoch: 6 [3840/14723 (26%)]\tLoss: 0.878371\n",
      "Train Epoch: 6 [4480/14723 (30%)]\tLoss: 0.496904\n",
      "Train Epoch: 6 [5120/14723 (35%)]\tLoss: 0.746729\n",
      "Train Epoch: 6 [5760/14723 (39%)]\tLoss: 0.667480\n",
      "Train Epoch: 6 [6400/14723 (43%)]\tLoss: 0.614375\n",
      "Train Epoch: 6 [7040/14723 (48%)]\tLoss: 0.651103\n",
      "Train Epoch: 6 [7680/14723 (52%)]\tLoss: 0.652390\n",
      "Train Epoch: 6 [8320/14723 (56%)]\tLoss: 0.857005\n",
      "Train Epoch: 6 [8960/14723 (61%)]\tLoss: 0.643535\n",
      "Train Epoch: 6 [9600/14723 (65%)]\tLoss: 0.680892\n",
      "Train Epoch: 6 [10240/14723 (69%)]\tLoss: 0.443970\n",
      "Train Epoch: 6 [10880/14723 (74%)]\tLoss: 0.541330\n",
      "Train Epoch: 6 [11520/14723 (78%)]\tLoss: 0.558121\n",
      "Train Epoch: 6 [12160/14723 (82%)]\tLoss: 0.467012\n",
      "Train Epoch: 6 [12800/14723 (87%)]\tLoss: 0.561945\n",
      "Train Epoch: 6 [13440/14723 (91%)]\tLoss: 0.500653\n",
      "Train Epoch: 6 [14080/14723 (95%)]\tLoss: 0.600601\n",
      "Train Epoch: 6 [690/14723 (100%)]\tLoss: 1.765944\n",
      "Train Epoch: 7 [0/14723 (0%)]\tLoss: 1.523152\n",
      "Train Epoch: 7 [640/14723 (4%)]\tLoss: 1.350342\n",
      "Train Epoch: 7 [1280/14723 (9%)]\tLoss: 0.948524\n",
      "Train Epoch: 7 [1920/14723 (13%)]\tLoss: 0.861691\n",
      "Train Epoch: 7 [2560/14723 (17%)]\tLoss: 0.703287\n",
      "Train Epoch: 7 [3200/14723 (22%)]\tLoss: 0.707096\n",
      "Train Epoch: 7 [3840/14723 (26%)]\tLoss: 0.697265\n",
      "Train Epoch: 7 [4480/14723 (30%)]\tLoss: 0.490189\n",
      "Train Epoch: 7 [5120/14723 (35%)]\tLoss: 0.572525\n",
      "Train Epoch: 7 [5760/14723 (39%)]\tLoss: 0.690944\n",
      "Train Epoch: 7 [6400/14723 (43%)]\tLoss: 0.869714\n",
      "Train Epoch: 7 [7040/14723 (48%)]\tLoss: 0.439768\n",
      "Train Epoch: 7 [7680/14723 (52%)]\tLoss: 0.675028\n",
      "Train Epoch: 7 [8320/14723 (56%)]\tLoss: 0.590552\n",
      "Train Epoch: 7 [8960/14723 (61%)]\tLoss: 0.559226\n",
      "Train Epoch: 7 [9600/14723 (65%)]\tLoss: 0.524169\n",
      "Train Epoch: 7 [10240/14723 (69%)]\tLoss: 0.528489\n",
      "Train Epoch: 7 [10880/14723 (74%)]\tLoss: 0.749028\n",
      "Train Epoch: 7 [11520/14723 (78%)]\tLoss: 0.581518\n",
      "Train Epoch: 7 [12160/14723 (82%)]\tLoss: 0.610690\n",
      "Train Epoch: 7 [12800/14723 (87%)]\tLoss: 0.525720\n",
      "Train Epoch: 7 [13440/14723 (91%)]\tLoss: 0.445211\n",
      "Train Epoch: 7 [14080/14723 (95%)]\tLoss: 0.473761\n",
      "Train Epoch: 7 [690/14723 (100%)]\tLoss: 2.114317\n",
      "Train Epoch: 8 [0/14723 (0%)]\tLoss: 0.351443\n",
      "Train Epoch: 8 [640/14723 (4%)]\tLoss: 0.431738\n",
      "Train Epoch: 8 [1280/14723 (9%)]\tLoss: 0.552716\n",
      "Train Epoch: 8 [1920/14723 (13%)]\tLoss: 0.573911\n",
      "Train Epoch: 8 [2560/14723 (17%)]\tLoss: 0.549551\n",
      "Train Epoch: 8 [3200/14723 (22%)]\tLoss: 0.449820\n",
      "Train Epoch: 8 [3840/14723 (26%)]\tLoss: 0.380093\n",
      "Train Epoch: 8 [4480/14723 (30%)]\tLoss: 0.546189\n",
      "Train Epoch: 8 [5120/14723 (35%)]\tLoss: 0.389285\n",
      "Train Epoch: 8 [5760/14723 (39%)]\tLoss: 0.396235\n",
      "Train Epoch: 8 [6400/14723 (43%)]\tLoss: 0.373109\n",
      "Train Epoch: 8 [7040/14723 (48%)]\tLoss: 0.227415\n",
      "Train Epoch: 8 [7680/14723 (52%)]\tLoss: 0.328278\n",
      "Train Epoch: 8 [8320/14723 (56%)]\tLoss: 0.417425\n",
      "Train Epoch: 8 [8960/14723 (61%)]\tLoss: 0.440842\n",
      "Train Epoch: 8 [9600/14723 (65%)]\tLoss: 0.514336\n",
      "Train Epoch: 8 [10240/14723 (69%)]\tLoss: 0.384534\n",
      "Train Epoch: 8 [10880/14723 (74%)]\tLoss: 0.302328\n",
      "Train Epoch: 8 [11520/14723 (78%)]\tLoss: 0.692302\n",
      "Train Epoch: 8 [12160/14723 (82%)]\tLoss: 0.398676\n",
      "Train Epoch: 8 [12800/14723 (87%)]\tLoss: 0.366923\n",
      "Train Epoch: 8 [13440/14723 (91%)]\tLoss: 0.340262\n",
      "Train Epoch: 8 [14080/14723 (95%)]\tLoss: 0.305304\n",
      "Train Epoch: 8 [690/14723 (100%)]\tLoss: 3.502962\n",
      "Train Epoch: 9 [0/14723 (0%)]\tLoss: 2.429663\n",
      "Train Epoch: 9 [640/14723 (4%)]\tLoss: 2.001550\n",
      "Train Epoch: 9 [1280/14723 (9%)]\tLoss: 1.598969\n",
      "Train Epoch: 9 [1920/14723 (13%)]\tLoss: 1.285735\n",
      "Train Epoch: 9 [2560/14723 (17%)]\tLoss: 1.189132\n",
      "Train Epoch: 9 [3200/14723 (22%)]\tLoss: 1.463701\n",
      "Train Epoch: 9 [3840/14723 (26%)]\tLoss: 1.024514\n",
      "Train Epoch: 9 [4480/14723 (30%)]\tLoss: 1.281571\n",
      "Train Epoch: 9 [5120/14723 (35%)]\tLoss: 1.189510\n",
      "Train Epoch: 9 [5760/14723 (39%)]\tLoss: 1.239212\n",
      "Train Epoch: 9 [6400/14723 (43%)]\tLoss: 1.048590\n",
      "Train Epoch: 9 [7040/14723 (48%)]\tLoss: 1.056793\n",
      "Train Epoch: 9 [7680/14723 (52%)]\tLoss: 1.210708\n",
      "Train Epoch: 9 [8320/14723 (56%)]\tLoss: 1.250134\n",
      "Train Epoch: 9 [8960/14723 (61%)]\tLoss: 1.293349\n",
      "Train Epoch: 9 [9600/14723 (65%)]\tLoss: 1.037626\n",
      "Train Epoch: 9 [10240/14723 (69%)]\tLoss: 1.207175\n",
      "Train Epoch: 9 [10880/14723 (74%)]\tLoss: 1.192857\n",
      "Train Epoch: 9 [11520/14723 (78%)]\tLoss: 1.127560\n",
      "Train Epoch: 9 [12160/14723 (82%)]\tLoss: 1.320937\n",
      "Train Epoch: 9 [12800/14723 (87%)]\tLoss: 1.059622\n",
      "Train Epoch: 9 [13440/14723 (91%)]\tLoss: 1.245196\n",
      "Train Epoch: 9 [14080/14723 (95%)]\tLoss: 0.849807\n",
      "Train Epoch: 9 [690/14723 (100%)]\tLoss: 1.555243\n",
      "Train Epoch: 10 [0/14723 (0%)]\tLoss: 1.106984\n",
      "Train Epoch: 10 [640/14723 (4%)]\tLoss: 1.039802\n",
      "Train Epoch: 10 [1280/14723 (9%)]\tLoss: 0.936464\n",
      "Train Epoch: 10 [1920/14723 (13%)]\tLoss: 0.852081\n",
      "Train Epoch: 10 [2560/14723 (17%)]\tLoss: 0.785001\n",
      "Train Epoch: 10 [3200/14723 (22%)]\tLoss: 1.069062\n",
      "Train Epoch: 10 [3840/14723 (26%)]\tLoss: 1.207678\n",
      "Train Epoch: 10 [4480/14723 (30%)]\tLoss: 0.965230\n",
      "Train Epoch: 10 [5120/14723 (35%)]\tLoss: 1.008582\n",
      "Train Epoch: 10 [5760/14723 (39%)]\tLoss: 0.986881\n",
      "Train Epoch: 10 [6400/14723 (43%)]\tLoss: 0.915962\n",
      "Train Epoch: 10 [7040/14723 (48%)]\tLoss: 0.806777\n",
      "Train Epoch: 10 [7680/14723 (52%)]\tLoss: 0.932564\n",
      "Train Epoch: 10 [8320/14723 (56%)]\tLoss: 0.871135\n",
      "Train Epoch: 10 [8960/14723 (61%)]\tLoss: 0.708877\n",
      "Train Epoch: 10 [9600/14723 (65%)]\tLoss: 0.958394\n",
      "Train Epoch: 10 [10240/14723 (69%)]\tLoss: 0.702637\n",
      "Train Epoch: 10 [10880/14723 (74%)]\tLoss: 0.703280\n",
      "Train Epoch: 10 [11520/14723 (78%)]\tLoss: 0.765239\n",
      "Train Epoch: 10 [12160/14723 (82%)]\tLoss: 0.884672\n",
      "Train Epoch: 10 [12800/14723 (87%)]\tLoss: 0.856353\n",
      "Train Epoch: 10 [13440/14723 (91%)]\tLoss: 0.747269\n",
      "Train Epoch: 10 [14080/14723 (95%)]\tLoss: 0.712794\n",
      "Train Epoch: 10 [690/14723 (100%)]\tLoss: 0.144263\n",
      "Training client 4\n",
      "Train Epoch: 1 [0/7654 (0%)]\tLoss: 2.221660\n",
      "Train Epoch: 1 [640/7654 (8%)]\tLoss: 0.333371\n",
      "Train Epoch: 1 [1280/7654 (17%)]\tLoss: 0.205181\n",
      "Train Epoch: 1 [1920/7654 (25%)]\tLoss: 0.297555\n",
      "Train Epoch: 1 [2560/7654 (33%)]\tLoss: 0.355380\n",
      "Train Epoch: 1 [3200/7654 (42%)]\tLoss: 0.508745\n",
      "Train Epoch: 1 [3840/7654 (50%)]\tLoss: 0.172385\n",
      "Train Epoch: 1 [4480/7654 (58%)]\tLoss: 0.142279\n",
      "Train Epoch: 1 [5120/7654 (67%)]\tLoss: 0.204954\n",
      "Train Epoch: 1 [5760/7654 (75%)]\tLoss: 0.318408\n",
      "Train Epoch: 1 [6400/7654 (83%)]\tLoss: 0.234164\n",
      "Train Epoch: 1 [7040/7654 (92%)]\tLoss: 0.380068\n",
      "Train Epoch: 2 [0/7654 (0%)]\tLoss: 0.094474\n",
      "Train Epoch: 2 [640/7654 (8%)]\tLoss: 0.090901\n",
      "Train Epoch: 2 [1280/7654 (17%)]\tLoss: 0.049904\n",
      "Train Epoch: 2 [1920/7654 (25%)]\tLoss: 0.064672\n",
      "Train Epoch: 2 [2560/7654 (33%)]\tLoss: 0.028575\n",
      "Train Epoch: 2 [3200/7654 (42%)]\tLoss: 0.074066\n",
      "Train Epoch: 2 [3840/7654 (50%)]\tLoss: 0.062409\n",
      "Train Epoch: 2 [4480/7654 (58%)]\tLoss: 0.071175\n",
      "Train Epoch: 2 [5120/7654 (67%)]\tLoss: 0.053784\n",
      "Train Epoch: 2 [5760/7654 (75%)]\tLoss: 0.011018\n",
      "Train Epoch: 2 [6400/7654 (83%)]\tLoss: 0.097342\n",
      "Train Epoch: 2 [7040/7654 (92%)]\tLoss: 0.044116\n",
      "Train Epoch: 3 [0/7654 (0%)]\tLoss: 0.009531\n",
      "Train Epoch: 3 [640/7654 (8%)]\tLoss: 0.030254\n",
      "Train Epoch: 3 [1280/7654 (17%)]\tLoss: 0.021222\n",
      "Train Epoch: 3 [1920/7654 (25%)]\tLoss: 0.104624\n",
      "Train Epoch: 3 [2560/7654 (33%)]\tLoss: 0.041887\n",
      "Train Epoch: 3 [3200/7654 (42%)]\tLoss: 0.025970\n",
      "Train Epoch: 3 [3840/7654 (50%)]\tLoss: 0.045214\n",
      "Train Epoch: 3 [4480/7654 (58%)]\tLoss: 0.015224\n",
      "Train Epoch: 3 [5120/7654 (67%)]\tLoss: 0.056707\n",
      "Train Epoch: 3 [5760/7654 (75%)]\tLoss: 0.019227\n",
      "Train Epoch: 3 [6400/7654 (83%)]\tLoss: 0.039914\n",
      "Train Epoch: 3 [7040/7654 (92%)]\tLoss: 0.034221\n",
      "Train Epoch: 4 [0/7654 (0%)]\tLoss: 0.008221\n",
      "Train Epoch: 4 [640/7654 (8%)]\tLoss: 0.004241\n",
      "Train Epoch: 4 [1280/7654 (17%)]\tLoss: 0.007477\n",
      "Train Epoch: 4 [1920/7654 (25%)]\tLoss: 0.017741\n",
      "Train Epoch: 4 [2560/7654 (33%)]\tLoss: 0.029592\n",
      "Train Epoch: 4 [3200/7654 (42%)]\tLoss: 0.042207\n",
      "Train Epoch: 4 [3840/7654 (50%)]\tLoss: 0.007192\n",
      "Train Epoch: 4 [4480/7654 (58%)]\tLoss: 0.004988\n",
      "Train Epoch: 4 [5120/7654 (67%)]\tLoss: 0.009558\n",
      "Train Epoch: 4 [5760/7654 (75%)]\tLoss: 0.006056\n",
      "Train Epoch: 4 [6400/7654 (83%)]\tLoss: 0.056641\n",
      "Train Epoch: 4 [7040/7654 (92%)]\tLoss: 0.015361\n",
      "Train Epoch: 5 [0/7654 (0%)]\tLoss: 0.004976\n",
      "Train Epoch: 5 [640/7654 (8%)]\tLoss: 0.025275\n",
      "Train Epoch: 5 [1280/7654 (17%)]\tLoss: 0.038657\n",
      "Train Epoch: 5 [1920/7654 (25%)]\tLoss: 0.015231\n",
      "Train Epoch: 5 [2560/7654 (33%)]\tLoss: 0.101326\n",
      "Train Epoch: 5 [3200/7654 (42%)]\tLoss: 0.017499\n",
      "Train Epoch: 5 [3840/7654 (50%)]\tLoss: 0.044733\n",
      "Train Epoch: 5 [4480/7654 (58%)]\tLoss: 0.017245\n",
      "Train Epoch: 5 [5120/7654 (67%)]\tLoss: 0.007810\n",
      "Train Epoch: 5 [5760/7654 (75%)]\tLoss: 0.002348\n",
      "Train Epoch: 5 [6400/7654 (83%)]\tLoss: 0.013088\n",
      "Train Epoch: 5 [7040/7654 (92%)]\tLoss: 0.053588\n",
      "Train Epoch: 6 [0/7654 (0%)]\tLoss: 0.008276\n",
      "Train Epoch: 6 [640/7654 (8%)]\tLoss: 0.061997\n",
      "Train Epoch: 6 [1280/7654 (17%)]\tLoss: 0.009387\n",
      "Train Epoch: 6 [1920/7654 (25%)]\tLoss: 0.003489\n",
      "Train Epoch: 6 [2560/7654 (33%)]\tLoss: 0.004809\n",
      "Train Epoch: 6 [3200/7654 (42%)]\tLoss: 0.004084\n",
      "Train Epoch: 6 [3840/7654 (50%)]\tLoss: 0.048800\n",
      "Train Epoch: 6 [4480/7654 (58%)]\tLoss: 0.013721\n",
      "Train Epoch: 6 [5120/7654 (67%)]\tLoss: 0.058692\n",
      "Train Epoch: 6 [5760/7654 (75%)]\tLoss: 0.017909\n",
      "Train Epoch: 6 [6400/7654 (83%)]\tLoss: 0.021490\n",
      "Train Epoch: 6 [7040/7654 (92%)]\tLoss: 0.006324\n",
      "Train Epoch: 7 [0/7654 (0%)]\tLoss: 0.020546\n",
      "Train Epoch: 7 [640/7654 (8%)]\tLoss: 0.036286\n",
      "Train Epoch: 7 [1280/7654 (17%)]\tLoss: 0.003635\n",
      "Train Epoch: 7 [1920/7654 (25%)]\tLoss: 0.001786\n",
      "Train Epoch: 7 [2560/7654 (33%)]\tLoss: 0.039631\n",
      "Train Epoch: 7 [3200/7654 (42%)]\tLoss: 0.007893\n",
      "Train Epoch: 7 [3840/7654 (50%)]\tLoss: 0.003127\n",
      "Train Epoch: 7 [4480/7654 (58%)]\tLoss: 0.013509\n",
      "Train Epoch: 7 [5120/7654 (67%)]\tLoss: 0.077499\n",
      "Train Epoch: 7 [5760/7654 (75%)]\tLoss: 0.015334\n",
      "Train Epoch: 7 [6400/7654 (83%)]\tLoss: 0.109428\n",
      "Train Epoch: 7 [7040/7654 (92%)]\tLoss: 0.014346\n",
      "Train Epoch: 8 [0/7654 (0%)]\tLoss: 0.001889\n",
      "Train Epoch: 8 [640/7654 (8%)]\tLoss: 0.002901\n",
      "Train Epoch: 8 [1280/7654 (17%)]\tLoss: 0.064928\n",
      "Train Epoch: 8 [1920/7654 (25%)]\tLoss: 0.008299\n",
      "Train Epoch: 8 [2560/7654 (33%)]\tLoss: 0.001763\n",
      "Train Epoch: 8 [3200/7654 (42%)]\tLoss: 0.002806\n",
      "Train Epoch: 8 [3840/7654 (50%)]\tLoss: 0.009797\n",
      "Train Epoch: 8 [4480/7654 (58%)]\tLoss: 0.069361\n",
      "Train Epoch: 8 [5120/7654 (67%)]\tLoss: 0.002964\n",
      "Train Epoch: 8 [5760/7654 (75%)]\tLoss: 0.027092\n",
      "Train Epoch: 8 [6400/7654 (83%)]\tLoss: 0.006577\n",
      "Train Epoch: 8 [7040/7654 (92%)]\tLoss: 0.003947\n",
      "Train Epoch: 9 [0/7654 (0%)]\tLoss: 0.005944\n",
      "Train Epoch: 9 [640/7654 (8%)]\tLoss: 0.006542\n",
      "Train Epoch: 9 [1280/7654 (17%)]\tLoss: 0.003020\n",
      "Train Epoch: 9 [1920/7654 (25%)]\tLoss: 0.023973\n",
      "Train Epoch: 9 [2560/7654 (33%)]\tLoss: 0.002594\n",
      "Train Epoch: 9 [3200/7654 (42%)]\tLoss: 0.029634\n",
      "Train Epoch: 9 [3840/7654 (50%)]\tLoss: 0.003131\n",
      "Train Epoch: 9 [4480/7654 (58%)]\tLoss: 0.001325\n",
      "Train Epoch: 9 [5120/7654 (67%)]\tLoss: 0.005190\n",
      "Train Epoch: 9 [5760/7654 (75%)]\tLoss: 0.011581\n",
      "Train Epoch: 9 [6400/7654 (83%)]\tLoss: 0.004856\n",
      "Train Epoch: 9 [7040/7654 (92%)]\tLoss: 0.007931\n",
      "Train Epoch: 10 [0/7654 (0%)]\tLoss: 0.005497\n",
      "Train Epoch: 10 [640/7654 (8%)]\tLoss: 0.001170\n",
      "Train Epoch: 10 [1280/7654 (17%)]\tLoss: 0.001910\n",
      "Train Epoch: 10 [1920/7654 (25%)]\tLoss: 0.001747\n",
      "Train Epoch: 10 [2560/7654 (33%)]\tLoss: 0.030273\n",
      "Train Epoch: 10 [3200/7654 (42%)]\tLoss: 0.006656\n",
      "Train Epoch: 10 [3840/7654 (50%)]\tLoss: 0.002634\n",
      "Train Epoch: 10 [4480/7654 (58%)]\tLoss: 0.005436\n",
      "Train Epoch: 10 [5120/7654 (67%)]\tLoss: 0.001293\n",
      "Train Epoch: 10 [5760/7654 (75%)]\tLoss: 0.007508\n",
      "Train Epoch: 10 [6400/7654 (83%)]\tLoss: 0.031661\n",
      "Train Epoch: 10 [7040/7654 (92%)]\tLoss: 0.016735\n",
      "after training[ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")]\n",
      "after fedaveraging[ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")]\n",
      "local_models in the distribute function [ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "), ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")]\n",
      "4\n",
      "local_models in the distribute function [ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")]\n",
      "1\n",
      "\n",
      "Test set: Avg. loss: 2.6226, Accuracy: 3394/10000 (34%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rounds_pca = 4\n",
    "\n",
    "for round_idx in range(rounds_pca):\n",
    "    \n",
    "    print(f\"Round {round_idx + 1}/{rounds_pca}\")\n",
    "\n",
    "    local_weights_pca = []\n",
    "    for client_idx, client_model in enumerate(local_models_pca):\n",
    "        print(f\"Training client {client_idx + 1}\")\n",
    "        \n",
    "        optimizer = optim.SGD(client_model.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "\n",
    "        train_losses = []\n",
    "        train_counter = []\n",
    "\n",
    "\n",
    "        for epoch in range(1, n_epochs + 1):  \n",
    "            train_resnet(epoch, client_model, pca_client_loaders[client_idx], optimizer, log_interval, train_losses, train_counter)\n",
    "        \n",
    "        client_weights = [param.data.numpy() for param in client_model.parameters()]\n",
    "        local_weights_pca.append(client_weights)\n",
    "        \n",
    "    print(f\"after training{local_models_pca}\")\n",
    "    global_weights_pca = federated_averaging(local_weights_pca)\n",
    "    print(f\"after fedaveraging{local_models_pca}\")\n",
    "\n",
    "    distribute_global_model(global_weights_pca,local_models_pca,single=False)\n",
    "\n",
    "    distribute_global_model(global_weights_pca,global_model_pca,single=True)\n",
    "    test_losses = []\n",
    "    test_resnet(global_model_pca,test_loader_pca,test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds_auto = 4\n",
    "\n",
    "for round_idx in range(rounds_auto):\n",
    "    print(f\"Round {round_idx + 1}/{rounds_auto}\")\n",
    "\n",
    "    local_weights_auto = []\n",
    "    for client_idx, client_model in enumerate(local_model_autoencoder):\n",
    "        print(f\"Training client {client_idx + 1}\")\n",
    "        \n",
    "        optimizer = optim.SGD(client_model.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "        \n",
    "        train_losses = []\n",
    "        train_counter = []\n",
    "\n",
    "        for epoch in range(1, n_epochs + 1):  \n",
    "            train(epoch, client_model, auto_client_loaders[client_idx], optimizer, log_interval, train_losses, train_counter)\n",
    "        \n",
    "        client_weights = [param.data.numpy() for param in client_model.parameters()]\n",
    "        local_weights_auto.append(client_weights)\n",
    "        \n",
    "    global_weights_auto = federated_averaging(local_weights_auto)\n",
    "\n",
    "    distribute_global_model(global_weights_auto,local_model_autoencoder,single=False)\n",
    "\n",
    "    distribute_global_model(global_weights_auto, global_model_auto,single=True)\n",
    "    test_losses = []\n",
    "    test(global_model_auto,test_loader_auto,test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounds_classic = 4\n",
    "\n",
    "for round_idx in range(rounds_classic):\n",
    "    \n",
    "    print(f\"Round {round_idx + 1}/{rounds_classic}\")\n",
    "\n",
    "    local_weights_classic = []\n",
    "    for client_idx, client_model in enumerate(local_models_classic):\n",
    "        print(f\"Training client {client_idx + 1}\")\n",
    "        \n",
    "        optimizer = optim.SGD(client_model.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)\n",
    "\n",
    "        train_losses = []\n",
    "        train_counter = []\n",
    "\n",
    "        for epoch in range(1, n_epochs + 1):  \n",
    "            train_resnet(epoch, client_model, classic_client_loaders[client_idx], optimizer, log_interval, train_losses, train_counter)\n",
    "        \n",
    "        client_weights = [param.data.numpy() for param in client_model.parameters()]\n",
    "        local_weights_classic.append(client_weights)\n",
    "        \n",
    "    print(f\"after training{local_models_classic}\")\n",
    "    global_weights_classic = federated_averaging(local_weights_classic)\n",
    "    print(f\"after fedaveraging{local_models_classic}\")\n",
    "\n",
    "    distribute_global_model(global_weights_classic,local_models_classic,single=False)\n",
    "\n",
    "    distribute_global_model(global_weights_classic,gloabl_model_classic,single=True)\n",
    "    test_losses = []\n",
    "    test_resnet(gloabl_model_classic,cifar10_test_loader,test_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
